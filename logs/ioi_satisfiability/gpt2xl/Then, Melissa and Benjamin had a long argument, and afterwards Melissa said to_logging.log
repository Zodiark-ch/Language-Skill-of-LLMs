[2024-07-24 10:31:13,214][explain_satisfiability.py][line:287][INFO] ############ CASE TEXT isThen, Melissa and Benjamin had a long argument, and afterwards Melissa said to
[2024-07-24 10:31:13,215][explain_satisfiability.py][line:288][INFO] ############ CASE Prediction is  Benjamin
[2024-07-24 10:31:13,215][explain_satisfiability.py][line:289][INFO] ############ Refined Forward Graph
[2024-07-24 10:31:13,215][explain_satisfiability.py][line:290][INFO] ****** Layer 1
[2024-07-24 10:31:13,215][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 0
[2024-07-24 10:31:13,215][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,215][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 1
[2024-07-24 10:31:13,216][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:31:13,216][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 2
[2024-07-24 10:31:13,216][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit16', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:31:13,216][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 3
[2024-07-24 10:31:13,216][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit24', 'circuit26']
[2024-07-24 10:31:13,216][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 4
[2024-07-24 10:31:13,216][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit26']
[2024-07-24 10:31:13,217][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 5
[2024-07-24 10:31:13,217][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:31:13,217][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 6
[2024-07-24 10:31:13,217][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit20', 'circuit22']
[2024-07-24 10:31:13,217][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 7
[2024-07-24 10:31:13,217][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit27']
[2024-07-24 10:31:13,217][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 8
[2024-07-24 10:31:13,218][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit21', 'circuit22', 'circuit23', 'circuit27']
[2024-07-24 10:31:13,218][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 9
[2024-07-24 10:31:13,218][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:31:13,218][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 10
[2024-07-24 10:31:13,218][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:31:13,218][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 11
[2024-07-24 10:31:13,218][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:31:13,219][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 12
[2024-07-24 10:31:13,219][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:13,219][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 13
[2024-07-24 10:31:13,219][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,219][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 14
[2024-07-24 10:31:13,219][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16']
[2024-07-24 10:31:13,219][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 15
[2024-07-24 10:31:13,220][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit24']
[2024-07-24 10:31:13,220][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 16
[2024-07-24 10:31:13,220][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit19', 'circuit20']
[2024-07-24 10:31:13,220][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 17
[2024-07-24 10:31:13,220][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,220][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 18
[2024-07-24 10:31:13,220][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit10', 'circuit11', 'circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit23', 'circuit26', 'circuit27']
[2024-07-24 10:31:13,220][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 19
[2024-07-24 10:31:13,220][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:31:13,220][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 20
[2024-07-24 10:31:13,220][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit7', 'circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,220][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 21
[2024-07-24 10:31:13,220][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:31:13,220][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 22
[2024-07-24 10:31:13,221][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit16', 'circuit17', 'circuit18', 'circuit20']
[2024-07-24 10:31:13,221][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 23
[2024-07-24 10:31:13,221][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit27']
[2024-07-24 10:31:13,221][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 24
[2024-07-24 10:31:13,221][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:31:13,221][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 25
[2024-07-24 10:31:13,221][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:31:13,221][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 26
[2024-07-24 10:31:13,221][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,221][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 27
[2024-07-24 10:31:13,221][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,221][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 28
[2024-07-24 10:31:13,221][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,222][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 0
[2024-07-24 10:31:13,222][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,222][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:13,222][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 1
[2024-07-24 10:31:13,222][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit21']
[2024-07-24 10:31:13,222][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit20', 'circuit26']
[2024-07-24 10:31:13,222][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 2
[2024-07-24 10:31:13,222][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit2', 'circuit13', 'circuit14', 'circuit16', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:31:13,222][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13']
[2024-07-24 10:31:13,222][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 3
[2024-07-24 10:31:13,222][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:31:13,222][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,222][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 4
[2024-07-24 10:31:13,223][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit19', 'circuit20', 'circuit23']
[2024-07-24 10:31:13,223][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,223][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 5
[2024-07-24 10:31:13,223][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,223][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,223][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 6
[2024-07-24 10:31:13,223][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:31:13,223][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,223][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 7
[2024-07-24 10:31:13,223][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit21', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:31:13,223][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21']
[2024-07-24 10:31:13,223][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 8
[2024-07-24 10:31:13,223][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit27']
[2024-07-24 10:31:13,223][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19']
[2024-07-24 10:31:13,224][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 9
[2024-07-24 10:31:13,224][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:31:13,224][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,224][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 10
[2024-07-24 10:31:13,224][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,224][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,224][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 11
[2024-07-24 10:31:13,224][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:31:13,224][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit26']
[2024-07-24 10:31:13,224][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 12
[2024-07-24 10:31:13,224][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:31:13,224][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,224][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 13
[2024-07-24 10:31:13,225][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,225][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit7', 'circuit8', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:31:13,225][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 14
[2024-07-24 10:31:13,225][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,225][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,225][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 15
[2024-07-24 10:31:13,225][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,225][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,225][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 16
[2024-07-24 10:31:13,225][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,225][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,225][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 17
[2024-07-24 10:31:13,225][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,225][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,226][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 18
[2024-07-24 10:31:13,226][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,226][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,226][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 19
[2024-07-24 10:31:13,226][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,226][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,226][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 20
[2024-07-24 10:31:13,226][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,226][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,226][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 21
[2024-07-24 10:31:13,226][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,226][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,226][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 22
[2024-07-24 10:31:13,227][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,227][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,227][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 23
[2024-07-24 10:31:13,227][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,227][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,227][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 24
[2024-07-24 10:31:13,227][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,227][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,227][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 25
[2024-07-24 10:31:13,227][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24']
[2024-07-24 10:31:13,227][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,227][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 26
[2024-07-24 10:31:13,227][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,227][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,228][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 27
[2024-07-24 10:31:13,228][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,228][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,228][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 28
[2024-07-24 10:31:13,228][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,228][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,228][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 0
[2024-07-24 10:31:13,228][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,228][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit5', 'circuit6', 'circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,228][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:13,228][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 1
[2024-07-24 10:31:13,228][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:31:13,228][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit24', 'circuit25']
[2024-07-24 10:31:13,229][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit26', 'circuit27']
[2024-07-24 10:31:13,229][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 2
[2024-07-24 10:31:13,229][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit26']
[2024-07-24 10:31:13,229][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,229][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,229][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 3
[2024-07-24 10:31:13,229][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,229][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,229][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0']
[2024-07-24 10:31:13,229][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 4
[2024-07-24 10:31:13,229][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit20']
[2024-07-24 10:31:13,229][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit20']
[2024-07-24 10:31:13,229][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,230][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 5
[2024-07-24 10:31:13,230][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:31:13,230][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit1', 'circuit7', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit20', 'circuit22', 'circuit25']
[2024-07-24 10:31:13,230][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20']
[2024-07-24 10:31:13,230][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 6
[2024-07-24 10:31:13,230][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:31:13,230][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,230][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17']
[2024-07-24 10:31:13,230][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 7
[2024-07-24 10:31:13,230][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit15', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:31:13,230][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,230][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,230][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 8
[2024-07-24 10:31:13,231][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:31:13,231][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,231][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,231][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 9
[2024-07-24 10:31:13,231][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,231][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,231][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,231][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 10
[2024-07-24 10:31:13,231][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,231][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,231][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,231][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 11
[2024-07-24 10:31:13,231][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:13,231][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit8', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:31:13,232][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:31:13,232][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 12
[2024-07-24 10:31:13,232][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit20', 'circuit22']
[2024-07-24 10:31:13,232][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,232][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,232][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 13
[2024-07-24 10:31:13,232][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:31:13,232][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit1', 'circuit5', 'circuit6', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:13,232][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit6', 'circuit8', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:13,232][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 14
[2024-07-24 10:31:13,232][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,232][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,232][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,233][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 15
[2024-07-24 10:31:13,233][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,233][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,233][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,233][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 16
[2024-07-24 10:31:13,233][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,233][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,233][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,233][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 17
[2024-07-24 10:31:13,233][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,233][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,233][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,233][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 18
[2024-07-24 10:31:13,233][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,234][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit26']
[2024-07-24 10:31:13,234][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,234][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 19
[2024-07-24 10:31:13,234][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,234][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit6', 'circuit7', 'circuit13', 'circuit14', 'circuit20']
[2024-07-24 10:31:13,234][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,234][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 20
[2024-07-24 10:31:13,234][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,234][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,234][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,234][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 21
[2024-07-24 10:31:13,234][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,234][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,234][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,234][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 22
[2024-07-24 10:31:13,234][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,234][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,234][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,235][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 23
[2024-07-24 10:31:13,235][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,235][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,235][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,235][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 24
[2024-07-24 10:31:13,235][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,235][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,235][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,235][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 25
[2024-07-24 10:31:13,235][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,235][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,235][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,235][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 26
[2024-07-24 10:31:13,235][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,235][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,235][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,235][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 27
[2024-07-24 10:31:13,235][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,235][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,235][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,236][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 28
[2024-07-24 10:31:13,236][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,236][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,236][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,236][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 0
[2024-07-24 10:31:13,236][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,236][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,236][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit7', 'circuit8', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:13,236][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit5', 'circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:13,236][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 1
[2024-07-24 10:31:13,236][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit6', 'circuit27']
[2024-07-24 10:31:13,236][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit6', 'circuit7', 'circuit14']
[2024-07-24 10:31:13,236][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit18', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:31:13,236][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,236][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 2
[2024-07-24 10:31:13,236][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit23', 'circuit24']
[2024-07-24 10:31:13,236][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit15']
[2024-07-24 10:31:13,236][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit23', 'circuit24']
[2024-07-24 10:31:13,236][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:31:13,236][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 3
[2024-07-24 10:31:13,237][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:31:13,237][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,237][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,237][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,237][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 4
[2024-07-24 10:31:13,237][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,237][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,237][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,237][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,237][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 5
[2024-07-24 10:31:13,237][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit28']
[2024-07-24 10:31:13,237][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0']
[2024-07-24 10:31:13,237][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,237][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,237][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 6
[2024-07-24 10:31:13,237][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,237][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,237][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,237][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,237][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 7
[2024-07-24 10:31:13,238][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:31:13,238][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,238][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,238][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,238][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 8
[2024-07-24 10:31:13,238][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,238][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,238][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,238][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,238][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 9
[2024-07-24 10:31:13,238][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit17', 'circuit20', 'circuit24']
[2024-07-24 10:31:13,238][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit21']
[2024-07-24 10:31:13,238][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,238][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,238][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 10
[2024-07-24 10:31:13,238][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,238][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit19']
[2024-07-24 10:31:13,238][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,238][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit25']
[2024-07-24 10:31:13,238][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 11
[2024-07-24 10:31:13,239][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit20']
[2024-07-24 10:31:13,239][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,239][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,239][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:31:13,239][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 12
[2024-07-24 10:31:13,239][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,239][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,239][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,239][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,239][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 13
[2024-07-24 10:31:13,239][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,239][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:13,239][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:13,239][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,239][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 14
[2024-07-24 10:31:13,239][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,239][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,239][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,239][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,239][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 15
[2024-07-24 10:31:13,240][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,240][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,240][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14']
[2024-07-24 10:31:13,240][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,240][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 16
[2024-07-24 10:31:13,240][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit20']
[2024-07-24 10:31:13,240][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,240][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,240][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,240][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 17
[2024-07-24 10:31:13,240][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,240][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,240][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,240][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,240][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 18
[2024-07-24 10:31:13,240][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,240][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,240][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,240][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,240][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 19
[2024-07-24 10:31:13,240][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,241][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit15']
[2024-07-24 10:31:13,241][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,241][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,241][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 20
[2024-07-24 10:31:13,241][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16']
[2024-07-24 10:31:13,241][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,241][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,241][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,241][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 21
[2024-07-24 10:31:13,241][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,241][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,241][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,241][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,241][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 22
[2024-07-24 10:31:13,241][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,241][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,241][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0']
[2024-07-24 10:31:13,241][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,241][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 23
[2024-07-24 10:31:13,241][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,242][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,242][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,242][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,242][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 24
[2024-07-24 10:31:13,242][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,242][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,242][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,242][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,242][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 25
[2024-07-24 10:31:13,242][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,242][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,242][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,242][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,242][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 26
[2024-07-24 10:31:13,242][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,242][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,242][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,242][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,242][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 27
[2024-07-24 10:31:13,242][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,243][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,243][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,243][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,243][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 28
[2024-07-24 10:31:13,243][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,243][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,243][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,243][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,243][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 0
[2024-07-24 10:31:13,243][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit5', 'circuit6', 'circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,243][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:13,243][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit7', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:13,243][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:13,243][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,243][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 1
[2024-07-24 10:31:13,243][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:31:13,243][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit23', 'circuit24']
[2024-07-24 10:31:13,243][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit22']
[2024-07-24 10:31:13,243][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:31:13,243][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit24']
[2024-07-24 10:31:13,244][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 2
[2024-07-24 10:31:13,244][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:31:13,244][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16']
[2024-07-24 10:31:13,244][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:31:13,244][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,244][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit24']
[2024-07-24 10:31:13,244][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 3
[2024-07-24 10:31:13,244][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,244][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:31:13,244][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14']
[2024-07-24 10:31:13,244][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,244][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,244][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 4
[2024-07-24 10:31:13,244][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16']
[2024-07-24 10:31:13,244][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13']
[2024-07-24 10:31:13,244][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit2', 'circuit4', 'circuit7', 'circuit10', 'circuit12', 'circuit13']
[2024-07-24 10:31:13,244][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit5']
[2024-07-24 10:31:13,244][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,244][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 5
[2024-07-24 10:31:13,244][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit18', 'circuit20', 'circuit24']
[2024-07-24 10:31:13,245][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,245][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,245][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,245][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,245][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 6
[2024-07-24 10:31:13,245][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit18', 'circuit19', 'circuit21']
[2024-07-24 10:31:13,245][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,245][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit23', 'circuit25']
[2024-07-24 10:31:13,245][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,245][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,245][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 7
[2024-07-24 10:31:13,245][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit20']
[2024-07-24 10:31:13,245][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,245][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,245][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:31:13,245][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,245][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 8
[2024-07-24 10:31:13,245][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,245][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,245][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,246][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,246][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,246][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 9
[2024-07-24 10:31:13,246][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,246][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,246][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit10', 'circuit12']
[2024-07-24 10:31:13,246][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit11', 'circuit14', 'circuit16', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:31:13,246][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,246][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 10
[2024-07-24 10:31:13,246][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:31:13,246][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,246][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,246][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,246][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,246][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 11
[2024-07-24 10:31:13,246][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,246][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,246][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,246][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,246][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,246][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 12
[2024-07-24 10:31:13,247][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,247][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,247][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit11', 'circuit13']
[2024-07-24 10:31:13,247][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,247][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,247][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 13
[2024-07-24 10:31:13,247][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,247][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit5', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,247][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,247][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,247][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit3', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:13,247][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 14
[2024-07-24 10:31:13,247][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14']
[2024-07-24 10:31:13,247][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit18', 'circuit20', 'circuit21', 'circuit24']
[2024-07-24 10:31:13,247][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:31:13,247][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,247][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,247][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 15
[2024-07-24 10:31:13,247][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit27']
[2024-07-24 10:31:13,247][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,248][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,248][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,248][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,248][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 16
[2024-07-24 10:31:13,248][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,248][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,248][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,248][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,248][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,248][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 17
[2024-07-24 10:31:13,248][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,248][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,248][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,248][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,248][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,248][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 18
[2024-07-24 10:31:13,248][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,248][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,248][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,248][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,249][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,249][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 19
[2024-07-24 10:31:13,249][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,249][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit6']
[2024-07-24 10:31:13,249][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,249][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,249][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,249][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 20
[2024-07-24 10:31:13,249][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,249][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,249][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,249][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,249][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,249][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 21
[2024-07-24 10:31:13,249][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,249][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,249][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,249][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,249][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,249][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 22
[2024-07-24 10:31:13,249][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,250][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,250][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,250][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,250][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,250][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 23
[2024-07-24 10:31:13,250][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit24']
[2024-07-24 10:31:13,250][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit16']
[2024-07-24 10:31:13,250][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,250][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit20', 'circuit21', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:31:13,250][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit22', 'circuit24']
[2024-07-24 10:31:13,250][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 24
[2024-07-24 10:31:13,250][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,250][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,250][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,250][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,250][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,250][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 25
[2024-07-24 10:31:13,250][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,250][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,250][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,251][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,251][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,251][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 26
[2024-07-24 10:31:13,251][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,251][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,251][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,251][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,251][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,251][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 27
[2024-07-24 10:31:13,251][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,251][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,251][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,251][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,251][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,251][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 28
[2024-07-24 10:31:13,251][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,251][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,251][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,251][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,251][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,252][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 0
[2024-07-24 10:31:13,252][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit7', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,252][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:13,252][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:13,252][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,252][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:13,252][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit4', 'circuit5', 'circuit7', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:13,252][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 1
[2024-07-24 10:31:13,252][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:31:13,252][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,252][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:31:13,252][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,252][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,252][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit18', 'circuit20', 'circuit22']
[2024-07-24 10:31:13,252][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 2
[2024-07-24 10:31:13,252][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,252][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,252][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,252][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit22', 'circuit23']
[2024-07-24 10:31:13,252][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit24']
[2024-07-24 10:31:13,253][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,253][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 3
[2024-07-24 10:31:13,253][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit27']
[2024-07-24 10:31:13,253][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21']
[2024-07-24 10:31:13,253][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23']
[2024-07-24 10:31:13,253][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit23']
[2024-07-24 10:31:13,253][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit24']
[2024-07-24 10:31:13,253][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit24']
[2024-07-24 10:31:13,253][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 4
[2024-07-24 10:31:13,253][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,253][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,253][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit7', 'circuit14']
[2024-07-24 10:31:13,253][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,253][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,253][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,253][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 5
[2024-07-24 10:31:13,253][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:31:13,253][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit19', 'circuit20']
[2024-07-24 10:31:13,253][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,253][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit26']
[2024-07-24 10:31:13,254][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,254][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,254][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 6
[2024-07-24 10:31:13,254][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit23', 'circuit24']
[2024-07-24 10:31:13,254][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15']
[2024-07-24 10:31:13,254][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13']
[2024-07-24 10:31:13,254][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13', 'circuit15', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:31:13,254][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit19', 'circuit22', 'circuit24']
[2024-07-24 10:31:13,254][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,254][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 7
[2024-07-24 10:31:13,254][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,254][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:31:13,254][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20']
[2024-07-24 10:31:13,254][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,254][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,254][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,254][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 8
[2024-07-24 10:31:13,254][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,254][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit24']
[2024-07-24 10:31:13,254][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,254][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,255][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,255][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,255][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 9
[2024-07-24 10:31:13,255][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,255][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,255][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,255][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,255][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,255][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,255][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 10
[2024-07-24 10:31:13,255][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,255][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,255][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,255][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,255][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,255][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,255][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 11
[2024-07-24 10:31:13,255][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:31:13,255][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit27']
[2024-07-24 10:31:13,255][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit13', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:31:13,256][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:31:13,256][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit24', 'circuit26']
[2024-07-24 10:31:13,256][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit16', 'circuit19', 'circuit21', 'circuit22']
[2024-07-24 10:31:13,256][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 12
[2024-07-24 10:31:13,256][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,256][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,256][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,256][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,256][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,256][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,256][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 13
[2024-07-24 10:31:13,256][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit20', 'circuit26']
[2024-07-24 10:31:13,256][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:31:13,256][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:31:13,256][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:31:13,256][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit15', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:31:13,256][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit10', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:31:13,256][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 14
[2024-07-24 10:31:13,256][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,256][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,257][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,257][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,257][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,257][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,257][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 15
[2024-07-24 10:31:13,257][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,257][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,257][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,257][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,257][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,257][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,257][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 16
[2024-07-24 10:31:13,257][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,257][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,257][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,257][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,257][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,257][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,257][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 17
[2024-07-24 10:31:13,257][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,257][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,258][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,258][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,258][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,258][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,258][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 18
[2024-07-24 10:31:13,258][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,258][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,258][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,258][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,258][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,258][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,258][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 19
[2024-07-24 10:31:13,258][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,258][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,258][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,258][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,258][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,258][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,258][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 20
[2024-07-24 10:31:13,258][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,259][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,259][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,259][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,259][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,259][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,259][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 21
[2024-07-24 10:31:13,259][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,259][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,259][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,259][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,259][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,259][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,259][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 22
[2024-07-24 10:31:13,259][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,259][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,259][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,259][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,259][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,259][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,259][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 23
[2024-07-24 10:31:13,259][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,260][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,260][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,260][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,260][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,260][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,260][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 24
[2024-07-24 10:31:13,260][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,260][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,260][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,260][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,260][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,260][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,260][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 25
[2024-07-24 10:31:13,260][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,260][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,260][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,260][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,260][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,260][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,260][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 26
[2024-07-24 10:31:13,261][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,261][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,261][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,261][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,261][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,261][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,261][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 27
[2024-07-24 10:31:13,261][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,261][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,261][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,261][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,261][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,261][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,261][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 28
[2024-07-24 10:31:13,261][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,261][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,261][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,261][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,261][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,261][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,262][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 0
[2024-07-24 10:31:13,262][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit6', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,262][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:31:13,262][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,262][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit4', 'circuit11', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:13,262][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:13,262][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:13,262][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit6', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:13,262][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 1
[2024-07-24 10:31:13,262][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,262][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,262][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,262][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,262][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,262][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,262][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,262][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 2
[2024-07-24 10:31:13,262][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit22', 'circuit27']
[2024-07-24 10:31:13,262][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15']
[2024-07-24 10:31:13,262][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit24']
[2024-07-24 10:31:13,263][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,263][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit20']
[2024-07-24 10:31:13,263][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit17', 'circuit20', 'circuit23']
[2024-07-24 10:31:13,263][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,263][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 3
[2024-07-24 10:31:13,263][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,263][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,263][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,263][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,263][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit23']
[2024-07-24 10:31:13,263][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,263][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit19', 'circuit23']
[2024-07-24 10:31:13,263][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 4
[2024-07-24 10:31:13,263][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,263][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit6']
[2024-07-24 10:31:13,263][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,263][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,263][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,263][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,263][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,263][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 5
[2024-07-24 10:31:13,264][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,264][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,264][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,264][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,264][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,264][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,264][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,264][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 6
[2024-07-24 10:31:13,264][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,264][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,264][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,264][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,264][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,264][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,264][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,264][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 7
[2024-07-24 10:31:13,264][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit27']
[2024-07-24 10:31:13,264][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit2', 'circuit13', 'circuit14', 'circuit15', 'circuit18', 'circuit19', 'circuit20']
[2024-07-24 10:31:13,264][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:31:13,264][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,265][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,265][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,265][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,265][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 8
[2024-07-24 10:31:13,265][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,265][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,265][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,265][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,265][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,265][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,265][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,265][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 9
[2024-07-24 10:31:13,265][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,265][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,265][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,265][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,265][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,265][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,265][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,265][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 10
[2024-07-24 10:31:13,265][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,266][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,266][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit6', 'circuit9', 'circuit10']
[2024-07-24 10:31:13,266][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,266][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,266][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,266][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,266][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 11
[2024-07-24 10:31:13,266][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14']
[2024-07-24 10:31:13,266][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,266][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,266][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,266][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,266][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,266][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,266][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 12
[2024-07-24 10:31:13,266][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20']
[2024-07-24 10:31:13,266][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,266][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,266][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,266][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,266][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,267][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,267][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 13
[2024-07-24 10:31:13,267][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:31:13,267][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit19', 'circuit21', 'circuit22', 'circuit26']
[2024-07-24 10:31:13,267][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit17']
[2024-07-24 10:31:13,267][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit18', 'circuit19', 'circuit21', 'circuit25', 'circuit27']
[2024-07-24 10:31:13,267][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit4', 'circuit14', 'circuit15', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:31:13,267][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit5', 'circuit11', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:31:13,267][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit13', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:31:13,267][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 14
[2024-07-24 10:31:13,267][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,267][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,267][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,267][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,267][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,267][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,267][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,267][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 15
[2024-07-24 10:31:13,267][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,267][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,268][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,268][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,268][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,268][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,268][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,268][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 16
[2024-07-24 10:31:13,268][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,268][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,268][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,268][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,268][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,268][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,268][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,268][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 17
[2024-07-24 10:31:13,268][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,268][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,268][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,268][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,268][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,268][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,268][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,269][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 18
[2024-07-24 10:31:13,269][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,269][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,269][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,269][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,269][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,269][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,269][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,269][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 19
[2024-07-24 10:31:13,269][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,269][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,269][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,269][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,269][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,269][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,269][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,269][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 20
[2024-07-24 10:31:13,269][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,269][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,269][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,270][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,270][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,270][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,270][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,270][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 21
[2024-07-24 10:31:13,270][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,270][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,270][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,270][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,270][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,270][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,270][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,270][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 22
[2024-07-24 10:31:13,270][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,270][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,270][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,270][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,270][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,270][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,270][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,271][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 23
[2024-07-24 10:31:13,271][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,271][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,271][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,271][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,271][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,271][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,271][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,271][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 24
[2024-07-24 10:31:13,271][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,271][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,271][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,271][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,271][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,271][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,271][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,271][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 25
[2024-07-24 10:31:13,271][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,271][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,271][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,271][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,272][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,272][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,272][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,272][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 26
[2024-07-24 10:31:13,272][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,272][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,272][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,272][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,272][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,272][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,272][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,272][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 27
[2024-07-24 10:31:13,272][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,272][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,272][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,272][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,272][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,272][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,272][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,272][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 28
[2024-07-24 10:31:13,273][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,273][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,273][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,273][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,273][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,273][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,273][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,273][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 0
[2024-07-24 10:31:13,273][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit8', 'circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,273][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit8', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:13,273][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit7', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:13,273][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit6', 'circuit7', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:13,273][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit3', 'circuit6', 'circuit7', 'circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:31:13,273][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit3', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:13,273][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit8', 'circuit12', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:31:13,273][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit7', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:13,273][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 1
[2024-07-24 10:31:13,273][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit20', 'circuit23', 'circuit25']
[2024-07-24 10:31:13,273][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,273][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:31:13,274][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit25']
[2024-07-24 10:31:13,274][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,274][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,274][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit24', 'circuit25']
[2024-07-24 10:31:13,274][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,274][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 2
[2024-07-24 10:31:13,274][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,274][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,274][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,274][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13']
[2024-07-24 10:31:13,274][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0']
[2024-07-24 10:31:13,274][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit13']
[2024-07-24 10:31:13,274][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0']
[2024-07-24 10:31:13,274][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit13', 'circuit18', 'circuit22', 'circuit23']
[2024-07-24 10:31:13,274][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 3
[2024-07-24 10:31:13,274][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:31:13,274][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,274][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,274][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,274][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit18', 'circuit23', 'circuit24']
[2024-07-24 10:31:13,275][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,275][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,275][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit23', 'circuit24']
[2024-07-24 10:31:13,275][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 4
[2024-07-24 10:31:13,275][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit24']
[2024-07-24 10:31:13,275][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit16']
[2024-07-24 10:31:13,275][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit8', 'circuit13', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit27']
[2024-07-24 10:31:13,275][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit18', 'circuit22', 'circuit27']
[2024-07-24 10:31:13,275][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit3', 'circuit26']
[2024-07-24 10:31:13,275][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0']
[2024-07-24 10:31:13,275][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0']
[2024-07-24 10:31:13,275][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0']
[2024-07-24 10:31:13,275][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 5
[2024-07-24 10:31:13,275][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,275][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,275][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,275][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,275][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,275][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,275][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,275][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,276][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 6
[2024-07-24 10:31:13,276][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,276][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,276][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,276][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,276][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,276][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,276][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,276][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit13']
[2024-07-24 10:31:13,276][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 7
[2024-07-24 10:31:13,276][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:31:13,276][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,276][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:31:13,276][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit15', 'circuit16', 'circuit23']
[2024-07-24 10:31:13,276][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit20', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:31:13,276][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit21', 'circuit23']
[2024-07-24 10:31:13,276][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:31:13,276][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,276][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 8
[2024-07-24 10:31:13,276][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,276][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,277][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,277][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,277][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,277][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,277][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,277][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,277][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 9
[2024-07-24 10:31:13,277][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,277][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,277][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,277][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,277][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,277][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,277][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,277][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,277][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 10
[2024-07-24 10:31:13,277][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit24']
[2024-07-24 10:31:13,277][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,277][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,277][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,278][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,278][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,278][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,278][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,278][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 11
[2024-07-24 10:31:13,278][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,278][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,278][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,278][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,278][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,278][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,278][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,278][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,278][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 12
[2024-07-24 10:31:13,278][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,278][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,278][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,278][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,278][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,278][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,278][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,279][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,279][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 13
[2024-07-24 10:31:13,279][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:31:13,279][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit16', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:31:13,279][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,279][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,279][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit16', 'circuit18']
[2024-07-24 10:31:13,279][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,279][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit13', 'circuit24', 'circuit25']
[2024-07-24 10:31:13,279][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,279][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 14
[2024-07-24 10:31:13,279][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,279][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,279][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,279][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,279][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,279][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,279][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,279][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,279][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 15
[2024-07-24 10:31:13,279][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,280][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,280][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,280][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,280][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,280][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,280][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,280][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,280][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 16
[2024-07-24 10:31:13,280][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,280][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,280][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,280][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,280][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,280][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,280][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,280][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,280][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 17
[2024-07-24 10:31:13,280][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,280][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,280][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,280][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,281][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,281][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,281][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,281][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,281][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 18
[2024-07-24 10:31:13,281][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,281][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,281][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,281][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,281][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,281][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,281][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,281][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,281][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 19
[2024-07-24 10:31:13,281][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,281][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,281][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,281][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,281][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,281][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,282][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,282][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,282][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 20
[2024-07-24 10:31:13,282][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,282][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,282][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,282][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,282][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,282][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,282][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,282][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,282][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 21
[2024-07-24 10:31:13,282][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,282][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,282][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,282][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,282][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,282][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,282][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,282][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,282][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 22
[2024-07-24 10:31:13,283][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,283][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,283][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,283][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,283][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,283][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,283][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,283][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,283][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 23
[2024-07-24 10:31:13,283][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,283][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,283][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,283][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,283][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,283][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,283][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,283][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,283][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 24
[2024-07-24 10:31:13,283][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,283][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,283][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,284][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,284][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,284][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,284][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,284][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,284][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 25
[2024-07-24 10:31:13,284][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,284][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,284][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,284][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,284][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,284][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,284][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,284][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,284][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 26
[2024-07-24 10:31:13,284][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,284][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,284][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,284][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,284][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,285][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,285][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,285][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,285][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 27
[2024-07-24 10:31:13,285][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,285][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,285][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,285][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,285][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,285][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,285][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,285][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,285][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 28
[2024-07-24 10:31:13,285][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,285][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,285][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,285][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,285][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,285][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,285][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,286][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,286][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 0
[2024-07-24 10:31:13,286][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:13,286][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit6', 'circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:31:13,286][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:31:13,286][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:31:13,286][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:31:13,286][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:31:13,286][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit6', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:31:13,286][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:31:13,286][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:31:13,286][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 1
[2024-07-24 10:31:13,286][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,286][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,286][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,286][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,286][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,286][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,286][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,286][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,286][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:13,287][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 2
[2024-07-24 10:31:13,287][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,287][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,287][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,287][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,287][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,287][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,287][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,287][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,287][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:13,287][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 3
[2024-07-24 10:31:13,287][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,287][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,287][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,287][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,287][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,287][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,287][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,287][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,287][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:13,288][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 4
[2024-07-24 10:31:13,288][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,288][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,288][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,288][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,288][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,288][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,288][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,288][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,288][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:13,288][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 5
[2024-07-24 10:31:13,288][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,288][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,288][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,288][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,288][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,288][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,288][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,288][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,288][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:13,288][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 6
[2024-07-24 10:31:13,289][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,289][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,289][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,289][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,289][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,289][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,289][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,289][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,289][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:13,289][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 7
[2024-07-24 10:31:13,289][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,289][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,289][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,289][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,289][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,289][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,289][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,289][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,289][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:13,289][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 8
[2024-07-24 10:31:13,289][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,290][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,290][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,290][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,290][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,290][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,290][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,290][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,290][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:13,290][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 9
[2024-07-24 10:31:13,290][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,290][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,290][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,290][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,290][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,290][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,290][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,290][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,290][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:13,290][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 10
[2024-07-24 10:31:13,291][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,291][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,291][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,291][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,291][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,291][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,291][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,291][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,291][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:13,291][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 11
[2024-07-24 10:31:13,291][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,291][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,291][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,291][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,291][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,291][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,291][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,291][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,291][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:13,291][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 12
[2024-07-24 10:31:13,291][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,292][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,292][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,292][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,292][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,292][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,292][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,292][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,292][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:13,292][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 13
[2024-07-24 10:31:13,292][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,292][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit7', 'circuit8', 'circuit17', 'circuit19', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:31:13,292][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,292][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0']
[2024-07-24 10:31:13,292][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit13', 'circuit22', 'circuit23']
[2024-07-24 10:31:13,292][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,292][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,292][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,292][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit21', 'circuit22']
[2024-07-24 10:31:13,292][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 14
[2024-07-24 10:31:13,292][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,292][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,293][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,293][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,293][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,293][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,293][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,293][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,293][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:13,293][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 15
[2024-07-24 10:31:13,293][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,293][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,293][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,293][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,293][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,293][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,293][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,293][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,293][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:13,293][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 16
[2024-07-24 10:31:13,293][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,293][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,293][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,294][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,294][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,294][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,294][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,294][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,294][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:13,294][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 17
[2024-07-24 10:31:13,294][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,294][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,294][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,294][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,294][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,294][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,294][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,294][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,294][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:13,294][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 18
[2024-07-24 10:31:13,294][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,294][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,294][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,295][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,295][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,295][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,295][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,295][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,295][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:13,295][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 19
[2024-07-24 10:31:13,295][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,295][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,295][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,295][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,295][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,295][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,295][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,295][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,295][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:13,295][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 20
[2024-07-24 10:31:13,295][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,295][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,295][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,295][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,296][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,296][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,296][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,296][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,296][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:13,296][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 21
[2024-07-24 10:31:13,296][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,296][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,296][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,296][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,296][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,296][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,296][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,296][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,296][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:13,296][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 22
[2024-07-24 10:31:13,296][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,296][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,296][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,296][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,296][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,297][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,297][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,297][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,297][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:13,297][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 23
[2024-07-24 10:31:13,297][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,297][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,297][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,297][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,297][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,297][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,297][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,297][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,297][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:13,297][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 24
[2024-07-24 10:31:13,297][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,297][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,297][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,297][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,297][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,297][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,298][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,298][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,298][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:13,298][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 25
[2024-07-24 10:31:13,298][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,298][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,298][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,298][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,298][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,298][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,298][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,298][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,298][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:13,298][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 26
[2024-07-24 10:31:13,298][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,298][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,298][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,298][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,298][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,298][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,299][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,299][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,299][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,299][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 27
[2024-07-24 10:31:13,299][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,299][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,299][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,299][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,299][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,299][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,299][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,299][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,299][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,299][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 28
[2024-07-24 10:31:13,299][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,299][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,299][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,299][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,299][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,299][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,300][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,300][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,300][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,300][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 0
[2024-07-24 10:31:13,300][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:31:13,300][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit15', 'circuit24']
[2024-07-24 10:31:13,300][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit19', 'circuit22', 'circuit23']
[2024-07-24 10:31:13,300][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:31:13,300][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit18', 'circuit20', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:31:13,300][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:31:13,300][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit13', 'circuit14', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:31:13,300][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:31:13,300][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit17', 'circuit21', 'circuit25']
[2024-07-24 10:31:13,300][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:31:13,300][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 1
[2024-07-24 10:31:13,300][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,300][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,300][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,300][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,300][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,301][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,301][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,301][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,301][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:13,301][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:13,301][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 2
[2024-07-24 10:31:13,301][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,301][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,301][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,301][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,301][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,301][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,301][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,301][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,301][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:13,301][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:13,301][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 3
[2024-07-24 10:31:13,301][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,301][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,301][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,301][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,302][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,302][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,302][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,302][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,302][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:13,302][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-24 10:31:13,302][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 4
[2024-07-24 10:31:13,302][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,302][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,302][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,302][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,302][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:31:13,302][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,302][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,302][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit24']
[2024-07-24 10:31:13,302][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit21']
[2024-07-24 10:31:13,302][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit16', 'circuit19', 'circuit22']
[2024-07-24 10:31:13,302][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 5
[2024-07-24 10:31:13,302][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,302][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,302][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,303][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,303][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,303][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,303][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,303][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,303][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:13,303][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit23']
[2024-07-24 10:31:13,303][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 6
[2024-07-24 10:31:13,303][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,303][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,303][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,303][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,303][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,303][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,303][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,303][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,303][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit14', 'circuit16', 'circuit18', 'circuit19']
[2024-07-24 10:31:13,303][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-24 10:31:13,303][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 7
[2024-07-24 10:31:13,303][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit21', 'circuit23', 'circuit24']
[2024-07-24 10:31:13,304][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,304][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,304][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,304][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,304][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,304][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,304][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,304][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:13,304][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:13,304][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 8
[2024-07-24 10:31:13,304][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,304][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,304][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,304][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,304][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,304][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,304][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,304][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,304][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:13,304][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:13,304][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 9
[2024-07-24 10:31:13,305][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,305][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,305][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,305][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,305][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,305][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,305][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,305][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,305][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:13,305][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:13,305][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 10
[2024-07-24 10:31:13,305][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,305][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,305][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,305][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,305][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,305][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,305][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,305][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,305][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:13,305][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:13,306][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 11
[2024-07-24 10:31:13,306][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,306][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,306][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,306][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,306][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,306][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,306][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,306][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,306][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:13,306][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:13,306][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 12
[2024-07-24 10:31:13,306][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,306][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,306][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,306][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,306][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,306][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,306][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,306][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,306][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:13,307][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:13,307][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 13
[2024-07-24 10:31:13,307][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:31:13,307][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit22']
[2024-07-24 10:31:13,307][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit23']
[2024-07-24 10:31:13,307][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,307][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,307][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,307][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,307][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,307][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:13,307][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit16', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:31:13,307][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 14
[2024-07-24 10:31:13,307][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,307][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,307][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,307][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,307][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,307][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,307][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,307][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,308][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:13,308][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:13,308][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 15
[2024-07-24 10:31:13,308][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,308][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,308][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,308][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,308][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,308][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,308][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,308][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,308][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:13,308][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:13,308][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 16
[2024-07-24 10:31:13,308][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,308][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,308][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,308][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,308][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,308][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,309][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,309][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,309][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:13,309][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:13,309][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 17
[2024-07-24 10:31:13,309][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,309][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,309][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,309][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,309][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,309][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,309][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,309][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,309][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:13,309][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:13,309][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 18
[2024-07-24 10:31:13,309][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,309][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,309][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,309][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,309][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,310][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,310][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,310][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,310][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:13,310][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:13,310][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 19
[2024-07-24 10:31:13,310][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,310][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,310][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,310][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,310][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,310][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,310][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,310][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,310][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:13,310][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:13,310][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 20
[2024-07-24 10:31:13,310][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,310][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,310][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,310][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,311][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,311][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,311][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,311][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,311][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:13,311][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:13,311][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 21
[2024-07-24 10:31:13,311][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,311][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,311][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,311][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,311][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,311][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,311][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,311][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,311][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:13,311][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:13,311][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 22
[2024-07-24 10:31:13,311][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,311][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,312][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,312][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,312][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,312][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,312][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,312][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,312][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:13,312][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:13,312][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 23
[2024-07-24 10:31:13,312][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,312][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,312][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,312][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,312][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,312][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,312][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,312][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,312][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:13,312][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:13,312][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 24
[2024-07-24 10:31:13,312][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,313][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,313][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,313][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,313][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,313][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,313][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,313][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,313][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:13,313][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:13,313][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 25
[2024-07-24 10:31:13,313][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,313][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,313][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,313][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,313][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,313][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,313][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,313][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,313][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:13,313][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:13,313][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 26
[2024-07-24 10:31:13,314][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,314][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,314][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,314][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,314][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,314][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,314][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,314][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,314][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,314][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,314][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 27
[2024-07-24 10:31:13,314][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,314][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,314][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,314][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,314][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,314][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,314][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,314][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,314][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,315][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,315][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 28
[2024-07-24 10:31:13,315][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,315][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,315][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,315][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,315][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,315][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,315][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,315][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,315][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,315][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,315][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 0
[2024-07-24 10:31:13,315][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit22', 'circuit25', 'circuit27']
[2024-07-24 10:31:13,315][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,315][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit20', 'circuit22', 'circuit23', 'circuit27']
[2024-07-24 10:31:13,315][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit20', 'circuit21', 'circuit22', 'circuit25', 'circuit27']
[2024-07-24 10:31:13,315][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit24', 'circuit27']
[2024-07-24 10:31:13,315][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,315][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit7', 'circuit8']
[2024-07-24 10:31:13,316][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit7', 'circuit23', 'circuit27']
[2024-07-24 10:31:13,316][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit14', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:31:13,316][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit16', 'circuit17', 'circuit19', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:31:13,316][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit13', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:31:13,316][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 1
[2024-07-24 10:31:13,316][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,316][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,316][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,316][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,316][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,316][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,316][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,316][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,316][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:13,316][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:13,316][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:31:13,316][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 2
[2024-07-24 10:31:13,316][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,316][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,316][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,317][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,317][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,317][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,317][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,317][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,317][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:13,317][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:13,317][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:31:13,317][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 3
[2024-07-24 10:31:13,317][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,317][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,317][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,317][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,317][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,317][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,317][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,317][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,317][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:13,317][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:13,317][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:31:13,317][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 4
[2024-07-24 10:31:13,318][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,318][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,318][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,318][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,318][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,318][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,318][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,318][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,318][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:13,318][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:13,318][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:31:13,318][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 5
[2024-07-24 10:31:13,318][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,318][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,318][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,318][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,318][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,318][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,318][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,318][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,318][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:13,319][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:13,319][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:31:13,319][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 6
[2024-07-24 10:31:13,319][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,319][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,319][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,319][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,319][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,319][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,319][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,319][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,319][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:13,319][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:13,319][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:31:13,319][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 7
[2024-07-24 10:31:13,319][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,319][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,319][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,319][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,319][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,319][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,320][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,320][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,320][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:13,320][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:13,320][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:31:13,320][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 8
[2024-07-24 10:31:13,320][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,320][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,320][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,320][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,320][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,320][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,320][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,320][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,320][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:13,320][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:13,320][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:31:13,320][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 9
[2024-07-24 10:31:13,320][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit21', 'circuit22']
[2024-07-24 10:31:13,320][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit22']
[2024-07-24 10:31:13,320][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit23', 'circuit24']
[2024-07-24 10:31:13,321][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:31:13,321][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit17', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:31:13,321][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:31:13,321][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:31:13,321][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit25']
[2024-07-24 10:31:13,321][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit13', 'circuit21', 'circuit23', 'circuit24']
[2024-07-24 10:31:13,321][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit5', 'circuit7', 'circuit8', 'circuit9', 'circuit15', 'circuit16', 'circuit17', 'circuit22', 'circuit25']
[2024-07-24 10:31:13,321][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0']
[2024-07-24 10:31:13,321][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 10
[2024-07-24 10:31:13,321][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit24']
[2024-07-24 10:31:13,321][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,321][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,321][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,321][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,321][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,321][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,321][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,321][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:13,321][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:13,321][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0']
[2024-07-24 10:31:13,321][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 11
[2024-07-24 10:31:13,322][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,322][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,322][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,322][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,322][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,322][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,322][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,322][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,322][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:13,322][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:13,322][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0']
[2024-07-24 10:31:13,322][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 12
[2024-07-24 10:31:13,322][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,322][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,322][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,322][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,322][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,322][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,322][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,322][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,322][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:13,323][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit16', 'circuit17', 'circuit23', 'circuit25']
[2024-07-24 10:31:13,323][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0']
[2024-07-24 10:31:13,323][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 13
[2024-07-24 10:31:13,323][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,323][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,323][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,323][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,323][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit17']
[2024-07-24 10:31:13,323][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit22', 'circuit24']
[2024-07-24 10:31:13,323][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit17', 'circuit24', 'circuit25']
[2024-07-24 10:31:13,323][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,323][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:13,323][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit22', 'circuit25']
[2024-07-24 10:31:13,323][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:31:13,323][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 14
[2024-07-24 10:31:13,323][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,323][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,323][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,323][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,323][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,324][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,324][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,324][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,324][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:13,324][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:13,324][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:31:13,324][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 15
[2024-07-24 10:31:13,324][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,324][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,324][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,324][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,324][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,324][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,324][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,324][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,324][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:13,324][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:13,324][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:31:13,324][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 16
[2024-07-24 10:31:13,324][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,324][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,325][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,325][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,325][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,325][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,325][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,325][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,325][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:13,325][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:13,325][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:31:13,325][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 17
[2024-07-24 10:31:13,325][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,325][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,325][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,325][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,325][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,325][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,325][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,325][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,325][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:13,325][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:13,325][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:31:13,326][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 18
[2024-07-24 10:31:13,326][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,326][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,326][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,326][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,326][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,326][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,326][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,326][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,326][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:13,326][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:13,326][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:31:13,326][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 19
[2024-07-24 10:31:13,326][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,326][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,326][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,326][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,326][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,326][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,326][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,326][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,327][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:13,327][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:13,327][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:31:13,327][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 20
[2024-07-24 10:31:13,327][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,327][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,327][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,327][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,327][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,327][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,327][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,327][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,327][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:13,327][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:13,327][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:31:13,327][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 21
[2024-07-24 10:31:13,327][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,327][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,327][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,327][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,327][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,328][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,328][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,328][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,328][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:13,328][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:13,328][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:31:13,328][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 22
[2024-07-24 10:31:13,328][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,328][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,328][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,328][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,328][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,328][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,328][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,328][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,328][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:13,328][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:13,328][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:31:13,328][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 23
[2024-07-24 10:31:13,328][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,328][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,329][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,329][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,329][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,329][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,329][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,329][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,329][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:13,329][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:13,329][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:31:13,329][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 24
[2024-07-24 10:31:13,329][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,329][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,329][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,329][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,329][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,329][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,329][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,329][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,329][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:13,329][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:13,329][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:31:13,330][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 25
[2024-07-24 10:31:13,330][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:31:13,330][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:31:13,330][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:31:13,330][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:31:13,330][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:31:13,330][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:31:13,330][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:31:13,330][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:31:13,330][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:31:13,330][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:31:13,330][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:31:13,330][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 26
[2024-07-24 10:31:13,330][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,330][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,330][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,330][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,330][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,330][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,330][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,331][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,331][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,331][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,331][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,331][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 27
[2024-07-24 10:31:13,331][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,331][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,331][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,331][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,331][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,331][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,331][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,331][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,331][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,331][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,331][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,331][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 28
[2024-07-24 10:31:13,331][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,331][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,331][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,332][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,332][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,332][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,332][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,332][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,332][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,332][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:13,332][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:31:14,452][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:31:14,453][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:14,455][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:14,456][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:14,457][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:14,458][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:14,459][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:14,460][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:14,461][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:14,463][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:14,464][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:14,465][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:14,465][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:14,466][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.9675, 0.0325], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:14,466][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0065, 0.9935], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:14,466][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.6358, 0.3642], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:14,467][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.6853, 0.3147], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:14,467][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.9772, 0.0228], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:14,468][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.2539, 0.7461], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:14,468][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.9881, 0.0119], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:14,468][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.9119, 0.0881], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:14,469][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.3215, 0.6785], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:14,469][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.7118, 0.2882], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:14,471][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.7102, 0.2898], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:14,472][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.6916, 0.3084], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:14,473][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Melissa] are: tensor([0.5522, 0.3627, 0.0850], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:14,474][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Melissa] are: tensor([6.3831e-04, 6.2358e-04, 9.9874e-01], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:14,475][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Melissa] are: tensor([0.6069, 0.2279, 0.1652], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:14,476][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Melissa] are: tensor([5.8955e-02, 9.3021e-04, 9.4011e-01], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:14,477][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Melissa] are: tensor([0.0502, 0.0048, 0.9450], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:14,478][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Melissa] are: tensor([1.4103e-02, 7.3540e-06, 9.8589e-01], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:14,480][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Melissa] are: tensor([0.3676, 0.4027, 0.2297], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:14,481][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Melissa] are: tensor([0.5706, 0.3015, 0.1280], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:14,482][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Melissa] are: tensor([0.5401, 0.2517, 0.2082], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:14,484][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Melissa] are: tensor([0.6116, 0.3270, 0.0614], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:14,485][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Melissa] are: tensor([0.4014, 0.2711, 0.3274], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:14,487][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Melissa] are: tensor([0.4556, 0.3438, 0.2006], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:14,488][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.6847, 0.0776, 0.1772, 0.0605], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:14,489][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ and] are: tensor([2.3020e-03, 3.9238e-02, 7.2233e-04, 9.5774e-01], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:14,490][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.2410, 0.1804, 0.0235, 0.5551], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:14,492][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.1132, 0.3869, 0.0267, 0.4733], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:14,492][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.3234, 0.1465, 0.2646, 0.2654], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:14,492][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1229, 0.1967, 0.0085, 0.6719], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:14,493][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.6087, 0.0291, 0.3401, 0.0221], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:14,493][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.2272, 0.1728, 0.3399, 0.2601], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:14,494][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0667, 0.4674, 0.0276, 0.4383], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:14,494][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.4297, 0.2399, 0.1075, 0.2229], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:14,494][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.4198, 0.3127, 0.0613, 0.2063], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:14,495][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.4426, 0.1933, 0.1114, 0.2526], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:14,496][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Benjamin] are: tensor([0.3592, 0.2662, 0.0793, 0.1633, 0.1320], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:14,497][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Benjamin] are: tensor([8.3391e-05, 1.1915e-04, 9.6542e-04, 8.2812e-05, 9.9875e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:14,498][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Benjamin] are: tensor([0.4947, 0.1676, 0.1070, 0.0870, 0.1437], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:14,499][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Benjamin] are: tensor([4.3862e-03, 4.6049e-05, 1.0389e-02, 2.4227e-04, 9.8494e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:14,500][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Benjamin] are: tensor([0.0260, 0.0044, 0.0434, 0.0068, 0.9193], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:14,501][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Benjamin] are: tensor([6.2693e-03, 1.6773e-06, 3.9269e-05, 4.3091e-07, 9.9369e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:14,502][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Benjamin] are: tensor([0.2204, 0.1621, 0.2434, 0.0824, 0.2918], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:14,504][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Benjamin] are: tensor([0.1447, 0.1350, 0.2837, 0.2755, 0.1612], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:14,505][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Benjamin] are: tensor([0.3370, 0.2172, 0.1119, 0.1443, 0.1896], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:14,507][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Benjamin] are: tensor([0.3910, 0.2125, 0.2131, 0.1649, 0.0184], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:14,508][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Benjamin] are: tensor([0.3084, 0.2082, 0.0557, 0.1296, 0.2982], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:14,510][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Benjamin] are: tensor([0.2831, 0.2183, 0.0818, 0.2905, 0.1262], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:14,511][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.4209, 0.0370, 0.1249, 0.0368, 0.0562, 0.3242], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:14,512][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ had] are: tensor([3.2186e-04, 1.6738e-03, 1.2185e-03, 2.8590e-03, 1.9608e-04, 9.9373e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:14,513][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.4805, 0.1225, 0.0766, 0.1450, 0.0318, 0.1436], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:14,515][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.0049, 0.0054, 0.0032, 0.0114, 0.0031, 0.9719], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:14,516][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.2175, 0.0618, 0.0437, 0.1119, 0.1032, 0.4618], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:14,517][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ had] are: tensor([3.9826e-02, 1.8585e-03, 1.0182e-04, 1.2921e-03, 1.5673e-04, 9.5676e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:14,518][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.3461, 0.0258, 0.2557, 0.0242, 0.3134, 0.0347], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:14,518][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.1306, 0.1017, 0.0677, 0.2361, 0.1702, 0.2936], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:14,518][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.0920, 0.2583, 0.0782, 0.3393, 0.0224, 0.2099], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:14,519][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.3047, 0.1837, 0.1061, 0.1893, 0.0882, 0.1279], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:14,519][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.2480, 0.1913, 0.0671, 0.1401, 0.0494, 0.3041], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:14,520][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.4352, 0.1453, 0.0721, 0.1813, 0.0745, 0.0916], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:14,520][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.5065, 0.0584, 0.1663, 0.0441, 0.1130, 0.0727, 0.0391],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:14,520][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ a] are: tensor([8.5560e-04, 4.2999e-03, 8.3604e-04, 4.2978e-03, 1.1204e-03, 4.6829e-04,
        9.8812e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:14,521][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.3067, 0.1902, 0.0542, 0.2243, 0.0501, 0.1270, 0.0474],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:14,522][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0291, 0.0178, 0.0126, 0.0328, 0.0191, 0.1775, 0.7111],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:14,523][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.1395, 0.0307, 0.0744, 0.0432, 0.0653, 0.4360, 0.2109],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:14,524][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0556, 0.1289, 0.0037, 0.0965, 0.0081, 0.0445, 0.6627],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:14,526][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.3242, 0.0108, 0.3238, 0.0092, 0.2739, 0.0477, 0.0105],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:14,527][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0958, 0.0576, 0.1029, 0.1286, 0.1023, 0.2158, 0.2971],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:14,529][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0239, 0.1304, 0.0124, 0.1936, 0.0091, 0.1415, 0.4891],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:14,530][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.2668, 0.1708, 0.0824, 0.1734, 0.0623, 0.1075, 0.1367],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:14,532][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.2247, 0.1916, 0.0630, 0.1624, 0.0505, 0.0832, 0.2246],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:14,533][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.3286, 0.1317, 0.0989, 0.1415, 0.1054, 0.0849, 0.1090],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:14,534][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.2469, 0.0591, 0.1126, 0.0547, 0.2755, 0.1017, 0.0776, 0.0719],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:14,535][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ long] are: tensor([2.8361e-04, 9.8579e-04, 2.5348e-03, 1.4062e-03, 2.0579e-03, 3.2410e-03,
        9.3523e-04, 9.8856e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:14,537][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.2920, 0.1505, 0.1074, 0.1522, 0.0777, 0.1063, 0.0760, 0.0378],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:14,538][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ long] are: tensor([6.5025e-03, 4.5886e-04, 3.6952e-04, 8.0150e-04, 2.7090e-03, 9.0833e-03,
        7.2361e-03, 9.7284e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:14,539][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.1002, 0.0228, 0.0421, 0.0300, 0.0347, 0.1496, 0.0792, 0.5416],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:14,540][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ long] are: tensor([5.4012e-03, 1.8780e-04, 1.6749e-04, 1.0300e-04, 5.4317e-04, 1.9173e-04,
        8.2326e-05, 9.9332e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:14,542][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.2944, 0.0317, 0.2990, 0.0221, 0.1960, 0.0487, 0.0228, 0.0852],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:14,543][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.1023, 0.0445, 0.0251, 0.0933, 0.0895, 0.1876, 0.3464, 0.1113],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:14,544][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.1200, 0.1201, 0.0929, 0.1526, 0.0218, 0.1478, 0.3003, 0.0444],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:14,545][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ long] are: tensor([0.2382, 0.1558, 0.0961, 0.1508, 0.0700, 0.0920, 0.1322, 0.0648],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:14,545][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.2188, 0.1550, 0.0652, 0.1086, 0.0402, 0.0753, 0.0851, 0.2518],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:14,545][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ long] are: tensor([0.3622, 0.0975, 0.1076, 0.1213, 0.0846, 0.0601, 0.0614, 0.1053],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:14,546][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.3665, 0.0877, 0.1633, 0.0691, 0.0448, 0.0748, 0.0588, 0.0747, 0.0603],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:14,546][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([1.8386e-03, 3.0466e-04, 9.6437e-04, 2.0707e-04, 1.0927e-02, 3.4537e-04,
        1.9328e-04, 3.4001e-05, 9.8519e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:14,547][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.2938, 0.0999, 0.1150, 0.0732, 0.0617, 0.0962, 0.1127, 0.0931, 0.0545],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:14,547][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([3.3873e-03, 4.0910e-05, 6.5248e-05, 9.1327e-05, 6.6483e-04, 2.4709e-04,
        6.2998e-04, 4.3083e-03, 9.9056e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:14,549][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.1335, 0.0060, 0.0070, 0.0052, 0.0077, 0.0162, 0.0136, 0.1789, 0.6318],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:14,550][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([1.2028e-02, 1.5134e-05, 2.4667e-06, 4.1251e-06, 3.8227e-05, 2.0254e-06,
        1.5990e-06, 6.3679e-07, 9.8791e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:14,551][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.1830, 0.0476, 0.2075, 0.0416, 0.1971, 0.0314, 0.0337, 0.0755, 0.1827],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:14,552][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.0904, 0.0518, 0.0175, 0.0965, 0.0389, 0.1331, 0.2123, 0.2555, 0.1039],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:14,554][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.2557, 0.0988, 0.0422, 0.1156, 0.0488, 0.2411, 0.1234, 0.0666, 0.0077],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:14,555][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.2309, 0.1345, 0.0873, 0.1260, 0.0766, 0.1095, 0.1127, 0.0813, 0.0412],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:14,557][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.2134, 0.1329, 0.0499, 0.1123, 0.0497, 0.0767, 0.0741, 0.0389, 0.2520],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:14,558][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([0.3168, 0.1405, 0.1164, 0.1017, 0.0482, 0.0402, 0.0388, 0.0858, 0.1117],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:14,560][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.4649, 0.0160, 0.0916, 0.0185, 0.0849, 0.0823, 0.0356, 0.0661, 0.1266,
        0.0135], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:14,561][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [,] are: tensor([1.8442e-03, 4.4350e-01, 2.7698e-04, 1.1169e-02, 7.6631e-05, 3.9665e-04,
        1.7959e-04, 5.1697e-05, 7.8237e-06, 5.4250e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:14,562][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.1991, 0.3134, 0.0265, 0.0766, 0.0120, 0.0365, 0.0075, 0.0102, 0.0100,
        0.3082], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:14,564][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0332, 0.0077, 0.0022, 0.0078, 0.0021, 0.0607, 0.0498, 0.0552, 0.0866,
        0.6947], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:14,565][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.2617, 0.0254, 0.0445, 0.0219, 0.0735, 0.1264, 0.0309, 0.1081, 0.0453,
        0.2625], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:14,566][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0963, 0.3403, 0.0136, 0.1227, 0.0159, 0.0683, 0.1010, 0.0298, 0.0100,
        0.2021], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:14,568][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.2797, 0.0083, 0.2382, 0.0080, 0.2261, 0.0262, 0.0102, 0.0675, 0.1304,
        0.0055], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:14,569][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0369, 0.0140, 0.0320, 0.0379, 0.0612, 0.0692, 0.1103, 0.1447, 0.1382,
        0.3557], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:14,570][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0191, 0.1645, 0.0072, 0.1848, 0.0069, 0.0641, 0.1657, 0.0291, 0.0075,
        0.3510], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:14,570][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.2112, 0.1208, 0.0716, 0.1255, 0.0665, 0.0847, 0.0923, 0.0689, 0.0557,
        0.1028], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:14,571][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.1713, 0.1577, 0.0757, 0.1448, 0.0569, 0.0937, 0.0908, 0.0582, 0.0416,
        0.1093], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:14,571][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.2448, 0.0947, 0.0806, 0.1074, 0.0731, 0.0683, 0.0651, 0.0795, 0.0739,
        0.1126], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:14,572][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.3571, 0.0291, 0.1177, 0.0250, 0.0767, 0.0702, 0.0424, 0.0933, 0.1296,
        0.0286, 0.0304], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:14,572][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ and] are: tensor([1.0614e-03, 1.2476e-02, 1.8693e-04, 5.1184e-01, 3.3040e-05, 6.9041e-04,
        2.3419e-04, 1.8326e-04, 8.4966e-06, 7.4675e-03, 4.6582e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:14,572][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0834, 0.0623, 0.0125, 0.3123, 0.0243, 0.0434, 0.0174, 0.0149, 0.0233,
        0.0554, 0.3506], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:14,573][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ and] are: tensor([1.0827e-02, 6.0678e-03, 1.6315e-04, 3.9903e-03, 5.0888e-05, 7.8508e-03,
        1.3931e-02, 1.5646e-02, 7.4131e-03, 4.9328e-01, 4.4078e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:14,574][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0356, 0.0131, 0.0130, 0.0247, 0.0068, 0.1628, 0.0661, 0.1205, 0.1787,
        0.1223, 0.2564], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:14,576][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0326, 0.0871, 0.0047, 0.3873, 0.0032, 0.0542, 0.1209, 0.0254, 0.0037,
        0.0306, 0.2502], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:14,577][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.2336, 0.0095, 0.2336, 0.0090, 0.2162, 0.0296, 0.0109, 0.0826, 0.1581,
        0.0072, 0.0099], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:14,578][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0334, 0.0121, 0.0215, 0.0202, 0.0234, 0.0427, 0.0641, 0.0802, 0.0987,
        0.2469, 0.3570], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:14,580][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0115, 0.0999, 0.0073, 0.1172, 0.0052, 0.0608, 0.1994, 0.0255, 0.0108,
        0.2619, 0.2004], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:14,581][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.1743, 0.1087, 0.0641, 0.1097, 0.0562, 0.0760, 0.0872, 0.0586, 0.0573,
        0.0961, 0.1118], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:14,582][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.1437, 0.1301, 0.0546, 0.1384, 0.0455, 0.0972, 0.0982, 0.0522, 0.0351,
        0.0944, 0.1105], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:14,584][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.2182, 0.0889, 0.0640, 0.1025, 0.0589, 0.0532, 0.0472, 0.0612, 0.0780,
        0.1124, 0.1155], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:14,585][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.2224, 0.0405, 0.0984, 0.0449, 0.1497, 0.1181, 0.0461, 0.0323, 0.1419,
        0.0351, 0.0536, 0.0171], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:14,586][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([1.7391e-03, 4.1711e-04, 2.0240e-03, 1.5582e-04, 1.2517e-03, 1.7358e-04,
        9.0097e-05, 1.4327e-04, 6.0536e-04, 9.2257e-05, 7.0693e-05, 9.9324e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:14,588][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.2487, 0.0813, 0.0718, 0.0771, 0.0779, 0.1569, 0.0644, 0.0568, 0.0328,
        0.0516, 0.0621, 0.0186], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:14,589][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([1.2695e-02, 5.1812e-05, 1.0928e-04, 7.2029e-05, 1.3434e-04, 1.1422e-03,
        2.1228e-04, 3.4371e-03, 1.4253e-03, 2.2501e-03, 4.8174e-03, 9.7365e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:14,590][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.0417, 0.0033, 0.0054, 0.0070, 0.0109, 0.0113, 0.0108, 0.0292, 0.0152,
        0.0127, 0.0435, 0.8090], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:14,591][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([9.2440e-02, 4.3735e-06, 1.4702e-04, 1.6931e-06, 2.2248e-04, 4.4300e-06,
        4.7544e-07, 4.6477e-06, 5.0041e-06, 9.8421e-08, 2.7239e-07, 9.0717e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:14,593][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.1347, 0.0564, 0.1855, 0.0419, 0.1264, 0.0351, 0.0598, 0.0525, 0.1211,
        0.0498, 0.0462, 0.0906], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:14,594][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.0519, 0.0186, 0.0074, 0.0288, 0.0340, 0.0330, 0.0701, 0.0482, 0.0272,
        0.1892, 0.3853, 0.1063], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:14,596][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.0959, 0.1083, 0.0333, 0.1372, 0.0275, 0.0388, 0.1198, 0.0359, 0.0982,
        0.1277, 0.1646, 0.0126], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:14,596][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([0.1730, 0.0978, 0.0829, 0.0898, 0.0630, 0.0744, 0.0655, 0.0561, 0.0849,
        0.0829, 0.0902, 0.0397], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:14,597][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.1906, 0.0926, 0.0450, 0.0887, 0.0503, 0.0830, 0.0551, 0.0515, 0.0386,
        0.0660, 0.0686, 0.1700], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:14,597][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([0.1840, 0.1458, 0.0569, 0.0967, 0.0384, 0.0332, 0.0425, 0.0428, 0.0391,
        0.1667, 0.1038, 0.0501], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:14,598][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Melissa] are: tensor([0.2203, 0.1247, 0.0483, 0.0924, 0.0501, 0.0227, 0.0416, 0.0316, 0.0540,
        0.1041, 0.1015, 0.0584, 0.0504], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:14,598][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Melissa] are: tensor([2.6595e-04, 1.2525e-04, 5.2445e-01, 4.8172e-04, 7.5136e-05, 3.6301e-04,
        3.9367e-05, 2.5054e-04, 2.0665e-05, 2.8689e-05, 2.5904e-04, 8.0319e-05,
        4.7356e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:14,599][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Melissa] are: tensor([0.2185, 0.0802, 0.1277, 0.0427, 0.0425, 0.0652, 0.0710, 0.0298, 0.0751,
        0.0484, 0.0361, 0.0577, 0.1050], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:14,599][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Melissa] are: tensor([3.2626e-03, 3.3973e-06, 3.3851e-03, 3.5968e-06, 7.6960e-04, 2.9900e-05,
        2.6516e-05, 4.3962e-04, 3.2713e-04, 1.3126e-04, 2.0322e-04, 2.4258e-03,
        9.8899e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:14,600][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Melissa] are: tensor([5.1936e-03, 3.8772e-04, 6.2788e-02, 3.6998e-04, 1.8711e-03, 3.5857e-04,
        5.4051e-04, 1.9708e-03, 1.0672e-03, 1.4407e-03, 2.0419e-03, 9.6427e-04,
        9.2101e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:14,601][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Melissa] are: tensor([1.6002e-03, 5.5479e-07, 6.5018e-01, 2.3554e-07, 5.2112e-05, 1.3959e-07,
        1.1678e-07, 3.2466e-06, 7.5976e-08, 1.6484e-08, 4.2057e-08, 2.3332e-06,
        3.4816e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:14,602][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Melissa] are: tensor([0.0869, 0.1281, 0.1319, 0.0757, 0.1159, 0.0276, 0.0551, 0.0343, 0.0444,
        0.1013, 0.0647, 0.0206, 0.1136], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:14,603][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Melissa] are: tensor([0.0851, 0.0151, 0.0082, 0.0311, 0.0353, 0.0342, 0.0686, 0.0706, 0.0416,
        0.1558, 0.2606, 0.0902, 0.1036], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:14,605][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Melissa] are: tensor([0.1607, 0.0794, 0.1201, 0.0668, 0.1118, 0.0359, 0.0663, 0.0365, 0.0617,
        0.0583, 0.0577, 0.0301, 0.1148], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:14,606][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Melissa] are: tensor([0.1793, 0.1103, 0.0259, 0.0965, 0.1021, 0.0566, 0.0636, 0.0579, 0.0456,
        0.0865, 0.0908, 0.0624, 0.0225], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:14,607][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Melissa] are: tensor([0.0672, 0.0628, 0.2556, 0.0646, 0.0406, 0.0496, 0.0477, 0.0359, 0.0229,
        0.0525, 0.0514, 0.0196, 0.2296], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:14,609][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Melissa] are: tensor([0.0762, 0.0535, 0.0449, 0.0899, 0.0560, 0.0756, 0.0569, 0.0714, 0.1025,
        0.0614, 0.1209, 0.1263, 0.0646], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:14,610][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.3664, 0.0317, 0.0579, 0.0184, 0.0271, 0.0668, 0.0195, 0.0484, 0.0467,
        0.0312, 0.0195, 0.1061, 0.0788, 0.0815], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:14,611][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ said] are: tensor([1.4410e-03, 3.5422e-03, 2.6620e-03, 1.1978e-03, 4.0696e-04, 8.4685e-03,
        1.4010e-03, 4.5664e-05, 1.5878e-03, 1.5467e-03, 7.2034e-04, 1.1209e-04,
        1.5583e-03, 9.7531e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:14,613][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.2207, 0.0493, 0.0383, 0.0426, 0.0233, 0.1015, 0.0335, 0.0245, 0.0483,
        0.0407, 0.0397, 0.0399, 0.0377, 0.2600], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:14,613][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ said] are: tensor([1.9792e-03, 7.3206e-05, 6.9802e-05, 5.4495e-05, 2.6961e-05, 3.0678e-04,
        4.2621e-04, 4.8449e-04, 1.2489e-03, 2.5291e-03, 3.5354e-03, 1.3119e-03,
        1.3993e-02, 9.7396e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:14,615][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.0856, 0.0131, 0.0037, 0.0186, 0.0121, 0.0266, 0.0217, 0.0251, 0.0426,
        0.0562, 0.1194, 0.0241, 0.0318, 0.5195], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:14,616][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ said] are: tensor([1.2077e-02, 2.4345e-03, 1.3417e-04, 8.9064e-04, 1.9842e-04, 8.6983e-03,
        2.0763e-04, 2.9480e-05, 6.7254e-04, 2.4886e-04, 2.8123e-04, 6.2020e-06,
        2.1086e-05, 9.7410e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:14,618][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.1780, 0.0087, 0.1421, 0.0088, 0.1839, 0.0117, 0.0071, 0.0318, 0.0839,
        0.0066, 0.0087, 0.1219, 0.1896, 0.0172], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:14,619][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.0341, 0.0065, 0.0057, 0.0109, 0.0044, 0.0146, 0.0310, 0.0134, 0.0212,
        0.1126, 0.1759, 0.1812, 0.2107, 0.1780], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:14,621][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.0513, 0.1062, 0.0202, 0.1042, 0.0153, 0.1015, 0.1374, 0.0312, 0.0277,
        0.1758, 0.1376, 0.0249, 0.0293, 0.0373], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:14,622][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ said] are: tensor([0.1446, 0.0777, 0.0561, 0.0798, 0.0584, 0.0639, 0.0608, 0.0451, 0.0530,
        0.0723, 0.0827, 0.0537, 0.0594, 0.0925], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:14,623][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.1007, 0.0726, 0.0460, 0.0765, 0.0374, 0.0788, 0.0591, 0.0248, 0.0473,
        0.0614, 0.0660, 0.0282, 0.0364, 0.2648], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:14,623][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ said] are: tensor([0.2416, 0.0575, 0.0634, 0.0768, 0.0449, 0.0367, 0.0308, 0.0555, 0.0659,
        0.0610, 0.0780, 0.0809, 0.0684, 0.0387], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:14,624][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.2718, 0.0264, 0.0635, 0.0220, 0.0427, 0.0709, 0.0237, 0.0383, 0.0757,
        0.0263, 0.0270, 0.0876, 0.0939, 0.1129, 0.0174], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:14,624][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ to] are: tensor([4.1212e-03, 1.1779e-02, 1.8219e-04, 3.4316e-02, 8.2869e-05, 3.0533e-04,
        1.4492e-03, 1.7847e-04, 5.7931e-05, 8.2843e-03, 3.0206e-02, 2.4504e-04,
        8.9417e-05, 1.4515e-04, 9.0856e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:14,624][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1609, 0.0707, 0.0274, 0.0971, 0.0209, 0.0591, 0.0254, 0.0379, 0.0309,
        0.0604, 0.0956, 0.0393, 0.0256, 0.0751, 0.1738], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:14,625][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ to] are: tensor([2.9170e-03, 2.6333e-04, 7.3690e-05, 1.8045e-04, 1.1086e-04, 7.2228e-04,
        1.1946e-03, 2.4023e-04, 1.1373e-03, 7.1324e-03, 1.1827e-02, 1.6419e-02,
        1.2983e-02, 2.9063e-01, 6.5417e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:14,625][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0343, 0.0022, 0.0034, 0.0036, 0.0035, 0.0325, 0.0099, 0.0251, 0.0548,
        0.0118, 0.0303, 0.0701, 0.0539, 0.3984, 0.2660], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:14,626][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ to] are: tensor([4.3090e-02, 6.0873e-02, 1.6993e-03, 7.7937e-02, 7.9139e-03, 3.1042e-02,
        2.2529e-01, 3.4175e-02, 4.7362e-03, 2.1081e-02, 4.1055e-02, 7.4117e-04,
        4.1108e-04, 3.2456e-02, 4.1750e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:14,628][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1112, 0.0054, 0.0919, 0.0046, 0.0828, 0.0156, 0.0044, 0.0288, 0.0496,
        0.0040, 0.0058, 0.1011, 0.1701, 0.0298, 0.2950], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:14,629][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0222, 0.0042, 0.0042, 0.0069, 0.0059, 0.0090, 0.0120, 0.0185, 0.0270,
        0.0495, 0.0802, 0.0940, 0.1311, 0.2600, 0.2752], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:14,630][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0080, 0.0594, 0.0043, 0.1035, 0.0038, 0.0466, 0.1310, 0.0198, 0.0089,
        0.1507, 0.1813, 0.0048, 0.0072, 0.0338, 0.2368], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:14,632][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.1192, 0.0739, 0.0463, 0.0813, 0.0355, 0.0542, 0.0692, 0.0475, 0.0427,
        0.0697, 0.0853, 0.0458, 0.0483, 0.0828, 0.0983], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:14,633][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.1020, 0.0838, 0.0381, 0.1004, 0.0272, 0.0744, 0.0855, 0.0502, 0.0333,
        0.0761, 0.0927, 0.0275, 0.0311, 0.0642, 0.1134], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:14,635][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.1728, 0.0683, 0.0597, 0.0701, 0.0569, 0.0486, 0.0442, 0.0519, 0.0520,
        0.0702, 0.0666, 0.0718, 0.0607, 0.0357, 0.0705], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:14,657][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:31:14,659][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:14,660][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:14,661][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:14,662][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:14,662][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:14,662][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:14,663][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:14,663][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:14,663][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:14,664][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:14,664][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:14,664][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:14,666][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.9675, 0.0325], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:14,667][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0065, 0.9935], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:14,668][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.6358, 0.3642], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:14,670][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.6853, 0.3147], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:14,671][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.9772, 0.0228], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:14,672][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.2539, 0.7461], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:14,673][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.9881, 0.0119], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:14,675][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.9119, 0.0881], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:14,676][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.3215, 0.6785], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:14,678][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.7118, 0.2882], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:14,679][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.7102, 0.2898], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:14,681][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.6916, 0.3084], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:14,682][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Melissa] are: tensor([0.5522, 0.3627, 0.0850], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:14,682][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Melissa] are: tensor([6.3831e-04, 6.2358e-04, 9.9874e-01], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:14,684][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Melissa] are: tensor([0.6069, 0.2279, 0.1652], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:14,685][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Melissa] are: tensor([5.8955e-02, 9.3021e-04, 9.4011e-01], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:14,686][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Melissa] are: tensor([0.0502, 0.0048, 0.9450], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:14,687][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Melissa] are: tensor([1.4103e-02, 7.3540e-06, 9.8589e-01], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:14,688][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Melissa] are: tensor([0.3676, 0.4027, 0.2297], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:14,688][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Melissa] are: tensor([0.5706, 0.3015, 0.1280], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:14,688][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Melissa] are: tensor([0.5401, 0.2517, 0.2082], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:14,689][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Melissa] are: tensor([0.6116, 0.3270, 0.0614], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:14,689][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Melissa] are: tensor([0.4014, 0.2711, 0.3274], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:14,689][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Melissa] are: tensor([0.4556, 0.3438, 0.2006], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:14,690][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.6847, 0.0776, 0.1772, 0.0605], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:14,690][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([2.3020e-03, 3.9238e-02, 7.2233e-04, 9.5774e-01], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:14,691][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.2410, 0.1804, 0.0235, 0.5551], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:14,692][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.1132, 0.3869, 0.0267, 0.4733], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:14,693][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.3234, 0.1465, 0.2646, 0.2654], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:14,695][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.1229, 0.1967, 0.0085, 0.6719], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:14,696][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.6087, 0.0291, 0.3401, 0.0221], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:14,697][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2272, 0.1728, 0.3399, 0.2601], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:14,699][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0667, 0.4674, 0.0276, 0.4383], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:14,700][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.4297, 0.2399, 0.1075, 0.2229], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:14,701][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.4198, 0.3127, 0.0613, 0.2063], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:14,703][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.4426, 0.1933, 0.1114, 0.2526], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:14,704][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Benjamin] are: tensor([0.3592, 0.2662, 0.0793, 0.1633, 0.1320], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:14,705][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Benjamin] are: tensor([8.3391e-05, 1.1915e-04, 9.6542e-04, 8.2812e-05, 9.9875e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:14,707][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Benjamin] are: tensor([0.4947, 0.1676, 0.1070, 0.0870, 0.1437], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:14,707][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Benjamin] are: tensor([4.3862e-03, 4.6049e-05, 1.0389e-02, 2.4227e-04, 9.8494e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:14,709][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Benjamin] are: tensor([0.0260, 0.0044, 0.0434, 0.0068, 0.9193], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:14,710][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Benjamin] are: tensor([6.2693e-03, 1.6773e-06, 3.9269e-05, 4.3091e-07, 9.9369e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:14,711][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Benjamin] are: tensor([0.2204, 0.1621, 0.2434, 0.0824, 0.2918], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:14,713][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Benjamin] are: tensor([0.1447, 0.1350, 0.2837, 0.2755, 0.1612], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:14,714][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Benjamin] are: tensor([0.3370, 0.2172, 0.1119, 0.1443, 0.1896], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:14,714][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Benjamin] are: tensor([0.3910, 0.2125, 0.2131, 0.1649, 0.0184], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:14,714][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Benjamin] are: tensor([0.3084, 0.2082, 0.0557, 0.1296, 0.2982], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:14,715][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Benjamin] are: tensor([0.2831, 0.2183, 0.0818, 0.2905, 0.1262], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:14,715][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.4209, 0.0370, 0.1249, 0.0368, 0.0562, 0.3242], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:14,716][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([3.2186e-04, 1.6738e-03, 1.2185e-03, 2.8590e-03, 1.9608e-04, 9.9373e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:14,716][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.4805, 0.1225, 0.0766, 0.1450, 0.0318, 0.1436], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:14,716][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.0049, 0.0054, 0.0032, 0.0114, 0.0031, 0.9719], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:14,718][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.2175, 0.0618, 0.0437, 0.1119, 0.1032, 0.4618], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:14,719][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([3.9826e-02, 1.8585e-03, 1.0182e-04, 1.2921e-03, 1.5673e-04, 9.5676e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:14,720][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.3461, 0.0258, 0.2557, 0.0242, 0.3134, 0.0347], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:14,721][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.1306, 0.1017, 0.0677, 0.2361, 0.1702, 0.2936], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:14,723][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.0920, 0.2583, 0.0782, 0.3393, 0.0224, 0.2099], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:14,724][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.3047, 0.1837, 0.1061, 0.1893, 0.0882, 0.1279], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:14,725][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.2480, 0.1913, 0.0671, 0.1401, 0.0494, 0.3041], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:14,727][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.4352, 0.1453, 0.0721, 0.1813, 0.0745, 0.0916], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:14,728][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.5065, 0.0584, 0.1663, 0.0441, 0.1130, 0.0727, 0.0391],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:14,729][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([8.5560e-04, 4.2999e-03, 8.3604e-04, 4.2978e-03, 1.1204e-03, 4.6829e-04,
        9.8812e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:14,731][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.3067, 0.1902, 0.0542, 0.2243, 0.0501, 0.1270, 0.0474],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:14,732][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0291, 0.0178, 0.0126, 0.0328, 0.0191, 0.1775, 0.7111],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:14,734][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.1395, 0.0307, 0.0744, 0.0432, 0.0653, 0.4360, 0.2109],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:14,735][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0556, 0.1289, 0.0037, 0.0965, 0.0081, 0.0445, 0.6627],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:14,736][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.3242, 0.0108, 0.3238, 0.0092, 0.2739, 0.0477, 0.0105],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:14,738][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0958, 0.0576, 0.1029, 0.1286, 0.1023, 0.2158, 0.2971],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:14,740][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0239, 0.1304, 0.0124, 0.1936, 0.0091, 0.1415, 0.4891],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:14,740][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.2668, 0.1708, 0.0824, 0.1734, 0.0623, 0.1075, 0.1367],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:14,740][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.2247, 0.1916, 0.0630, 0.1624, 0.0505, 0.0832, 0.2246],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:14,741][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.3286, 0.1317, 0.0989, 0.1415, 0.1054, 0.0849, 0.1090],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:14,741][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.2469, 0.0591, 0.1126, 0.0547, 0.2755, 0.1017, 0.0776, 0.0719],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:14,742][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([2.8361e-04, 9.8579e-04, 2.5348e-03, 1.4062e-03, 2.0579e-03, 3.2410e-03,
        9.3523e-04, 9.8856e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:14,742][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([0.2920, 0.1505, 0.1074, 0.1522, 0.0777, 0.1063, 0.0760, 0.0378],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:14,742][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([6.5025e-03, 4.5886e-04, 3.6952e-04, 8.0150e-04, 2.7090e-03, 9.0833e-03,
        7.2361e-03, 9.7284e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:14,743][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.1002, 0.0228, 0.0421, 0.0300, 0.0347, 0.1496, 0.0792, 0.5416],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:14,743][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([5.4012e-03, 1.8780e-04, 1.6749e-04, 1.0300e-04, 5.4317e-04, 1.9173e-04,
        8.2326e-05, 9.9332e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:14,745][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.2944, 0.0317, 0.2990, 0.0221, 0.1960, 0.0487, 0.0228, 0.0852],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:14,746][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.1023, 0.0445, 0.0251, 0.0933, 0.0895, 0.1876, 0.3464, 0.1113],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:14,747][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.1200, 0.1201, 0.0929, 0.1526, 0.0218, 0.1478, 0.3003, 0.0444],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:14,749][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([0.2382, 0.1558, 0.0961, 0.1508, 0.0700, 0.0920, 0.1322, 0.0648],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:14,750][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.2188, 0.1550, 0.0652, 0.1086, 0.0402, 0.0753, 0.0851, 0.2518],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:14,752][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([0.3622, 0.0975, 0.1076, 0.1213, 0.0846, 0.0601, 0.0614, 0.1053],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:14,753][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.3665, 0.0877, 0.1633, 0.0691, 0.0448, 0.0748, 0.0588, 0.0747, 0.0603],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:14,754][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([1.8386e-03, 3.0466e-04, 9.6437e-04, 2.0707e-04, 1.0927e-02, 3.4537e-04,
        1.9328e-04, 3.4001e-05, 9.8519e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:14,755][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([0.2938, 0.0999, 0.1150, 0.0732, 0.0617, 0.0962, 0.1127, 0.0931, 0.0545],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:14,756][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([3.3873e-03, 4.0910e-05, 6.5248e-05, 9.1327e-05, 6.6483e-04, 2.4709e-04,
        6.2998e-04, 4.3083e-03, 9.9056e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:14,757][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.1335, 0.0060, 0.0070, 0.0052, 0.0077, 0.0162, 0.0136, 0.1789, 0.6318],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:14,758][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([1.2028e-02, 1.5134e-05, 2.4667e-06, 4.1251e-06, 3.8227e-05, 2.0254e-06,
        1.5990e-06, 6.3679e-07, 9.8791e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:14,760][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.1830, 0.0476, 0.2075, 0.0416, 0.1971, 0.0314, 0.0337, 0.0755, 0.1827],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:14,761][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.0904, 0.0518, 0.0175, 0.0965, 0.0389, 0.1331, 0.2123, 0.2555, 0.1039],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:14,763][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([0.2557, 0.0988, 0.0422, 0.1156, 0.0488, 0.2411, 0.1234, 0.0666, 0.0077],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:14,764][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([0.2309, 0.1345, 0.0873, 0.1260, 0.0766, 0.1095, 0.1127, 0.0813, 0.0412],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:14,766][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.2134, 0.1329, 0.0499, 0.1123, 0.0497, 0.0767, 0.0741, 0.0389, 0.2520],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:14,766][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([0.3168, 0.1405, 0.1164, 0.1017, 0.0482, 0.0402, 0.0388, 0.0858, 0.1117],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:14,767][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.4649, 0.0160, 0.0916, 0.0185, 0.0849, 0.0823, 0.0356, 0.0661, 0.1266,
        0.0135], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:14,767][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([1.8442e-03, 4.4350e-01, 2.7698e-04, 1.1169e-02, 7.6631e-05, 3.9665e-04,
        1.7959e-04, 5.1697e-05, 7.8237e-06, 5.4250e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:14,768][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.1991, 0.3134, 0.0265, 0.0766, 0.0120, 0.0365, 0.0075, 0.0102, 0.0100,
        0.3082], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:14,768][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0332, 0.0077, 0.0022, 0.0078, 0.0021, 0.0607, 0.0498, 0.0552, 0.0866,
        0.6947], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:14,768][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.2617, 0.0254, 0.0445, 0.0219, 0.0735, 0.1264, 0.0309, 0.1081, 0.0453,
        0.2625], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:14,769][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0963, 0.3403, 0.0136, 0.1227, 0.0159, 0.0683, 0.1010, 0.0298, 0.0100,
        0.2021], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:14,770][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.2797, 0.0083, 0.2382, 0.0080, 0.2261, 0.0262, 0.0102, 0.0675, 0.1304,
        0.0055], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:14,772][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0369, 0.0140, 0.0320, 0.0379, 0.0612, 0.0692, 0.1103, 0.1447, 0.1382,
        0.3557], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:14,773][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0191, 0.1645, 0.0072, 0.1848, 0.0069, 0.0641, 0.1657, 0.0291, 0.0075,
        0.3510], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:14,774][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.2112, 0.1208, 0.0716, 0.1255, 0.0665, 0.0847, 0.0923, 0.0689, 0.0557,
        0.1028], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:14,775][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.1713, 0.1577, 0.0757, 0.1448, 0.0569, 0.0937, 0.0908, 0.0582, 0.0416,
        0.1093], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:14,776][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.2448, 0.0947, 0.0806, 0.1074, 0.0731, 0.0683, 0.0651, 0.0795, 0.0739,
        0.1126], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:14,777][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.3571, 0.0291, 0.1177, 0.0250, 0.0767, 0.0702, 0.0424, 0.0933, 0.1296,
        0.0286, 0.0304], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:14,777][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([1.0614e-03, 1.2476e-02, 1.8693e-04, 5.1184e-01, 3.3040e-05, 6.9041e-04,
        2.3419e-04, 1.8326e-04, 8.4966e-06, 7.4675e-03, 4.6582e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:14,778][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0834, 0.0623, 0.0125, 0.3123, 0.0243, 0.0434, 0.0174, 0.0149, 0.0233,
        0.0554, 0.3506], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:14,778][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([1.0827e-02, 6.0678e-03, 1.6315e-04, 3.9903e-03, 5.0888e-05, 7.8508e-03,
        1.3931e-02, 1.5646e-02, 7.4131e-03, 4.9328e-01, 4.4078e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:14,778][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0356, 0.0131, 0.0130, 0.0247, 0.0068, 0.1628, 0.0661, 0.1205, 0.1787,
        0.1223, 0.2564], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:14,779][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0326, 0.0871, 0.0047, 0.3873, 0.0032, 0.0542, 0.1209, 0.0254, 0.0037,
        0.0306, 0.2502], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:14,780][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.2336, 0.0095, 0.2336, 0.0090, 0.2162, 0.0296, 0.0109, 0.0826, 0.1581,
        0.0072, 0.0099], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:14,782][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0334, 0.0121, 0.0215, 0.0202, 0.0234, 0.0427, 0.0641, 0.0802, 0.0987,
        0.2469, 0.3570], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:14,783][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0115, 0.0999, 0.0073, 0.1172, 0.0052, 0.0608, 0.1994, 0.0255, 0.0108,
        0.2619, 0.2004], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:14,785][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.1743, 0.1087, 0.0641, 0.1097, 0.0562, 0.0760, 0.0872, 0.0586, 0.0573,
        0.0961, 0.1118], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:14,786][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.1437, 0.1301, 0.0546, 0.1384, 0.0455, 0.0972, 0.0982, 0.0522, 0.0351,
        0.0944, 0.1105], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:14,788][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.2182, 0.0889, 0.0640, 0.1025, 0.0589, 0.0532, 0.0472, 0.0612, 0.0780,
        0.1124, 0.1155], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:14,789][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.2224, 0.0405, 0.0984, 0.0449, 0.1497, 0.1181, 0.0461, 0.0323, 0.1419,
        0.0351, 0.0536, 0.0171], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:14,790][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([1.7391e-03, 4.1711e-04, 2.0240e-03, 1.5582e-04, 1.2517e-03, 1.7358e-04,
        9.0097e-05, 1.4327e-04, 6.0536e-04, 9.2257e-05, 7.0693e-05, 9.9324e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:14,791][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([0.2487, 0.0813, 0.0718, 0.0771, 0.0779, 0.1569, 0.0644, 0.0568, 0.0328,
        0.0516, 0.0621, 0.0186], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:14,792][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([1.2695e-02, 5.1812e-05, 1.0928e-04, 7.2029e-05, 1.3434e-04, 1.1422e-03,
        2.1228e-04, 3.4371e-03, 1.4253e-03, 2.2501e-03, 4.8174e-03, 9.7365e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:14,794][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.0417, 0.0033, 0.0054, 0.0070, 0.0109, 0.0113, 0.0108, 0.0292, 0.0152,
        0.0127, 0.0435, 0.8090], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:14,795][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([9.2440e-02, 4.3735e-06, 1.4702e-04, 1.6931e-06, 2.2248e-04, 4.4300e-06,
        4.7544e-07, 4.6477e-06, 5.0041e-06, 9.8421e-08, 2.7239e-07, 9.0717e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:14,795][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.1347, 0.0564, 0.1855, 0.0419, 0.1264, 0.0351, 0.0598, 0.0525, 0.1211,
        0.0498, 0.0462, 0.0906], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:14,796][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.0519, 0.0186, 0.0074, 0.0288, 0.0340, 0.0330, 0.0701, 0.0482, 0.0272,
        0.1892, 0.3853, 0.1063], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:14,796][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.0959, 0.1083, 0.0333, 0.1372, 0.0275, 0.0388, 0.1198, 0.0359, 0.0982,
        0.1277, 0.1646, 0.0126], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:14,797][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([0.1730, 0.0978, 0.0829, 0.0898, 0.0630, 0.0744, 0.0655, 0.0561, 0.0849,
        0.0829, 0.0902, 0.0397], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:14,797][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([0.1906, 0.0926, 0.0450, 0.0887, 0.0503, 0.0830, 0.0551, 0.0515, 0.0386,
        0.0660, 0.0686, 0.1700], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:14,798][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([0.1840, 0.1458, 0.0569, 0.0967, 0.0384, 0.0332, 0.0425, 0.0428, 0.0391,
        0.1667, 0.1038, 0.0501], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:14,798][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Melissa] are: tensor([0.2203, 0.1247, 0.0483, 0.0924, 0.0501, 0.0227, 0.0416, 0.0316, 0.0540,
        0.1041, 0.1015, 0.0584, 0.0504], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:14,799][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Melissa] are: tensor([2.6595e-04, 1.2525e-04, 5.2445e-01, 4.8172e-04, 7.5136e-05, 3.6301e-04,
        3.9367e-05, 2.5054e-04, 2.0665e-05, 2.8689e-05, 2.5904e-04, 8.0319e-05,
        4.7356e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:14,800][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Melissa] are: tensor([0.2185, 0.0802, 0.1277, 0.0427, 0.0425, 0.0652, 0.0710, 0.0298, 0.0751,
        0.0484, 0.0361, 0.0577, 0.1050], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:14,801][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Melissa] are: tensor([3.2626e-03, 3.3973e-06, 3.3851e-03, 3.5968e-06, 7.6960e-04, 2.9900e-05,
        2.6516e-05, 4.3962e-04, 3.2713e-04, 1.3126e-04, 2.0322e-04, 2.4258e-03,
        9.8899e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:14,802][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Melissa] are: tensor([5.1936e-03, 3.8772e-04, 6.2788e-02, 3.6998e-04, 1.8711e-03, 3.5857e-04,
        5.4051e-04, 1.9708e-03, 1.0672e-03, 1.4407e-03, 2.0419e-03, 9.6427e-04,
        9.2101e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:14,803][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Melissa] are: tensor([1.6002e-03, 5.5479e-07, 6.5018e-01, 2.3554e-07, 5.2112e-05, 1.3959e-07,
        1.1678e-07, 3.2466e-06, 7.5976e-08, 1.6484e-08, 4.2057e-08, 2.3332e-06,
        3.4816e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:14,804][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Melissa] are: tensor([0.0869, 0.1281, 0.1319, 0.0757, 0.1159, 0.0276, 0.0551, 0.0343, 0.0444,
        0.1013, 0.0647, 0.0206, 0.1136], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:14,806][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Melissa] are: tensor([0.0851, 0.0151, 0.0082, 0.0311, 0.0353, 0.0342, 0.0686, 0.0706, 0.0416,
        0.1558, 0.2606, 0.0902, 0.1036], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:14,807][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Melissa] are: tensor([0.1607, 0.0794, 0.1201, 0.0668, 0.1118, 0.0359, 0.0663, 0.0365, 0.0617,
        0.0583, 0.0577, 0.0301, 0.1148], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:14,809][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Melissa] are: tensor([0.1793, 0.1103, 0.0259, 0.0965, 0.1021, 0.0566, 0.0636, 0.0579, 0.0456,
        0.0865, 0.0908, 0.0624, 0.0225], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:14,810][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Melissa] are: tensor([0.0672, 0.0628, 0.2556, 0.0646, 0.0406, 0.0496, 0.0477, 0.0359, 0.0229,
        0.0525, 0.0514, 0.0196, 0.2296], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:14,812][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Melissa] are: tensor([0.0762, 0.0535, 0.0449, 0.0899, 0.0560, 0.0756, 0.0569, 0.0714, 0.1025,
        0.0614, 0.1209, 0.1263, 0.0646], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:14,813][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.3664, 0.0317, 0.0579, 0.0184, 0.0271, 0.0668, 0.0195, 0.0484, 0.0467,
        0.0312, 0.0195, 0.1061, 0.0788, 0.0815], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:14,814][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([1.4410e-03, 3.5422e-03, 2.6620e-03, 1.1978e-03, 4.0696e-04, 8.4685e-03,
        1.4010e-03, 4.5664e-05, 1.5878e-03, 1.5467e-03, 7.2034e-04, 1.1209e-04,
        1.5583e-03, 9.7531e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:14,816][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([0.2207, 0.0493, 0.0383, 0.0426, 0.0233, 0.1015, 0.0335, 0.0245, 0.0483,
        0.0407, 0.0397, 0.0399, 0.0377, 0.2600], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:14,817][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([1.9792e-03, 7.3206e-05, 6.9802e-05, 5.4495e-05, 2.6961e-05, 3.0678e-04,
        4.2621e-04, 4.8449e-04, 1.2489e-03, 2.5291e-03, 3.5354e-03, 1.3119e-03,
        1.3993e-02, 9.7396e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:14,818][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([0.0856, 0.0131, 0.0037, 0.0186, 0.0121, 0.0266, 0.0217, 0.0251, 0.0426,
        0.0562, 0.1194, 0.0241, 0.0318, 0.5195], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:14,819][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([1.2077e-02, 2.4345e-03, 1.3417e-04, 8.9064e-04, 1.9842e-04, 8.6983e-03,
        2.0763e-04, 2.9480e-05, 6.7254e-04, 2.4886e-04, 2.8123e-04, 6.2020e-06,
        2.1086e-05, 9.7410e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:14,821][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([0.1780, 0.0087, 0.1421, 0.0088, 0.1839, 0.0117, 0.0071, 0.0318, 0.0839,
        0.0066, 0.0087, 0.1219, 0.1896, 0.0172], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:14,821][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.0341, 0.0065, 0.0057, 0.0109, 0.0044, 0.0146, 0.0310, 0.0134, 0.0212,
        0.1126, 0.1759, 0.1812, 0.2107, 0.1780], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:14,822][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([0.0513, 0.1062, 0.0202, 0.1042, 0.0153, 0.1015, 0.1374, 0.0312, 0.0277,
        0.1758, 0.1376, 0.0249, 0.0293, 0.0373], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:14,822][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([0.1446, 0.0777, 0.0561, 0.0798, 0.0584, 0.0639, 0.0608, 0.0451, 0.0530,
        0.0723, 0.0827, 0.0537, 0.0594, 0.0925], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:14,823][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([0.1007, 0.0726, 0.0460, 0.0765, 0.0374, 0.0788, 0.0591, 0.0248, 0.0473,
        0.0614, 0.0660, 0.0282, 0.0364, 0.2648], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:14,823][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([0.2416, 0.0575, 0.0634, 0.0768, 0.0449, 0.0367, 0.0308, 0.0555, 0.0659,
        0.0610, 0.0780, 0.0809, 0.0684, 0.0387], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:14,824][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.2718, 0.0264, 0.0635, 0.0220, 0.0427, 0.0709, 0.0237, 0.0383, 0.0757,
        0.0263, 0.0270, 0.0876, 0.0939, 0.1129, 0.0174], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:14,825][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([4.1212e-03, 1.1779e-02, 1.8219e-04, 3.4316e-02, 8.2869e-05, 3.0533e-04,
        1.4492e-03, 1.7847e-04, 5.7931e-05, 8.2843e-03, 3.0206e-02, 2.4504e-04,
        8.9417e-05, 1.4515e-04, 9.0856e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:14,826][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1609, 0.0707, 0.0274, 0.0971, 0.0209, 0.0591, 0.0254, 0.0379, 0.0309,
        0.0604, 0.0956, 0.0393, 0.0256, 0.0751, 0.1738], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:14,827][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([2.9170e-03, 2.6333e-04, 7.3690e-05, 1.8045e-04, 1.1086e-04, 7.2228e-04,
        1.1946e-03, 2.4023e-04, 1.1373e-03, 7.1324e-03, 1.1827e-02, 1.6419e-02,
        1.2983e-02, 2.9063e-01, 6.5417e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:14,828][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0343, 0.0022, 0.0034, 0.0036, 0.0035, 0.0325, 0.0099, 0.0251, 0.0548,
        0.0118, 0.0303, 0.0701, 0.0539, 0.3984, 0.2660], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:14,829][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([4.3090e-02, 6.0873e-02, 1.6993e-03, 7.7937e-02, 7.9139e-03, 3.1042e-02,
        2.2529e-01, 3.4175e-02, 4.7362e-03, 2.1081e-02, 4.1055e-02, 7.4117e-04,
        4.1108e-04, 3.2456e-02, 4.1750e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:14,830][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.1112, 0.0054, 0.0919, 0.0046, 0.0828, 0.0156, 0.0044, 0.0288, 0.0496,
        0.0040, 0.0058, 0.1011, 0.1701, 0.0298, 0.2950], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:14,832][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0222, 0.0042, 0.0042, 0.0069, 0.0059, 0.0090, 0.0120, 0.0185, 0.0270,
        0.0495, 0.0802, 0.0940, 0.1311, 0.2600, 0.2752], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:14,833][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0080, 0.0594, 0.0043, 0.1035, 0.0038, 0.0466, 0.1310, 0.0198, 0.0089,
        0.1507, 0.1813, 0.0048, 0.0072, 0.0338, 0.2368], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:14,835][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.1192, 0.0739, 0.0463, 0.0813, 0.0355, 0.0542, 0.0692, 0.0475, 0.0427,
        0.0697, 0.0853, 0.0458, 0.0483, 0.0828, 0.0983], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:14,836][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.1020, 0.0838, 0.0381, 0.1004, 0.0272, 0.0744, 0.0855, 0.0502, 0.0333,
        0.0761, 0.0927, 0.0275, 0.0311, 0.0642, 0.1134], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:14,838][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.1728, 0.0683, 0.0597, 0.0701, 0.0569, 0.0486, 0.0442, 0.0519, 0.0520,
        0.0702, 0.0666, 0.0718, 0.0607, 0.0357, 0.0705], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:14,839][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:31:14,841][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 1895],
        [ 7494],
        [ 2671],
        [12443],
        [    1],
        [18725],
        [15319],
        [16725],
        [11526],
        [ 2968],
        [ 5801],
        [34023],
        [ 1840],
        [ 1304],
        [ 4741]], device='cuda:0')
[2024-07-24 10:31:14,842][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[38968],
        [24150],
        [ 2371],
        [21901],
        [    1],
        [31309],
        [14851],
        [24525],
        [35341],
        [19583],
        [17975],
        [31082],
        [ 1873],
        [12191],
        [23038]], device='cuda:0')
[2024-07-24 10:31:14,844][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[ 3565],
        [ 3458],
        [ 4421],
        [ 4207],
        [ 3566],
        [11598],
        [ 3171],
        [ 2558],
        [ 6690],
        [ 4614],
        [ 5933],
        [ 5107],
        [ 7282],
        [ 9639],
        [11682]], device='cuda:0')
[2024-07-24 10:31:14,845][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[35839],
        [ 9039],
        [31165],
        [31448],
        [ 4585],
        [34674],
        [40532],
        [43163],
        [21184],
        [ 8839],
        [32444],
        [44292],
        [31878],
        [14704],
        [30623]], device='cuda:0')
[2024-07-24 10:31:14,847][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[11979],
        [11038],
        [12961],
        [37573],
        [13057],
        [21233],
        [24027],
        [19628],
        [15379],
        [17079],
        [40890],
        [20258],
        [17950],
        [25737],
        [31465]], device='cuda:0')
[2024-07-24 10:31:14,848][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[36798],
        [39710],
        [41184],
        [34719],
        [ 3590],
        [10293],
        [16210],
        [11372],
        [31989],
        [26037],
        [22543],
        [25202],
        [29544],
        [27141],
        [18024]], device='cuda:0')
[2024-07-24 10:31:14,849][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[14323],
        [14669],
        [16113],
        [16815],
        [  121],
        [ 8422],
        [13599],
        [ 8221],
        [ 7263],
        [12280],
        [14806],
        [ 6134],
        [17149],
        [13636],
        [15423]], device='cuda:0')
[2024-07-24 10:31:14,851][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[38539],
        [28054],
        [21639],
        [26421],
        [ 8477],
        [36513],
        [25472],
        [11486],
        [26691],
        [26400],
        [25026],
        [36389],
        [21640],
        [32533],
        [23335]], device='cuda:0')
[2024-07-24 10:31:14,852][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[19933],
        [20178],
        [27323],
        [19882],
        [ 3044],
        [ 2100],
        [ 3151],
        [ 6134],
        [ 1387],
        [ 1552],
        [ 1393],
        [ 8588],
        [17192],
        [ 3969],
        [ 9159]], device='cuda:0')
[2024-07-24 10:31:14,854][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[ 9335],
        [ 8514],
        [ 5344],
        [ 4895],
        [ 4361],
        [13407],
        [25554],
        [28746],
        [25812],
        [ 9839],
        [ 8156],
        [10463],
        [ 8409],
        [ 5986],
        [ 8152]], device='cuda:0')
[2024-07-24 10:31:14,854][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[16440],
        [ 1835],
        [10493],
        [ 1211],
        [ 8427],
        [ 1081],
        [ 2832],
        [ 2341],
        [ 4090],
        [ 1470],
        [ 1395],
        [  688],
        [ 7446],
        [  829],
        [ 1156]], device='cuda:0')
[2024-07-24 10:31:14,855][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[18693],
        [20125],
        [19334],
        [19370],
        [16040],
        [17284],
        [16766],
        [15471],
        [14522],
        [16376],
        [17826],
        [16881],
        [17092],
        [20104],
        [22115]], device='cuda:0')
[2024-07-24 10:31:14,857][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[12812],
        [14860],
        [28652],
        [18533],
        [32683],
        [24437],
        [32593],
        [28155],
        [13138],
        [25561],
        [24575],
        [23749],
        [39356],
        [18167],
        [22615]], device='cuda:0')
[2024-07-24 10:31:14,858][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[36148],
        [24296],
        [17380],
        [17455],
        [13660],
        [15613],
        [14641],
        [15801],
        [13404],
        [10868],
        [10122],
        [10360],
        [ 9204],
        [13033],
        [10350]], device='cuda:0')
[2024-07-24 10:31:14,859][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[24375],
        [12641],
        [26296],
        [22965],
        [    4],
        [40788],
        [37414],
        [25043],
        [30546],
        [ 9779],
        [20256],
        [49409],
        [23054],
        [14049],
        [11712]], device='cuda:0')
[2024-07-24 10:31:14,861][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[25171],
        [23298],
        [11650],
        [23391],
        [16395],
        [21306],
        [25462],
        [30177],
        [20221],
        [20436],
        [19770],
        [19625],
        [15098],
        [24018],
        [25974]], device='cuda:0')
[2024-07-24 10:31:14,862][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[ 5353],
        [17759],
        [18142],
        [ 7566],
        [37514],
        [16807],
        [ 4753],
        [26895],
        [30057],
        [15439],
        [ 7010],
        [21940],
        [16038],
        [26469],
        [ 4845]], device='cuda:0')
[2024-07-24 10:31:14,863][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[35672],
        [25350],
        [32969],
        [32890],
        [35238],
        [37742],
        [35347],
        [37463],
        [38137],
        [16504],
        [35346],
        [37390],
        [38028],
        [32647],
        [23958]], device='cuda:0')
[2024-07-24 10:31:14,865][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[ 9782],
        [21312],
        [ 9811],
        [28545],
        [18321],
        [33919],
        [34076],
        [22887],
        [24680],
        [37361],
        [36159],
        [17668],
        [17982],
        [27717],
        [35765]], device='cuda:0')
[2024-07-24 10:31:14,866][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[22711],
        [23238],
        [11611],
        [29797],
        [36377],
        [30061],
        [25264],
        [25406],
        [31577],
        [33678],
        [28910],
        [44006],
        [ 3585],
        [34937],
        [30029]], device='cuda:0')
[2024-07-24 10:31:14,868][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[22062],
        [12707],
        [21142],
        [12475],
        [ 5516],
        [ 5293],
        [ 7344],
        [ 6601],
        [19168],
        [10371],
        [12325],
        [ 7993],
        [22304],
        [ 7705],
        [10867]], device='cuda:0')
[2024-07-24 10:31:14,869][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[28767],
        [28595],
        [31298],
        [24689],
        [ 4244],
        [ 4905],
        [ 5730],
        [ 7532],
        [ 4421],
        [ 5884],
        [ 5352],
        [ 7686],
        [18455],
        [ 5906],
        [23297]], device='cuda:0')
[2024-07-24 10:31:14,871][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[ 5853],
        [ 5412],
        [ 3919],
        [ 9308],
        [ 6798],
        [ 4295],
        [ 9232],
        [10550],
        [10612],
        [ 3829],
        [ 6598],
        [ 6490],
        [ 8069],
        [ 8055],
        [ 2565]], device='cuda:0')
[2024-07-24 10:31:14,872][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[30835],
        [11403],
        [30840],
        [ 7020],
        [29299],
        [11947],
        [ 9172],
        [12980],
        [16915],
        [ 6381],
        [ 6090],
        [ 9672],
        [31062],
        [ 9490],
        [ 6830]], device='cuda:0')
[2024-07-24 10:31:14,874][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[30460],
        [30042],
        [30612],
        [31414],
        [31942],
        [36857],
        [37510],
        [39040],
        [40925],
        [39428],
        [38522],
        [39191],
        [37616],
        [40079],
        [39340]], device='cuda:0')
[2024-07-24 10:31:14,875][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[45950],
        [48401],
        [44745],
        [48590],
        [46609],
        [47286],
        [47746],
        [47728],
        [46016],
        [47818],
        [47645],
        [48070],
        [41296],
        [46754],
        [47781]], device='cuda:0')
[2024-07-24 10:31:14,876][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 9694],
        [ 7417],
        [30651],
        [15218],
        [20483],
        [16626],
        [18294],
        [19249],
        [31558],
        [24885],
        [20922],
        [21443],
        [19590],
        [24114],
        [20543]], device='cuda:0')
[2024-07-24 10:31:14,878][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[10814],
        [ 9512],
        [10320],
        [10066],
        [ 9967],
        [14744],
        [13886],
        [ 9261],
        [ 9202],
        [12877],
        [13645],
        [ 9780],
        [12657],
        [12220],
        [12284]], device='cuda:0')
[2024-07-24 10:31:14,879][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[15279],
        [30398],
        [16779],
        [20402],
        [50249],
        [ 6747],
        [ 8111],
        [19557],
        [14353],
        [33978],
        [22632],
        [  679],
        [19360],
        [29275],
        [31772]], device='cuda:0')
[2024-07-24 10:31:14,881][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[19016],
        [19016],
        [19016],
        [19016],
        [19016],
        [19016],
        [19016],
        [19016],
        [19016],
        [19016],
        [19016],
        [19016],
        [19016],
        [19016],
        [19016]], device='cuda:0')
[2024-07-24 10:31:14,908][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:31:14,908][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:14,909][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:14,909][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:14,910][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:14,911][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:14,912][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:14,914][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:14,915][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:14,915][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:14,917][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:14,918][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:14,919][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:14,920][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.2690, 0.7310], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:14,922][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.3145, 0.6855], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:14,923][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.7593, 0.2407], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:14,925][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.7306, 0.2694], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:14,926][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.2897, 0.7103], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:14,927][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.5838, 0.4162], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:14,929][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.9390, 0.0610], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:14,930][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.7495, 0.2505], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:14,932][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0163, 0.9837], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:14,932][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.1370, 0.8630], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:14,932][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.2393, 0.7607], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:14,933][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.2270, 0.7730], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:14,933][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Melissa] are: tensor([0.0302, 0.2460, 0.7238], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:14,934][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Melissa] are: tensor([0.2370, 0.6476, 0.1154], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:14,934][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Melissa] are: tensor([0.4495, 0.3440, 0.2065], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:14,934][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Melissa] are: tensor([0.3805, 0.1542, 0.4654], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:14,935][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Melissa] are: tensor([0.1324, 0.4023, 0.4653], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:14,935][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Melissa] are: tensor([0.3040, 0.5463, 0.1496], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:14,935][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Melissa] are: tensor([0.1404, 0.1269, 0.7327], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:14,936][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Melissa] are: tensor([0.2011, 0.0646, 0.7343], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:14,937][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Melissa] are: tensor([0.0323, 0.9642, 0.0035], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:14,939][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Melissa] are: tensor([0.0935, 0.7135, 0.1929], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:14,940][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Melissa] are: tensor([0.1333, 0.3910, 0.4756], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:14,941][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Melissa] are: tensor([0.0858, 0.4641, 0.4500], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:14,942][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0272, 0.1788, 0.6044, 0.1897], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:14,944][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.1996, 0.4725, 0.0998, 0.2281], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:14,945][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.2484, 0.1525, 0.1463, 0.4529], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:14,946][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.2996, 0.0823, 0.4475, 0.1706], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:14,948][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.1079, 0.2684, 0.3747, 0.2490], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:14,949][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.4727, 0.1472, 0.0133, 0.3668], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:14,950][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.4844, 0.0431, 0.4564, 0.0160], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:14,952][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.1389, 0.1274, 0.6000, 0.1337], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:14,953][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0166, 0.9745, 0.0056, 0.0032], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:14,955][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0761, 0.5247, 0.2420, 0.1572], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:14,956][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0983, 0.2817, 0.3820, 0.2380], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:14,958][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0472, 0.3653, 0.0256, 0.5619], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:14,958][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Benjamin] are: tensor([0.0088, 0.1116, 0.5632, 0.1515, 0.1649], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:14,959][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Benjamin] are: tensor([0.1707, 0.4605, 0.0819, 0.2252, 0.0617], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:14,959][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Benjamin] are: tensor([0.1774, 0.1957, 0.1176, 0.3829, 0.1264], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:14,959][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Benjamin] are: tensor([0.2535, 0.0899, 0.3183, 0.1517, 0.1866], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:14,960][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Benjamin] are: tensor([0.0778, 0.2351, 0.2564, 0.2060, 0.2247], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:14,960][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Benjamin] are: tensor([0.2125, 0.2675, 0.0519, 0.3818, 0.0863], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:14,960][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Benjamin] are: tensor([0.0495, 0.0961, 0.2436, 0.5102, 0.1005], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:14,961][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Benjamin] are: tensor([0.0486, 0.0205, 0.3989, 0.3111, 0.2209], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:14,961][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Benjamin] are: tensor([4.5585e-02, 9.4402e-01, 7.0733e-03, 3.1941e-03, 1.3179e-04],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:14,961][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Benjamin] are: tensor([0.0603, 0.5127, 0.1581, 0.1206, 0.1483], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:14,962][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Benjamin] are: tensor([0.0793, 0.2173, 0.2751, 0.1815, 0.2468], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:14,962][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Benjamin] are: tensor([0.1464, 0.3637, 0.0362, 0.1651, 0.2887], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:14,964][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.0313, 0.1094, 0.2370, 0.1559, 0.1514, 0.3150], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:14,965][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.1585, 0.3835, 0.0777, 0.1739, 0.0540, 0.1524], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:14,966][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.1282, 0.1678, 0.1136, 0.2642, 0.1478, 0.1784], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:14,968][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.1945, 0.0621, 0.2647, 0.1142, 0.1640, 0.2005], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:14,968][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.0678, 0.1783, 0.2235, 0.1534, 0.2025, 0.1746], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:14,970][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.2989, 0.2474, 0.0166, 0.1759, 0.1560, 0.1052], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:14,971][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.3972, 0.0108, 0.0453, 0.0277, 0.0160, 0.5030], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:14,972][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.0161, 0.0155, 0.2932, 0.0639, 0.0664, 0.5449], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:14,973][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ had] are: tensor([4.1234e-02, 9.4600e-01, 7.7352e-03, 2.9375e-03, 7.5334e-05, 2.0182e-03],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:14,975][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.0480, 0.3840, 0.1710, 0.0820, 0.1123, 0.2026], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:14,976][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.0581, 0.1805, 0.2338, 0.1475, 0.2129, 0.1672], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:14,977][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ had] are: tensor([1.8039e-02, 5.8701e-02, 5.6288e-04, 3.2600e-02, 4.0563e-04, 8.8969e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:14,979][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0088, 0.0607, 0.1530, 0.0865, 0.1019, 0.3460, 0.2432],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:14,980][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.1379, 0.3228, 0.0647, 0.1492, 0.0461, 0.1362, 0.1432],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:14,981][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.1512, 0.1197, 0.0943, 0.2365, 0.1227, 0.1044, 0.1712],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:14,983][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.1705, 0.0509, 0.2180, 0.0889, 0.1563, 0.1482, 0.1672],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:14,984][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0613, 0.1504, 0.1938, 0.1359, 0.1724, 0.1487, 0.1375],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:14,985][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.3069, 0.1646, 0.0277, 0.2870, 0.0601, 0.0213, 0.1324],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:14,985][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.1593, 0.0090, 0.1699, 0.0088, 0.2842, 0.3161, 0.0527],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:14,985][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0137, 0.0014, 0.0484, 0.0037, 0.0498, 0.8734, 0.0096],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:14,986][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ a] are: tensor([5.3282e-02, 9.3093e-01, 4.8999e-03, 2.3614e-03, 4.9895e-05, 2.1356e-03,
        6.3381e-03], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:14,986][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0463, 0.3205, 0.1322, 0.0832, 0.1001, 0.1582, 0.1595],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:14,986][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0533, 0.1529, 0.2055, 0.1283, 0.1869, 0.1434, 0.1297],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:14,987][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0226, 0.0366, 0.0013, 0.0409, 0.0010, 0.0233, 0.8743],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:14,987][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.0037, 0.0337, 0.0960, 0.0522, 0.0713, 0.2657, 0.3233, 0.1540],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:14,987][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ long] are: tensor([0.1206, 0.3020, 0.0571, 0.1449, 0.0426, 0.1274, 0.1458, 0.0596],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:14,988][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.1226, 0.1129, 0.1017, 0.2024, 0.1151, 0.1076, 0.1296, 0.1081],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:14,989][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ long] are: tensor([0.1515, 0.0458, 0.2346, 0.0859, 0.1415, 0.1435, 0.1284, 0.0688],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:14,990][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.0480, 0.1371, 0.1656, 0.1183, 0.1459, 0.1303, 0.1161, 0.1387],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:14,991][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ long] are: tensor([0.3698, 0.2276, 0.0049, 0.1758, 0.0219, 0.0159, 0.1106, 0.0735],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:14,992][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ long] are: tensor([2.7648e-02, 2.3749e-03, 1.8988e-04, 2.2842e-03, 7.2578e-04, 1.1063e-01,
        3.4118e-02, 8.2203e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:14,994][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.0256, 0.0121, 0.0480, 0.0219, 0.0525, 0.7110, 0.1092, 0.0196],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:14,994][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ long] are: tensor([4.6537e-02, 9.2572e-01, 7.0636e-03, 5.5386e-03, 9.9315e-05, 3.0084e-03,
        1.1411e-02, 6.2185e-04], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:14,996][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ long] are: tensor([0.0369, 0.3064, 0.1358, 0.0774, 0.0941, 0.1478, 0.1826, 0.0189],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:14,997][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.0462, 0.1363, 0.1777, 0.1124, 0.1609, 0.1251, 0.1136, 0.1278],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:14,999][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ long] are: tensor([0.0880, 0.1406, 0.0015, 0.0367, 0.0010, 0.1609, 0.2566, 0.3146],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:15,000][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.0027, 0.0356, 0.0869, 0.0511, 0.0768, 0.1996, 0.2375, 0.2188, 0.0909],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:15,001][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([0.1165, 0.2929, 0.0562, 0.1387, 0.0415, 0.1232, 0.1391, 0.0584, 0.0334],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:15,003][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.1039, 0.0998, 0.0937, 0.1923, 0.0947, 0.1078, 0.1214, 0.0837, 0.1028],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:15,004][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([0.1454, 0.0416, 0.2297, 0.0825, 0.1271, 0.1316, 0.1190, 0.0633, 0.0597],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:15,006][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.0397, 0.1139, 0.1416, 0.0947, 0.1241, 0.1098, 0.0934, 0.1145, 0.1681],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:15,007][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([0.1503, 0.1065, 0.0100, 0.0629, 0.0623, 0.0174, 0.0731, 0.0079, 0.5096],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:15,008][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.1100, 0.0189, 0.0245, 0.0524, 0.1415, 0.1516, 0.1279, 0.2282, 0.1448],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:15,010][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.0027, 0.0025, 0.0123, 0.0140, 0.0319, 0.7677, 0.0112, 0.1524, 0.0053],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:15,011][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([6.7063e-02, 9.0963e-01, 5.1601e-03, 2.7218e-03, 9.0825e-05, 5.3319e-03,
        9.3631e-03, 3.7273e-04, 2.7038e-04], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:15,011][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.0302, 0.2783, 0.1163, 0.0617, 0.0923, 0.1472, 0.2308, 0.0179, 0.0253],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:15,012][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.0412, 0.1171, 0.1540, 0.0952, 0.1378, 0.1060, 0.0967, 0.1091, 0.1429],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:15,012][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([7.1963e-02, 3.3745e-02, 2.0778e-04, 1.8682e-02, 5.4590e-04, 7.5726e-02,
        7.9132e-02, 2.2295e-02, 6.9770e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:15,012][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0084, 0.0304, 0.1215, 0.0466, 0.0865, 0.1119, 0.1841, 0.1400, 0.1654,
        0.1052], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:15,013][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.1221, 0.2751, 0.0552, 0.1213, 0.0378, 0.1111, 0.1157, 0.0501, 0.0296,
        0.0819], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:15,013][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0918, 0.0605, 0.0719, 0.1250, 0.0857, 0.0851, 0.0900, 0.0836, 0.1164,
        0.1902], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:15,014][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.1305, 0.0374, 0.1687, 0.0769, 0.1107, 0.1260, 0.1143, 0.0761, 0.0712,
        0.0882], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:15,014][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0390, 0.0962, 0.1308, 0.0873, 0.1142, 0.0983, 0.0858, 0.1060, 0.1458,
        0.0965], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:15,014][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.2963, 0.1571, 0.0162, 0.2156, 0.0289, 0.0089, 0.0706, 0.0094, 0.1039,
        0.0930], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:15,016][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0503, 0.0051, 0.0152, 0.0019, 0.0167, 0.2722, 0.0235, 0.6002, 0.0069,
        0.0081], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:15,017][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0058, 0.0034, 0.0445, 0.0135, 0.0188, 0.5495, 0.0114, 0.2357, 0.1081,
        0.0094], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:15,018][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [,] are: tensor([6.1971e-02, 9.2380e-01, 3.4382e-03, 2.4291e-03, 4.6117e-05, 2.9848e-03,
        4.8233e-03, 2.1719e-04, 1.6123e-04, 1.3080e-04], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:15,019][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0388, 0.2351, 0.1155, 0.0676, 0.0731, 0.1000, 0.1116, 0.0184, 0.0303,
        0.2098], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:15,021][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0364, 0.1043, 0.1416, 0.0868, 0.1278, 0.0979, 0.0864, 0.1014, 0.1313,
        0.0860], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:15,022][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0602, 0.2176, 0.0231, 0.1488, 0.0053, 0.1164, 0.1643, 0.0326, 0.0263,
        0.2054], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:15,023][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0051, 0.0335, 0.1183, 0.0354, 0.0853, 0.1044, 0.1869, 0.1496, 0.1317,
        0.1059, 0.0439], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:15,025][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.1092, 0.2592, 0.0504, 0.1114, 0.0344, 0.1031, 0.1100, 0.0479, 0.0280,
        0.0768, 0.0696], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:15,026][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0656, 0.0456, 0.0573, 0.1274, 0.0674, 0.0667, 0.0703, 0.0575, 0.0965,
        0.1477, 0.1980], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:15,028][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.1223, 0.0351, 0.1484, 0.0748, 0.0993, 0.1063, 0.0949, 0.0690, 0.0676,
        0.0817, 0.1005], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:15,029][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0362, 0.0865, 0.1230, 0.0804, 0.1077, 0.0887, 0.0783, 0.0964, 0.1356,
        0.0878, 0.0795], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:15,030][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.2005, 0.0637, 0.0045, 0.1850, 0.0145, 0.0023, 0.0256, 0.0036, 0.0437,
        0.0350, 0.4217], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:15,032][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0576, 0.0049, 0.0482, 0.0017, 0.0046, 0.4217, 0.0431, 0.3981, 0.0109,
        0.0073, 0.0020], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:15,033][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0087, 0.0096, 0.0168, 0.0086, 0.0084, 0.7502, 0.0091, 0.1153, 0.0358,
        0.0235, 0.0140], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:15,034][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ and] are: tensor([6.2272e-02, 9.1980e-01, 3.9180e-03, 2.8476e-03, 6.6842e-05, 3.9342e-03,
        6.3920e-03, 2.8431e-04, 2.4447e-04, 2.0669e-04, 3.5540e-05],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:15,036][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0350, 0.2119, 0.1127, 0.0656, 0.0738, 0.0873, 0.1175, 0.0182, 0.0293,
        0.1878, 0.0609], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:15,037][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0342, 0.0943, 0.1306, 0.0802, 0.1190, 0.0901, 0.0791, 0.0937, 0.1217,
        0.0789, 0.0782], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:15,038][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0166, 0.1143, 0.0061, 0.1580, 0.0012, 0.1256, 0.0435, 0.0147, 0.0169,
        0.1258, 0.3773], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:15,038][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.0030, 0.0301, 0.0645, 0.0435, 0.0345, 0.1657, 0.1360, 0.2005, 0.0966,
        0.1226, 0.0551, 0.0478], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:15,038][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([0.0967, 0.2576, 0.0452, 0.1126, 0.0318, 0.1011, 0.1119, 0.0466, 0.0263,
        0.0796, 0.0727, 0.0179], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:15,039][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.0774, 0.0692, 0.0597, 0.1157, 0.0524, 0.0604, 0.0749, 0.0603, 0.0731,
        0.1560, 0.1496, 0.0514], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:15,039][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([0.1099, 0.0340, 0.1334, 0.0628, 0.0850, 0.0926, 0.0896, 0.0534, 0.0531,
        0.0760, 0.0793, 0.1309], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:15,040][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.0317, 0.0894, 0.1008, 0.0761, 0.0844, 0.0820, 0.0749, 0.0859, 0.1228,
        0.0875, 0.0757, 0.0889], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:15,040][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([0.2239, 0.1251, 0.0082, 0.0845, 0.0314, 0.0110, 0.0428, 0.0189, 0.0872,
        0.0472, 0.1313, 0.1884], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:15,040][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.0215, 0.0099, 0.0024, 0.0105, 0.0061, 0.0716, 0.0101, 0.7855, 0.0008,
        0.0280, 0.0144, 0.0392], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:15,041][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.0064, 0.0069, 0.0319, 0.0207, 0.0594, 0.5772, 0.0191, 0.0898, 0.1348,
        0.0116, 0.0248, 0.0173], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:15,042][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([6.1072e-02, 9.0928e-01, 5.6986e-03, 3.6371e-03, 1.3106e-04, 9.3948e-03,
        9.4451e-03, 4.1990e-04, 3.8776e-04, 3.9906e-04, 5.9956e-05, 7.1640e-05],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:15,043][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([0.0260, 0.1939, 0.0810, 0.0449, 0.0594, 0.1547, 0.1600, 0.0128, 0.0190,
        0.1914, 0.0350, 0.0218], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:15,044][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.0318, 0.0895, 0.1138, 0.0735, 0.1048, 0.0807, 0.0737, 0.0820, 0.1066,
        0.0724, 0.0711, 0.1001], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:15,045][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([0.0206, 0.0187, 0.0040, 0.0067, 0.0087, 0.1894, 0.0290, 0.4926, 0.1936,
        0.0080, 0.0108, 0.0179], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:15,047][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Melissa] are: tensor([0.0027, 0.0259, 0.0832, 0.0309, 0.0688, 0.1171, 0.1646, 0.1016, 0.0980,
        0.1043, 0.0437, 0.0570, 0.1021], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:15,048][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Melissa] are: tensor([0.0888, 0.2378, 0.0380, 0.1130, 0.0299, 0.1052, 0.1228, 0.0499, 0.0278,
        0.0839, 0.0743, 0.0177, 0.0108], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:15,050][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Melissa] are: tensor([0.0616, 0.0600, 0.0448, 0.1179, 0.0539, 0.0594, 0.0746, 0.0563, 0.0654,
        0.1496, 0.1559, 0.0496, 0.0509], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:15,051][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Melissa] are: tensor([0.1023, 0.0361, 0.1121, 0.0602, 0.0774, 0.0848, 0.0824, 0.0478, 0.0528,
        0.0666, 0.0714, 0.1212, 0.0849], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:15,053][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Melissa] are: tensor([0.0248, 0.0787, 0.0912, 0.0685, 0.0789, 0.0732, 0.0642, 0.0766, 0.1101,
        0.0755, 0.0674, 0.0777, 0.1130], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:15,054][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Melissa] are: tensor([0.0487, 0.0874, 0.0217, 0.1267, 0.0474, 0.0038, 0.1319, 0.0043, 0.1097,
        0.0570, 0.2748, 0.0752, 0.0115], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:15,056][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Melissa] are: tensor([0.0305, 0.0297, 0.1328, 0.0744, 0.0746, 0.0739, 0.1193, 0.1081, 0.0078,
        0.0657, 0.0945, 0.0116, 0.1771], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:15,057][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Melissa] are: tensor([0.0062, 0.0032, 0.0225, 0.0173, 0.0837, 0.4437, 0.0686, 0.1374, 0.0909,
        0.0049, 0.0192, 0.0525, 0.0499], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:15,058][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Melissa] are: tensor([1.1735e-01, 8.6269e-01, 1.9704e-03, 2.2697e-03, 9.6251e-05, 9.9042e-03,
        4.7760e-03, 1.8805e-04, 2.2256e-04, 3.7636e-04, 5.7960e-05, 7.8250e-05,
        2.1748e-05], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:15,059][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Melissa] are: tensor([0.0210, 0.1588, 0.0437, 0.0386, 0.0548, 0.1363, 0.2720, 0.0148, 0.0171,
        0.1673, 0.0277, 0.0143, 0.0336], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:15,061][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Melissa] are: tensor([0.0287, 0.0807, 0.1021, 0.0666, 0.0919, 0.0722, 0.0662, 0.0739, 0.0957,
        0.0656, 0.0645, 0.0915, 0.1003], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:15,062][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Melissa] are: tensor([2.8148e-02, 1.7167e-01, 2.1902e-01, 9.2810e-02, 4.3068e-03, 2.4234e-02,
        2.1999e-02, 1.6846e-02, 7.5115e-03, 1.4956e-01, 1.6607e-01, 1.6326e-04,
        9.7668e-02], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:15,063][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.0050, 0.0302, 0.0737, 0.0396, 0.0558, 0.1332, 0.1265, 0.1189, 0.0627,
        0.0950, 0.0505, 0.0500, 0.0888, 0.0700], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:15,064][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ said] are: tensor([0.0909, 0.2249, 0.0441, 0.1088, 0.0318, 0.0990, 0.1094, 0.0452, 0.0270,
        0.0788, 0.0719, 0.0184, 0.0122, 0.0376], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:15,065][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.0549, 0.0505, 0.0596, 0.0816, 0.0597, 0.0567, 0.0644, 0.0430, 0.0678,
        0.1423, 0.1154, 0.0433, 0.0704, 0.0902], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:15,065][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ said] are: tensor([0.0973, 0.0246, 0.1144, 0.0491, 0.0761, 0.0836, 0.0707, 0.0420, 0.0418,
        0.0579, 0.0645, 0.1235, 0.0864, 0.0681], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:15,065][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.0240, 0.0676, 0.0864, 0.0578, 0.0772, 0.0652, 0.0580, 0.0680, 0.0974,
        0.0673, 0.0573, 0.0769, 0.1049, 0.0920], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:15,066][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ said] are: tensor([0.0959, 0.0531, 0.0050, 0.0567, 0.0306, 0.0078, 0.0465, 0.0059, 0.1694,
        0.0262, 0.1047, 0.0506, 0.0029, 0.3445], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:15,066][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.0986, 0.0091, 0.0142, 0.0107, 0.0703, 0.1551, 0.0028, 0.0394, 0.1407,
        0.0093, 0.0165, 0.0987, 0.0199, 0.3146], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:15,067][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.0025, 0.0009, 0.0676, 0.0062, 0.0349, 0.4496, 0.0029, 0.0744, 0.0193,
        0.0015, 0.0114, 0.0319, 0.2163, 0.0806], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:15,067][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ said] are: tensor([9.4622e-02, 8.8548e-01, 4.3220e-03, 2.9799e-03, 8.8825e-05, 5.6883e-03,
        5.8030e-03, 3.1184e-04, 2.5572e-04, 2.2978e-04, 4.0081e-05, 4.5680e-05,
        1.1309e-05, 1.1831e-04], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:15,067][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ said] are: tensor([0.0293, 0.1585, 0.0868, 0.0383, 0.0673, 0.1106, 0.1087, 0.0148, 0.0312,
        0.1391, 0.0322, 0.0254, 0.0726, 0.0851], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:15,069][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.0244, 0.0712, 0.0964, 0.0596, 0.0869, 0.0671, 0.0591, 0.0695, 0.0903,
        0.0589, 0.0580, 0.0873, 0.0954, 0.0760], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:15,070][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ said] are: tensor([1.5443e-02, 1.7402e-02, 8.9993e-04, 8.9324e-03, 1.1426e-03, 3.1620e-01,
        1.4142e-01, 1.7637e-01, 1.4966e-01, 2.1249e-02, 2.4225e-02, 1.5589e-03,
        2.5800e-04, 1.2523e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:15,071][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0036, 0.0240, 0.0598, 0.0296, 0.0610, 0.1405, 0.1206, 0.1121, 0.0951,
        0.0842, 0.0362, 0.0439, 0.0658, 0.1024, 0.0210], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:15,072][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0944, 0.2168, 0.0431, 0.1003, 0.0303, 0.0906, 0.0996, 0.0414, 0.0246,
        0.0707, 0.0645, 0.0168, 0.0116, 0.0338, 0.0615], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:15,074][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0490, 0.0418, 0.0460, 0.0709, 0.0489, 0.0520, 0.0612, 0.0558, 0.0695,
        0.1167, 0.1005, 0.0539, 0.0608, 0.0779, 0.0950], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:15,075][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0895, 0.0226, 0.1045, 0.0426, 0.0732, 0.0803, 0.0688, 0.0421, 0.0444,
        0.0541, 0.0557, 0.1157, 0.0841, 0.0676, 0.0546], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:15,077][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0263, 0.0614, 0.0807, 0.0555, 0.0707, 0.0619, 0.0573, 0.0678, 0.0912,
        0.0629, 0.0554, 0.0737, 0.0967, 0.0810, 0.0575], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:15,078][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.1996, 0.0442, 0.0100, 0.0803, 0.0220, 0.0056, 0.0316, 0.0094, 0.1809,
        0.0179, 0.1795, 0.1174, 0.0054, 0.0872, 0.0090], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:15,080][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.3270, 0.0010, 0.0013, 0.0023, 0.0082, 0.1366, 0.0267, 0.2144, 0.0027,
        0.0018, 0.0035, 0.0333, 0.0020, 0.2368, 0.0025], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:15,081][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0064, 0.0120, 0.0208, 0.0173, 0.0262, 0.5823, 0.0097, 0.0672, 0.0664,
        0.0199, 0.0208, 0.0265, 0.0408, 0.0642, 0.0195], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:15,082][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ to] are: tensor([1.0465e-01, 8.8065e-01, 3.0607e-03, 2.4612e-03, 7.2282e-05, 4.5851e-03,
        3.7351e-03, 2.1760e-04, 1.8849e-04, 1.9350e-04, 3.4925e-05, 4.1735e-05,
        1.0754e-05, 9.1627e-05, 1.2059e-05], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:15,084][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0285, 0.1566, 0.0790, 0.0464, 0.0569, 0.0859, 0.1034, 0.0148, 0.0233,
        0.1510, 0.0410, 0.0253, 0.0651, 0.0597, 0.0630], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:15,085][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0233, 0.0674, 0.0912, 0.0557, 0.0825, 0.0630, 0.0560, 0.0654, 0.0857,
        0.0558, 0.0543, 0.0813, 0.0906, 0.0721, 0.0557], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:15,086][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0232, 0.0522, 0.0042, 0.0573, 0.0017, 0.1871, 0.2558, 0.0613, 0.0124,
        0.0729, 0.1092, 0.0010, 0.0017, 0.0047, 0.1552], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:15,100][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:31:15,101][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:15,102][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:15,103][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:15,104][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:15,105][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:15,106][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:15,107][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:15,109][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:15,110][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:15,111][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:15,112][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:15,113][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:15,115][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.8006, 0.1994], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:15,116][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.2428, 0.7572], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:15,117][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.5777, 0.4223], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:15,117][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.5000, 0.5000], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:15,117][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.5831, 0.4169], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:15,118][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.3936, 0.6064], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:15,118][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.9658, 0.0342], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:15,118][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.5954, 0.4046], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:15,119][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.5388, 0.4612], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:15,119][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([9.9968e-01, 3.1935e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:15,120][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.1621, 0.8379], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:15,120][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.1285, 0.8715], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:15,122][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Melissa] are: tensor([0.0142, 0.0514, 0.9343], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:15,123][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Melissa] are: tensor([0.0990, 0.4217, 0.4793], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:15,124][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Melissa] are: tensor([0.3893, 0.3112, 0.2995], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:15,126][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Melissa] are: tensor([0.3334, 0.3334, 0.3332], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:15,127][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Melissa] are: tensor([0.4741, 0.3164, 0.2095], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:15,128][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Melissa] are: tensor([0.3071, 0.6617, 0.0312], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:15,129][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Melissa] are: tensor([0.7073, 0.1256, 0.1671], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:15,131][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Melissa] are: tensor([0.0170, 0.0310, 0.9519], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:15,132][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Melissa] are: tensor([0.2800, 0.2594, 0.4606], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:15,133][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Melissa] are: tensor([9.9860e-01, 4.3183e-04, 9.7176e-04], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:15,134][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Melissa] are: tensor([0.0968, 0.4216, 0.4816], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:15,136][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Melissa] are: tensor([0.0643, 0.9047, 0.0310], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:15,137][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0043, 0.0261, 0.9587, 0.0108], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:15,138][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0790, 0.2334, 0.2955, 0.3921], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:15,140][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.3143, 0.2346, 0.2305, 0.2206], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:15,141][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.2501, 0.2501, 0.2499, 0.2499], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:15,143][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.3178, 0.2330, 0.1620, 0.2872], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:15,143][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.1343, 0.1450, 0.0078, 0.7128], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:15,143][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.5935, 0.0915, 0.2239, 0.0910], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:15,144][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0355, 0.0533, 0.8803, 0.0310], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:15,144][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.2503, 0.2472, 0.3961, 0.1064], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:15,144][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([9.2116e-01, 6.3095e-04, 2.5926e-03, 7.5613e-02], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:15,145][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0675, 0.2982, 0.3819, 0.2524], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:15,145][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0334, 0.1362, 0.0010, 0.8294], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:15,145][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Benjamin] are: tensor([2.8628e-04, 4.5677e-03, 9.6617e-01, 7.9246e-03, 2.1050e-02],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:15,146][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Benjamin] are: tensor([0.0487, 0.1960, 0.2160, 0.3629, 0.1763], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:15,146][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Benjamin] are: tensor([0.2406, 0.1866, 0.1914, 0.1774, 0.2040], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:15,146][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Benjamin] are: tensor([0.2001, 0.2001, 0.1999, 0.1999, 0.2000], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:15,148][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Benjamin] are: tensor([0.2862, 0.1924, 0.1277, 0.2433, 0.1504], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:15,149][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Benjamin] are: tensor([0.1076, 0.1874, 0.0088, 0.6765, 0.0197], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:15,150][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Benjamin] are: tensor([0.5878, 0.1109, 0.1933, 0.0888, 0.0192], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:15,152][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Benjamin] are: tensor([0.0088, 0.0149, 0.8026, 0.0313, 0.1424], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:15,153][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Benjamin] are: tensor([0.1757, 0.1593, 0.3062, 0.0468, 0.3120], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:15,154][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Benjamin] are: tensor([9.2170e-01, 8.3655e-04, 3.5374e-03, 5.6378e-02, 1.7547e-02],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:15,155][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Benjamin] are: tensor([0.0584, 0.2306, 0.2757, 0.1934, 0.2420], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:15,156][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Benjamin] are: tensor([1.9288e-02, 1.9828e-01, 7.5065e-04, 7.7058e-01, 1.1100e-02],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:15,158][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.1049, 0.0769, 0.3910, 0.1061, 0.1379, 0.1833], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:15,159][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.0556, 0.1375, 0.1727, 0.2135, 0.1441, 0.2765], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:15,160][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.2097, 0.1618, 0.1604, 0.1509, 0.1768, 0.1402], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:15,162][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.1667, 0.1667, 0.1666, 0.1666, 0.1667, 0.1666], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:15,163][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.2279, 0.1659, 0.1130, 0.2053, 0.1315, 0.1563], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:15,165][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.1090, 0.1778, 0.0079, 0.4938, 0.0434, 0.1682], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:15,166][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.5055, 0.0727, 0.1989, 0.0954, 0.0093, 0.1181], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:15,168][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.0077, 0.0120, 0.7974, 0.0157, 0.0818, 0.0854], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:15,169][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.1284, 0.1165, 0.2183, 0.0417, 0.2321, 0.2630], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:15,170][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.7795, 0.0012, 0.0062, 0.0294, 0.0289, 0.1549], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:15,170][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.0401, 0.1902, 0.2293, 0.1547, 0.2051, 0.1806], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:15,170][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.0173, 0.1876, 0.0009, 0.6346, 0.0018, 0.1578], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:15,171][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0045, 0.0193, 0.1565, 0.0231, 0.0652, 0.6686, 0.0629],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:15,171][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0400, 0.1005, 0.1304, 0.1585, 0.1107, 0.2168, 0.2431],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:15,171][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.1846, 0.1416, 0.1418, 0.1337, 0.1551, 0.1237, 0.1195],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:15,172][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.1429, 0.1429, 0.1428, 0.1428, 0.1429, 0.1428, 0.1428],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:15,172][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.1904, 0.1395, 0.0960, 0.1733, 0.1121, 0.1317, 0.1570],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:15,173][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0667, 0.0969, 0.0063, 0.4418, 0.0177, 0.0498, 0.3208],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:15,174][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.3869, 0.0927, 0.2014, 0.1080, 0.0506, 0.0626, 0.0979],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:15,175][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0186, 0.0091, 0.6004, 0.0103, 0.1658, 0.1695, 0.0264],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:15,176][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.1090, 0.1023, 0.1861, 0.0395, 0.1954, 0.2246, 0.1432],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:15,177][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([1.4947e-01, 1.1787e-04, 3.1508e-04, 5.5370e-03, 2.3612e-03, 7.1767e-03,
        8.3502e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:15,178][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0369, 0.1591, 0.2019, 0.1342, 0.1800, 0.1532, 0.1346],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:15,180][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0165, 0.1203, 0.0014, 0.4487, 0.0007, 0.0114, 0.4010],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:15,181][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.0007, 0.0031, 0.0793, 0.0047, 0.0486, 0.3522, 0.4951, 0.0162],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:15,182][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([0.0229, 0.0742, 0.0886, 0.1318, 0.0717, 0.1944, 0.2285, 0.1879],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:15,184][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([0.1617, 0.1231, 0.1257, 0.1167, 0.1354, 0.1063, 0.1030, 0.1281],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:15,185][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([0.1251, 0.1251, 0.1250, 0.1250, 0.1251, 0.1249, 0.1250, 0.1249],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:15,187][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.1770, 0.1260, 0.0840, 0.1571, 0.0982, 0.1189, 0.1428, 0.0961],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:15,188][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([0.0875, 0.1271, 0.0026, 0.3802, 0.0098, 0.0453, 0.2818, 0.0656],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:15,190][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.3651, 0.1321, 0.0275, 0.1136, 0.0204, 0.1391, 0.1154, 0.0868],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:15,191][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.0185, 0.0119, 0.4544, 0.0127, 0.1221, 0.3038, 0.0681, 0.0085],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:15,192][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.0925, 0.0823, 0.1514, 0.0278, 0.1634, 0.1672, 0.1014, 0.2140],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:15,193][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([4.7647e-02, 1.1453e-04, 4.6869e-04, 6.6709e-03, 1.5497e-03, 2.7454e-03,
        4.2214e-01, 5.1867e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:15,195][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.0328, 0.1424, 0.1755, 0.1173, 0.1551, 0.1331, 0.1178, 0.1260],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:15,196][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([2.4500e-02, 1.5035e-01, 8.8687e-04, 6.9922e-01, 5.9676e-04, 3.2188e-02,
        3.0232e-02, 6.2027e-02], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:15,196][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.0004, 0.0057, 0.1021, 0.0136, 0.1271, 0.2902, 0.2529, 0.1938, 0.0142],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:15,197][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([0.0166, 0.0603, 0.0689, 0.1110, 0.0569, 0.1723, 0.2078, 0.1669, 0.1392],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:15,197][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([0.1355, 0.1053, 0.1072, 0.1020, 0.1152, 0.0914, 0.0884, 0.1111, 0.1440],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:15,198][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([0.1112, 0.1112, 0.1111, 0.1111, 0.1112, 0.1111, 0.1111, 0.1110, 0.1111],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:15,198][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.1683, 0.1154, 0.0759, 0.1450, 0.0896, 0.1091, 0.1319, 0.0877, 0.0771],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:15,199][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([0.1001, 0.1132, 0.0044, 0.3088, 0.0193, 0.0629, 0.2659, 0.0327, 0.0928],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:15,199][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.3692, 0.1010, 0.0759, 0.0980, 0.0685, 0.0753, 0.0890, 0.0302, 0.0931],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:15,200][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.0061, 0.0061, 0.2391, 0.0098, 0.1380, 0.4008, 0.0150, 0.1268, 0.0584],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:15,201][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([0.0767, 0.0700, 0.1278, 0.0225, 0.1330, 0.1329, 0.0798, 0.1745, 0.1829],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:15,202][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([1.9888e-02, 4.6728e-05, 3.1904e-04, 1.6611e-03, 1.5155e-03, 3.0799e-03,
        5.3158e-01, 4.4115e-01, 7.5379e-04], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:15,203][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.0294, 0.1228, 0.1513, 0.1003, 0.1327, 0.1136, 0.1007, 0.1075, 0.1416],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:15,204][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([3.9314e-02, 1.7674e-01, 6.6373e-04, 7.1442e-01, 1.4329e-03, 1.1876e-02,
        2.6924e-02, 2.3566e-03, 2.6278e-02], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:15,205][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0124, 0.0062, 0.2426, 0.0164, 0.1505, 0.0345, 0.1499, 0.0417, 0.3281,
        0.0176], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:15,207][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0228, 0.0603, 0.0746, 0.0973, 0.0631, 0.1312, 0.1505, 0.1421, 0.1296,
        0.1285], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:15,208][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.1201, 0.0942, 0.0951, 0.0917, 0.1046, 0.0835, 0.0807, 0.1012, 0.1334,
        0.0954], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:15,209][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.0999, 0.1000, 0.0999, 0.1000,
        0.1001], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:15,211][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.1405, 0.1044, 0.0712, 0.1276, 0.0824, 0.0969, 0.1150, 0.0800, 0.0719,
        0.1101], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:15,212][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0801, 0.0936, 0.0051, 0.3169, 0.0125, 0.0293, 0.2050, 0.0302, 0.0313,
        0.1959], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:15,214][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.3152, 0.0472, 0.0659, 0.0778, 0.0300, 0.0800, 0.1186, 0.0767, 0.1301,
        0.0584], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:15,215][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0088, 0.0141, 0.4024, 0.0164, 0.0821, 0.1117, 0.0300, 0.0653, 0.2476,
        0.0218], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:15,217][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0725, 0.0686, 0.1111, 0.0274, 0.1099, 0.1237, 0.0865, 0.1475, 0.1499,
        0.1030], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:15,217][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([5.2412e-02, 3.6198e-05, 9.6652e-05, 3.3393e-03, 5.0255e-04, 1.1353e-03,
        2.6429e-01, 6.7577e-01, 4.0838e-04, 2.0127e-03], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:15,219][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0254, 0.1095, 0.1389, 0.0911, 0.1229, 0.1051, 0.0889, 0.0995, 0.1301,
        0.0886], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:15,220][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0204, 0.0828, 0.0013, 0.3313, 0.0014, 0.0132, 0.0199, 0.0042, 0.0026,
        0.5228], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:15,222][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0012, 0.0092, 0.3351, 0.0039, 0.2133, 0.0279, 0.1464, 0.0782, 0.1559,
        0.0250, 0.0038], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:15,222][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0215, 0.0554, 0.0708, 0.0864, 0.0586, 0.1147, 0.1321, 0.1262, 0.1182,
        0.1147, 0.1014], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:15,223][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.1099, 0.0858, 0.0861, 0.0831, 0.0948, 0.0757, 0.0731, 0.0918, 0.1213,
        0.0869, 0.0916], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:15,223][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0909, 0.0909, 0.0909, 0.0909, 0.0909, 0.0908, 0.0909, 0.0908, 0.0909,
        0.0910, 0.0909], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:15,223][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.1215, 0.0915, 0.0634, 0.1118, 0.0736, 0.0855, 0.1009, 0.0710, 0.0646,
        0.0970, 0.1191], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:15,224][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0414, 0.0418, 0.0022, 0.2207, 0.0071, 0.0112, 0.1025, 0.0141, 0.0152,
        0.0958, 0.4481], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:15,224][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.2678, 0.0572, 0.1235, 0.0505, 0.0232, 0.0720, 0.1479, 0.0582, 0.0817,
        0.0746, 0.0434], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:15,225][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0177, 0.0248, 0.2872, 0.0155, 0.0752, 0.2001, 0.0325, 0.0579, 0.2330,
        0.0380, 0.0181], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:15,225][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0593, 0.0576, 0.1005, 0.0245, 0.1028, 0.1220, 0.0817, 0.1424, 0.1554,
        0.1028, 0.0510], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:15,225][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([4.1643e-02, 2.7476e-05, 1.2453e-04, 3.5050e-03, 7.3823e-04, 7.6020e-04,
        2.9658e-01, 6.4956e-01, 5.3299e-04, 1.3607e-03, 5.1669e-03],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:15,226][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0236, 0.0979, 0.1282, 0.0841, 0.1142, 0.0962, 0.0808, 0.0920, 0.1206,
        0.0806, 0.0818], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:15,227][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([8.8118e-03, 3.0083e-02, 2.4992e-04, 2.0656e-01, 2.9056e-04, 6.0288e-03,
        5.1944e-03, 1.0904e-03, 6.6386e-04, 2.1449e-01, 5.2653e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:15,228][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.0008, 0.0112, 0.0590, 0.0197, 0.0101, 0.2629, 0.0437, 0.4021, 0.0678,
        0.0570, 0.0185, 0.0472], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:15,230][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([0.0134, 0.0438, 0.0531, 0.0791, 0.0442, 0.1156, 0.1373, 0.1144, 0.0995,
        0.1158, 0.1030, 0.0808], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:15,231][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([0.0951, 0.0786, 0.0814, 0.0763, 0.0869, 0.0684, 0.0666, 0.0846, 0.1093,
        0.0788, 0.0833, 0.0908], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:15,233][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([0.0834, 0.0834, 0.0833, 0.0833, 0.0834, 0.0833, 0.0833, 0.0833, 0.0834,
        0.0834, 0.0834, 0.0833], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:15,234][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.1174, 0.0837, 0.0564, 0.1041, 0.0658, 0.0788, 0.0946, 0.0645, 0.0574,
        0.0904, 0.1130, 0.0738], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:15,236][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([0.0508, 0.0737, 0.0023, 0.1866, 0.0080, 0.0279, 0.1159, 0.0290, 0.0212,
        0.1070, 0.2996, 0.0780], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:15,237][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.2286, 0.0587, 0.0681, 0.0412, 0.0098, 0.2049, 0.0387, 0.1836, 0.0417,
        0.0503, 0.0296, 0.0448], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:15,238][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.0037, 0.0069, 0.1718, 0.0061, 0.1053, 0.2071, 0.0117, 0.0208, 0.4116,
        0.0084, 0.0061, 0.0407], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:15,240][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.0661, 0.0614, 0.1018, 0.0148, 0.1003, 0.1045, 0.0602, 0.1381, 0.1415,
        0.0700, 0.0300, 0.1114], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:15,241][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([4.3609e-02, 2.5147e-05, 1.1882e-04, 1.6986e-03, 5.4889e-04, 1.1388e-02,
        5.1913e-01, 4.1870e-01, 4.7823e-04, 1.6353e-03, 2.1378e-03, 5.2855e-04],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:15,242][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([0.0229, 0.0930, 0.1122, 0.0766, 0.1016, 0.0850, 0.0759, 0.0809, 0.1058,
        0.0739, 0.0733, 0.0989], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:15,243][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([1.4722e-02, 3.9753e-02, 1.8288e-04, 1.5990e-01, 2.5810e-04, 2.8967e-03,
        2.4579e-03, 1.7454e-03, 5.9157e-04, 3.2156e-01, 4.5107e-01, 4.8581e-03],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:15,245][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Melissa] are: tensor([0.0018, 0.0084, 0.1301, 0.0081, 0.2728, 0.0837, 0.1089, 0.0186, 0.0694,
        0.0283, 0.0080, 0.1055, 0.1565], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:15,246][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Melissa] are: tensor([0.0091, 0.0380, 0.0431, 0.0718, 0.0352, 0.1170, 0.1372, 0.1116, 0.0919,
        0.1127, 0.0968, 0.0791, 0.0565], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:15,248][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Melissa] are: tensor([0.0883, 0.0741, 0.0729, 0.0687, 0.0778, 0.0625, 0.0604, 0.0765, 0.1048,
        0.0753, 0.0796, 0.0850, 0.0741], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:15,249][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Melissa] are: tensor([0.0769, 0.0770, 0.0769, 0.0769, 0.0769, 0.0769, 0.0769, 0.0769, 0.0769,
        0.0770, 0.0769, 0.0769, 0.0769], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:15,249][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Melissa] are: tensor([0.1144, 0.0765, 0.0506, 0.0963, 0.0603, 0.0726, 0.0884, 0.0594, 0.0520,
        0.0849, 0.1072, 0.0689, 0.0684], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:15,249][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Melissa] are: tensor([0.0200, 0.0455, 0.0019, 0.1926, 0.0057, 0.0121, 0.1573, 0.0093, 0.0151,
        0.0863, 0.4234, 0.0294, 0.0014], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:15,250][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Melissa] are: tensor([0.2410, 0.0989, 0.1136, 0.0538, 0.0447, 0.0410, 0.0897, 0.0299, 0.0766,
        0.0754, 0.0399, 0.0632, 0.0323], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:15,250][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Melissa] are: tensor([0.0027, 0.0061, 0.1730, 0.0066, 0.1333, 0.1642, 0.0413, 0.0258, 0.1799,
        0.0078, 0.0063, 0.0668, 0.1861], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:15,251][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Melissa] are: tensor([0.0513, 0.0512, 0.0835, 0.0134, 0.0902, 0.1002, 0.0550, 0.1257, 0.1486,
        0.0671, 0.0318, 0.0939, 0.0880], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:15,251][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Melissa] are: tensor([2.5322e-02, 1.2914e-05, 2.8021e-05, 1.0348e-03, 3.0010e-04, 3.7199e-03,
        5.6583e-01, 4.0082e-01, 5.4404e-04, 7.8202e-04, 1.3954e-03, 1.5346e-04,
        6.0623e-05], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:15,251][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Melissa] are: tensor([0.0210, 0.0842, 0.1001, 0.0699, 0.0884, 0.0766, 0.0684, 0.0726, 0.0946,
        0.0676, 0.0670, 0.0907, 0.0989], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:15,252][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Melissa] are: tensor([2.1051e-03, 3.3079e-02, 9.7254e-04, 1.2115e-01, 1.3016e-04, 1.2088e-03,
        5.3116e-03, 3.8891e-04, 2.1397e-04, 3.9377e-01, 4.4067e-01, 2.6410e-04,
        7.3557e-04], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:15,253][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.0036, 0.0109, 0.1336, 0.0196, 0.1629, 0.1982, 0.0669, 0.0728, 0.0131,
        0.0405, 0.0219, 0.0569, 0.1800, 0.0189], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:15,254][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([0.0144, 0.0384, 0.0496, 0.0653, 0.0408, 0.0905, 0.1074, 0.0970, 0.0869,
        0.0911, 0.0811, 0.0694, 0.0625, 0.1056], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:15,256][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([0.0852, 0.0667, 0.0687, 0.0647, 0.0753, 0.0600, 0.0580, 0.0717, 0.0961,
        0.0689, 0.0725, 0.0790, 0.0698, 0.0634], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:15,257][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([0.0715, 0.0715, 0.0714, 0.0714, 0.0715, 0.0714, 0.0714, 0.0714, 0.0714,
        0.0715, 0.0714, 0.0714, 0.0714, 0.0714], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:15,258][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([0.1003, 0.0730, 0.0494, 0.0908, 0.0578, 0.0687, 0.0824, 0.0563, 0.0500,
        0.0785, 0.0971, 0.0636, 0.0626, 0.0696], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:15,260][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([0.0350, 0.0443, 0.0022, 0.1458, 0.0091, 0.0220, 0.1351, 0.0170, 0.0316,
        0.0844, 0.2634, 0.0382, 0.0018, 0.1701], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:15,261][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([0.2679, 0.0485, 0.0415, 0.0627, 0.0194, 0.0813, 0.0505, 0.0423, 0.2298,
        0.0433, 0.0405, 0.0441, 0.0061, 0.0223], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:15,263][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.0021, 0.0026, 0.2867, 0.0030, 0.0605, 0.0564, 0.0022, 0.0153, 0.0484,
        0.0024, 0.0035, 0.0598, 0.3650, 0.0922], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:15,264][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([0.0458, 0.0411, 0.0766, 0.0148, 0.0793, 0.0866, 0.0527, 0.1121, 0.1183,
        0.0619, 0.0295, 0.0947, 0.0869, 0.0997], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:15,265][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([6.8962e-02, 1.4723e-05, 1.3160e-04, 5.2306e-04, 1.0062e-03, 3.7114e-03,
        2.9120e-01, 6.2887e-01, 3.3418e-03, 6.1513e-04, 6.6984e-04, 3.3615e-04,
        3.0158e-04, 3.1576e-04], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:15,266][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([0.0171, 0.0739, 0.0943, 0.0624, 0.0833, 0.0715, 0.0605, 0.0679, 0.0891,
        0.0605, 0.0605, 0.0865, 0.0941, 0.0784], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:15,267][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([8.8038e-03, 4.7183e-02, 4.0698e-04, 1.3852e-01, 6.1525e-04, 5.8396e-03,
        1.5528e-02, 1.0088e-03, 3.0283e-03, 3.3337e-01, 3.9328e-01, 1.1708e-03,
        3.7769e-04, 5.0862e-02], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:15,269][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0019, 0.0057, 0.0624, 0.0034, 0.1785, 0.2398, 0.0542, 0.0383, 0.0729,
        0.0206, 0.0042, 0.0425, 0.0823, 0.1930, 0.0003], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:15,270][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0150, 0.0378, 0.0486, 0.0603, 0.0400, 0.0798, 0.0915, 0.0865, 0.0794,
        0.0802, 0.0720, 0.0646, 0.0584, 0.0927, 0.0931], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:15,272][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0707, 0.0609, 0.0611, 0.0651, 0.0697, 0.0577, 0.0567, 0.0726, 0.0923,
        0.0683, 0.0717, 0.0738, 0.0612, 0.0625, 0.0558], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:15,273][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0667, 0.0667, 0.0666, 0.0666, 0.0667, 0.0666, 0.0667, 0.0666, 0.0667,
        0.0667, 0.0667, 0.0666, 0.0667, 0.0667, 0.0667], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:15,275][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0911, 0.0681, 0.0466, 0.0830, 0.0540, 0.0631, 0.0749, 0.0524, 0.0471,
        0.0716, 0.0875, 0.0590, 0.0577, 0.0636, 0.0804], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:15,275][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0453, 0.0363, 0.0030, 0.1679, 0.0086, 0.0182, 0.1267, 0.0199, 0.0258,
        0.0740, 0.3200, 0.0429, 0.0023, 0.0783, 0.0307], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:15,276][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.2500, 0.0546, 0.0284, 0.0991, 0.0407, 0.0444, 0.0938, 0.0399, 0.0750,
        0.0479, 0.0660, 0.0651, 0.0088, 0.0276, 0.0588], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:15,276][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0056, 0.0107, 0.1606, 0.0085, 0.0623, 0.0846, 0.0109, 0.0186, 0.2220,
        0.0154, 0.0092, 0.0643, 0.1781, 0.1418, 0.0074], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:15,276][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0373, 0.0355, 0.0654, 0.0155, 0.0708, 0.0820, 0.0529, 0.1057, 0.1260,
        0.0687, 0.0344, 0.0788, 0.0833, 0.1005, 0.0430], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:15,277][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([2.5206e-02, 1.3131e-05, 4.6360e-05, 1.0532e-03, 4.0605e-04, 7.7141e-04,
        3.4411e-01, 5.3115e-01, 1.7441e-04, 8.1062e-04, 1.3805e-03, 2.3930e-04,
        1.0241e-04, 2.9390e-05, 9.4505e-02], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:15,277][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0162, 0.0700, 0.0889, 0.0581, 0.0789, 0.0672, 0.0575, 0.0638, 0.0845,
        0.0574, 0.0566, 0.0802, 0.0892, 0.0747, 0.0568], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:15,278][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([5.3222e-03, 3.5255e-02, 2.5917e-04, 1.4881e-01, 2.1412e-04, 3.4609e-03,
        8.3312e-03, 7.2116e-04, 6.4275e-04, 2.3649e-01, 3.5892e-01, 6.6668e-04,
        2.3780e-04, 1.7002e-03, 1.9897e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:15,279][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:31:15,280][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 3341],
        [ 8286],
        [ 1162],
        [ 5655],
        [   14],
        [25511],
        [19573],
        [17530],
        [12523],
        [ 6667],
        [ 7408],
        [25102],
        [ 1784],
        [ 8276],
        [ 8963]], device='cuda:0')
[2024-07-24 10:31:15,281][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 1171],
        [12196],
        [ 2639],
        [10118],
        [    3],
        [23903],
        [16312],
        [22029],
        [12982],
        [ 6825],
        [ 4278],
        [38256],
        [ 1939],
        [ 1543],
        [ 3654]], device='cuda:0')
[2024-07-24 10:31:15,282][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[ 2921],
        [ 7332],
        [ 9909],
        [ 9912],
        [11276],
        [ 9756],
        [10900],
        [10051],
        [ 9450],
        [ 9830],
        [ 9701],
        [ 8905],
        [10457],
        [10232],
        [10391]], device='cuda:0')
[2024-07-24 10:31:15,284][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[21634],
        [22333],
        [22737],
        [20549],
        [20278],
        [19713],
        [19288],
        [19167],
        [19215],
        [19210],
        [19030],
        [19030],
        [18939],
        [19067],
        [19126]], device='cuda:0')
[2024-07-24 10:31:15,285][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 3924],
        [ 5872],
        [ 8836],
        [ 9182],
        [10135],
        [12062],
        [13731],
        [13991],
        [15822],
        [16223],
        [13863],
        [14503],
        [14453],
        [11998],
        [12910]], device='cuda:0')
[2024-07-24 10:31:15,287][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[21883],
        [26072],
        [37152],
        [37399],
        [36277],
        [36982],
        [34769],
        [35039],
        [35677],
        [34793],
        [34232],
        [33814],
        [35036],
        [36089],
        [35552]], device='cuda:0')
[2024-07-24 10:31:15,288][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[17846],
        [26704],
        [24074],
        [24043],
        [22729],
        [22024],
        [22642],
        [22956],
        [22737],
        [23525],
        [23696],
        [23622],
        [23330],
        [22953],
        [23163]], device='cuda:0')
[2024-07-24 10:31:15,289][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[12965],
        [18601],
        [20260],
        [16712],
        [19918],
        [21238],
        [18815],
        [18544],
        [23849],
        [19309],
        [16487],
        [18228],
        [18965],
        [20577],
        [18568]], device='cuda:0')
[2024-07-24 10:31:15,291][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[11440],
        [11031],
        [ 1761],
        [ 3414],
        [ 5844],
        [ 4329],
        [ 4531],
        [ 3543],
        [ 8241],
        [ 2684],
        [ 2103],
        [ 3376],
        [ 1787],
        [16709],
        [ 5681]], device='cuda:0')
[2024-07-24 10:31:15,292][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[6511],
        [3911],
        [2327],
        [1831],
        [8032],
        [6099],
        [9873],
        [8780],
        [8184],
        [5663],
        [6899],
        [7116],
        [6996],
        [4652],
        [5841]], device='cuda:0')
[2024-07-24 10:31:15,294][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[16076],
        [31384],
        [31283],
        [31204],
        [31060],
        [31017],
        [30895],
        [30632],
        [30645],
        [30893],
        [30791],
        [30495],
        [30451],
        [30586],
        [30666]], device='cuda:0')
[2024-07-24 10:31:15,295][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[43079],
        [40817],
        [39665],
        [39687],
        [40865],
        [41239],
        [41289],
        [41256],
        [41557],
        [41960],
        [42145],
        [42216],
        [41996],
        [42086],
        [42279]], device='cuda:0')
[2024-07-24 10:31:15,297][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[9998],
        [9046],
        [7914],
        [7398],
        [7317],
        [7478],
        [7659],
        [7391],
        [7108],
        [7183],
        [7200],
        [7263],
        [7261],
        [7164],
        [7269]], device='cuda:0')
[2024-07-24 10:31:15,298][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[28642],
        [27770],
        [27399],
        [30105],
        [31907],
        [29354],
        [27559],
        [27184],
        [25715],
        [28786],
        [31590],
        [25418],
        [29022],
        [26078],
        [27488]], device='cuda:0')
[2024-07-24 10:31:15,299][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 8699],
        [19282],
        [12958],
        [12473],
        [ 5112],
        [42251],
        [22860],
        [29626],
        [19855],
        [ 7907],
        [14388],
        [16152],
        [31310],
        [29830],
        [27794]], device='cuda:0')
[2024-07-24 10:31:15,301][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[46385],
        [45920],
        [26850],
        [26457],
        [26648],
        [40552],
        [40160],
        [29564],
        [34525],
        [25513],
        [30345],
        [39737],
        [34527],
        [38943],
        [33274]], device='cuda:0')
[2024-07-24 10:31:15,302][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[2580],
        [3861],
        [4801],
        [4759],
        [5075],
        [5176],
        [5296],
        [5623],
        [5616],
        [5742],
        [5931],
        [6160],
        [6229],
        [6414],
        [6506]], device='cuda:0')
[2024-07-24 10:31:15,303][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[5054],
        [5091],
        [6013],
        [5993],
        [6085],
        [6122],
        [6038],
        [6049],
        [5833],
        [5625],
        [5448],
        [5547],
        [5768],
        [5728],
        [5573]], device='cuda:0')
[2024-07-24 10:31:15,304][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[25490],
        [25488],
        [25500],
        [25501],
        [25509],
        [25507],
        [25512],
        [25497],
        [25499],
        [25500],
        [25494],
        [25496],
        [25496],
        [25498],
        [25496]], device='cuda:0')
[2024-07-24 10:31:15,305][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[11327],
        [12387],
        [13092],
        [13367],
        [13430],
        [13983],
        [14294],
        [14315],
        [14283],
        [14494],
        [14826],
        [15027],
        [15063],
        [15193],
        [15432]], device='cuda:0')
[2024-07-24 10:31:15,306][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[46955],
        [46340],
        [46359],
        [47012],
        [46938],
        [46948],
        [46357],
        [46435],
        [46219],
        [46382],
        [46622],
        [46783],
        [46593],
        [46837],
        [46865]], device='cuda:0')
[2024-07-24 10:31:15,307][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[30164],
        [29552],
        [31192],
        [33534],
        [32558],
        [35856],
        [35036],
        [31795],
        [31836],
        [30231],
        [32134],
        [34209],
        [31242],
        [30622],
        [30794]], device='cuda:0')
[2024-07-24 10:31:15,308][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[34216],
        [29850],
        [41678],
        [42057],
        [45490],
        [44450],
        [47348],
        [47499],
        [47169],
        [45858],
        [46082],
        [47512],
        [47292],
        [44210],
        [46365]], device='cuda:0')
[2024-07-24 10:31:15,310][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[ 6437],
        [ 9529],
        [10557],
        [10113],
        [15025],
        [18071],
        [18265],
        [20367],
        [16842],
        [15104],
        [14595],
        [13998],
        [13419],
        [13468],
        [13065]], device='cuda:0')
[2024-07-24 10:31:15,311][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[44842],
        [44842],
        [44840],
        [45136],
        [44982],
        [45027],
        [33133],
        [35325],
        [34340],
        [36744],
        [36445],
        [34520],
        [34096],
        [36429],
        [35943]], device='cuda:0')
[2024-07-24 10:31:15,313][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[ 9061],
        [10362],
        [ 8591],
        [ 9260],
        [ 9308],
        [ 9574],
        [ 9242],
        [ 9464],
        [ 9502],
        [ 9450],
        [ 9485],
        [ 9095],
        [ 8752],
        [ 8902],
        [ 8867]], device='cuda:0')
[2024-07-24 10:31:15,314][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[14013],
        [18402],
        [18296],
        [14835],
        [15059],
        [14893],
        [12954],
        [14426],
        [14761],
        [16205],
        [15873],
        [16168],
        [16396],
        [15865],
        [15304]], device='cuda:0')
[2024-07-24 10:31:15,315][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[17319],
        [15757],
        [18138],
        [17876],
        [15865],
        [11406],
        [13764],
        [15484],
        [16299],
        [18399],
        [18048],
        [14091],
        [17132],
        [17989],
        [17796]], device='cuda:0')
[2024-07-24 10:31:15,316][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[26979],
        [ 7284],
        [ 7786],
        [18572],
        [19507],
        [ 3200],
        [10935],
        [ 9414],
        [12618],
        [30046],
        [17245],
        [20528],
        [ 2802],
        [ 9831],
        [ 8108]], device='cuda:0')
[2024-07-24 10:31:15,318][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[34123],
        [34123],
        [34123],
        [34123],
        [34123],
        [34123],
        [34123],
        [34123],
        [34123],
        [34123],
        [34123],
        [34123],
        [34123],
        [34123],
        [34123]], device='cuda:0')
[2024-07-24 10:31:15,334][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:31:15,335][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:15,335][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:15,336][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:15,336][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:15,336][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:15,337][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:15,337][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:15,337][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:15,338][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:15,338][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:15,338][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:15,339][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:15,339][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.3560, 0.6440], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:15,339][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.9922, 0.0078], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:15,341][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.9792, 0.0208], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:15,342][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.8947, 0.1053], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:15,344][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0670, 0.9330], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:15,345][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.1160, 0.8840], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:15,346][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.5229, 0.4771], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:15,347][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.6002, 0.3998], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:15,349][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.9041, 0.0959], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:15,350][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0037, 0.9963], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:15,352][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.3799, 0.6201], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:15,353][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.5098, 0.4902], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:15,355][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Melissa] are: tensor([0.1861, 0.3628, 0.4511], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:15,356][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Melissa] are: tensor([0.7456, 0.1013, 0.1531], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:15,357][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Melissa] are: tensor([0.6638, 0.1883, 0.1479], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:15,358][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Melissa] are: tensor([0.8372, 0.0534, 0.1094], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:15,359][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Melissa] are: tensor([4.1366e-04, 1.1975e-01, 8.7984e-01], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:15,361][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Melissa] are: tensor([0.0411, 0.6990, 0.2599], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:15,362][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Melissa] are: tensor([0.3792, 0.3149, 0.3059], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:15,362][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Melissa] are: tensor([0.2607, 0.1625, 0.5768], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:15,362][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Melissa] are: tensor([0.5122, 0.4401, 0.0478], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:15,362][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Melissa] are: tensor([2.4623e-04, 5.9916e-01, 4.0060e-01], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:15,363][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Melissa] are: tensor([0.2284, 0.3681, 0.4035], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:15,363][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Melissa] are: tensor([0.2634, 0.2872, 0.4495], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:15,363][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.1256, 0.2441, 0.3049, 0.3254], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:15,364][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.7786, 0.0177, 0.1310, 0.0728], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:15,364][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0447, 0.0064, 0.9477, 0.0012], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:15,364][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.8266, 0.0391, 0.1260, 0.0083], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:15,365][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ and] are: tensor([6.8732e-04, 4.0458e-02, 7.3146e-01, 2.2739e-01], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:15,366][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0424, 0.3588, 0.3937, 0.2052], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:15,367][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.3123, 0.2347, 0.2389, 0.2142], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:15,368][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.1550, 0.0967, 0.4601, 0.2882], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:15,369][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.4098, 0.3329, 0.2049, 0.0524], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:15,370][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ and] are: tensor([2.7797e-05, 3.8190e-02, 3.0089e-01, 6.6089e-01], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:15,371][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.1684, 0.2611, 0.2845, 0.2860], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:15,373][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.2049, 0.2087, 0.3816, 0.2048], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:15,374][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Benjamin] are: tensor([0.0908, 0.1779, 0.2285, 0.2452, 0.2576], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:15,376][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Benjamin] are: tensor([0.5654, 0.0986, 0.1051, 0.1110, 0.1199], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:15,377][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Benjamin] are: tensor([0.0637, 0.0218, 0.8677, 0.0407, 0.0061], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:15,378][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Benjamin] are: tensor([0.5039, 0.0466, 0.1780, 0.0169, 0.2546], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:15,379][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Benjamin] are: tensor([6.6393e-05, 9.2424e-03, 1.4391e-01, 1.3050e-01, 7.1628e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:15,381][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Benjamin] are: tensor([0.0207, 0.2864, 0.2565, 0.3357, 0.1007], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:15,382][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Benjamin] are: tensor([0.2436, 0.1936, 0.1957, 0.1733, 0.1938], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:15,383][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Benjamin] are: tensor([0.0880, 0.0764, 0.2663, 0.2644, 0.3049], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:15,385][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Benjamin] are: tensor([0.3187, 0.2707, 0.1474, 0.2506, 0.0125], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:15,386][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Benjamin] are: tensor([3.4807e-06, 9.2283e-03, 7.4351e-02, 4.7785e-01, 4.3857e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:15,387][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Benjamin] are: tensor([0.1227, 0.2006, 0.2167, 0.2158, 0.2442], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:15,388][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Benjamin] are: tensor([0.1531, 0.1419, 0.2836, 0.1606, 0.2607], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:15,388][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.0685, 0.1269, 0.1578, 0.1759, 0.1810, 0.2899], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:15,388][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.7136, 0.0175, 0.0832, 0.0507, 0.0747, 0.0603], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:15,389][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.0340, 0.1476, 0.0520, 0.5519, 0.2123, 0.0022], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:15,389][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.6469, 0.0339, 0.1452, 0.0100, 0.1406, 0.0234], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:15,389][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ had] are: tensor([4.1459e-05, 1.2100e-02, 7.1134e-03, 2.5358e-01, 2.4182e-01, 4.8534e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:15,390][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.0261, 0.2267, 0.2612, 0.2146, 0.1601, 0.1114], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:15,390][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.2195, 0.1760, 0.1568, 0.1481, 0.1539, 0.1457], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:15,390][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.0639, 0.0737, 0.1956, 0.1938, 0.2945, 0.1786], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:15,391][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.1473, 0.4767, 0.2561, 0.0771, 0.0154, 0.0275], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:15,391][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ had] are: tensor([1.4247e-06, 3.2161e-03, 1.8281e-02, 1.1409e-01, 5.9911e-01, 2.6530e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:15,393][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.0935, 0.1532, 0.1644, 0.1639, 0.1854, 0.2395], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:15,394][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.1277, 0.1367, 0.2487, 0.1239, 0.2390, 0.1240], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:15,395][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0645, 0.1070, 0.1268, 0.1421, 0.1420, 0.2135, 0.2042],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:15,397][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.6687, 0.0122, 0.0862, 0.0480, 0.0743, 0.0510, 0.0596],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:15,398][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ a] are: tensor([3.5060e-01, 3.3474e-02, 2.9956e-02, 2.5589e-01, 1.7079e-01, 1.5901e-01,
        2.8546e-04], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:15,399][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.6543, 0.0329, 0.1323, 0.0089, 0.1312, 0.0245, 0.0158],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:15,400][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ a] are: tensor([2.6335e-05, 2.8938e-03, 2.6462e-02, 5.6907e-02, 3.7521e-01, 3.3063e-01,
        2.0787e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:15,401][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0210, 0.1960, 0.1605, 0.1741, 0.1805, 0.2360, 0.0318],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:15,403][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.2023, 0.1508, 0.1375, 0.1266, 0.1341, 0.1291, 0.1196],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:15,404][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0568, 0.0477, 0.1804, 0.1394, 0.2807, 0.1254, 0.1695],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:15,406][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.1013, 0.0912, 0.0868, 0.1419, 0.0295, 0.5438, 0.0055],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:15,406][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ a] are: tensor([1.0856e-06, 1.4148e-03, 1.1036e-02, 4.8169e-02, 2.3341e-01, 3.4969e-01,
        3.5628e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:15,408][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0753, 0.1199, 0.1249, 0.1255, 0.1404, 0.1763, 0.2377],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:15,409][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.1186, 0.1183, 0.2001, 0.1314, 0.2077, 0.1279, 0.0960],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:15,411][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.0521, 0.0880, 0.1031, 0.1156, 0.1165, 0.1782, 0.1777, 0.1688],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:15,412][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ long] are: tensor([0.4797, 0.0362, 0.0753, 0.0654, 0.0783, 0.0751, 0.0898, 0.1003],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:15,414][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.0575, 0.0083, 0.1545, 0.0302, 0.1354, 0.3835, 0.2234, 0.0071],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:15,414][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ long] are: tensor([0.4660, 0.0338, 0.1186, 0.0120, 0.1462, 0.0364, 0.0254, 0.1616],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:15,414][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ long] are: tensor([7.8077e-06, 3.7263e-04, 6.2135e-03, 1.4786e-02, 3.0208e-02, 2.0816e-01,
        1.7649e-01, 5.6376e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:15,415][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ long] are: tensor([0.0160, 0.1762, 0.1864, 0.1898, 0.1115, 0.1676, 0.0838, 0.0687],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:15,415][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.1559, 0.1311, 0.1213, 0.1152, 0.1163, 0.1195, 0.1137, 0.1271],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:15,416][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.0511, 0.0685, 0.1545, 0.1528, 0.1992, 0.1073, 0.1389, 0.1276],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:15,416][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.0673, 0.1808, 0.0996, 0.0712, 0.0115, 0.5095, 0.0535, 0.0066],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:15,416][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ long] are: tensor([1.7610e-07, 1.2099e-04, 9.3781e-04, 5.8806e-03, 2.7270e-02, 6.2934e-02,
        1.4915e-01, 7.5371e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:15,417][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.0580, 0.0959, 0.0992, 0.0986, 0.1115, 0.1412, 0.1934, 0.2021],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:15,417][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ long] are: tensor([0.0988, 0.1040, 0.1710, 0.1091, 0.1776, 0.1089, 0.0827, 0.1478],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:15,417][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.0435, 0.0733, 0.0866, 0.0965, 0.0965, 0.1545, 0.1506, 0.1448, 0.1536],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:15,419][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([0.3263, 0.0553, 0.0597, 0.0647, 0.0686, 0.0822, 0.0984, 0.1077, 0.1370],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:15,420][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.0383, 0.0392, 0.2137, 0.0525, 0.1125, 0.3178, 0.0698, 0.1546, 0.0015],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:15,421][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([0.2396, 0.0159, 0.0567, 0.0063, 0.0953, 0.0219, 0.0171, 0.1336, 0.4137],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:15,422][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([8.5581e-07, 1.4839e-04, 1.5472e-03, 3.7198e-03, 1.4994e-02, 3.6917e-02,
        3.4744e-02, 7.3756e-01, 1.7037e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:15,424][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([0.0119, 0.1718, 0.1492, 0.1755, 0.0803, 0.1444, 0.0601, 0.0982, 0.1085],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:15,424][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.1427, 0.1129, 0.1069, 0.0975, 0.1069, 0.1021, 0.0990, 0.1309, 0.1010],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:15,426][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.0471, 0.0551, 0.1227, 0.1392, 0.1646, 0.1095, 0.1423, 0.1178, 0.1016],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:15,427][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.0463, 0.1358, 0.0620, 0.0836, 0.0801, 0.4628, 0.1084, 0.0186, 0.0024],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:15,428][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([3.8948e-08, 6.0311e-05, 3.6938e-04, 2.2869e-03, 1.2184e-02, 1.7941e-02,
        3.4486e-02, 7.2140e-01, 2.1127e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:15,429][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.0497, 0.0797, 0.0818, 0.0818, 0.0920, 0.1155, 0.1570, 0.1633, 0.1792],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:15,431][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([0.0795, 0.0811, 0.1486, 0.0858, 0.1482, 0.0918, 0.0716, 0.1438, 0.1497],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:15,432][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0344, 0.0627, 0.0717, 0.0795, 0.0784, 0.1308, 0.1335, 0.1310, 0.1392,
        0.1387], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:15,434][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.3990, 0.0123, 0.0725, 0.0436, 0.0638, 0.0451, 0.0551, 0.0616, 0.1471,
        0.0999], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:15,435][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [,] are: tensor([4.3858e-02, 4.2250e-04, 2.5961e-01, 5.1709e-02, 1.0394e-01, 1.4099e-01,
        5.9209e-02, 2.8066e-01, 5.9485e-02, 1.2192e-04], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:15,436][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.3860, 0.0166, 0.0647, 0.0049, 0.0703, 0.0154, 0.0100, 0.0766, 0.2849,
        0.0707], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:15,437][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [,] are: tensor([5.4799e-06, 4.9540e-05, 2.9873e-03, 2.5843e-03, 4.8890e-02, 1.1454e-02,
        3.3184e-02, 1.2510e-01, 4.1442e-01, 3.6132e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:15,438][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0137, 0.0959, 0.1054, 0.1382, 0.0843, 0.1303, 0.0463, 0.1059, 0.1769,
        0.1031], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:15,440][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.1413, 0.1091, 0.0929, 0.0836, 0.0887, 0.0922, 0.0848, 0.1182, 0.0898,
        0.0996], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:15,440][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0429, 0.0308, 0.1214, 0.0907, 0.1740, 0.0963, 0.1115, 0.1011, 0.1071,
        0.1241], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:15,441][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.1847, 0.0202, 0.0355, 0.0803, 0.0092, 0.4261, 0.0901, 0.0456, 0.0966,
        0.0117], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:15,441][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [,] are: tensor([2.8398e-08, 4.1270e-06, 1.0315e-04, 5.1553e-04, 3.8380e-03, 4.2952e-03,
        1.7865e-02, 1.0174e-01, 2.7012e-01, 6.0152e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:15,442][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0430, 0.0687, 0.0698, 0.0704, 0.0788, 0.0991, 0.1371, 0.1431, 0.1581,
        0.1318], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:15,442][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0761, 0.0755, 0.1431, 0.0855, 0.1314, 0.0820, 0.0650, 0.1172, 0.1360,
        0.0882], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:15,442][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0323, 0.0565, 0.0641, 0.0705, 0.0701, 0.1135, 0.1147, 0.1127, 0.1214,
        0.1218, 0.1223], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:15,443][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.3860, 0.0079, 0.0700, 0.0372, 0.0578, 0.0384, 0.0460, 0.0495, 0.1379,
        0.0860, 0.0833], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:15,443][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ and] are: tensor([2.5386e-02, 3.9206e-03, 6.9015e-01, 6.9522e-04, 1.2123e-01, 2.6034e-02,
        3.2912e-02, 8.2391e-02, 1.6032e-02, 1.0006e-03, 2.5238e-04],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:15,443][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.4549, 0.0179, 0.0470, 0.0042, 0.0563, 0.0137, 0.0092, 0.0635, 0.2166,
        0.0641, 0.0526], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:15,444][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ and] are: tensor([6.6141e-06, 4.4321e-05, 5.3480e-04, 2.5980e-04, 2.3106e-03, 1.1578e-03,
        7.5556e-03, 7.8573e-03, 1.9412e-02, 3.3153e-01, 6.2933e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:15,445][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0126, 0.1013, 0.1096, 0.0539, 0.1005, 0.1304, 0.0437, 0.1028, 0.1913,
        0.1145, 0.0395], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:15,447][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.1226, 0.0920, 0.0834, 0.0750, 0.0822, 0.0817, 0.0768, 0.1125, 0.0828,
        0.0934, 0.0977], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:15,448][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0382, 0.0254, 0.1166, 0.0749, 0.1627, 0.0862, 0.0983, 0.0809, 0.0967,
        0.1058, 0.1143], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:15,450][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.1055, 0.0972, 0.0652, 0.0144, 0.0089, 0.3961, 0.1023, 0.0760, 0.0561,
        0.0702, 0.0083], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:15,450][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ and] are: tensor([1.1243e-08, 1.7272e-06, 1.8998e-05, 3.3635e-05, 7.6163e-04, 1.0285e-03,
        3.0241e-03, 2.0819e-02, 4.9125e-02, 2.5803e-01, 6.6715e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:15,452][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0389, 0.0609, 0.0613, 0.0623, 0.0692, 0.0863, 0.1195, 0.1248, 0.1385,
        0.1164, 0.1218], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:15,453][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0694, 0.0740, 0.1335, 0.0729, 0.1280, 0.0799, 0.0621, 0.1048, 0.1278,
        0.0841, 0.0635], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:15,455][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.0287, 0.0491, 0.0593, 0.0659, 0.0654, 0.1022, 0.1019, 0.0989, 0.1073,
        0.1107, 0.1117, 0.0988], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:15,456][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([0.3052, 0.0288, 0.0485, 0.0474, 0.0487, 0.0509, 0.0634, 0.0684, 0.0984,
        0.0966, 0.0726, 0.0711], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:15,457][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.0336, 0.0465, 0.0437, 0.3373, 0.0321, 0.0900, 0.1071, 0.0221, 0.0528,
        0.0152, 0.2164, 0.0032], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:15,459][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([0.2039, 0.0113, 0.0186, 0.0035, 0.0292, 0.0092, 0.0068, 0.0481, 0.1201,
        0.0528, 0.0463, 0.4501], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:15,460][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([3.5105e-07, 6.1331e-06, 1.0703e-05, 1.6098e-04, 3.5430e-04, 8.2891e-04,
        9.9574e-04, 1.3347e-01, 3.0511e-03, 5.5813e-02, 3.8885e-01, 4.1646e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:15,461][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([0.0089, 0.0908, 0.1005, 0.0974, 0.0745, 0.1103, 0.0378, 0.0695, 0.1559,
        0.1061, 0.0812, 0.0671], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:15,463][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.1073, 0.0812, 0.0811, 0.0711, 0.0803, 0.0776, 0.0738, 0.0988, 0.0773,
        0.0740, 0.0804, 0.0971], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:15,464][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.0305, 0.0358, 0.0820, 0.0831, 0.1008, 0.0756, 0.0815, 0.0766, 0.0641,
        0.1489, 0.1246, 0.0966], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:15,466][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.0364, 0.0887, 0.0046, 0.0813, 0.0036, 0.5204, 0.0194, 0.0514, 0.0881,
        0.0502, 0.0538, 0.0020], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:15,466][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([2.7892e-09, 9.0901e-07, 6.7824e-06, 2.5040e-05, 1.7855e-04, 2.4456e-04,
        8.2558e-04, 6.4730e-03, 1.3611e-02, 9.5749e-02, 4.7162e-01, 4.1127e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:15,467][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.0326, 0.0552, 0.0545, 0.0544, 0.0616, 0.0784, 0.1106, 0.1172, 0.1267,
        0.1056, 0.1089, 0.0943], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:15,467][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([0.0564, 0.0613, 0.1148, 0.0595, 0.1121, 0.0689, 0.0500, 0.1018, 0.1129,
        0.0735, 0.0534, 0.1353], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:15,468][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Melissa] are: tensor([0.0243, 0.0431, 0.0514, 0.0573, 0.0580, 0.0929, 0.0928, 0.0904, 0.0980,
        0.0991, 0.0998, 0.0903, 0.1025], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:15,468][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Melissa] are: tensor([0.2546, 0.0390, 0.0469, 0.0450, 0.0496, 0.0522, 0.0598, 0.0740, 0.0971,
        0.0913, 0.0584, 0.0742, 0.0580], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:15,469][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Melissa] are: tensor([0.0875, 0.0253, 0.0147, 0.0351, 0.0721, 0.2519, 0.0364, 0.0799, 0.0457,
        0.0054, 0.0150, 0.3239, 0.0072], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:15,469][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Melissa] are: tensor([0.1454, 0.0044, 0.0044, 0.0011, 0.0097, 0.0030, 0.0023, 0.0194, 0.0458,
        0.0232, 0.0198, 0.2506, 0.4709], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:15,469][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Melissa] are: tensor([9.9142e-08, 2.0990e-06, 1.1632e-05, 4.0988e-05, 1.5202e-03, 7.4183e-05,
        5.7129e-04, 7.2366e-04, 3.8744e-03, 1.9148e-02, 1.2843e-01, 1.1877e-01,
        7.2683e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:15,470][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Melissa] are: tensor([0.0043, 0.0886, 0.0303, 0.0933, 0.0510, 0.0926, 0.0416, 0.0788, 0.1699,
        0.1056, 0.0824, 0.1253, 0.0362], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:15,470][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Melissa] are: tensor([0.0894, 0.0683, 0.0736, 0.0667, 0.0773, 0.0692, 0.0739, 0.0999, 0.0755,
        0.0732, 0.0771, 0.0931, 0.0629], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:15,471][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Melissa] are: tensor([0.0320, 0.0234, 0.0696, 0.0716, 0.1013, 0.0655, 0.0811, 0.0626, 0.0599,
        0.1089, 0.1082, 0.1107, 0.1054], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:15,473][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Melissa] are: tensor([0.0467, 0.0386, 0.0039, 0.0509, 0.0349, 0.5694, 0.0309, 0.0496, 0.0492,
        0.0231, 0.0316, 0.0682, 0.0031], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:15,474][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Melissa] are: tensor([2.0780e-09, 2.3683e-07, 2.7343e-07, 7.9960e-06, 7.1267e-05, 1.1176e-04,
        2.9764e-04, 2.5758e-03, 2.5556e-03, 2.5711e-02, 1.6249e-01, 5.6915e-01,
        2.3703e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:15,475][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Melissa] are: tensor([0.0321, 0.0503, 0.0505, 0.0513, 0.0569, 0.0706, 0.0965, 0.1011, 0.1112,
        0.0936, 0.0979, 0.0840, 0.1040], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:15,477][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Melissa] are: tensor([0.0513, 0.0574, 0.0912, 0.0598, 0.0957, 0.0674, 0.0453, 0.0869, 0.1055,
        0.0701, 0.0533, 0.1221, 0.0940], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:15,478][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.0204, 0.0369, 0.0451, 0.0503, 0.0510, 0.0815, 0.0827, 0.0822, 0.0899,
        0.0907, 0.0933, 0.0817, 0.0942, 0.1001], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:15,479][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ said] are: tensor([0.2716, 0.0135, 0.0483, 0.0357, 0.0456, 0.0421, 0.0486, 0.0507, 0.0983,
        0.0778, 0.0661, 0.0596, 0.0659, 0.0762], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:15,481][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.0220, 0.0319, 0.0168, 0.1668, 0.0443, 0.4485, 0.0089, 0.0429, 0.0092,
        0.0088, 0.1519, 0.0361, 0.0113, 0.0008], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:15,482][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ said] are: tensor([0.1060, 0.0037, 0.0079, 0.0009, 0.0094, 0.0021, 0.0016, 0.0140, 0.0401,
        0.0152, 0.0142, 0.1752, 0.5153, 0.0942], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:15,483][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ said] are: tensor([1.6978e-07, 2.5265e-06, 2.7029e-06, 4.2118e-05, 2.8002e-05, 1.5730e-04,
        3.5118e-04, 7.9817e-04, 1.4135e-03, 2.1203e-02, 1.3953e-01, 4.6443e-01,
        6.3915e-02, 3.0813e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:15,485][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ said] are: tensor([0.0077, 0.0891, 0.0741, 0.0893, 0.0572, 0.0656, 0.0350, 0.0792, 0.0906,
        0.1158, 0.0884, 0.0937, 0.0876, 0.0268], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:15,486][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.0894, 0.0737, 0.0684, 0.0646, 0.0676, 0.0688, 0.0675, 0.0833, 0.0632,
        0.0709, 0.0746, 0.0748, 0.0572, 0.0759], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:15,488][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.0238, 0.0239, 0.0714, 0.0617, 0.1002, 0.0585, 0.0701, 0.0632, 0.0571,
        0.1070, 0.0966, 0.1048, 0.1072, 0.0545], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:15,489][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.0416, 0.3044, 0.1045, 0.0579, 0.0476, 0.0525, 0.0141, 0.0414, 0.0242,
        0.1332, 0.0387, 0.0473, 0.0798, 0.0128], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:15,490][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ said] are: tensor([8.5248e-10, 1.0443e-07, 6.0939e-07, 3.9355e-06, 2.0915e-05, 1.4309e-05,
        6.7911e-05, 3.9818e-04, 1.4755e-03, 1.9576e-02, 9.3344e-02, 1.4242e-01,
        5.5863e-01, 1.8404e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:15,491][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.0278, 0.0454, 0.0462, 0.0459, 0.0521, 0.0649, 0.0886, 0.0940, 0.1025,
        0.0854, 0.0886, 0.0768, 0.0955, 0.0863], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:15,493][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ said] are: tensor([0.0480, 0.0503, 0.0996, 0.0466, 0.0947, 0.0544, 0.0437, 0.0880, 0.0946,
        0.0603, 0.0435, 0.1201, 0.1030, 0.0532], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:15,493][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0202, 0.0346, 0.0418, 0.0470, 0.0468, 0.0746, 0.0734, 0.0734, 0.0796,
        0.0804, 0.0824, 0.0726, 0.0842, 0.0903, 0.0986], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:15,494][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.2592, 0.0092, 0.0497, 0.0314, 0.0431, 0.0336, 0.0387, 0.0416, 0.0935,
        0.0665, 0.0610, 0.0559, 0.0702, 0.0660, 0.0803], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:15,494][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ to] are: tensor([6.6883e-02, 8.7998e-03, 2.1317e-02, 4.3246e-02, 2.0118e-02, 1.4825e-01,
        3.6398e-02, 4.1537e-01, 6.9602e-02, 3.0737e-03, 3.2095e-02, 1.0603e-01,
        1.5475e-02, 1.3344e-02, 8.6420e-06], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:15,495][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.1850, 0.0032, 0.0063, 0.0007, 0.0085, 0.0020, 0.0014, 0.0126, 0.0343,
        0.0138, 0.0115, 0.1717, 0.4044, 0.1290, 0.0158], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:15,495][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ to] are: tensor([4.3310e-08, 3.5142e-07, 1.2688e-06, 3.3087e-06, 1.5305e-05, 8.0055e-05,
        2.8092e-05, 3.7911e-04, 1.8905e-03, 1.9741e-03, 1.0260e-02, 3.6961e-02,
        3.4418e-02, 7.0619e-01, 2.0780e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:15,495][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0072, 0.0615, 0.0803, 0.0853, 0.0563, 0.1007, 0.0273, 0.0588, 0.1007,
        0.0800, 0.0812, 0.0809, 0.1057, 0.0473, 0.0266], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:15,496][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0835, 0.0641, 0.0619, 0.0550, 0.0615, 0.0588, 0.0578, 0.0797, 0.0618,
        0.0632, 0.0691, 0.0706, 0.0571, 0.0715, 0.0844], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:15,496][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0241, 0.0181, 0.0597, 0.0517, 0.0967, 0.0570, 0.0636, 0.0537, 0.0506,
        0.0818, 0.0773, 0.1176, 0.0879, 0.0668, 0.0935], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:15,497][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ to] are: tensor([7.0437e-03, 1.5665e-02, 1.6790e-03, 1.1383e-02, 3.8129e-03, 1.2195e-01,
        5.0882e-03, 1.4727e-03, 6.8254e-03, 8.0286e-03, 9.0386e-03, 5.7569e-03,
        1.2782e-03, 8.0093e-01, 5.6508e-05], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:15,497][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ to] are: tensor([3.5260e-10, 2.0619e-08, 1.7355e-07, 4.8159e-07, 2.8016e-06, 2.3075e-06,
        1.1843e-05, 1.1359e-04, 2.3564e-04, 2.3455e-03, 1.0470e-02, 4.0989e-02,
        1.3014e-01, 1.8299e-01, 6.3269e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:15,499][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0266, 0.0418, 0.0424, 0.0428, 0.0478, 0.0592, 0.0812, 0.0852, 0.0943,
        0.0791, 0.0826, 0.0713, 0.0887, 0.0802, 0.0768], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:15,500][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0463, 0.0520, 0.0902, 0.0554, 0.0874, 0.0563, 0.0430, 0.0767, 0.0863,
        0.0619, 0.0492, 0.1005, 0.0921, 0.0577, 0.0451], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:15,523][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:31:15,524][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:15,525][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:15,525][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:15,526][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:15,527][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:15,527][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:15,528][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:15,529][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:15,530][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:15,530][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:15,531][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:15,532][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:15,533][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.4549, 0.5451], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:15,534][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.7789, 0.2211], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:15,536][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0030, 0.9970], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:15,537][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0677, 0.9323], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:15,539][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0670, 0.9330], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:15,540][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0236, 0.9764], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:15,542][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.6793, 0.3207], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:15,544][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.2481, 0.7519], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:15,545][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.1159, 0.8841], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:15,547][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0037, 0.9963], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:15,549][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.2425, 0.7575], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:15,550][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.5231, 0.4769], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:15,552][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Melissa] are: tensor([0.0904, 0.3679, 0.5418], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:15,553][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Melissa] are: tensor([0.2544, 0.5594, 0.1863], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:15,554][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Melissa] are: tensor([7.6150e-06, 2.0414e-01, 7.9585e-01], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:15,556][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Melissa] are: tensor([0.0026, 0.2872, 0.7102], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:15,557][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Melissa] are: tensor([4.1366e-04, 1.1975e-01, 8.7984e-01], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:15,558][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Melissa] are: tensor([0.0014, 0.5689, 0.4297], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:15,558][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Melissa] are: tensor([0.0955, 0.1699, 0.7346], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:15,559][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Melissa] are: tensor([0.0172, 0.0733, 0.9095], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:15,561][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Melissa] are: tensor([0.0035, 0.3469, 0.6497], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:15,562][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Melissa] are: tensor([2.4623e-04, 5.9916e-01, 4.0060e-01], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:15,563][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Melissa] are: tensor([0.0934, 0.4446, 0.4621], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:15,565][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Melissa] are: tensor([0.2814, 0.2938, 0.4247], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:15,566][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0441, 0.1516, 0.3004, 0.5039], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:15,568][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.4059, 0.2215, 0.1812, 0.1913], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:15,569][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([1.1533e-06, 5.5828e-03, 5.2958e-01, 4.6484e-01], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:15,570][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0007, 0.0445, 0.4757, 0.4791], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:15,572][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([6.8732e-04, 4.0458e-02, 7.3146e-01, 2.2739e-01], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:15,573][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([4.0625e-04, 6.6215e-02, 2.0973e-01, 7.2365e-01], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:15,574][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0678, 0.0745, 0.3814, 0.4762], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:15,576][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0033, 0.0055, 0.1062, 0.8851], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:15,578][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0027, 0.1112, 0.3082, 0.5778], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:15,579][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([2.7797e-05, 3.8190e-02, 3.0089e-01, 6.6089e-01], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:15,580][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0502, 0.2481, 0.2894, 0.4123], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:15,582][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.2174, 0.2097, 0.3566, 0.2162], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:15,584][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Benjamin] are: tensor([0.0143, 0.0630, 0.2625, 0.4488, 0.2114], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:15,584][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Benjamin] are: tensor([0.1629, 0.4048, 0.1129, 0.2483, 0.0711], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:15,585][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Benjamin] are: tensor([5.3772e-08, 3.6394e-04, 4.6007e-02, 1.6528e-01, 7.8835e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:15,586][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Benjamin] are: tensor([5.6994e-05, 7.0314e-03, 5.8690e-02, 2.1772e-01, 7.1651e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:15,587][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Benjamin] are: tensor([6.6393e-05, 9.2424e-03, 1.4391e-01, 1.3050e-01, 7.1628e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:15,587][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Benjamin] are: tensor([2.2842e-05, 9.9726e-03, 5.1898e-02, 4.5640e-01, 4.8171e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:15,589][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Benjamin] are: tensor([0.0276, 0.0626, 0.1428, 0.3405, 0.4266], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:15,591][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Benjamin] are: tensor([0.0015, 0.0042, 0.0577, 0.5517, 0.3849], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:15,592][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Benjamin] are: tensor([2.9695e-04, 1.9940e-02, 7.3203e-02, 3.3460e-01, 5.7196e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:15,593][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Benjamin] are: tensor([3.4807e-06, 9.2283e-03, 7.4351e-02, 4.7785e-01, 4.3857e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:15,594][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Benjamin] are: tensor([0.0257, 0.1395, 0.1555, 0.3377, 0.3416], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:15,596][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Benjamin] are: tensor([0.1663, 0.1414, 0.2795, 0.1702, 0.2426], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:15,597][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.0077, 0.0434, 0.0685, 0.2959, 0.2959, 0.2886], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:15,599][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.2167, 0.2264, 0.1468, 0.1725, 0.0746, 0.1630], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:15,600][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([6.8276e-09, 7.1505e-05, 1.6114e-03, 5.1625e-02, 8.6510e-01, 8.1597e-02],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:15,601][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([6.9770e-05, 7.6451e-03, 5.2225e-02, 1.4438e-01, 6.4990e-01, 1.4578e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:15,603][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([4.1459e-05, 1.2100e-02, 7.1134e-03, 2.5358e-01, 2.4182e-01, 4.8534e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:15,604][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([1.6242e-05, 4.4568e-03, 2.5885e-02, 1.5099e-01, 6.1569e-01, 2.0296e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:15,605][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.0204, 0.0400, 0.1383, 0.2304, 0.3701, 0.2008], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:15,607][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.0006, 0.0021, 0.0301, 0.2807, 0.2139, 0.4726], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:15,608][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([1.9122e-04, 1.9651e-02, 6.0808e-02, 2.2999e-01, 3.1659e-01, 3.7277e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:15,609][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([1.4247e-06, 3.2161e-03, 1.8281e-02, 1.1409e-01, 5.9911e-01, 2.6530e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:15,611][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.0198, 0.1113, 0.1192, 0.2294, 0.2307, 0.2896], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:15,612][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.1386, 0.1392, 0.2441, 0.1307, 0.2304, 0.1170], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:15,613][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0087, 0.0355, 0.0558, 0.1852, 0.2211, 0.2510, 0.2427],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:15,614][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.2705, 0.1733, 0.0947, 0.1472, 0.0702, 0.1428, 0.1012],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:15,614][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([7.8341e-09, 1.8808e-05, 6.8766e-04, 2.5321e-02, 2.7965e-01, 5.1173e-01,
        1.8260e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:15,615][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([5.8357e-05, 3.1457e-03, 3.6738e-02, 8.3412e-02, 4.0838e-01, 1.6091e-01,
        3.0736e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:15,617][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([2.6335e-05, 2.8938e-03, 2.6462e-02, 5.6907e-02, 3.7521e-01, 3.3063e-01,
        2.0787e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:15,618][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([1.7757e-05, 2.1526e-03, 8.6125e-03, 8.0903e-02, 2.7918e-01, 3.1966e-01,
        3.0947e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:15,619][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0140, 0.0209, 0.0888, 0.1390, 0.2572, 0.1379, 0.3422],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:15,621][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([4.2181e-04, 8.4196e-04, 1.2692e-02, 1.2671e-01, 8.6511e-02, 1.8260e-01,
        5.9022e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:15,622][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([6.2988e-05, 3.0144e-03, 1.4028e-02, 6.8746e-02, 1.7851e-01, 5.7788e-01,
        1.5776e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:15,623][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([1.0856e-06, 1.4148e-03, 1.1036e-02, 4.8169e-02, 2.3341e-01, 3.4969e-01,
        3.5628e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:15,625][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0175, 0.0833, 0.0933, 0.1711, 0.1609, 0.1851, 0.2889],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:15,626][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.1294, 0.1202, 0.1927, 0.1410, 0.1964, 0.1245, 0.0958],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:15,628][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.0051, 0.0211, 0.0291, 0.0941, 0.0953, 0.1032, 0.2252, 0.4268],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:15,630][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([0.2992, 0.2333, 0.0478, 0.1344, 0.0299, 0.0887, 0.0798, 0.0869],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:15,631][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([7.6642e-10, 6.5564e-07, 4.6231e-05, 4.1044e-04, 9.0373e-03, 3.1604e-02,
        1.5290e-01, 8.0600e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:15,632][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([5.2505e-06, 3.0985e-04, 3.9708e-03, 1.1784e-02, 8.5843e-02, 3.5040e-02,
        3.8740e-01, 4.7564e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:15,633][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([7.8077e-06, 3.7263e-04, 6.2135e-03, 1.4786e-02, 3.0208e-02, 2.0816e-01,
        1.7649e-01, 5.6376e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:15,634][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([1.8694e-06, 3.0459e-04, 1.0873e-03, 1.4971e-02, 7.1688e-02, 9.4474e-02,
        2.4180e-01, 5.7568e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:15,636][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.0111, 0.0167, 0.0369, 0.0811, 0.1058, 0.0980, 0.2257, 0.4247],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:15,637][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([2.5367e-04, 6.3991e-04, 8.1841e-03, 8.7443e-02, 5.2637e-02, 1.1580e-01,
        3.4319e-01, 3.9186e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:15,638][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([2.5631e-05, 1.0056e-03, 5.0230e-03, 1.2939e-02, 3.4584e-02, 1.3394e-01,
        1.6143e-01, 6.5105e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:15,640][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([1.7610e-07, 1.2099e-04, 9.3781e-04, 5.8806e-03, 2.7270e-02, 6.2934e-02,
        1.4915e-01, 7.5371e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:15,641][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.0087, 0.0493, 0.0502, 0.1054, 0.0967, 0.1144, 0.1713, 0.4039],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:15,643][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([0.1122, 0.1100, 0.1657, 0.1178, 0.1707, 0.1099, 0.0836, 0.1301],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:15,645][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.0036, 0.0120, 0.0254, 0.0622, 0.0515, 0.0870, 0.1396, 0.5119, 0.1068],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:15,646][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([0.1291, 0.1432, 0.1090, 0.0703, 0.0539, 0.1833, 0.0645, 0.1933, 0.0534],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:15,646][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([8.6359e-11, 1.1781e-07, 5.8413e-06, 7.9827e-05, 1.3634e-03, 2.2485e-03,
        1.4466e-02, 5.6195e-01, 4.1988e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:15,647][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([3.6980e-06, 2.5981e-04, 2.1666e-03, 7.6644e-03, 4.0132e-02, 3.4957e-02,
        1.3224e-01, 5.0956e-01, 2.7301e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:15,648][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([8.5581e-07, 1.4839e-04, 1.5472e-03, 3.7198e-03, 1.4994e-02, 3.6917e-02,
        3.4744e-02, 7.3756e-01, 1.7037e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:15,649][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([1.2272e-06, 1.3756e-04, 8.2361e-04, 5.4094e-03, 1.0423e-02, 2.0334e-02,
        7.2031e-02, 5.0244e-01, 3.8840e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:15,651][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.0086, 0.0087, 0.0342, 0.0512, 0.0906, 0.0518, 0.1676, 0.3454, 0.2418],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:15,652][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([1.7721e-04, 5.0631e-04, 5.7983e-03, 6.5348e-02, 3.6990e-02, 7.9258e-02,
        2.4298e-01, 2.6053e-01, 3.0841e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:15,653][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([1.3164e-05, 5.9413e-04, 1.8062e-03, 1.0265e-02, 5.0425e-02, 1.3999e-01,
        1.1016e-01, 4.7511e-01, 2.1164e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:15,654][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([3.8948e-08, 6.0311e-05, 3.6938e-04, 2.2869e-03, 1.2184e-02, 1.7941e-02,
        3.4486e-02, 7.2140e-01, 2.1127e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:15,656][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.0077, 0.0376, 0.0338, 0.0909, 0.0660, 0.0800, 0.1536, 0.2561, 0.2743],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:15,658][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([0.0883, 0.0831, 0.1450, 0.0929, 0.1427, 0.0928, 0.0739, 0.1338, 0.1474],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:15,660][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0041, 0.0040, 0.0170, 0.0573, 0.0603, 0.0856, 0.1154, 0.2056, 0.1664,
        0.2844], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:15,661][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.2286, 0.1053, 0.0554, 0.0999, 0.0577, 0.0998, 0.0669, 0.0980, 0.0453,
        0.1430], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:15,662][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([7.5812e-11, 3.5682e-09, 1.7462e-06, 2.5907e-05, 3.3122e-04, 4.9496e-04,
        2.3529e-03, 1.0343e-01, 1.8294e-01, 7.1041e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:15,664][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([2.9839e-06, 3.2065e-05, 6.6780e-04, 2.0132e-03, 9.2954e-03, 1.0044e-02,
        5.0253e-02, 1.6880e-01, 1.7602e-01, 5.8288e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:15,665][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([5.4799e-06, 4.9540e-05, 2.9873e-03, 2.5843e-03, 4.8890e-02, 1.1454e-02,
        3.3184e-02, 1.2510e-01, 4.1442e-01, 3.6132e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:15,666][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([3.9960e-07, 5.8775e-06, 6.4267e-05, 9.1131e-04, 1.3308e-03, 4.1826e-03,
        1.6357e-02, 6.5874e-02, 1.6664e-01, 7.4463e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:15,668][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0060, 0.0060, 0.0263, 0.0557, 0.0761, 0.0592, 0.1198, 0.2445, 0.1922,
        0.2142], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:15,669][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([8.5541e-05, 1.7218e-04, 2.2658e-03, 2.3741e-02, 1.4584e-02, 3.2228e-02,
        9.0356e-02, 9.8537e-02, 1.2363e-01, 6.1440e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:15,670][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([1.0339e-05, 8.1920e-05, 3.9155e-04, 3.4396e-03, 3.2724e-03, 3.2728e-02,
        4.0681e-02, 1.2766e-01, 2.9567e-01, 4.9607e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:15,671][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([2.8398e-08, 4.1270e-06, 1.0315e-04, 5.1553e-04, 3.8380e-03, 4.2952e-03,
        1.7865e-02, 1.0174e-01, 2.7012e-01, 6.0152e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:15,673][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0064, 0.0306, 0.0300, 0.0611, 0.0495, 0.0634, 0.0853, 0.1662, 0.1740,
        0.3335], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:15,673][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0858, 0.0785, 0.1419, 0.0950, 0.1243, 0.0813, 0.0664, 0.1044, 0.1324,
        0.0900], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:15,674][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0022, 0.0026, 0.0063, 0.0111, 0.0249, 0.0350, 0.0433, 0.0577, 0.0770,
        0.1917, 0.5482], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:15,675][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.1905, 0.0958, 0.0526, 0.1078, 0.0437, 0.0801, 0.0492, 0.0769, 0.0315,
        0.1345, 0.1373], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:15,676][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([2.2825e-11, 9.7130e-10, 1.8301e-07, 1.0046e-07, 1.6277e-05, 1.2012e-05,
        1.0172e-04, 2.4894e-03, 6.9922e-03, 1.6644e-01, 8.2395e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:15,677][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([1.1729e-06, 1.2475e-05, 2.0031e-04, 1.4714e-04, 2.9016e-03, 1.8823e-03,
        1.1702e-02, 3.3988e-02, 4.7760e-02, 2.2836e-01, 6.7305e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:15,679][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([6.6141e-06, 4.4321e-05, 5.3480e-04, 2.5980e-04, 2.3106e-03, 1.1578e-03,
        7.5556e-03, 7.8573e-03, 1.9412e-02, 3.3153e-01, 6.2933e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:15,680][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([1.3867e-07, 1.7838e-06, 1.1045e-05, 2.5299e-05, 3.1732e-04, 6.1067e-04,
        3.5448e-03, 1.0116e-02, 3.5754e-02, 3.6140e-01, 5.8822e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:15,682][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0044, 0.0048, 0.0178, 0.0258, 0.0473, 0.0348, 0.0656, 0.1132, 0.1074,
        0.1255, 0.4534], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:15,683][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([5.3295e-05, 8.7671e-05, 1.0769e-03, 1.0051e-02, 6.2777e-03, 1.3999e-02,
        3.8572e-02, 3.8814e-02, 5.1090e-02, 2.6679e-01, 5.7319e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:15,684][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([6.0211e-06, 4.1409e-05, 9.4498e-05, 2.4346e-04, 6.3737e-04, 8.4449e-03,
        9.7056e-03, 3.1017e-02, 5.3343e-02, 2.7444e-01, 6.2203e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:15,685][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([1.1243e-08, 1.7272e-06, 1.8998e-05, 3.3635e-05, 7.6163e-04, 1.0285e-03,
        3.0241e-03, 2.0819e-02, 4.9125e-02, 2.5803e-01, 6.6715e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:15,687][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0043, 0.0246, 0.0254, 0.0405, 0.0392, 0.0454, 0.0604, 0.1034, 0.1245,
        0.2446, 0.2877], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:15,689][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0778, 0.0782, 0.1316, 0.0795, 0.1225, 0.0805, 0.0637, 0.0908, 0.1252,
        0.0867, 0.0635], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:15,690][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.0009, 0.0014, 0.0023, 0.0104, 0.0099, 0.0127, 0.0156, 0.0360, 0.0516,
        0.1166, 0.4963, 0.2463], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:15,692][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([0.0952, 0.0674, 0.0350, 0.1128, 0.0267, 0.0634, 0.0816, 0.2304, 0.0160,
        0.0881, 0.1624, 0.0210], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:15,693][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([8.4026e-12, 2.1104e-10, 3.2578e-09, 1.2336e-07, 7.1694e-07, 1.4273e-06,
        1.9234e-05, 1.0594e-04, 9.2192e-04, 2.2138e-02, 7.5260e-01, 2.2421e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:15,694][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([3.6510e-07, 7.3272e-06, 6.1881e-05, 1.1233e-04, 8.6033e-04, 7.6797e-04,
        4.0121e-03, 8.0581e-03, 1.4990e-02, 1.1502e-01, 4.5691e-01, 3.9920e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:15,696][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([3.5105e-07, 6.1331e-06, 1.0703e-05, 1.6098e-04, 3.5430e-04, 8.2891e-04,
        9.9574e-04, 1.3347e-01, 3.0511e-03, 5.5813e-02, 3.8885e-01, 4.1646e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:15,697][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([4.4489e-08, 7.9507e-07, 3.9972e-06, 2.9647e-05, 1.5121e-04, 1.7331e-04,
        7.0125e-04, 2.4212e-03, 8.9400e-03, 1.1757e-01, 6.3166e-01, 2.3835e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:15,699][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.0020, 0.0028, 0.0099, 0.0180, 0.0242, 0.0256, 0.0490, 0.0780, 0.0773,
        0.0945, 0.3255, 0.2934], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:15,700][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([5.4558e-05, 1.3916e-04, 1.2248e-03, 1.0135e-02, 6.0360e-03, 1.3224e-02,
        3.4682e-02, 3.8625e-02, 4.5721e-02, 2.3916e-01, 4.4667e-01, 1.6433e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:15,701][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([9.6950e-07, 2.3969e-05, 3.4629e-05, 2.2980e-04, 2.2019e-04, 1.7428e-03,
        2.7862e-03, 9.4206e-03, 1.9171e-02, 1.1991e-01, 5.9045e-01, 2.5602e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:15,702][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([2.7892e-09, 9.0901e-07, 6.7824e-06, 2.5040e-05, 1.7855e-04, 2.4456e-04,
        8.2558e-04, 6.4730e-03, 1.3611e-02, 9.5749e-02, 4.7162e-01, 4.1127e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:15,702][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([0.0025, 0.0164, 0.0152, 0.0284, 0.0265, 0.0331, 0.0455, 0.0822, 0.1020,
        0.2218, 0.2340, 0.1923], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:15,704][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([0.0624, 0.0653, 0.1150, 0.0654, 0.1106, 0.0712, 0.0514, 0.0934, 0.1155,
        0.0751, 0.0521, 0.1228], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:15,705][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Melissa] are: tensor([0.0007, 0.0008, 0.0011, 0.0072, 0.0109, 0.0146, 0.0216, 0.0235, 0.0149,
        0.0781, 0.3779, 0.2350, 0.2137], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:15,707][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Melissa] are: tensor([0.0616, 0.0854, 0.0185, 0.0710, 0.0198, 0.1351, 0.0608, 0.0883, 0.0458,
        0.1285, 0.0953, 0.1601, 0.0300], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:15,708][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Melissa] are: tensor([9.4565e-13, 3.2753e-11, 4.1410e-10, 1.2335e-08, 2.2511e-07, 4.0099e-07,
        1.8191e-06, 3.9335e-05, 1.4166e-04, 2.5084e-03, 7.4012e-02, 2.3652e-01,
        6.8678e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:15,709][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Melissa] are: tensor([9.6476e-08, 1.0140e-06, 3.9456e-06, 2.3314e-05, 1.7301e-04, 1.4379e-04,
        7.2039e-04, 2.8851e-03, 3.4807e-03, 2.9489e-02, 1.3614e-01, 3.5317e-01,
        4.7376e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:15,711][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Melissa] are: tensor([9.9142e-08, 2.0990e-06, 1.1632e-05, 4.0988e-05, 1.5202e-03, 7.4183e-05,
        5.7129e-04, 7.2366e-04, 3.8744e-03, 1.9148e-02, 1.2843e-01, 1.1877e-01,
        7.2683e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:15,712][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Melissa] are: tensor([1.0753e-08, 2.2688e-07, 3.1505e-07, 1.0808e-05, 3.6205e-05, 6.9747e-05,
        3.7911e-04, 1.4556e-03, 5.8429e-03, 3.9820e-02, 2.4322e-01, 4.4914e-01,
        2.6002e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:15,714][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Melissa] are: tensor([0.0014, 0.0025, 0.0051, 0.0127, 0.0148, 0.0193, 0.0275, 0.0446, 0.0463,
        0.0829, 0.2259, 0.2651, 0.2520], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:15,715][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Melissa] are: tensor([3.1514e-05, 1.3838e-04, 1.0149e-03, 9.5490e-03, 5.6783e-03, 1.1917e-02,
        3.1649e-02, 2.9426e-02, 3.4376e-02, 1.7553e-01, 3.8688e-01, 1.4955e-01,
        1.6426e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:15,716][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Melissa] are: tensor([3.7531e-07, 3.5471e-06, 7.8388e-06, 5.6618e-05, 1.7519e-04, 8.6613e-04,
        1.0560e-03, 3.6841e-03, 9.1663e-03, 2.9809e-02, 1.4557e-01, 5.0975e-01,
        2.9985e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:15,717][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Melissa] are: tensor([2.0780e-09, 2.3683e-07, 2.7343e-07, 7.9960e-06, 7.1267e-05, 1.1176e-04,
        2.9764e-04, 2.5758e-03, 2.5556e-03, 2.5711e-02, 1.6249e-01, 5.6915e-01,
        2.3703e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:15,719][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Melissa] are: tensor([0.0016, 0.0110, 0.0103, 0.0253, 0.0205, 0.0272, 0.0380, 0.0606, 0.0750,
        0.1510, 0.2178, 0.1675, 0.1943], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:15,721][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Melissa] are: tensor([0.0574, 0.0614, 0.0898, 0.0665, 0.0937, 0.0706, 0.0468, 0.0779, 0.1081,
        0.0735, 0.0543, 0.1141, 0.0858], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:15,723][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.0005, 0.0008, 0.0011, 0.0048, 0.0062, 0.0139, 0.0094, 0.0170, 0.0274,
        0.0611, 0.2489, 0.2978, 0.1566, 0.1546], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:15,725][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([0.0805, 0.0933, 0.0469, 0.0665, 0.0291, 0.0574, 0.0291, 0.1227, 0.0461,
        0.1358, 0.1030, 0.0949, 0.0361, 0.0588], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:15,726][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([4.2321e-13, 7.6974e-12, 1.4902e-10, 3.7737e-09, 2.9666e-08, 1.4301e-07,
        2.7905e-07, 2.8175e-06, 2.6191e-05, 1.1306e-03, 3.9117e-02, 1.3917e-01,
        5.2134e-01, 2.9921e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:15,727][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([1.0064e-07, 1.1195e-06, 4.6333e-06, 2.6421e-05, 8.0402e-05, 1.9987e-05,
        2.6268e-04, 1.4447e-03, 2.0022e-03, 2.1683e-02, 1.3360e-01, 2.0453e-01,
        4.5779e-01, 1.7855e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:15,728][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([1.6978e-07, 2.5265e-06, 2.7029e-06, 4.2118e-05, 2.8002e-05, 1.5730e-04,
        3.5118e-04, 7.9817e-04, 1.4135e-03, 2.1203e-02, 1.3953e-01, 4.6443e-01,
        6.3915e-02, 3.0813e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:15,729][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([1.3423e-08, 2.3811e-07, 5.7563e-07, 6.3222e-06, 1.0407e-05, 1.5028e-05,
        1.1440e-04, 6.0456e-04, 5.3546e-04, 3.1980e-02, 1.5737e-01, 1.1761e-01,
        5.0262e-01, 1.8914e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:15,730][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([0.0013, 0.0014, 0.0060, 0.0093, 0.0120, 0.0110, 0.0234, 0.0358, 0.0301,
        0.0456, 0.1684, 0.2292, 0.3052, 0.1213], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:15,731][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([2.3367e-05, 6.5274e-05, 5.5189e-04, 5.2834e-03, 3.0771e-03, 6.5281e-03,
        1.8592e-02, 1.8165e-02, 2.2412e-02, 1.2494e-01, 2.4290e-01, 9.8260e-02,
        1.0212e-01, 3.5708e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:15,732][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([7.3796e-07, 6.4847e-06, 1.0570e-05, 5.6950e-05, 1.4497e-04, 3.0493e-04,
        4.7641e-04, 2.9301e-03, 3.0709e-03, 4.5551e-02, 1.3851e-01, 1.9644e-01,
        2.5782e-01, 3.5467e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:15,734][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([8.5248e-10, 1.0443e-07, 6.0939e-07, 3.9355e-06, 2.0915e-05, 1.4309e-05,
        6.7911e-05, 3.9818e-04, 1.4755e-03, 1.9576e-02, 9.3344e-02, 1.4242e-01,
        5.5863e-01, 1.8404e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:15,735][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([0.0015, 0.0098, 0.0100, 0.0199, 0.0165, 0.0193, 0.0301, 0.0476, 0.0530,
        0.1204, 0.1501, 0.1189, 0.1785, 0.2246], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:15,737][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([0.0526, 0.0515, 0.1020, 0.0498, 0.0943, 0.0542, 0.0455, 0.0830, 0.0957,
        0.0619, 0.0426, 0.1169, 0.1001, 0.0498], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:15,738][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([2.5307e-04, 2.5221e-04, 5.3816e-04, 1.6157e-03, 1.1607e-03, 1.9254e-03,
        2.5158e-03, 4.9200e-03, 7.9642e-03, 2.2667e-02, 9.4672e-02, 1.5420e-01,
        1.0142e-01, 1.5514e-01, 4.5076e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:15,740][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.1788, 0.0743, 0.0272, 0.0606, 0.0242, 0.0347, 0.0519, 0.0879, 0.0387,
        0.1095, 0.0820, 0.0332, 0.0190, 0.0437, 0.1345], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:15,742][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([1.6979e-13, 4.3585e-13, 8.9613e-12, 1.7980e-10, 1.1683e-09, 7.3330e-09,
        2.2729e-08, 4.6733e-07, 3.1777e-06, 4.3734e-05, 1.5926e-03, 4.7873e-03,
        2.1340e-02, 2.8050e-01, 6.9173e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:15,743][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([4.9051e-08, 2.3009e-07, 1.8738e-06, 3.3595e-06, 2.5158e-05, 7.2286e-06,
        9.4694e-05, 2.6411e-04, 4.0084e-04, 3.9401e-03, 1.5782e-02, 4.1588e-02,
        1.8246e-01, 3.6154e-01, 3.9390e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:15,744][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([4.3310e-08, 3.5142e-07, 1.2688e-06, 3.3087e-06, 1.5305e-05, 8.0055e-05,
        2.8092e-05, 3.7911e-04, 1.8905e-03, 1.9741e-03, 1.0260e-02, 3.6961e-02,
        3.4418e-02, 7.0619e-01, 2.0780e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:15,745][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([5.7953e-09, 2.9076e-08, 1.2739e-07, 9.8900e-07, 1.4362e-06, 3.9132e-06,
        1.3495e-05, 7.1592e-05, 1.3365e-04, 3.4999e-03, 2.2388e-02, 2.9318e-02,
        1.0995e-01, 1.5157e-01, 6.8305e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:15,747][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0013, 0.0013, 0.0034, 0.0066, 0.0103, 0.0076, 0.0182, 0.0223, 0.0249,
        0.0371, 0.1056, 0.1188, 0.1346, 0.1344, 0.3736], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:15,749][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([1.3595e-05, 2.3581e-05, 2.0650e-04, 2.2089e-03, 1.1693e-03, 2.6987e-03,
        7.7359e-03, 7.1865e-03, 8.4721e-03, 4.9206e-02, 1.0460e-01, 3.9922e-02,
        4.0569e-02, 1.7587e-01, 5.6012e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:15,750][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([1.7509e-07, 8.1431e-07, 7.2997e-07, 6.2551e-06, 1.6955e-05, 8.2200e-05,
        6.3140e-05, 8.5110e-05, 5.4853e-04, 5.4575e-03, 2.1495e-02, 3.0647e-02,
        1.6302e-02, 6.4769e-01, 2.7760e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:15,751][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([3.5260e-10, 2.0619e-08, 1.7355e-07, 4.8159e-07, 2.8016e-06, 2.3075e-06,
        1.1843e-05, 1.1359e-04, 2.3564e-04, 2.3455e-03, 1.0470e-02, 4.0989e-02,
        1.3014e-01, 1.8299e-01, 6.3269e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:15,753][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0015, 0.0071, 0.0070, 0.0131, 0.0109, 0.0147, 0.0186, 0.0341, 0.0383,
        0.0745, 0.0950, 0.0910, 0.1121, 0.1776, 0.3046], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:15,755][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0509, 0.0567, 0.0888, 0.0645, 0.0841, 0.0584, 0.0454, 0.0684, 0.0855,
        0.0668, 0.0533, 0.0927, 0.0861, 0.0573, 0.0411], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:15,758][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:31:15,760][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 8034],
        [11442],
        [ 1878],
        [ 7045],
        [ 1248],
        [17453],
        [11410],
        [17042],
        [ 9326],
        [ 8253],
        [ 8887],
        [27878],
        [ 2730],
        [ 7281],
        [ 6197]], device='cuda:0')
[2024-07-24 10:31:15,762][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 5855],
        [13612],
        [ 2019],
        [ 7747],
        [  944],
        [29434],
        [22630],
        [26039],
        [13162],
        [11752],
        [10277],
        [31623],
        [ 2938],
        [ 7783],
        [10408]], device='cuda:0')
[2024-07-24 10:31:15,763][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[31493],
        [35684],
        [36448],
        [36210],
        [36369],
        [35960],
        [35703],
        [35879],
        [35848],
        [36117],
        [35952],
        [36052],
        [35736],
        [35562],
        [35633]], device='cuda:0')
[2024-07-24 10:31:15,765][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[16943],
        [16928],
        [15727],
        [15851],
        [14180],
        [14688],
        [14399],
        [14000],
        [12927],
        [11984],
        [11300],
        [11343],
        [11155],
        [11085],
        [11503]], device='cuda:0')
[2024-07-24 10:31:15,767][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 7005],
        [ 6986],
        [ 4237],
        [ 1505],
        [ 1452],
        [12498],
        [ 4725],
        [ 1794],
        [ 1129],
        [ 1849],
        [ 1395],
        [14836],
        [ 7682],
        [ 5582],
        [ 5948]], device='cuda:0')
[2024-07-24 10:31:15,768][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[17410],
        [17218],
        [15244],
        [14887],
        [ 9746],
        [11305],
        [11339],
        [ 8653],
        [ 8582],
        [ 9576],
        [10166],
        [ 8051],
        [ 5499],
        [ 5099],
        [ 5644]], device='cuda:0')
[2024-07-24 10:31:15,770][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[31238],
        [20730],
        [ 5186],
        [ 5890],
        [10816],
        [19609],
        [16263],
        [10679],
        [14632],
        [39306],
        [27634],
        [29150],
        [ 6571],
        [31411],
        [26138]], device='cuda:0')
[2024-07-24 10:31:15,772][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[41859],
        [43229],
        [42406],
        [43186],
        [45070],
        [45151],
        [45949],
        [46063],
        [46141],
        [46529],
        [46471],
        [46843],
        [47027],
        [46754],
        [46759]], device='cuda:0')
[2024-07-24 10:31:15,773][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[2428],
        [1603],
        [1300],
        [1019],
        [ 899],
        [1008],
        [1013],
        [1029],
        [1039],
        [1089],
        [1115],
        [1239],
        [1288],
        [1312],
        [1417]], device='cuda:0')
[2024-07-24 10:31:15,775][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[15165],
        [13162],
        [13538],
        [15580],
        [16005],
        [16344],
        [16077],
        [16713],
        [17357],
        [17096],
        [17760],
        [17952],
        [17748],
        [18041],
        [17888]], device='cuda:0')
[2024-07-24 10:31:15,777][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[20622],
        [20978],
        [22169],
        [20644],
        [19942],
        [21106],
        [17940],
        [19785],
        [22589],
        [17991],
        [20737],
        [16545],
        [17882],
        [20542],
        [ 2060]], device='cuda:0')
[2024-07-24 10:31:15,778][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[19824],
        [16845],
        [15649],
        [19654],
        [24362],
        [20983],
        [15622],
        [28545],
        [25872],
        [14361],
        [20798],
        [25465],
        [28415],
        [22408],
        [20902]], device='cuda:0')
[2024-07-24 10:31:15,780][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[24447],
        [24880],
        [28941],
        [31106],
        [33210],
        [35524],
        [36588],
        [38175],
        [38282],
        [38321],
        [38641],
        [38848],
        [39013],
        [39428],
        [39560]], device='cuda:0')
[2024-07-24 10:31:15,781][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[11629],
        [11446],
        [10671],
        [13105],
        [13695],
        [12289],
        [12349],
        [11111],
        [ 9799],
        [10060],
        [10733],
        [10469],
        [10205],
        [ 9694],
        [10305]], device='cuda:0')
[2024-07-24 10:31:15,783][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 9132],
        [17166],
        [ 4291],
        [13174],
        [ 6585],
        [ 5420],
        [ 4057],
        [ 8278],
        [ 6746],
        [11533],
        [14192],
        [11925],
        [ 7959],
        [ 9269],
        [10576]], device='cuda:0')
[2024-07-24 10:31:15,785][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[9240],
        [4728],
        [2487],
        [3974],
        [3264],
        [4662],
        [5129],
        [3617],
        [2507],
        [2680],
        [3405],
        [3310],
        [3196],
        [2718],
        [3331]], device='cuda:0')
[2024-07-24 10:31:15,786][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[22395],
        [20038],
        [28907],
        [20607],
        [11540],
        [21617],
        [23548],
        [18279],
        [16268],
        [18473],
        [17057],
        [19999],
        [30706],
        [27568],
        [21939]], device='cuda:0')
[2024-07-24 10:31:15,788][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[ 1367],
        [ 2917],
        [ 8956],
        [14191],
        [10912],
        [ 8867],
        [ 3622],
        [ 3468],
        [ 6441],
        [ 2468],
        [ 2344],
        [ 4485],
        [27209],
        [18994],
        [11426]], device='cuda:0')
[2024-07-24 10:31:15,789][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[24248],
        [20414],
        [21419],
        [25814],
        [29879],
        [28641],
        [27561],
        [27997],
        [30330],
        [25901],
        [27592],
        [27403],
        [26392],
        [25904],
        [28019]], device='cuda:0')
[2024-07-24 10:31:15,791][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[17690],
        [14449],
        [ 7326],
        [ 8909],
        [12382],
        [20583],
        [21091],
        [27384],
        [22534],
        [39170],
        [10274],
        [44541],
        [14617],
        [47857],
        [35708]], device='cuda:0')
[2024-07-24 10:31:15,792][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[17277],
        [14102],
        [16588],
        [14671],
        [12671],
        [11614],
        [ 4969],
        [ 9562],
        [10648],
        [ 5134],
        [ 6917],
        [11422],
        [10578],
        [ 8414],
        [ 4310]], device='cuda:0')
[2024-07-24 10:31:15,794][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[ 5540],
        [10439],
        [ 4659],
        [ 6790],
        [ 5537],
        [ 7424],
        [ 8401],
        [17203],
        [20738],
        [21745],
        [14949],
        [16694],
        [ 6304],
        [ 6327],
        [12098]], device='cuda:0')
[2024-07-24 10:31:15,796][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[ 4505],
        [ 7911],
        [11016],
        [ 9184],
        [13411],
        [10166],
        [10507],
        [10191],
        [ 6510],
        [ 8341],
        [ 5394],
        [ 4416],
        [ 5260],
        [ 7328],
        [ 4469]], device='cuda:0')
[2024-07-24 10:31:15,797][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[4092],
        [4126],
        [3700],
        [5920],
        [5752],
        [3034],
        [3494],
        [5423],
        [4199],
        [4360],
        [5513],
        [4210],
        [3234],
        [2201],
        [2209]], device='cuda:0')
[2024-07-24 10:31:15,799][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[ 677],
        [ 945],
        [ 617],
        [ 808],
        [ 849],
        [ 808],
        [1016],
        [ 659],
        [ 624],
        [ 886],
        [ 962],
        [ 776],
        [ 476],
        [ 515],
        [1167]], device='cuda:0')
[2024-07-24 10:31:15,801][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[ 7048],
        [ 7844],
        [10375],
        [ 6833],
        [ 6455],
        [ 6931],
        [ 5271],
        [ 5643],
        [ 6078],
        [ 5861],
        [ 5039],
        [ 5605],
        [ 7121],
        [ 7372],
        [ 5698]], device='cuda:0')
[2024-07-24 10:31:15,803][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[17660],
        [14813],
        [14758],
        [10251],
        [14277],
        [15370],
        [14527],
        [16498],
        [19299],
        [17620],
        [16397],
        [18177],
        [17650],
        [18963],
        [17208]], device='cuda:0')
[2024-07-24 10:31:15,804][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[37492],
        [35330],
        [37696],
        [34093],
        [36303],
        [34096],
        [35926],
        [36727],
        [38104],
        [35502],
        [38879],
        [34322],
        [35719],
        [33674],
        [35747]], device='cuda:0')
[2024-07-24 10:31:15,806][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[44524],
        [38780],
        [36169],
        [39354],
        [36333],
        [33516],
        [44904],
        [38658],
        [32420],
        [35070],
        [43681],
        [37090],
        [33726],
        [34423],
        [39450]], device='cuda:0')
[2024-07-24 10:31:15,807][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[49919],
        [49919],
        [49919],
        [49919],
        [49919],
        [49919],
        [49919],
        [49919],
        [49919],
        [49919],
        [49919],
        [49919],
        [49919],
        [49919],
        [49919]], device='cuda:0')
[2024-07-24 10:31:15,848][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:31:15,850][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:15,851][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:15,852][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:15,853][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:15,855][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:15,856][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:15,858][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:15,858][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:15,859][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:15,860][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:15,860][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:15,861][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:15,862][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.5976, 0.4024], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:15,863][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.8600, 0.1400], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:15,863][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.1486, 0.8514], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:15,864][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.4565, 0.5435], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:15,865][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.5150, 0.4850], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:15,866][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.2247, 0.7753], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:15,866][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0113, 0.9887], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:15,868][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0350, 0.9650], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:15,869][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0238, 0.9762], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:15,871][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.1489, 0.8511], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:15,873][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.4098, 0.5902], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:15,874][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.4985, 0.5015], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:15,876][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Melissa] are: tensor([0.3136, 0.4012, 0.2852], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:15,878][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Melissa] are: tensor([0.4227, 0.2929, 0.2843], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:15,878][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Melissa] are: tensor([0.0038, 0.9490, 0.0472], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:15,879][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Melissa] are: tensor([0.1140, 0.7910, 0.0950], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:15,880][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Melissa] are: tensor([0.3311, 0.3092, 0.3597], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:15,881][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Melissa] are: tensor([0.0891, 0.4240, 0.4869], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:15,882][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Melissa] are: tensor([0.0118, 0.7197, 0.2685], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:15,884][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Melissa] are: tensor([0.0127, 0.4657, 0.5216], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:15,885][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Melissa] are: tensor([0.0054, 0.9520, 0.0425], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:15,887][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Melissa] are: tensor([0.0780, 0.4417, 0.4802], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:15,889][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Melissa] are: tensor([0.2979, 0.4081, 0.2940], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:15,890][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Melissa] are: tensor([0.3320, 0.4476, 0.2204], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:15,892][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.2298, 0.3014, 0.2266, 0.2422], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:15,893][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.4203, 0.0644, 0.5102, 0.0052], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:15,895][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0073, 0.8116, 0.0673, 0.1138], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:15,897][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0978, 0.2243, 0.6302, 0.0477], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:15,898][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.2502, 0.2281, 0.2644, 0.2573], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:15,900][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0583, 0.2261, 0.3715, 0.3441], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:15,902][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0063, 0.5190, 0.2886, 0.1860], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:15,903][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0090, 0.2201, 0.3448, 0.4261], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:15,905][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0057, 0.1955, 0.0149, 0.7838], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:15,906][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0411, 0.1427, 0.0716, 0.7446], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:15,906][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.1912, 0.2662, 0.1808, 0.3618], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:15,907][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.2390, 0.3042, 0.3546, 0.1022], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:15,908][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Benjamin] are: tensor([0.1695, 0.3057, 0.1731, 0.1982, 0.1535], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:15,909][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Benjamin] are: tensor([0.0431, 0.0255, 0.6890, 0.1233, 0.1191], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:15,910][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Benjamin] are: tensor([0.0017, 0.7353, 0.0407, 0.2130, 0.0093], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:15,912][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Benjamin] are: tensor([0.0412, 0.1774, 0.6863, 0.0612, 0.0339], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:15,914][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Benjamin] are: tensor([0.1949, 0.1799, 0.2089, 0.2008, 0.2155], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:15,915][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Benjamin] are: tensor([0.0614, 0.2080, 0.2447, 0.3080, 0.1778], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:15,917][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Benjamin] are: tensor([0.0066, 0.5352, 0.2124, 0.2060, 0.0397], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:15,918][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Benjamin] are: tensor([0.0093, 0.2109, 0.2321, 0.4319, 0.1159], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:15,920][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Benjamin] are: tensor([0.0010, 0.0600, 0.0055, 0.9107, 0.0228], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:15,922][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Benjamin] are: tensor([0.0080, 0.0521, 0.0704, 0.7730, 0.0965], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:15,924][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Benjamin] are: tensor([0.1401, 0.1903, 0.1341, 0.3762, 0.1592], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:15,925][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Benjamin] are: tensor([0.2201, 0.2478, 0.3441, 0.1185, 0.0695], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:15,927][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.1576, 0.2495, 0.1497, 0.1705, 0.1377, 0.1350], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:15,928][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.4577, 0.0102, 0.0125, 0.4426, 0.0401, 0.0370], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:15,929][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ had] are: tensor([3.4228e-04, 6.7495e-01, 9.4219e-02, 1.9961e-01, 2.4073e-02, 6.8058e-03],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:15,931][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.0786, 0.2903, 0.3503, 0.1276, 0.1402, 0.0131], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:15,933][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.1633, 0.1487, 0.1762, 0.1683, 0.1829, 0.1607], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:15,934][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.0332, 0.1260, 0.2136, 0.2277, 0.1799, 0.2197], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:15,934][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.0035, 0.4864, 0.2462, 0.1795, 0.0360, 0.0484], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:15,935][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.0021, 0.1100, 0.2065, 0.2647, 0.1038, 0.3129], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:15,936][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ had] are: tensor([1.3640e-05, 4.4575e-02, 3.9733e-03, 9.1158e-01, 3.8867e-02, 9.9509e-04],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:15,938][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.0015, 0.1227, 0.0207, 0.7700, 0.0619, 0.0231], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:15,939][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.1020, 0.1363, 0.1366, 0.2829, 0.1585, 0.1837], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:15,941][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.3330, 0.2398, 0.1915, 0.1168, 0.0252, 0.0938], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:15,942][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.1207, 0.2486, 0.1290, 0.1513, 0.1127, 0.1195, 0.1183],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:15,944][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0242, 0.0135, 0.7856, 0.0293, 0.1021, 0.0354, 0.0100],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:15,945][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ a] are: tensor([2.5663e-04, 5.9932e-01, 8.0564e-02, 2.5925e-01, 3.6613e-02, 1.8820e-02,
        5.1825e-03], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:15,947][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.1416, 0.4261, 0.2251, 0.0568, 0.0632, 0.0690, 0.0182],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:15,949][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.1420, 0.1305, 0.1489, 0.1456, 0.1564, 0.1396, 0.1369],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:15,950][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0310, 0.1127, 0.1684, 0.1724, 0.1589, 0.1852, 0.1714],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:15,952][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0015, 0.4417, 0.2519, 0.1658, 0.0329, 0.0482, 0.0580],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:15,954][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0008, 0.0848, 0.1958, 0.2187, 0.0919, 0.3155, 0.0925],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:15,955][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ a] are: tensor([1.2067e-05, 5.5634e-02, 8.1070e-03, 8.7940e-01, 5.2925e-02, 3.7826e-03,
        1.4335e-04], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:15,956][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ a] are: tensor([3.0195e-04, 3.7312e-02, 2.6167e-02, 7.4601e-01, 1.3741e-01, 5.1229e-02,
        1.5728e-03], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:15,957][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0925, 0.1523, 0.1127, 0.2361, 0.1493, 0.1479, 0.1092],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:15,959][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.1455, 0.2798, 0.2480, 0.1059, 0.0548, 0.1155, 0.0505],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:15,961][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.1131, 0.2132, 0.1153, 0.1354, 0.1032, 0.1059, 0.1047, 0.1092],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:15,962][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ long] are: tensor([0.0526, 0.0939, 0.4770, 0.1556, 0.0495, 0.0673, 0.1026, 0.0014],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:15,962][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ long] are: tensor([1.8547e-04, 6.4492e-01, 4.6693e-02, 2.5904e-01, 1.5522e-02, 1.6277e-02,
        9.7728e-03, 7.5843e-03], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:15,963][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ long] are: tensor([0.1069, 0.3134, 0.0587, 0.1432, 0.2169, 0.0149, 0.1251, 0.0210],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:15,964][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.1209, 0.1113, 0.1295, 0.1269, 0.1385, 0.1217, 0.1194, 0.1318],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:15,966][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ long] are: tensor([0.0261, 0.0876, 0.1451, 0.1833, 0.1177, 0.1838, 0.1932, 0.0631],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:15,967][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.0046, 0.4356, 0.2153, 0.1653, 0.0312, 0.0530, 0.0631, 0.0319],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:15,969][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.0035, 0.1086, 0.1407, 0.2393, 0.0769, 0.2513, 0.0822, 0.0974],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:15,970][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ long] are: tensor([1.9500e-05, 5.1386e-02, 6.9038e-03, 8.9512e-01, 4.0597e-02, 4.5390e-03,
        1.5184e-04, 1.2862e-03], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:15,971][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ long] are: tensor([3.9120e-04, 4.1335e-02, 3.1492e-02, 7.8430e-01, 9.2681e-02, 3.4833e-02,
        2.0562e-03, 1.2914e-02], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:15,973][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.0619, 0.1088, 0.1054, 0.2509, 0.1381, 0.1268, 0.1285, 0.0795],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:15,974][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ long] are: tensor([0.1524, 0.1649, 0.2015, 0.0650, 0.0447, 0.0579, 0.0920, 0.2214],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:15,976][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.1086, 0.1891, 0.1051, 0.1234, 0.0967, 0.0933, 0.0929, 0.0948, 0.0961],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:15,978][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([0.0578, 0.0363, 0.0563, 0.0905, 0.0155, 0.3566, 0.3719, 0.0102, 0.0050],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:15,979][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([3.2608e-04, 6.2280e-01, 5.3862e-02, 2.5111e-01, 1.8806e-02, 1.8745e-02,
        1.1136e-02, 1.4668e-02, 8.5517e-03], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:15,981][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([0.0361, 0.2549, 0.2089, 0.1147, 0.1216, 0.0900, 0.0532, 0.1142, 0.0064],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:15,982][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.1073, 0.0986, 0.1164, 0.1143, 0.1238, 0.1093, 0.1064, 0.1174, 0.1064],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:15,984][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([0.0209, 0.0840, 0.1289, 0.1753, 0.1077, 0.1646, 0.1691, 0.0559, 0.0937],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:15,986][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.0024, 0.4292, 0.1983, 0.1676, 0.0310, 0.0504, 0.0637, 0.0315, 0.0260],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:15,987][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.0034, 0.1083, 0.1220, 0.2342, 0.0641, 0.2689, 0.0883, 0.0888, 0.0221],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:15,988][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([4.6769e-05, 5.6925e-02, 1.2505e-02, 8.6634e-01, 5.4195e-02, 5.0725e-03,
        1.6673e-04, 3.9517e-03, 7.9376e-04], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:15,989][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.0008, 0.0473, 0.0405, 0.7088, 0.1282, 0.0519, 0.0017, 0.0163, 0.0045],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:15,990][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.0570, 0.1048, 0.0980, 0.2260, 0.1268, 0.1154, 0.1299, 0.0694, 0.0725],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:15,991][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([0.0838, 0.1147, 0.1348, 0.0462, 0.0224, 0.0791, 0.0659, 0.4024, 0.0507],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:15,993][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.1077, 0.1267, 0.0991, 0.1110, 0.1003, 0.0896, 0.0937, 0.0933, 0.0916,
        0.0870], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:15,994][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0477, 0.0014, 0.0705, 0.0726, 0.0860, 0.5020, 0.1649, 0.0044, 0.0316,
        0.0188], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:15,996][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0023, 0.3795, 0.0446, 0.2095, 0.0148, 0.0091, 0.0067, 0.0085, 0.0076,
        0.3175], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:15,998][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0613, 0.0925, 0.2613, 0.0245, 0.2095, 0.0428, 0.0671, 0.2009, 0.0278,
        0.0122], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:15,999][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0969, 0.0901, 0.1071, 0.1044, 0.1112, 0.1011, 0.0971, 0.1076, 0.0976,
        0.0870], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:16,001][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0207, 0.0719, 0.1286, 0.1446, 0.1014, 0.1387, 0.1438, 0.0594, 0.0962,
        0.0946], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:16,003][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0017, 0.3667, 0.1944, 0.1587, 0.0323, 0.0438, 0.0495, 0.0277, 0.0229,
        0.1023], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:16,004][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0010, 0.0723, 0.1294, 0.1707, 0.0665, 0.2141, 0.0719, 0.1067, 0.0348,
        0.1326], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:16,006][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [,] are: tensor([5.5277e-04, 4.5285e-02, 3.5565e-03, 7.8857e-01, 1.9468e-02, 3.9047e-03,
        2.4037e-04, 1.6989e-03, 1.1991e-03, 1.3552e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:16,007][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0026, 0.0279, 0.0500, 0.6682, 0.1827, 0.0139, 0.0010, 0.0105, 0.0021,
        0.0411], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:16,009][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0765, 0.1192, 0.0766, 0.1627, 0.0968, 0.1189, 0.0932, 0.0578, 0.0586,
        0.1396], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:16,011][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0961, 0.1010, 0.0924, 0.0616, 0.0214, 0.0687, 0.0886, 0.2700, 0.1448,
        0.0552], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:16,013][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0872, 0.1489, 0.0890, 0.1009, 0.0817, 0.0800, 0.0787, 0.0789, 0.0809,
        0.0891, 0.0848], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:16,014][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0585, 0.0109, 0.0916, 0.0009, 0.0630, 0.5914, 0.0379, 0.0087, 0.0420,
        0.0936, 0.0015], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:16,016][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0022, 0.2695, 0.0153, 0.0340, 0.0070, 0.0035, 0.0026, 0.0031, 0.0038,
        0.2796, 0.3795], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:16,017][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0387, 0.1227, 0.3078, 0.0226, 0.1835, 0.0507, 0.1202, 0.0690, 0.0466,
        0.0259, 0.0123], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:16,017][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0900, 0.0832, 0.0968, 0.0944, 0.1006, 0.0917, 0.0886, 0.0999, 0.0889,
        0.0790, 0.0870], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:16,018][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0185, 0.0710, 0.1155, 0.1202, 0.0923, 0.1150, 0.1343, 0.0549, 0.0818,
        0.0934, 0.1029], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:16,020][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0027, 0.3542, 0.1905, 0.1296, 0.0263, 0.0374, 0.0411, 0.0237, 0.0194,
        0.0899, 0.0853], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:16,021][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0007, 0.0622, 0.1377, 0.1525, 0.0638, 0.2019, 0.0646, 0.0953, 0.0344,
        0.1213, 0.0657], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:16,022][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ and] are: tensor([9.4115e-04, 5.4727e-02, 3.6677e-03, 2.4480e-01, 2.0408e-02, 2.4062e-03,
        1.6036e-04, 1.2391e-03, 7.4018e-04, 1.5244e-01, 5.1847e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:16,024][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0083, 0.0822, 0.0263, 0.3832, 0.0636, 0.0173, 0.0013, 0.0094, 0.0028,
        0.1257, 0.2800], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:16,026][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0621, 0.1027, 0.0683, 0.1471, 0.0864, 0.1093, 0.0745, 0.0463, 0.0436,
        0.1315, 0.1282], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:16,027][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0774, 0.1161, 0.1467, 0.0351, 0.0268, 0.0527, 0.0740, 0.2464, 0.1312,
        0.0643, 0.0292], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:16,029][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.0952, 0.1207, 0.0811, 0.0946, 0.0792, 0.0768, 0.0767, 0.0759, 0.0741,
        0.0753, 0.0802, 0.0702], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:16,031][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([0.0887, 0.0361, 0.0683, 0.0328, 0.0190, 0.4582, 0.0557, 0.0646, 0.0244,
        0.0958, 0.0494, 0.0069], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:16,032][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([2.9883e-04, 1.4771e-01, 8.7222e-03, 4.8117e-02, 4.0014e-03, 1.3634e-03,
        9.5597e-04, 1.7840e-03, 1.6778e-03, 1.8139e-01, 5.8322e-01, 2.0753e-02],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:16,033][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([0.0224, 0.1605, 0.0345, 0.1148, 0.0960, 0.0132, 0.0626, 0.3812, 0.0031,
        0.0288, 0.0649, 0.0179], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:16,035][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.0807, 0.0750, 0.0864, 0.0865, 0.0935, 0.0849, 0.0803, 0.0921, 0.0814,
        0.0697, 0.0791, 0.0903], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:16,037][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([0.0144, 0.0667, 0.0931, 0.1340, 0.0717, 0.1267, 0.1355, 0.0392, 0.0585,
        0.0929, 0.1110, 0.0563], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:16,039][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.0060, 0.2573, 0.1200, 0.1211, 0.0224, 0.0356, 0.0345, 0.0232, 0.0174,
        0.0795, 0.0761, 0.2069], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:16,040][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.0024, 0.0681, 0.0968, 0.1615, 0.0510, 0.1688, 0.0467, 0.0751, 0.0243,
        0.1154, 0.0707, 0.1191], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:16,042][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([1.5750e-04, 1.4262e-02, 1.3325e-03, 2.0454e-01, 8.3212e-03, 1.1842e-03,
        8.1479e-05, 7.7049e-04, 5.3237e-04, 1.2603e-01, 6.3169e-01, 1.1098e-02],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:16,043][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([0.0023, 0.0440, 0.0448, 0.3532, 0.0863, 0.0226, 0.0012, 0.0154, 0.0051,
        0.1123, 0.2958, 0.0170], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:16,044][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.0709, 0.1073, 0.0578, 0.1466, 0.0775, 0.0855, 0.0781, 0.0438, 0.0487,
        0.1037, 0.1128, 0.0673], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:16,045][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([0.0582, 0.0732, 0.0902, 0.0403, 0.0221, 0.0671, 0.0741, 0.3651, 0.0611,
        0.0403, 0.0324, 0.0758], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:16,046][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Melissa] are: tensor([0.0779, 0.1640, 0.0809, 0.0929, 0.0673, 0.0661, 0.0629, 0.0610, 0.0656,
        0.0778, 0.0687, 0.0655, 0.0494], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:16,048][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Melissa] are: tensor([0.0608, 0.0708, 0.0537, 0.1172, 0.1148, 0.0533, 0.0329, 0.0041, 0.0849,
        0.1207, 0.1460, 0.1051, 0.0357], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:16,049][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Melissa] are: tensor([0.0005, 0.1402, 0.0064, 0.0414, 0.0031, 0.0019, 0.0011, 0.0015, 0.0020,
        0.2232, 0.5129, 0.0385, 0.0273], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:16,051][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Melissa] are: tensor([0.0204, 0.2346, 0.0199, 0.0629, 0.1528, 0.0206, 0.0725, 0.1854, 0.0053,
        0.0311, 0.0326, 0.1431, 0.0187], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:16,053][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Melissa] are: tensor([0.0763, 0.0699, 0.0821, 0.0807, 0.0867, 0.0778, 0.0750, 0.0843, 0.0773,
        0.0662, 0.0735, 0.0825, 0.0675], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:16,054][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Melissa] are: tensor([0.0132, 0.0734, 0.0784, 0.1148, 0.0618, 0.1449, 0.1190, 0.0324, 0.0647,
        0.0845, 0.0934, 0.0653, 0.0542], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:16,056][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Melissa] are: tensor([0.0039, 0.2221, 0.0927, 0.1000, 0.0166, 0.0260, 0.0234, 0.0167, 0.0118,
        0.0641, 0.0645, 0.1992, 0.1591], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:16,058][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Melissa] are: tensor([0.0010, 0.0673, 0.0688, 0.1647, 0.0402, 0.1707, 0.0472, 0.0609, 0.0151,
        0.1150, 0.0676, 0.1400, 0.0415], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:16,059][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Melissa] are: tensor([4.0259e-04, 2.2601e-02, 1.0453e-03, 2.7328e-01, 1.5503e-02, 1.7930e-03,
        8.9515e-05, 1.8101e-03, 1.0933e-03, 8.5001e-02, 5.5568e-01, 3.1600e-02,
        1.0095e-02], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:16,061][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Melissa] are: tensor([0.0052, 0.0209, 0.0178, 0.4056, 0.0658, 0.0203, 0.0016, 0.0108, 0.0027,
        0.0915, 0.2924, 0.0350, 0.0303], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:16,063][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Melissa] are: tensor([0.0541, 0.0817, 0.0669, 0.1520, 0.0808, 0.0893, 0.0786, 0.0444, 0.0437,
        0.0961, 0.1011, 0.0564, 0.0548], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:16,064][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Melissa] are: tensor([0.0654, 0.1256, 0.0500, 0.0500, 0.0337, 0.0961, 0.1331, 0.1085, 0.0619,
        0.0547, 0.0344, 0.1391, 0.0474], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:16,066][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.0843, 0.1097, 0.0732, 0.0824, 0.0700, 0.0662, 0.0691, 0.0679, 0.0674,
        0.0689, 0.0696, 0.0620, 0.0507, 0.0586], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:16,068][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ said] are: tensor([0.0944, 0.0355, 0.0438, 0.0753, 0.0023, 0.0556, 0.2917, 0.0194, 0.0013,
        0.1577, 0.1237, 0.0502, 0.0445, 0.0047], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:16,070][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.0006, 0.1467, 0.0094, 0.0327, 0.0032, 0.0008, 0.0007, 0.0010, 0.0012,
        0.1544, 0.3777, 0.0310, 0.0420, 0.1984], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:16,071][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ said] are: tensor([0.0574, 0.1410, 0.0223, 0.0436, 0.0420, 0.0144, 0.0265, 0.2840, 0.0020,
        0.0400, 0.0398, 0.2566, 0.0275, 0.0028], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:16,072][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.0716, 0.0649, 0.0778, 0.0757, 0.0817, 0.0721, 0.0700, 0.0782, 0.0712,
        0.0605, 0.0666, 0.0752, 0.0625, 0.0720], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:16,072][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ said] are: tensor([0.0147, 0.0515, 0.0794, 0.0895, 0.0721, 0.1003, 0.0936, 0.0374, 0.0658,
        0.0695, 0.0796, 0.0599, 0.0553, 0.1315], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:16,073][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.0030, 0.2138, 0.1069, 0.0784, 0.0161, 0.0220, 0.0272, 0.0163, 0.0135,
        0.0605, 0.0573, 0.1596, 0.1528, 0.0725], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:16,075][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.0011, 0.0563, 0.0887, 0.1309, 0.0426, 0.1333, 0.0430, 0.0594, 0.0193,
        0.0934, 0.0550, 0.1144, 0.0583, 0.1042], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:16,076][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ said] are: tensor([6.9381e-04, 2.6983e-02, 1.6614e-03, 2.2733e-01, 1.2862e-02, 4.5037e-04,
        3.7239e-05, 7.3830e-04, 2.5498e-04, 9.9268e-02, 5.4934e-01, 1.4543e-02,
        1.7222e-02, 4.8620e-02], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:16,078][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ said] are: tensor([0.0075, 0.0296, 0.0059, 0.5415, 0.0213, 0.0081, 0.0007, 0.0059, 0.0006,
        0.0666, 0.1787, 0.0347, 0.0052, 0.0939], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:16,080][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.0520, 0.0740, 0.0562, 0.1211, 0.0773, 0.0837, 0.0826, 0.0470, 0.0492,
        0.0817, 0.0956, 0.0568, 0.0536, 0.0693], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:16,082][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ said] are: tensor([0.0903, 0.0855, 0.0429, 0.0344, 0.0145, 0.0794, 0.0393, 0.1422, 0.0790,
        0.0450, 0.0277, 0.2559, 0.0422, 0.0218], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:16,083][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0688, 0.1193, 0.0717, 0.0792, 0.0636, 0.0642, 0.0625, 0.0613, 0.0642,
        0.0674, 0.0642, 0.0580, 0.0472, 0.0530, 0.0551], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:16,085][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0064, 0.0018, 0.0611, 0.0057, 0.0306, 0.3152, 0.0226, 0.0051, 0.0461,
        0.0174, 0.0151, 0.0119, 0.0674, 0.3825, 0.0111], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:16,087][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ to] are: tensor([7.9997e-04, 2.0316e-02, 9.4726e-04, 5.1352e-03, 4.3484e-04, 1.4521e-04,
        1.4854e-04, 1.5043e-04, 1.7529e-04, 1.7187e-02, 5.5981e-02, 4.6255e-03,
        4.8418e-03, 5.2992e-02, 8.3612e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:16,088][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0535, 0.1152, 0.0790, 0.0149, 0.0567, 0.0481, 0.0530, 0.1349, 0.1658,
        0.0216, 0.0139, 0.0477, 0.1156, 0.0785, 0.0016], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:16,090][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0684, 0.0628, 0.0716, 0.0701, 0.0748, 0.0669, 0.0659, 0.0731, 0.0651,
        0.0581, 0.0633, 0.0698, 0.0592, 0.0657, 0.0653], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:16,092][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0126, 0.0532, 0.0838, 0.0868, 0.0684, 0.0908, 0.0930, 0.0364, 0.0628,
        0.0703, 0.0727, 0.0500, 0.0609, 0.1181, 0.0403], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:16,093][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0030, 0.2006, 0.0915, 0.0800, 0.0150, 0.0203, 0.0213, 0.0145, 0.0117,
        0.0529, 0.0464, 0.1474, 0.1282, 0.0742, 0.0931], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:16,095][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0007, 0.0421, 0.0835, 0.1077, 0.0437, 0.1192, 0.0354, 0.0657, 0.0241,
        0.0765, 0.0390, 0.1059, 0.0549, 0.1001, 0.1016], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:16,097][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ to] are: tensor([1.3161e-03, 7.7015e-03, 6.5199e-04, 5.2968e-02, 1.5714e-03, 1.4696e-04,
        7.5520e-06, 1.2833e-04, 7.5582e-05, 1.5693e-02, 8.0297e-02, 5.8183e-03,
        6.7485e-03, 8.9912e-02, 7.3696e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:16,098][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0133, 0.0173, 0.0055, 0.2032, 0.0293, 0.0072, 0.0005, 0.0020, 0.0026,
        0.0368, 0.1095, 0.0118, 0.0085, 0.4006, 0.1519], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:16,099][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0642, 0.0887, 0.0411, 0.1227, 0.0661, 0.0673, 0.0688, 0.0345, 0.0363,
        0.0922, 0.0976, 0.0610, 0.0405, 0.0657, 0.0532], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:16,100][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0616, 0.0826, 0.0492, 0.0434, 0.0248, 0.0370, 0.0414, 0.1623, 0.1977,
        0.0500, 0.0386, 0.0965, 0.0495, 0.0414, 0.0240], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:16,151][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:31:16,152][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:16,153][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:16,154][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:16,155][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:16,156][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:16,157][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:16,159][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:16,160][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:16,161][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:16,163][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:16,164][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:16,165][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:16,167][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.8333, 0.1667], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:16,169][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.2081, 0.7919], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:16,170][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0129, 0.9871], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:16,171][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([6.8672e-04, 9.9931e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:16,173][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.5202, 0.4798], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:16,175][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.5473, 0.4527], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:16,176][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0977, 0.9023], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:16,178][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0022, 0.9978], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:16,179][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0238, 0.9762], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:16,179][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.1489, 0.8511], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:16,180][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.9288, 0.0712], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:16,181][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.2514, 0.7486], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:16,182][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Melissa] are: tensor([0.2279, 0.0733, 0.6988], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:16,184][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Melissa] are: tensor([0.0657, 0.8769, 0.0574], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:16,186][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Melissa] are: tensor([0.0036, 0.8962, 0.1002], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:16,187][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Melissa] are: tensor([2.1986e-04, 8.9051e-01, 1.0927e-01], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:16,188][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Melissa] are: tensor([0.3507, 0.3152, 0.3341], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:16,190][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Melissa] are: tensor([0.1876, 0.1722, 0.6402], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:16,191][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Melissa] are: tensor([0.0203, 0.6300, 0.3497], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:16,193][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Melissa] are: tensor([3.6352e-04, 9.5047e-01, 4.9165e-02], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:16,194][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Melissa] are: tensor([0.0054, 0.9520, 0.0425], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:16,196][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Melissa] are: tensor([0.0780, 0.4417, 0.4802], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:16,197][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Melissa] are: tensor([0.6851, 0.1833, 0.1316], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:16,199][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Melissa] are: tensor([0.1232, 0.7164, 0.1604], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:16,201][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.2863, 0.4039, 0.0822, 0.2276], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:16,202][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0917, 0.2284, 0.0181, 0.6618], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:16,204][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0023, 0.2650, 0.0448, 0.6880], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:16,205][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([2.0872e-04, 1.3557e-01, 1.8763e-02, 8.4546e-01], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:16,206][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.2453, 0.2280, 0.2399, 0.2869], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:16,207][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.2823, 0.1582, 0.3747, 0.1847], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:16,207][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0455, 0.1613, 0.1959, 0.5972], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:16,208][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([8.1867e-04, 1.0988e-01, 2.7944e-02, 8.6136e-01], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:16,209][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0057, 0.1955, 0.0149, 0.7838], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:16,211][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0411, 0.1427, 0.0716, 0.7446], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:16,213][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.5951, 0.0988, 0.0491, 0.2570], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:16,214][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0835, 0.1313, 0.0432, 0.7420], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:16,216][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Benjamin] are: tensor([0.4799, 0.0951, 0.0101, 0.0251, 0.3897], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:16,217][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Benjamin] are: tensor([0.0198, 0.1272, 0.0182, 0.8018, 0.0330], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:16,219][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Benjamin] are: tensor([8.4842e-04, 6.6375e-02, 1.2169e-02, 8.9380e-01, 2.6810e-02],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:16,220][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Benjamin] are: tensor([1.8565e-05, 2.8404e-02, 1.2529e-02, 9.3531e-01, 2.3744e-02],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:16,222][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Benjamin] are: tensor([0.1989, 0.1833, 0.1976, 0.2379, 0.1822], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:16,223][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Benjamin] are: tensor([0.1188, 0.0961, 0.2405, 0.1194, 0.4251], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:16,225][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Benjamin] are: tensor([0.0086, 0.1002, 0.0773, 0.7149, 0.0990], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:16,226][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Benjamin] are: tensor([5.8317e-05, 6.2437e-02, 1.4392e-02, 8.9846e-01, 2.4651e-02],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:16,228][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Benjamin] are: tensor([0.0010, 0.0600, 0.0055, 0.9107, 0.0228], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:16,229][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Benjamin] are: tensor([0.0080, 0.0521, 0.0704, 0.7730, 0.0965], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:16,231][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Benjamin] are: tensor([0.4469, 0.1017, 0.0606, 0.2885, 0.1023], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:16,233][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Benjamin] are: tensor([0.0264, 0.0806, 0.0370, 0.8131, 0.0428], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:16,234][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.1159, 0.2748, 0.0493, 0.1703, 0.0795, 0.3103], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:16,234][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.0012, 0.1026, 0.0060, 0.8502, 0.0339, 0.0062], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:16,235][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([4.5045e-06, 3.8659e-02, 1.9663e-02, 8.5736e-01, 8.3101e-02, 1.2164e-03],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:16,236][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([5.7494e-07, 2.3930e-02, 5.8961e-03, 9.2018e-01, 4.9364e-02, 6.3220e-04],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:16,237][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.1776, 0.1677, 0.1662, 0.2033, 0.1582, 0.1270], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:16,239][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.0725, 0.0780, 0.2119, 0.0876, 0.4539, 0.0962], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:16,240][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([1.1228e-04, 3.6803e-02, 7.8100e-02, 6.5747e-01, 2.2344e-01, 4.0759e-03],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:16,241][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([7.8679e-07, 3.0009e-02, 1.0129e-02, 8.5890e-01, 9.8947e-02, 2.0188e-03],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:16,242][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([1.3640e-05, 4.4575e-02, 3.9733e-03, 9.1158e-01, 3.8867e-02, 9.9509e-04],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:16,244][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.0015, 0.1227, 0.0207, 0.7700, 0.0619, 0.0231], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:16,245][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.1229, 0.1357, 0.0801, 0.4524, 0.1169, 0.0919], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:16,247][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.0012, 0.0410, 0.0238, 0.8915, 0.0341, 0.0085], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:16,249][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.1350, 0.2042, 0.0516, 0.1852, 0.1555, 0.0264, 0.2422],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:16,250][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([7.0870e-04, 1.4504e-01, 1.3087e-02, 7.5894e-01, 6.5411e-02, 1.4412e-02,
        2.4025e-03], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:16,251][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([2.8374e-06, 3.2345e-02, 8.9411e-03, 8.5898e-01, 9.4371e-02, 5.2818e-03,
        7.5845e-05], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:16,252][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([1.1715e-07, 2.6666e-02, 8.1158e-03, 8.7257e-01, 8.6144e-02, 6.4540e-03,
        5.0713e-05], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:16,254][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.1525, 0.1528, 0.1523, 0.1876, 0.1387, 0.1164, 0.0998],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:16,256][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0548, 0.0752, 0.1921, 0.0923, 0.3875, 0.1179, 0.0802],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:16,257][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([1.6783e-04, 3.9308e-02, 5.9065e-02, 6.9577e-01, 1.9453e-01, 1.0247e-02,
        9.0508e-04], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:16,258][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([6.4595e-07, 3.4268e-02, 1.4925e-02, 8.1647e-01, 1.2731e-01, 6.9245e-03,
        1.0944e-04], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:16,259][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([1.2067e-05, 5.5634e-02, 8.1070e-03, 8.7940e-01, 5.2925e-02, 3.7826e-03,
        1.4335e-04], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:16,260][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([3.0195e-04, 3.7312e-02, 2.6167e-02, 7.4601e-01, 1.3741e-01, 5.1229e-02,
        1.5728e-03], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:16,261][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.1227, 0.1301, 0.0774, 0.4424, 0.1314, 0.0662, 0.0297],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:16,262][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([7.5835e-04, 4.1733e-02, 3.6395e-02, 8.2685e-01, 8.0355e-02, 1.2995e-02,
        9.0844e-04], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:16,263][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.1400, 0.1993, 0.0903, 0.0986, 0.0411, 0.0196, 0.0470, 0.3641],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:16,264][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([0.0012, 0.1301, 0.0098, 0.8055, 0.0386, 0.0102, 0.0024, 0.0022],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:16,265][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([2.2203e-06, 2.7771e-02, 5.9003e-03, 9.2150e-01, 3.9518e-02, 4.7688e-03,
        2.2890e-04, 3.1567e-04], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:16,266][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([1.6089e-07, 2.4420e-02, 3.4911e-03, 9.0044e-01, 6.9270e-02, 2.0920e-03,
        4.5552e-05, 2.4064e-04], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:16,268][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.1440, 0.1457, 0.1396, 0.1711, 0.1257, 0.1064, 0.0888, 0.0786],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:16,269][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([0.0642, 0.0637, 0.2173, 0.0984, 0.3068, 0.1124, 0.0943, 0.0430],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:16,270][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([2.1908e-04, 4.3607e-02, 5.5072e-02, 7.4578e-01, 1.4503e-01, 6.6460e-03,
        9.4692e-04, 2.7008e-03], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:16,272][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([5.5357e-07, 2.9801e-02, 7.8328e-03, 8.8647e-01, 7.1701e-02, 3.8025e-03,
        1.0211e-04, 2.8549e-04], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:16,273][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([1.9500e-05, 5.1386e-02, 6.9038e-03, 8.9512e-01, 4.0597e-02, 4.5390e-03,
        1.5184e-04, 1.2862e-03], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:16,274][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([3.9120e-04, 4.1335e-02, 3.1492e-02, 7.8430e-01, 9.2681e-02, 3.4833e-02,
        2.0562e-03, 1.2914e-02], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:16,276][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.1565, 0.1245, 0.0565, 0.4550, 0.0781, 0.0614, 0.0237, 0.0442],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:16,277][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([0.0014, 0.0473, 0.0199, 0.8499, 0.0623, 0.0095, 0.0023, 0.0074],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:16,279][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.0381, 0.1711, 0.0110, 0.0629, 0.0485, 0.0041, 0.0205, 0.0145, 0.6294],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:16,281][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([0.0011, 0.1738, 0.0125, 0.7396, 0.0557, 0.0102, 0.0018, 0.0032, 0.0020],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:16,282][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([9.3919e-06, 2.4798e-02, 8.3321e-03, 9.0323e-01, 5.5901e-02, 6.0042e-03,
        2.3906e-04, 1.0743e-03, 4.1228e-04], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:16,283][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([6.9541e-07, 3.3710e-02, 7.0397e-03, 8.8026e-01, 7.3345e-02, 2.9038e-03,
        3.2308e-05, 1.1724e-03, 1.5391e-03], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:16,285][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.1273, 0.1303, 0.1250, 0.1569, 0.1184, 0.0954, 0.0871, 0.0770, 0.0827],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:16,287][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([0.0576, 0.0645, 0.2156, 0.0898, 0.3340, 0.0724, 0.0767, 0.0397, 0.0498],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:16,288][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([2.6978e-04, 4.7614e-02, 5.9425e-02, 7.2929e-01, 1.4516e-01, 7.0594e-03,
        1.0955e-03, 7.1282e-03, 2.9604e-03], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:16,289][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([2.6499e-06, 5.3398e-02, 1.0924e-02, 7.9356e-01, 1.2947e-01, 7.5150e-03,
        1.5388e-04, 2.7618e-03, 2.2176e-03], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:16,290][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([4.6769e-05, 5.6925e-02, 1.2505e-02, 8.6634e-01, 5.4195e-02, 5.0725e-03,
        1.6673e-04, 3.9517e-03, 7.9376e-04], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:16,290][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([0.0008, 0.0473, 0.0405, 0.7088, 0.1282, 0.0519, 0.0017, 0.0163, 0.0045],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:16,291][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.1840, 0.1558, 0.0721, 0.3617, 0.1078, 0.0399, 0.0186, 0.0249, 0.0352],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:16,293][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([0.0013, 0.0353, 0.0298, 0.8019, 0.0818, 0.0104, 0.0017, 0.0338, 0.0040],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:16,294][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0278, 0.2554, 0.0667, 0.1327, 0.0781, 0.0159, 0.0303, 0.0446, 0.1362,
        0.2124], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:16,296][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0083, 0.0840, 0.0083, 0.7257, 0.0334, 0.0085, 0.0020, 0.0019, 0.0017,
        0.1263], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:16,297][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([1.0992e-04, 2.2709e-02, 8.2955e-03, 8.6503e-01, 4.1467e-02, 2.9839e-03,
        1.4283e-04, 5.1866e-04, 3.0867e-04, 5.8432e-02], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:16,298][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([3.0503e-05, 2.2583e-02, 5.8866e-03, 5.0151e-01, 8.6893e-02, 1.6877e-03,
        5.2957e-05, 1.1223e-03, 2.3395e-03, 3.7789e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:16,300][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.1199, 0.1159, 0.1162, 0.1437, 0.1052, 0.0866, 0.0731, 0.0673, 0.0748,
        0.0974], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:16,302][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0806, 0.0608, 0.1586, 0.0701, 0.2965, 0.0901, 0.0839, 0.0449, 0.0678,
        0.0466], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:16,303][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0020, 0.0344, 0.0658, 0.6448, 0.1858, 0.0048, 0.0008, 0.0036, 0.0025,
        0.0554], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:16,305][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([6.5611e-05, 2.9002e-02, 1.6143e-02, 5.7949e-01, 1.1179e-01, 4.2789e-03,
        1.3726e-04, 1.3276e-03, 4.4071e-03, 2.5336e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:16,306][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([5.5277e-04, 4.5285e-02, 3.5565e-03, 7.8857e-01, 1.9468e-02, 3.9047e-03,
        2.4037e-04, 1.6989e-03, 1.1991e-03, 1.3552e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:16,308][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0026, 0.0279, 0.0500, 0.6682, 0.1827, 0.0139, 0.0010, 0.0105, 0.0021,
        0.0411], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:16,310][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.2733, 0.0975, 0.0512, 0.2698, 0.0630, 0.0382, 0.0130, 0.0181, 0.0141,
        0.1620], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:16,311][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0061, 0.0422, 0.0217, 0.7719, 0.0523, 0.0067, 0.0014, 0.0129, 0.0036,
        0.0812], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:16,313][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0504, 0.1933, 0.0411, 0.1400, 0.0444, 0.0174, 0.0272, 0.0382, 0.0845,
        0.2394, 0.1240], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:16,315][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0109, 0.1473, 0.0091, 0.3199, 0.0333, 0.0076, 0.0020, 0.0020, 0.0021,
        0.2165, 0.2490], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:16,316][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([2.1844e-04, 7.0114e-02, 8.9140e-03, 3.2050e-01, 6.1160e-02, 2.9153e-03,
        1.6628e-04, 5.5934e-04, 4.5199e-04, 1.7556e-01, 3.5944e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:16,317][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([2.9072e-05, 2.7397e-02, 3.1319e-03, 1.5473e-01, 2.4697e-02, 6.4047e-04,
        2.0860e-05, 4.5619e-04, 1.1011e-03, 2.5401e-01, 5.3379e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:16,318][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.1106, 0.1085, 0.1060, 0.1334, 0.0953, 0.0761, 0.0631, 0.0571, 0.0640,
        0.0880, 0.0980], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:16,318][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.1311, 0.0749, 0.1149, 0.0621, 0.1884, 0.0848, 0.0829, 0.0558, 0.0668,
        0.0555, 0.0830], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:16,320][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0075, 0.0615, 0.0619, 0.2583, 0.1933, 0.0055, 0.0009, 0.0040, 0.0029,
        0.1006, 0.3036], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:16,321][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([6.7847e-05, 2.0135e-02, 6.5644e-03, 2.2218e-01, 5.4072e-02, 1.4768e-03,
        4.6120e-05, 5.0178e-04, 1.9259e-03, 1.2475e-01, 5.6828e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:16,323][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([9.4115e-04, 5.4727e-02, 3.6677e-03, 2.4480e-01, 2.0408e-02, 2.4062e-03,
        1.6036e-04, 1.2391e-03, 7.4018e-04, 1.5244e-01, 5.1847e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:16,324][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0083, 0.0822, 0.0263, 0.3832, 0.0636, 0.0173, 0.0013, 0.0094, 0.0028,
        0.1257, 0.2800], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:16,326][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.3040, 0.0870, 0.0411, 0.1817, 0.0521, 0.0298, 0.0098, 0.0118, 0.0112,
        0.1188, 0.1527], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:16,327][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0137, 0.0617, 0.0225, 0.4110, 0.0489, 0.0078, 0.0014, 0.0110, 0.0046,
        0.1015, 0.3159], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:16,329][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.1514, 0.1591, 0.0237, 0.0833, 0.0302, 0.0095, 0.0371, 0.0816, 0.0732,
        0.1164, 0.0502, 0.1843], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:16,331][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([0.0046, 0.0970, 0.0072, 0.3315, 0.0235, 0.0086, 0.0020, 0.0025, 0.0023,
        0.2036, 0.3077, 0.0098], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:16,332][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([5.6147e-05, 1.5471e-02, 4.8707e-03, 3.1741e-01, 3.0118e-02, 9.3022e-04,
        1.0416e-04, 5.3752e-04, 4.3461e-04, 8.8244e-02, 5.3443e-01, 7.3952e-03],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:16,333][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([1.0579e-05, 7.2108e-03, 1.5060e-03, 2.0727e-01, 3.2880e-02, 5.1674e-04,
        1.3396e-05, 8.6566e-04, 4.7290e-04, 1.4173e-01, 5.9805e-01, 9.4751e-03],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:16,335][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.0942, 0.0970, 0.0956, 0.1200, 0.0871, 0.0757, 0.0624, 0.0564, 0.0636,
        0.0829, 0.0923, 0.0729], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:16,337][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([0.0982, 0.0923, 0.1521, 0.0751, 0.2270, 0.0571, 0.0575, 0.0362, 0.0375,
        0.0364, 0.0762, 0.0544], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:16,339][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.0015, 0.0497, 0.0327, 0.3259, 0.1475, 0.0060, 0.0007, 0.0038, 0.0029,
        0.0852, 0.3167, 0.0272], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:16,340][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([5.3391e-06, 9.1650e-03, 2.6452e-03, 1.6518e-01, 1.3923e-02, 8.5631e-04,
        3.9131e-05, 4.0195e-04, 7.4574e-04, 1.1060e-01, 6.8991e-01, 6.5292e-03],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:16,341][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([1.5750e-04, 1.4262e-02, 1.3325e-03, 2.0454e-01, 8.3212e-03, 1.1842e-03,
        8.1479e-05, 7.7049e-04, 5.3237e-04, 1.2603e-01, 6.3169e-01, 1.1098e-02],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:16,343][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([0.0023, 0.0440, 0.0448, 0.3532, 0.0863, 0.0226, 0.0012, 0.0154, 0.0051,
        0.1123, 0.2958, 0.0170], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:16,344][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([0.2203, 0.0408, 0.0295, 0.1841, 0.0469, 0.0283, 0.0106, 0.0138, 0.0101,
        0.1158, 0.2080, 0.0919], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:16,345][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([0.0045, 0.0317, 0.0145, 0.3482, 0.0412, 0.0060, 0.0010, 0.0193, 0.0050,
        0.1116, 0.3392, 0.0777], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:16,346][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Melissa] are: tensor([0.0990, 0.0927, 0.4015, 0.0296, 0.0138, 0.0012, 0.0117, 0.0093, 0.0102,
        0.0423, 0.0212, 0.0031, 0.2642], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:16,346][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Melissa] are: tensor([0.0047, 0.0826, 0.0031, 0.3813, 0.0151, 0.0050, 0.0013, 0.0015, 0.0018,
        0.1455, 0.3254, 0.0256, 0.0073], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:16,348][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Melissa] are: tensor([3.2364e-04, 2.5785e-02, 2.9074e-03, 2.7064e-01, 1.7867e-02, 1.6203e-03,
        1.1147e-04, 3.4118e-04, 4.3214e-04, 1.2106e-01, 5.2002e-01, 2.0538e-02,
        1.8351e-02], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:16,349][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Melissa] are: tensor([1.1589e-05, 8.3500e-03, 9.5678e-04, 1.7556e-01, 1.4806e-02, 5.5776e-04,
        1.5243e-05, 2.1731e-04, 4.9639e-04, 1.7759e-01, 5.9439e-01, 1.0792e-02,
        1.6251e-02], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:16,351][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Melissa] are: tensor([0.0905, 0.0868, 0.0825, 0.1084, 0.0841, 0.0685, 0.0601, 0.0566, 0.0599,
        0.0786, 0.0921, 0.0704, 0.0615], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:16,353][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Melissa] are: tensor([0.0448, 0.0496, 0.1158, 0.0514, 0.2454, 0.0581, 0.0481, 0.0318, 0.0514,
        0.0361, 0.0597, 0.0745, 0.1333], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:16,354][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Melissa] are: tensor([0.0029, 0.0440, 0.0235, 0.2431, 0.0770, 0.0023, 0.0005, 0.0017, 0.0014,
        0.0805, 0.4212, 0.0198, 0.0820], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:16,356][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Melissa] are: tensor([2.1615e-05, 1.5511e-02, 1.1895e-03, 1.5563e-01, 2.7861e-02, 1.1770e-03,
        6.4991e-05, 7.2477e-04, 1.2179e-03, 1.6933e-01, 5.5971e-01, 4.9634e-02,
        1.7918e-02], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:16,357][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Melissa] are: tensor([4.0259e-04, 2.2601e-02, 1.0453e-03, 2.7328e-01, 1.5503e-02, 1.7930e-03,
        8.9515e-05, 1.8101e-03, 1.0933e-03, 8.5001e-02, 5.5568e-01, 3.1600e-02,
        1.0095e-02], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:16,359][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Melissa] are: tensor([0.0052, 0.0209, 0.0178, 0.4056, 0.0658, 0.0203, 0.0016, 0.0108, 0.0027,
        0.0915, 0.2924, 0.0350, 0.0303], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:16,360][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Melissa] are: tensor([0.2036, 0.0593, 0.0446, 0.1576, 0.0978, 0.0239, 0.0071, 0.0109, 0.0125,
        0.1000, 0.1479, 0.0566, 0.0781], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:16,362][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Melissa] are: tensor([0.0115, 0.0386, 0.0086, 0.3474, 0.0352, 0.0065, 0.0014, 0.0046, 0.0043,
        0.0836, 0.3036, 0.1381, 0.0165], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:16,364][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.0697, 0.1824, 0.0214, 0.0891, 0.0356, 0.0094, 0.0229, 0.0203, 0.0860,
        0.1440, 0.0588, 0.0088, 0.0133, 0.2384], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:16,366][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([0.0110, 0.0743, 0.0029, 0.3569, 0.0068, 0.0026, 0.0008, 0.0019, 0.0004,
        0.1792, 0.3062, 0.0167, 0.0064, 0.0337], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:16,367][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([3.4951e-04, 1.8869e-02, 6.0177e-03, 2.8936e-01, 2.6977e-02, 5.5150e-04,
        5.6146e-05, 2.5674e-04, 1.8861e-04, 9.2036e-02, 3.2055e-01, 1.4025e-02,
        3.3590e-02, 1.9717e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:16,369][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([2.4457e-05, 7.5684e-03, 8.3219e-04, 1.9944e-01, 1.7741e-02, 9.2405e-05,
        3.3272e-06, 9.7951e-05, 1.0992e-04, 9.1519e-02, 3.4897e-01, 1.5536e-02,
        1.3392e-02, 3.0467e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:16,370][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([0.0893, 0.0859, 0.0828, 0.1030, 0.0784, 0.0620, 0.0529, 0.0486, 0.0534,
        0.0727, 0.0802, 0.0638, 0.0579, 0.0690], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:16,371][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([0.0610, 0.0581, 0.1228, 0.0491, 0.2324, 0.0484, 0.0504, 0.0228, 0.0340,
        0.0248, 0.0498, 0.0657, 0.1477, 0.0330], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:16,372][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([0.0027, 0.0204, 0.0275, 0.2556, 0.0904, 0.0014, 0.0003, 0.0020, 0.0010,
        0.0558, 0.3266, 0.0245, 0.0794, 0.1124], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:16,373][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([3.1116e-05, 1.0212e-02, 2.3120e-03, 1.5045e-01, 1.7509e-02, 1.8930e-04,
        2.6963e-05, 7.2082e-05, 3.7302e-04, 8.3718e-02, 4.4610e-01, 1.5498e-02,
        3.4893e-02, 2.3862e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:16,374][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([6.9381e-04, 2.6983e-02, 1.6614e-03, 2.2733e-01, 1.2862e-02, 4.5037e-04,
        3.7239e-05, 7.3830e-04, 2.5498e-04, 9.9268e-02, 5.4934e-01, 1.4543e-02,
        1.7222e-02, 4.8620e-02], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:16,376][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([0.0075, 0.0296, 0.0059, 0.5415, 0.0213, 0.0081, 0.0007, 0.0059, 0.0006,
        0.0666, 0.1787, 0.0347, 0.0052, 0.0939], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:16,378][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([0.2061, 0.0716, 0.0306, 0.1324, 0.0387, 0.0196, 0.0068, 0.0071, 0.0085,
        0.0960, 0.1189, 0.0617, 0.0501, 0.1517], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:16,380][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([0.0148, 0.0209, 0.0073, 0.3638, 0.0073, 0.0039, 0.0006, 0.0057, 0.0015,
        0.0572, 0.2602, 0.1374, 0.0107, 0.1086], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:16,381][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0993, 0.1635, 0.0207, 0.1133, 0.0280, 0.0096, 0.0405, 0.0333, 0.0606,
        0.1488, 0.0771, 0.0147, 0.0171, 0.0680, 0.1056], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:16,383][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0224, 0.0548, 0.0032, 0.2304, 0.0144, 0.0026, 0.0008, 0.0006, 0.0007,
        0.0700, 0.1319, 0.0067, 0.0073, 0.0861, 0.3681], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:16,384][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([8.7716e-04, 7.3466e-03, 1.3602e-03, 9.9259e-02, 9.1389e-03, 2.3968e-04,
        2.1678e-05, 7.1617e-05, 6.0739e-05, 1.9886e-02, 9.3591e-02, 5.7380e-03,
        7.3447e-03, 2.1090e-01, 5.4417e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:16,386][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([1.2743e-05, 5.4684e-04, 6.8840e-05, 8.8175e-03, 6.1581e-04, 2.4089e-05,
        6.0786e-07, 6.4353e-06, 6.7332e-05, 4.8797e-03, 1.8168e-02, 8.2334e-04,
        1.2743e-03, 2.4215e-01, 7.2255e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:16,388][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0909, 0.0871, 0.0782, 0.0977, 0.0712, 0.0601, 0.0515, 0.0473, 0.0524,
        0.0673, 0.0720, 0.0601, 0.0537, 0.0636, 0.0469], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:16,389][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0687, 0.0470, 0.0971, 0.0492, 0.1755, 0.0600, 0.0472, 0.0285, 0.0395,
        0.0348, 0.0594, 0.0683, 0.1209, 0.0471, 0.0569], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:16,391][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([1.0608e-02, 1.1521e-02, 1.2284e-02, 8.7010e-02, 2.7546e-02, 7.6199e-04,
        1.6505e-04, 7.1332e-04, 6.0902e-04, 1.8062e-02, 9.6846e-02, 1.3696e-02,
        3.9599e-02, 1.2786e-01, 5.5272e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:16,392][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([3.8490e-05, 1.1601e-03, 2.1657e-04, 9.6374e-03, 1.4742e-03, 2.0777e-05,
        1.7254e-06, 1.3622e-05, 5.7223e-05, 5.2077e-03, 2.1085e-02, 1.9270e-03,
        3.3118e-03, 1.1634e-01, 8.3950e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:16,393][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([1.3161e-03, 7.7015e-03, 6.5199e-04, 5.2968e-02, 1.5714e-03, 1.4696e-04,
        7.5520e-06, 1.2833e-04, 7.5582e-05, 1.5693e-02, 8.0297e-02, 5.8183e-03,
        6.7485e-03, 8.9912e-02, 7.3696e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:16,395][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0133, 0.0173, 0.0055, 0.2032, 0.0293, 0.0072, 0.0005, 0.0020, 0.0026,
        0.0368, 0.1095, 0.0118, 0.0085, 0.4006, 0.1519], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:16,397][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.3498, 0.0400, 0.0148, 0.0601, 0.0215, 0.0095, 0.0033, 0.0035, 0.0054,
        0.0466, 0.0524, 0.0325, 0.0245, 0.0933, 0.2427], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:16,398][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([2.0473e-02, 1.3847e-02, 4.8525e-03, 1.4934e-01, 1.2305e-02, 1.0008e-03,
        3.5632e-04, 3.5792e-03, 1.8105e-03, 3.0651e-02, 1.1566e-01, 4.6171e-02,
        1.0747e-02, 1.6790e-01, 4.2130e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:16,401][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:31:16,403][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 8093],
        [19676],
        [ 5928],
        [15969],
        [16713],
        [25497],
        [16407],
        [25046],
        [13380],
        [20608],
        [20616],
        [28322],
        [ 8385],
        [13433],
        [13474]], device='cuda:0')
[2024-07-24 10:31:16,405][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 8375],
        [17148],
        [ 4143],
        [11847],
        [17503],
        [20933],
        [13027],
        [25620],
        [12206],
        [14034],
        [14198],
        [31471],
        [ 5948],
        [ 8728],
        [ 7702]], device='cuda:0')
[2024-07-24 10:31:16,406][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[11318],
        [13685],
        [15096],
        [14380],
        [14074],
        [14229],
        [14585],
        [14689],
        [14562],
        [14036],
        [13899],
        [13741],
        [13908],
        [13752],
        [14039]], device='cuda:0')
[2024-07-24 10:31:16,408][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[ 6780],
        [ 5511],
        [ 3620],
        [ 5708],
        [ 8670],
        [12746],
        [ 8798],
        [ 6893],
        [ 6232],
        [ 8109],
        [ 9146],
        [10489],
        [13721],
        [ 8026],
        [ 8411]], device='cuda:0')
[2024-07-24 10:31:16,410][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[18051],
        [15173],
        [15472],
        [16580],
        [17145],
        [18140],
        [18757],
        [17779],
        [17877],
        [20071],
        [25696],
        [28798],
        [28360],
        [28829],
        [20511]], device='cuda:0')
[2024-07-24 10:31:16,411][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[26053],
        [33210],
        [37874],
        [43008],
        [43561],
        [42080],
        [39058],
        [38350],
        [35969],
        [37141],
        [40634],
        [24722],
        [32716],
        [26788],
        [36746]], device='cuda:0')
[2024-07-24 10:31:16,413][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[15740],
        [16587],
        [18750],
        [19928],
        [20237],
        [20316],
        [20300],
        [20828],
        [20761],
        [20643],
        [20640],
        [20294],
        [20060],
        [20102],
        [19887]], device='cuda:0')
[2024-07-24 10:31:16,415][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[29741],
        [25538],
        [19703],
        [17427],
        [16578],
        [16446],
        [16694],
        [17533],
        [18453],
        [19010],
        [18627],
        [18742],
        [18664],
        [18607],
        [18544]], device='cuda:0')
[2024-07-24 10:31:16,417][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[43124],
        [34560],
        [36422],
        [37276],
        [37076],
        [37122],
        [37051],
        [36917],
        [36881],
        [36532],
        [36544],
        [37560],
        [37073],
        [36738],
        [36365]], device='cuda:0')
[2024-07-24 10:31:16,418][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[29486],
        [28349],
        [30294],
        [28085],
        [27636],
        [26515],
        [26089],
        [25995],
        [25706],
        [25302],
        [24835],
        [24648],
        [24605],
        [25219],
        [24693]], device='cuda:0')
[2024-07-24 10:31:16,420][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[17967],
        [45604],
        [45993],
        [44950],
        [44108],
        [44172],
        [44526],
        [44275],
        [44631],
        [43185],
        [31583],
        [27609],
        [30560],
        [29583],
        [42096]], device='cuda:0')
[2024-07-24 10:31:16,422][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[  262],
        [14928],
        [12055],
        [12023],
        [11134],
        [12520],
        [11606],
        [11666],
        [11219],
        [ 9381],
        [ 7541],
        [ 6759],
        [ 6624],
        [ 7253],
        [ 5139]], device='cuda:0')
[2024-07-24 10:31:16,423][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[38214],
        [33706],
        [24870],
        [21729],
        [18850],
        [17429],
        [17329],
        [17097],
        [17303],
        [18655],
        [18415],
        [18333],
        [17287],
        [17248],
        [17420]], device='cuda:0')
[2024-07-24 10:31:16,425][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[5126],
        [2790],
        [3049],
        [3353],
        [3033],
        [2716],
        [2616],
        [3874],
        [4870],
        [3775],
        [3726],
        [4197],
        [2702],
        [2443],
        [2699]], device='cuda:0')
[2024-07-24 10:31:16,426][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 8003],
        [19748],
        [17162],
        [19217],
        [14360],
        [23283],
        [23660],
        [16914],
        [14241],
        [24357],
        [25217],
        [16287],
        [18789],
        [23215],
        [26564]], device='cuda:0')
[2024-07-24 10:31:16,428][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[43954],
        [44651],
        [36043],
        [44940],
        [43526],
        [45465],
        [45612],
        [45175],
        [44082],
        [44230],
        [43804],
        [45357],
        [35333],
        [44485],
        [44478]], device='cuda:0')
[2024-07-24 10:31:16,430][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[ 2303],
        [ 8303],
        [ 7640],
        [ 8317],
        [ 9187],
        [ 9569],
        [ 8424],
        [ 9157],
        [ 8368],
        [ 9850],
        [10577],
        [11820],
        [12233],
        [13122],
        [ 9462]], device='cuda:0')
[2024-07-24 10:31:16,431][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[15578],
        [ 3838],
        [ 3758],
        [ 7402],
        [ 8888],
        [ 8480],
        [ 8537],
        [ 8977],
        [ 8869],
        [ 8454],
        [ 4272],
        [ 4971],
        [ 4340],
        [ 2927],
        [ 4983]], device='cuda:0')
[2024-07-24 10:31:16,433][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[ 9960],
        [11175],
        [14643],
        [ 9545],
        [ 9566],
        [10151],
        [11518],
        [10780],
        [11067],
        [11584],
        [10426],
        [10610],
        [10683],
        [14289],
        [15947]], device='cuda:0')
[2024-07-24 10:31:16,434][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[27412],
        [27089],
        [28557],
        [29855],
        [30812],
        [31066],
        [31267],
        [30874],
        [30934],
        [31239],
        [31166],
        [30970],
        [31031],
        [31114],
        [30925]], device='cuda:0')
[2024-07-24 10:31:16,436][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[4839],
        [5096],
        [8080],
        [7097],
        [5849],
        [5868],
        [6005],
        [6101],
        [6026],
        [5855],
        [5859],
        [5973],
        [6529],
        [6521],
        [6334]], device='cuda:0')
[2024-07-24 10:31:16,438][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[ 6804],
        [10961],
        [15444],
        [10111],
        [ 9309],
        [ 9823],
        [ 9515],
        [ 9143],
        [ 9254],
        [ 9420],
        [ 8475],
        [ 7973],
        [ 6407],
        [ 8652],
        [ 6521]], device='cuda:0')
[2024-07-24 10:31:16,439][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[13570],
        [ 1833],
        [ 1810],
        [ 5417],
        [ 5689],
        [ 5719],
        [ 5598],
        [ 5776],
        [ 5436],
        [ 5690],
        [ 6987],
        [ 7462],
        [ 7065],
        [ 5101],
        [ 5956]], device='cuda:0')
[2024-07-24 10:31:16,441][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[14484],
        [ 1965],
        [ 2150],
        [ 8298],
        [ 9749],
        [10162],
        [10421],
        [10189],
        [10476],
        [ 9408],
        [ 7742],
        [ 7746],
        [ 7974],
        [ 8233],
        [ 4634]], device='cuda:0')
[2024-07-24 10:31:16,443][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[10027],
        [ 6551],
        [ 5648],
        [ 5778],
        [ 6448],
        [ 6419],
        [ 7219],
        [ 6767],
        [ 7346],
        [ 7656],
        [ 7162],
        [ 7657],
        [ 7701],
        [ 7123],
        [ 7819]], device='cuda:0')
[2024-07-24 10:31:16,444][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[15712],
        [17190],
        [21375],
        [36859],
        [40897],
        [41185],
        [41293],
        [42400],
        [40364],
        [37001],
        [35678],
        [32544],
        [33861],
        [26896],
        [26798]], device='cuda:0')
[2024-07-24 10:31:16,446][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[4912],
        [4993],
        [4725],
        [7789],
        [8366],
        [8870],
        [8603],
        [8609],
        [8403],
        [7896],
        [6986],
        [7198],
        [7519],
        [6910],
        [7523]], device='cuda:0')
[2024-07-24 10:31:16,447][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[31456],
        [38133],
        [40042],
        [33744],
        [32320],
        [32086],
        [31204],
        [32072],
        [32447],
        [32115],
        [34084],
        [33208],
        [34942],
        [34152],
        [33930]], device='cuda:0')
[2024-07-24 10:31:16,449][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[42290],
        [47697],
        [37835],
        [39054],
        [37997],
        [27154],
        [30713],
        [27106],
        [28844],
        [29636],
        [28755],
        [31469],
        [23903],
        [28864],
        [29465]], device='cuda:0')
[2024-07-24 10:31:16,451][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[42366],
        [42366],
        [42366],
        [42366],
        [42366],
        [42366],
        [42366],
        [42366],
        [42366],
        [42366],
        [42366],
        [42366],
        [42366],
        [42366],
        [42366]], device='cuda:0')
[2024-07-24 10:31:16,511][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:31:16,513][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:16,514][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:16,516][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:16,517][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:16,519][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:16,520][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:16,522][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:16,523][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:16,524][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:16,524][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:16,525][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:16,526][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:16,527][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.3799, 0.6201], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:16,528][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.2089, 0.7911], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:16,530][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.1893, 0.8107], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:16,531][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0179, 0.9821], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:16,533][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.9880, 0.0120], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:16,535][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0477, 0.9523], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:16,536][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.2894, 0.7106], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:16,538][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0016, 0.9984], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:16,539][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.4447, 0.5553], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:16,541][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.6820, 0.3180], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:16,542][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.1959, 0.8041], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:16,544][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [,] are: tensor([1.6457e-07, 1.0000e+00], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:16,545][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Melissa] are: tensor([0.1809, 0.3126, 0.5065], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:16,547][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Melissa] are: tensor([0.1289, 0.4566, 0.4145], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:16,548][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Melissa] are: tensor([0.0972, 0.5515, 0.3513], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:16,550][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Melissa] are: tensor([0.0494, 0.5076, 0.4431], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:16,551][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Melissa] are: tensor([0.9929, 0.0033, 0.0038], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:16,552][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Melissa] are: tensor([0.0419, 0.8701, 0.0880], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:16,552][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Melissa] are: tensor([0.1244, 0.2278, 0.6478], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:16,553][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Melissa] are: tensor([0.0008, 0.5924, 0.4069], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:16,554][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Melissa] are: tensor([0.2368, 0.2428, 0.5203], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:16,556][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Melissa] are: tensor([0.4727, 0.2962, 0.2310], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:16,557][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Melissa] are: tensor([0.0916, 0.3984, 0.5101], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:16,558][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Melissa] are: tensor([8.7497e-11, 9.9924e-01, 7.6251e-04], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:16,560][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.1440, 0.2098, 0.3890, 0.2572], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:16,561][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0745, 0.3021, 0.3025, 0.3209], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:16,563][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0889, 0.4569, 0.1461, 0.3081], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:16,565][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0143, 0.1261, 0.1456, 0.7139], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:16,566][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.9705, 0.0043, 0.0052, 0.0200], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:16,568][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0658, 0.4955, 0.0553, 0.3834], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:16,569][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.1006, 0.1233, 0.4289, 0.3471], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:16,571][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ and] are: tensor([2.5474e-04, 1.9569e-01, 8.0652e-02, 7.2341e-01], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:16,572][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.2134, 0.1658, 0.3979, 0.2229], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:16,574][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.5833, 0.1598, 0.1619, 0.0950], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:16,575][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0693, 0.2744, 0.3479, 0.3085], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:16,577][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ and] are: tensor([9.8108e-11, 2.8332e-01, 7.4386e-02, 6.4230e-01], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:16,578][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Benjamin] are: tensor([0.0945, 0.1517, 0.2950, 0.2517, 0.2071], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:16,579][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Benjamin] are: tensor([0.0706, 0.2380, 0.2537, 0.2744, 0.1634], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:16,580][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Benjamin] are: tensor([0.0378, 0.2839, 0.1763, 0.2296, 0.2725], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:16,581][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Benjamin] are: tensor([0.0081, 0.0732, 0.0679, 0.6813, 0.1695], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:16,581][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Benjamin] are: tensor([0.9786, 0.0044, 0.0046, 0.0099, 0.0025], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:16,583][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Benjamin] are: tensor([0.0265, 0.2626, 0.0277, 0.5456, 0.1376], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:16,584][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Benjamin] are: tensor([0.0670, 0.1019, 0.3339, 0.2843, 0.2129], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:16,585][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Benjamin] are: tensor([1.5475e-04, 1.6664e-01, 9.7378e-02, 4.9131e-01, 2.4452e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:16,587][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Benjamin] are: tensor([0.1777, 0.1327, 0.2864, 0.1834, 0.2198], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:16,588][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Benjamin] are: tensor([0.3037, 0.1504, 0.1481, 0.1451, 0.2527], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:16,590][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Benjamin] are: tensor([0.0611, 0.1991, 0.2504, 0.2228, 0.2665], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:16,591][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Benjamin] are: tensor([4.4474e-14, 1.4752e-02, 3.4459e-04, 9.8347e-01, 1.4284e-03],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:16,593][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.0813, 0.1358, 0.2146, 0.2117, 0.2385, 0.1181], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:16,595][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.0623, 0.2043, 0.1943, 0.2339, 0.1451, 0.1601], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:16,596][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.0387, 0.2348, 0.1206, 0.2107, 0.1786, 0.2165], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:16,597][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ had] are: tensor([4.0649e-04, 7.2528e-02, 1.0407e-01, 5.2628e-01, 2.5380e-01, 4.2906e-02],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:16,599][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.9712, 0.0030, 0.0050, 0.0151, 0.0026, 0.0032], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:16,601][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.0068, 0.2260, 0.0400, 0.5204, 0.1914, 0.0154], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:16,602][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.0308, 0.0736, 0.2363, 0.2189, 0.1684, 0.2720], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:16,603][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ had] are: tensor([7.4088e-05, 1.0780e-01, 6.7917e-02, 4.5892e-01, 2.1965e-01, 1.4564e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:16,605][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.1321, 0.0973, 0.2436, 0.1358, 0.2049, 0.1863], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:16,607][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.1582, 0.1220, 0.1334, 0.1291, 0.4027, 0.0546], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:16,607][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.0441, 0.1540, 0.2065, 0.1755, 0.2269, 0.1930], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:16,608][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ had] are: tensor([8.8697e-13, 2.1183e-02, 2.0426e-03, 7.9249e-01, 1.8426e-01, 1.6195e-05],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:16,609][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0422, 0.1144, 0.1937, 0.1675, 0.2314, 0.1621, 0.0888],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:16,610][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0411, 0.1728, 0.1715, 0.1917, 0.1296, 0.1497, 0.1436],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:16,611][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0388, 0.2047, 0.0962, 0.1577, 0.1221, 0.2438, 0.1368],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:16,612][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ a] are: tensor([2.6889e-04, 9.9361e-02, 8.1061e-02, 5.3185e-01, 2.0060e-01, 8.0282e-02,
        6.5716e-03], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:16,614][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.8379, 0.0081, 0.0247, 0.0406, 0.0117, 0.0107, 0.0663],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:16,616][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0010, 0.1441, 0.0740, 0.4912, 0.2492, 0.0340, 0.0065],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:16,617][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0158, 0.0515, 0.2003, 0.1690, 0.1337, 0.2415, 0.1882],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:16,618][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ a] are: tensor([4.9751e-05, 1.3280e-01, 5.5323e-02, 4.9978e-01, 1.5269e-01, 1.5134e-01,
        8.0127e-03], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:16,620][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0978, 0.0772, 0.2460, 0.1211, 0.1935, 0.1820, 0.0823],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:16,622][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0527, 0.0818, 0.1073, 0.1081, 0.5227, 0.0675, 0.0598],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:16,623][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0315, 0.1271, 0.1840, 0.1511, 0.2086, 0.1689, 0.1289],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:16,624][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ a] are: tensor([3.1038e-14, 1.1800e-02, 6.4926e-04, 8.4925e-01, 1.3780e-01, 5.0293e-04,
        5.9690e-10], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:16,626][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.0361, 0.1044, 0.1412, 0.1952, 0.1987, 0.1353, 0.1093, 0.0798],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:16,628][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ long] are: tensor([0.0429, 0.1461, 0.1459, 0.1701, 0.1064, 0.1173, 0.1328, 0.1385],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:16,630][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.0275, 0.1388, 0.0889, 0.1432, 0.1580, 0.2224, 0.1087, 0.1125],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:16,631][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ long] are: tensor([0.0008, 0.1053, 0.0548, 0.6089, 0.1616, 0.0447, 0.0051, 0.0187],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:16,633][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.9373, 0.0031, 0.0059, 0.0170, 0.0021, 0.0032, 0.0299, 0.0016],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:16,634][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ long] are: tensor([0.0074, 0.1536, 0.0418, 0.5923, 0.1596, 0.0207, 0.0129, 0.0118],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:16,635][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.0257, 0.0531, 0.1638, 0.1418, 0.1142, 0.1822, 0.1622, 0.1571],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:16,636][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ long] are: tensor([1.6478e-04, 1.1289e-01, 6.4372e-02, 4.1041e-01, 1.7390e-01, 1.2239e-01,
        9.6752e-03, 1.0620e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:16,637][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.1126, 0.0809, 0.1725, 0.1068, 0.1397, 0.1417, 0.0854, 0.1604],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:16,638][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ long] are: tensor([0.1320, 0.0999, 0.1080, 0.1237, 0.2922, 0.0736, 0.0605, 0.1102],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:16,639][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.0329, 0.1188, 0.1584, 0.1313, 0.1621, 0.1374, 0.1127, 0.1463],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:16,640][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ long] are: tensor([6.8390e-13, 4.6642e-02, 4.6447e-04, 9.0662e-01, 4.5447e-02, 8.1642e-04,
        2.1624e-09, 1.2354e-05], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:16,642][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.0324, 0.0872, 0.1597, 0.1353, 0.1364, 0.1532, 0.0974, 0.1379, 0.0604],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:16,644][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([0.0355, 0.1246, 0.1324, 0.1468, 0.0862, 0.1056, 0.1189, 0.1298, 0.1201],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:16,645][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.0223, 0.1261, 0.0677, 0.1217, 0.1282, 0.1777, 0.0976, 0.1124, 0.1462],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:16,647][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([0.0007, 0.0790, 0.0810, 0.5321, 0.2157, 0.0482, 0.0045, 0.0230, 0.0156],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:16,649][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.9313, 0.0037, 0.0047, 0.0137, 0.0041, 0.0028, 0.0339, 0.0011, 0.0048],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:16,650][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([0.0042, 0.1761, 0.0351, 0.5684, 0.1422, 0.0227, 0.0099, 0.0240, 0.0173],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:16,652][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.0181, 0.0414, 0.1387, 0.1211, 0.1017, 0.1715, 0.1518, 0.1472, 0.1085],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:16,653][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([1.8414e-04, 1.1708e-01, 5.8765e-02, 3.7443e-01, 1.5683e-01, 1.1761e-01,
        9.0114e-03, 1.0340e-01, 6.2694e-02], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:16,655][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.0910, 0.0596, 0.1500, 0.0861, 0.1203, 0.1141, 0.0676, 0.1309, 0.1803],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:16,657][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.1041, 0.0755, 0.1109, 0.1072, 0.2835, 0.0555, 0.0584, 0.1612, 0.0439],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:16,658][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.0284, 0.1019, 0.1409, 0.1108, 0.1489, 0.1188, 0.0974, 0.1297, 0.1232],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:16,659][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([2.1774e-11, 3.9770e-02, 1.2611e-03, 8.9586e-01, 5.9931e-02, 1.6166e-03,
        1.5721e-08, 1.5367e-03, 2.5255e-05], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:16,661][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0365, 0.0672, 0.1505, 0.1032, 0.1412, 0.1118, 0.0903, 0.1360, 0.0793,
        0.0840], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:16,663][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0290, 0.1077, 0.1112, 0.1237, 0.0818, 0.0988, 0.1007, 0.1103, 0.1123,
        0.1245], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:16,663][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0300, 0.1327, 0.0568, 0.1129, 0.0760, 0.1413, 0.0938, 0.0892, 0.1191,
        0.1482], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:16,664][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0020, 0.0556, 0.0791, 0.4667, 0.2090, 0.0588, 0.0062, 0.0297, 0.0253,
        0.0676], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:16,665][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.8994, 0.0041, 0.0087, 0.0196, 0.0035, 0.0048, 0.0334, 0.0016, 0.0058,
        0.0191], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:16,666][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0153, 0.1601, 0.0294, 0.4747, 0.1133, 0.0185, 0.0111, 0.0156, 0.0146,
        0.1474], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:16,668][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0159, 0.0321, 0.1149, 0.1008, 0.0849, 0.1394, 0.1153, 0.1323, 0.0922,
        0.1721], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:16,669][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [,] are: tensor([1.4624e-04, 9.4749e-02, 4.3899e-02, 3.3256e-01, 1.1442e-01, 8.7654e-02,
        6.2377e-03, 6.2162e-02, 3.4444e-02, 2.2372e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:16,671][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0615, 0.0530, 0.1560, 0.0796, 0.1217, 0.1088, 0.0501, 0.1369, 0.1892,
        0.0433], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:16,672][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.2198, 0.0880, 0.1056, 0.0767, 0.2207, 0.0467, 0.0321, 0.1117, 0.0445,
        0.0544], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:16,674][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0234, 0.0911, 0.1228, 0.1045, 0.1300, 0.1124, 0.0871, 0.1206, 0.1117,
        0.0965], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:16,675][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [,] are: tensor([1.4500e-10, 1.2202e-02, 3.2234e-03, 1.3779e-01, 8.0929e-01, 2.2308e-04,
        8.6932e-10, 4.1583e-04, 1.6495e-04, 3.6693e-02], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:16,677][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0414, 0.0675, 0.1444, 0.0866, 0.1409, 0.0965, 0.0786, 0.1043, 0.0722,
        0.0879, 0.0797], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:16,679][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0230, 0.0983, 0.1037, 0.1061, 0.0726, 0.0826, 0.0924, 0.0974, 0.0964,
        0.1168, 0.1106], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:16,680][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0221, 0.1281, 0.0435, 0.0970, 0.0578, 0.1242, 0.0881, 0.0934, 0.1103,
        0.1544, 0.0813], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:16,682][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0018, 0.0707, 0.0797, 0.3210, 0.2105, 0.0521, 0.0053, 0.0240, 0.0204,
        0.0745, 0.1399], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:16,684][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.8853, 0.0042, 0.0080, 0.0230, 0.0034, 0.0038, 0.0303, 0.0015, 0.0046,
        0.0184, 0.0175], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:16,685][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0157, 0.1781, 0.0261, 0.2307, 0.1088, 0.0167, 0.0097, 0.0107, 0.0123,
        0.2088, 0.1824], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:16,687][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0144, 0.0293, 0.1055, 0.0896, 0.0753, 0.1275, 0.1057, 0.1174, 0.0835,
        0.1601, 0.0917], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:16,689][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ and] are: tensor([1.4693e-04, 7.9807e-02, 3.9744e-02, 2.7304e-01, 9.3858e-02, 6.4220e-02,
        5.4707e-03, 4.4358e-02, 2.4735e-02, 1.4484e-01, 2.2978e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:16,690][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0524, 0.0495, 0.1503, 0.0745, 0.1125, 0.1120, 0.0504, 0.1271, 0.1891,
        0.0426, 0.0395], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:16,691][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.2564, 0.0765, 0.0957, 0.0614, 0.1773, 0.0399, 0.0263, 0.1079, 0.0314,
        0.0586, 0.0686], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:16,692][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0216, 0.0846, 0.1121, 0.0974, 0.1145, 0.1017, 0.0805, 0.1060, 0.1007,
        0.0876, 0.0933], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:16,693][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ and] are: tensor([3.9276e-10, 3.5775e-02, 2.8964e-03, 1.3752e-01, 4.1205e-01, 7.0342e-05,
        4.2114e-10, 4.5000e-05, 2.9103e-05, 6.1119e-02, 3.5049e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:16,694][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.0322, 0.0673, 0.0949, 0.1242, 0.0910, 0.1138, 0.0837, 0.0734, 0.0407,
        0.1116, 0.1036, 0.0636], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:16,695][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([0.0246, 0.0891, 0.0924, 0.1044, 0.0624, 0.0762, 0.0855, 0.0903, 0.0832,
        0.1059, 0.1072, 0.0788], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:16,697][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.0117, 0.1032, 0.0576, 0.0824, 0.0870, 0.1269, 0.0641, 0.0779, 0.1131,
        0.1252, 0.0669, 0.0840], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:16,699][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([0.0005, 0.0426, 0.0504, 0.3659, 0.1590, 0.0314, 0.0034, 0.0256, 0.0202,
        0.0746, 0.1987, 0.0277], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:16,700][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([8.9553e-01, 3.3422e-03, 8.0444e-03, 1.8444e-02, 3.2694e-03, 4.1557e-03,
        3.0997e-02, 1.1783e-03, 3.1602e-03, 1.6929e-02, 1.4244e-02, 7.0145e-04],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:16,702][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([0.0039, 0.1013, 0.0184, 0.3313, 0.0685, 0.0187, 0.0050, 0.0100, 0.0108,
        0.1756, 0.2225, 0.0340], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:16,703][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.0216, 0.0275, 0.0886, 0.0858, 0.0670, 0.1100, 0.0946, 0.1013, 0.0745,
        0.1476, 0.0891, 0.0925], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:16,705][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([8.8895e-05, 5.2713e-02, 2.8602e-02, 2.0389e-01, 7.0792e-02, 6.2717e-02,
        4.8112e-03, 5.7004e-02, 2.5198e-02, 1.8203e-01, 2.1647e-01, 9.5688e-02],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:16,706][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.0605, 0.0467, 0.1189, 0.0649, 0.0869, 0.0965, 0.0531, 0.1145, 0.1487,
        0.0395, 0.0394, 0.1304], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:16,708][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([0.1411, 0.0650, 0.0879, 0.0854, 0.1604, 0.0560, 0.0388, 0.0853, 0.0513,
        0.0713, 0.0760, 0.0814], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:16,710][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.0213, 0.0797, 0.1017, 0.0886, 0.1022, 0.0892, 0.0730, 0.0927, 0.0890,
        0.0792, 0.0832, 0.1002], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:16,711][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([1.5268e-11, 5.4673e-04, 1.7861e-05, 4.0397e-02, 4.8123e-03, 6.7286e-05,
        5.7426e-10, 1.9861e-05, 1.2090e-05, 2.2139e-02, 9.3132e-01, 6.7145e-04],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:16,713][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Melissa] are: tensor([0.0313, 0.0580, 0.0913, 0.0932, 0.0986, 0.0895, 0.0687, 0.0786, 0.0449,
        0.0845, 0.0846, 0.0610, 0.1158], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:16,714][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Melissa] are: tensor([0.0194, 0.0826, 0.0802, 0.0936, 0.0592, 0.0729, 0.0764, 0.0830, 0.0818,
        0.0984, 0.0935, 0.0753, 0.0839], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:16,716][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Melissa] are: tensor([0.0175, 0.1038, 0.0670, 0.0750, 0.0634, 0.0922, 0.0596, 0.0560, 0.1171,
        0.1169, 0.0611, 0.0869, 0.0834], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:16,718][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Melissa] are: tensor([0.0029, 0.0414, 0.0401, 0.3925, 0.1480, 0.0358, 0.0060, 0.0161, 0.0153,
        0.0680, 0.1523, 0.0403, 0.0414], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:16,719][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Melissa] are: tensor([9.2468e-01, 2.8028e-03, 5.9219e-03, 1.0691e-02, 3.4833e-03, 2.9997e-03,
        1.9053e-02, 9.8753e-04, 3.6549e-03, 1.1177e-02, 8.4608e-03, 3.8471e-04,
        5.7007e-03], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:16,720][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Melissa] are: tensor([0.0109, 0.1403, 0.0079, 0.3124, 0.0455, 0.0111, 0.0069, 0.0060, 0.0069,
        0.1601, 0.2331, 0.0440, 0.0148], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:16,720][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Melissa] are: tensor([0.0125, 0.0260, 0.0724, 0.0795, 0.0598, 0.1048, 0.0896, 0.0893, 0.0645,
        0.1395, 0.0825, 0.0940, 0.0855], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:16,722][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Melissa] are: tensor([1.4929e-04, 5.6173e-02, 4.6436e-02, 1.8158e-01, 1.2359e-01, 5.3405e-02,
        4.6934e-03, 3.8726e-02, 2.5821e-02, 1.4268e-01, 1.6316e-01, 7.4749e-02,
        8.8829e-02], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:16,723][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Melissa] are: tensor([0.0451, 0.0459, 0.1055, 0.0688, 0.0942, 0.0910, 0.0580, 0.0903, 0.1198,
        0.0435, 0.0450, 0.1010, 0.0918], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:16,725][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Melissa] are: tensor([0.1801, 0.0704, 0.0566, 0.0701, 0.1704, 0.0331, 0.0231, 0.0736, 0.0344,
        0.0494, 0.0638, 0.1070, 0.0680], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:16,727][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Melissa] are: tensor([0.0203, 0.0739, 0.0914, 0.0792, 0.0876, 0.0819, 0.0647, 0.0835, 0.0790,
        0.0716, 0.0752, 0.0896, 0.1021], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:16,728][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Melissa] are: tensor([5.7504e-11, 8.0542e-03, 2.9454e-06, 1.2822e-01, 3.9096e-03, 1.1179e-04,
        4.4997e-10, 1.8019e-05, 6.9815e-06, 6.7496e-02, 7.7261e-01, 1.8365e-02,
        1.2126e-03], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:16,729][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.0201, 0.0414, 0.1145, 0.0752, 0.1025, 0.0623, 0.0532, 0.1155, 0.0315,
        0.0675, 0.0619, 0.0611, 0.1336, 0.0596], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:16,731][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ said] are: tensor([0.0198, 0.0739, 0.0760, 0.0869, 0.0544, 0.0669, 0.0680, 0.0828, 0.0713,
        0.0895, 0.0902, 0.0712, 0.0818, 0.0671], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:16,733][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.0115, 0.0558, 0.0326, 0.0637, 0.0703, 0.0850, 0.0403, 0.0582, 0.0996,
        0.0827, 0.0628, 0.0721, 0.0444, 0.2209], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:16,735][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ said] are: tensor([0.0007, 0.0454, 0.0648, 0.3785, 0.1837, 0.0199, 0.0018, 0.0075, 0.0083,
        0.0395, 0.1069, 0.0141, 0.0420, 0.0869], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:16,736][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ said] are: tensor([9.0834e-01, 3.1776e-03, 5.6095e-03, 1.6127e-02, 3.1817e-03, 3.5685e-03,
        2.4620e-02, 1.0981e-03, 3.4152e-03, 1.1665e-02, 9.4889e-03, 2.7851e-04,
        3.6711e-03, 5.7553e-03], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:16,738][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ said] are: tensor([0.0131, 0.1299, 0.0172, 0.3338, 0.0682, 0.0078, 0.0044, 0.0052, 0.0059,
        0.1245, 0.1519, 0.0411, 0.0191, 0.0779], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:16,740][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.0130, 0.0239, 0.0769, 0.0667, 0.0522, 0.0883, 0.0770, 0.0809, 0.0567,
        0.1226, 0.0739, 0.0833, 0.1011, 0.0837], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:16,741][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ said] are: tensor([6.3364e-05, 5.8960e-02, 2.7477e-02, 1.8205e-01, 7.2147e-02, 5.3509e-02,
        2.8643e-03, 3.0697e-02, 1.5272e-02, 1.1453e-01, 1.4153e-01, 5.3291e-02,
        4.3463e-02, 2.0415e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:16,743][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.0672, 0.0401, 0.1097, 0.0572, 0.0900, 0.0786, 0.0352, 0.0870, 0.1196,
        0.0286, 0.0279, 0.1012, 0.0917, 0.0661], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:16,744][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ said] are: tensor([0.1846, 0.0546, 0.0557, 0.0642, 0.1215, 0.0289, 0.0220, 0.0551, 0.0347,
        0.0465, 0.0535, 0.0705, 0.0655, 0.1425], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:16,746][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.0169, 0.0619, 0.0838, 0.0716, 0.0879, 0.0767, 0.0613, 0.0798, 0.0752,
        0.0661, 0.0693, 0.0827, 0.0961, 0.0707], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:16,747][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ said] are: tensor([5.7499e-10, 1.9286e-03, 1.6077e-04, 1.7967e-01, 1.7005e-02, 1.0518e-05,
        2.1931e-10, 4.3101e-06, 1.7413e-06, 1.8210e-02, 4.9286e-01, 2.2600e-02,
        6.2889e-02, 2.0465e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:16,748][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0212, 0.0416, 0.0864, 0.0641, 0.0974, 0.0623, 0.0497, 0.0777, 0.0590,
        0.0554, 0.0573, 0.0592, 0.0977, 0.1177, 0.0532], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:16,749][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0167, 0.0710, 0.0715, 0.0789, 0.0538, 0.0579, 0.0641, 0.0694, 0.0698,
        0.0828, 0.0805, 0.0655, 0.0742, 0.0654, 0.0784], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:16,750][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0155, 0.0771, 0.0343, 0.0629, 0.0425, 0.0814, 0.0508, 0.0519, 0.0827,
        0.0926, 0.0523, 0.0752, 0.0411, 0.1749, 0.0649], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:16,752][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0044, 0.0415, 0.0337, 0.1931, 0.0775, 0.0209, 0.0037, 0.0090, 0.0110,
        0.0397, 0.0860, 0.0222, 0.0291, 0.1798, 0.2485], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:16,753][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ to] are: tensor([9.2893e-01, 2.8064e-03, 3.7260e-03, 9.7606e-03, 2.4457e-03, 1.6450e-03,
        2.0655e-02, 6.5704e-04, 2.8992e-03, 8.8288e-03, 7.4691e-03, 2.7507e-04,
        2.9693e-03, 3.4544e-03, 3.4752e-03], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:16,755][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0310, 0.0963, 0.0139, 0.2033, 0.0518, 0.0070, 0.0054, 0.0052, 0.0078,
        0.1049, 0.1350, 0.0415, 0.0220, 0.1300, 0.1449], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:16,757][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0180, 0.0192, 0.0640, 0.0585, 0.0475, 0.0774, 0.0608, 0.0744, 0.0501,
        0.1012, 0.0591, 0.0692, 0.0851, 0.0764, 0.1393], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:16,758][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ to] are: tensor([1.5642e-04, 6.1073e-02, 2.2173e-02, 1.3433e-01, 5.3808e-02, 2.9885e-02,
        2.5971e-03, 2.2806e-02, 1.3083e-02, 8.8001e-02, 1.0285e-01, 5.5325e-02,
        3.7869e-02, 1.5659e-01, 2.1945e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:16,760][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0418, 0.0340, 0.1035, 0.0545, 0.0815, 0.0761, 0.0403, 0.0858, 0.1162,
        0.0280, 0.0298, 0.1086, 0.0899, 0.0665, 0.0435], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:16,762][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.2335, 0.0455, 0.0523, 0.0357, 0.0796, 0.0215, 0.0122, 0.0545, 0.0218,
        0.0305, 0.0359, 0.0558, 0.0498, 0.1906, 0.0808], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:16,763][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0164, 0.0608, 0.0778, 0.0700, 0.0797, 0.0723, 0.0564, 0.0733, 0.0688,
        0.0617, 0.0658, 0.0785, 0.0882, 0.0641, 0.0662], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:16,765][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ to] are: tensor([1.0836e-10, 2.9136e-05, 2.5820e-06, 2.3473e-04, 3.7907e-04, 1.0554e-07,
        1.4425e-12, 1.1549e-07, 8.3582e-08, 6.1212e-05, 4.7977e-04, 1.7794e-04,
        2.9808e-04, 2.6799e-02, 9.7154e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:16,814][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:31:16,816][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:16,817][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:16,818][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:16,820][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:16,820][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:16,822][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:16,823][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:16,825][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:16,826][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:16,827][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:16,829][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:16,830][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:16,831][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0109, 0.9891], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:16,832][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0241, 0.9759], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:16,833][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.3046, 0.6954], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:16,833][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0179, 0.9821], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:16,834][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.9978, 0.0022], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:16,836][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0015, 0.9985], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:16,837][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.9255, 0.0745], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:16,839][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0016, 0.9984], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:16,840][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.9848, 0.0152], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:16,842][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.6082, 0.3918], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:16,843][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.9911, 0.0089], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:16,845][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([1.6457e-07, 1.0000e+00], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:16,846][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Melissa] are: tensor([0.0094, 0.8720, 0.1186], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:16,848][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Melissa] are: tensor([0.0247, 0.6208, 0.3545], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:16,849][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Melissa] are: tensor([0.3436, 0.4091, 0.2473], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:16,851][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Melissa] are: tensor([0.0494, 0.5076, 0.4431], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:16,853][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Melissa] are: tensor([0.9964, 0.0014, 0.0021], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:16,854][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Melissa] are: tensor([0.1964, 0.5580, 0.2456], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:16,856][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Melissa] are: tensor([0.2486, 0.7367, 0.0147], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:16,858][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Melissa] are: tensor([0.0008, 0.5924, 0.4069], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:16,858][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Melissa] are: tensor([0.9135, 0.0463, 0.0402], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:16,859][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Melissa] are: tensor([0.3920, 0.3625, 0.2455], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:16,860][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Melissa] are: tensor([0.9636, 0.0273, 0.0091], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:16,861][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Melissa] are: tensor([8.7497e-11, 9.9924e-01, 7.6251e-04], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:16,862][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0116, 0.3252, 0.0471, 0.6161], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:16,864][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0240, 0.2663, 0.1945, 0.5152], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:16,865][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.1816, 0.2177, 0.2427, 0.3581], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:16,867][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0143, 0.1261, 0.1456, 0.7139], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:16,869][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.9917, 0.0012, 0.0019, 0.0051], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:16,870][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.6031, 0.2130, 0.1004, 0.0835], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:16,872][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.4688, 0.2689, 0.2109, 0.0514], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:16,873][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([2.5474e-04, 1.9569e-01, 8.0652e-02, 7.2341e-01], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:16,875][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.8878, 0.0307, 0.0210, 0.0605], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:16,876][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.3571, 0.1654, 0.1619, 0.3156], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:16,878][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.9637, 0.0128, 0.0034, 0.0201], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:16,879][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([9.8108e-11, 2.8332e-01, 7.4386e-02, 6.4230e-01], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:16,881][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Benjamin] are: tensor([0.0039, 0.2003, 0.0406, 0.5943, 0.1609], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:16,882][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Benjamin] are: tensor([0.0105, 0.1652, 0.0888, 0.3926, 0.3429], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:16,884][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Benjamin] are: tensor([0.2948, 0.1373, 0.1362, 0.1362, 0.2954], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:16,884][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Benjamin] are: tensor([0.0081, 0.0732, 0.0679, 0.6813, 0.1695], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:16,885][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Benjamin] are: tensor([9.9175e-01, 1.8507e-03, 2.2396e-03, 3.2625e-03, 8.9839e-04],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:16,886][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Benjamin] are: tensor([0.5171, 0.0794, 0.0322, 0.1166, 0.2547], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:16,887][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Benjamin] are: tensor([0.1211, 0.2871, 0.3818, 0.1772, 0.0328], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:16,888][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Benjamin] are: tensor([1.5475e-04, 1.6664e-01, 9.7378e-02, 4.9131e-01, 2.4452e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:16,889][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Benjamin] are: tensor([0.7335, 0.0548, 0.0708, 0.1065, 0.0343], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:16,891][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Benjamin] are: tensor([0.1710, 0.1150, 0.1194, 0.3828, 0.2118], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:16,893][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Benjamin] are: tensor([0.9124, 0.0344, 0.0059, 0.0412, 0.0060], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:16,894][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Benjamin] are: tensor([4.4474e-14, 1.4752e-02, 3.4459e-04, 9.8347e-01, 1.4284e-03],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:16,895][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.0022, 0.1736, 0.0376, 0.5050, 0.2596, 0.0220], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:16,897][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.0053, 0.1110, 0.0805, 0.2601, 0.2970, 0.2461], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:16,899][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.0787, 0.1891, 0.1454, 0.1892, 0.3399, 0.0578], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:16,900][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([4.0649e-04, 7.2528e-02, 1.0407e-01, 5.2628e-01, 2.5380e-01, 4.2906e-02],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:16,901][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([9.8904e-01, 1.2490e-03, 2.5626e-03, 4.8727e-03, 9.5337e-04, 1.3240e-03],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:16,902][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([1.3052e-04, 4.8814e-02, 9.5143e-02, 9.7777e-02, 7.5630e-01, 1.8321e-03],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:16,904][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.3378, 0.1470, 0.2322, 0.1512, 0.1094, 0.0223], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:16,905][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([7.4088e-05, 1.0780e-01, 6.7917e-02, 4.5892e-01, 2.1965e-01, 1.4564e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:16,907][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.7687, 0.0352, 0.0292, 0.0840, 0.0384, 0.0445], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:16,908][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.0424, 0.1227, 0.1187, 0.3617, 0.3033, 0.0511], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:16,910][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.9187, 0.0217, 0.0066, 0.0314, 0.0061, 0.0156], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:16,911][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([8.8697e-13, 2.1183e-02, 2.0426e-03, 7.9249e-01, 1.8426e-01, 1.6195e-05],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:16,911][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([1.2312e-04, 1.0924e-01, 3.0100e-02, 4.6632e-01, 3.2794e-01, 6.3086e-02,
        3.1957e-03], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:16,912][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0004, 0.1253, 0.0616, 0.1909, 0.2738, 0.2297, 0.1184],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:16,913][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0397, 0.1649, 0.1721, 0.1484, 0.2988, 0.0686, 0.1076],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:16,914][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([2.6889e-04, 9.9361e-02, 8.1061e-02, 5.3185e-01, 2.0060e-01, 8.0282e-02,
        6.5716e-03], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:16,916][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.9288, 0.0039, 0.0118, 0.0156, 0.0043, 0.0046, 0.0308],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:16,917][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([1.0615e-04, 2.1385e-02, 9.5733e-02, 6.8730e-02, 8.0951e-01, 1.2394e-03,
        3.2988e-03], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:16,919][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.2552, 0.2483, 0.0793, 0.1991, 0.0687, 0.1303, 0.0189],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:16,920][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([4.9751e-05, 1.3280e-01, 5.5323e-02, 4.9978e-01, 1.5269e-01, 1.5134e-01,
        8.0127e-03], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:16,921][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.2664, 0.0859, 0.0745, 0.1525, 0.0806, 0.1309, 0.2092],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:16,923][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0107, 0.0969, 0.1192, 0.3192, 0.2988, 0.1238, 0.0313],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:16,925][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.6620, 0.0409, 0.0253, 0.0611, 0.0275, 0.0431, 0.1400],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:16,926][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([3.1038e-14, 1.1800e-02, 6.4926e-04, 8.4925e-01, 1.3780e-01, 5.0293e-04,
        5.9690e-10], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:16,928][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.0010, 0.1437, 0.0162, 0.6034, 0.1583, 0.0578, 0.0058, 0.0139],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:16,929][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([0.0027, 0.0836, 0.0569, 0.1739, 0.2130, 0.1838, 0.1744, 0.1117],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:16,931][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([0.0863, 0.0911, 0.1075, 0.1112, 0.2597, 0.0356, 0.1004, 0.2083],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:16,933][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([0.0008, 0.1053, 0.0548, 0.6089, 0.1616, 0.0447, 0.0051, 0.0187],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:16,934][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([9.8054e-01, 1.0462e-03, 2.1027e-03, 4.4774e-03, 5.6845e-04, 9.2043e-04,
        9.8800e-03, 4.6431e-04], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:16,936][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([0.0060, 0.0628, 0.0726, 0.1381, 0.6048, 0.0031, 0.0282, 0.0843],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:16,937][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.2808, 0.1746, 0.1318, 0.1913, 0.0646, 0.0483, 0.0974, 0.0110],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:16,937][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([1.6478e-04, 1.1289e-01, 6.4372e-02, 4.1041e-01, 1.7390e-01, 1.2239e-01,
        9.6752e-03, 1.0620e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:16,938][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.7294, 0.0191, 0.0139, 0.0436, 0.0187, 0.0270, 0.1281, 0.0203],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:16,939][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([0.0411, 0.0898, 0.0784, 0.3985, 0.2428, 0.0920, 0.0303, 0.0272],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:16,940][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.9156, 0.0085, 0.0038, 0.0150, 0.0025, 0.0050, 0.0469, 0.0028],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:16,942][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([6.8390e-13, 4.6642e-02, 4.6447e-04, 9.0662e-01, 4.5447e-02, 8.1642e-04,
        2.1624e-09, 1.2354e-05], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:16,943][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.0007, 0.1937, 0.0226, 0.5465, 0.1310, 0.0645, 0.0045, 0.0226, 0.0139],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:16,945][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([0.0027, 0.0755, 0.0700, 0.1507, 0.1962, 0.2005, 0.1025, 0.1377, 0.0643],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:16,947][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([0.0280, 0.0778, 0.1652, 0.0730, 0.1830, 0.0359, 0.0599, 0.3184, 0.0587],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:16,948][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([0.0007, 0.0790, 0.0810, 0.5321, 0.2157, 0.0482, 0.0045, 0.0230, 0.0156],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:16,950][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([9.7511e-01, 1.3684e-03, 1.7635e-03, 4.3752e-03, 1.3791e-03, 1.0113e-03,
        1.3002e-02, 3.2360e-04, 1.6686e-03], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:16,951][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([0.0042, 0.0609, 0.0265, 0.1930, 0.2963, 0.0008, 0.0081, 0.0656, 0.3445],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:16,953][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.0720, 0.2760, 0.0752, 0.1896, 0.0374, 0.2296, 0.0455, 0.0637, 0.0108],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:16,954][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([1.8414e-04, 1.1708e-01, 5.8765e-02, 3.7443e-01, 1.5683e-01, 1.1761e-01,
        9.0114e-03, 1.0340e-01, 6.2694e-02], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:16,956][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([0.5900, 0.0228, 0.0230, 0.0617, 0.0357, 0.0355, 0.1524, 0.0356, 0.0433],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:16,958][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([0.0352, 0.0681, 0.0962, 0.3559, 0.2478, 0.0797, 0.0353, 0.0587, 0.0231],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:16,959][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.8406, 0.0163, 0.0068, 0.0220, 0.0102, 0.0073, 0.0842, 0.0064, 0.0063],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:16,961][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([2.1774e-11, 3.9770e-02, 1.2611e-03, 8.9586e-01, 5.9931e-02, 1.6166e-03,
        1.5721e-08, 1.5367e-03, 2.5255e-05], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:16,962][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0030, 0.1459, 0.0275, 0.4186, 0.1799, 0.0554, 0.0070, 0.0229, 0.0143,
        0.1256], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:16,963][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0064, 0.0775, 0.0666, 0.1448, 0.1589, 0.1841, 0.0993, 0.1176, 0.0877,
        0.0570], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:16,963][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0200, 0.1051, 0.1253, 0.0948, 0.2267, 0.0432, 0.0458, 0.2823, 0.0355,
        0.0214], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:16,964][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0020, 0.0556, 0.0791, 0.4667, 0.2090, 0.0588, 0.0062, 0.0297, 0.0253,
        0.0676], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:16,965][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([9.6574e-01, 1.4278e-03, 3.1781e-03, 5.7671e-03, 9.8872e-04, 1.5414e-03,
        1.1442e-02, 4.6797e-04, 1.7988e-03, 7.6491e-03], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:16,967][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0027, 0.0246, 0.0372, 0.0531, 0.3171, 0.0015, 0.0059, 0.0945, 0.2829,
        0.1807], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:16,968][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.2715, 0.0453, 0.1224, 0.0702, 0.0616, 0.1224, 0.0665, 0.0683, 0.1528,
        0.0190], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:16,970][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([1.4624e-04, 9.4749e-02, 4.3899e-02, 3.3256e-01, 1.1442e-01, 8.7654e-02,
        6.2377e-03, 6.2162e-02, 3.4444e-02, 2.2372e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:16,971][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.5441, 0.0274, 0.0240, 0.0528, 0.0291, 0.0423, 0.1414, 0.0379, 0.0490,
        0.0520], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:16,973][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0673, 0.0845, 0.0938, 0.2861, 0.2273, 0.0699, 0.0310, 0.0351, 0.0246,
        0.0804], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:16,975][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.8593, 0.0115, 0.0043, 0.0177, 0.0033, 0.0092, 0.0625, 0.0055, 0.0046,
        0.0222], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:16,976][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([1.4500e-10, 1.2202e-02, 3.2234e-03, 1.3779e-01, 8.0929e-01, 2.2308e-04,
        8.6932e-10, 4.1583e-04, 1.6495e-04, 3.6693e-02], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:16,978][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0035, 0.1279, 0.0234, 0.3004, 0.1720, 0.0417, 0.0059, 0.0139, 0.0098,
        0.1182, 0.1833], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:16,979][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0051, 0.0588, 0.0538, 0.1064, 0.1474, 0.1773, 0.0806, 0.0916, 0.0687,
        0.0537, 0.1566], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:16,981][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0160, 0.0536, 0.1495, 0.0907, 0.2198, 0.0382, 0.0549, 0.2531, 0.0516,
        0.0231, 0.0496], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:16,983][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0018, 0.0707, 0.0797, 0.3210, 0.2105, 0.0521, 0.0053, 0.0240, 0.0204,
        0.0745, 0.1399], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:16,984][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([9.6118e-01, 1.4561e-03, 2.9124e-03, 6.6742e-03, 9.3759e-04, 1.1855e-03,
        1.0399e-02, 4.2771e-04, 1.4302e-03, 7.0723e-03, 6.3286e-03],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:16,986][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.4646, 0.0224, 0.0122, 0.0170, 0.0662, 0.0007, 0.0053, 0.0209, 0.0541,
        0.0939, 0.2427], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:16,987][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.1414, 0.1134, 0.1061, 0.0199, 0.1041, 0.0907, 0.0736, 0.0993, 0.1956,
        0.0424, 0.0136], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:16,988][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([1.4693e-04, 7.9807e-02, 3.9744e-02, 2.7304e-01, 9.3858e-02, 6.4220e-02,
        5.4707e-03, 4.4358e-02, 2.4735e-02, 1.4484e-01, 2.2978e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:16,989][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.5443, 0.0250, 0.0173, 0.0454, 0.0188, 0.0378, 0.1384, 0.0287, 0.0386,
        0.0487, 0.0571], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:16,990][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0668, 0.0812, 0.0831, 0.2271, 0.1938, 0.0589, 0.0276, 0.0322, 0.0157,
        0.0907, 0.1229], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:16,991][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.8624, 0.0103, 0.0030, 0.0175, 0.0024, 0.0073, 0.0524, 0.0041, 0.0031,
        0.0172, 0.0203], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:16,992][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([3.9276e-10, 3.5775e-02, 2.8964e-03, 1.3752e-01, 4.1205e-01, 7.0342e-05,
        4.2114e-10, 4.5000e-05, 2.9103e-05, 6.1119e-02, 3.5049e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:16,994][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.0013, 0.0781, 0.0118, 0.3285, 0.0973, 0.0277, 0.0054, 0.0187, 0.0188,
        0.1244, 0.2414, 0.0467], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:16,995][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([0.0025, 0.0494, 0.0374, 0.0997, 0.1068, 0.1369, 0.0786, 0.1044, 0.0603,
        0.0466, 0.1617, 0.1156], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:16,997][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([0.0887, 0.0497, 0.1516, 0.0815, 0.2160, 0.0220, 0.0496, 0.1422, 0.0310,
        0.0168, 0.0445, 0.1065], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:16,999][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([0.0005, 0.0426, 0.0504, 0.3659, 0.1590, 0.0314, 0.0034, 0.0256, 0.0202,
        0.0746, 0.1987, 0.0277], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:17,000][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([9.5697e-01, 1.5726e-03, 3.4404e-03, 6.7427e-03, 1.1121e-03, 1.6067e-03,
        1.2015e-02, 4.2294e-04, 1.1662e-03, 8.1213e-03, 6.5217e-03, 3.0531e-04],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:17,001][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([3.7699e-03, 5.9542e-03, 2.6103e-03, 1.6913e-02, 2.1536e-02, 1.7724e-04,
        6.7757e-04, 4.2809e-03, 1.7799e-02, 3.7098e-02, 2.1601e-01, 6.7318e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:17,003][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.0532, 0.1944, 0.0272, 0.0705, 0.1070, 0.1082, 0.0482, 0.0653, 0.1944,
        0.0675, 0.0545, 0.0096], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:17,004][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([8.8895e-05, 5.2713e-02, 2.8602e-02, 2.0389e-01, 7.0792e-02, 6.2717e-02,
        4.8112e-03, 5.7004e-02, 2.5198e-02, 1.8203e-01, 2.1647e-01, 9.5688e-02],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:17,006][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.5714, 0.0228, 0.0153, 0.0397, 0.0166, 0.0323, 0.1252, 0.0257, 0.0390,
        0.0391, 0.0450, 0.0279], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:17,008][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([0.0301, 0.0569, 0.0684, 0.2745, 0.1437, 0.0760, 0.0244, 0.0262, 0.0242,
        0.0979, 0.1217, 0.0561], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:17,009][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([0.8573, 0.0134, 0.0034, 0.0168, 0.0041, 0.0052, 0.0518, 0.0034, 0.0043,
        0.0176, 0.0178, 0.0051], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:17,011][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([1.5268e-11, 5.4673e-04, 1.7861e-05, 4.0397e-02, 4.8123e-03, 6.7286e-05,
        5.7426e-10, 1.9861e-05, 1.2090e-05, 2.2139e-02, 9.3132e-01, 6.7145e-04],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:17,012][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Melissa] are: tensor([0.0019, 0.0975, 0.0139, 0.3189, 0.1205, 0.0340, 0.0044, 0.0138, 0.0113,
        0.1212, 0.2028, 0.0282, 0.0316], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:17,014][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Melissa] are: tensor([0.0021, 0.0365, 0.0240, 0.0979, 0.0791, 0.1339, 0.0542, 0.0799, 0.0573,
        0.0427, 0.1678, 0.1324, 0.0921], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:17,015][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Melissa] are: tensor([0.0497, 0.0982, 0.0871, 0.0523, 0.1321, 0.0249, 0.0400, 0.1324, 0.0198,
        0.0199, 0.0302, 0.1048, 0.2088], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:17,016][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Melissa] are: tensor([0.0029, 0.0414, 0.0401, 0.3925, 0.1480, 0.0358, 0.0060, 0.0161, 0.0153,
        0.0680, 0.1523, 0.0403, 0.0414], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:17,017][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Melissa] are: tensor([9.6493e-01, 1.4388e-03, 3.2677e-03, 3.9472e-03, 1.5420e-03, 1.2861e-03,
        7.1840e-03, 3.7585e-04, 1.5487e-03, 5.9951e-03, 3.9365e-03, 1.5835e-04,
        4.3868e-03], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:17,018][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Melissa] are: tensor([5.5797e-03, 3.8144e-03, 7.2392e-04, 6.0565e-03, 8.2840e-03, 7.9958e-05,
        1.0820e-03, 2.9729e-03, 1.0099e-02, 2.0607e-02, 1.0784e-01, 7.9766e-01,
        3.5194e-02], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:17,019][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Melissa] are: tensor([0.0498, 0.2001, 0.0028, 0.0674, 0.1156, 0.1824, 0.0199, 0.0900, 0.1303,
        0.0652, 0.0542, 0.0197, 0.0028], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:17,020][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Melissa] are: tensor([1.4929e-04, 5.6173e-02, 4.6436e-02, 1.8158e-01, 1.2359e-01, 5.3405e-02,
        4.6934e-03, 3.8726e-02, 2.5821e-02, 1.4268e-01, 1.6316e-01, 7.4749e-02,
        8.8829e-02], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:17,022][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Melissa] are: tensor([0.4135, 0.0253, 0.0212, 0.0562, 0.0319, 0.0507, 0.1366, 0.0320, 0.0456,
        0.0498, 0.0745, 0.0386, 0.0242], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:17,024][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Melissa] are: tensor([0.0406, 0.0732, 0.0429, 0.2293, 0.1799, 0.0487, 0.0206, 0.0269, 0.0195,
        0.0763, 0.1114, 0.0913, 0.0393], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:17,025][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Melissa] are: tensor([0.7824, 0.0144, 0.0044, 0.0220, 0.0027, 0.0140, 0.0715, 0.0060, 0.0060,
        0.0352, 0.0309, 0.0058, 0.0047], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:17,027][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Melissa] are: tensor([5.7504e-11, 8.0542e-03, 2.9454e-06, 1.2822e-01, 3.9096e-03, 1.1179e-04,
        4.4997e-10, 1.8019e-05, 6.9815e-06, 6.7496e-02, 7.7261e-01, 1.8365e-02,
        1.2126e-03], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:17,029][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.0066, 0.0781, 0.0241, 0.2594, 0.1421, 0.0174, 0.0048, 0.0196, 0.0043,
        0.0808, 0.1504, 0.0242, 0.0378, 0.1505], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:17,030][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([0.0049, 0.0225, 0.0231, 0.0695, 0.0754, 0.1302, 0.0433, 0.0886, 0.0490,
        0.0424, 0.1307, 0.1458, 0.0887, 0.0858], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:17,032][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([0.0231, 0.0756, 0.0879, 0.0799, 0.1965, 0.0315, 0.0369, 0.1443, 0.0154,
        0.0144, 0.0256, 0.0580, 0.1597, 0.0512], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:17,034][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([0.0007, 0.0454, 0.0648, 0.3785, 0.1837, 0.0199, 0.0018, 0.0075, 0.0083,
        0.0395, 0.1069, 0.0141, 0.0420, 0.0869], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:17,035][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([9.7017e-01, 1.0515e-03, 1.9976e-03, 4.1664e-03, 9.1696e-04, 1.1450e-03,
        7.8984e-03, 2.7700e-04, 1.0501e-03, 4.2782e-03, 3.1723e-03, 8.2285e-05,
        1.8484e-03, 1.9493e-03], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:17,037][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([3.4753e-03, 3.3136e-03, 2.1813e-03, 7.4912e-03, 1.5200e-02, 4.1461e-05,
        3.3348e-04, 1.5399e-03, 1.2613e-02, 1.9605e-02, 8.1645e-02, 7.5846e-01,
        6.0421e-02, 3.3680e-02], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:17,038][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([0.1166, 0.0909, 0.0597, 0.0608, 0.0608, 0.0699, 0.0273, 0.1116, 0.0715,
        0.0617, 0.0585, 0.1297, 0.0735, 0.0075], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:17,040][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([6.3364e-05, 5.8960e-02, 2.7477e-02, 1.8205e-01, 7.2147e-02, 5.3509e-02,
        2.8643e-03, 3.0697e-02, 1.5272e-02, 1.1453e-01, 1.4153e-01, 5.3291e-02,
        4.3463e-02, 2.0415e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:17,041][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([0.4422, 0.0277, 0.0141, 0.0499, 0.0212, 0.0409, 0.1269, 0.0283, 0.0363,
        0.0401, 0.0550, 0.0379, 0.0136, 0.0659], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:17,042][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([0.0854, 0.0787, 0.0561, 0.2407, 0.1230, 0.0318, 0.0188, 0.0133, 0.0149,
        0.0650, 0.0828, 0.0534, 0.0368, 0.0992], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:17,042][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([0.8518, 0.0099, 0.0029, 0.0142, 0.0036, 0.0072, 0.0581, 0.0036, 0.0031,
        0.0173, 0.0177, 0.0032, 0.0031, 0.0041], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:17,043][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([5.7499e-10, 1.9286e-03, 1.6077e-04, 1.7967e-01, 1.7005e-02, 1.0518e-05,
        2.1931e-10, 4.3101e-06, 1.7413e-06, 1.8210e-02, 4.9286e-01, 2.2600e-02,
        6.2889e-02, 2.0465e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:17,045][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0082, 0.0594, 0.0082, 0.1694, 0.0803, 0.0119, 0.0028, 0.0041, 0.0057,
        0.0423, 0.0757, 0.0159, 0.0126, 0.3166, 0.1870], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:17,047][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0047, 0.0191, 0.0253, 0.0588, 0.0831, 0.0948, 0.0369, 0.0581, 0.0456,
        0.0312, 0.0964, 0.0988, 0.0794, 0.1022, 0.1655], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:17,048][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0273, 0.0437, 0.0398, 0.0471, 0.0963, 0.0233, 0.0315, 0.1133, 0.0170,
        0.0153, 0.0263, 0.0733, 0.0949, 0.0447, 0.3063], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:17,050][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0044, 0.0415, 0.0337, 0.1931, 0.0775, 0.0209, 0.0037, 0.0090, 0.0110,
        0.0397, 0.0860, 0.0222, 0.0291, 0.1798, 0.2485], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:17,051][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([9.7681e-01, 9.1211e-04, 1.3238e-03, 2.6454e-03, 6.3796e-04, 4.9735e-04,
        6.7675e-03, 1.7495e-04, 9.3532e-04, 3.3354e-03, 2.5115e-03, 8.1876e-05,
        1.3060e-03, 1.1168e-03, 9.4208e-04], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:17,052][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([5.6392e-02, 6.1109e-03, 2.5504e-03, 1.1732e-02, 1.8689e-02, 6.9767e-05,
        5.0782e-04, 2.8222e-03, 1.4828e-02, 2.3694e-02, 1.3997e-01, 4.1521e-01,
        7.1969e-02, 8.5948e-02, 1.4952e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:17,054][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.1030, 0.0814, 0.0765, 0.1137, 0.0652, 0.1195, 0.0317, 0.0381, 0.0783,
        0.0336, 0.0832, 0.0579, 0.0663, 0.0410, 0.0106], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:17,056][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([1.5642e-04, 6.1073e-02, 2.2173e-02, 1.3433e-01, 5.3808e-02, 2.9885e-02,
        2.5971e-03, 2.2806e-02, 1.3083e-02, 8.8001e-02, 1.0285e-01, 5.5325e-02,
        3.7869e-02, 1.5659e-01, 2.1945e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:17,057][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.5734, 0.0139, 0.0112, 0.0316, 0.0154, 0.0224, 0.1075, 0.0182, 0.0282,
        0.0271, 0.0356, 0.0226, 0.0111, 0.0404, 0.0413], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:17,059][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.1313, 0.0404, 0.0381, 0.1265, 0.0989, 0.0258, 0.0186, 0.0139, 0.0108,
        0.0454, 0.0614, 0.0344, 0.0300, 0.1520, 0.1726], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:17,061][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.8819, 0.0074, 0.0019, 0.0115, 0.0021, 0.0049, 0.0446, 0.0023, 0.0021,
        0.0134, 0.0125, 0.0024, 0.0015, 0.0019, 0.0095], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:17,062][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([1.0836e-10, 2.9136e-05, 2.5820e-06, 2.3473e-04, 3.7907e-04, 1.0554e-07,
        1.4425e-12, 1.1549e-07, 8.3582e-08, 6.1212e-05, 4.7977e-04, 1.7794e-04,
        2.9808e-04, 2.6799e-02, 9.7154e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:17,066][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:31:17,067][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[6798],
        [7235],
        [1835],
        [3910],
        [5799],
        [9638],
        [7910],
        [6934],
        [3568],
        [4756],
        [4858],
        [9699],
        [2488],
        [3454],
        [2463]], device='cuda:0')
[2024-07-24 10:31:17,069][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 7711],
        [15787],
        [ 4639],
        [10604],
        [16598],
        [20485],
        [13626],
        [20184],
        [10073],
        [15838],
        [14592],
        [25118],
        [ 7102],
        [10221],
        [ 8707]], device='cuda:0')
[2024-07-24 10:31:17,070][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[29429],
        [32315],
        [38724],
        [35011],
        [30258],
        [27919],
        [27138],
        [28170],
        [31527],
        [31734],
        [30878],
        [28415],
        [31494],
        [33636],
        [32463]], device='cuda:0')
[2024-07-24 10:31:17,072][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[3477],
        [4702],
        [4065],
        [5138],
        [5010],
        [4819],
        [4900],
        [5637],
        [5641],
        [5713],
        [5695],
        [5736],
        [5374],
        [5466],
        [5444]], device='cuda:0')
[2024-07-24 10:31:17,073][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 6239],
        [13659],
        [ 9635],
        [12298],
        [ 8362],
        [10902],
        [11726],
        [10641],
        [10258],
        [11966],
        [12810],
        [11275],
        [10332],
        [11699],
        [11837]], device='cuda:0')
[2024-07-24 10:31:17,075][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[15061],
        [10524],
        [ 6455],
        [17686],
        [26704],
        [29861],
        [28023],
        [26178],
        [28184],
        [28156],
        [27685],
        [25927],
        [25392],
        [28543],
        [27606]], device='cuda:0')
[2024-07-24 10:31:17,077][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[ 5822],
        [ 7708],
        [ 6466],
        [ 8025],
        [ 7137],
        [ 7454],
        [13843],
        [ 9045],
        [ 9080],
        [11436],
        [12849],
        [11948],
        [ 9914],
        [10871],
        [ 9678]], device='cuda:0')
[2024-07-24 10:31:17,078][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[ 3883],
        [ 9613],
        [11622],
        [12441],
        [16281],
        [18168],
        [21554],
        [17998],
        [16819],
        [14022],
        [11471],
        [12217],
        [11751],
        [14511],
        [14118]], device='cuda:0')
[2024-07-24 10:31:17,080][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[13803],
        [ 7386],
        [ 7875],
        [ 7360],
        [ 7405],
        [ 6458],
        [ 6328],
        [ 6618],
        [ 6594],
        [ 6328],
        [ 6194],
        [ 6329],
        [ 6307],
        [ 6113],
        [ 5804]], device='cuda:0')
[2024-07-24 10:31:17,082][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[6100],
        [5367],
        [6226],
        [4901],
        [4386],
        [4728],
        [4893],
        [5146],
        [5316],
        [5904],
        [6091],
        [6523],
        [6464],
        [6727],
        [6572]], device='cuda:0')
[2024-07-24 10:31:17,083][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[ 8569],
        [ 9466],
        [21687],
        [21944],
        [23873],
        [24499],
        [24881],
        [23991],
        [24996],
        [25353],
        [25302],
        [25649],
        [26304],
        [26750],
        [26909]], device='cuda:0')
[2024-07-24 10:31:17,085][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[ 1819],
        [ 6715],
        [10597],
        [10169],
        [18404],
        [22625],
        [25418],
        [21452],
        [21294],
        [19760],
        [18855],
        [20468],
        [20044],
        [19183],
        [18533]], device='cuda:0')
[2024-07-24 10:31:17,087][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[15083],
        [20849],
        [20227],
        [19521],
        [19146],
        [18036],
        [17456],
        [17952],
        [17665],
        [17601],
        [17409],
        [16991],
        [16399],
        [16167],
        [15589]], device='cuda:0')
[2024-07-24 10:31:17,088][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[26349],
        [ 9482],
        [ 9487],
        [ 8162],
        [ 7031],
        [11080],
        [ 9927],
        [ 7911],
        [ 8186],
        [33465],
        [13357],
        [ 1818],
        [ 2135],
        [ 3361],
        [ 3955]], device='cuda:0')
[2024-07-24 10:31:17,090][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 5086],
        [20190],
        [28656],
        [23410],
        [20491],
        [25976],
        [10572],
        [23127],
        [31361],
        [16100],
        [18802],
        [14768],
        [35135],
        [23973],
        [26885]], device='cuda:0')
[2024-07-24 10:31:17,092][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[15261],
        [16435],
        [19771],
        [25518],
        [34414],
        [38396],
        [40561],
        [35548],
        [33670],
        [36424],
        [39070],
        [37391],
        [38118],
        [35521],
        [27164]], device='cuda:0')
[2024-07-24 10:31:17,094][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[17291],
        [45048],
        [46153],
        [41118],
        [39511],
        [37776],
        [37289],
        [35252],
        [34960],
        [34669],
        [33133],
        [32358],
        [32815],
        [33722],
        [33140]], device='cuda:0')
[2024-07-24 10:31:17,095][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[ 4433],
        [10628],
        [10534],
        [16394],
        [14050],
        [14635],
        [15257],
        [17955],
        [19052],
        [18316],
        [19007],
        [17120],
        [16667],
        [17798],
        [21143]], device='cuda:0')
[2024-07-24 10:31:17,097][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[ 8696],
        [16350],
        [15112],
        [17512],
        [14021],
        [11907],
        [12646],
        [13628],
        [12472],
        [11958],
        [11234],
        [11484],
        [11969],
        [11310],
        [ 8668]], device='cuda:0')
[2024-07-24 10:31:17,098][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[13085],
        [12823],
        [12711],
        [12073],
        [12100],
        [11748],
        [ 7705],
        [11075],
        [10632],
        [10099],
        [ 9625],
        [ 9360],
        [ 9929],
        [10163],
        [10719]], device='cuda:0')
[2024-07-24 10:31:17,100][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[25836],
        [33782],
        [29366],
        [30626],
        [34700],
        [33376],
        [32967],
        [33392],
        [25051],
        [23065],
        [31030],
        [30150],
        [29015],
        [27586],
        [25310]], device='cuda:0')
[2024-07-24 10:31:17,102][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[ 3233],
        [ 2345],
        [11458],
        [ 4539],
        [ 5443],
        [ 4097],
        [ 7173],
        [ 6213],
        [ 8684],
        [ 4973],
        [ 4858],
        [ 6377],
        [ 7064],
        [ 6552],
        [ 6960]], device='cuda:0')
[2024-07-24 10:31:17,103][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[37759],
        [36681],
        [39742],
        [42328],
        [41901],
        [41135],
        [41002],
        [39898],
        [39326],
        [37756],
        [36728],
        [34268],
        [35139],
        [35281],
        [33917]], device='cuda:0')
[2024-07-24 10:31:17,105][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[24527],
        [26182],
        [31179],
        [31099],
        [34950],
        [34185],
        [37025],
        [34103],
        [36305],
        [37399],
        [37799],
        [37150],
        [37824],
        [37533],
        [37355]], device='cuda:0')
[2024-07-24 10:31:17,107][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[33831],
        [22545],
        [17066],
        [18033],
        [17506],
        [16525],
        [14962],
        [15832],
        [15848],
        [16375],
        [17550],
        [17170],
        [17814],
        [16582],
        [17055]], device='cuda:0')
[2024-07-24 10:31:17,108][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[20626],
        [20253],
        [19054],
        [19364],
        [17831],
        [17736],
        [17909],
        [19623],
        [19196],
        [19243],
        [19436],
        [19364],
        [19593],
        [19401],
        [19644]], device='cuda:0')
[2024-07-24 10:31:17,110][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[49815],
        [48678],
        [48677],
        [48362],
        [47961],
        [47382],
        [47491],
        [47890],
        [47827],
        [42436],
        [47571],
        [49303],
        [49252],
        [49114],
        [48325]], device='cuda:0')
[2024-07-24 10:31:17,112][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[25945],
        [20301],
        [15838],
        [15888],
        [13429],
        [14316],
        [13337],
        [13646],
        [14141],
        [15670],
        [13670],
        [13426],
        [12470],
        [13770],
        [16224]], device='cuda:0')
[2024-07-24 10:31:17,114][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[40519],
        [ 6650],
        [ 9750],
        [10698],
        [16847],
        [14798],
        [24562],
        [10523],
        [10433],
        [14382],
        [16321],
        [20548],
        [ 7961],
        [13130],
        [ 8969]], device='cuda:0')
[2024-07-24 10:31:17,115][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[17480],
        [17480],
        [17480],
        [17480],
        [17480],
        [17480],
        [17480],
        [17480],
        [17480],
        [17480],
        [17480],
        [17480],
        [17480],
        [17480],
        [17480]], device='cuda:0')
[2024-07-24 10:31:17,175][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:31:17,176][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:17,177][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:17,178][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:17,178][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:17,180][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:17,181][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:17,182][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:17,184][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:17,185][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:17,186][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:17,187][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:17,189][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:17,191][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0087, 0.9913], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:17,192][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0762, 0.9238], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:17,194][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.4821, 0.5179], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:17,195][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.4769, 0.5231], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:17,197][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.9711, 0.0289], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:17,198][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.3612, 0.6388], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:17,200][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.4524, 0.5476], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:17,202][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.3358, 0.6642], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:17,202][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.3269, 0.6731], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:17,203][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.5221, 0.4779], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:17,204][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.9767, 0.0233], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:17,205][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.9721, 0.0279], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:17,206][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Melissa] are: tensor([0.0031, 0.3297, 0.6672], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:17,208][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Melissa] are: tensor([0.0172, 0.4796, 0.5033], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:17,209][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Melissa] are: tensor([0.3714, 0.3165, 0.3121], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:17,211][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Melissa] are: tensor([0.1229, 0.3960, 0.4811], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:17,212][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Melissa] are: tensor([0.8223, 0.1373, 0.0404], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:17,214][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Melissa] are: tensor([0.0519, 0.4198, 0.5283], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:17,216][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Melissa] are: tensor([0.1611, 0.3898, 0.4491], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:17,217][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Melissa] are: tensor([0.5599, 0.2843, 0.1558], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:17,219][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Melissa] are: tensor([0.2016, 0.4367, 0.3618], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:17,220][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Melissa] are: tensor([0.3888, 0.4451, 0.1661], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:17,222][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Melissa] are: tensor([0.9375, 0.0320, 0.0305], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:17,224][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Melissa] are: tensor([0.9549, 0.0269, 0.0182], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:17,225][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0023, 0.2170, 0.5174, 0.2632], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:17,227][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0131, 0.3278, 0.3852, 0.2740], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:17,228][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.2715, 0.2307, 0.2594, 0.2383], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:17,229][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.1016, 0.3858, 0.4516, 0.0610], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:17,230][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.7644, 0.0776, 0.0841, 0.0740], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:17,230][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0667, 0.2518, 0.4819, 0.1996], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:17,231][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.1596, 0.2241, 0.4162, 0.2001], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:17,233][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.4662, 0.2905, 0.0886, 0.1547], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:17,234][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.1375, 0.2843, 0.2626, 0.3156], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:17,236][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.2986, 0.2363, 0.2244, 0.2406], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:17,237][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.9006, 0.0271, 0.0258, 0.0466], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:17,239][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.9060, 0.0227, 0.0172, 0.0541], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:17,241][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Benjamin] are: tensor([0.0020, 0.1635, 0.3166, 0.2226, 0.2953], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:17,242][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Benjamin] are: tensor([0.0119, 0.2471, 0.2833, 0.2255, 0.2322], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:17,244][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Benjamin] are: tensor([0.1963, 0.1897, 0.2004, 0.2155, 0.1980], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:17,245][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Benjamin] are: tensor([0.0865, 0.0958, 0.1151, 0.0470, 0.6556], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:17,247][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Benjamin] are: tensor([0.5736, 0.1403, 0.0545, 0.2064, 0.0253], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:17,249][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Benjamin] are: tensor([0.0195, 0.1930, 0.4031, 0.2206, 0.1637], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:17,250][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Benjamin] are: tensor([0.0670, 0.2265, 0.2519, 0.2900, 0.1645], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:17,252][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Benjamin] are: tensor([0.2006, 0.1770, 0.1663, 0.2463, 0.2099], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:17,254][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Benjamin] are: tensor([0.1098, 0.2065, 0.1906, 0.2483, 0.2448], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:17,255][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Benjamin] are: tensor([0.2883, 0.2048, 0.2088, 0.2241, 0.0740], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:17,257][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Benjamin] are: tensor([0.7330, 0.0380, 0.0364, 0.0821, 0.1105], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:17,259][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Benjamin] are: tensor([0.8935, 0.0281, 0.0209, 0.0323, 0.0251], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:17,260][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.0020, 0.1244, 0.2711, 0.1634, 0.2114, 0.2278], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:17,261][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.0117, 0.1974, 0.2101, 0.1794, 0.1826, 0.2187], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:17,261][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.0993, 0.1698, 0.2475, 0.1944, 0.2148, 0.0742], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:17,263][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.0020, 0.0883, 0.2107, 0.0232, 0.6703, 0.0054], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:17,265][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.7639, 0.0666, 0.0249, 0.0953, 0.0377, 0.0116], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:17,266][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.0971, 0.1915, 0.2041, 0.1979, 0.1861, 0.1233], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:17,268][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.1007, 0.1585, 0.2286, 0.1900, 0.1899, 0.1323], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:17,269][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.3376, 0.1833, 0.0730, 0.2198, 0.1469, 0.0394], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:17,271][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.0810, 0.1653, 0.1586, 0.1941, 0.1981, 0.2029], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:17,273][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.2376, 0.1634, 0.1675, 0.1526, 0.0808, 0.1981], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:17,274][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.7386, 0.0356, 0.0439, 0.0682, 0.0778, 0.0359], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:17,276][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.6994, 0.0519, 0.0379, 0.1178, 0.0445, 0.0485], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:17,278][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0009, 0.1152, 0.2326, 0.1483, 0.1933, 0.2285, 0.0812],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:17,280][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0043, 0.1660, 0.1826, 0.1454, 0.1552, 0.2088, 0.1377],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:17,281][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0364, 0.1293, 0.3050, 0.1903, 0.2707, 0.0422, 0.0262],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:17,283][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0019, 0.0819, 0.1488, 0.0658, 0.6740, 0.0211, 0.0065],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:17,285][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.7131, 0.0696, 0.0304, 0.1167, 0.0301, 0.0214, 0.0187],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:17,286][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0423, 0.1549, 0.2059, 0.1440, 0.1999, 0.1147, 0.1382],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:17,286][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0679, 0.1454, 0.2340, 0.1658, 0.1864, 0.1396, 0.0608],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:17,287][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0256, 0.1814, 0.1258, 0.2597, 0.2164, 0.1466, 0.0445],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:17,288][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0546, 0.1439, 0.1372, 0.1723, 0.1767, 0.1846, 0.1306],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:17,289][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.1769, 0.1353, 0.1242, 0.1370, 0.0552, 0.1765, 0.1949],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:17,291][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.5201, 0.0724, 0.0559, 0.0847, 0.0820, 0.0520, 0.1330],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:17,293][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.2137, 0.0719, 0.0995, 0.1712, 0.1237, 0.1019, 0.2181],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:17,294][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.0011, 0.0908, 0.1918, 0.1180, 0.1623, 0.1987, 0.0878, 0.1494],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:17,296][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ long] are: tensor([0.0057, 0.1459, 0.1528, 0.1268, 0.1342, 0.1711, 0.1367, 0.1269],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:17,297][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.1139, 0.1452, 0.2000, 0.1558, 0.1752, 0.0548, 0.0335, 0.1215],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:17,299][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ long] are: tensor([0.0112, 0.1439, 0.1363, 0.0262, 0.6562, 0.0055, 0.0076, 0.0132],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:17,301][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.4727, 0.1056, 0.0341, 0.1754, 0.0345, 0.0259, 0.1319, 0.0200],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:17,303][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ long] are: tensor([0.0416, 0.1003, 0.1142, 0.1358, 0.1788, 0.1236, 0.2713, 0.0344],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:17,304][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.0591, 0.1363, 0.1430, 0.1765, 0.1506, 0.1441, 0.1086, 0.0818],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:17,306][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.1375, 0.1900, 0.0804, 0.2260, 0.2118, 0.0655, 0.0628, 0.0261],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:17,308][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.0641, 0.1190, 0.1155, 0.1436, 0.1480, 0.1520, 0.1127, 0.1452],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:17,309][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ long] are: tensor([0.1962, 0.1121, 0.1175, 0.1103, 0.0566, 0.1641, 0.1564, 0.0867],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:17,311][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.7967, 0.0219, 0.0189, 0.0319, 0.0337, 0.0137, 0.0762, 0.0070],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:17,312][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ long] are: tensor([0.7436, 0.0199, 0.0117, 0.0365, 0.0181, 0.0092, 0.1455, 0.0154],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:17,313][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.0008, 0.0770, 0.1726, 0.1046, 0.1430, 0.1760, 0.0753, 0.1394, 0.1112],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:17,314][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([0.0058, 0.1160, 0.1425, 0.1102, 0.1120, 0.1530, 0.1346, 0.1332, 0.0929],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:17,315][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.1001, 0.1323, 0.1712, 0.1476, 0.1456, 0.0509, 0.0325, 0.1249, 0.0949],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:17,317][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([0.0152, 0.0821, 0.1012, 0.0346, 0.6977, 0.0064, 0.0093, 0.0218, 0.0317],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:17,319][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.4268, 0.1046, 0.0343, 0.1949, 0.0252, 0.0215, 0.1521, 0.0342, 0.0064],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:17,320][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([0.0092, 0.0894, 0.1548, 0.0833, 0.0744, 0.1524, 0.1934, 0.2144, 0.0287],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:17,322][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.0459, 0.1286, 0.1499, 0.1564, 0.1303, 0.1039, 0.0968, 0.0997, 0.0885],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:17,323][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.1179, 0.1336, 0.0927, 0.2108, 0.2651, 0.0558, 0.0549, 0.0395, 0.0297],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:17,325][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.0575, 0.1011, 0.0999, 0.1248, 0.1285, 0.1338, 0.0976, 0.1328, 0.1240],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:17,327][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.2413, 0.1075, 0.0783, 0.0956, 0.0348, 0.1503, 0.1106, 0.1218, 0.0598],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:17,329][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.6418, 0.0266, 0.0256, 0.0511, 0.0707, 0.0262, 0.1069, 0.0098, 0.0414],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:17,330][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([0.5921, 0.0389, 0.0332, 0.0648, 0.0359, 0.0200, 0.1627, 0.0161, 0.0363],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:17,332][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0007, 0.0682, 0.1554, 0.0855, 0.1349, 0.1534, 0.0652, 0.1280, 0.1143,
        0.0943], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:17,334][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0043, 0.1088, 0.1269, 0.0938, 0.1156, 0.1461, 0.1091, 0.1131, 0.1017,
        0.0806], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:17,336][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0872, 0.1147, 0.1456, 0.1266, 0.1331, 0.0524, 0.0367, 0.1170, 0.1052,
        0.0817], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:17,337][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0422, 0.1294, 0.1744, 0.0154, 0.5490, 0.0039, 0.0074, 0.0099, 0.0269,
        0.0415], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:17,338][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.5924, 0.0317, 0.0483, 0.0590, 0.0342, 0.0217, 0.1394, 0.0445, 0.0219,
        0.0069], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:17,338][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0175, 0.0485, 0.1181, 0.1000, 0.1399, 0.1195, 0.1806, 0.1241, 0.1173,
        0.0344], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:17,339][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0558, 0.0769, 0.1709, 0.0892, 0.1522, 0.0980, 0.0813, 0.0897, 0.1219,
        0.0641], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:17,340][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.2115, 0.1270, 0.0950, 0.1779, 0.1541, 0.0522, 0.0545, 0.0366, 0.0298,
        0.0613], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:17,342][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0478, 0.0914, 0.0901, 0.1104, 0.1147, 0.1203, 0.0859, 0.1149, 0.1090,
        0.1156], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:17,343][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.1057, 0.0914, 0.0924, 0.0898, 0.0559, 0.1217, 0.1261, 0.1135, 0.0961,
        0.1075], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:17,345][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.6537, 0.0244, 0.0282, 0.0485, 0.0528, 0.0262, 0.0879, 0.0106, 0.0334,
        0.0343], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:17,347][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.6450, 0.0205, 0.0190, 0.0430, 0.0194, 0.0144, 0.1296, 0.0086, 0.0162,
        0.0844], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:17,348][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0006, 0.0621, 0.1473, 0.0737, 0.1248, 0.1497, 0.0607, 0.1156, 0.1111,
        0.0908, 0.0637], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:17,350][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0031, 0.1013, 0.1197, 0.0827, 0.1067, 0.1386, 0.1023, 0.1071, 0.0982,
        0.0747, 0.0654], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:17,352][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0888, 0.1103, 0.1321, 0.1130, 0.1124, 0.0461, 0.0281, 0.1003, 0.0930,
        0.0780, 0.0979], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:17,353][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.1623, 0.1020, 0.1669, 0.0156, 0.3872, 0.0058, 0.0142, 0.0142, 0.0301,
        0.0617, 0.0402], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:17,355][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.3022, 0.0661, 0.0786, 0.0605, 0.0596, 0.0424, 0.1885, 0.1037, 0.0575,
        0.0195, 0.0215], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:17,357][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0135, 0.0613, 0.1070, 0.0465, 0.1277, 0.1188, 0.1580, 0.1446, 0.1402,
        0.0444, 0.0381], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:17,358][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0553, 0.0799, 0.1540, 0.0750, 0.1396, 0.1022, 0.0646, 0.0809, 0.1163,
        0.0622, 0.0699], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:17,360][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.2576, 0.1480, 0.0766, 0.1250, 0.1301, 0.0444, 0.0559, 0.0239, 0.0219,
        0.0564, 0.0602], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:17,362][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0446, 0.0860, 0.0819, 0.0986, 0.1037, 0.1079, 0.0767, 0.1033, 0.0975,
        0.1060, 0.0939], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:17,363][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.1058, 0.0805, 0.0888, 0.0822, 0.0541, 0.1190, 0.1096, 0.0991, 0.0883,
        0.0974, 0.0749], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:17,364][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.6527, 0.0294, 0.0265, 0.0443, 0.0478, 0.0220, 0.0832, 0.0079, 0.0282,
        0.0306, 0.0274], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:17,365][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.6305, 0.0166, 0.0124, 0.0388, 0.0134, 0.0110, 0.1135, 0.0060, 0.0123,
        0.0672, 0.0783], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:17,366][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.0006, 0.0583, 0.1266, 0.0760, 0.1161, 0.1393, 0.0566, 0.1056, 0.0922,
        0.0896, 0.0673, 0.0719], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:17,367][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([0.0034, 0.0961, 0.1009, 0.0864, 0.0884, 0.1229, 0.0928, 0.0958, 0.0807,
        0.0793, 0.0714, 0.0818], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:17,369][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.0870, 0.0886, 0.1190, 0.1027, 0.1004, 0.0393, 0.0212, 0.0825, 0.0773,
        0.0673, 0.0920, 0.1228], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:17,371][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([0.0617, 0.0732, 0.0832, 0.0178, 0.4598, 0.0036, 0.0075, 0.0095, 0.0231,
        0.0658, 0.0454, 0.1495], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:17,372][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.1404, 0.1490, 0.0255, 0.2324, 0.0244, 0.0391, 0.1658, 0.0445, 0.0162,
        0.0504, 0.1012, 0.0108], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:17,374][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([0.0093, 0.0634, 0.0826, 0.0796, 0.0791, 0.1183, 0.1844, 0.0912, 0.1201,
        0.0585, 0.0710, 0.0423], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:17,376][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.0238, 0.0902, 0.1051, 0.1242, 0.1017, 0.0956, 0.0869, 0.0685, 0.0651,
        0.0877, 0.1072, 0.0440], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:17,378][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.0551, 0.1278, 0.0860, 0.1746, 0.1873, 0.0647, 0.0342, 0.0406, 0.0354,
        0.0768, 0.0790, 0.0385], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:17,379][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.0415, 0.0776, 0.0764, 0.0917, 0.0925, 0.0971, 0.0690, 0.0912, 0.0873,
        0.0952, 0.0868, 0.0937], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:17,381][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([0.1057, 0.0627, 0.0667, 0.0664, 0.0417, 0.1018, 0.1042, 0.0997, 0.0947,
        0.1050, 0.0726, 0.0789], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:17,383][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.4661, 0.0495, 0.0524, 0.0789, 0.0858, 0.0346, 0.0866, 0.0122, 0.0317,
        0.0410, 0.0348, 0.0263], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:17,384][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([0.5865, 0.0239, 0.0119, 0.0371, 0.0143, 0.0126, 0.1253, 0.0077, 0.0141,
        0.0737, 0.0670, 0.0258], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:17,386][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Melissa] are: tensor([0.0007, 0.0540, 0.1053, 0.0694, 0.0941, 0.1120, 0.0496, 0.0888, 0.0843,
        0.0779, 0.0600, 0.0690, 0.1350], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:17,388][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Melissa] are: tensor([0.0031, 0.0850, 0.0955, 0.0744, 0.0846, 0.1127, 0.0728, 0.0816, 0.0779,
        0.0677, 0.0574, 0.0808, 0.1064], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:17,389][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Melissa] are: tensor([0.0708, 0.0913, 0.0934, 0.1029, 0.0866, 0.0377, 0.0233, 0.0762, 0.0704,
        0.0594, 0.0851, 0.1297, 0.0731], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:17,390][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Melissa] are: tensor([0.0262, 0.0344, 0.0400, 0.0133, 0.3721, 0.0033, 0.0053, 0.0099, 0.0280,
        0.0281, 0.0421, 0.2827, 0.1146], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:17,391][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Melissa] are: tensor([0.3588, 0.1012, 0.0259, 0.1240, 0.0144, 0.0291, 0.1828, 0.0436, 0.0082,
        0.0192, 0.0560, 0.0175, 0.0194], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:17,392][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Melissa] are: tensor([0.0050, 0.0562, 0.0621, 0.0563, 0.0979, 0.1226, 0.0791, 0.0457, 0.2342,
        0.0372, 0.0336, 0.1089, 0.0613], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:17,393][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Melissa] are: tensor([0.0319, 0.0806, 0.0884, 0.1063, 0.0978, 0.0746, 0.0703, 0.0718, 0.0761,
        0.0771, 0.0936, 0.0516, 0.0798], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:17,395][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Melissa] are: tensor([0.1888, 0.0860, 0.0815, 0.1501, 0.1401, 0.0386, 0.0430, 0.0220, 0.0236,
        0.0514, 0.0682, 0.0369, 0.0696], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:17,397][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Melissa] are: tensor([0.0372, 0.0681, 0.0641, 0.0830, 0.0846, 0.0893, 0.0653, 0.0863, 0.0824,
        0.0887, 0.0796, 0.0884, 0.0830], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:17,398][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Melissa] are: tensor([0.0819, 0.1012, 0.0324, 0.0747, 0.0475, 0.1183, 0.0882, 0.0913, 0.0638,
        0.0944, 0.0740, 0.0973, 0.0348], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:17,400][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Melissa] are: tensor([0.5903, 0.0303, 0.0355, 0.0457, 0.0525, 0.0289, 0.0848, 0.0093, 0.0304,
        0.0305, 0.0270, 0.0158, 0.0188], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:17,402][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Melissa] are: tensor([0.7035, 0.0182, 0.0108, 0.0181, 0.0095, 0.0083, 0.1071, 0.0051, 0.0106,
        0.0366, 0.0358, 0.0068, 0.0296], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:17,404][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.0005, 0.0506, 0.1075, 0.0655, 0.0896, 0.1020, 0.0450, 0.0812, 0.0712,
        0.0708, 0.0549, 0.0630, 0.1350, 0.0632], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:17,405][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ said] are: tensor([0.0035, 0.0802, 0.0928, 0.0706, 0.0763, 0.0945, 0.0731, 0.0793, 0.0616,
        0.0611, 0.0559, 0.0770, 0.1056, 0.0683], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:17,407][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.0631, 0.0870, 0.1130, 0.0908, 0.0874, 0.0305, 0.0187, 0.0708, 0.0644,
        0.0580, 0.0738, 0.1111, 0.0800, 0.0513], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:17,409][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ said] are: tensor([0.0772, 0.0481, 0.0549, 0.0134, 0.2144, 0.0021, 0.0059, 0.0059, 0.0104,
        0.0206, 0.0297, 0.1646, 0.1295, 0.2234], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:17,411][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.3143, 0.0948, 0.0239, 0.2240, 0.0297, 0.0182, 0.0583, 0.0326, 0.0128,
        0.0307, 0.1167, 0.0160, 0.0159, 0.0120], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:17,412][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ said] are: tensor([0.0242, 0.0632, 0.1063, 0.0615, 0.0712, 0.0872, 0.0856, 0.0996, 0.0596,
        0.0504, 0.0536, 0.0951, 0.1142, 0.0283], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:17,414][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.0311, 0.0746, 0.0958, 0.0952, 0.0740, 0.0653, 0.0495, 0.0648, 0.0740,
        0.0735, 0.0894, 0.0598, 0.0913, 0.0616], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:17,415][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.2801, 0.0806, 0.0453, 0.1075, 0.0795, 0.0359, 0.0486, 0.0236, 0.0195,
        0.0444, 0.0701, 0.0489, 0.0456, 0.0704], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:17,416][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.0335, 0.0655, 0.0632, 0.0767, 0.0788, 0.0820, 0.0593, 0.0797, 0.0744,
        0.0826, 0.0732, 0.0831, 0.0799, 0.0683], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:17,417][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ said] are: tensor([0.0719, 0.0574, 0.0451, 0.0493, 0.0375, 0.1094, 0.0911, 0.0700, 0.0893,
        0.0746, 0.0438, 0.0857, 0.0467, 0.1283], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:17,419][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.5700, 0.0290, 0.0270, 0.0510, 0.0649, 0.0211, 0.0789, 0.0086, 0.0364,
        0.0300, 0.0254, 0.0214, 0.0136, 0.0225], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:17,420][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ said] are: tensor([0.6824, 0.0118, 0.0107, 0.0215, 0.0100, 0.0077, 0.1058, 0.0040, 0.0107,
        0.0405, 0.0404, 0.0088, 0.0269, 0.0191], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:17,422][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0004, 0.0449, 0.0993, 0.0557, 0.0856, 0.1008, 0.0416, 0.0802, 0.0724,
        0.0655, 0.0485, 0.0591, 0.1309, 0.0661, 0.0491], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:17,424][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0021, 0.0765, 0.0784, 0.0620, 0.0727, 0.0937, 0.0753, 0.0747, 0.0668,
        0.0561, 0.0497, 0.0634, 0.0882, 0.0739, 0.0666], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:17,425][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0803, 0.0791, 0.0955, 0.0830, 0.0803, 0.0306, 0.0174, 0.0679, 0.0599,
        0.0547, 0.0694, 0.1019, 0.0717, 0.0520, 0.0565], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:17,427][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.1523, 0.0537, 0.0380, 0.0074, 0.1769, 0.0013, 0.0070, 0.0041, 0.0087,
        0.0206, 0.0184, 0.0669, 0.0733, 0.2445, 0.1270], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:17,429][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.1769, 0.0915, 0.0399, 0.1601, 0.0557, 0.0348, 0.1763, 0.0496, 0.0280,
        0.0286, 0.0647, 0.0204, 0.0218, 0.0398, 0.0120], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:17,431][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0140, 0.0463, 0.0719, 0.0530, 0.0607, 0.0741, 0.1344, 0.0912, 0.1090,
        0.0387, 0.0447, 0.0603, 0.0885, 0.0794, 0.0336], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:17,433][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0401, 0.0593, 0.1032, 0.0686, 0.0894, 0.0675, 0.0523, 0.0690, 0.0742,
        0.0516, 0.0632, 0.0594, 0.0967, 0.0666, 0.0387], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:17,435][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.1019, 0.0683, 0.0608, 0.1133, 0.1321, 0.0367, 0.0337, 0.0185, 0.0213,
        0.0478, 0.0520, 0.0162, 0.0423, 0.1582, 0.0970], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:17,436][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0342, 0.0648, 0.0616, 0.0716, 0.0729, 0.0759, 0.0532, 0.0733, 0.0684,
        0.0747, 0.0680, 0.0768, 0.0740, 0.0657, 0.0649], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:17,438][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0591, 0.0633, 0.0622, 0.0639, 0.0286, 0.0785, 0.0917, 0.0583, 0.0715,
        0.0819, 0.0570, 0.0703, 0.0671, 0.0914, 0.0551], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:17,440][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.7096, 0.0187, 0.0144, 0.0254, 0.0357, 0.0143, 0.0672, 0.0047, 0.0223,
        0.0197, 0.0155, 0.0145, 0.0078, 0.0112, 0.0189], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:17,441][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.6754, 0.0141, 0.0086, 0.0236, 0.0099, 0.0070, 0.0993, 0.0042, 0.0083,
        0.0414, 0.0403, 0.0068, 0.0198, 0.0145, 0.0269], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:17,507][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:31:17,508][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:17,508][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:17,509][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:17,510][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:17,511][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:17,511][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:17,512][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:17,513][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:17,515][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:17,516][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:17,517][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:17,518][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:17,520][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0255, 0.9745], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:17,522][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.9078, 0.0922], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:17,523][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.7744, 0.2256], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:17,525][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.5854, 0.4146], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:17,527][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.1884, 0.8116], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:17,528][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.7573, 0.2427], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:17,529][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.3237, 0.6763], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:17,531][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.3358, 0.6642], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:17,533][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.8900, 0.1100], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:17,534][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.9386, 0.0614], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:17,534][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.9767, 0.0233], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:17,535][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.9625, 0.0375], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:17,536][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Melissa] are: tensor([0.0096, 0.4729, 0.5175], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:17,537][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Melissa] are: tensor([0.0792, 0.7590, 0.1619], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:17,539][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Melissa] are: tensor([0.7875, 0.1703, 0.0423], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:17,541][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Melissa] are: tensor([0.3784, 0.3448, 0.2768], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:17,542][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Melissa] are: tensor([0.1061, 0.6895, 0.2045], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:17,544][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Melissa] are: tensor([0.5974, 0.3536, 0.0489], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:17,545][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Melissa] are: tensor([0.2827, 0.5937, 0.1236], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:17,547][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Melissa] are: tensor([0.5599, 0.2843, 0.1558], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:17,549][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Melissa] are: tensor([0.7754, 0.1286, 0.0960], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:17,550][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Melissa] are: tensor([0.7923, 0.0864, 0.1213], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:17,552][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Melissa] are: tensor([0.9375, 0.0320, 0.0305], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:17,554][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Melissa] are: tensor([0.9383, 0.0356, 0.0262], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:17,555][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0074, 0.3147, 0.3681, 0.3098], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:17,557][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0493, 0.0046, 0.9436, 0.0025], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:17,559][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.8325, 0.0810, 0.0420, 0.0445], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:17,560][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.3293, 0.2695, 0.2106, 0.1906], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:17,560][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.1149, 0.3723, 0.0743, 0.4385], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:17,561][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.3966, 0.2252, 0.1481, 0.2301], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:17,562][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.2222, 0.3330, 0.1592, 0.2856], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:17,563][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.4662, 0.2905, 0.0886, 0.1547], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:17,565][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.4955, 0.0793, 0.2065, 0.2187], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:17,567][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.8320, 0.0511, 0.0701, 0.0468], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:17,568][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.9006, 0.0271, 0.0258, 0.0466], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:17,570][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.8981, 0.0260, 0.0214, 0.0545], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:17,571][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Benjamin] are: tensor([0.0050, 0.2372, 0.2616, 0.2597, 0.2365], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:17,573][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Benjamin] are: tensor([0.0301, 0.1986, 0.6319, 0.1258, 0.0137], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:17,575][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Benjamin] are: tensor([0.7075, 0.1169, 0.0345, 0.0847, 0.0564], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:17,576][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Benjamin] are: tensor([0.1465, 0.1885, 0.1740, 0.2535, 0.2376], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:17,578][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Benjamin] are: tensor([0.0311, 0.2235, 0.0720, 0.5165, 0.1568], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:17,580][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Benjamin] are: tensor([0.6533, 0.1341, 0.0573, 0.1222, 0.0330], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:17,581][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Benjamin] are: tensor([0.0649, 0.2932, 0.1853, 0.3248, 0.1318], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:17,583][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Benjamin] are: tensor([0.2006, 0.1770, 0.1663, 0.2463, 0.2099], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:17,585][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Benjamin] are: tensor([0.4869, 0.0537, 0.0865, 0.2513, 0.1216], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:17,586][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Benjamin] are: tensor([0.7322, 0.0590, 0.0851, 0.0626, 0.0611], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:17,586][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Benjamin] are: tensor([0.7330, 0.0380, 0.0364, 0.0821, 0.1105], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:17,587][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Benjamin] are: tensor([0.8394, 0.0492, 0.0327, 0.0477, 0.0310], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:17,588][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.0071, 0.1844, 0.2176, 0.2020, 0.1861, 0.2028], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:17,589][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.0323, 0.0279, 0.7138, 0.0592, 0.1563, 0.0105], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:17,591][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.4430, 0.2001, 0.0820, 0.1345, 0.1206, 0.0197], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:17,593][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.0634, 0.2190, 0.2211, 0.2399, 0.1948, 0.0618], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:17,594][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.0303, 0.2432, 0.0817, 0.3855, 0.2017, 0.0576], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:17,595][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.2044, 0.1690, 0.1041, 0.2900, 0.1285, 0.1040], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:17,596][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.0676, 0.2699, 0.1168, 0.3171, 0.1676, 0.0610], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:17,597][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.3376, 0.1833, 0.0730, 0.2198, 0.1469, 0.0394], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:17,598][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.3460, 0.0432, 0.1594, 0.1909, 0.1726, 0.0878], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:17,599][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.7701, 0.0433, 0.0629, 0.0427, 0.0489, 0.0321], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:17,601][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.7386, 0.0356, 0.0439, 0.0682, 0.0778, 0.0359], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:17,603][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.7792, 0.0395, 0.0316, 0.0740, 0.0283, 0.0474], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:17,604][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0034, 0.1618, 0.1779, 0.1748, 0.1563, 0.1826, 0.1432],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:17,606][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0186, 0.1220, 0.3098, 0.1584, 0.1420, 0.2398, 0.0094],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:17,608][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0531, 0.1731, 0.1359, 0.2332, 0.2622, 0.0792, 0.0634],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:17,609][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0203, 0.1601, 0.1718, 0.2478, 0.2467, 0.1191, 0.0341],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:17,611][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0040, 0.1871, 0.0764, 0.3593, 0.2062, 0.1467, 0.0203],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:17,613][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0388, 0.1723, 0.0755, 0.3418, 0.1061, 0.1577, 0.1079],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:17,614][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0041, 0.2279, 0.0953, 0.3137, 0.1509, 0.1779, 0.0301],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:17,614][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0256, 0.1814, 0.1258, 0.2597, 0.2164, 0.1466, 0.0445],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:17,615][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0284, 0.0799, 0.1561, 0.2659, 0.2061, 0.2059, 0.0578],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:17,616][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.6188, 0.0638, 0.0787, 0.0582, 0.0610, 0.0455, 0.0739],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:17,617][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.5201, 0.0724, 0.0559, 0.0847, 0.0820, 0.0520, 0.1330],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:17,619][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.3312, 0.0515, 0.0764, 0.1260, 0.0850, 0.0977, 0.2322],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:17,620][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.0022, 0.1367, 0.1577, 0.1471, 0.1369, 0.1616, 0.1332, 0.1246],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:17,622][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([0.0214, 0.1369, 0.1898, 0.2343, 0.3063, 0.0556, 0.0522, 0.0035],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:17,623][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([0.5075, 0.1241, 0.0608, 0.1001, 0.1038, 0.0165, 0.0842, 0.0030],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:17,625][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([0.0391, 0.2148, 0.1954, 0.2212, 0.2118, 0.0704, 0.0307, 0.0166],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:17,626][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.0284, 0.2127, 0.0564, 0.3955, 0.1584, 0.0880, 0.0419, 0.0187],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:17,628][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([0.2861, 0.0659, 0.0766, 0.2014, 0.1047, 0.0931, 0.1305, 0.0417],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:17,630][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.0425, 0.2552, 0.0787, 0.2215, 0.0919, 0.1179, 0.0929, 0.0995],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:17,632][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.1375, 0.1900, 0.0804, 0.2260, 0.2118, 0.0655, 0.0628, 0.0261],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:17,633][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.2276, 0.0329, 0.1190, 0.2020, 0.1905, 0.1158, 0.0874, 0.0249],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:17,635][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([0.7266, 0.0335, 0.0520, 0.0387, 0.0461, 0.0286, 0.0571, 0.0176],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:17,637][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.7967, 0.0219, 0.0189, 0.0319, 0.0337, 0.0137, 0.0762, 0.0070],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:17,639][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([0.7465, 0.0226, 0.0144, 0.0429, 0.0179, 0.0173, 0.1195, 0.0187],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:17,640][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.0014, 0.1232, 0.1479, 0.1351, 0.1234, 0.1442, 0.1178, 0.1147, 0.0922],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:17,640][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([0.0042, 0.0514, 0.5555, 0.1067, 0.0149, 0.0452, 0.1072, 0.1129, 0.0019],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:17,641][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([0.3830, 0.1537, 0.0684, 0.1327, 0.1123, 0.0250, 0.1003, 0.0090, 0.0156],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:17,642][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([0.0408, 0.1481, 0.1844, 0.2401, 0.2372, 0.0695, 0.0348, 0.0260, 0.0190],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:17,644][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.0166, 0.2162, 0.0603, 0.3173, 0.1604, 0.1163, 0.0366, 0.0347, 0.0415],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:17,645][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([0.1899, 0.0439, 0.1288, 0.1115, 0.0783, 0.0919, 0.1452, 0.1334, 0.0772],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:17,647][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.0391, 0.1885, 0.0704, 0.1898, 0.0752, 0.1013, 0.0793, 0.1429, 0.1135],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:17,648][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.1179, 0.1336, 0.0927, 0.2108, 0.2651, 0.0558, 0.0549, 0.0395, 0.0297],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:17,650][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([0.1839, 0.0293, 0.1523, 0.1702, 0.1641, 0.1186, 0.0906, 0.0586, 0.0325],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:17,652][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([0.6261, 0.0427, 0.0671, 0.0456, 0.0541, 0.0356, 0.0622, 0.0267, 0.0400],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:17,653][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.6418, 0.0266, 0.0256, 0.0511, 0.0707, 0.0262, 0.1069, 0.0098, 0.0414],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:17,655][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([0.5604, 0.0489, 0.0376, 0.0658, 0.0333, 0.0345, 0.1529, 0.0203, 0.0463],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:17,657][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0019, 0.1107, 0.1313, 0.1115, 0.1120, 0.1261, 0.1024, 0.1073, 0.1016,
        0.0951], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:17,659][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0157, 0.0008, 0.3597, 0.0051, 0.2382, 0.1368, 0.0340, 0.0451, 0.1636,
        0.0011], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:17,660][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.4518, 0.1198, 0.0697, 0.0930, 0.1139, 0.0231, 0.0775, 0.0065, 0.0140,
        0.0307], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:17,662][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0628, 0.1723, 0.1903, 0.1954, 0.1855, 0.0688, 0.0324, 0.0176, 0.0181,
        0.0568], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:17,664][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0294, 0.1993, 0.0553, 0.3185, 0.1303, 0.0952, 0.0339, 0.0262, 0.0289,
        0.0831], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:17,665][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0799, 0.0589, 0.0796, 0.2081, 0.0906, 0.1319, 0.1029, 0.1063, 0.0698,
        0.0719], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:17,666][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.1234, 0.1201, 0.0788, 0.1053, 0.1028, 0.0654, 0.0806, 0.1202, 0.1121,
        0.0913], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:17,666][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.2115, 0.1270, 0.0950, 0.1779, 0.1541, 0.0522, 0.0545, 0.0366, 0.0298,
        0.0613], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:17,667][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.1922, 0.0232, 0.1493, 0.1604, 0.1519, 0.1404, 0.0757, 0.0372, 0.0254,
        0.0443], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:17,669][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.6635, 0.0391, 0.0527, 0.0380, 0.0417, 0.0280, 0.0534, 0.0207, 0.0322,
        0.0306], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:17,670][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.6537, 0.0244, 0.0282, 0.0485, 0.0528, 0.0262, 0.0879, 0.0106, 0.0334,
        0.0343], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:17,672][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.6061, 0.0303, 0.0249, 0.0510, 0.0207, 0.0279, 0.1237, 0.0138, 0.0256,
        0.0760], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:17,674][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0018, 0.1023, 0.1218, 0.0987, 0.1016, 0.1188, 0.0958, 0.0956, 0.0941,
        0.0884, 0.0812], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:17,676][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0273, 0.0029, 0.3619, 0.0013, 0.1134, 0.1030, 0.0392, 0.0413, 0.3065,
        0.0023, 0.0009], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:17,677][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.4288, 0.1226, 0.0759, 0.0863, 0.1209, 0.0182, 0.0643, 0.0052, 0.0131,
        0.0309, 0.0338], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:17,679][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0711, 0.1652, 0.1913, 0.1638, 0.1631, 0.0643, 0.0313, 0.0148, 0.0159,
        0.0577, 0.0615], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:17,681][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0268, 0.1867, 0.0459, 0.2477, 0.1262, 0.0749, 0.0309, 0.0224, 0.0276,
        0.0930, 0.1179], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:17,682][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0787, 0.0829, 0.0838, 0.1300, 0.0772, 0.1265, 0.0991, 0.1041, 0.0666,
        0.0835, 0.0676], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:17,684][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0999, 0.1490, 0.0737, 0.1039, 0.0823, 0.0588, 0.0633, 0.0864, 0.0854,
        0.0909, 0.1064], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:17,686][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2576, 0.1480, 0.0766, 0.1250, 0.1301, 0.0444, 0.0559, 0.0239, 0.0219,
        0.0564, 0.0602], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:17,688][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.2051, 0.0335, 0.1282, 0.1070, 0.1370, 0.1230, 0.0716, 0.0305, 0.0227,
        0.0594, 0.0819], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:17,690][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.6325, 0.0438, 0.0500, 0.0389, 0.0411, 0.0279, 0.0510, 0.0205, 0.0302,
        0.0300, 0.0342], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:17,691][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.6527, 0.0294, 0.0265, 0.0443, 0.0478, 0.0220, 0.0832, 0.0079, 0.0282,
        0.0306, 0.0274], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:17,692][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.5934, 0.0247, 0.0172, 0.0464, 0.0153, 0.0217, 0.1117, 0.0102, 0.0210,
        0.0659, 0.0725], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:17,692][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.0011, 0.0941, 0.1071, 0.1012, 0.0972, 0.1117, 0.0903, 0.0868, 0.0739,
        0.0839, 0.0814, 0.0712], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:17,693][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([0.0099, 0.1553, 0.2130, 0.0884, 0.0382, 0.2138, 0.0655, 0.0170, 0.0423,
        0.1034, 0.0500, 0.0030], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:17,695][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([0.2631, 0.1028, 0.0802, 0.1580, 0.1146, 0.0281, 0.0753, 0.0074, 0.0202,
        0.0471, 0.0748, 0.0285], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:17,696][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([0.0214, 0.1563, 0.1606, 0.1909, 0.1755, 0.0617, 0.0192, 0.0153, 0.0168,
        0.0742, 0.0786, 0.0295], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:17,698][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.0111, 0.1269, 0.0508, 0.2562, 0.1378, 0.0870, 0.0202, 0.0202, 0.0256,
        0.0889, 0.1361, 0.0392], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:17,700][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([0.1095, 0.0830, 0.0737, 0.1751, 0.0458, 0.0846, 0.1164, 0.0725, 0.0548,
        0.0884, 0.0818, 0.0145], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:17,701][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.0495, 0.0868, 0.0469, 0.1100, 0.0718, 0.0551, 0.0477, 0.1049, 0.0908,
        0.1372, 0.1438, 0.0556], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:17,703][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.0551, 0.1278, 0.0860, 0.1746, 0.1873, 0.0647, 0.0342, 0.0406, 0.0354,
        0.0768, 0.0790, 0.0385], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:17,705][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.1126, 0.0272, 0.1320, 0.1811, 0.1199, 0.1189, 0.0567, 0.0241, 0.0233,
        0.0652, 0.1209, 0.0182], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:17,707][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([0.5736, 0.0427, 0.0501, 0.0413, 0.0460, 0.0306, 0.0573, 0.0219, 0.0358,
        0.0328, 0.0365, 0.0312], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:17,708][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([0.4661, 0.0495, 0.0524, 0.0789, 0.0858, 0.0346, 0.0866, 0.0122, 0.0317,
        0.0410, 0.0348, 0.0263], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:17,710][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([0.5234, 0.0334, 0.0175, 0.0475, 0.0175, 0.0254, 0.1221, 0.0132, 0.0235,
        0.0743, 0.0703, 0.0319], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:17,712][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Melissa] are: tensor([0.0014, 0.0866, 0.0954, 0.0914, 0.0836, 0.0998, 0.0783, 0.0791, 0.0731,
        0.0776, 0.0730, 0.0709, 0.0898], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:17,714][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Melissa] are: tensor([0.0086, 0.1212, 0.0212, 0.0646, 0.0768, 0.1740, 0.0108, 0.0080, 0.2803,
        0.1420, 0.0376, 0.0438, 0.0109], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:17,715][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Melissa] are: tensor([0.4368, 0.1387, 0.0375, 0.1013, 0.0695, 0.0201, 0.0686, 0.0046, 0.0131,
        0.0279, 0.0384, 0.0209, 0.0227], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:17,716][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Melissa] are: tensor([0.0339, 0.1282, 0.1167, 0.1863, 0.1603, 0.0681, 0.0258, 0.0201, 0.0208,
        0.0573, 0.0789, 0.0559, 0.0477], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:17,717][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Melissa] are: tensor([0.0174, 0.1389, 0.0373, 0.2711, 0.1107, 0.0755, 0.0215, 0.0240, 0.0270,
        0.0759, 0.1177, 0.0499, 0.0331], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:17,718][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Melissa] are: tensor([0.0510, 0.0850, 0.0270, 0.1653, 0.0672, 0.1350, 0.0897, 0.0964, 0.0883,
        0.0718, 0.0759, 0.0360, 0.0115], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:17,719][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Melissa] are: tensor([0.0774, 0.1416, 0.0227, 0.1037, 0.0368, 0.0411, 0.0622, 0.0623, 0.0926,
        0.1188, 0.1182, 0.0941, 0.0284], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:17,721][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Melissa] are: tensor([0.1888, 0.0860, 0.0815, 0.1501, 0.1401, 0.0386, 0.0430, 0.0220, 0.0236,
        0.0514, 0.0682, 0.0369, 0.0696], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:17,722][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Melissa] are: tensor([0.1730, 0.0304, 0.0459, 0.1449, 0.1137, 0.1051, 0.0677, 0.0328, 0.0286,
        0.0679, 0.1212, 0.0359, 0.0330], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:17,724][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Melissa] are: tensor([0.4831, 0.0481, 0.0515, 0.0522, 0.0508, 0.0391, 0.0635, 0.0277, 0.0387,
        0.0396, 0.0423, 0.0335, 0.0301], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:17,726][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Melissa] are: tensor([0.5903, 0.0303, 0.0355, 0.0457, 0.0525, 0.0289, 0.0848, 0.0093, 0.0304,
        0.0305, 0.0270, 0.0158, 0.0188], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:17,727][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Melissa] are: tensor([0.6200, 0.0326, 0.0185, 0.0276, 0.0124, 0.0196, 0.1094, 0.0102, 0.0211,
        0.0428, 0.0445, 0.0104, 0.0308], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:17,729][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.0007, 0.0815, 0.0938, 0.0904, 0.0821, 0.0948, 0.0762, 0.0716, 0.0597,
        0.0694, 0.0685, 0.0648, 0.0882, 0.0583], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:17,731][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([0.0050, 0.0228, 0.3779, 0.0249, 0.0535, 0.0188, 0.0132, 0.0305, 0.0058,
        0.0270, 0.0254, 0.0916, 0.3022, 0.0014], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:17,732][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([0.4139, 0.1065, 0.0712, 0.0883, 0.0851, 0.0121, 0.0532, 0.0029, 0.0099,
        0.0275, 0.0322, 0.0170, 0.0374, 0.0428], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:17,734][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([0.0739, 0.1216, 0.1428, 0.1507, 0.1380, 0.0542, 0.0275, 0.0141, 0.0131,
        0.0437, 0.0552, 0.0389, 0.0599, 0.0664], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:17,736][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([0.0261, 0.1356, 0.0429, 0.2343, 0.1022, 0.0375, 0.0206, 0.0142, 0.0168,
        0.0707, 0.0996, 0.0478, 0.0394, 0.1122], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:17,738][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([0.0958, 0.0769, 0.0810, 0.1216, 0.0665, 0.0713, 0.0922, 0.0727, 0.0458,
        0.0720, 0.0705, 0.0293, 0.0405, 0.0640], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:17,740][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([0.0523, 0.1244, 0.0390, 0.1271, 0.0598, 0.0408, 0.0418, 0.0503, 0.0556,
        0.0969, 0.1002, 0.0641, 0.0409, 0.1069], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:17,741][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.2801, 0.0806, 0.0453, 0.1075, 0.0795, 0.0359, 0.0486, 0.0236, 0.0195,
        0.0444, 0.0701, 0.0489, 0.0456, 0.0704], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:17,742][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([0.2101, 0.0222, 0.1041, 0.1079, 0.0924, 0.0561, 0.0511, 0.0191, 0.0118,
        0.0519, 0.0811, 0.0304, 0.0731, 0.0885], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:17,743][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([0.5587, 0.0368, 0.0472, 0.0361, 0.0410, 0.0283, 0.0501, 0.0199, 0.0318,
        0.0303, 0.0340, 0.0296, 0.0292, 0.0270], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:17,744][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([0.5700, 0.0290, 0.0270, 0.0510, 0.0649, 0.0211, 0.0789, 0.0086, 0.0364,
        0.0300, 0.0254, 0.0214, 0.0136, 0.0225], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:17,746][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([0.6064, 0.0194, 0.0181, 0.0292, 0.0136, 0.0186, 0.1108, 0.0085, 0.0214,
        0.0445, 0.0435, 0.0126, 0.0287, 0.0246], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:17,747][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0009, 0.0761, 0.0874, 0.0777, 0.0750, 0.0888, 0.0718, 0.0704, 0.0634,
        0.0649, 0.0618, 0.0590, 0.0817, 0.0602, 0.0608], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:17,749][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0797, 0.0018, 0.1347, 0.0018, 0.0900, 0.1027, 0.0683, 0.0517, 0.1691,
        0.0020, 0.0018, 0.0119, 0.0794, 0.2042, 0.0007], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:17,751][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.7518, 0.0372, 0.0196, 0.0241, 0.0342, 0.0043, 0.0424, 0.0012, 0.0040,
        0.0086, 0.0104, 0.0080, 0.0113, 0.0202, 0.0226], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:17,753][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.1124, 0.1143, 0.1293, 0.1305, 0.1290, 0.0375, 0.0300, 0.0097, 0.0101,
        0.0389, 0.0461, 0.0282, 0.0440, 0.0661, 0.0741], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:17,754][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0393, 0.1143, 0.0323, 0.1360, 0.0865, 0.0369, 0.0221, 0.0123, 0.0147,
        0.0465, 0.0624, 0.0313, 0.0353, 0.1419, 0.1883], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:17,756][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.1363, 0.0511, 0.0587, 0.1016, 0.0443, 0.0797, 0.1049, 0.0837, 0.0516,
        0.0526, 0.0524, 0.0217, 0.0253, 0.0739, 0.0620], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:17,758][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0559, 0.0954, 0.0479, 0.0742, 0.0484, 0.0332, 0.0321, 0.0444, 0.0560,
        0.0574, 0.0624, 0.0655, 0.0397, 0.1548, 0.1328], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:17,760][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.1019, 0.0683, 0.0608, 0.1133, 0.1321, 0.0367, 0.0337, 0.0185, 0.0213,
        0.0478, 0.0520, 0.0162, 0.0423, 0.1582, 0.0970], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:17,761][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.3025, 0.0135, 0.0739, 0.0842, 0.0755, 0.0493, 0.0534, 0.0169, 0.0115,
        0.0295, 0.0547, 0.0172, 0.0487, 0.0965, 0.0727], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:17,763][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.5958, 0.0340, 0.0420, 0.0322, 0.0334, 0.0237, 0.0445, 0.0164, 0.0260,
        0.0253, 0.0286, 0.0244, 0.0238, 0.0231, 0.0268], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:17,765][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.7096, 0.0187, 0.0144, 0.0254, 0.0357, 0.0143, 0.0672, 0.0047, 0.0223,
        0.0197, 0.0155, 0.0145, 0.0078, 0.0112, 0.0189], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:17,767][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.6006, 0.0236, 0.0140, 0.0333, 0.0126, 0.0160, 0.0961, 0.0083, 0.0164,
        0.0467, 0.0452, 0.0101, 0.0212, 0.0189, 0.0369], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:17,770][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:31:17,772][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 7136],
        [ 9153],
        [ 2422],
        [ 3550],
        [21220],
        [ 9824],
        [ 7081],
        [ 8077],
        [ 3925],
        [ 3418],
        [ 2780],
        [ 8787],
        [ 3029],
        [ 3700],
        [ 1397]], device='cuda:0')
[2024-07-24 10:31:17,774][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 7298],
        [12326],
        [ 3287],
        [ 5227],
        [19423],
        [10066],
        [ 7793],
        [ 7015],
        [ 3872],
        [ 5692],
        [ 5034],
        [ 9911],
        [ 3176],
        [ 4282],
        [ 2281]], device='cuda:0')
[2024-07-24 10:31:17,775][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[43441],
        [30808],
        [24548],
        [26005],
        [24470],
        [24045],
        [23837],
        [22957],
        [22983],
        [23403],
        [23893],
        [24269],
        [23919],
        [23881],
        [23965]], device='cuda:0')
[2024-07-24 10:31:17,777][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[18907],
        [ 6898],
        [ 3221],
        [ 3999],
        [ 2327],
        [ 2498],
        [ 2370],
        [ 2694],
        [ 3142],
        [ 3288],
        [ 3549],
        [ 3887],
        [ 3601],
        [ 3640],
        [ 3719]], device='cuda:0')
[2024-07-24 10:31:17,779][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[12224],
        [28345],
        [22245],
        [23568],
        [24108],
        [23986],
        [23342],
        [22536],
        [21686],
        [21335],
        [21693],
        [21722],
        [21871],
        [21862],
        [22023]], device='cuda:0')
[2024-07-24 10:31:17,780][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[ 2656],
        [20822],
        [33631],
        [33164],
        [36145],
        [37075],
        [36545],
        [36453],
        [36904],
        [36945],
        [36749],
        [36938],
        [37529],
        [31309],
        [28719]], device='cuda:0')
[2024-07-24 10:31:17,782][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[13186],
        [14802],
        [19481],
        [18586],
        [25496],
        [21224],
        [23149],
        [29818],
        [30406],
        [26622],
        [28347],
        [31277],
        [30100],
        [27637],
        [28819]], device='cuda:0')
[2024-07-24 10:31:17,784][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[44878],
        [46685],
        [46081],
        [45925],
        [44914],
        [45572],
        [45583],
        [46088],
        [47724],
        [47372],
        [47571],
        [47503],
        [48055],
        [47856],
        [47412]], device='cuda:0')
[2024-07-24 10:31:17,785][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[38341],
        [37902],
        [38207],
        [39168],
        [38870],
        [39246],
        [39581],
        [39689],
        [38846],
        [38182],
        [38054],
        [38325],
        [37954],
        [37749],
        [37605]], device='cuda:0')
[2024-07-24 10:31:17,787][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[  815],
        [13393],
        [ 5983],
        [ 8306],
        [12870],
        [ 9804],
        [13684],
        [12103],
        [12057],
        [ 9866],
        [ 9217],
        [12008],
        [ 9498],
        [ 7298],
        [ 9515]], device='cuda:0')
[2024-07-24 10:31:17,789][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[37076],
        [14150],
        [16520],
        [18336],
        [19373],
        [19573],
        [19556],
        [19836],
        [19510],
        [19557],
        [19613],
        [19482],
        [19857],
        [19830],
        [19648]], device='cuda:0')
[2024-07-24 10:31:17,790][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[  689],
        [ 5056],
        [ 9356],
        [13418],
        [14276],
        [15957],
        [17889],
        [17953],
        [16850],
        [19592],
        [19119],
        [19022],
        [18729],
        [21118],
        [21107]], device='cuda:0')
[2024-07-24 10:31:17,792][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[22153],
        [22196],
        [22486],
        [23321],
        [27054],
        [26793],
        [29426],
        [27343],
        [29800],
        [28823],
        [28836],
        [29474],
        [29434],
        [30377],
        [29423]], device='cuda:0')
[2024-07-24 10:31:17,794][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[18300],
        [19123],
        [18941],
        [20836],
        [19365],
        [23472],
        [22121],
        [18933],
        [18414],
        [19050],
        [18885],
        [19332],
        [17573],
        [17312],
        [18044]], device='cuda:0')
[2024-07-24 10:31:17,796][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[41945],
        [14846],
        [25166],
        [17334],
        [31845],
        [19314],
        [18950],
        [20855],
        [19873],
        [10345],
        [ 9855],
        [15457],
        [16843],
        [15609],
        [13156]], device='cuda:0')
[2024-07-24 10:31:17,797][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[10176],
        [22337],
        [26075],
        [24321],
        [23573],
        [23455],
        [23378],
        [23087],
        [22708],
        [22732],
        [22811],
        [22782],
        [23289],
        [23176],
        [22827]], device='cuda:0')
[2024-07-24 10:31:17,799][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[19599],
        [18778],
        [19445],
        [35545],
        [32489],
        [33431],
        [27009],
        [26266],
        [33788],
        [32126],
        [33858],
        [24096],
        [19374],
        [32585],
        [27716]], device='cuda:0')
[2024-07-24 10:31:17,800][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[ 4326],
        [17112],
        [15703],
        [11794],
        [11937],
        [10579],
        [ 8945],
        [ 9953],
        [ 9750],
        [ 9639],
        [ 9418],
        [ 8552],
        [ 9698],
        [ 9446],
        [ 8008]], device='cuda:0')
[2024-07-24 10:31:17,802][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[18904],
        [34738],
        [29137],
        [26564],
        [29391],
        [30138],
        [32622],
        [31374],
        [32356],
        [32806],
        [33769],
        [34065],
        [35062],
        [33740],
        [35001]], device='cuda:0')
[2024-07-24 10:31:17,804][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[27787],
        [29022],
        [29120],
        [21585],
        [18965],
        [20248],
        [19273],
        [19141],
        [19613],
        [19532],
        [20286],
        [19040],
        [19400],
        [21087],
        [23190]], device='cuda:0')
[2024-07-24 10:31:17,805][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[32742],
        [31381],
        [31389],
        [31110],
        [30510],
        [31089],
        [31650],
        [29544],
        [29934],
        [31323],
        [31158],
        [31312],
        [31559],
        [31572],
        [30468]], device='cuda:0')
[2024-07-24 10:31:17,807][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[47390],
        [41306],
        [40863],
        [41956],
        [41575],
        [42134],
        [41985],
        [42445],
        [42319],
        [42975],
        [43566],
        [43853],
        [44790],
        [44067],
        [44413]], device='cuda:0')
[2024-07-24 10:31:17,809][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[29585],
        [30293],
        [30846],
        [27181],
        [20230],
        [22679],
        [20783],
        [20458],
        [19355],
        [20746],
        [21886],
        [19685],
        [21262],
        [19943],
        [15758]], device='cuda:0')
[2024-07-24 10:31:17,810][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[38027],
        [40216],
        [40431],
        [44774],
        [45249],
        [45990],
        [46470],
        [46210],
        [46113],
        [46180],
        [46462],
        [46515],
        [46417],
        [46926],
        [45978]], device='cuda:0')
[2024-07-24 10:31:17,812][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[44712],
        [44940],
        [43796],
        [44232],
        [43094],
        [43499],
        [40386],
        [42374],
        [39198],
        [40249],
        [39469],
        [37416],
        [34263],
        [36909],
        [38301]], device='cuda:0')
[2024-07-24 10:31:17,814][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[19991],
        [19486],
        [19358],
        [16894],
        [18349],
        [18718],
        [17288],
        [18273],
        [19944],
        [19925],
        [19754],
        [18617],
        [20757],
        [20905],
        [21665]], device='cuda:0')
[2024-07-24 10:31:17,815][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[27073],
        [29473],
        [31090],
        [33210],
        [36927],
        [38989],
        [39302],
        [38144],
        [41564],
        [41299],
        [41101],
        [41106],
        [42290],
        [42602],
        [42210]], device='cuda:0')
[2024-07-24 10:31:17,817][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[6144],
        [5188],
        [5089],
        [5015],
        [6981],
        [6882],
        [9122],
        [8309],
        [8758],
        [7521],
        [7073],
        [9075],
        [8055],
        [7206],
        [7021]], device='cuda:0')
[2024-07-24 10:31:17,819][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[6321],
        [4009],
        [2461],
        [2650],
        [1466],
        [2042],
        [1822],
        [2183],
        [1315],
        [2070],
        [1826],
        [2550],
        [2902],
        [1720],
        [2206]], device='cuda:0')
[2024-07-24 10:31:17,821][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[22483],
        [22483],
        [22483],
        [22483],
        [22483],
        [22483],
        [22483],
        [22483],
        [22483],
        [22483],
        [22483],
        [22483],
        [22483],
        [22483],
        [22483]], device='cuda:0')
[2024-07-24 10:31:17,886][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:31:17,887][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:17,888][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:17,890][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:17,891][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:17,892][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:17,893][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:17,894][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:17,895][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:17,897][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:17,898][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:17,899][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:17,901][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:17,902][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.4914, 0.5086], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:17,903][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.3349, 0.6651], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:17,904][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.3166, 0.6834], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:17,905][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.9778, 0.0222], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:17,906][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.9467, 0.0533], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:17,907][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0677, 0.9323], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:17,908][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.1857, 0.8143], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:17,910][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.5892, 0.4108], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:17,911][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.7700, 0.2300], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:17,912][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0069, 0.9931], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:17,914][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.4365, 0.5635], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:17,915][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.1460, 0.8540], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:17,917][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Melissa] are: tensor([0.3515, 0.3709, 0.2776], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:17,919][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Melissa] are: tensor([0.2107, 0.4151, 0.3742], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:17,920][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Melissa] are: tensor([0.2004, 0.4017, 0.3979], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:17,922][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Melissa] are: tensor([0.9765, 0.0126, 0.0109], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:17,924][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Melissa] are: tensor([0.8605, 0.0717, 0.0678], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:17,925][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Melissa] are: tensor([0.0321, 0.5500, 0.4179], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:17,927][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Melissa] are: tensor([0.1073, 0.4367, 0.4561], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:17,928][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Melissa] are: tensor([0.7400, 0.1346, 0.1254], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:17,929][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Melissa] are: tensor([0.8152, 0.1341, 0.0507], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:17,930][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Melissa] are: tensor([0.0058, 0.8995, 0.0947], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:17,931][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Melissa] are: tensor([0.2855, 0.3586, 0.3559], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:17,931][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Melissa] are: tensor([0.1227, 0.6778, 0.1995], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:17,932][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.2632, 0.2942, 0.2292, 0.2135], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:17,934][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.1186, 0.2562, 0.2553, 0.3698], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:17,935][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.1419, 0.2856, 0.2790, 0.2935], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:17,937][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.8741, 0.0241, 0.0375, 0.0643], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:17,938][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.8090, 0.0652, 0.0606, 0.0652], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:17,940][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0306, 0.3592, 0.2919, 0.3182], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:17,942][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0709, 0.3065, 0.3134, 0.3093], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:17,943][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.4200, 0.1573, 0.1816, 0.2411], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:17,945][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.7584, 0.0767, 0.0553, 0.1096], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:17,947][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0020, 0.5090, 0.1258, 0.3632], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:17,948][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.1973, 0.2520, 0.2551, 0.2955], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:17,950][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.1066, 0.4338, 0.1017, 0.3580], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:17,951][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Benjamin] are: tensor([0.2110, 0.2479, 0.1857, 0.2049, 0.1506], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:17,953][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Benjamin] are: tensor([0.0531, 0.1630, 0.2452, 0.2756, 0.2630], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:17,955][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Benjamin] are: tensor([0.1197, 0.2188, 0.2129, 0.2227, 0.2260], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:17,956][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Benjamin] are: tensor([0.6682, 0.0562, 0.0430, 0.1464, 0.0862], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:17,956][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Benjamin] are: tensor([0.7526, 0.0588, 0.0552, 0.0580, 0.0753], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:17,957][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Benjamin] are: tensor([0.0212, 0.2840, 0.2188, 0.2740, 0.2021], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:17,958][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Benjamin] are: tensor([0.0572, 0.2316, 0.2359, 0.2312, 0.2442], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:17,959][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Benjamin] are: tensor([0.3178, 0.0742, 0.1002, 0.1875, 0.3203], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:17,961][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Benjamin] are: tensor([0.4962, 0.1268, 0.0734, 0.2021, 0.1015], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:17,963][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Benjamin] are: tensor([0.0044, 0.3455, 0.1471, 0.4225, 0.0805], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:17,964][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Benjamin] are: tensor([0.1712, 0.2089, 0.2004, 0.2322, 0.1872], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:17,966][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Benjamin] are: tensor([0.0375, 0.3266, 0.1036, 0.3566, 0.1757], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:17,967][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.2040, 0.2076, 0.1465, 0.1508, 0.1266, 0.1645], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:17,969][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.0499, 0.1306, 0.1473, 0.2541, 0.1978, 0.2203], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:17,971][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.0871, 0.1802, 0.1764, 0.1851, 0.1901, 0.1810], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:17,972][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.3020, 0.0800, 0.1583, 0.2184, 0.1967, 0.0445], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:17,974][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.7221, 0.0539, 0.0491, 0.0537, 0.0691, 0.0521], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:17,976][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.0188, 0.2229, 0.1779, 0.2137, 0.1724, 0.1943], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:17,977][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.0399, 0.1849, 0.1909, 0.1855, 0.1963, 0.2025], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:17,979][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.2060, 0.0941, 0.1188, 0.1488, 0.2823, 0.1500], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:17,981][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.4896, 0.1136, 0.0657, 0.1897, 0.1096, 0.0319], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:17,982][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.0014, 0.2694, 0.1500, 0.3400, 0.1476, 0.0917], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:17,983][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.1441, 0.1720, 0.1696, 0.1878, 0.1535, 0.1730], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:17,983][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0406, 0.3059, 0.0853, 0.3465, 0.1850, 0.0366], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:17,984][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.1353, 0.2099, 0.1372, 0.1513, 0.1108, 0.1670, 0.0886],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:17,986][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0019, 0.0856, 0.0984, 0.2291, 0.3153, 0.2132, 0.0567],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:17,987][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0584, 0.1564, 0.1554, 0.1636, 0.1689, 0.1582, 0.1390],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:17,989][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0187, 0.1588, 0.1579, 0.2497, 0.2602, 0.1122, 0.0426],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:17,990][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.5056, 0.0749, 0.0639, 0.0718, 0.0848, 0.0690, 0.1301],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:17,992][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0064, 0.2172, 0.1609, 0.1830, 0.1470, 0.1842, 0.1012],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:17,994][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0242, 0.1577, 0.1625, 0.1600, 0.1673, 0.1695, 0.1587],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:17,995][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0366, 0.1329, 0.1221, 0.2002, 0.2490, 0.1952, 0.0640],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:17,997][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0305, 0.1409, 0.1037, 0.3050, 0.2164, 0.1435, 0.0600],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:17,998][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ a] are: tensor([2.3963e-05, 3.5879e-01, 3.8256e-02, 4.0051e-01, 5.2675e-02, 1.4912e-01,
        6.1966e-04], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:18,000][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.1044, 0.1435, 0.1527, 0.1613, 0.1389, 0.1561, 0.1431],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:18,002][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0039, 0.1684, 0.1209, 0.3306, 0.2250, 0.1362, 0.0149],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:18,003][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.1292, 0.1654, 0.1133, 0.1253, 0.0940, 0.1474, 0.1070, 0.1185],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:18,005][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ long] are: tensor([0.0313, 0.0974, 0.0996, 0.1743, 0.1556, 0.1331, 0.1149, 0.1938],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:18,007][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.0530, 0.1359, 0.1347, 0.1418, 0.1441, 0.1362, 0.1208, 0.1334],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:18,007][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ long] are: tensor([0.3160, 0.0637, 0.0681, 0.1651, 0.1323, 0.0317, 0.2179, 0.0053],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:18,008][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.6178, 0.0468, 0.0420, 0.0456, 0.0597, 0.0446, 0.1027, 0.0408],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:18,009][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ long] are: tensor([0.0125, 0.1742, 0.1257, 0.1657, 0.1196, 0.1512, 0.0936, 0.1575],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:18,010][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.0246, 0.1363, 0.1402, 0.1381, 0.1433, 0.1453, 0.1345, 0.1377],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:18,011][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.2387, 0.0800, 0.0586, 0.1110, 0.1738, 0.1070, 0.1537, 0.0773],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:18,013][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.4262, 0.0687, 0.0449, 0.1238, 0.0828, 0.0355, 0.2011, 0.0170],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:18,015][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ long] are: tensor([0.0014, 0.2776, 0.0554, 0.3911, 0.0890, 0.0717, 0.0068, 0.1069],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:18,016][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.1067, 0.1301, 0.1293, 0.1414, 0.1159, 0.1328, 0.1340, 0.1098],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:18,018][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ long] are: tensor([0.0271, 0.2378, 0.0829, 0.3377, 0.1814, 0.0566, 0.0371, 0.0395],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:18,020][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.1168, 0.1402, 0.0959, 0.1162, 0.0830, 0.1238, 0.0947, 0.1127, 0.1167],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:18,022][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([0.0205, 0.0906, 0.1028, 0.1500, 0.1657, 0.1076, 0.1164, 0.1566, 0.0898],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:18,023][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.0404, 0.1216, 0.1218, 0.1283, 0.1312, 0.1235, 0.1089, 0.1198, 0.1046],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:18,025][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([0.2393, 0.0745, 0.0742, 0.2108, 0.1297, 0.0417, 0.2074, 0.0087, 0.0136],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:18,027][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.5679, 0.0467, 0.0423, 0.0475, 0.0617, 0.0460, 0.1018, 0.0427, 0.0434],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:18,028][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([0.0101, 0.1608, 0.1124, 0.1393, 0.1000, 0.1263, 0.0874, 0.1478, 0.1159],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:18,030][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.0171, 0.1236, 0.1247, 0.1230, 0.1267, 0.1303, 0.1201, 0.1197, 0.1149],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:18,032][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.1454, 0.0706, 0.0727, 0.1296, 0.2056, 0.1179, 0.1105, 0.0907, 0.0570],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:18,033][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.3526, 0.0758, 0.0467, 0.1599, 0.0706, 0.0390, 0.1975, 0.0291, 0.0288],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:18,035][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.0016, 0.1745, 0.1068, 0.2460, 0.0919, 0.0993, 0.0081, 0.2082, 0.0636],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:18,037][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.0872, 0.1184, 0.1232, 0.1279, 0.1071, 0.1183, 0.1143, 0.0952, 0.1084],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:18,038][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([0.0205, 0.1853, 0.0820, 0.3423, 0.1688, 0.0650, 0.0315, 0.0585, 0.0461],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:18,038][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0782, 0.1223, 0.0935, 0.0971, 0.0842, 0.1212, 0.0781, 0.1000, 0.1244,
        0.1010], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:18,039][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0299, 0.0801, 0.0907, 0.1296, 0.0935, 0.1212, 0.0684, 0.1710, 0.0671,
        0.1485], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:18,040][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0407, 0.1096, 0.1085, 0.1151, 0.1178, 0.1114, 0.0970, 0.1081, 0.0933,
        0.0985], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:18,042][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.3230, 0.0348, 0.1075, 0.1435, 0.1076, 0.0410, 0.1961, 0.0075, 0.0158,
        0.0231], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:18,043][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.4772, 0.0513, 0.0475, 0.0519, 0.0641, 0.0513, 0.1039, 0.0474, 0.0491,
        0.0564], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:18,045][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0102, 0.1228, 0.1013, 0.1188, 0.1005, 0.1185, 0.0703, 0.1266, 0.1126,
        0.1184], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:18,047][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0161, 0.1128, 0.1126, 0.1134, 0.1147, 0.1145, 0.1051, 0.1045, 0.1016,
        0.1046], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:18,048][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0881, 0.0812, 0.0878, 0.1245, 0.1874, 0.1167, 0.0696, 0.0915, 0.0600,
        0.0932], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:18,050][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.3702, 0.0724, 0.0575, 0.1171, 0.0899, 0.0342, 0.1620, 0.0210, 0.0258,
        0.0498], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:18,052][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0004, 0.2528, 0.0614, 0.2317, 0.0866, 0.0949, 0.0027, 0.1388, 0.0464,
        0.0843], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:18,054][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0921, 0.1047, 0.1027, 0.1111, 0.0942, 0.1047, 0.1055, 0.0869, 0.0979,
        0.1002], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:18,055][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0384, 0.1948, 0.0740, 0.2804, 0.1468, 0.0490, 0.0353, 0.0337, 0.0349,
        0.1126], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:18,057][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0577, 0.1108, 0.0904, 0.0846, 0.0824, 0.1166, 0.0729, 0.0958, 0.1177,
        0.0945, 0.0766], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:18,059][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0401, 0.0731, 0.0612, 0.1003, 0.0756, 0.1057, 0.0481, 0.1481, 0.0575,
        0.1427, 0.1474], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:18,060][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0433, 0.0987, 0.0968, 0.1023, 0.1046, 0.0997, 0.0877, 0.0975, 0.0849,
        0.0895, 0.0949], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:18,062][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.2950, 0.0525, 0.0932, 0.1615, 0.1124, 0.0325, 0.1700, 0.0050, 0.0121,
        0.0231, 0.0425], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:18,063][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.4489, 0.0484, 0.0442, 0.0491, 0.0589, 0.0481, 0.0983, 0.0444, 0.0458,
        0.0535, 0.0603], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:18,064][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0084, 0.1137, 0.0965, 0.1008, 0.0949, 0.1035, 0.0664, 0.1192, 0.1057,
        0.1078, 0.0830], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:18,065][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0187, 0.1015, 0.1011, 0.1012, 0.1033, 0.1035, 0.0959, 0.0948, 0.0909,
        0.0930, 0.0960], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:18,066][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0988, 0.0708, 0.0798, 0.1038, 0.1608, 0.1020, 0.0743, 0.0789, 0.0548,
        0.0839, 0.0922], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:18,067][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.3762, 0.0607, 0.0552, 0.0936, 0.0812, 0.0251, 0.1509, 0.0154, 0.0211,
        0.0461, 0.0744], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:18,069][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0004, 0.2693, 0.0463, 0.1870, 0.0602, 0.0797, 0.0027, 0.1281, 0.0413,
        0.0833, 0.1017], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:18,071][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0841, 0.0934, 0.0897, 0.1035, 0.0849, 0.0952, 0.0964, 0.0785, 0.0876,
        0.0888, 0.0979], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:18,072][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0347, 0.1764, 0.0568, 0.2011, 0.1204, 0.0435, 0.0330, 0.0313, 0.0325,
        0.1197, 0.1505], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:18,074][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.0666, 0.0978, 0.0719, 0.0863, 0.0657, 0.0850, 0.0853, 0.0879, 0.0940,
        0.0857, 0.0806, 0.0932], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:18,076][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([0.0216, 0.0674, 0.0563, 0.0978, 0.0987, 0.0816, 0.0454, 0.1091, 0.0632,
        0.1226, 0.1315, 0.1049], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:18,078][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.0321, 0.0900, 0.0898, 0.0954, 0.0965, 0.0926, 0.0812, 0.0895, 0.0779,
        0.0827, 0.0873, 0.0850], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:18,080][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([0.1323, 0.0735, 0.0863, 0.2143, 0.1568, 0.0484, 0.1438, 0.0096, 0.0160,
        0.0318, 0.0692, 0.0180], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:18,081][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.4330, 0.0458, 0.0427, 0.0455, 0.0559, 0.0451, 0.0920, 0.0413, 0.0439,
        0.0493, 0.0556, 0.0499], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:18,083][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([0.0061, 0.1081, 0.0843, 0.0997, 0.0756, 0.0930, 0.0628, 0.1075, 0.0891,
        0.1020, 0.0823, 0.0895], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:18,085][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.0127, 0.0961, 0.0932, 0.0942, 0.0962, 0.0947, 0.0879, 0.0873, 0.0820,
        0.0844, 0.0887, 0.0826], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:18,086][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.0665, 0.0594, 0.0575, 0.0992, 0.1402, 0.0811, 0.0560, 0.0813, 0.0690,
        0.0819, 0.0942, 0.1137], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:18,088][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.1580, 0.0629, 0.0554, 0.1760, 0.0825, 0.0463, 0.1081, 0.0271, 0.0287,
        0.0735, 0.1361, 0.0455], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:18,090][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([0.0004, 0.2066, 0.0618, 0.2576, 0.0378, 0.0774, 0.0029, 0.0856, 0.0373,
        0.0817, 0.1312, 0.0196], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:18,090][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.0672, 0.0883, 0.0864, 0.0977, 0.0796, 0.0891, 0.0855, 0.0731, 0.0819,
        0.0814, 0.0918, 0.0781], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:18,091][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([0.0094, 0.1094, 0.0570, 0.2133, 0.1220, 0.0665, 0.0168, 0.0344, 0.0401,
        0.1230, 0.1559, 0.0522], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:18,092][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Melissa] are: tensor([0.0628, 0.0949, 0.0671, 0.0775, 0.0595, 0.0855, 0.0692, 0.0771, 0.0897,
        0.0809, 0.0717, 0.0921, 0.0721], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:18,094][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Melissa] are: tensor([0.0283, 0.0587, 0.0532, 0.0878, 0.0670, 0.0745, 0.0597, 0.0836, 0.0374,
        0.1013, 0.1204, 0.1172, 0.1108], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:18,096][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Melissa] are: tensor([0.0370, 0.0826, 0.0822, 0.0854, 0.0867, 0.0827, 0.0741, 0.0818, 0.0716,
        0.0749, 0.0793, 0.0784, 0.0834], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:18,097][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Melissa] are: tensor([0.2255, 0.0608, 0.0628, 0.1951, 0.0879, 0.0350, 0.1684, 0.0076, 0.0131,
        0.0252, 0.0546, 0.0171, 0.0469], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:18,099][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Melissa] are: tensor([0.4206, 0.0424, 0.0390, 0.0418, 0.0515, 0.0415, 0.0871, 0.0386, 0.0406,
        0.0463, 0.0515, 0.0470, 0.0521], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:18,101][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Melissa] are: tensor([0.0055, 0.0990, 0.0767, 0.0926, 0.0728, 0.0836, 0.0571, 0.0966, 0.0854,
        0.0922, 0.0760, 0.0912, 0.0713], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:18,102][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Melissa] are: tensor([0.0170, 0.0853, 0.0870, 0.0856, 0.0890, 0.0875, 0.0799, 0.0809, 0.0746,
        0.0762, 0.0805, 0.0744, 0.0821], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:18,104][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Melissa] are: tensor([0.0844, 0.0455, 0.0450, 0.0841, 0.1193, 0.0902, 0.0669, 0.0664, 0.0589,
        0.0769, 0.0866, 0.1233, 0.0524], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:18,106][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Melissa] are: tensor([0.3044, 0.0603, 0.0276, 0.1323, 0.0552, 0.0317, 0.1339, 0.0157, 0.0257,
        0.0483, 0.0956, 0.0370, 0.0322], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:18,107][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Melissa] are: tensor([2.1993e-04, 2.5078e-01, 2.5158e-02, 2.2708e-01, 5.8217e-02, 8.9406e-02,
        2.0998e-03, 1.1670e-01, 3.7365e-02, 6.2200e-02, 7.9484e-02, 3.5187e-02,
        1.6100e-02], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:18,109][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Melissa] are: tensor([0.0768, 0.0860, 0.0808, 0.0874, 0.0702, 0.0773, 0.0806, 0.0642, 0.0741,
        0.0748, 0.0835, 0.0697, 0.0746], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:18,111][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Melissa] are: tensor([0.0179, 0.1443, 0.0457, 0.2082, 0.1059, 0.0453, 0.0211, 0.0283, 0.0350,
        0.0896, 0.1370, 0.0673, 0.0544], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:18,112][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.0458, 0.0933, 0.0697, 0.0722, 0.0554, 0.0819, 0.0493, 0.0672, 0.0828,
        0.0723, 0.0673, 0.0901, 0.0715, 0.0811], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:18,114][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ said] are: tensor([0.0374, 0.0532, 0.0416, 0.0689, 0.0513, 0.0522, 0.0534, 0.0826, 0.0359,
        0.1031, 0.1049, 0.1107, 0.1112, 0.0935], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:18,116][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.0258, 0.0767, 0.0768, 0.0807, 0.0828, 0.0775, 0.0685, 0.0759, 0.0664,
        0.0691, 0.0737, 0.0724, 0.0793, 0.0744], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:18,117][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ said] are: tensor([0.1779, 0.0462, 0.0837, 0.1548, 0.1107, 0.0309, 0.1453, 0.0069, 0.0140,
        0.0241, 0.0463, 0.0108, 0.0612, 0.0871], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:18,118][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.3917, 0.0407, 0.0376, 0.0412, 0.0511, 0.0402, 0.0835, 0.0373, 0.0388,
        0.0441, 0.0498, 0.0456, 0.0514, 0.0470], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:18,118][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ said] are: tensor([0.0079, 0.0936, 0.0761, 0.0854, 0.0689, 0.0781, 0.0499, 0.0877, 0.0769,
        0.0841, 0.0704, 0.0856, 0.0655, 0.0699], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:18,120][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.0103, 0.0796, 0.0814, 0.0795, 0.0834, 0.0837, 0.0749, 0.0742, 0.0689,
        0.0720, 0.0748, 0.0681, 0.0755, 0.0737], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:18,122][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.0764, 0.0517, 0.0447, 0.0799, 0.0942, 0.0732, 0.0535, 0.0556, 0.0386,
        0.0638, 0.0732, 0.0980, 0.0496, 0.1478], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:18,124][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.2959, 0.0637, 0.0431, 0.1006, 0.0573, 0.0176, 0.1138, 0.0128, 0.0162,
        0.0453, 0.0720, 0.0277, 0.0421, 0.0919], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:18,125][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ said] are: tensor([0.0006, 0.1812, 0.0626, 0.2228, 0.0835, 0.0580, 0.0033, 0.0810, 0.0275,
        0.0740, 0.0936, 0.0334, 0.0403, 0.0381], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:18,127][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.0592, 0.0752, 0.0777, 0.0809, 0.0686, 0.0743, 0.0710, 0.0589, 0.0674,
        0.0700, 0.0759, 0.0658, 0.0719, 0.0831], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:18,129][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ said] are: tensor([0.0305, 0.1392, 0.0491, 0.1935, 0.0975, 0.0249, 0.0268, 0.0231, 0.0218,
        0.0884, 0.1147, 0.0581, 0.0536, 0.0786], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:18,131][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0389, 0.0857, 0.0622, 0.0691, 0.0546, 0.0781, 0.0523, 0.0654, 0.0765,
        0.0687, 0.0619, 0.0773, 0.0603, 0.0785, 0.0705], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:18,132][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0366, 0.0485, 0.0363, 0.0637, 0.0418, 0.0616, 0.0357, 0.0782, 0.0346,
        0.0842, 0.0924, 0.1116, 0.0972, 0.0946, 0.0831], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:18,134][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0292, 0.0711, 0.0705, 0.0744, 0.0766, 0.0726, 0.0632, 0.0699, 0.0606,
        0.0641, 0.0686, 0.0672, 0.0716, 0.0692, 0.0714], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:18,136][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.3222, 0.0320, 0.0564, 0.1135, 0.0862, 0.0178, 0.1631, 0.0030, 0.0072,
        0.0138, 0.0294, 0.0078, 0.0379, 0.0570, 0.0527], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:18,138][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.3633, 0.0405, 0.0375, 0.0400, 0.0493, 0.0392, 0.0787, 0.0359, 0.0380,
        0.0427, 0.0477, 0.0430, 0.0486, 0.0453, 0.0502], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:18,139][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0060, 0.0858, 0.0713, 0.0762, 0.0668, 0.0744, 0.0451, 0.0853, 0.0716,
        0.0782, 0.0642, 0.0790, 0.0631, 0.0685, 0.0645], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:18,141][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0123, 0.0742, 0.0745, 0.0746, 0.0766, 0.0757, 0.0697, 0.0703, 0.0664,
        0.0678, 0.0697, 0.0647, 0.0705, 0.0679, 0.0650], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:18,143][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.1009, 0.0428, 0.0375, 0.0629, 0.0958, 0.0590, 0.0584, 0.0406, 0.0326,
        0.0493, 0.0564, 0.0806, 0.0406, 0.1353, 0.1072], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:18,143][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.4366, 0.0350, 0.0256, 0.0520, 0.0397, 0.0126, 0.1157, 0.0070, 0.0121,
        0.0245, 0.0420, 0.0185, 0.0266, 0.0731, 0.0790], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:18,144][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0006, 0.1821, 0.0378, 0.1740, 0.0508, 0.0642, 0.0036, 0.0929, 0.0310,
        0.0588, 0.0789, 0.0259, 0.0257, 0.0498, 0.1238], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:18,145][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0585, 0.0673, 0.0691, 0.0722, 0.0633, 0.0691, 0.0678, 0.0573, 0.0649,
        0.0637, 0.0699, 0.0630, 0.0654, 0.0760, 0.0726], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:18,147][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0299, 0.1186, 0.0394, 0.1474, 0.0936, 0.0237, 0.0243, 0.0205, 0.0239,
        0.0682, 0.0941, 0.0356, 0.0395, 0.0920, 0.1493], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:18,224][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:31:18,225][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:18,226][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:18,227][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:18,228][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:18,229][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:18,230][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:18,232][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:18,233][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:18,233][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:18,234][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:18,235][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:18,235][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:18,236][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.9561, 0.0439], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:18,237][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.3956, 0.6044], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:18,238][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.8831, 0.1169], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:18,238][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.9251, 0.0749], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:18,239][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.9987, 0.0013], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:18,240][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.4042, 0.5958], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:18,241][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.9952, 0.0048], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:18,241][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.2934, 0.7066], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:18,242][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.7700, 0.2300], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:18,243][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0069, 0.9931], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:18,244][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.9505, 0.0495], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:18,245][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.1460, 0.8540], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:18,246][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Melissa] are: tensor([0.9437, 0.0336, 0.0227], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:18,248][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Melissa] are: tensor([0.4836, 0.2603, 0.2561], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:18,250][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Melissa] are: tensor([0.5209, 0.1598, 0.3193], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:18,251][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Melissa] are: tensor([0.9267, 0.0413, 0.0321], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:18,253][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Melissa] are: tensor([0.9923, 0.0040, 0.0037], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:18,254][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Melissa] are: tensor([0.1648, 0.4487, 0.3865], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:18,256][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Melissa] are: tensor([0.9959, 0.0013, 0.0028], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:18,258][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Melissa] are: tensor([0.4540, 0.3442, 0.2018], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:18,259][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Melissa] are: tensor([0.8152, 0.1341, 0.0507], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:18,260][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Melissa] are: tensor([0.0058, 0.8995, 0.0947], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:18,261][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Melissa] are: tensor([0.9104, 0.0529, 0.0367], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:18,262][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Melissa] are: tensor([0.1227, 0.6778, 0.1995], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:18,262][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.9233, 0.0315, 0.0187, 0.0265], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:18,263][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.1114, 0.1601, 0.1543, 0.5742], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:18,265][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.4790, 0.1114, 0.2465, 0.1631], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:18,266][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.8700, 0.0336, 0.0385, 0.0580], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:18,268][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.9858, 0.0039, 0.0041, 0.0061], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:18,269][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.1185, 0.2160, 0.1956, 0.4698], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:18,271][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.9930, 0.0018, 0.0019, 0.0033], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:18,273][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2057, 0.2584, 0.1794, 0.3565], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:18,274][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.7584, 0.0767, 0.0553, 0.1096], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:18,276][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0020, 0.5090, 0.1258, 0.3632], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:18,278][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.8611, 0.0641, 0.0354, 0.0395], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:18,279][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.1066, 0.4338, 0.1017, 0.3580], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:18,281][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Benjamin] are: tensor([0.8606, 0.0327, 0.0214, 0.0369, 0.0483], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:18,283][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Benjamin] are: tensor([0.0329, 0.1075, 0.1428, 0.4965, 0.2202], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:18,285][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Benjamin] are: tensor([0.2809, 0.1316, 0.2659, 0.1698, 0.1518], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:18,286][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Benjamin] are: tensor([0.7201, 0.0568, 0.0455, 0.0986, 0.0790], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:18,287][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Benjamin] are: tensor([0.9298, 0.0079, 0.0105, 0.0156, 0.0363], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:18,288][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Benjamin] are: tensor([0.0506, 0.1519, 0.1573, 0.4237, 0.2165], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:18,288][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Benjamin] are: tensor([0.9839, 0.0021, 0.0031, 0.0043, 0.0066], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:18,289][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Benjamin] are: tensor([0.0883, 0.1432, 0.1185, 0.3519, 0.2980], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:18,291][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Benjamin] are: tensor([0.4962, 0.1268, 0.0734, 0.2021, 0.1015], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:18,292][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Benjamin] are: tensor([0.0044, 0.3455, 0.1471, 0.4225, 0.0805], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:18,294][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Benjamin] are: tensor([0.7911, 0.0501, 0.0407, 0.0535, 0.0646], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:18,296][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Benjamin] are: tensor([0.0375, 0.3266, 0.1036, 0.3566, 0.1757], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:18,297][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.6824, 0.0872, 0.0488, 0.0758, 0.0922, 0.0137], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:18,299][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.0502, 0.0934, 0.1025, 0.4786, 0.1695, 0.1058], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:18,301][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.2238, 0.1218, 0.2276, 0.1595, 0.1319, 0.1354], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:18,302][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.5866, 0.0558, 0.0799, 0.1220, 0.1201, 0.0357], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:18,304][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.9445, 0.0056, 0.0066, 0.0128, 0.0241, 0.0063], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:18,306][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.0438, 0.1416, 0.1489, 0.3728, 0.1953, 0.0976], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:18,307][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.9896, 0.0011, 0.0019, 0.0024, 0.0028, 0.0023], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:18,309][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.0748, 0.1589, 0.1248, 0.2439, 0.2335, 0.1641], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:18,311][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.4896, 0.1136, 0.0657, 0.1897, 0.1096, 0.0319], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:18,312][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.0014, 0.2694, 0.1500, 0.3400, 0.1476, 0.0917], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:18,313][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.7944, 0.0491, 0.0343, 0.0475, 0.0507, 0.0240], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:18,314][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.0406, 0.3059, 0.0853, 0.3465, 0.1850, 0.0366], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:18,315][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0917, 0.1482, 0.1189, 0.1985, 0.2346, 0.1042, 0.1040],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:18,316][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0022, 0.1371, 0.0968, 0.3938, 0.1695, 0.1875, 0.0132],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:18,317][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0148, 0.1462, 0.2165, 0.1993, 0.1543, 0.2211, 0.0478],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:18,319][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0530, 0.1495, 0.1463, 0.2317, 0.2059, 0.1451, 0.0685],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:18,321][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.5512, 0.0544, 0.0377, 0.0491, 0.0719, 0.0326, 0.2031],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:18,322][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0061, 0.1447, 0.1404, 0.3154, 0.2069, 0.1647, 0.0219],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:18,324][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.5089, 0.0339, 0.0426, 0.0494, 0.0480, 0.0425, 0.2747],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:18,325][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0103, 0.1625, 0.1189, 0.2601, 0.2077, 0.2109, 0.0297],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:18,327][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0305, 0.1409, 0.1037, 0.3050, 0.2164, 0.1435, 0.0600],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:18,328][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([2.3963e-05, 3.5879e-01, 3.8256e-02, 4.0051e-01, 5.2675e-02, 1.4912e-01,
        6.1966e-04], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:18,330][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0750, 0.1666, 0.1582, 0.1628, 0.1612, 0.1598, 0.1164],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:18,332][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0039, 0.1684, 0.1209, 0.3306, 0.2250, 0.1362, 0.0149],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:18,333][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.6517, 0.0445, 0.0279, 0.0389, 0.0584, 0.0108, 0.1629, 0.0049],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:18,335][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([0.0675, 0.0913, 0.0718, 0.3573, 0.1703, 0.0775, 0.1013, 0.0630],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:18,337][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([0.1577, 0.0771, 0.1924, 0.1251, 0.0942, 0.1008, 0.1862, 0.0664],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:18,338][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([0.5115, 0.0536, 0.0563, 0.1002, 0.0919, 0.0313, 0.1467, 0.0084],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:18,339][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.8554, 0.0032, 0.0029, 0.0057, 0.0131, 0.0026, 0.1160, 0.0010],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:18,340][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([0.0566, 0.1226, 0.1156, 0.3130, 0.1592, 0.1040, 0.0667, 0.0622],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:18,341][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([8.7578e-01, 8.7524e-04, 1.4038e-03, 2.0571e-03, 2.3270e-03, 1.4708e-03,
        1.1543e-01, 6.6035e-04], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:18,342][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.0671, 0.1576, 0.0738, 0.2250, 0.1778, 0.1479, 0.0800, 0.0709],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:18,343][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.4262, 0.0687, 0.0449, 0.1238, 0.0828, 0.0355, 0.2011, 0.0170],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:18,345][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([0.0014, 0.2776, 0.0554, 0.3911, 0.0890, 0.0717, 0.0068, 0.1069],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:18,347][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.6918, 0.0144, 0.0113, 0.0154, 0.0196, 0.0073, 0.2315, 0.0088],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:18,348][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([0.0271, 0.2378, 0.0829, 0.3377, 0.1814, 0.0566, 0.0371, 0.0395],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:18,350][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.5059, 0.0553, 0.0430, 0.0680, 0.0811, 0.0208, 0.1926, 0.0139, 0.0194],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:18,352][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([0.0320, 0.1091, 0.0861, 0.3422, 0.1842, 0.0767, 0.0625, 0.0634, 0.0439],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:18,353][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([0.0957, 0.0947, 0.1696, 0.1237, 0.0965, 0.1130, 0.1337, 0.0658, 0.1072],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:18,355][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([0.3906, 0.0718, 0.0671, 0.1323, 0.0988, 0.0484, 0.1460, 0.0168, 0.0282],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:18,357][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.7844, 0.0051, 0.0064, 0.0116, 0.0253, 0.0064, 0.1541, 0.0034, 0.0035],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:18,359][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([0.0250, 0.1153, 0.1090, 0.3284, 0.1479, 0.1035, 0.0438, 0.0745, 0.0526],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:18,360][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.8167, 0.0023, 0.0040, 0.0051, 0.0060, 0.0039, 0.1562, 0.0015, 0.0043],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:18,362][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.0416, 0.1225, 0.0836, 0.2289, 0.1960, 0.1473, 0.0566, 0.0784, 0.0450],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:18,364][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([0.3526, 0.0758, 0.0467, 0.1599, 0.0706, 0.0390, 0.1975, 0.0291, 0.0288],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:18,365][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([0.0016, 0.1745, 0.1068, 0.2460, 0.0919, 0.0993, 0.0081, 0.2082, 0.0636],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:18,366][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.5593, 0.0249, 0.0340, 0.0344, 0.0432, 0.0157, 0.2429, 0.0175, 0.0281],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:18,367][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([0.0205, 0.1853, 0.0820, 0.3423, 0.1688, 0.0650, 0.0315, 0.0585, 0.0461],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:18,368][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.5764, 0.0566, 0.0406, 0.0521, 0.0653, 0.0136, 0.1504, 0.0076, 0.0147,
        0.0226], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:18,369][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0406, 0.0916, 0.0873, 0.3149, 0.1199, 0.0915, 0.0579, 0.0688, 0.0331,
        0.0945], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:18,370][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.1099, 0.0692, 0.1425, 0.1105, 0.0771, 0.0850, 0.1280, 0.0579, 0.0874,
        0.1326], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:18,372][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.4013, 0.0491, 0.0838, 0.1140, 0.0939, 0.0446, 0.1348, 0.0130, 0.0246,
        0.0410], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:18,374][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.7705, 0.0071, 0.0075, 0.0136, 0.0294, 0.0076, 0.1455, 0.0039, 0.0044,
        0.0106], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:18,376][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0355, 0.1093, 0.1077, 0.2880, 0.1295, 0.0892, 0.0461, 0.0582, 0.0435,
        0.0930], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:18,377][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.8091, 0.0028, 0.0046, 0.0059, 0.0063, 0.0047, 0.1531, 0.0018, 0.0044,
        0.0072], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:18,379][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0390, 0.1268, 0.0933, 0.1940, 0.1657, 0.1248, 0.0450, 0.0656, 0.0411,
        0.1049], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:18,381][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.3702, 0.0724, 0.0575, 0.1171, 0.0899, 0.0342, 0.1620, 0.0210, 0.0258,
        0.0498], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:18,383][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0004, 0.2528, 0.0614, 0.2317, 0.0866, 0.0949, 0.0027, 0.1388, 0.0464,
        0.0843], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:18,384][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.4781, 0.0280, 0.0340, 0.0458, 0.0436, 0.0238, 0.2614, 0.0241, 0.0328,
        0.0284], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:18,386][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0384, 0.1948, 0.0740, 0.2804, 0.1468, 0.0490, 0.0353, 0.0337, 0.0349,
        0.1126], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:18,388][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.5881, 0.0546, 0.0412, 0.0442, 0.0640, 0.0116, 0.1352, 0.0062, 0.0114,
        0.0195, 0.0241], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:18,390][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0282, 0.0916, 0.0696, 0.2607, 0.1151, 0.0745, 0.0421, 0.0544, 0.0283,
        0.0969, 0.1387], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:18,391][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.1219, 0.0647, 0.1200, 0.0927, 0.0678, 0.0735, 0.1270, 0.0518, 0.0738,
        0.1153, 0.0913], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:18,392][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.4150, 0.0504, 0.0669, 0.1082, 0.0902, 0.0351, 0.1236, 0.0091, 0.0186,
        0.0383, 0.0447], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:18,393][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.7973, 0.0049, 0.0049, 0.0103, 0.0209, 0.0053, 0.1357, 0.0025, 0.0026,
        0.0078, 0.0078], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:18,394][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0339, 0.0956, 0.0920, 0.2375, 0.1135, 0.0715, 0.0409, 0.0453, 0.0364,
        0.0820, 0.1515], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:18,395][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.8164, 0.0026, 0.0037, 0.0052, 0.0055, 0.0042, 0.1451, 0.0014, 0.0035,
        0.0057, 0.0068], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:18,396][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0437, 0.1119, 0.0836, 0.1618, 0.1418, 0.1082, 0.0474, 0.0559, 0.0371,
        0.0946, 0.1141], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:18,398][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.3762, 0.0607, 0.0552, 0.0936, 0.0812, 0.0251, 0.1509, 0.0154, 0.0211,
        0.0461, 0.0744], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:18,400][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0004, 0.2693, 0.0463, 0.1870, 0.0602, 0.0797, 0.0027, 0.1281, 0.0413,
        0.0833, 0.1017], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:18,402][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.5005, 0.0303, 0.0254, 0.0339, 0.0307, 0.0210, 0.2540, 0.0179, 0.0279,
        0.0265, 0.0320], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:18,403][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0347, 0.1764, 0.0568, 0.2011, 0.1204, 0.0435, 0.0330, 0.0313, 0.0325,
        0.1197, 0.1505], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:18,405][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.3174, 0.0864, 0.0649, 0.0956, 0.1020, 0.0315, 0.1371, 0.0123, 0.0304,
        0.0397, 0.0573, 0.0252], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:18,407][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([0.0190, 0.0887, 0.0657, 0.2643, 0.1510, 0.0604, 0.0354, 0.0409, 0.0361,
        0.0835, 0.1258, 0.0292], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:18,408][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([0.0520, 0.0424, 0.1010, 0.0963, 0.0585, 0.0886, 0.0788, 0.0619, 0.0737,
        0.1329, 0.1191, 0.0949], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:18,410][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([0.2408, 0.0611, 0.0799, 0.1387, 0.1142, 0.0517, 0.1109, 0.0175, 0.0282,
        0.0543, 0.0633, 0.0394], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:18,412][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.6613, 0.0111, 0.0141, 0.0250, 0.0400, 0.0144, 0.1692, 0.0065, 0.0083,
        0.0204, 0.0201, 0.0096], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:18,413][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([0.0151, 0.0969, 0.0837, 0.2278, 0.1098, 0.0752, 0.0268, 0.0622, 0.0356,
        0.0844, 0.1423, 0.0402], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:18,415][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.7941, 0.0029, 0.0033, 0.0057, 0.0050, 0.0043, 0.1607, 0.0019, 0.0049,
        0.0073, 0.0081, 0.0017], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:18,417][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.0175, 0.0985, 0.0655, 0.1727, 0.1272, 0.0967, 0.0269, 0.0627, 0.0467,
        0.0964, 0.1225, 0.0667], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:18,418][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.1580, 0.0629, 0.0554, 0.1760, 0.0825, 0.0463, 0.1081, 0.0271, 0.0287,
        0.0735, 0.1361, 0.0455], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:18,419][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([0.0004, 0.2066, 0.0618, 0.2576, 0.0378, 0.0774, 0.0029, 0.0856, 0.0373,
        0.0817, 0.1312, 0.0196], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:18,420][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([0.3059, 0.0565, 0.0429, 0.0604, 0.0531, 0.0377, 0.2269, 0.0259, 0.0426,
        0.0451, 0.0565, 0.0464], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:18,420][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([0.0094, 0.1094, 0.0570, 0.2133, 0.1220, 0.0665, 0.0168, 0.0344, 0.0401,
        0.1230, 0.1559, 0.0522], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:18,422][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Melissa] are: tensor([0.5559, 0.0425, 0.0309, 0.0478, 0.0659, 0.0109, 0.1343, 0.0072, 0.0121,
        0.0172, 0.0297, 0.0197, 0.0259], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:18,424][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Melissa] are: tensor([0.0315, 0.0762, 0.0617, 0.2632, 0.1141, 0.0634, 0.0477, 0.0370, 0.0251,
        0.0739, 0.1206, 0.0388, 0.0469], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:18,426][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Melissa] are: tensor([0.0825, 0.0654, 0.0875, 0.0821, 0.0625, 0.0636, 0.0993, 0.0427, 0.0552,
        0.0994, 0.0809, 0.1042, 0.0747], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:18,427][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Melissa] are: tensor([0.3008, 0.0570, 0.0537, 0.1285, 0.0741, 0.0437, 0.1123, 0.0149, 0.0243,
        0.0467, 0.0580, 0.0419, 0.0440], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:18,429][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Melissa] are: tensor([0.7424, 0.0067, 0.0065, 0.0122, 0.0238, 0.0078, 0.1524, 0.0039, 0.0052,
        0.0121, 0.0113, 0.0074, 0.0083], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:18,431][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Melissa] are: tensor([0.0204, 0.0861, 0.0778, 0.2255, 0.1065, 0.0686, 0.0291, 0.0452, 0.0355,
        0.0703, 0.1271, 0.0496, 0.0582], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:18,432][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Melissa] are: tensor([0.8187, 0.0021, 0.0045, 0.0043, 0.0080, 0.0032, 0.1397, 0.0012, 0.0031,
        0.0044, 0.0047, 0.0012, 0.0049], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:18,434][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Melissa] are: tensor([0.0277, 0.0774, 0.0519, 0.1457, 0.1112, 0.1062, 0.0363, 0.0530, 0.0427,
        0.0951, 0.1187, 0.0757, 0.0584], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:18,436][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Melissa] are: tensor([0.3044, 0.0603, 0.0276, 0.1323, 0.0552, 0.0317, 0.1339, 0.0157, 0.0257,
        0.0483, 0.0956, 0.0370, 0.0322], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:18,437][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Melissa] are: tensor([2.1993e-04, 2.5078e-01, 2.5158e-02, 2.2708e-01, 5.8217e-02, 8.9406e-02,
        2.0998e-03, 1.1670e-01, 3.7365e-02, 6.2200e-02, 7.9484e-02, 3.5187e-02,
        1.6100e-02], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:18,439][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Melissa] are: tensor([0.4489, 0.0312, 0.0248, 0.0330, 0.0339, 0.0228, 0.2540, 0.0181, 0.0321,
        0.0247, 0.0327, 0.0239, 0.0199], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:18,441][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Melissa] are: tensor([0.0179, 0.1443, 0.0457, 0.2082, 0.1059, 0.0453, 0.0211, 0.0283, 0.0350,
        0.0896, 0.1370, 0.0673, 0.0544], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:18,442][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.4494, 0.0579, 0.0524, 0.0672, 0.0744, 0.0100, 0.1182, 0.0064, 0.0120,
        0.0215, 0.0316, 0.0156, 0.0331, 0.0502], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:18,444][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([0.0411, 0.0777, 0.0590, 0.2149, 0.0944, 0.0340, 0.0526, 0.0323, 0.0213,
        0.0815, 0.1085, 0.0366, 0.0459, 0.1000], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:18,445][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([0.0915, 0.0470, 0.0919, 0.0678, 0.0529, 0.0580, 0.0970, 0.0374, 0.0582,
        0.0913, 0.0694, 0.0839, 0.0749, 0.0787], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:18,446][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([0.3179, 0.0416, 0.0570, 0.0964, 0.0781, 0.0323, 0.1139, 0.0102, 0.0201,
        0.0366, 0.0422, 0.0246, 0.0455, 0.0837], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:18,446][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([0.7317, 0.0053, 0.0070, 0.0138, 0.0255, 0.0076, 0.1602, 0.0037, 0.0045,
        0.0088, 0.0093, 0.0061, 0.0069, 0.0096], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:18,448][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([0.0208, 0.0774, 0.0748, 0.2036, 0.0887, 0.0507, 0.0276, 0.0396, 0.0251,
        0.0638, 0.1267, 0.0401, 0.0577, 0.1035], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:18,450][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([0.7940, 0.0028, 0.0043, 0.0052, 0.0057, 0.0038, 0.1511, 0.0015, 0.0040,
        0.0060, 0.0067, 0.0012, 0.0043, 0.0095], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:18,452][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.0254, 0.0860, 0.0509, 0.1394, 0.0874, 0.0852, 0.0299, 0.0424, 0.0270,
        0.0775, 0.0987, 0.0565, 0.0548, 0.1388], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:18,453][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([0.2959, 0.0637, 0.0431, 0.1006, 0.0573, 0.0176, 0.1138, 0.0128, 0.0162,
        0.0453, 0.0720, 0.0277, 0.0421, 0.0919], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:18,455][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([0.0006, 0.1812, 0.0626, 0.2228, 0.0835, 0.0580, 0.0033, 0.0810, 0.0275,
        0.0740, 0.0936, 0.0334, 0.0403, 0.0381], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:18,457][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([0.3550, 0.0366, 0.0444, 0.0545, 0.0505, 0.0263, 0.2057, 0.0193, 0.0301,
        0.0275, 0.0370, 0.0338, 0.0278, 0.0514], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:18,459][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([0.0305, 0.1392, 0.0491, 0.1935, 0.0975, 0.0249, 0.0268, 0.0231, 0.0218,
        0.0884, 0.1147, 0.0581, 0.0536, 0.0786], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:18,460][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.7063, 0.0250, 0.0183, 0.0198, 0.0350, 0.0041, 0.1063, 0.0024, 0.0054,
        0.0073, 0.0096, 0.0085, 0.0116, 0.0283, 0.0121], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:18,462][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0693, 0.0590, 0.0434, 0.1656, 0.0684, 0.0341, 0.0584, 0.0265, 0.0195,
        0.0562, 0.0806, 0.0324, 0.0364, 0.1010, 0.1491], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:18,464][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1222, 0.0415, 0.0859, 0.0615, 0.0456, 0.0486, 0.1094, 0.0330, 0.0482,
        0.0773, 0.0574, 0.0819, 0.0602, 0.0716, 0.0557], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:18,466][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.4901, 0.0270, 0.0405, 0.0619, 0.0583, 0.0183, 0.1092, 0.0045, 0.0113,
        0.0213, 0.0242, 0.0157, 0.0276, 0.0560, 0.0339], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:18,467][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.7648, 0.0050, 0.0058, 0.0114, 0.0241, 0.0056, 0.1381, 0.0026, 0.0031,
        0.0077, 0.0074, 0.0041, 0.0055, 0.0077, 0.0073], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:18,469][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0412, 0.0601, 0.0628, 0.1610, 0.0787, 0.0437, 0.0380, 0.0288, 0.0224,
        0.0511, 0.1002, 0.0281, 0.0470, 0.0988, 0.1378], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:18,471][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([8.3446e-01, 1.5648e-03, 2.4747e-03, 3.1327e-03, 3.8202e-03, 2.4675e-03,
        1.3023e-01, 7.4173e-04, 2.3781e-03, 3.2818e-03, 3.8057e-03, 6.5424e-04,
        2.3288e-03, 5.2332e-03, 3.4302e-03], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:18,472][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0429, 0.0716, 0.0434, 0.1083, 0.0894, 0.0676, 0.0378, 0.0306, 0.0232,
        0.0599, 0.0754, 0.0468, 0.0455, 0.1238, 0.1338], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:18,472][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.4366, 0.0350, 0.0256, 0.0520, 0.0397, 0.0126, 0.1157, 0.0070, 0.0121,
        0.0245, 0.0420, 0.0185, 0.0266, 0.0731, 0.0790], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:18,473][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0006, 0.1821, 0.0378, 0.1740, 0.0508, 0.0642, 0.0036, 0.0929, 0.0310,
        0.0588, 0.0789, 0.0259, 0.0257, 0.0498, 0.1238], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:18,475][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.5035, 0.0197, 0.0222, 0.0285, 0.0312, 0.0126, 0.2206, 0.0121, 0.0197,
        0.0162, 0.0206, 0.0221, 0.0143, 0.0354, 0.0210], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:18,477][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0299, 0.1186, 0.0394, 0.1474, 0.0936, 0.0237, 0.0243, 0.0205, 0.0239,
        0.0682, 0.0941, 0.0356, 0.0395, 0.0920, 0.1493], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:18,480][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:31:18,482][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 7408],
        [ 3149],
        [  823],
        [  942],
        [25666],
        [ 1596],
        [ 3183],
        [ 2700],
        [ 1840],
        [  463],
        [  435],
        [ 1901],
        [ 1000],
        [  819],
        [  137]], device='cuda:0')
[2024-07-24 10:31:18,483][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 6980],
        [10299],
        [ 4432],
        [ 4778],
        [39950],
        [ 9632],
        [ 7020],
        [10534],
        [ 5292],
        [ 4539],
        [ 3218],
        [ 8998],
        [ 6019],
        [ 5289],
        [ 1937]], device='cuda:0')
[2024-07-24 10:31:18,485][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[42018],
        [41884],
        [41670],
        [41460],
        [39460],
        [37389],
        [37002],
        [36193],
        [35810],
        [35199],
        [35345],
        [35834],
        [35779],
        [35479],
        [36133]], device='cuda:0')
[2024-07-24 10:31:18,487][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[498],
        [360],
        [307],
        [301],
        [396],
        [340],
        [397],
        [344],
        [359],
        [302],
        [328],
        [427],
        [445],
        [447],
        [448]], device='cuda:0')
[2024-07-24 10:31:18,489][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 639],
        [1280],
        [2077],
        [2234],
        [2799],
        [2944],
        [3166],
        [3384],
        [3758],
        [3523],
        [3311],
        [3434],
        [3606],
        [3647],
        [3619]], device='cuda:0')
[2024-07-24 10:31:18,490][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[4757],
        [5386],
        [4527],
        [3984],
        [5976],
        [6568],
        [7777],
        [6411],
        [6534],
        [5572],
        [5872],
        [6379],
        [5829],
        [5489],
        [5145]], device='cuda:0')
[2024-07-24 10:31:18,492][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[4498],
        [4219],
        [4067],
        [3805],
        [4237],
        [3818],
        [4108],
        [3254],
        [3166],
        [3230],
        [3374],
        [3482],
        [3665],
        [3726],
        [3726]], device='cuda:0')
[2024-07-24 10:31:18,494][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[ 8768],
        [14702],
        [14004],
        [15772],
        [16893],
        [17836],
        [18139],
        [17901],
        [18582],
        [19255],
        [18936],
        [18827],
        [18564],
        [18482],
        [18606]], device='cuda:0')
[2024-07-24 10:31:18,496][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[12202],
        [ 9325],
        [ 9586],
        [ 8917],
        [ 8314],
        [ 8125],
        [ 7927],
        [ 7596],
        [ 7801],
        [ 7896],
        [ 7714],
        [ 7691],
        [ 7456],
        [ 7426],
        [ 7134]], device='cuda:0')
[2024-07-24 10:31:18,498][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[14962],
        [ 3577],
        [ 3972],
        [ 2064],
        [ 4342],
        [ 2983],
        [ 2502],
        [ 2957],
        [ 3046],
        [ 2963],
        [ 2615],
        [ 2450],
        [ 2413],
        [ 2120],
        [ 2014]], device='cuda:0')
[2024-07-24 10:31:18,499][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[26790],
        [29801],
        [29233],
        [28726],
        [28710],
        [28963],
        [28649],
        [27850],
        [27736],
        [27276],
        [26333],
        [24263],
        [24573],
        [24604],
        [24477]], device='cuda:0')
[2024-07-24 10:31:18,500][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[42705],
        [49646],
        [49902],
        [50112],
        [50211],
        [50234],
        [50164],
        [50202],
        [50221],
        [50206],
        [50190],
        [50185],
        [50192],
        [50224],
        [50204]], device='cuda:0')
[2024-07-24 10:31:18,502][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[29941],
        [25254],
        [22212],
        [16608],
        [17304],
        [15106],
        [13685],
        [12706],
        [11777],
        [11440],
        [10534],
        [ 9434],
        [ 8721],
        [ 8371],
        [ 7985]], device='cuda:0')
[2024-07-24 10:31:18,504][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[15219],
        [ 8232],
        [10093],
        [ 6678],
        [ 8614],
        [ 8328],
        [ 9095],
        [ 8088],
        [ 7788],
        [ 7188],
        [ 6418],
        [ 6200],
        [ 6696],
        [ 7067],
        [ 7241]], device='cuda:0')
[2024-07-24 10:31:18,505][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[28355],
        [15180],
        [12309],
        [22504],
        [19271],
        [23280],
        [17247],
        [22145],
        [22131],
        [19402],
        [20834],
        [21782],
        [17717],
        [22153],
        [15728]], device='cuda:0')
[2024-07-24 10:31:18,507][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[19140],
        [20505],
        [20446],
        [20033],
        [19894],
        [17901],
        [14460],
        [18616],
        [15032],
        [16588],
        [16420],
        [12729],
        [14496],
        [10905],
        [16659]], device='cuda:0')
[2024-07-24 10:31:18,509][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[48877],
        [42105],
        [42459],
        [44197],
        [45420],
        [45479],
        [45503],
        [47354],
        [47233],
        [47104],
        [46956],
        [47301],
        [47037],
        [46780],
        [47483]], device='cuda:0')
[2024-07-24 10:31:18,510][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[14662],
        [ 5434],
        [10751],
        [10725],
        [11108],
        [11497],
        [11558],
        [ 9453],
        [ 8413],
        [ 8175],
        [ 7580],
        [ 7519],
        [ 7709],
        [ 7555],
        [ 7478]], device='cuda:0')
[2024-07-24 10:31:18,512][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[18963],
        [18287],
        [19015],
        [16370],
        [15297],
        [16139],
        [15861],
        [14233],
        [14820],
        [15633],
        [15452],
        [16474],
        [16155],
        [16857],
        [15789]], device='cuda:0')
[2024-07-24 10:31:18,514][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[19414],
        [19332],
        [18918],
        [19005],
        [16211],
        [17131],
        [18924],
        [19868],
        [19545],
        [19215],
        [19685],
        [18626],
        [19209],
        [19225],
        [19351]], device='cuda:0')
[2024-07-24 10:31:18,515][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[12917],
        [18060],
        [13446],
        [14365],
        [14808],
        [14153],
        [13815],
        [12660],
        [11594],
        [11142],
        [11770],
        [10759],
        [10434],
        [12200],
        [12650]], device='cuda:0')
[2024-07-24 10:31:18,517][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[39724],
        [39104],
        [39505],
        [39197],
        [38729],
        [39050],
        [23583],
        [36631],
        [34160],
        [33510],
        [33566],
        [32554],
        [33894],
        [32549],
        [34264]], device='cuda:0')
[2024-07-24 10:31:18,519][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[48022],
        [27658],
        [33239],
        [33238],
        [32232],
        [33701],
        [33956],
        [35832],
        [35101],
        [35190],
        [37043],
        [38212],
        [38506],
        [38508],
        [39097]], device='cuda:0')
[2024-07-24 10:31:18,521][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[32383],
        [14962],
        [18722],
        [14067],
        [ 4589],
        [ 4496],
        [ 3991],
        [ 5758],
        [ 4792],
        [ 5281],
        [ 6159],
        [ 6190],
        [ 6936],
        [ 8376],
        [12187]], device='cuda:0')
[2024-07-24 10:31:18,522][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[28533],
        [  665],
        [  939],
        [ 2452],
        [ 3869],
        [ 4937],
        [ 3303],
        [ 4562],
        [ 8113],
        [ 5591],
        [ 5288],
        [ 6407],
        [ 5672],
        [ 7271],
        [ 6762]], device='cuda:0')
[2024-07-24 10:31:18,524][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[24526],
        [25231],
        [27585],
        [28561],
        [30022],
        [29738],
        [34497],
        [35645],
        [36912],
        [37154],
        [36554],
        [37619],
        [37501],
        [37366],
        [37367]], device='cuda:0')
[2024-07-24 10:31:18,526][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[20698],
        [36212],
        [39790],
        [43694],
        [44194],
        [44779],
        [45867],
        [45633],
        [46089],
        [46036],
        [46075],
        [46773],
        [46654],
        [46299],
        [46934]], device='cuda:0')
[2024-07-24 10:31:18,527][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[ 6996],
        [21183],
        [12788],
        [11331],
        [12596],
        [11934],
        [15788],
        [ 9594],
        [ 9587],
        [ 9802],
        [ 9734],
        [10508],
        [ 9514],
        [ 9278],
        [ 7178]], device='cuda:0')
[2024-07-24 10:31:18,529][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[14317],
        [33224],
        [40306],
        [28047],
        [36204],
        [26661],
        [28715],
        [30743],
        [33528],
        [30390],
        [29215],
        [27821],
        [29744],
        [27122],
        [31723]], device='cuda:0')
[2024-07-24 10:31:18,530][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[15616],
        [15616],
        [15616],
        [15616],
        [15616],
        [15616],
        [15616],
        [15616],
        [15616],
        [15616],
        [15616],
        [15616],
        [15616],
        [15616],
        [15616]], device='cuda:0')
[2024-07-24 10:31:18,608][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:31:18,609][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:18,611][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:18,612][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:18,613][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:18,613][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:18,614][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:18,615][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:18,615][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:18,616][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:18,617][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:18,618][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:18,619][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:18,619][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.3093, 0.6907], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:18,620][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0724, 0.9276], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:18,621][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [,] are: tensor([1.3068e-05, 9.9999e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:18,623][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.7225, 0.2775], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:18,625][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.3443, 0.6557], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:18,626][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.9983, 0.0017], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:18,627][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.2471, 0.7529], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:18,629][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.4280, 0.5720], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:18,630][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.4298, 0.5702], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:18,632][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.4320, 0.5680], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:18,633][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.4913, 0.5087], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:18,635][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.2072, 0.7928], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:18,637][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Melissa] are: tensor([0.1691, 0.6280, 0.2029], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:18,638][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Melissa] are: tensor([0.0241, 0.3118, 0.6641], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:18,639][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Melissa] are: tensor([5.5663e-06, 9.8465e-01, 1.5342e-02], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:18,641][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Melissa] are: tensor([0.6448, 0.1647, 0.1905], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:18,642][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Melissa] are: tensor([0.3886, 0.3919, 0.2195], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:18,643][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Melissa] are: tensor([0.9658, 0.0075, 0.0267], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:18,644][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Melissa] are: tensor([0.1291, 0.4359, 0.4351], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:18,644][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Melissa] are: tensor([0.3310, 0.3833, 0.2857], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:18,645][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Melissa] are: tensor([0.5480, 0.2644, 0.1875], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:18,647][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Melissa] are: tensor([0.2093, 0.6335, 0.1572], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:18,648][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Melissa] are: tensor([0.0079, 0.8265, 0.1656], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:18,650][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Melissa] are: tensor([0.0318, 0.7303, 0.2379], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:18,651][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.1433, 0.3221, 0.1436, 0.3910], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:18,653][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0031, 0.2061, 0.4410, 0.3498], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:18,654][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ and] are: tensor([4.2386e-06, 9.7680e-01, 1.5745e-02, 7.4464e-03], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:18,656][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.3901, 0.1337, 0.1707, 0.3055], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:18,657][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.2222, 0.3043, 0.1429, 0.3307], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:18,659][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.9737, 0.0028, 0.0111, 0.0124], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:18,660][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0942, 0.3021, 0.3006, 0.3031], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:18,662][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.1665, 0.3598, 0.1420, 0.3316], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:18,664][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.4343, 0.1964, 0.1466, 0.2227], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:18,665][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.1140, 0.3283, 0.1643, 0.3934], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:18,667][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0111, 0.5761, 0.3788, 0.0339], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:18,669][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0215, 0.4343, 0.3670, 0.1772], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:18,669][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Benjamin] are: tensor([0.0280, 0.2291, 0.1236, 0.4400, 0.1793], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:18,670][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Benjamin] are: tensor([0.0036, 0.1087, 0.3160, 0.2251, 0.3466], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:18,671][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Benjamin] are: tensor([2.6596e-06, 9.7765e-01, 1.2757e-02, 8.6820e-03, 9.0515e-04],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:18,672][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Benjamin] are: tensor([0.2238, 0.1049, 0.1291, 0.2948, 0.2474], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:18,673][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Benjamin] are: tensor([0.0949, 0.2442, 0.1553, 0.3262, 0.1795], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:18,675][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Benjamin] are: tensor([0.8351, 0.0095, 0.0374, 0.0476, 0.0704], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:18,677][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Benjamin] are: tensor([0.0718, 0.2319, 0.2329, 0.2335, 0.2300], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:18,678][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Benjamin] are: tensor([0.0719, 0.2454, 0.1335, 0.3064, 0.2427], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:18,680][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Benjamin] are: tensor([0.1347, 0.2240, 0.1216, 0.2995, 0.2202], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:18,681][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Benjamin] are: tensor([0.0406, 0.3196, 0.0920, 0.3694, 0.1784], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:18,683][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Benjamin] are: tensor([0.0009, 0.3375, 0.5950, 0.0251, 0.0414], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:18,685][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Benjamin] are: tensor([0.0251, 0.4482, 0.2013, 0.2303, 0.0950], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:18,686][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.1017, 0.2127, 0.0974, 0.3216, 0.1824, 0.0842], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:18,688][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.0015, 0.1122, 0.2256, 0.2151, 0.2457, 0.2000], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:18,689][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ had] are: tensor([7.3580e-06, 9.7170e-01, 1.5193e-02, 6.7217e-03, 1.1938e-03, 5.1870e-03],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:18,691][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.1522, 0.1055, 0.1117, 0.2805, 0.2125, 0.1376], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:18,692][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.1576, 0.2690, 0.1211, 0.2874, 0.0958, 0.0692], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:18,694][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.9146, 0.0045, 0.0184, 0.0178, 0.0362, 0.0085], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:18,695][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.0500, 0.1921, 0.1917, 0.1928, 0.1878, 0.1856], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:18,696][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.1146, 0.1872, 0.1047, 0.2301, 0.2274, 0.1360], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:18,697][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.1694, 0.1613, 0.1256, 0.2597, 0.1838, 0.1002], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:18,697][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.0215, 0.2116, 0.1154, 0.3743, 0.1691, 0.1081], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:18,698][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.0277, 0.5898, 0.0990, 0.0268, 0.0306, 0.2261], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:18,700][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.1880, 0.3911, 0.0965, 0.1707, 0.0732, 0.0805], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:18,701][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0045, 0.1576, 0.1051, 0.3194, 0.1809, 0.2151, 0.0173],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:18,703][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0004, 0.1634, 0.1750, 0.2048, 0.2139, 0.2416, 0.0009],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:18,704][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ a] are: tensor([1.0153e-06, 9.5795e-01, 1.7073e-02, 1.5821e-02, 9.8394e-04, 8.1708e-03,
        1.0273e-06], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:18,706][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0134, 0.1550, 0.1242, 0.2915, 0.1690, 0.2153, 0.0316],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:18,707][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0045, 0.1931, 0.1239, 0.3397, 0.1302, 0.1936, 0.0150],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:18,709][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.2372, 0.0865, 0.1077, 0.1241, 0.1651, 0.1090, 0.1705],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:18,711][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0350, 0.1645, 0.1648, 0.1659, 0.1618, 0.1605, 0.1476],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:18,712][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0011, 0.2781, 0.1409, 0.2322, 0.1207, 0.2227, 0.0043],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:18,714][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0101, 0.1717, 0.1207, 0.2883, 0.1685, 0.2168, 0.0239],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:18,716][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0028, 0.2087, 0.1173, 0.2839, 0.1657, 0.2116, 0.0100],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:18,717][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ a] are: tensor([5.1887e-05, 2.9747e-01, 1.8339e-01, 3.6168e-02, 5.5336e-02, 4.2751e-01,
        7.0958e-05], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:18,719][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0006, 0.3276, 0.1971, 0.2158, 0.1385, 0.1158, 0.0047],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:18,721][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.0647, 0.2214, 0.0595, 0.2699, 0.1078, 0.1093, 0.1059, 0.0616],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:18,721][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ long] are: tensor([0.0039, 0.0963, 0.1653, 0.1732, 0.2093, 0.1516, 0.0152, 0.1852],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:18,722][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ long] are: tensor([1.0553e-06, 9.6927e-01, 1.0149e-02, 7.6104e-03, 1.1206e-03, 3.5781e-03,
        1.8189e-06, 8.2693e-03], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:18,723][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ long] are: tensor([0.1478, 0.0933, 0.0718, 0.2208, 0.1446, 0.1310, 0.1431, 0.0477],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:18,724][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.0898, 0.2318, 0.0957, 0.2487, 0.0959, 0.0786, 0.1096, 0.0499],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:18,725][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ long] are: tensor([0.7663, 0.0031, 0.0076, 0.0098, 0.0215, 0.0065, 0.1828, 0.0024],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:18,727][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.0328, 0.1411, 0.1420, 0.1436, 0.1404, 0.1411, 0.1333, 0.1258],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:18,729][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.1286, 0.1161, 0.0709, 0.1554, 0.1779, 0.0990, 0.1541, 0.0979],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:18,730][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.1690, 0.1586, 0.0871, 0.1891, 0.1303, 0.0794, 0.1319, 0.0546],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:18,732][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ long] are: tensor([0.0178, 0.2069, 0.0870, 0.3308, 0.1145, 0.1346, 0.0348, 0.0737],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:18,734][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.0040, 0.4088, 0.0889, 0.0268, 0.1224, 0.1710, 0.0035, 0.1746],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:18,735][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ long] are: tensor([0.0093, 0.3356, 0.1450, 0.2267, 0.0734, 0.0828, 0.0948, 0.0324],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:18,737][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.0297, 0.1850, 0.0713, 0.2644, 0.1074, 0.1086, 0.0639, 0.0936, 0.0760],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:18,739][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([0.0126, 0.0893, 0.1424, 0.1500, 0.1782, 0.1271, 0.0465, 0.1487, 0.1052],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:18,740][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([1.8489e-06, 9.6089e-01, 1.0601e-02, 9.3943e-03, 1.0625e-03, 5.0570e-03,
        2.4245e-06, 1.0737e-02, 2.2503e-03], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:18,742][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([0.0905, 0.0966, 0.0720, 0.2186, 0.1342, 0.1315, 0.1060, 0.0727, 0.0779],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:18,743][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.0493, 0.1773, 0.1031, 0.2661, 0.1018, 0.0953, 0.0734, 0.0621, 0.0716],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:18,745][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([0.6579, 0.0059, 0.0179, 0.0251, 0.0416, 0.0144, 0.2137, 0.0069, 0.0166],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:18,747][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.0272, 0.1248, 0.1279, 0.1281, 0.1265, 0.1256, 0.1185, 0.1124, 0.1090],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:18,748][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.0480, 0.1148, 0.0573, 0.1726, 0.1271, 0.1133, 0.0756, 0.1205, 0.1709],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:18,749][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.0935, 0.1296, 0.0868, 0.1767, 0.1540, 0.1031, 0.0914, 0.0828, 0.0820],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:18,749][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.0120, 0.1862, 0.0759, 0.3068, 0.1143, 0.1354, 0.0264, 0.0844, 0.0586],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:18,750][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([3.7733e-04, 1.1832e-01, 9.4107e-02, 1.1703e-02, 2.7555e-02, 3.8917e-01,
        1.4046e-03, 2.4865e-01, 1.0871e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:18,752][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([0.0322, 0.3209, 0.1538, 0.1124, 0.0672, 0.1246, 0.0932, 0.0702, 0.0255],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:18,753][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0738, 0.1380, 0.0536, 0.1684, 0.1025, 0.0693, 0.0852, 0.0502, 0.0656,
        0.1934], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:18,755][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0036, 0.0776, 0.1208, 0.1296, 0.1314, 0.1189, 0.0135, 0.1530, 0.1428,
        0.1089], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:18,756][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [,] are: tensor([7.7494e-07, 9.6500e-01, 8.7606e-03, 5.0559e-03, 7.2500e-04, 3.1422e-03,
        8.3993e-07, 7.8884e-03, 1.8315e-03, 7.5968e-03], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:18,758][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.1016, 0.0760, 0.0794, 0.1828, 0.1223, 0.0945, 0.0935, 0.0436, 0.0510,
        0.1553], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:18,759][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0837, 0.1648, 0.1098, 0.2129, 0.0939, 0.0653, 0.0866, 0.0377, 0.0400,
        0.1052], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:18,761][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.6326, 0.0080, 0.0255, 0.0275, 0.0463, 0.0155, 0.1910, 0.0081, 0.0188,
        0.0267], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:18,763][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0264, 0.1169, 0.1151, 0.1159, 0.1134, 0.1116, 0.1018, 0.1005, 0.0953,
        0.1032], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:18,765][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0317, 0.1189, 0.0658, 0.1416, 0.1151, 0.1128, 0.0505, 0.0822, 0.1158,
        0.1655], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:18,766][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.1232, 0.1144, 0.0849, 0.1478, 0.1237, 0.0764, 0.0898, 0.0703, 0.0680,
        0.1015], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:18,768][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0215, 0.1501, 0.0823, 0.2368, 0.1070, 0.1101, 0.0354, 0.0639, 0.0536,
        0.1393], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:18,770][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0019, 0.0202, 0.0298, 0.0036, 0.0087, 0.0659, 0.0036, 0.1537, 0.6965,
        0.0161], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:18,772][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0254, 0.1165, 0.1423, 0.0762, 0.0817, 0.0656, 0.1661, 0.1259, 0.1459,
        0.0544], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:18,773][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0736, 0.1169, 0.0476, 0.1302, 0.0958, 0.0511, 0.0784, 0.0367, 0.0458,
        0.1659, 0.1580], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:18,774][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0028, 0.0694, 0.1091, 0.1160, 0.1022, 0.1091, 0.0104, 0.1383, 0.1306,
        0.1060, 0.1061], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:18,775][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ and] are: tensor([1.3916e-06, 9.5392e-01, 1.0393e-02, 4.7836e-03, 8.1303e-04, 3.5603e-03,
        1.6123e-06, 8.3420e-03, 2.3822e-03, 9.0531e-03, 6.7522e-03],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:18,776][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0961, 0.0735, 0.0679, 0.1555, 0.1123, 0.0757, 0.0835, 0.0319, 0.0388,
        0.1281, 0.1367], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:18,777][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0901, 0.1159, 0.0907, 0.1749, 0.0827, 0.0547, 0.0865, 0.0306, 0.0363,
        0.1030, 0.1347], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:18,778][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.7025, 0.0046, 0.0151, 0.0159, 0.0316, 0.0089, 0.1754, 0.0044, 0.0112,
        0.0154, 0.0151], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:18,780][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0275, 0.1046, 0.1035, 0.1039, 0.1016, 0.0999, 0.0923, 0.0909, 0.0865,
        0.0933, 0.0960], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:18,782][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0375, 0.1020, 0.0524, 0.1168, 0.0886, 0.0922, 0.0545, 0.0670, 0.0983,
        0.1475, 0.1432], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:18,783][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.1399, 0.1018, 0.0721, 0.1204, 0.1076, 0.0640, 0.0944, 0.0478, 0.0581,
        0.0951, 0.0989], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:18,785][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0221, 0.1301, 0.0839, 0.2008, 0.0956, 0.0895, 0.0345, 0.0536, 0.0421,
        0.1194, 0.1283], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:18,786][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ and] are: tensor([4.4644e-04, 4.4672e-02, 3.7273e-02, 2.7716e-03, 8.7407e-03, 7.2039e-02,
        1.1034e-03, 1.4074e-01, 6.7240e-01, 1.8577e-02, 1.2444e-03],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:18,788][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0107, 0.1688, 0.1485, 0.0599, 0.0795, 0.0938, 0.0846, 0.0900, 0.1413,
        0.0817, 0.0413], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:18,790][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.0094, 0.0666, 0.0441, 0.1701, 0.0838, 0.0802, 0.0206, 0.0440, 0.0590,
        0.1730, 0.2020, 0.0471], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:18,792][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([0.0018, 0.0734, 0.1267, 0.1238, 0.1149, 0.0961, 0.0070, 0.1213, 0.1037,
        0.0789, 0.0818, 0.0705], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:18,793][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([6.5710e-07, 9.3618e-01, 1.2494e-02, 7.8720e-03, 9.5486e-04, 5.9993e-03,
        1.3040e-06, 9.7478e-03, 1.9593e-03, 1.2533e-02, 1.0057e-02, 2.1987e-03],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:18,795][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([0.0295, 0.0553, 0.0552, 0.1547, 0.0869, 0.0971, 0.0409, 0.0484, 0.0557,
        0.1507, 0.1710, 0.0546], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:18,796][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.0127, 0.1043, 0.0875, 0.2192, 0.0823, 0.0757, 0.0234, 0.0466, 0.0452,
        0.1118, 0.1541, 0.0374], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:18,798][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([0.4893, 0.0165, 0.0242, 0.0401, 0.0654, 0.0208, 0.1799, 0.0101, 0.0245,
        0.0413, 0.0429, 0.0449], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:18,800][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.0210, 0.0941, 0.0948, 0.0953, 0.0934, 0.0924, 0.0863, 0.0835, 0.0806,
        0.0854, 0.0883, 0.0849], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:18,800][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.0231, 0.0671, 0.0546, 0.1165, 0.0997, 0.0782, 0.0372, 0.0711, 0.1001,
        0.1383, 0.1365, 0.0777], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:18,801][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.0153, 0.1072, 0.0767, 0.1874, 0.0886, 0.0761, 0.0209, 0.0576, 0.0635,
        0.1163, 0.1368, 0.0536], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:18,802][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([0.0053, 0.0994, 0.0664, 0.2172, 0.0888, 0.1129, 0.0127, 0.0727, 0.0449,
        0.1067, 0.1289, 0.0441], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:18,803][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([2.3867e-04, 2.6552e-02, 9.9504e-03, 3.2508e-03, 4.9611e-03, 1.0834e-01,
        4.2845e-04, 6.3715e-02, 7.5267e-01, 2.2731e-02, 4.0805e-03, 3.0763e-03],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:18,805][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([0.0068, 0.1884, 0.0411, 0.1531, 0.0371, 0.0704, 0.0492, 0.0524, 0.0439,
        0.1897, 0.1318, 0.0361], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:18,806][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Melissa] are: tensor([0.0295, 0.0798, 0.0287, 0.1241, 0.0685, 0.0525, 0.0445, 0.0517, 0.0600,
        0.1530, 0.1772, 0.0752, 0.0554], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:18,808][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Melissa] are: tensor([0.0055, 0.0580, 0.0880, 0.0979, 0.0807, 0.0966, 0.0141, 0.1149, 0.0989,
        0.0897, 0.0887, 0.0699, 0.0970], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:18,809][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Melissa] are: tensor([6.4657e-07, 9.6423e-01, 7.8601e-03, 4.5732e-03, 5.8299e-04, 2.2117e-03,
        7.9818e-07, 5.7004e-03, 1.3256e-03, 5.7903e-03, 4.8237e-03, 1.3722e-03,
        1.5266e-03], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:18,811][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Melissa] are: tensor([0.0651, 0.0484, 0.0479, 0.1383, 0.0897, 0.0726, 0.0665, 0.0374, 0.0436,
        0.1227, 0.1486, 0.0506, 0.0686], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:18,812][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Melissa] are: tensor([0.0514, 0.1041, 0.0765, 0.1560, 0.0833, 0.0488, 0.0602, 0.0322, 0.0370,
        0.1044, 0.1298, 0.0427, 0.0736], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:18,814][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Melissa] are: tensor([0.4355, 0.0109, 0.0304, 0.0540, 0.0619, 0.0260, 0.1763, 0.0123, 0.0304,
        0.0388, 0.0448, 0.0461, 0.0325], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:18,816][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Melissa] are: tensor([0.0211, 0.0871, 0.0866, 0.0874, 0.0854, 0.0855, 0.0793, 0.0759, 0.0726,
        0.0789, 0.0811, 0.0777, 0.0814], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:18,818][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Melissa] are: tensor([0.0331, 0.0761, 0.0533, 0.1109, 0.0849, 0.0676, 0.0445, 0.0691, 0.0973,
        0.1270, 0.1187, 0.0577, 0.0597], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:18,819][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Melissa] are: tensor([0.0807, 0.0705, 0.0587, 0.1388, 0.0923, 0.0602, 0.0646, 0.0542, 0.0552,
        0.0751, 0.0932, 0.0932, 0.0631], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:18,821][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Melissa] are: tensor([0.0140, 0.1215, 0.0417, 0.1871, 0.0837, 0.0859, 0.0243, 0.0529, 0.0504,
        0.1142, 0.1252, 0.0588, 0.0402], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:18,822][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Melissa] are: tensor([2.6601e-05, 2.8007e-02, 5.2345e-03, 3.9101e-03, 6.2060e-03, 7.5439e-02,
        3.3274e-05, 3.7789e-02, 8.0602e-01, 2.8396e-02, 3.1249e-03, 2.9441e-03,
        2.8643e-03], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:18,824][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Melissa] are: tensor([0.0063, 0.1902, 0.0559, 0.1317, 0.0356, 0.1230, 0.0250, 0.0715, 0.0771,
        0.1211, 0.0757, 0.0488, 0.0382], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:18,826][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.0389, 0.0737, 0.0452, 0.1073, 0.0561, 0.0294, 0.0472, 0.0287, 0.0305,
        0.1271, 0.1309, 0.0412, 0.0637, 0.1801], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:18,828][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ said] are: tensor([0.0011, 0.0498, 0.0891, 0.0819, 0.0903, 0.0772, 0.0048, 0.1043, 0.0974,
        0.0672, 0.0653, 0.0638, 0.1068, 0.1011], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:18,829][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ said] are: tensor([1.0370e-06, 9.5500e-01, 1.1295e-02, 5.5438e-03, 8.1612e-04, 2.9688e-03,
        1.1001e-06, 6.9344e-03, 1.0305e-03, 6.5857e-03, 5.4997e-03, 2.0472e-03,
        1.7931e-03, 4.8583e-04], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:18,831][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ said] are: tensor([0.0609, 0.0515, 0.0427, 0.1168, 0.0706, 0.0549, 0.0551, 0.0280, 0.0299,
        0.1007, 0.1118, 0.0361, 0.0514, 0.1897], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:18,831][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.0555, 0.1263, 0.0616, 0.1428, 0.0536, 0.0414, 0.0550, 0.0241, 0.0262,
        0.0871, 0.1061, 0.0249, 0.0479, 0.1475], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:18,832][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ said] are: tensor([0.5754, 0.0057, 0.0220, 0.0215, 0.0410, 0.0093, 0.1724, 0.0062, 0.0130,
        0.0208, 0.0235, 0.0278, 0.0304, 0.0310], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:18,833][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.0149, 0.0822, 0.0813, 0.0827, 0.0801, 0.0792, 0.0730, 0.0706, 0.0672,
        0.0732, 0.0761, 0.0721, 0.0764, 0.0711], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:18,835][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.0167, 0.0748, 0.0451, 0.1007, 0.0769, 0.0782, 0.0294, 0.0576, 0.0746,
        0.1232, 0.1203, 0.0556, 0.0482, 0.0987], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:18,837][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.0795, 0.0753, 0.0524, 0.1061, 0.0616, 0.0436, 0.0591, 0.0352, 0.0370,
        0.0757, 0.0741, 0.0592, 0.0554, 0.1858], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:18,838][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ said] are: tensor([0.0097, 0.1231, 0.0579, 0.1919, 0.0682, 0.0594, 0.0168, 0.0420, 0.0257,
        0.0952, 0.1088, 0.0417, 0.0381, 0.1213], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:18,840][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.0007, 0.0524, 0.0556, 0.0063, 0.0082, 0.0931, 0.0013, 0.2221, 0.4025,
        0.0398, 0.0065, 0.0110, 0.0742, 0.0264], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:18,842][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ said] are: tensor([0.0093, 0.2214, 0.1782, 0.0823, 0.0458, 0.0804, 0.0312, 0.0580, 0.0139,
        0.0613, 0.0363, 0.0544, 0.1188, 0.0088], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:18,844][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0528, 0.0569, 0.0230, 0.0635, 0.0409, 0.0239, 0.0482, 0.0189, 0.0235,
        0.0858, 0.0827, 0.0354, 0.0351, 0.1799, 0.2295], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:18,845][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0016, 0.0443, 0.0705, 0.0797, 0.0798, 0.0725, 0.0065, 0.1013, 0.0898,
        0.0663, 0.0682, 0.0626, 0.0956, 0.0998, 0.0615], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:18,847][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ to] are: tensor([9.2904e-07, 9.3664e-01, 1.1932e-02, 6.4115e-03, 8.2227e-04, 3.1929e-03,
        1.3327e-06, 9.0985e-03, 1.9585e-03, 8.4577e-03, 5.9150e-03, 2.5709e-03,
        2.0172e-03, 6.3446e-04, 1.0350e-02], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:18,849][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0919, 0.0355, 0.0361, 0.0868, 0.0563, 0.0391, 0.0680, 0.0177, 0.0261,
        0.0817, 0.0905, 0.0261, 0.0423, 0.1684, 0.1336], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:18,850][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.1193, 0.0806, 0.0482, 0.0942, 0.0553, 0.0291, 0.0847, 0.0149, 0.0215,
        0.0613, 0.0723, 0.0225, 0.0405, 0.1373, 0.1182], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:18,852][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.6300, 0.0048, 0.0134, 0.0166, 0.0314, 0.0072, 0.1600, 0.0037, 0.0116,
        0.0154, 0.0175, 0.0228, 0.0190, 0.0275, 0.0193], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:18,854][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0167, 0.0759, 0.0750, 0.0759, 0.0742, 0.0738, 0.0680, 0.0664, 0.0636,
        0.0679, 0.0706, 0.0672, 0.0710, 0.0664, 0.0674], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:18,856][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0323, 0.0464, 0.0298, 0.0788, 0.0630, 0.0598, 0.0462, 0.0500, 0.0800,
        0.1111, 0.1053, 0.0515, 0.0411, 0.1050, 0.0997], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:18,856][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.1000, 0.0771, 0.0440, 0.0744, 0.0631, 0.0352, 0.0578, 0.0256, 0.0370,
        0.0564, 0.0578, 0.0463, 0.0480, 0.1878, 0.0896], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:18,857][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0234, 0.0987, 0.0445, 0.1393, 0.0566, 0.0575, 0.0298, 0.0304, 0.0273,
        0.0790, 0.0836, 0.0344, 0.0314, 0.1345, 0.1295], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:18,858][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ to] are: tensor([5.5574e-04, 4.2485e-02, 1.5481e-02, 4.6610e-03, 1.0303e-02, 5.0016e-02,
        9.6146e-04, 7.6204e-02, 6.8372e-01, 4.2719e-02, 5.7305e-03, 1.7145e-03,
        1.4616e-02, 4.8417e-02, 2.4193e-03], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:18,859][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0117, 0.1945, 0.0643, 0.0830, 0.0656, 0.0406, 0.0800, 0.0264, 0.0850,
        0.0768, 0.0566, 0.0758, 0.0643, 0.0394, 0.0360], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:18,947][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:31:18,948][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:18,950][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:18,951][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:18,953][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:18,954][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:18,955][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:18,956][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:18,958][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:18,959][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:18,960][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:18,961][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:18,961][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:18,962][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.3093, 0.6907], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:18,963][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.9378, 0.0622], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:18,964][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([6.6546e-05, 9.9993e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:18,965][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.7411, 0.2589], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:18,967][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.3443, 0.6557], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:18,968][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.9983, 0.0017], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:18,970][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.9921, 0.0079], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:18,971][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.4280, 0.5720], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:18,973][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.4298, 0.5702], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:18,975][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.4508, 0.5492], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:18,976][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0114, 0.9886], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:18,978][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.7563, 0.2437], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:18,980][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Melissa] are: tensor([0.1691, 0.6280, 0.2029], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:18,981][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Melissa] are: tensor([0.5948, 0.0929, 0.3123], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:18,982][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Melissa] are: tensor([6.7889e-05, 7.8300e-01, 2.1694e-01], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:18,984][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Melissa] are: tensor([0.6613, 0.1567, 0.1820], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:18,986][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Melissa] are: tensor([0.3886, 0.3919, 0.2195], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:18,986][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Melissa] are: tensor([0.9658, 0.0075, 0.0267], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:18,987][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Melissa] are: tensor([0.9677, 0.0130, 0.0194], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:18,988][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Melissa] are: tensor([0.3310, 0.3833, 0.2857], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:18,989][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Melissa] are: tensor([0.5480, 0.2644, 0.1875], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:18,990][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Melissa] are: tensor([0.2168, 0.6198, 0.1634], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:18,992][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Melissa] are: tensor([0.0043, 0.6297, 0.3659], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:18,993][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Melissa] are: tensor([0.4489, 0.3421, 0.2090], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:18,995][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.1433, 0.3221, 0.1436, 0.3910], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:18,997][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.4796, 0.0854, 0.2098, 0.2252], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:18,998][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([1.1094e-05, 3.4889e-01, 9.0617e-02, 5.6049e-01], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:18,999][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.4029, 0.1319, 0.1670, 0.2981], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:19,001][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.2222, 0.3043, 0.1429, 0.3307], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:19,003][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.9737, 0.0028, 0.0111, 0.0124], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:19,004][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.9459, 0.0141, 0.0166, 0.0235], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:19,006][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.1665, 0.3598, 0.1420, 0.3316], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:19,007][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.4343, 0.1964, 0.1466, 0.2227], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:19,009][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.1201, 0.3163, 0.1723, 0.3913], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:19,011][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0013, 0.2032, 0.2156, 0.5800], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:19,012][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.4134, 0.1869, 0.1578, 0.2419], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:19,012][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Benjamin] are: tensor([0.0280, 0.2291, 0.1236, 0.4400, 0.1793], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:19,013][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Benjamin] are: tensor([0.1509, 0.0662, 0.2971, 0.2212, 0.2645], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:19,014][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Benjamin] are: tensor([1.3148e-05, 2.6461e-01, 1.0703e-01, 5.3732e-01, 9.1033e-02],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:19,015][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Benjamin] are: tensor([0.2345, 0.1044, 0.1283, 0.2893, 0.2435], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:19,016][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Benjamin] are: tensor([0.0949, 0.2442, 0.1553, 0.3262, 0.1795], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:19,018][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Benjamin] are: tensor([0.8351, 0.0095, 0.0374, 0.0476, 0.0704], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:19,019][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Benjamin] are: tensor([0.7945, 0.0286, 0.0361, 0.0560, 0.0849], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:19,021][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Benjamin] are: tensor([0.0719, 0.2454, 0.1335, 0.3064, 0.2427], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:19,022][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Benjamin] are: tensor([0.1347, 0.2240, 0.1216, 0.2995, 0.2202], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:19,024][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Benjamin] are: tensor([0.0418, 0.3108, 0.0956, 0.3681, 0.1837], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:19,026][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Benjamin] are: tensor([0.0009, 0.1472, 0.2029, 0.4832, 0.1658], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:19,027][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Benjamin] are: tensor([0.1743, 0.2212, 0.1239, 0.2705, 0.2100], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:19,029][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.1017, 0.2127, 0.0974, 0.3216, 0.1824, 0.0842], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:19,031][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.1683, 0.0561, 0.1825, 0.1872, 0.1960, 0.2099], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:19,032][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([1.7836e-05, 1.9538e-01, 8.5545e-02, 3.8040e-01, 7.8154e-02, 2.6050e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:19,033][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.1594, 0.1056, 0.1113, 0.2764, 0.2097, 0.1375], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:19,035][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.1576, 0.2690, 0.1211, 0.2874, 0.0958, 0.0692], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:19,037][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.9146, 0.0045, 0.0184, 0.0178, 0.0362, 0.0085], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:19,038][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.8424, 0.0158, 0.0241, 0.0324, 0.0591, 0.0263], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:19,038][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.1146, 0.1872, 0.1047, 0.2301, 0.2274, 0.1360], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:19,039][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.1694, 0.1613, 0.1256, 0.2597, 0.1838, 0.1002], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:19,040][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.0228, 0.2030, 0.1193, 0.3713, 0.1770, 0.1065], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:19,042][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.0006, 0.0779, 0.1217, 0.3553, 0.2187, 0.2258], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:19,043][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.1825, 0.1426, 0.1245, 0.2028, 0.2226, 0.1251], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:19,045][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0045, 0.1576, 0.1051, 0.3194, 0.1809, 0.2151, 0.0173],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:19,046][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0066, 0.1915, 0.1569, 0.2151, 0.1328, 0.2824, 0.0147],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:19,048][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([6.9004e-07, 2.4182e-01, 8.0490e-02, 2.8980e-01, 2.3770e-02, 3.6409e-01,
        2.1852e-05], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:19,049][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0135, 0.1572, 0.1263, 0.2865, 0.1675, 0.2172, 0.0318],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:19,051][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0045, 0.1931, 0.1239, 0.3397, 0.1302, 0.1936, 0.0150],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:19,053][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.2372, 0.0865, 0.1077, 0.1241, 0.1651, 0.1090, 0.1705],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:19,054][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.1204, 0.1390, 0.1185, 0.1493, 0.1769, 0.1717, 0.1242],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:19,056][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0011, 0.2781, 0.1409, 0.2322, 0.1207, 0.2227, 0.0043],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:19,058][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0101, 0.1717, 0.1207, 0.2883, 0.1685, 0.2168, 0.0239],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:19,059][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0028, 0.2051, 0.1184, 0.2849, 0.1682, 0.2104, 0.0101],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:19,060][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([2.2869e-05, 2.1827e-01, 9.8466e-02, 3.4539e-01, 8.8466e-02, 2.4914e-01,
        2.4374e-04], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:19,062][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0048, 0.1973, 0.1743, 0.2375, 0.1343, 0.2385, 0.0133],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:19,063][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.0647, 0.2214, 0.0595, 0.2699, 0.1078, 0.1093, 0.1059, 0.0616],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:19,064][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([0.1646, 0.0425, 0.1221, 0.1292, 0.1515, 0.1216, 0.1450, 0.1235],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:19,065][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([1.6162e-05, 1.6166e-01, 4.6007e-02, 3.2789e-01, 5.1452e-02, 1.6284e-01,
        2.6756e-04, 2.4987e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:19,066][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([0.1535, 0.0927, 0.0712, 0.2166, 0.1422, 0.1299, 0.1455, 0.0484],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:19,067][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.0898, 0.2318, 0.0957, 0.2487, 0.0959, 0.0786, 0.1096, 0.0499],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:19,068][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([0.7663, 0.0031, 0.0076, 0.0098, 0.0215, 0.0065, 0.1828, 0.0024],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:19,070][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.6726, 0.0077, 0.0122, 0.0163, 0.0318, 0.0148, 0.2339, 0.0106],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:19,071][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.1286, 0.1161, 0.0709, 0.1554, 0.1779, 0.0990, 0.1541, 0.0979],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:19,073][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.1690, 0.1586, 0.0871, 0.1891, 0.1303, 0.0794, 0.1319, 0.0546],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:19,075][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([0.0188, 0.2017, 0.0895, 0.3311, 0.1183, 0.1338, 0.0358, 0.0710],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:19,076][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.0004, 0.0866, 0.0654, 0.3580, 0.1732, 0.1948, 0.0024, 0.1192],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:19,078][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([0.2578, 0.0491, 0.0590, 0.0809, 0.1193, 0.0695, 0.2518, 0.1127],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:19,080][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.0297, 0.1850, 0.0713, 0.2644, 0.1074, 0.1086, 0.0639, 0.0936, 0.0760],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:19,081][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([0.1317, 0.0419, 0.1057, 0.1050, 0.1131, 0.1220, 0.1303, 0.1418, 0.1086],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:19,082][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([1.3250e-05, 1.4499e-01, 5.0259e-02, 2.3874e-01, 4.2901e-02, 1.8106e-01,
        2.0251e-04, 2.7171e-01, 7.0127e-02], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:19,084][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([0.0952, 0.0953, 0.0714, 0.2131, 0.1325, 0.1306, 0.1086, 0.0738, 0.0796],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:19,086][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.0493, 0.1773, 0.1031, 0.2661, 0.1018, 0.0953, 0.0734, 0.0621, 0.0716],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:19,087][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([0.6579, 0.0059, 0.0179, 0.0251, 0.0416, 0.0144, 0.2137, 0.0069, 0.0166],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:19,089][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.5472, 0.0141, 0.0243, 0.0345, 0.0550, 0.0281, 0.2355, 0.0238, 0.0375],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:19,090][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.0480, 0.1148, 0.0573, 0.1726, 0.1271, 0.1133, 0.0756, 0.1205, 0.1709],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:19,091][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([0.0935, 0.1296, 0.0868, 0.1767, 0.1540, 0.1031, 0.0914, 0.0828, 0.0820],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:19,092][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([0.0126, 0.1818, 0.0779, 0.3086, 0.1177, 0.1346, 0.0269, 0.0821, 0.0580],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:19,093][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.0007, 0.0819, 0.1152, 0.2643, 0.2236, 0.1424, 0.0030, 0.1086, 0.0602],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:19,094][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([0.0755, 0.0909, 0.0855, 0.1313, 0.1425, 0.1009, 0.1001, 0.1570, 0.1163],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:19,096][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0738, 0.1380, 0.0536, 0.1684, 0.1025, 0.0693, 0.0852, 0.0502, 0.0656,
        0.1934], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:19,098][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0830, 0.0406, 0.0737, 0.1080, 0.1001, 0.1409, 0.0942, 0.1398, 0.1089,
        0.1108], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:19,099][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([2.2622e-06, 1.1653e-01, 2.9812e-02, 2.2161e-01, 3.0515e-02, 1.6391e-01,
        5.4423e-05, 2.2833e-01, 4.9184e-02, 1.6006e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:19,100][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.1063, 0.0752, 0.0784, 0.1786, 0.1200, 0.0937, 0.0956, 0.0443, 0.0523,
        0.1556], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:19,102][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0837, 0.1648, 0.1098, 0.2129, 0.0939, 0.0653, 0.0866, 0.0377, 0.0400,
        0.1052], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:19,104][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.6326, 0.0080, 0.0255, 0.0275, 0.0463, 0.0155, 0.1910, 0.0081, 0.0188,
        0.0267], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:19,106][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.4913, 0.0182, 0.0263, 0.0346, 0.0592, 0.0332, 0.2215, 0.0288, 0.0407,
        0.0462], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:19,107][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0317, 0.1189, 0.0658, 0.1416, 0.1151, 0.1128, 0.0505, 0.0822, 0.1158,
        0.1655], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:19,109][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.1232, 0.1144, 0.0849, 0.1478, 0.1237, 0.0764, 0.0898, 0.0703, 0.0680,
        0.1015], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:19,111][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0224, 0.1478, 0.0850, 0.2372, 0.1104, 0.1093, 0.0362, 0.0627, 0.0535,
        0.1354], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:19,112][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([1.3201e-04, 7.3918e-02, 6.1225e-02, 2.1917e-01, 1.3489e-01, 1.7607e-01,
        9.1833e-04, 1.3555e-01, 6.2855e-02, 1.3528e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:19,114][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0745, 0.0751, 0.0861, 0.1174, 0.1377, 0.0973, 0.0956, 0.1171, 0.0966,
        0.1025], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:19,115][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0736, 0.1169, 0.0476, 0.1302, 0.0958, 0.0511, 0.0784, 0.0367, 0.0458,
        0.1659, 0.1580], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:19,116][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0971, 0.0311, 0.0672, 0.0851, 0.0760, 0.1118, 0.1007, 0.1113, 0.0895,
        0.0942, 0.1361], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:19,117][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([3.1803e-06, 1.2441e-01, 2.6270e-02, 1.8006e-01, 2.6218e-02, 1.4733e-01,
        6.8692e-05, 1.7184e-01, 4.7016e-02, 1.4611e-01, 1.3068e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:19,118][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0988, 0.0731, 0.0673, 0.1521, 0.1099, 0.0758, 0.0848, 0.0329, 0.0403,
        0.1288, 0.1363], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:19,119][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0901, 0.1159, 0.0907, 0.1749, 0.0827, 0.0547, 0.0865, 0.0306, 0.0363,
        0.1030, 0.1347], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:19,121][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.7025, 0.0046, 0.0151, 0.0159, 0.0316, 0.0089, 0.1754, 0.0044, 0.0112,
        0.0154, 0.0151], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:19,122][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.5384, 0.0138, 0.0211, 0.0261, 0.0462, 0.0231, 0.2134, 0.0205, 0.0298,
        0.0342, 0.0335], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:19,124][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0375, 0.1020, 0.0524, 0.1168, 0.0886, 0.0922, 0.0545, 0.0670, 0.0983,
        0.1475, 0.1432], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:19,125][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.1399, 0.1018, 0.0721, 0.1204, 0.1076, 0.0640, 0.0944, 0.0478, 0.0581,
        0.0951, 0.0989], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:19,127][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0231, 0.1278, 0.0874, 0.2014, 0.0997, 0.0891, 0.0353, 0.0530, 0.0423,
        0.1157, 0.1252], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:19,129][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0002, 0.0665, 0.0549, 0.1891, 0.1242, 0.1527, 0.0012, 0.1142, 0.0553,
        0.1155, 0.1261], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:19,130][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0948, 0.0870, 0.0664, 0.0893, 0.1051, 0.0698, 0.1103, 0.0993, 0.0862,
        0.1003, 0.0915], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:19,132][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.0094, 0.0666, 0.0441, 0.1701, 0.0838, 0.0802, 0.0206, 0.0440, 0.0590,
        0.1730, 0.2020, 0.0471], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:19,134][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([0.0299, 0.0490, 0.0953, 0.1166, 0.0776, 0.1067, 0.0385, 0.1230, 0.0898,
        0.0929, 0.1363, 0.0442], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:19,135][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([3.1941e-06, 1.2362e-01, 4.0575e-02, 1.8842e-01, 2.5938e-02, 1.7741e-01,
        6.0150e-05, 1.4706e-01, 3.6418e-02, 1.2368e-01, 1.2133e-01, 1.5490e-02],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:19,137][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([0.0312, 0.0554, 0.0554, 0.1510, 0.0860, 0.0969, 0.0422, 0.0492, 0.0575,
        0.1515, 0.1677, 0.0561], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:19,138][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.0127, 0.1043, 0.0875, 0.2192, 0.0823, 0.0757, 0.0234, 0.0466, 0.0452,
        0.1118, 0.1541, 0.0374], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:19,140][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([0.4893, 0.0165, 0.0242, 0.0401, 0.0654, 0.0208, 0.1799, 0.0101, 0.0245,
        0.0413, 0.0429, 0.0449], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:19,142][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.3440, 0.0247, 0.0323, 0.0484, 0.0687, 0.0379, 0.1802, 0.0286, 0.0460,
        0.0528, 0.0541, 0.0823], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:19,143][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.0231, 0.0671, 0.0546, 0.1165, 0.0997, 0.0782, 0.0372, 0.0711, 0.1001,
        0.1383, 0.1365, 0.0777], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:19,143][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.0153, 0.1072, 0.0767, 0.1874, 0.0886, 0.0761, 0.0209, 0.0576, 0.0635,
        0.1163, 0.1368, 0.0536], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:19,144][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([0.0057, 0.0990, 0.0688, 0.2180, 0.0914, 0.1121, 0.0132, 0.0715, 0.0450,
        0.1044, 0.1272, 0.0438], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:19,146][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([9.6230e-05, 6.9493e-02, 7.3886e-02, 2.4260e-01, 8.8037e-02, 1.7782e-01,
        6.5904e-04, 9.5868e-02, 3.8684e-02, 8.0975e-02, 1.1327e-01, 1.8615e-02],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:19,147][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([0.0468, 0.0759, 0.0838, 0.0945, 0.0969, 0.1002, 0.0672, 0.0991, 0.0798,
        0.0984, 0.1041, 0.0533], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:19,149][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Melissa] are: tensor([0.0295, 0.0798, 0.0287, 0.1241, 0.0685, 0.0525, 0.0445, 0.0517, 0.0600,
        0.1530, 0.1772, 0.0752, 0.0554], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:19,151][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Melissa] are: tensor([0.0305, 0.0304, 0.0728, 0.0887, 0.0639, 0.1129, 0.0433, 0.1141, 0.0914,
        0.0900, 0.1327, 0.0430, 0.0864], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:19,152][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Melissa] are: tensor([1.8778e-06, 1.3257e-01, 2.9644e-02, 1.8886e-01, 2.7914e-02, 1.3490e-01,
        4.4503e-05, 1.6547e-01, 4.2172e-02, 1.2367e-01, 1.1676e-01, 1.5556e-02,
        2.2452e-02], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:19,153][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Melissa] are: tensor([0.0676, 0.0479, 0.0474, 0.1350, 0.0881, 0.0726, 0.0679, 0.0382, 0.0449,
        0.1233, 0.1473, 0.0521, 0.0678], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:19,155][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Melissa] are: tensor([0.0514, 0.1041, 0.0765, 0.1560, 0.0833, 0.0488, 0.0602, 0.0322, 0.0370,
        0.1044, 0.1298, 0.0427, 0.0736], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:19,157][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Melissa] are: tensor([0.4355, 0.0109, 0.0304, 0.0540, 0.0619, 0.0260, 0.1763, 0.0123, 0.0304,
        0.0388, 0.0448, 0.0461, 0.0325], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:19,159][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Melissa] are: tensor([0.3764, 0.0200, 0.0280, 0.0408, 0.0632, 0.0372, 0.1739, 0.0252, 0.0361,
        0.0439, 0.0420, 0.0729, 0.0405], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:19,161][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Melissa] are: tensor([0.0331, 0.0761, 0.0533, 0.1109, 0.0849, 0.0676, 0.0445, 0.0691, 0.0973,
        0.1270, 0.1187, 0.0577, 0.0597], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:19,162][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Melissa] are: tensor([0.0807, 0.0705, 0.0587, 0.1388, 0.0923, 0.0602, 0.0646, 0.0542, 0.0552,
        0.0751, 0.0932, 0.0932, 0.0631], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:19,164][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Melissa] are: tensor([0.0146, 0.1211, 0.0430, 0.1893, 0.0856, 0.0847, 0.0249, 0.0517, 0.0501,
        0.1119, 0.1250, 0.0583, 0.0398], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:19,165][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Melissa] are: tensor([6.0427e-05, 5.8752e-02, 3.9188e-02, 2.1405e-01, 8.1144e-02, 1.6971e-01,
        5.1460e-04, 1.1822e-01, 5.5494e-02, 9.9096e-02, 1.1973e-01, 2.0735e-02,
        2.3319e-02], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:19,167][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Melissa] are: tensor([0.0581, 0.1023, 0.0657, 0.0920, 0.1037, 0.0726, 0.0714, 0.0967, 0.0706,
        0.0743, 0.0608, 0.0825, 0.0491], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:19,168][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.0389, 0.0737, 0.0452, 0.1073, 0.0561, 0.0294, 0.0472, 0.0287, 0.0305,
        0.1271, 0.1309, 0.0412, 0.0637, 0.1801], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:19,169][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([0.0452, 0.0320, 0.0709, 0.0725, 0.0654, 0.0797, 0.0499, 0.0921, 0.0749,
        0.0792, 0.1064, 0.0427, 0.1015, 0.0877], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:19,170][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([2.9671e-06, 1.1814e-01, 4.0799e-02, 1.9607e-01, 3.1719e-02, 1.0745e-01,
        6.1410e-05, 1.5783e-01, 3.0163e-02, 1.0593e-01, 1.0192e-01, 1.8454e-02,
        2.4667e-02, 6.6799e-02], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:19,172][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([0.0643, 0.0507, 0.0421, 0.1137, 0.0695, 0.0546, 0.0567, 0.0284, 0.0308,
        0.1011, 0.1107, 0.0371, 0.0504, 0.1900], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:19,173][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([0.0555, 0.1263, 0.0616, 0.1428, 0.0536, 0.0414, 0.0550, 0.0241, 0.0262,
        0.0871, 0.1061, 0.0249, 0.0479, 0.1475], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:19,175][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([0.5754, 0.0057, 0.0220, 0.0215, 0.0410, 0.0093, 0.1724, 0.0062, 0.0130,
        0.0208, 0.0235, 0.0278, 0.0304, 0.0310], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:19,177][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([0.4026, 0.0151, 0.0222, 0.0299, 0.0480, 0.0270, 0.1783, 0.0222, 0.0333,
        0.0355, 0.0381, 0.0618, 0.0376, 0.0484], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:19,178][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.0167, 0.0748, 0.0451, 0.1007, 0.0769, 0.0782, 0.0294, 0.0576, 0.0746,
        0.1232, 0.1203, 0.0556, 0.0482, 0.0987], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:19,180][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([0.0795, 0.0753, 0.0524, 0.1061, 0.0616, 0.0436, 0.0591, 0.0352, 0.0370,
        0.0757, 0.0741, 0.0592, 0.0554, 0.1858], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:19,182][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([0.0103, 0.1204, 0.0600, 0.1936, 0.0713, 0.0590, 0.0174, 0.0418, 0.0259,
        0.0924, 0.1078, 0.0416, 0.0379, 0.1204], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:19,183][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([1.5269e-04, 5.7551e-02, 7.2660e-02, 2.1452e-01, 1.3218e-01, 1.0229e-01,
        9.1745e-04, 7.5299e-02, 3.4697e-02, 7.9192e-02, 8.8830e-02, 2.9648e-02,
        3.4542e-02, 7.7520e-02], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:19,185][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([0.0658, 0.0651, 0.0589, 0.0755, 0.0912, 0.0542, 0.0826, 0.0843, 0.0633,
        0.0843, 0.0794, 0.0789, 0.0475, 0.0690], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:19,187][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0528, 0.0569, 0.0230, 0.0635, 0.0409, 0.0239, 0.0482, 0.0189, 0.0235,
        0.0858, 0.0827, 0.0354, 0.0351, 0.1799, 0.2295], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:19,188][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0620, 0.0210, 0.0489, 0.0657, 0.0580, 0.0708, 0.0636, 0.0822, 0.0667,
        0.0681, 0.0990, 0.0359, 0.0868, 0.0813, 0.0901], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:19,190][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([2.1329e-06, 7.3217e-02, 2.1686e-02, 1.5742e-01, 2.0129e-02, 1.0326e-01,
        5.0039e-05, 1.5798e-01, 3.4491e-02, 1.0101e-01, 8.9898e-02, 1.5250e-02,
        1.5911e-02, 6.5754e-02, 1.4393e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:19,192][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0957, 0.0351, 0.0355, 0.0849, 0.0553, 0.0388, 0.0692, 0.0181, 0.0268,
        0.0818, 0.0899, 0.0269, 0.0417, 0.1675, 0.1329], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:19,193][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.1193, 0.0806, 0.0482, 0.0942, 0.0553, 0.0291, 0.0847, 0.0149, 0.0215,
        0.0613, 0.0723, 0.0225, 0.0405, 0.1373, 0.1182], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:19,194][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.6300, 0.0048, 0.0134, 0.0166, 0.0314, 0.0072, 0.1600, 0.0037, 0.0116,
        0.0154, 0.0175, 0.0228, 0.0190, 0.0275, 0.0193], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:19,195][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.4865, 0.0110, 0.0164, 0.0215, 0.0375, 0.0181, 0.1846, 0.0142, 0.0240,
        0.0270, 0.0265, 0.0457, 0.0286, 0.0349, 0.0234], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:19,196][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0323, 0.0464, 0.0298, 0.0788, 0.0630, 0.0598, 0.0462, 0.0500, 0.0800,
        0.1111, 0.1053, 0.0515, 0.0411, 0.1050, 0.0997], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:19,198][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.1000, 0.0771, 0.0440, 0.0744, 0.0631, 0.0352, 0.0578, 0.0256, 0.0370,
        0.0564, 0.0578, 0.0463, 0.0480, 0.1878, 0.0896], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:19,199][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0243, 0.0975, 0.0464, 0.1415, 0.0587, 0.0569, 0.0303, 0.0300, 0.0277,
        0.0769, 0.0828, 0.0340, 0.0314, 0.1339, 0.1275], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:19,201][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0002, 0.0439, 0.0500, 0.1779, 0.0930, 0.1103, 0.0011, 0.0726, 0.0364,
        0.0763, 0.0809, 0.0214, 0.0243, 0.0789, 0.1328], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:19,203][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0661, 0.0543, 0.0499, 0.0783, 0.0796, 0.0551, 0.0783, 0.0790, 0.0644,
        0.0729, 0.0721, 0.0667, 0.0434, 0.0671, 0.0728], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:19,206][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:31:19,208][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 4462],
        [  803],
        [  330],
        [  178],
        [14768],
        [  134],
        [  211],
        [  453],
        [ 1085],
        [  556],
        [  350],
        [ 1086],
        [ 1219],
        [  732],
        [  383]], device='cuda:0')
[2024-07-24 10:31:19,210][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 5277],
        [  967],
        [  414],
        [  143],
        [18485],
        [  109],
        [  298],
        [  434],
        [  956],
        [  464],
        [  244],
        [  759],
        [ 1149],
        [  781],
        [  338]], device='cuda:0')
[2024-07-24 10:31:19,211][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[30302],
        [32405],
        [35715],
        [37125],
        [36788],
        [36163],
        [35569],
        [36208],
        [37120],
        [36542],
        [35789],
        [35606],
        [36438],
        [37304],
        [38284]], device='cuda:0')
[2024-07-24 10:31:19,213][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[23238],
        [10857],
        [ 5884],
        [ 7135],
        [11361],
        [10860],
        [10922],
        [ 9770],
        [ 9574],
        [ 8815],
        [ 8307],
        [ 8560],
        [ 7367],
        [ 7558],
        [ 7528]], device='cuda:0')
[2024-07-24 10:31:19,215][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[21342],
        [28923],
        [28827],
        [28774],
        [28833],
        [28805],
        [28708],
        [28630],
        [28481],
        [28549],
        [28455],
        [28294],
        [28571],
        [28490],
        [28248]], device='cuda:0')
[2024-07-24 10:31:19,216][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[  716],
        [ 1665],
        [ 1209],
        [ 5819],
        [ 8225],
        [10816],
        [12332],
        [10033],
        [11033],
        [11901],
        [12859],
        [14332],
        [12655],
        [14809],
        [14912]], device='cuda:0')
[2024-07-24 10:31:19,218][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[12906],
        [39005],
        [37809],
        [42410],
        [43129],
        [43566],
        [45145],
        [44276],
        [45009],
        [45218],
        [46362],
        [46909],
        [46374],
        [46608],
        [47034]], device='cuda:0')
[2024-07-24 10:31:19,220][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[37873],
        [38035],
        [40481],
        [39823],
        [46458],
        [43587],
        [48913],
        [44040],
        [46771],
        [47155],
        [45820],
        [47306],
        [47128],
        [46656],
        [46225]], device='cuda:0')
[2024-07-24 10:31:19,222][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[3212],
        [1937],
        [3173],
        [3915],
        [4206],
        [5056],
        [5835],
        [6103],
        [5920],
        [5958],
        [6178],
        [6266],
        [6646],
        [6814],
        [6800]], device='cuda:0')
[2024-07-24 10:31:19,223][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[31736],
        [22268],
        [29355],
        [23542],
        [30344],
        [30847],
        [27632],
        [30695],
        [28129],
        [28226],
        [27494],
        [28046],
        [29405],
        [29035],
        [30339]], device='cuda:0')
[2024-07-24 10:31:19,225][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[31260],
        [34469],
        [41397],
        [36112],
        [42168],
        [41970],
        [40634],
        [40515],
        [40105],
        [38987],
        [37664],
        [35192],
        [38159],
        [37488],
        [36802]], device='cuda:0')
[2024-07-24 10:31:19,226][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[20223],
        [14922],
        [16888],
        [21220],
        [14803],
        [16127],
        [16038],
        [17884],
        [17870],
        [17542],
        [18825],
        [18832],
        [18365],
        [18152],
        [19079]], device='cuda:0')
[2024-07-24 10:31:19,228][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[36204],
        [36238],
        [36172],
        [36317],
        [33450],
        [29319],
        [24084],
        [20654],
        [28745],
        [35457],
        [35392],
        [34774],
        [34869],
        [35299],
        [34976]], device='cuda:0')
[2024-07-24 10:31:19,230][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[20905],
        [24060],
        [13428],
        [ 8107],
        [ 9076],
        [11405],
        [ 7520],
        [ 9254],
        [ 8799],
        [ 6825],
        [ 7539],
        [10543],
        [ 9734],
        [ 6473],
        [ 8094]], device='cuda:0')
[2024-07-24 10:31:19,231][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 8922],
        [ 7715],
        [ 5477],
        [ 9027],
        [ 5459],
        [11324],
        [ 8267],
        [14888],
        [10805],
        [ 8339],
        [ 8395],
        [12035],
        [ 5889],
        [ 7944],
        [ 6954]], device='cuda:0')
[2024-07-24 10:31:19,233][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[35928],
        [43523],
        [37469],
        [33796],
        [29385],
        [30981],
        [28782],
        [31293],
        [28962],
        [29803],
        [30118],
        [26822],
        [27053],
        [24106],
        [21544]], device='cuda:0')
[2024-07-24 10:31:19,235][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[25425],
        [25574],
        [26199],
        [21809],
        [19359],
        [19802],
        [16918],
        [20012],
        [18507],
        [16424],
        [15765],
        [14919],
        [16203],
        [16859],
        [16634]], device='cuda:0')
[2024-07-24 10:31:19,236][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[ 9309],
        [40112],
        [40844],
        [35223],
        [35761],
        [29375],
        [27073],
        [31169],
        [30627],
        [28457],
        [28462],
        [28053],
        [29237],
        [28610],
        [24330]], device='cuda:0')
[2024-07-24 10:31:19,238][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[15789],
        [12794],
        [22889],
        [25515],
        [27220],
        [27119],
        [27648],
        [26331],
        [27802],
        [26897],
        [25628],
        [27082],
        [25138],
        [25712],
        [23586]], device='cuda:0')
[2024-07-24 10:31:19,240][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[18837],
        [ 4308],
        [ 6319],
        [ 6655],
        [ 8092],
        [ 7869],
        [ 9678],
        [ 8251],
        [ 9355],
        [ 9710],
        [10368],
        [10972],
        [12044],
        [12042],
        [13133]], device='cuda:0')
[2024-07-24 10:31:19,241][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[17683],
        [17715],
        [18333],
        [18851],
        [19803],
        [19875],
        [17449],
        [17889],
        [16478],
        [15915],
        [17159],
        [16411],
        [16112],
        [16197],
        [16754]], device='cuda:0')
[2024-07-24 10:31:19,243][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[22428],
        [23255],
        [24936],
        [26525],
        [30622],
        [29554],
        [33707],
        [29299],
        [32078],
        [32667],
        [32103],
        [32161],
        [31320],
        [32465],
        [32668]], device='cuda:0')
[2024-07-24 10:31:19,245][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[33808],
        [23678],
        [19888],
        [18405],
        [13721],
        [13470],
        [14777],
        [15103],
        [13848],
        [13843],
        [13797],
        [14324],
        [13865],
        [13040],
        [12856]], device='cuda:0')
[2024-07-24 10:31:19,247][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[28758],
        [14667],
        [13404],
        [27890],
        [25453],
        [25060],
        [24356],
        [22697],
        [18901],
        [18110],
        [18791],
        [18168],
        [16603],
        [15492],
        [14775]], device='cuda:0')
[2024-07-24 10:31:19,248][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[36095],
        [10862],
        [ 8998],
        [ 6327],
        [ 3972],
        [ 3092],
        [ 2509],
        [ 2431],
        [ 1854],
        [ 1855],
        [ 2118],
        [ 1705],
        [ 1922],
        [ 2297],
        [ 2022]], device='cuda:0')
[2024-07-24 10:31:19,250][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[46194],
        [13122],
        [11665],
        [13385],
        [12347],
        [10356],
        [10727],
        [ 8761],
        [ 8499],
        [ 8168],
        [ 8945],
        [ 9074],
        [ 8688],
        [ 9353],
        [ 8768]], device='cuda:0')
[2024-07-24 10:31:19,251][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[30516],
        [31993],
        [29888],
        [28228],
        [27106],
        [25776],
        [25055],
        [23418],
        [22980],
        [22980],
        [23681],
        [23784],
        [24515],
        [24312],
        [22980]], device='cuda:0')
[2024-07-24 10:31:19,253][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[ 6912],
        [19806],
        [19879],
        [20178],
        [22995],
        [25924],
        [26628],
        [27601],
        [30070],
        [31539],
        [30803],
        [31315],
        [31061],
        [31152],
        [33273]], device='cuda:0')
[2024-07-24 10:31:19,255][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[32605],
        [33234],
        [37120],
        [36565],
        [38954],
        [34382],
        [25357],
        [31261],
        [32832],
        [34808],
        [34832],
        [31285],
        [36430],
        [35291],
        [37475]], device='cuda:0')
[2024-07-24 10:31:19,256][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[11893],
        [11893],
        [11893],
        [11893],
        [11893],
        [11893],
        [11893],
        [11893],
        [11893],
        [11893],
        [11893],
        [11893],
        [11893],
        [11893],
        [11893]], device='cuda:0')
[2024-07-24 10:31:19,352][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:31:19,352][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:19,353][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:19,355][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:19,356][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:19,357][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:19,358][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:19,360][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:19,361][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:19,362][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:19,364][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:19,365][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:19,366][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:19,368][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.5916, 0.4084], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:19,369][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [,] are: tensor([2.5042e-04, 9.9975e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:19,371][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.9812, 0.0188], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:19,372][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [,] are: tensor([9.9937e-01, 6.3317e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:19,373][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.1812, 0.8188], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:19,375][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.9301, 0.0699], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:19,376][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.2099, 0.7901], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:19,377][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.5696, 0.4304], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:19,378][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.9834, 0.0166], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:19,378][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.9946, 0.0054], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:19,380][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.5784, 0.4216], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:19,381][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.1773, 0.8227], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:19,382][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Melissa] are: tensor([0.3637, 0.2901, 0.3462], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:19,384][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Melissa] are: tensor([2.4555e-05, 4.7114e-01, 5.2883e-01], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:19,385][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Melissa] are: tensor([0.9184, 0.0664, 0.0152], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:19,386][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Melissa] are: tensor([9.9925e-01, 1.8871e-04, 5.5864e-04], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:19,388][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Melissa] are: tensor([0.0619, 0.6756, 0.2625], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:19,390][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Melissa] are: tensor([0.7788, 0.1384, 0.0828], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:19,391][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Melissa] are: tensor([0.0388, 0.7746, 0.1867], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:19,393][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Melissa] are: tensor([0.2434, 0.6241, 0.1325], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:19,394][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Melissa] are: tensor([0.8703, 0.0297, 0.1000], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:19,396][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Melissa] are: tensor([0.9794, 0.0097, 0.0109], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:19,398][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Melissa] are: tensor([0.4636, 0.2247, 0.3117], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:19,399][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Melissa] are: tensor([0.0817, 0.5086, 0.4097], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:19,401][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.3041, 0.2271, 0.2551, 0.2137], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:19,402][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ and] are: tensor([2.3963e-06, 8.6300e-02, 1.2713e-01, 7.8657e-01], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:19,403][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.9217, 0.0428, 0.0144, 0.0211], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:19,404][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ and] are: tensor([9.9783e-01, 5.5208e-04, 1.0895e-03, 5.3004e-04], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:19,404][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0395, 0.3476, 0.1282, 0.4847], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:19,405][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.7393, 0.1134, 0.0664, 0.0809], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:19,407][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0837, 0.2498, 0.6353, 0.0312], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:19,408][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.3057, 0.4500, 0.0997, 0.1445], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:19,410][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.8152, 0.0332, 0.0781, 0.0734], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:19,411][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.9750, 0.0069, 0.0061, 0.0120], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:19,413][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.3538, 0.1650, 0.1800, 0.3013], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:19,415][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0604, 0.3468, 0.2338, 0.3590], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:19,416][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Benjamin] are: tensor([0.2387, 0.1732, 0.1947, 0.1569, 0.2365], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:19,417][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Benjamin] are: tensor([1.0165e-05, 8.1806e-02, 7.2096e-02, 5.9929e-01, 2.4680e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:19,419][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Benjamin] are: tensor([0.8316, 0.0832, 0.0194, 0.0516, 0.0142], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:19,420][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Benjamin] are: tensor([9.9910e-01, 1.5503e-04, 3.9324e-04, 1.8262e-04, 1.6530e-04],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:19,422][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Benjamin] are: tensor([0.0089, 0.2425, 0.1199, 0.4883, 0.1403], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:19,423][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Benjamin] are: tensor([0.3920, 0.1937, 0.1048, 0.1588, 0.1506], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:19,425][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Benjamin] are: tensor([0.0075, 0.9021, 0.0510, 0.0300, 0.0095], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:19,427][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Benjamin] are: tensor([0.0497, 0.4435, 0.1258, 0.2554, 0.1256], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:19,428][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Benjamin] are: tensor([0.6193, 0.0367, 0.1103, 0.0899, 0.1439], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:19,429][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Benjamin] are: tensor([0.9467, 0.0089, 0.0106, 0.0196, 0.0143], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:19,430][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Benjamin] are: tensor([0.1962, 0.1516, 0.1696, 0.2795, 0.2031], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:19,431][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Benjamin] are: tensor([0.0245, 0.2608, 0.1455, 0.3323, 0.2369], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:19,431][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.2081, 0.1360, 0.1580, 0.1229, 0.1810, 0.1941], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:19,432][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ had] are: tensor([2.0814e-06, 4.5640e-02, 8.1637e-02, 5.0087e-01, 2.5145e-01, 1.2040e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:19,434][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.9300, 0.0255, 0.0093, 0.0218, 0.0084, 0.0050], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:19,435][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ had] are: tensor([9.9815e-01, 3.4905e-04, 6.5696e-04, 3.3655e-04, 2.8148e-04, 2.2865e-04],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:19,437][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.0160, 0.2348, 0.0894, 0.4060, 0.1143, 0.1395], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:19,438][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.5752, 0.1142, 0.0709, 0.0910, 0.0986, 0.0501], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:19,440][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.0101, 0.7595, 0.1403, 0.0194, 0.0137, 0.0571], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:19,441][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.1703, 0.4184, 0.0745, 0.1605, 0.1156, 0.0608], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:19,443][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.6666, 0.0259, 0.0726, 0.0717, 0.1184, 0.0448], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:19,445][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.9425, 0.0072, 0.0099, 0.0149, 0.0145, 0.0111], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:19,446][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.2365, 0.0999, 0.1401, 0.2184, 0.1685, 0.1367], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:19,448][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0187, 0.1755, 0.1690, 0.2630, 0.2206, 0.1532], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:19,450][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.2314, 0.1184, 0.1443, 0.1055, 0.1870, 0.2095, 0.0039],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:19,451][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ a] are: tensor([6.5425e-06, 2.2513e-02, 5.0597e-02, 3.1073e-01, 2.1942e-01, 6.9899e-02,
        3.2684e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:19,453][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.2626, 0.1389, 0.1185, 0.1040, 0.1025, 0.0669, 0.2065],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:19,454][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ a] are: tensor([9.9812e-01, 2.5970e-04, 6.0163e-04, 2.6453e-04, 2.7009e-04, 2.1433e-04,
        2.7347e-04], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:19,455][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0021, 0.1475, 0.1149, 0.3214, 0.1422, 0.2647, 0.0073],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:19,456][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0771, 0.1609, 0.1173, 0.1725, 0.1965, 0.1775, 0.0982],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:19,457][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0254, 0.6333, 0.1209, 0.0873, 0.0364, 0.0810, 0.0157],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:19,457][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0109, 0.2281, 0.1135, 0.2558, 0.1719, 0.1924, 0.0274],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:19,459][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.1200, 0.1284, 0.1319, 0.1419, 0.1986, 0.1363, 0.1428],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:19,460][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0735, 0.1503, 0.1082, 0.2221, 0.1400, 0.2044, 0.1014],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:19,462][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0154, 0.1579, 0.1589, 0.2525, 0.1674, 0.2124, 0.0355],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:19,464][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0042, 0.2342, 0.1380, 0.2181, 0.1798, 0.2117, 0.0140],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:19,465][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.1765, 0.1214, 0.1498, 0.1145, 0.1726, 0.1781, 0.0087, 0.0785],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:19,466][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ long] are: tensor([3.0753e-06, 2.0952e-02, 4.7445e-02, 2.8904e-01, 1.7696e-01, 5.4246e-02,
        3.1503e-01, 9.6325e-02], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:19,468][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.6979, 0.0304, 0.0106, 0.0187, 0.0047, 0.0090, 0.2254, 0.0032],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:19,469][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ long] are: tensor([9.9626e-01, 3.9937e-04, 7.1199e-04, 4.3873e-04, 3.1950e-04, 2.8316e-04,
        3.6615e-04, 1.2166e-03], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:19,471][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.0090, 0.1597, 0.0704, 0.3818, 0.1051, 0.1464, 0.0210, 0.1066],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:19,473][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ long] are: tensor([0.3672, 0.1081, 0.0507, 0.0803, 0.0680, 0.0532, 0.2390, 0.0336],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:19,475][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.0321, 0.5940, 0.1773, 0.0374, 0.0279, 0.0379, 0.0180, 0.0755],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:19,476][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.1002, 0.4087, 0.0451, 0.1328, 0.0612, 0.0588, 0.1393, 0.0540],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:19,478][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.4360, 0.0250, 0.0481, 0.0637, 0.0815, 0.0327, 0.2796, 0.0332],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:19,480][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ long] are: tensor([0.7085, 0.0038, 0.0048, 0.0079, 0.0069, 0.0055, 0.2577, 0.0049],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:19,481][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.1450, 0.0887, 0.1043, 0.1752, 0.1171, 0.1127, 0.1665, 0.0905],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:19,482][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ long] are: tensor([0.0159, 0.1589, 0.1233, 0.1953, 0.1545, 0.1421, 0.0393, 0.1707],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:19,482][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.1233, 0.1196, 0.1400, 0.1047, 0.1680, 0.1748, 0.0070, 0.0758, 0.0867],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:19,483][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([3.4977e-07, 1.8939e-02, 3.1975e-02, 3.1172e-01, 1.0633e-01, 5.4093e-02,
        3.3223e-01, 8.3664e-02, 6.1047e-02], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:19,485][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.5051, 0.1148, 0.0302, 0.0733, 0.0223, 0.0176, 0.1990, 0.0058, 0.0318],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:19,486][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([9.9237e-01, 7.1761e-04, 1.1428e-03, 7.1931e-04, 4.9875e-04, 5.2911e-04,
        7.1915e-04, 1.8995e-03, 1.3987e-03], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:19,488][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.0062, 0.1737, 0.0597, 0.3057, 0.0795, 0.1300, 0.0160, 0.1159, 0.1134],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:19,489][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([0.2621, 0.1116, 0.0660, 0.0962, 0.0858, 0.0645, 0.1930, 0.0513, 0.0695],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:19,491][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.0044, 0.6977, 0.0692, 0.0417, 0.0135, 0.0804, 0.0051, 0.0752, 0.0127],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:19,492][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.0624, 0.2931, 0.0512, 0.1330, 0.0705, 0.0699, 0.0978, 0.0844, 0.1376],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:19,494][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.3246, 0.0370, 0.0789, 0.0761, 0.1135, 0.0454, 0.2283, 0.0426, 0.0536],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:19,496][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.6366, 0.0076, 0.0095, 0.0174, 0.0131, 0.0128, 0.2736, 0.0086, 0.0208],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:19,497][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.0815, 0.0875, 0.1003, 0.1672, 0.1062, 0.1106, 0.1096, 0.0939, 0.1432],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:19,499][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([0.0085, 0.1363, 0.1047, 0.1926, 0.1321, 0.1227, 0.0242, 0.1537, 0.1252],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:19,501][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.1199, 0.1036, 0.1200, 0.1017, 0.1451, 0.1474, 0.0139, 0.0836, 0.0859,
        0.0789], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:19,502][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [,] are: tensor([9.9356e-08, 1.3879e-02, 3.0821e-02, 2.2907e-01, 1.3755e-01, 5.5545e-02,
        2.7617e-01, 9.1654e-02, 6.3625e-02, 1.0168e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:19,504][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.6708, 0.0467, 0.0103, 0.0379, 0.0086, 0.0094, 0.1728, 0.0039, 0.0200,
        0.0195], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:19,505][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [,] are: tensor([9.9276e-01, 6.4243e-04, 9.1947e-04, 5.9232e-04, 4.3381e-04, 4.0464e-04,
        5.6903e-04, 1.6915e-03, 1.0004e-03, 9.8637e-04], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:19,507][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0120, 0.1556, 0.0570, 0.2407, 0.0728, 0.0949, 0.0211, 0.0785, 0.0926,
        0.1747], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:19,508][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.3875, 0.0809, 0.0514, 0.0597, 0.0653, 0.0335, 0.2051, 0.0221, 0.0367,
        0.0577], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:19,508][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0210, 0.4239, 0.1294, 0.0280, 0.0361, 0.1238, 0.0241, 0.1078, 0.0326,
        0.0733], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:19,509][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.1203, 0.2431, 0.0463, 0.0841, 0.0631, 0.0404, 0.1204, 0.0461, 0.0836,
        0.1526], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:19,510][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.2844, 0.0310, 0.0812, 0.0789, 0.1053, 0.0471, 0.1948, 0.0515, 0.0582,
        0.0677], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:19,512][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.6173, 0.0078, 0.0098, 0.0173, 0.0133, 0.0117, 0.2617, 0.0099, 0.0203,
        0.0309], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:19,513][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0694, 0.0849, 0.0882, 0.1506, 0.0898, 0.0901, 0.0857, 0.0770, 0.1047,
        0.1596], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:19,515][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0103, 0.1362, 0.0932, 0.1506, 0.1285, 0.0910, 0.0237, 0.1173, 0.0961,
        0.1532], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:19,517][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.1134, 0.0972, 0.1105, 0.0914, 0.1277, 0.1358, 0.0168, 0.0756, 0.0815,
        0.0747, 0.0754], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:19,518][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ and] are: tensor([7.3057e-08, 1.2569e-02, 2.2887e-02, 1.6390e-01, 9.7431e-02, 4.7915e-02,
        2.2960e-01, 7.9007e-02, 4.2732e-02, 7.0821e-02, 2.3313e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:19,519][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.6721, 0.0493, 0.0187, 0.0225, 0.0132, 0.0082, 0.1575, 0.0034, 0.0197,
        0.0251, 0.0102], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:19,521][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ and] are: tensor([9.8781e-01, 7.8879e-04, 1.3709e-03, 9.1312e-04, 6.7683e-04, 5.4612e-04,
        7.4873e-04, 2.2488e-03, 1.4157e-03, 1.3465e-03, 2.1321e-03],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:19,522][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0117, 0.1168, 0.0513, 0.1958, 0.0680, 0.0889, 0.0209, 0.0715, 0.0825,
        0.1486, 0.1440], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:19,524][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.3383, 0.0833, 0.0464, 0.0564, 0.0675, 0.0364, 0.1863, 0.0233, 0.0396,
        0.0636, 0.0589], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:19,526][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0219, 0.3311, 0.2931, 0.0151, 0.0433, 0.1015, 0.0311, 0.0839, 0.0264,
        0.0477, 0.0049], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:19,527][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.1245, 0.1842, 0.0436, 0.0766, 0.0660, 0.0357, 0.1166, 0.0433, 0.0709,
        0.1360, 0.1026], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:19,529][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.3020, 0.0278, 0.0693, 0.0682, 0.0951, 0.0384, 0.1951, 0.0423, 0.0499,
        0.0589, 0.0531], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:19,531][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.6010, 0.0081, 0.0087, 0.0154, 0.0121, 0.0113, 0.2495, 0.0094, 0.0198,
        0.0278, 0.0370], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:19,533][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0817, 0.0672, 0.0709, 0.1186, 0.0747, 0.0714, 0.0936, 0.0623, 0.0949,
        0.1391, 0.1256], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:19,534][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0136, 0.1082, 0.0693, 0.1242, 0.0998, 0.0795, 0.0286, 0.1081, 0.0882,
        0.1434, 0.1371], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:19,534][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.0981, 0.0960, 0.1058, 0.0890, 0.1271, 0.1313, 0.0085, 0.0715, 0.0697,
        0.0699, 0.0724, 0.0607], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:19,535][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([3.4090e-07, 1.5898e-02, 2.0115e-02, 1.5769e-01, 6.5437e-02, 3.5483e-02,
        2.0416e-01, 4.3765e-02, 3.0507e-02, 8.5052e-02, 2.1076e-01, 1.3114e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:19,537][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.3911, 0.1109, 0.0153, 0.0701, 0.0074, 0.0228, 0.1679, 0.0103, 0.0522,
        0.0908, 0.0497, 0.0116], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:19,538][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([9.9306e-01, 4.1952e-04, 7.4641e-04, 4.1773e-04, 3.5225e-04, 2.5625e-04,
        3.5636e-04, 1.1825e-03, 7.9278e-04, 6.9069e-04, 9.8250e-04, 7.4236e-04],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:19,540][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.0016, 0.0930, 0.0445, 0.2100, 0.0643, 0.1243, 0.0051, 0.0791, 0.0813,
        0.1336, 0.1285, 0.0347], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:19,542][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([0.0977, 0.1075, 0.0717, 0.1137, 0.0827, 0.0675, 0.0854, 0.0478, 0.0610,
        0.1045, 0.0999, 0.0608], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:19,543][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.0027, 0.7330, 0.0298, 0.0192, 0.0048, 0.0341, 0.0024, 0.0452, 0.0059,
        0.1050, 0.0082, 0.0096], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:19,545][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.0191, 0.2094, 0.0465, 0.1176, 0.0570, 0.0602, 0.0326, 0.0589, 0.0844,
        0.1533, 0.1217, 0.0394], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:19,547][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.1369, 0.0441, 0.0934, 0.1019, 0.1155, 0.0558, 0.1260, 0.0559, 0.0625,
        0.0743, 0.0746, 0.0591], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:19,548][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([0.4559, 0.0134, 0.0173, 0.0301, 0.0172, 0.0190, 0.2584, 0.0172, 0.0338,
        0.0482, 0.0576, 0.0320], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:19,550][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.0342, 0.0688, 0.0768, 0.1357, 0.0718, 0.0805, 0.0508, 0.0680, 0.0936,
        0.1351, 0.1183, 0.0664], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:19,552][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([0.0059, 0.1017, 0.0633, 0.1205, 0.0827, 0.0782, 0.0152, 0.1103, 0.0856,
        0.1224, 0.1289, 0.0853], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:19,554][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Melissa] are: tensor([0.0998, 0.0839, 0.1009, 0.0750, 0.1138, 0.1238, 0.0072, 0.0541, 0.0653,
        0.0639, 0.0597, 0.0498, 0.1028], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:19,555][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Melissa] are: tensor([7.2346e-07, 1.4245e-02, 1.8905e-02, 1.5928e-01, 8.2729e-02, 2.9677e-02,
        1.6068e-01, 4.8242e-02, 3.5482e-02, 8.1495e-02, 1.9599e-01, 1.1650e-01,
        5.6771e-02], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:19,557][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Melissa] are: tensor([0.5463, 0.0774, 0.0209, 0.0496, 0.0062, 0.0140, 0.1697, 0.0046, 0.0206,
        0.0336, 0.0198, 0.0064, 0.0309], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:19,558][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Melissa] are: tensor([9.9062e-01, 2.8655e-04, 6.1326e-04, 3.0906e-04, 2.7389e-04, 2.6442e-04,
        3.8663e-04, 1.4514e-03, 8.9410e-04, 6.6116e-04, 9.8724e-04, 6.9526e-04,
        2.5534e-03], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:19,559][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Melissa] are: tensor([0.0043, 0.0943, 0.0468, 0.1954, 0.0717, 0.0924, 0.0095, 0.0765, 0.0748,
        0.1336, 0.1199, 0.0402, 0.0405], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:19,560][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Melissa] are: tensor([0.2017, 0.0882, 0.0546, 0.0743, 0.0843, 0.0398, 0.1355, 0.0302, 0.0466,
        0.0729, 0.0655, 0.0607, 0.0458], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:19,561][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Melissa] are: tensor([0.0064, 0.8021, 0.0409, 0.0157, 0.0048, 0.0229, 0.0039, 0.0264, 0.0041,
        0.0523, 0.0066, 0.0040, 0.0097], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:19,561][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Melissa] are: tensor([0.0338, 0.1726, 0.0445, 0.1020, 0.0690, 0.0444, 0.0481, 0.0564, 0.0880,
        0.1396, 0.1067, 0.0477, 0.0473], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:19,563][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Melissa] are: tensor([0.2140, 0.0238, 0.0673, 0.0752, 0.0773, 0.0438, 0.1591, 0.0429, 0.0549,
        0.0631, 0.0545, 0.0724, 0.0517], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:19,565][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Melissa] are: tensor([0.4921, 0.0102, 0.0138, 0.0247, 0.0162, 0.0166, 0.2492, 0.0136, 0.0230,
        0.0395, 0.0514, 0.0295, 0.0203], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:19,567][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Melissa] are: tensor([0.0498, 0.0561, 0.0715, 0.1185, 0.0703, 0.0686, 0.0651, 0.0555, 0.0924,
        0.1146, 0.1001, 0.0592, 0.0784], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:19,568][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Melissa] are: tensor([0.0077, 0.0830, 0.0575, 0.1100, 0.0847, 0.0601, 0.0192, 0.0862, 0.0695,
        0.1107, 0.1155, 0.0916, 0.1043], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:19,570][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.0787, 0.0753, 0.0928, 0.0697, 0.1096, 0.1302, 0.0054, 0.0540, 0.0622,
        0.0553, 0.0546, 0.0436, 0.0952, 0.0735], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:19,571][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ said] are: tensor([2.9649e-07, 9.5446e-03, 1.9254e-02, 1.4005e-01, 6.0170e-02, 3.0410e-02,
        1.5416e-01, 5.2126e-02, 3.1179e-02, 7.7280e-02, 1.5368e-01, 1.3852e-01,
        5.1449e-02, 8.2174e-02], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:19,573][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.4829, 0.0561, 0.0246, 0.0426, 0.0140, 0.0099, 0.1498, 0.0054, 0.0225,
        0.0384, 0.0155, 0.0077, 0.0337, 0.0967], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:19,574][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ said] are: tensor([9.9271e-01, 3.6378e-04, 6.3927e-04, 2.8340e-04, 2.7657e-04, 2.1163e-04,
        2.8796e-04, 1.0376e-03, 6.5417e-04, 4.8745e-04, 6.5136e-04, 4.9979e-04,
        1.5905e-03, 3.0482e-04], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:19,576][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.0058, 0.0792, 0.0350, 0.1557, 0.0375, 0.0577, 0.0113, 0.0553, 0.0605,
        0.1141, 0.1033, 0.0253, 0.0301, 0.2292], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:19,577][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ said] are: tensor([0.2676, 0.0667, 0.0420, 0.0475, 0.0466, 0.0260, 0.1418, 0.0203, 0.0316,
        0.0584, 0.0531, 0.0449, 0.0368, 0.1168], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:19,579][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.0030, 0.8124, 0.0478, 0.0115, 0.0033, 0.0251, 0.0015, 0.0342, 0.0036,
        0.0446, 0.0017, 0.0014, 0.0043, 0.0057], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:19,581][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.0858, 0.1460, 0.0299, 0.0588, 0.0354, 0.0264, 0.0852, 0.0331, 0.0479,
        0.1163, 0.0799, 0.0292, 0.0308, 0.1954], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:19,583][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.2430, 0.0192, 0.0552, 0.0574, 0.0725, 0.0344, 0.1651, 0.0346, 0.0416,
        0.0486, 0.0455, 0.0585, 0.0476, 0.0767], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:19,585][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ said] are: tensor([0.6111, 0.0044, 0.0068, 0.0103, 0.0093, 0.0079, 0.2312, 0.0063, 0.0152,
        0.0193, 0.0259, 0.0150, 0.0103, 0.0271], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:19,586][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.0641, 0.0445, 0.0558, 0.0938, 0.0572, 0.0529, 0.0717, 0.0495, 0.0629,
        0.0949, 0.0834, 0.0516, 0.0634, 0.1542], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:19,588][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ said] are: tensor([0.0055, 0.0726, 0.0558, 0.1016, 0.0702, 0.0487, 0.0127, 0.0677, 0.0524,
        0.0983, 0.1038, 0.0687, 0.0962, 0.1458], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:19,590][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0873, 0.0723, 0.0801, 0.0652, 0.0967, 0.0985, 0.0120, 0.0566, 0.0621,
        0.0557, 0.0530, 0.0485, 0.0819, 0.0693, 0.0607], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:19,590][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ to] are: tensor([2.9378e-07, 9.5166e-03, 2.5313e-02, 1.1355e-01, 8.2249e-02, 2.4530e-02,
        1.4702e-01, 4.7309e-02, 3.1337e-02, 5.6478e-02, 1.1403e-01, 1.0441e-01,
        6.2987e-02, 6.5143e-02, 1.1612e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:19,591][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.5195, 0.0559, 0.0156, 0.0292, 0.0100, 0.0084, 0.1823, 0.0026, 0.0149,
        0.0264, 0.0136, 0.0093, 0.0260, 0.0748, 0.0115], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:19,592][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ to] are: tensor([9.9291e-01, 2.6420e-04, 5.9864e-04, 2.1481e-04, 2.7031e-04, 1.6189e-04,
        2.0798e-04, 9.6137e-04, 6.8368e-04, 3.9621e-04, 5.3609e-04, 4.2198e-04,
        1.6340e-03, 2.4124e-04, 4.9691e-04], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:19,594][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0073, 0.0756, 0.0309, 0.1340, 0.0424, 0.0458, 0.0126, 0.0394, 0.0509,
        0.0922, 0.0866, 0.0230, 0.0279, 0.2051, 0.1261], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:19,596][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.3162, 0.0548, 0.0355, 0.0394, 0.0459, 0.0207, 0.1496, 0.0129, 0.0233,
        0.0419, 0.0401, 0.0306, 0.0279, 0.1050, 0.0560], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:19,597][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0050, 0.6457, 0.0965, 0.0315, 0.0087, 0.0370, 0.0036, 0.0408, 0.0065,
        0.0646, 0.0078, 0.0084, 0.0296, 0.0084, 0.0060], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:19,599][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0968, 0.1171, 0.0234, 0.0385, 0.0320, 0.0176, 0.0856, 0.0199, 0.0414,
        0.0785, 0.0559, 0.0230, 0.0277, 0.1540, 0.1886], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:19,601][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.2867, 0.0169, 0.0519, 0.0427, 0.0667, 0.0233, 0.1714, 0.0225, 0.0341,
        0.0399, 0.0351, 0.0489, 0.0400, 0.0707, 0.0492], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:19,602][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.5433, 0.0056, 0.0079, 0.0141, 0.0101, 0.0098, 0.2344, 0.0076, 0.0184,
        0.0251, 0.0333, 0.0177, 0.0119, 0.0351, 0.0257], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:19,604][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0623, 0.0451, 0.0477, 0.0785, 0.0490, 0.0412, 0.0666, 0.0354, 0.0586,
        0.0874, 0.0757, 0.0456, 0.0588, 0.1352, 0.1130], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:19,606][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0072, 0.0580, 0.0456, 0.0781, 0.0632, 0.0445, 0.0153, 0.0515, 0.0477,
        0.0814, 0.0803, 0.0649, 0.0703, 0.1352, 0.1571], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:19,703][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:31:19,704][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:19,706][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:19,707][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:19,709][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:19,710][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:19,712][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:19,713][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:19,715][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:19,716][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:19,717][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:19,718][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:19,718][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:19,719][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.8420, 0.1580], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:19,720][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0141, 0.9859], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:19,721][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.9605, 0.0395], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:19,722][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.5021, 0.4979], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:19,723][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.1812, 0.8188], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:19,724][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.9630, 0.0370], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:19,726][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.8189, 0.1811], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:19,727][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.5696, 0.4304], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:19,728][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.9834, 0.0166], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:19,729][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.9488, 0.0512], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:19,730][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.5784, 0.4216], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:19,730][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.1773, 0.8227], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:19,731][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Melissa] are: tensor([0.8264, 0.0977, 0.0759], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:19,733][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Melissa] are: tensor([0.0027, 0.5325, 0.4648], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:19,734][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Melissa] are: tensor([0.7311, 0.0949, 0.1741], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:19,736][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Melissa] are: tensor([0.3062, 0.3290, 0.3648], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:19,737][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Melissa] are: tensor([0.0619, 0.6756, 0.2625], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:19,739][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Melissa] are: tensor([0.8868, 0.0719, 0.0413], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:19,740][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Melissa] are: tensor([0.5733, 0.2314, 0.1953], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:19,742][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Melissa] are: tensor([0.2434, 0.6241, 0.1325], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:19,744][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Melissa] are: tensor([0.8703, 0.0297, 0.1000], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:19,745][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Melissa] are: tensor([0.7516, 0.0995, 0.1489], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:19,747][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Melissa] are: tensor([0.4636, 0.2247, 0.3117], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:19,748][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Melissa] are: tensor([0.0817, 0.5086, 0.4097], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:19,750][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.7480, 0.0630, 0.0477, 0.1413], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:19,752][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0011, 0.2479, 0.3477, 0.4033], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:19,753][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.7527, 0.0602, 0.0956, 0.0915], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:19,755][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.1679, 0.2091, 0.2574, 0.3656], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:19,755][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0395, 0.3476, 0.1282, 0.4847], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:19,756][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.8586, 0.0643, 0.0363, 0.0407], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:19,757][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.3623, 0.2295, 0.1540, 0.2542], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:19,758][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.3057, 0.4500, 0.0997, 0.1445], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:19,759][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.8152, 0.0332, 0.0781, 0.0734], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:19,761][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.7323, 0.0582, 0.0837, 0.1258], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:19,762][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.3538, 0.1650, 0.1800, 0.3013], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:19,764][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0604, 0.3468, 0.2338, 0.3590], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:19,766][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Benjamin] are: tensor([0.6086, 0.0855, 0.0635, 0.1669, 0.0755], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:19,767][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Benjamin] are: tensor([0.0006, 0.2537, 0.2248, 0.3673, 0.1537], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:19,769][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Benjamin] are: tensor([0.4056, 0.0713, 0.1571, 0.1663, 0.1997], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:19,771][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Benjamin] are: tensor([0.1126, 0.2159, 0.1473, 0.2487, 0.2755], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:19,772][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Benjamin] are: tensor([0.0089, 0.2425, 0.1199, 0.4883, 0.1403], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:19,774][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Benjamin] are: tensor([0.5487, 0.1422, 0.0758, 0.1095, 0.1237], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:19,775][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Benjamin] are: tensor([0.2302, 0.2102, 0.1432, 0.1878, 0.2285], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:19,777][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Benjamin] are: tensor([0.0497, 0.4435, 0.1258, 0.2554, 0.1256], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:19,779][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Benjamin] are: tensor([0.6193, 0.0367, 0.1103, 0.0899, 0.1439], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:19,780][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Benjamin] are: tensor([0.4898, 0.0734, 0.1114, 0.1620, 0.1634], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:19,781][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Benjamin] are: tensor([0.1962, 0.1516, 0.1696, 0.2795, 0.2031], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:19,782][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Benjamin] are: tensor([0.0245, 0.2608, 0.1455, 0.3323, 0.2369], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:19,783][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.6520, 0.0702, 0.0455, 0.1403, 0.0553, 0.0367], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:19,783][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.0013, 0.1478, 0.1985, 0.2671, 0.1847, 0.2006], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:19,785][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.3943, 0.0698, 0.1404, 0.1239, 0.1606, 0.1110], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:19,786][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.0774, 0.1372, 0.1501, 0.2203, 0.2577, 0.1574], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:19,788][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.0160, 0.2348, 0.0894, 0.4060, 0.1143, 0.1395], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:19,789][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.7083, 0.0789, 0.0488, 0.0584, 0.0749, 0.0307], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:19,791][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.3935, 0.1627, 0.0929, 0.1149, 0.1873, 0.0486], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:19,792][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.1703, 0.4184, 0.0745, 0.1605, 0.1156, 0.0608], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:19,794][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.6666, 0.0259, 0.0726, 0.0717, 0.1184, 0.0448], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:19,796][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.6490, 0.0365, 0.0658, 0.0837, 0.1135, 0.0515], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:19,797][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.2365, 0.0999, 0.1401, 0.2184, 0.1685, 0.1367], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:19,799][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.0187, 0.1755, 0.1690, 0.2630, 0.2206, 0.1532], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:19,801][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.1453, 0.0877, 0.0626, 0.1638, 0.0719, 0.0610, 0.4077],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:19,802][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([3.1420e-05, 2.3072e-01, 2.4844e-01, 1.9058e-01, 8.3791e-02, 2.4621e-01,
        2.2936e-04], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:19,804][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0573, 0.1307, 0.1690, 0.1692, 0.1993, 0.1941, 0.0803],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:19,805][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0076, 0.2222, 0.1669, 0.2292, 0.1594, 0.1959, 0.0189],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:19,807][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0021, 0.1475, 0.1149, 0.3214, 0.1422, 0.2647, 0.0073],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:19,808][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0924, 0.1564, 0.1123, 0.1658, 0.1964, 0.1660, 0.1107],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:19,809][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0072, 0.2297, 0.1709, 0.1985, 0.1506, 0.2247, 0.0184],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:19,810][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0109, 0.2281, 0.1135, 0.2558, 0.1719, 0.1924, 0.0274],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:19,810][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.1200, 0.1284, 0.1319, 0.1419, 0.1986, 0.1363, 0.1428],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:19,812][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0532, 0.1707, 0.1413, 0.2130, 0.1693, 0.1800, 0.0726],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:19,813][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0154, 0.1579, 0.1589, 0.2525, 0.1674, 0.2124, 0.0355],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:19,815][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0042, 0.2342, 0.1380, 0.2181, 0.1798, 0.2117, 0.0140],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:19,817][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.2621, 0.0279, 0.0171, 0.0436, 0.0179, 0.0135, 0.4413, 0.1765],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:19,818][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([0.0012, 0.1175, 0.1325, 0.1929, 0.1382, 0.1478, 0.0053, 0.2645],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:19,820][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([0.3137, 0.0402, 0.0803, 0.0763, 0.0972, 0.0647, 0.2534, 0.0743],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:19,822][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([0.0594, 0.1114, 0.1319, 0.1501, 0.1671, 0.1294, 0.0929, 0.1577],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:19,823][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.0090, 0.1597, 0.0704, 0.3818, 0.1051, 0.1464, 0.0210, 0.1066],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:19,825][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([0.4747, 0.0753, 0.0343, 0.0520, 0.0502, 0.0325, 0.2628, 0.0184],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:19,827][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.3113, 0.1141, 0.0446, 0.0697, 0.0963, 0.0472, 0.2849, 0.0317],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:19,829][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.1002, 0.4087, 0.0451, 0.1328, 0.0612, 0.0588, 0.1393, 0.0540],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:19,830][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.4360, 0.0250, 0.0481, 0.0637, 0.0815, 0.0327, 0.2796, 0.0332],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:19,832][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([0.4582, 0.0311, 0.0469, 0.0658, 0.0734, 0.0384, 0.2535, 0.0327],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:19,834][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.1450, 0.0887, 0.1043, 0.1752, 0.1171, 0.1127, 0.1665, 0.0905],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:19,835][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([0.0159, 0.1589, 0.1233, 0.1953, 0.1545, 0.1421, 0.0393, 0.1707],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:19,835][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.2061, 0.0345, 0.0234, 0.0652, 0.0237, 0.0179, 0.3716, 0.1935, 0.0642],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:19,836][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([2.7649e-04, 1.1194e-01, 1.1530e-01, 1.5494e-01, 9.6229e-02, 1.2733e-01,
        1.5200e-03, 2.9431e-01, 9.8151e-02], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:19,837][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([0.1960, 0.0439, 0.0929, 0.0917, 0.1227, 0.0790, 0.1776, 0.0883, 0.1078],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:19,839][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([0.0299, 0.1145, 0.1051, 0.1638, 0.1416, 0.1378, 0.0537, 0.1116, 0.1419],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:19,840][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.0062, 0.1737, 0.0597, 0.3057, 0.0795, 0.1300, 0.0160, 0.1159, 0.1134],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:19,842][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([0.3640, 0.0835, 0.0494, 0.0696, 0.0721, 0.0443, 0.2320, 0.0327, 0.0523],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:19,843][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.1092, 0.1549, 0.0792, 0.1174, 0.1420, 0.0805, 0.1341, 0.0709, 0.1117],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:19,845][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.0624, 0.2931, 0.0512, 0.1330, 0.0705, 0.0699, 0.0978, 0.0844, 0.1376],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:19,847][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([0.3246, 0.0370, 0.0789, 0.0761, 0.1135, 0.0454, 0.2283, 0.0426, 0.0536],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:19,848][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([0.3458, 0.0393, 0.0609, 0.0836, 0.0884, 0.0541, 0.2130, 0.0378, 0.0770],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:19,850][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.0815, 0.0875, 0.1003, 0.1672, 0.1062, 0.1106, 0.1096, 0.0939, 0.1432],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:19,852][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([0.0085, 0.1363, 0.1047, 0.1926, 0.1321, 0.1227, 0.0242, 0.1537, 0.1252],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:19,854][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.1797, 0.0373, 0.0263, 0.0748, 0.0270, 0.0179, 0.3175, 0.1421, 0.0596,
        0.1178], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:19,855][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([1.3078e-04, 8.6046e-02, 1.2779e-01, 1.6171e-01, 7.7783e-02, 1.1899e-01,
        7.8134e-04, 2.3003e-01, 6.7228e-02, 1.2951e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:19,857][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.2398, 0.0466, 0.0737, 0.0744, 0.0971, 0.0615, 0.1947, 0.0701, 0.0792,
        0.0629], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:19,858][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0170, 0.0949, 0.1019, 0.1443, 0.1327, 0.1189, 0.0336, 0.1151, 0.1191,
        0.1224], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:19,860][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0120, 0.1556, 0.0570, 0.2407, 0.0728, 0.0949, 0.0211, 0.0785, 0.0926,
        0.1747], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:19,861][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.4811, 0.0595, 0.0380, 0.0416, 0.0525, 0.0220, 0.2229, 0.0130, 0.0260,
        0.0434], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:19,862][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0898, 0.1384, 0.0714, 0.1119, 0.1415, 0.0825, 0.1092, 0.0587, 0.0805,
        0.1161], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:19,863][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.1203, 0.2431, 0.0463, 0.0841, 0.0631, 0.0404, 0.1204, 0.0461, 0.0836,
        0.1526], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:19,864][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.2844, 0.0310, 0.0812, 0.0789, 0.1053, 0.0471, 0.1948, 0.0515, 0.0582,
        0.0677], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:19,865][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.2902, 0.0375, 0.0621, 0.0863, 0.0908, 0.0498, 0.1769, 0.0397, 0.0712,
        0.0957], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:19,867][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0694, 0.0849, 0.0882, 0.1506, 0.0898, 0.0901, 0.0857, 0.0770, 0.1047,
        0.1596], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:19,869][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0103, 0.1362, 0.0932, 0.1506, 0.1285, 0.0910, 0.0237, 0.1173, 0.0961,
        0.1532], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:19,870][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.1912, 0.0263, 0.0161, 0.0490, 0.0191, 0.0130, 0.3097, 0.1173, 0.0453,
        0.0883, 0.1248], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:19,871][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([1.3666e-04, 8.6554e-02, 1.2196e-01, 1.3501e-01, 6.8145e-02, 1.0956e-01,
        7.5382e-04, 1.9883e-01, 6.1334e-02, 1.2138e-01, 9.6344e-02],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:19,873][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.2476, 0.0370, 0.0659, 0.0602, 0.0837, 0.0587, 0.1966, 0.0664, 0.0804,
        0.0550, 0.0484], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:19,875][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0236, 0.0825, 0.0936, 0.1229, 0.1136, 0.1061, 0.0419, 0.1005, 0.1146,
        0.1097, 0.0909], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:19,876][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0117, 0.1168, 0.0513, 0.1958, 0.0680, 0.0889, 0.0209, 0.0715, 0.0825,
        0.1486, 0.1440], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:19,878][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.4340, 0.0630, 0.0351, 0.0403, 0.0558, 0.0247, 0.2084, 0.0144, 0.0286,
        0.0491, 0.0467], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:19,880][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.1039, 0.1240, 0.0608, 0.1002, 0.1088, 0.0666, 0.1160, 0.0448, 0.0704,
        0.1061, 0.0985], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:19,882][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.1245, 0.1842, 0.0436, 0.0766, 0.0660, 0.0357, 0.1166, 0.0433, 0.0709,
        0.1360, 0.1026], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:19,883][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.3020, 0.0278, 0.0693, 0.0682, 0.0951, 0.0384, 0.1951, 0.0423, 0.0499,
        0.0589, 0.0531], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:19,885][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.3178, 0.0313, 0.0464, 0.0642, 0.0712, 0.0407, 0.1807, 0.0304, 0.0611,
        0.0748, 0.0813], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:19,887][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0817, 0.0672, 0.0709, 0.1186, 0.0747, 0.0714, 0.0936, 0.0623, 0.0949,
        0.1391, 0.1256], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:19,888][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0136, 0.1082, 0.0693, 0.1242, 0.0998, 0.0795, 0.0286, 0.1081, 0.0882,
        0.1434, 0.1371], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:19,889][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.1125, 0.0218, 0.0197, 0.0477, 0.0225, 0.0161, 0.2196, 0.1590, 0.0535,
        0.0890, 0.1230, 0.1155], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:19,889][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([1.1842e-04, 9.6656e-02, 1.0977e-01, 1.4524e-01, 6.1811e-02, 1.3540e-01,
        6.7362e-04, 1.8439e-01, 5.6893e-02, 1.0482e-01, 7.9692e-02, 2.4533e-02],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:19,891][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([0.0820, 0.0322, 0.0910, 0.0880, 0.1041, 0.0927, 0.0938, 0.0868, 0.0870,
        0.0585, 0.0632, 0.1207], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:19,892][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([0.0128, 0.0807, 0.0939, 0.1206, 0.0938, 0.0986, 0.0266, 0.1009, 0.1078,
        0.0987, 0.0888, 0.0767], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:19,894][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.0016, 0.0930, 0.0445, 0.2100, 0.0643, 0.1243, 0.0051, 0.0791, 0.0813,
        0.1336, 0.1285, 0.0347], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:19,895][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([0.1447, 0.0969, 0.0648, 0.1019, 0.0809, 0.0570, 0.1108, 0.0369, 0.0545,
        0.0984, 0.0966, 0.0567], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:19,897][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.0517, 0.1263, 0.0762, 0.1021, 0.1236, 0.0791, 0.0739, 0.0454, 0.0698,
        0.0941, 0.0862, 0.0715], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:19,899][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.0191, 0.2094, 0.0465, 0.1176, 0.0570, 0.0602, 0.0326, 0.0589, 0.0844,
        0.1533, 0.1217, 0.0394], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:19,901][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.1369, 0.0441, 0.0934, 0.1019, 0.1155, 0.0558, 0.1260, 0.0559, 0.0625,
        0.0743, 0.0746, 0.0591], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:19,902][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([0.1853, 0.0396, 0.0633, 0.0870, 0.0674, 0.0503, 0.1397, 0.0439, 0.0713,
        0.0928, 0.0956, 0.0638], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:19,904][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([0.0342, 0.0688, 0.0768, 0.1357, 0.0718, 0.0805, 0.0508, 0.0680, 0.0936,
        0.1351, 0.1183, 0.0664], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:19,906][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([0.0059, 0.1017, 0.0633, 0.1205, 0.0827, 0.0782, 0.0152, 0.1103, 0.0856,
        0.1224, 0.1289, 0.0853], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:19,907][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Melissa] are: tensor([0.1444, 0.0228, 0.0142, 0.0428, 0.0140, 0.0102, 0.2489, 0.1076, 0.0422,
        0.0778, 0.1031, 0.1017, 0.0703], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:19,909][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Melissa] are: tensor([9.7291e-05, 9.3625e-02, 1.1160e-01, 1.3508e-01, 6.5717e-02, 9.1689e-02,
        5.4395e-04, 1.7271e-01, 5.5944e-02, 1.1093e-01, 8.0062e-02, 2.4430e-02,
        5.7570e-02], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:19,910][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Melissa] are: tensor([0.1240, 0.0337, 0.0731, 0.0712, 0.0836, 0.0584, 0.1259, 0.0633, 0.0800,
        0.0614, 0.0531, 0.1108, 0.0615], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:19,912][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Melissa] are: tensor([0.0200, 0.0707, 0.0755, 0.1040, 0.0864, 0.0987, 0.0359, 0.0951, 0.1108,
        0.1060, 0.0794, 0.0653, 0.0523], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:19,913][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Melissa] are: tensor([0.0043, 0.0943, 0.0468, 0.1954, 0.0717, 0.0924, 0.0095, 0.0765, 0.0748,
        0.1336, 0.1199, 0.0402, 0.0405], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:19,914][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Melissa] are: tensor([0.2835, 0.0703, 0.0441, 0.0573, 0.0768, 0.0294, 0.1674, 0.0207, 0.0375,
        0.0621, 0.0572, 0.0523, 0.0414], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:19,915][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Melissa] are: tensor([0.0794, 0.1104, 0.0567, 0.0879, 0.0906, 0.0555, 0.0921, 0.0487, 0.0662,
        0.0903, 0.0764, 0.0712, 0.0746], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:19,916][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Melissa] are: tensor([0.0338, 0.1726, 0.0445, 0.1020, 0.0690, 0.0444, 0.0481, 0.0564, 0.0880,
        0.1396, 0.1067, 0.0477, 0.0473], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:19,918][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Melissa] are: tensor([0.2140, 0.0238, 0.0673, 0.0752, 0.0773, 0.0438, 0.1591, 0.0429, 0.0549,
        0.0631, 0.0545, 0.0724, 0.0517], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:19,919][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Melissa] are: tensor([0.1516, 0.0365, 0.0592, 0.0835, 0.0736, 0.0476, 0.1151, 0.0419, 0.0638,
        0.0979, 0.0974, 0.0657, 0.0661], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:19,921][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Melissa] are: tensor([0.0498, 0.0561, 0.0715, 0.1185, 0.0703, 0.0686, 0.0651, 0.0555, 0.0924,
        0.1146, 0.1001, 0.0592, 0.0784], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:19,923][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Melissa] are: tensor([0.0077, 0.0830, 0.0575, 0.1100, 0.0847, 0.0601, 0.0192, 0.0862, 0.0695,
        0.1107, 0.1155, 0.0916, 0.1043], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:19,924][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.1459, 0.0196, 0.0115, 0.0389, 0.0137, 0.0082, 0.2559, 0.0924, 0.0342,
        0.0689, 0.0970, 0.1084, 0.0588, 0.0466], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:19,926][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([1.0388e-04, 7.8239e-02, 8.9294e-02, 1.2786e-01, 5.7246e-02, 8.9577e-02,
        6.7818e-04, 1.5473e-01, 4.1603e-02, 1.0516e-01, 7.6799e-02, 3.1851e-02,
        4.3590e-02, 1.0327e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:19,928][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([0.1329, 0.0328, 0.0629, 0.0587, 0.0749, 0.0530, 0.1209, 0.0596, 0.0631,
        0.0511, 0.0448, 0.1004, 0.0519, 0.0931], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:19,929][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([0.0158, 0.0607, 0.0651, 0.1176, 0.0826, 0.0778, 0.0293, 0.0765, 0.0869,
        0.0915, 0.0785, 0.0561, 0.0428, 0.1190], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:19,931][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([0.0058, 0.0792, 0.0350, 0.1557, 0.0375, 0.0577, 0.0113, 0.0553, 0.0605,
        0.1141, 0.1033, 0.0253, 0.0301, 0.2292], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:19,933][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([0.3690, 0.0507, 0.0322, 0.0344, 0.0397, 0.0180, 0.1689, 0.0128, 0.0238,
        0.0465, 0.0435, 0.0363, 0.0312, 0.0930], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:19,935][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([0.0829, 0.1004, 0.0478, 0.0855, 0.0894, 0.0470, 0.0942, 0.0382, 0.0506,
        0.0809, 0.0683, 0.0652, 0.0559, 0.0937], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:19,936][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.0858, 0.1460, 0.0299, 0.0588, 0.0354, 0.0264, 0.0852, 0.0331, 0.0479,
        0.1163, 0.0799, 0.0292, 0.0308, 0.1954], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:19,938][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([0.2430, 0.0192, 0.0552, 0.0574, 0.0725, 0.0344, 0.1651, 0.0346, 0.0416,
        0.0486, 0.0455, 0.0585, 0.0476, 0.0767], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:19,940][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([0.3097, 0.0185, 0.0350, 0.0454, 0.0531, 0.0297, 0.1649, 0.0220, 0.0451,
        0.0562, 0.0616, 0.0437, 0.0410, 0.0743], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:19,941][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([0.0641, 0.0445, 0.0558, 0.0938, 0.0572, 0.0529, 0.0717, 0.0495, 0.0629,
        0.0949, 0.0834, 0.0516, 0.0634, 0.1542], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:19,942][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([0.0055, 0.0726, 0.0558, 0.1016, 0.0702, 0.0487, 0.0127, 0.0677, 0.0524,
        0.0983, 0.1038, 0.0687, 0.0962, 0.1458], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:19,943][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.1494, 0.0168, 0.0106, 0.0318, 0.0112, 0.0074, 0.2389, 0.0776, 0.0296,
        0.0569, 0.0848, 0.0866, 0.0554, 0.0399, 0.1033], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:19,944][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0001, 0.0563, 0.0782, 0.1124, 0.0581, 0.0704, 0.0008, 0.1319, 0.0418,
        0.0803, 0.0654, 0.0300, 0.0413, 0.0980, 0.1351], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:19,946][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1469, 0.0298, 0.0572, 0.0532, 0.0682, 0.0449, 0.1278, 0.0524, 0.0640,
        0.0448, 0.0381, 0.0914, 0.0438, 0.0927, 0.0446], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:19,948][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0165, 0.0615, 0.0624, 0.0914, 0.0825, 0.0687, 0.0281, 0.0647, 0.0730,
        0.0799, 0.0665, 0.0540, 0.0450, 0.1051, 0.1007], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:19,950][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0073, 0.0756, 0.0309, 0.1340, 0.0424, 0.0458, 0.0126, 0.0394, 0.0509,
        0.0922, 0.0866, 0.0230, 0.0279, 0.2051, 0.1261], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:19,951][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.4270, 0.0399, 0.0259, 0.0267, 0.0373, 0.0134, 0.1740, 0.0077, 0.0166,
        0.0317, 0.0315, 0.0237, 0.0229, 0.0805, 0.0411], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:19,953][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.1013, 0.0779, 0.0373, 0.0676, 0.0773, 0.0394, 0.1079, 0.0234, 0.0461,
        0.0660, 0.0583, 0.0497, 0.0531, 0.0960, 0.0987], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:19,955][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0968, 0.1171, 0.0234, 0.0385, 0.0320, 0.0176, 0.0856, 0.0199, 0.0414,
        0.0785, 0.0559, 0.0230, 0.0277, 0.1540, 0.1886], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:19,957][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.2867, 0.0169, 0.0519, 0.0427, 0.0667, 0.0233, 0.1714, 0.0225, 0.0341,
        0.0399, 0.0351, 0.0489, 0.0400, 0.0707, 0.0492], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:19,958][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.2546, 0.0185, 0.0376, 0.0503, 0.0517, 0.0306, 0.1480, 0.0218, 0.0482,
        0.0577, 0.0628, 0.0445, 0.0440, 0.0783, 0.0514], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:19,960][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0623, 0.0451, 0.0477, 0.0785, 0.0490, 0.0412, 0.0666, 0.0354, 0.0586,
        0.0874, 0.0757, 0.0456, 0.0588, 0.1352, 0.1130], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:19,962][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0072, 0.0580, 0.0456, 0.0781, 0.0632, 0.0445, 0.0153, 0.0515, 0.0477,
        0.0814, 0.0803, 0.0649, 0.0703, 0.1352, 0.1571], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:19,965][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:31:19,967][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[4149],
        [  62],
        [   8],
        [   3],
        [ 724],
        [  30],
        [  56],
        [  37],
        [  47],
        [  13],
        [  11],
        [  24],
        [  41],
        [  24],
        [   9]], device='cuda:0')
[2024-07-24 10:31:19,968][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[4013],
        [ 278],
        [  50],
        [  42],
        [1082],
        [  68],
        [  69],
        [  91],
        [ 105],
        [  58],
        [  34],
        [  64],
        [  80],
        [  71],
        [  42]], device='cuda:0')
[2024-07-24 10:31:19,970][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[10430],
        [23607],
        [30348],
        [29957],
        [31527],
        [31283],
        [31044],
        [31712],
        [31848],
        [31716],
        [31731],
        [31957],
        [32352],
        [32339],
        [31980]], device='cuda:0')
[2024-07-24 10:31:19,971][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[27431],
        [13956],
        [23281],
        [14720],
        [30191],
        [31078],
        [33822],
        [31230],
        [25567],
        [26784],
        [22300],
        [21451],
        [23265],
        [21405],
        [22756]], device='cuda:0')
[2024-07-24 10:31:19,973][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[22126],
        [22248],
        [23225],
        [23664],
        [23155],
        [22456],
        [23603],
        [26814],
        [26387],
        [26317],
        [25687],
        [27362],
        [27551],
        [25311],
        [26167]], device='cuda:0')
[2024-07-24 10:31:19,974][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[14367],
        [14362],
        [14363],
        [14348],
        [14362],
        [14350],
        [14348],
        [14329],
        [14285],
        [14293],
        [14236],
        [14302],
        [14283],
        [14303],
        [14304]], device='cuda:0')
[2024-07-24 10:31:19,976][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[30738],
        [19765],
        [21587],
        [22582],
        [26046],
        [26701],
        [28981],
        [27667],
        [27938],
        [29263],
        [30208],
        [30430],
        [30979],
        [27436],
        [28015]], device='cuda:0')
[2024-07-24 10:31:19,978][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[ 6607],
        [ 6356],
        [ 9103],
        [10428],
        [18066],
        [14559],
        [20297],
        [12577],
        [15672],
        [13485],
        [14169],
        [16975],
        [16029],
        [14248],
        [13976]], device='cuda:0')
[2024-07-24 10:31:19,979][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[7970],
        [  63],
        [  51],
        [  72],
        [  52],
        [  50],
        [  53],
        [  66],
        [  67],
        [  85],
        [  74],
        [  62],
        [  59],
        [  60],
        [  61]], device='cuda:0')
[2024-07-24 10:31:19,981][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[28761],
        [40569],
        [42336],
        [41512],
        [41102],
        [40398],
        [37565],
        [40225],
        [38781],
        [39017],
        [38027],
        [37421],
        [36969],
        [35603],
        [36100]], device='cuda:0')
[2024-07-24 10:31:19,983][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[35424],
        [33581],
        [27214],
        [20803],
        [20962],
        [20103],
        [10243],
        [12913],
        [11357],
        [ 9955],
        [ 9211],
        [ 8855],
        [ 9013],
        [ 9160],
        [ 8513]], device='cuda:0')
[2024-07-24 10:31:19,984][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[39153],
        [39389],
        [39131],
        [39388],
        [38817],
        [38927],
        [31895],
        [42544],
        [41103],
        [40855],
        [41246],
        [39624],
        [39969],
        [41027],
        [40482]], device='cuda:0')
[2024-07-24 10:31:19,986][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[16031],
        [ 6484],
        [ 2596],
        [ 2048],
        [  603],
        [  725],
        [  860],
        [ 1114],
        [ 1416],
        [ 1506],
        [ 1680],
        [ 1699],
        [ 1692],
        [ 1294],
        [ 1209]], device='cuda:0')
[2024-07-24 10:31:19,988][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[15291],
        [25469],
        [13372],
        [24353],
        [48534],
        [47899],
        [46183],
        [46650],
        [46681],
        [46785],
        [46181],
        [45417],
        [43609],
        [41825],
        [43111]], device='cuda:0')
[2024-07-24 10:31:19,990][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[28748],
        [ 5883],
        [ 9913],
        [ 1088],
        [42334],
        [ 6006],
        [25978],
        [ 6063],
        [12854],
        [ 4330],
        [ 1037],
        [ 1485],
        [11624],
        [21753],
        [ 4380]], device='cuda:0')
[2024-07-24 10:31:19,991][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[24482],
        [ 8632],
        [ 5310],
        [ 6282],
        [ 4650],
        [ 4915],
        [ 5162],
        [ 4474],
        [ 4283],
        [ 4289],
        [ 4228],
        [ 4307],
        [ 4190],
        [ 4325],
        [ 4165]], device='cuda:0')
[2024-07-24 10:31:19,993][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[ 4919],
        [ 5238],
        [ 7587],
        [12723],
        [11767],
        [13584],
        [12768],
        [14499],
        [14125],
        [13953],
        [14574],
        [14845],
        [14132],
        [13574],
        [13244]], device='cuda:0')
[2024-07-24 10:31:19,995][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[27249],
        [19681],
        [ 8979],
        [ 6872],
        [ 6632],
        [ 7036],
        [ 6914],
        [ 7652],
        [ 7995],
        [ 7649],
        [ 7868],
        [ 7572],
        [ 8771],
        [ 7878],
        [ 7828]], device='cuda:0')
[2024-07-24 10:31:19,996][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[25365],
        [  481],
        [ 1083],
        [ 1024],
        [  691],
        [  801],
        [  793],
        [ 1006],
        [ 1111],
        [ 1073],
        [ 1126],
        [ 1125],
        [ 1206],
        [ 1185],
        [ 1183]], device='cuda:0')
[2024-07-24 10:31:19,998][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[29250],
        [43291],
        [42853],
        [34824],
        [33016],
        [31937],
        [30388],
        [30543],
        [31132],
        [29736],
        [26791],
        [26980],
        [27281],
        [18084],
        [19384]], device='cuda:0')
[2024-07-24 10:31:19,999][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[40104],
        [39808],
        [37205],
        [35882],
        [20453],
        [27605],
        [15223],
        [26849],
        [21363],
        [25324],
        [23246],
        [16243],
        [18144],
        [21676],
        [22974]], device='cuda:0')
[2024-07-24 10:31:20,001][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[7720],
        [2905],
        [5189],
        [7029],
        [6270],
        [5678],
        [7653],
        [4693],
        [5290],
        [4767],
        [4605],
        [5096],
        [4618],
        [4846],
        [4751]], device='cuda:0')
[2024-07-24 10:31:20,003][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[ 1880],
        [ 1323],
        [ 1345],
        [ 1925],
        [ 3965],
        [ 3787],
        [ 9371],
        [ 3927],
        [ 6749],
        [ 7222],
        [ 9460],
        [10441],
        [11628],
        [12442],
        [12834]], device='cuda:0')
[2024-07-24 10:31:20,004][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[ 8017],
        [ 7632],
        [ 7623],
        [ 7274],
        [ 6688],
        [ 6959],
        [ 8554],
        [ 9336],
        [ 9755],
        [10394],
        [10161],
        [ 8453],
        [ 8762],
        [10013],
        [10134]], device='cuda:0')
[2024-07-24 10:31:20,006][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[12568],
        [10917],
        [ 9095],
        [11251],
        [11266],
        [10784],
        [13355],
        [ 9433],
        [10229],
        [11608],
        [11101],
        [13797],
        [14275],
        [11786],
        [12145]], device='cuda:0')
[2024-07-24 10:31:20,008][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[ 1689],
        [21014],
        [15179],
        [16439],
        [22197],
        [21332],
        [23034],
        [20510],
        [23105],
        [22007],
        [19852],
        [20320],
        [20596],
        [19259],
        [19318]], device='cuda:0')
[2024-07-24 10:31:20,009][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[11437],
        [32155],
        [28369],
        [34521],
        [40743],
        [39614],
        [38866],
        [37447],
        [39627],
        [39853],
        [40525],
        [39458],
        [36602],
        [35533],
        [37594]], device='cuda:0')
[2024-07-24 10:31:20,011][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[39198],
        [39395],
        [43041],
        [42194],
        [45249],
        [43821],
        [44148],
        [44101],
        [43916],
        [43074],
        [43933],
        [44612],
        [44273],
        [45147],
        [44682]], device='cuda:0')
[2024-07-24 10:31:20,013][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[22619],
        [44665],
        [48012],
        [48747],
        [36066],
        [47934],
        [34757],
        [49117],
        [45937],
        [47681],
        [49264],
        [49274],
        [47796],
        [43622],
        [48789]], device='cuda:0')
[2024-07-24 10:31:20,015][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[15000],
        [15000],
        [15000],
        [15000],
        [15000],
        [15000],
        [15000],
        [15000],
        [15000],
        [15000],
        [15000],
        [15000],
        [15000],
        [15000],
        [15000]], device='cuda:0')
[2024-07-24 10:31:20,112][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:31:20,114][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:20,115][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:20,116][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:20,118][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:20,118][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:20,119][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:20,120][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:20,121][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:20,122][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:20,123][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:20,125][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:20,126][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:20,128][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.5899, 0.4101], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:20,129][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.1149, 0.8851], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:20,131][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.5101, 0.4899], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:20,132][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.9801, 0.0199], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:20,133][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0637, 0.9363], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:20,133][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.9037, 0.0963], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:20,134][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0115, 0.9885], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:20,136][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.6177, 0.3823], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:20,137][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.3912, 0.6088], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:20,139][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0469, 0.9531], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:20,140][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.4726, 0.5274], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:20,142][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0521, 0.9479], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:20,144][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Melissa] are: tensor([0.8257, 0.1394, 0.0349], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:20,145][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Melissa] are: tensor([0.0063, 0.2259, 0.7678], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:20,147][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Melissa] are: tensor([0.2960, 0.1108, 0.5932], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:20,148][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Melissa] are: tensor([0.7768, 0.2031, 0.0201], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:20,150][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Melissa] are: tensor([0.0123, 0.1604, 0.8273], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:20,151][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Melissa] are: tensor([0.6175, 0.1371, 0.2454], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:20,153][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Melissa] are: tensor([5.5415e-04, 2.1085e-01, 7.8860e-01], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:20,154][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Melissa] are: tensor([0.2383, 0.4135, 0.3481], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:20,156][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Melissa] are: tensor([0.1547, 0.6970, 0.1483], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:20,157][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Melissa] are: tensor([0.0047, 0.3017, 0.6936], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:20,158][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Melissa] are: tensor([0.1132, 0.6195, 0.2673], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:20,159][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Melissa] are: tensor([0.0078, 0.2776, 0.7146], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:20,160][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.6163, 0.1653, 0.0697, 0.1487], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:20,160][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0041, 0.1571, 0.5568, 0.2820], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:20,162][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.1124, 0.1121, 0.4091, 0.3663], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:20,163][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.5675, 0.3231, 0.0629, 0.0465], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:20,165][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0129, 0.1101, 0.3713, 0.5057], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:20,167][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.5674, 0.1134, 0.1233, 0.1958], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:20,168][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0009, 0.1505, 0.5695, 0.2791], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:20,170][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.1251, 0.2210, 0.2324, 0.4215], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:20,171][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.1538, 0.3846, 0.1495, 0.3121], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:20,173][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0075, 0.1555, 0.4738, 0.3633], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:20,174][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0586, 0.3768, 0.2325, 0.3321], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:20,176][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0056, 0.1439, 0.4160, 0.4345], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:20,178][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Benjamin] are: tensor([0.4474, 0.2482, 0.0587, 0.1353, 0.1103], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:20,179][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Benjamin] are: tensor([0.0018, 0.0916, 0.3473, 0.1673, 0.3920], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:20,181][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Benjamin] are: tensor([0.0973, 0.0815, 0.3102, 0.2767, 0.2342], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:20,183][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Benjamin] are: tensor([0.1984, 0.5545, 0.1014, 0.1293, 0.0164], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:20,184][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Benjamin] are: tensor([0.0038, 0.0820, 0.4012, 0.4293, 0.0838], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:20,185][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Benjamin] are: tensor([0.4860, 0.1315, 0.1354, 0.1582, 0.0889], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:20,185][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Benjamin] are: tensor([3.0291e-04, 9.5816e-02, 5.7092e-01, 2.1574e-01, 1.1723e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:20,186][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Benjamin] are: tensor([0.0693, 0.1808, 0.1901, 0.4427, 0.1170], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:20,187][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Benjamin] are: tensor([0.0332, 0.3647, 0.1195, 0.2569, 0.2258], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:20,188][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Benjamin] are: tensor([0.0009, 0.0871, 0.4241, 0.2338, 0.2540], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:20,190][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Benjamin] are: tensor([0.0113, 0.3865, 0.1981, 0.3634, 0.0408], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:20,192][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Benjamin] are: tensor([0.0024, 0.0910, 0.3687, 0.2641, 0.2737], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:20,193][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.3700, 0.1635, 0.0819, 0.1728, 0.0876, 0.1242], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:20,195][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.0014, 0.0440, 0.2459, 0.1306, 0.3240, 0.2541], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:20,196][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.0653, 0.0296, 0.3037, 0.2480, 0.1618, 0.1916], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:20,198][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.7089, 0.2152, 0.0263, 0.0318, 0.0054, 0.0124], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:20,200][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.0101, 0.0724, 0.2878, 0.3648, 0.0711, 0.1939], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:20,201][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.3954, 0.0525, 0.0577, 0.0973, 0.0571, 0.3400], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:20,203][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ had] are: tensor([2.9755e-04, 7.4193e-02, 3.8079e-01, 1.8357e-01, 1.1466e-01, 2.4649e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:20,204][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.0552, 0.1339, 0.2049, 0.3137, 0.0945, 0.1977], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:20,206][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.0430, 0.2117, 0.1078, 0.2715, 0.2068, 0.1592], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:20,208][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.0006, 0.0454, 0.1267, 0.1109, 0.2245, 0.4920], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:20,209][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.0577, 0.4335, 0.1000, 0.2165, 0.0289, 0.1634], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:20,210][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0013, 0.0394, 0.1710, 0.1551, 0.1638, 0.4694], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:20,211][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0293, 0.3489, 0.1293, 0.1707, 0.1496, 0.1372, 0.0350],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:20,212][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ a] are: tensor([6.9138e-05, 7.6245e-02, 4.1332e-01, 7.2989e-02, 1.0223e-01, 3.3491e-01,
        2.4537e-04], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:20,212][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0234, 0.1753, 0.2002, 0.1579, 0.1973, 0.2105, 0.0355],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:20,214][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.2332, 0.1413, 0.0715, 0.1283, 0.0733, 0.0968, 0.2555],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:20,215][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ a] are: tensor([2.8446e-04, 1.2463e-01, 3.5192e-01, 2.1639e-01, 7.7354e-02, 2.2837e-01,
        1.0553e-03], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:20,216][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0639, 0.1058, 0.0991, 0.1349, 0.0754, 0.4301, 0.0909],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:20,217][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ a] are: tensor([4.9986e-06, 6.1333e-02, 4.0106e-01, 9.8881e-02, 5.9224e-02, 3.7946e-01,
        3.7399e-05], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:20,219][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0064, 0.1261, 0.1945, 0.1893, 0.1259, 0.3432, 0.0146],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:20,221][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0165, 0.2283, 0.1457, 0.1905, 0.2370, 0.1588, 0.0233],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:20,222][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ a] are: tensor([6.7035e-06, 5.8922e-02, 3.2902e-01, 4.3842e-02, 6.0169e-02, 5.0800e-01,
        3.6131e-05], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:20,223][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0061, 0.2665, 0.0866, 0.2441, 0.0807, 0.3020, 0.0141],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:20,225][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ a] are: tensor([7.4044e-05, 5.9503e-02, 3.2179e-01, 8.0174e-02, 1.0292e-01, 4.3527e-01,
        2.7508e-04], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:20,226][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.1265, 0.1891, 0.0788, 0.2024, 0.0756, 0.1314, 0.1223, 0.0740],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:20,228][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ long] are: tensor([0.0015, 0.0527, 0.2762, 0.1326, 0.2492, 0.2126, 0.0034, 0.0718],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:20,230][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.0606, 0.0367, 0.1801, 0.2169, 0.1305, 0.1510, 0.0720, 0.1521],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:20,231][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ long] are: tensor([0.3408, 0.2470, 0.0223, 0.0465, 0.0069, 0.0291, 0.2968, 0.0106],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:20,233][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.0047, 0.0443, 0.2441, 0.3016, 0.0340, 0.2116, 0.0094, 0.1503],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:20,235][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ long] are: tensor([0.2229, 0.0532, 0.0586, 0.0956, 0.0454, 0.2167, 0.2312, 0.0763],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:20,236][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ long] are: tensor([8.7225e-05, 6.2754e-02, 2.4105e-01, 1.5727e-01, 7.0715e-02, 1.7800e-01,
        4.7382e-04, 2.8965e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:20,237][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.0290, 0.1110, 0.1101, 0.2699, 0.0634, 0.1778, 0.0556, 0.1833],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:20,238][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.0474, 0.2142, 0.0706, 0.2652, 0.2119, 0.0993, 0.0448, 0.0467],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:20,238][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ long] are: tensor([1.2585e-04, 2.2034e-02, 6.5456e-02, 5.7448e-02, 7.7819e-02, 2.2394e-01,
        6.0038e-04, 5.5258e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:20,239][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.0076, 0.3093, 0.1050, 0.3120, 0.0201, 0.1839, 0.0219, 0.0401],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:20,241][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ long] are: tensor([0.0013, 0.0334, 0.1206, 0.0785, 0.0942, 0.2880, 0.0033, 0.3808],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:20,242][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.1381, 0.1497, 0.0525, 0.1291, 0.0608, 0.0933, 0.1194, 0.0744, 0.1827],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:20,244][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([0.0010, 0.0642, 0.2464, 0.1071, 0.1774, 0.2709, 0.0025, 0.0791, 0.0515],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:20,246][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.0310, 0.0282, 0.1616, 0.1761, 0.0734, 0.1267, 0.0422, 0.1698, 0.1911],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:20,247][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([0.2746, 0.2587, 0.0317, 0.0579, 0.0090, 0.0362, 0.2605, 0.0255, 0.0460],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:20,249][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.0021, 0.0797, 0.2005, 0.2906, 0.0344, 0.1527, 0.0046, 0.0788, 0.1567],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:20,251][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([0.1867, 0.0476, 0.0517, 0.0763, 0.0414, 0.1619, 0.1999, 0.0618, 0.1728],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:20,252][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([5.2239e-05, 5.1185e-02, 2.7682e-01, 1.1546e-01, 5.3040e-02, 1.5434e-01,
        2.7610e-04, 2.4589e-01, 1.0294e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:20,254][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.0128, 0.1143, 0.0904, 0.2498, 0.0526, 0.1784, 0.0252, 0.1628, 0.1138],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:20,256][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.0370, 0.2060, 0.0647, 0.2395, 0.1370, 0.1202, 0.0446, 0.0898, 0.0611],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:20,257][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([5.1592e-05, 2.6368e-02, 7.0265e-02, 3.8533e-02, 9.6808e-02, 1.6583e-01,
        2.5061e-04, 4.4672e-01, 1.5517e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:20,258][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.0073, 0.3066, 0.0934, 0.2457, 0.0272, 0.1918, 0.0212, 0.0444, 0.0623],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:20,260][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([0.0006, 0.0244, 0.1171, 0.0461, 0.0551, 0.2503, 0.0014, 0.3965, 0.1086],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:20,262][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0825, 0.1279, 0.0442, 0.0950, 0.0535, 0.0864, 0.0828, 0.0683, 0.1912,
        0.1684], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:20,263][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0006, 0.0371, 0.2056, 0.1061, 0.2022, 0.2428, 0.0017, 0.0872, 0.0480,
        0.0689], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:20,264][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0210, 0.0302, 0.1317, 0.1212, 0.0764, 0.1004, 0.0286, 0.1361, 0.1547,
        0.1997], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:20,264][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.3744, 0.1573, 0.0353, 0.0423, 0.0099, 0.0265, 0.2598, 0.0124, 0.0384,
        0.0437], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:20,265][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0006, 0.0436, 0.1420, 0.2410, 0.0277, 0.1259, 0.0018, 0.0896, 0.1226,
        0.2051], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:20,267][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.1130, 0.0488, 0.0519, 0.0947, 0.0450, 0.2217, 0.1309, 0.0673, 0.1213,
        0.1054], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:20,268][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [,] are: tensor([4.3876e-05, 4.5154e-02, 2.4301e-01, 8.8525e-02, 4.9250e-02, 1.1312e-01,
        2.3682e-04, 2.5987e-01, 1.2200e-01, 7.8791e-02], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:20,270][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0156, 0.0973, 0.0963, 0.1968, 0.0564, 0.1473, 0.0249, 0.1371, 0.0823,
        0.1459], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:20,271][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0451, 0.1550, 0.0748, 0.1763, 0.1623, 0.1119, 0.0496, 0.0750, 0.0496,
        0.1003], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:20,273][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [,] are: tensor([5.9536e-05, 1.7668e-02, 6.7427e-02, 3.4809e-02, 5.7021e-02, 1.6407e-01,
        3.2275e-04, 4.6398e-01, 1.4968e-01, 4.4954e-02], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:20,274][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0126, 0.1918, 0.1433, 0.2163, 0.0382, 0.1390, 0.0288, 0.0355, 0.0622,
        0.1324], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:20,275][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0004, 0.0293, 0.1347, 0.0758, 0.0672, 0.2153, 0.0009, 0.3403, 0.0635,
        0.0726], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:20,276][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0840, 0.1212, 0.0358, 0.0991, 0.0515, 0.0759, 0.0826, 0.0458, 0.1590,
        0.1512, 0.0938], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:20,277][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0009, 0.0405, 0.1795, 0.0970, 0.1915, 0.2474, 0.0021, 0.0925, 0.0458,
        0.0638, 0.0391], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:20,278][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0263, 0.0322, 0.1113, 0.1176, 0.0663, 0.0915, 0.0346, 0.0990, 0.1357,
        0.1929, 0.0926], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:20,280][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.2658, 0.1812, 0.0641, 0.0617, 0.0267, 0.0383, 0.2132, 0.0175, 0.0467,
        0.0563, 0.0287], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:20,282][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0011, 0.0352, 0.1215, 0.1647, 0.0241, 0.1226, 0.0030, 0.0758, 0.1079,
        0.1839, 0.1603], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:20,283][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1322, 0.0416, 0.0488, 0.0833, 0.0395, 0.1673, 0.1410, 0.0511, 0.1171,
        0.1012, 0.0768], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:20,285][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ and] are: tensor([8.8282e-05, 5.1248e-02, 2.0601e-01, 9.5158e-02, 4.9875e-02, 1.2145e-01,
        4.1790e-04, 2.2374e-01, 1.0602e-01, 7.5801e-02, 7.0182e-02],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:20,286][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0213, 0.0859, 0.0842, 0.1698, 0.0528, 0.1179, 0.0307, 0.1150, 0.0728,
        0.1293, 0.1203], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:20,288][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0631, 0.1534, 0.0556, 0.1530, 0.1251, 0.0921, 0.0635, 0.0653, 0.0560,
        0.1092, 0.0638], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:20,289][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ and] are: tensor([1.1636e-04, 1.6173e-02, 5.9440e-02, 3.3223e-02, 5.6768e-02, 1.6422e-01,
        5.3682e-04, 4.4095e-01, 1.5490e-01, 4.3708e-02, 2.9971e-02],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:20,291][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0076, 0.1359, 0.1232, 0.2033, 0.0469, 0.1384, 0.0182, 0.0412, 0.0674,
        0.1283, 0.0896], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:20,292][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0006, 0.0250, 0.1106, 0.0676, 0.0745, 0.2425, 0.0015, 0.3038, 0.0686,
        0.0604, 0.0450], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:20,293][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.0291, 0.1068, 0.0577, 0.1444, 0.0711, 0.1081, 0.0392, 0.0734, 0.1326,
        0.1060, 0.0740, 0.0575], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:20,294][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([0.0004, 0.0433, 0.2164, 0.0859, 0.1377, 0.2448, 0.0012, 0.1132, 0.0521,
        0.0561, 0.0324, 0.0164], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:20,294][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.0191, 0.0315, 0.0952, 0.1270, 0.0752, 0.1127, 0.0298, 0.1233, 0.1225,
        0.1196, 0.0652, 0.0788], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:20,296][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([0.0393, 0.2377, 0.1000, 0.1287, 0.0298, 0.1323, 0.0567, 0.0507, 0.0943,
        0.0810, 0.0374, 0.0121], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:20,298][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.0003, 0.0454, 0.1461, 0.1702, 0.0245, 0.1341, 0.0010, 0.0958, 0.0924,
        0.1323, 0.1155, 0.0424], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:20,299][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([0.0602, 0.0785, 0.0687, 0.0999, 0.0480, 0.1561, 0.0804, 0.0560, 0.1083,
        0.1019, 0.0687, 0.0733], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:20,301][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([7.7731e-06, 4.1979e-02, 2.2269e-01, 9.6984e-02, 4.8095e-02, 1.4438e-01,
        4.7538e-05, 2.3314e-01, 8.7389e-02, 6.8794e-02, 4.7992e-02, 8.5008e-03],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:20,302][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.0025, 0.0814, 0.0703, 0.1932, 0.0415, 0.1507, 0.0058, 0.1209, 0.0696,
        0.1243, 0.0959, 0.0440], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:20,304][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.0113, 0.1631, 0.0658, 0.2297, 0.1267, 0.1296, 0.0148, 0.0558, 0.0422,
        0.0749, 0.0519, 0.0341], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:20,306][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([1.0531e-05, 1.9525e-02, 7.0284e-02, 3.5616e-02, 3.0576e-02, 1.8453e-01,
        6.6602e-05, 4.6159e-01, 1.2058e-01, 3.9952e-02, 2.3605e-02, 1.3670e-02],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:20,307][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.0009, 0.1071, 0.0807, 0.2173, 0.0286, 0.2843, 0.0032, 0.0541, 0.0645,
        0.0849, 0.0559, 0.0185], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:20,308][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([1.4636e-04, 2.0408e-02, 1.1364e-01, 4.3869e-02, 5.5472e-02, 2.0405e-01,
        4.4135e-04, 3.6333e-01, 7.1947e-02, 3.8937e-02, 3.4630e-02, 5.3129e-02],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:20,310][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Melissa] are: tensor([0.1208, 0.1222, 0.0286, 0.1163, 0.0369, 0.0420, 0.0967, 0.0355, 0.1225,
        0.1138, 0.0827, 0.0589, 0.0230], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:20,312][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Melissa] are: tensor([0.0006, 0.0612, 0.2208, 0.1182, 0.1795, 0.1517, 0.0015, 0.0585, 0.0460,
        0.0640, 0.0364, 0.0145, 0.0472], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:20,314][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Melissa] are: tensor([0.0274, 0.0250, 0.1003, 0.1105, 0.0537, 0.0552, 0.0329, 0.1057, 0.1223,
        0.1584, 0.0776, 0.0679, 0.0632], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:20,315][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Melissa] are: tensor([0.1277, 0.2311, 0.0551, 0.1025, 0.0212, 0.0666, 0.1428, 0.0344, 0.0821,
        0.0726, 0.0336, 0.0193, 0.0109], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:20,317][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Melissa] are: tensor([0.0003, 0.0535, 0.1877, 0.1640, 0.0209, 0.0929, 0.0011, 0.0418, 0.0795,
        0.1405, 0.0851, 0.0251, 0.1076], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:20,318][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Melissa] are: tensor([0.0948, 0.0524, 0.0710, 0.0997, 0.0410, 0.1380, 0.1142, 0.0509, 0.1256,
        0.0701, 0.0460, 0.0619, 0.0343], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:20,319][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Melissa] are: tensor([2.4351e-05, 5.1423e-02, 1.6369e-01, 7.4098e-02, 2.9219e-02, 7.2630e-02,
        1.2716e-04, 2.0216e-01, 1.0724e-01, 8.8453e-02, 6.3599e-02, 1.1580e-02,
        1.3575e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:20,320][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Melissa] are: tensor([0.0046, 0.0589, 0.0605, 0.1713, 0.0417, 0.1495, 0.0098, 0.1122, 0.0659,
        0.1253, 0.0974, 0.0661, 0.0368], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:20,321][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Melissa] are: tensor([0.0287, 0.1652, 0.0468, 0.1580, 0.0931, 0.1022, 0.0344, 0.0627, 0.0419,
        0.1149, 0.0737, 0.0335, 0.0450], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:20,322][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Melissa] are: tensor([2.7404e-05, 2.1963e-02, 5.0932e-02, 3.5112e-02, 1.7659e-02, 1.6656e-01,
        1.3853e-04, 4.4346e-01, 1.0977e-01, 3.9535e-02, 2.4741e-02, 1.3729e-02,
        7.6377e-02], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:20,323][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Melissa] are: tensor([0.0024, 0.1141, 0.0745, 0.2218, 0.0328, 0.1572, 0.0075, 0.0512, 0.0842,
        0.1289, 0.0672, 0.0343, 0.0238], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:20,325][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Melissa] are: tensor([0.0003, 0.0231, 0.1199, 0.0486, 0.0381, 0.1465, 0.0008, 0.2603, 0.0695,
        0.0560, 0.0412, 0.0495, 0.1462], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:20,327][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.0912, 0.0755, 0.0258, 0.1018, 0.0390, 0.0464, 0.0813, 0.0344, 0.1172,
        0.1078, 0.0579, 0.0414, 0.0207, 0.1594], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:20,329][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ said] are: tensor([0.0002, 0.0428, 0.1988, 0.0892, 0.1413, 0.1988, 0.0007, 0.0712, 0.0316,
        0.0510, 0.0235, 0.0140, 0.0275, 0.1093], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:20,330][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.0100, 0.0162, 0.0881, 0.1100, 0.0483, 0.0695, 0.0142, 0.0830, 0.0975,
        0.1432, 0.0636, 0.0502, 0.0391, 0.1673], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:20,332][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ said] are: tensor([0.2584, 0.1988, 0.0548, 0.0492, 0.0078, 0.0217, 0.1922, 0.0096, 0.0265,
        0.0428, 0.0204, 0.0070, 0.0071, 0.1038], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:20,334][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.0003, 0.0328, 0.0907, 0.1624, 0.0161, 0.0754, 0.0009, 0.0452, 0.0529,
        0.1155, 0.0904, 0.0281, 0.0618, 0.2275], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:20,336][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ said] are: tensor([0.0878, 0.0303, 0.0285, 0.0576, 0.0214, 0.1138, 0.1030, 0.0423, 0.0963,
        0.0605, 0.0498, 0.0436, 0.0174, 0.2479], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:20,337][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ said] are: tensor([8.9504e-06, 3.6797e-02, 1.9138e-01, 7.6675e-02, 4.6033e-02, 9.5990e-02,
        5.9449e-05, 1.3976e-01, 6.3460e-02, 5.7108e-02, 3.9748e-02, 9.8282e-03,
        9.8409e-02, 1.4474e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:20,339][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.0076, 0.0557, 0.1039, 0.1473, 0.0371, 0.1010, 0.0138, 0.0652, 0.0404,
        0.0967, 0.0870, 0.0455, 0.0452, 0.1536], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:20,340][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.0195, 0.1304, 0.0668, 0.1872, 0.1224, 0.1065, 0.0240, 0.0480, 0.0350,
        0.0765, 0.0527, 0.0282, 0.0274, 0.0753], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:20,342][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ said] are: tensor([1.4940e-05, 2.0919e-02, 5.3129e-02, 4.0734e-02, 4.0055e-02, 1.3081e-01,
        1.0652e-04, 3.5914e-01, 1.0790e-01, 3.8858e-02, 1.9981e-02, 1.4212e-02,
        6.6069e-02, 1.0808e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:20,343][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.0075, 0.1440, 0.0670, 0.1287, 0.0106, 0.0746, 0.0155, 0.0221, 0.0301,
        0.0833, 0.0430, 0.0173, 0.0127, 0.3435], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:20,344][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ said] are: tensor([1.4044e-04, 1.4699e-02, 7.0011e-02, 5.2424e-02, 4.8521e-02, 1.8305e-01,
        4.5920e-04, 2.8750e-01, 5.0504e-02, 5.0392e-02, 3.6025e-02, 4.4387e-02,
        8.0809e-02, 8.1070e-02], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:20,345][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0385, 0.0628, 0.0247, 0.0630, 0.0303, 0.0527, 0.0438, 0.0305, 0.1169,
        0.1025, 0.0515, 0.0517, 0.0316, 0.1929, 0.1066], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:20,346][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0004, 0.0340, 0.1523, 0.0895, 0.1353, 0.1592, 0.0011, 0.0633, 0.0406,
        0.0483, 0.0272, 0.0169, 0.0298, 0.1225, 0.0794], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:20,347][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0090, 0.0135, 0.0728, 0.0697, 0.0382, 0.0653, 0.0150, 0.0795, 0.1072,
        0.1185, 0.0535, 0.0557, 0.0461, 0.1684, 0.0874], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:20,349][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.1865, 0.1701, 0.0583, 0.0551, 0.0113, 0.0379, 0.1625, 0.0134, 0.0344,
        0.0436, 0.0211, 0.0107, 0.0086, 0.1565, 0.0302], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:20,350][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0003, 0.0259, 0.0573, 0.1028, 0.0122, 0.0495, 0.0008, 0.0239, 0.0455,
        0.0986, 0.0732, 0.0249, 0.0624, 0.1946, 0.2282], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:20,352][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0901, 0.0296, 0.0287, 0.0508, 0.0230, 0.1022, 0.1001, 0.0340, 0.0884,
        0.0576, 0.0413, 0.0376, 0.0210, 0.2112, 0.0843], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:20,353][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ to] are: tensor([1.6391e-05, 3.1074e-02, 9.6422e-02, 5.4458e-02, 2.8525e-02, 5.5901e-02,
        9.4206e-05, 1.1851e-01, 7.6952e-02, 5.4608e-02, 4.0723e-02, 9.4417e-03,
        8.2263e-02, 1.1239e-01, 2.3862e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:20,355][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0096, 0.0531, 0.0587, 0.1299, 0.0282, 0.0696, 0.0152, 0.0611, 0.0511,
        0.0973, 0.0910, 0.0492, 0.0357, 0.1179, 0.1325], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:20,357][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0273, 0.1253, 0.0530, 0.1389, 0.0933, 0.0938, 0.0334, 0.0575, 0.0404,
        0.0826, 0.0474, 0.0320, 0.0302, 0.0777, 0.0670], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:20,358][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ to] are: tensor([1.9483e-05, 1.1666e-02, 4.0077e-02, 2.7629e-02, 3.1535e-02, 9.9572e-02,
        1.2851e-04, 3.3153e-01, 1.1539e-01, 3.2798e-02, 2.1652e-02, 1.4835e-02,
        7.4196e-02, 8.2180e-02, 1.1678e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:20,360][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0067, 0.0845, 0.0527, 0.0817, 0.0147, 0.0585, 0.0142, 0.0179, 0.0319,
        0.0677, 0.0377, 0.0184, 0.0179, 0.4051, 0.0904], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:20,361][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0003, 0.0203, 0.0864, 0.0551, 0.0465, 0.1646, 0.0007, 0.2068, 0.0495,
        0.0479, 0.0352, 0.0418, 0.0792, 0.0711, 0.0945], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:20,459][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:31:20,460][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:20,461][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:20,462][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:20,463][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:20,464][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:20,464][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:20,466][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:20,467][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:20,468][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:20,470][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:20,471][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:20,472][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:20,474][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.5899, 0.4101], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:20,475][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.1149, 0.8851], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:20,477][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.5101, 0.4899], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:20,478][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.9801, 0.0199], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:20,480][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0637, 0.9363], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:20,482][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.9037, 0.0963], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:20,483][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0115, 0.9885], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:20,485][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.6177, 0.3823], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:20,487][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.3912, 0.6088], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:20,487][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0469, 0.9531], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:20,488][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.4726, 0.5274], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:20,489][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0521, 0.9479], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:20,490][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Melissa] are: tensor([0.8257, 0.1394, 0.0349], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:20,491][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Melissa] are: tensor([0.0063, 0.2259, 0.7678], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:20,492][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Melissa] are: tensor([0.2960, 0.1108, 0.5932], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:20,493][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Melissa] are: tensor([0.7768, 0.2031, 0.0201], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:20,495][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Melissa] are: tensor([0.0123, 0.1604, 0.8273], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:20,497][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Melissa] are: tensor([0.6175, 0.1371, 0.2454], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:20,498][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Melissa] are: tensor([5.5415e-04, 2.1085e-01, 7.8860e-01], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:20,499][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Melissa] are: tensor([0.2383, 0.4135, 0.3481], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:20,501][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Melissa] are: tensor([0.1547, 0.6970, 0.1483], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:20,502][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Melissa] are: tensor([0.0047, 0.3017, 0.6936], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:20,504][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Melissa] are: tensor([0.1132, 0.6195, 0.2673], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:20,506][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Melissa] are: tensor([0.0078, 0.2776, 0.7146], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:20,507][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.6163, 0.1653, 0.0697, 0.1487], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:20,509][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0041, 0.1571, 0.5568, 0.2820], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:20,510][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.1124, 0.1121, 0.4091, 0.3663], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:20,512][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.5675, 0.3231, 0.0629, 0.0465], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:20,513][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0129, 0.1101, 0.3713, 0.5057], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:20,514][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.5674, 0.1134, 0.1233, 0.1958], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:20,515][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0009, 0.1505, 0.5695, 0.2791], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:20,516][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.1251, 0.2210, 0.2324, 0.4215], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:20,517][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.1538, 0.3846, 0.1495, 0.3121], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:20,519][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0075, 0.1555, 0.4738, 0.3633], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:20,520][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0586, 0.3768, 0.2325, 0.3321], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:20,522][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0056, 0.1439, 0.4160, 0.4345], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:20,523][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Benjamin] are: tensor([0.4474, 0.2482, 0.0587, 0.1353, 0.1103], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:20,525][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Benjamin] are: tensor([0.0018, 0.0916, 0.3473, 0.1673, 0.3920], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:20,527][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Benjamin] are: tensor([0.0973, 0.0815, 0.3102, 0.2767, 0.2342], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:20,528][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Benjamin] are: tensor([0.1984, 0.5545, 0.1014, 0.1293, 0.0164], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:20,530][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Benjamin] are: tensor([0.0038, 0.0820, 0.4012, 0.4293, 0.0838], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:20,531][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Benjamin] are: tensor([0.4860, 0.1315, 0.1354, 0.1582, 0.0889], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:20,533][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Benjamin] are: tensor([3.0291e-04, 9.5816e-02, 5.7092e-01, 2.1574e-01, 1.1723e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:20,534][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Benjamin] are: tensor([0.0693, 0.1808, 0.1901, 0.4427, 0.1170], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:20,536][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Benjamin] are: tensor([0.0332, 0.3647, 0.1195, 0.2569, 0.2258], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:20,538][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Benjamin] are: tensor([0.0009, 0.0871, 0.4241, 0.2338, 0.2540], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:20,539][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Benjamin] are: tensor([0.0113, 0.3865, 0.1981, 0.3634, 0.0408], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:20,540][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Benjamin] are: tensor([0.0024, 0.0910, 0.3687, 0.2641, 0.2737], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:20,541][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.3700, 0.1635, 0.0819, 0.1728, 0.0876, 0.1242], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:20,541][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.0014, 0.0440, 0.2459, 0.1306, 0.3240, 0.2541], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:20,542][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.0653, 0.0296, 0.3037, 0.2480, 0.1618, 0.1916], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:20,544][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.7089, 0.2152, 0.0263, 0.0318, 0.0054, 0.0124], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:20,545][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.0101, 0.0724, 0.2878, 0.3648, 0.0711, 0.1939], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:20,547][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.3954, 0.0525, 0.0577, 0.0973, 0.0571, 0.3400], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:20,548][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([2.9755e-04, 7.4193e-02, 3.8079e-01, 1.8357e-01, 1.1466e-01, 2.4649e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:20,549][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.0552, 0.1339, 0.2049, 0.3137, 0.0945, 0.1977], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:20,551][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.0430, 0.2117, 0.1078, 0.2715, 0.2068, 0.1592], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:20,553][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.0006, 0.0454, 0.1267, 0.1109, 0.2245, 0.4920], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:20,554][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.0577, 0.4335, 0.1000, 0.2165, 0.0289, 0.1634], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:20,556][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.0013, 0.0394, 0.1710, 0.1551, 0.1638, 0.4694], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:20,558][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0293, 0.3489, 0.1293, 0.1707, 0.1496, 0.1372, 0.0350],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:20,559][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([6.9138e-05, 7.6245e-02, 4.1332e-01, 7.2989e-02, 1.0223e-01, 3.3491e-01,
        2.4537e-04], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:20,560][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0234, 0.1753, 0.2002, 0.1579, 0.1973, 0.2105, 0.0355],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:20,562][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.2332, 0.1413, 0.0715, 0.1283, 0.0733, 0.0968, 0.2555],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:20,563][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([2.8446e-04, 1.2463e-01, 3.5192e-01, 2.1639e-01, 7.7354e-02, 2.2837e-01,
        1.0553e-03], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:20,565][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0639, 0.1058, 0.0991, 0.1349, 0.0754, 0.4301, 0.0909],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:20,566][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([4.9986e-06, 6.1333e-02, 4.0106e-01, 9.8881e-02, 5.9224e-02, 3.7946e-01,
        3.7399e-05], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:20,567][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0064, 0.1261, 0.1945, 0.1893, 0.1259, 0.3432, 0.0146],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:20,567][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0165, 0.2283, 0.1457, 0.1905, 0.2370, 0.1588, 0.0233],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:20,568][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([6.7035e-06, 5.8922e-02, 3.2902e-01, 4.3842e-02, 6.0169e-02, 5.0800e-01,
        3.6131e-05], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:20,570][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0061, 0.2665, 0.0866, 0.2441, 0.0807, 0.3020, 0.0141],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:20,571][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([7.4044e-05, 5.9503e-02, 3.2179e-01, 8.0174e-02, 1.0292e-01, 4.3527e-01,
        2.7508e-04], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:20,573][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.1265, 0.1891, 0.0788, 0.2024, 0.0756, 0.1314, 0.1223, 0.0740],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:20,574][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([0.0015, 0.0527, 0.2762, 0.1326, 0.2492, 0.2126, 0.0034, 0.0718],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:20,576][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([0.0606, 0.0367, 0.1801, 0.2169, 0.1305, 0.1510, 0.0720, 0.1521],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:20,577][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([0.3408, 0.2470, 0.0223, 0.0465, 0.0069, 0.0291, 0.2968, 0.0106],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:20,579][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.0047, 0.0443, 0.2441, 0.3016, 0.0340, 0.2116, 0.0094, 0.1503],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:20,581][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([0.2229, 0.0532, 0.0586, 0.0956, 0.0454, 0.2167, 0.2312, 0.0763],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:20,582][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([8.7225e-05, 6.2754e-02, 2.4105e-01, 1.5727e-01, 7.0715e-02, 1.7800e-01,
        4.7382e-04, 2.8965e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:20,584][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.0290, 0.1110, 0.1101, 0.2699, 0.0634, 0.1778, 0.0556, 0.1833],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:20,585][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.0474, 0.2142, 0.0706, 0.2652, 0.2119, 0.0993, 0.0448, 0.0467],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:20,587][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([1.2585e-04, 2.2034e-02, 6.5456e-02, 5.7448e-02, 7.7819e-02, 2.2394e-01,
        6.0038e-04, 5.5258e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:20,588][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.0076, 0.3093, 0.1050, 0.3120, 0.0201, 0.1839, 0.0219, 0.0401],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:20,590][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([0.0013, 0.0334, 0.1206, 0.0785, 0.0942, 0.2880, 0.0033, 0.3808],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:20,591][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.1381, 0.1497, 0.0525, 0.1291, 0.0608, 0.0933, 0.1194, 0.0744, 0.1827],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:20,592][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([0.0010, 0.0642, 0.2464, 0.1071, 0.1774, 0.2709, 0.0025, 0.0791, 0.0515],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:20,593][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([0.0310, 0.0282, 0.1616, 0.1761, 0.0734, 0.1267, 0.0422, 0.1698, 0.1911],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:20,594][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([0.2746, 0.2587, 0.0317, 0.0579, 0.0090, 0.0362, 0.2605, 0.0255, 0.0460],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:20,595][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.0021, 0.0797, 0.2005, 0.2906, 0.0344, 0.1527, 0.0046, 0.0788, 0.1567],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:20,596][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([0.1867, 0.0476, 0.0517, 0.0763, 0.0414, 0.1619, 0.1999, 0.0618, 0.1728],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:20,597][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([5.2239e-05, 5.1185e-02, 2.7682e-01, 1.1546e-01, 5.3040e-02, 1.5434e-01,
        2.7610e-04, 2.4589e-01, 1.0294e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:20,599][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.0128, 0.1143, 0.0904, 0.2498, 0.0526, 0.1784, 0.0252, 0.1628, 0.1138],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:20,601][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([0.0370, 0.2060, 0.0647, 0.2395, 0.1370, 0.1202, 0.0446, 0.0898, 0.0611],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:20,602][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([5.1592e-05, 2.6368e-02, 7.0265e-02, 3.8533e-02, 9.6808e-02, 1.6583e-01,
        2.5061e-04, 4.4672e-01, 1.5517e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:20,604][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.0073, 0.3066, 0.0934, 0.2457, 0.0272, 0.1918, 0.0212, 0.0444, 0.0623],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:20,605][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([0.0006, 0.0244, 0.1171, 0.0461, 0.0551, 0.2503, 0.0014, 0.3965, 0.1086],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:20,607][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0825, 0.1279, 0.0442, 0.0950, 0.0535, 0.0864, 0.0828, 0.0683, 0.1912,
        0.1684], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:20,608][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0006, 0.0371, 0.2056, 0.1061, 0.2022, 0.2428, 0.0017, 0.0872, 0.0480,
        0.0689], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:20,610][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0210, 0.0302, 0.1317, 0.1212, 0.0764, 0.1004, 0.0286, 0.1361, 0.1547,
        0.1997], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:20,612][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.3744, 0.1573, 0.0353, 0.0423, 0.0099, 0.0265, 0.2598, 0.0124, 0.0384,
        0.0437], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:20,613][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0006, 0.0436, 0.1420, 0.2410, 0.0277, 0.1259, 0.0018, 0.0896, 0.1226,
        0.2051], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:20,615][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.1130, 0.0488, 0.0519, 0.0947, 0.0450, 0.2217, 0.1309, 0.0673, 0.1213,
        0.1054], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:20,616][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([4.3876e-05, 4.5154e-02, 2.4301e-01, 8.8525e-02, 4.9250e-02, 1.1312e-01,
        2.3682e-04, 2.5987e-01, 1.2200e-01, 7.8791e-02], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:20,618][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0156, 0.0973, 0.0963, 0.1968, 0.0564, 0.1473, 0.0249, 0.1371, 0.0823,
        0.1459], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:20,618][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0451, 0.1550, 0.0748, 0.1763, 0.1623, 0.1119, 0.0496, 0.0750, 0.0496,
        0.1003], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:20,619][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([5.9536e-05, 1.7668e-02, 6.7427e-02, 3.4809e-02, 5.7021e-02, 1.6407e-01,
        3.2275e-04, 4.6398e-01, 1.4968e-01, 4.4954e-02], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:20,620][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0126, 0.1918, 0.1433, 0.2163, 0.0382, 0.1390, 0.0288, 0.0355, 0.0622,
        0.1324], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:20,622][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0004, 0.0293, 0.1347, 0.0758, 0.0672, 0.2153, 0.0009, 0.3403, 0.0635,
        0.0726], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:20,623][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0840, 0.1212, 0.0358, 0.0991, 0.0515, 0.0759, 0.0826, 0.0458, 0.1590,
        0.1512, 0.0938], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:20,625][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0009, 0.0405, 0.1795, 0.0970, 0.1915, 0.2474, 0.0021, 0.0925, 0.0458,
        0.0638, 0.0391], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:20,627][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0263, 0.0322, 0.1113, 0.1176, 0.0663, 0.0915, 0.0346, 0.0990, 0.1357,
        0.1929, 0.0926], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:20,628][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.2658, 0.1812, 0.0641, 0.0617, 0.0267, 0.0383, 0.2132, 0.0175, 0.0467,
        0.0563, 0.0287], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:20,630][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0011, 0.0352, 0.1215, 0.1647, 0.0241, 0.1226, 0.0030, 0.0758, 0.1079,
        0.1839, 0.1603], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:20,632][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.1322, 0.0416, 0.0488, 0.0833, 0.0395, 0.1673, 0.1410, 0.0511, 0.1171,
        0.1012, 0.0768], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:20,633][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([8.8282e-05, 5.1248e-02, 2.0601e-01, 9.5158e-02, 4.9875e-02, 1.2145e-01,
        4.1790e-04, 2.2374e-01, 1.0602e-01, 7.5801e-02, 7.0182e-02],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:20,635][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0213, 0.0859, 0.0842, 0.1698, 0.0528, 0.1179, 0.0307, 0.1150, 0.0728,
        0.1293, 0.1203], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:20,636][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0631, 0.1534, 0.0556, 0.1530, 0.1251, 0.0921, 0.0635, 0.0653, 0.0560,
        0.1092, 0.0638], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:20,638][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([1.1636e-04, 1.6173e-02, 5.9440e-02, 3.3223e-02, 5.6768e-02, 1.6422e-01,
        5.3682e-04, 4.4095e-01, 1.5490e-01, 4.3708e-02, 2.9971e-02],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:20,639][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0076, 0.1359, 0.1232, 0.2033, 0.0469, 0.1384, 0.0182, 0.0412, 0.0674,
        0.1283, 0.0896], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:20,641][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0006, 0.0250, 0.1106, 0.0676, 0.0745, 0.2425, 0.0015, 0.3038, 0.0686,
        0.0604, 0.0450], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:20,643][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.0291, 0.1068, 0.0577, 0.1444, 0.0711, 0.1081, 0.0392, 0.0734, 0.1326,
        0.1060, 0.0740, 0.0575], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:20,644][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([0.0004, 0.0433, 0.2164, 0.0859, 0.1377, 0.2448, 0.0012, 0.1132, 0.0521,
        0.0561, 0.0324, 0.0164], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:20,644][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([0.0191, 0.0315, 0.0952, 0.1270, 0.0752, 0.1127, 0.0298, 0.1233, 0.1225,
        0.1196, 0.0652, 0.0788], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:20,645][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([0.0393, 0.2377, 0.1000, 0.1287, 0.0298, 0.1323, 0.0567, 0.0507, 0.0943,
        0.0810, 0.0374, 0.0121], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:20,646][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.0003, 0.0454, 0.1461, 0.1702, 0.0245, 0.1341, 0.0010, 0.0958, 0.0924,
        0.1323, 0.1155, 0.0424], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:20,648][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([0.0602, 0.0785, 0.0687, 0.0999, 0.0480, 0.1561, 0.0804, 0.0560, 0.1083,
        0.1019, 0.0687, 0.0733], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:20,649][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([7.7731e-06, 4.1979e-02, 2.2269e-01, 9.6984e-02, 4.8095e-02, 1.4438e-01,
        4.7538e-05, 2.3314e-01, 8.7389e-02, 6.8794e-02, 4.7992e-02, 8.5008e-03],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:20,651][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.0025, 0.0814, 0.0703, 0.1932, 0.0415, 0.1507, 0.0058, 0.1209, 0.0696,
        0.1243, 0.0959, 0.0440], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:20,653][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.0113, 0.1631, 0.0658, 0.2297, 0.1267, 0.1296, 0.0148, 0.0558, 0.0422,
        0.0749, 0.0519, 0.0341], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:20,654][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([1.0531e-05, 1.9525e-02, 7.0284e-02, 3.5616e-02, 3.0576e-02, 1.8453e-01,
        6.6602e-05, 4.6159e-01, 1.2058e-01, 3.9952e-02, 2.3605e-02, 1.3670e-02],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:20,655][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([0.0009, 0.1071, 0.0807, 0.2173, 0.0286, 0.2843, 0.0032, 0.0541, 0.0645,
        0.0849, 0.0559, 0.0185], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:20,657][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([1.4636e-04, 2.0408e-02, 1.1364e-01, 4.3869e-02, 5.5472e-02, 2.0405e-01,
        4.4135e-04, 3.6333e-01, 7.1947e-02, 3.8937e-02, 3.4630e-02, 5.3129e-02],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:20,658][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Melissa] are: tensor([0.1208, 0.1222, 0.0286, 0.1163, 0.0369, 0.0420, 0.0967, 0.0355, 0.1225,
        0.1138, 0.0827, 0.0589, 0.0230], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:20,660][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Melissa] are: tensor([0.0006, 0.0612, 0.2208, 0.1182, 0.1795, 0.1517, 0.0015, 0.0585, 0.0460,
        0.0640, 0.0364, 0.0145, 0.0472], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:20,662][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Melissa] are: tensor([0.0274, 0.0250, 0.1003, 0.1105, 0.0537, 0.0552, 0.0329, 0.1057, 0.1223,
        0.1584, 0.0776, 0.0679, 0.0632], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:20,664][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Melissa] are: tensor([0.1277, 0.2311, 0.0551, 0.1025, 0.0212, 0.0666, 0.1428, 0.0344, 0.0821,
        0.0726, 0.0336, 0.0193, 0.0109], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:20,665][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Melissa] are: tensor([0.0003, 0.0535, 0.1877, 0.1640, 0.0209, 0.0929, 0.0011, 0.0418, 0.0795,
        0.1405, 0.0851, 0.0251, 0.1076], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:20,667][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Melissa] are: tensor([0.0948, 0.0524, 0.0710, 0.0997, 0.0410, 0.1380, 0.1142, 0.0509, 0.1256,
        0.0701, 0.0460, 0.0619, 0.0343], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:20,668][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Melissa] are: tensor([2.4351e-05, 5.1423e-02, 1.6369e-01, 7.4098e-02, 2.9219e-02, 7.2630e-02,
        1.2716e-04, 2.0216e-01, 1.0724e-01, 8.8453e-02, 6.3599e-02, 1.1580e-02,
        1.3575e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:20,669][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Melissa] are: tensor([0.0046, 0.0589, 0.0605, 0.1713, 0.0417, 0.1495, 0.0098, 0.1122, 0.0659,
        0.1253, 0.0974, 0.0661, 0.0368], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:20,670][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Melissa] are: tensor([0.0287, 0.1652, 0.0468, 0.1580, 0.0931, 0.1022, 0.0344, 0.0627, 0.0419,
        0.1149, 0.0737, 0.0335, 0.0450], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:20,671][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Melissa] are: tensor([2.7404e-05, 2.1963e-02, 5.0932e-02, 3.5112e-02, 1.7659e-02, 1.6656e-01,
        1.3853e-04, 4.4346e-01, 1.0977e-01, 3.9535e-02, 2.4741e-02, 1.3729e-02,
        7.6377e-02], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:20,672][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Melissa] are: tensor([0.0024, 0.1141, 0.0745, 0.2218, 0.0328, 0.1572, 0.0075, 0.0512, 0.0842,
        0.1289, 0.0672, 0.0343, 0.0238], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:20,674][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Melissa] are: tensor([0.0003, 0.0231, 0.1199, 0.0486, 0.0381, 0.1465, 0.0008, 0.2603, 0.0695,
        0.0560, 0.0412, 0.0495, 0.1462], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:20,675][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.0912, 0.0755, 0.0258, 0.1018, 0.0390, 0.0464, 0.0813, 0.0344, 0.1172,
        0.1078, 0.0579, 0.0414, 0.0207, 0.1594], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:20,677][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([0.0002, 0.0428, 0.1988, 0.0892, 0.1413, 0.1988, 0.0007, 0.0712, 0.0316,
        0.0510, 0.0235, 0.0140, 0.0275, 0.1093], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:20,679][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([0.0100, 0.0162, 0.0881, 0.1100, 0.0483, 0.0695, 0.0142, 0.0830, 0.0975,
        0.1432, 0.0636, 0.0502, 0.0391, 0.1673], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:20,681][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([0.2584, 0.1988, 0.0548, 0.0492, 0.0078, 0.0217, 0.1922, 0.0096, 0.0265,
        0.0428, 0.0204, 0.0070, 0.0071, 0.1038], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:20,682][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([0.0003, 0.0328, 0.0907, 0.1624, 0.0161, 0.0754, 0.0009, 0.0452, 0.0529,
        0.1155, 0.0904, 0.0281, 0.0618, 0.2275], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:20,684][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([0.0878, 0.0303, 0.0285, 0.0576, 0.0214, 0.1138, 0.1030, 0.0423, 0.0963,
        0.0605, 0.0498, 0.0436, 0.0174, 0.2479], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:20,685][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([8.9504e-06, 3.6797e-02, 1.9138e-01, 7.6675e-02, 4.6033e-02, 9.5990e-02,
        5.9449e-05, 1.3976e-01, 6.3460e-02, 5.7108e-02, 3.9748e-02, 9.8282e-03,
        9.8409e-02, 1.4474e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:20,687][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.0076, 0.0557, 0.1039, 0.1473, 0.0371, 0.1010, 0.0138, 0.0652, 0.0404,
        0.0967, 0.0870, 0.0455, 0.0452, 0.1536], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:20,689][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([0.0195, 0.1304, 0.0668, 0.1872, 0.1224, 0.1065, 0.0240, 0.0480, 0.0350,
        0.0765, 0.0527, 0.0282, 0.0274, 0.0753], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:20,690][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([1.4940e-05, 2.0919e-02, 5.3129e-02, 4.0734e-02, 4.0055e-02, 1.3081e-01,
        1.0652e-04, 3.5914e-01, 1.0790e-01, 3.8858e-02, 1.9981e-02, 1.4212e-02,
        6.6069e-02, 1.0808e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:20,692][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([0.0075, 0.1440, 0.0670, 0.1287, 0.0106, 0.0746, 0.0155, 0.0221, 0.0301,
        0.0833, 0.0430, 0.0173, 0.0127, 0.3435], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:20,693][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([1.4044e-04, 1.4699e-02, 7.0011e-02, 5.2424e-02, 4.8521e-02, 1.8305e-01,
        4.5920e-04, 2.8750e-01, 5.0504e-02, 5.0392e-02, 3.6025e-02, 4.4387e-02,
        8.0809e-02, 8.1070e-02], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:20,695][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0385, 0.0628, 0.0247, 0.0630, 0.0303, 0.0527, 0.0438, 0.0305, 0.1169,
        0.1025, 0.0515, 0.0517, 0.0316, 0.1929, 0.1066], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:20,696][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0004, 0.0340, 0.1523, 0.0895, 0.1353, 0.1592, 0.0011, 0.0633, 0.0406,
        0.0483, 0.0272, 0.0169, 0.0298, 0.1225, 0.0794], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:20,697][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0090, 0.0135, 0.0728, 0.0697, 0.0382, 0.0653, 0.0150, 0.0795, 0.1072,
        0.1185, 0.0535, 0.0557, 0.0461, 0.1684, 0.0874], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:20,698][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.1865, 0.1701, 0.0583, 0.0551, 0.0113, 0.0379, 0.1625, 0.0134, 0.0344,
        0.0436, 0.0211, 0.0107, 0.0086, 0.1565, 0.0302], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:20,699][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0003, 0.0259, 0.0573, 0.1028, 0.0122, 0.0495, 0.0008, 0.0239, 0.0455,
        0.0986, 0.0732, 0.0249, 0.0624, 0.1946, 0.2282], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:20,701][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0901, 0.0296, 0.0287, 0.0508, 0.0230, 0.1022, 0.1001, 0.0340, 0.0884,
        0.0576, 0.0413, 0.0376, 0.0210, 0.2112, 0.0843], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:20,702][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([1.6391e-05, 3.1074e-02, 9.6422e-02, 5.4458e-02, 2.8525e-02, 5.5901e-02,
        9.4206e-05, 1.1851e-01, 7.6952e-02, 5.4608e-02, 4.0723e-02, 9.4417e-03,
        8.2263e-02, 1.1239e-01, 2.3862e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:20,704][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0096, 0.0531, 0.0587, 0.1299, 0.0282, 0.0696, 0.0152, 0.0611, 0.0511,
        0.0973, 0.0910, 0.0492, 0.0357, 0.1179, 0.1325], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:20,706][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0273, 0.1253, 0.0530, 0.1389, 0.0933, 0.0938, 0.0334, 0.0575, 0.0404,
        0.0826, 0.0474, 0.0320, 0.0302, 0.0777, 0.0670], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:20,707][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([1.9483e-05, 1.1666e-02, 4.0077e-02, 2.7629e-02, 3.1535e-02, 9.9572e-02,
        1.2851e-04, 3.3153e-01, 1.1539e-01, 3.2798e-02, 2.1652e-02, 1.4835e-02,
        7.4196e-02, 8.2180e-02, 1.1678e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:20,709][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0067, 0.0845, 0.0527, 0.0817, 0.0147, 0.0585, 0.0142, 0.0179, 0.0319,
        0.0677, 0.0377, 0.0184, 0.0179, 0.4051, 0.0904], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:20,711][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0003, 0.0203, 0.0864, 0.0551, 0.0465, 0.1646, 0.0007, 0.2068, 0.0495,
        0.0479, 0.0352, 0.0418, 0.0792, 0.0711, 0.0945], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:20,714][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:31:20,716][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[866],
        [139],
        [122],
        [ 53],
        [113],
        [  9],
        [  8],
        [ 12],
        [ 12],
        [ 11],
        [  9],
        [  6],
        [ 19],
        [ 12],
        [ 11]], device='cuda:0')
[2024-07-24 10:31:20,718][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[721],
        [110],
        [ 67],
        [ 34],
        [ 35],
        [  6],
        [  1],
        [  5],
        [  9],
        [  6],
        [  5],
        [  1],
        [ 10],
        [  6],
        [  9]], device='cuda:0')
[2024-07-24 10:31:20,720][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[34072],
        [31346],
        [31435],
        [30350],
        [31616],
        [28121],
        [27293],
        [26769],
        [26525],
        [24694],
        [23421],
        [23969],
        [23778],
        [22922],
        [21102]], device='cuda:0')
[2024-07-24 10:31:20,722][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[16052],
        [27169],
        [33395],
        [34285],
        [28687],
        [25974],
        [28117],
        [26494],
        [26531],
        [25855],
        [25706],
        [25996],
        [27957],
        [25751],
        [25826]], device='cuda:0')
[2024-07-24 10:31:20,723][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[35207],
        [44388],
        [46598],
        [44923],
        [47620],
        [47531],
        [48015],
        [48049],
        [48020],
        [48195],
        [47932],
        [47877],
        [47895],
        [47729],
        [47500]], device='cuda:0')
[2024-07-24 10:31:20,724][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[42639],
        [43837],
        [49083],
        [49913],
        [50119],
        [49499],
        [49837],
        [49692],
        [49793],
        [49579],
        [49805],
        [49926],
        [49882],
        [49779],
        [49771]], device='cuda:0')
[2024-07-24 10:31:20,726][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[2830],
        [9618],
        [2319],
        [3746],
        [2984],
        [4145],
        [3987],
        [5152],
        [5800],
        [7428],
        [9007],
        [7649],
        [5432],
        [6406],
        [7519]], device='cuda:0')
[2024-07-24 10:31:20,727][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[44342],
        [44890],
        [36136],
        [38316],
        [33930],
        [31953],
        [30570],
        [32855],
        [30015],
        [29127],
        [30656],
        [31287],
        [31130],
        [30742],
        [30533]], device='cuda:0')
[2024-07-24 10:31:20,729][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[40106],
        [29109],
        [45368],
        [44342],
        [47000],
        [45609],
        [43813],
        [41227],
        [41083],
        [40126],
        [38967],
        [39347],
        [38089],
        [40795],
        [35873]], device='cuda:0')
[2024-07-24 10:31:20,731][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[15965],
        [  996],
        [ 2161],
        [ 1951],
        [ 1496],
        [ 2273],
        [ 2627],
        [ 2852],
        [ 3171],
        [ 3245],
        [ 3641],
        [ 3904],
        [ 4277],
        [ 4460],
        [ 4970]], device='cuda:0')
[2024-07-24 10:31:20,732][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[  590],
        [45089],
        [47927],
        [48799],
        [49822],
        [49767],
        [49825],
        [49811],
        [49619],
        [49767],
        [49693],
        [49656],
        [49584],
        [49634],
        [49490]], device='cuda:0')
[2024-07-24 10:31:20,734][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[25856],
        [33758],
        [19817],
        [25708],
        [47603],
        [48471],
        [36740],
        [40097],
        [41971],
        [38415],
        [38660],
        [35659],
        [33056],
        [35356],
        [34951]], device='cuda:0')
[2024-07-24 10:31:20,736][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[21586],
        [24976],
        [27638],
        [23589],
        [22873],
        [21214],
        [18500],
        [19958],
        [20164],
        [21093],
        [20524],
        [18230],
        [19584],
        [22107],
        [22634]], device='cuda:0')
[2024-07-24 10:31:20,738][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[40346],
        [40057],
        [49253],
        [44842],
        [49227],
        [44939],
        [46570],
        [42717],
        [41127],
        [42343],
        [41811],
        [41331],
        [44398],
        [41957],
        [42354]], device='cuda:0')
[2024-07-24 10:31:20,739][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[21684],
        [10190],
        [ 7773],
        [ 8531],
        [15172],
        [ 9240],
        [27494],
        [28827],
        [25566],
        [13501],
        [15933],
        [17105],
        [ 7898],
        [ 9526],
        [17427]], device='cuda:0')
[2024-07-24 10:31:20,741][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[19203],
        [11697],
        [16535],
        [11279],
        [14491],
        [16777],
        [16248],
        [17134],
        [19068],
        [21138],
        [21058],
        [20455],
        [19740],
        [19599],
        [20295]], device='cuda:0')
[2024-07-24 10:31:20,743][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[43750],
        [14718],
        [31168],
        [28032],
        [11935],
        [ 9018],
        [15815],
        [11011],
        [11406],
        [ 9198],
        [ 8561],
        [10374],
        [11503],
        [11342],
        [10022]], device='cuda:0')
[2024-07-24 10:31:20,744][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[14183],
        [17887],
        [21372],
        [24865],
        [20849],
        [19221],
        [16923],
        [20838],
        [25173],
        [26446],
        [27160],
        [24805],
        [26315],
        [26037],
        [25211]], device='cuda:0')
[2024-07-24 10:31:20,746][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[1947],
        [1860],
        [1641],
        [1509],
        [1432],
        [1595],
        [1805],
        [1980],
        [2124],
        [2309],
        [2063],
        [1761],
        [1872],
        [2024],
        [1983]], device='cuda:0')
[2024-07-24 10:31:20,748][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[22115],
        [38888],
        [39881],
        [38748],
        [38471],
        [36622],
        [38048],
        [32196],
        [33046],
        [29588],
        [26300],
        [27470],
        [29879],
        [24826],
        [20277]], device='cuda:0')
[2024-07-24 10:31:20,749][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[17144],
        [ 2053],
        [ 2397],
        [ 2792],
        [ 4064],
        [ 5237],
        [ 5622],
        [ 4606],
        [ 4271],
        [ 5606],
        [ 5853],
        [ 5528],
        [ 5682],
        [ 7706],
        [ 8476]], device='cuda:0')
[2024-07-24 10:31:20,751][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[ 2339],
        [10670],
        [18376],
        [13221],
        [15104],
        [13173],
        [14502],
        [ 7736],
        [ 8748],
        [ 7820],
        [ 7196],
        [ 7460],
        [ 7755],
        [ 9186],
        [ 8174]], device='cuda:0')
[2024-07-24 10:31:20,753][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[13964],
        [38662],
        [29853],
        [31993],
        [30273],
        [29335],
        [27825],
        [30377],
        [31730],
        [30158],
        [29798],
        [30004],
        [28651],
        [28146],
        [28929]], device='cuda:0')
[2024-07-24 10:31:20,754][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[24154],
        [16814],
        [15313],
        [18782],
        [20678],
        [21993],
        [20821],
        [22153],
        [21356],
        [21792],
        [21604],
        [22253],
        [21134],
        [21730],
        [20932]], device='cuda:0')
[2024-07-24 10:31:20,756][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[37942],
        [32709],
        [25751],
        [25780],
        [17273],
        [24958],
        [28409],
        [30940],
        [31986],
        [32756],
        [32537],
        [32807],
        [32078],
        [33210],
        [33488]], device='cuda:0')
[2024-07-24 10:31:20,758][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[ 7428],
        [18594],
        [15911],
        [17437],
        [18055],
        [17491],
        [16757],
        [18493],
        [19289],
        [17718],
        [17762],
        [17461],
        [18753],
        [16671],
        [15410]], device='cuda:0')
[2024-07-24 10:31:20,759][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[19198],
        [14903],
        [ 9918],
        [16988],
        [12056],
        [21984],
        [19515],
        [20901],
        [21469],
        [20995],
        [22139],
        [21519],
        [18359],
        [21284],
        [21505]], device='cuda:0')
[2024-07-24 10:31:20,761][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[37752],
        [38183],
        [41126],
        [39190],
        [41241],
        [38531],
        [37774],
        [38935],
        [36740],
        [34935],
        [35719],
        [36857],
        [36491],
        [35053],
        [35928]], device='cuda:0')
[2024-07-24 10:31:20,763][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[23735],
        [40766],
        [39955],
        [40293],
        [39849],
        [39088],
        [22826],
        [27993],
        [27642],
        [43472],
        [42724],
        [43122],
        [45768],
        [45915],
        [43119]], device='cuda:0')
[2024-07-24 10:31:20,764][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[2552],
        [2552],
        [2552],
        [2552],
        [2552],
        [2552],
        [2552],
        [2552],
        [2552],
        [2552],
        [2552],
        [2552],
        [2552],
        [2552],
        [2552]], device='cuda:0')
[2024-07-24 10:31:20,871][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:31:20,873][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:20,874][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:20,875][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:20,877][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:20,878][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:20,879][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:20,880][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:20,881][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:20,882][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:20,883][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:20,884][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:20,885][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:20,887][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.1187, 0.8813], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:20,889][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0103, 0.9897], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:20,890][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.3048, 0.6952], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:20,892][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0599, 0.9401], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:20,893][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.8418, 0.1582], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:20,895][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0336, 0.9664], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:20,896][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.9642, 0.0358], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:20,898][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.3293, 0.6707], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:20,900][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0059, 0.9941], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:20,901][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0558, 0.9442], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:20,903][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0025, 0.9975], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:20,904][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0186, 0.9814], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:20,905][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Melissa] are: tensor([0.0108, 0.7084, 0.2808], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:20,906][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Melissa] are: tensor([4.6363e-05, 5.3386e-02, 9.4657e-01], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:20,906][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Melissa] are: tensor([0.0139, 0.4360, 0.5501], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:20,907][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Melissa] are: tensor([0.0077, 0.3950, 0.5973], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:20,909][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Melissa] are: tensor([0.3712, 0.1525, 0.4763], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:20,910][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Melissa] are: tensor([0.0102, 0.5026, 0.4873], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:20,912][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Melissa] are: tensor([0.6073, 0.0552, 0.3375], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:20,913][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Melissa] are: tensor([0.2508, 0.3352, 0.4140], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:20,915][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Melissa] are: tensor([0.0027, 0.5795, 0.4178], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:20,916][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Melissa] are: tensor([0.0050, 0.9606, 0.0344], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:20,917][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Melissa] are: tensor([7.4430e-04, 9.5690e-01, 4.2355e-02], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:20,919][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Melissa] are: tensor([0.0075, 0.7407, 0.2518], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:20,921][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0205, 0.4640, 0.1815, 0.3340], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:20,922][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ and] are: tensor([1.3204e-04, 5.3945e-02, 7.6291e-01, 1.8301e-01], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:20,923][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0157, 0.2340, 0.2758, 0.4745], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:20,925][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0078, 0.3365, 0.4775, 0.1781], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:20,927][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.3274, 0.2058, 0.3481, 0.1187], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:20,928][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0078, 0.3235, 0.3602, 0.3085], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:20,930][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.5768, 0.0581, 0.2473, 0.1177], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:20,931][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0977, 0.2588, 0.3074, 0.3361], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:20,931][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0024, 0.4082, 0.2255, 0.3639], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:20,932][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ and] are: tensor([8.0774e-04, 8.2680e-01, 4.8043e-02, 1.2435e-01], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:20,933][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ and] are: tensor([1.8944e-04, 3.1968e-01, 2.8757e-02, 6.5137e-01], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:20,934][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0019, 0.2025, 0.0917, 0.7039], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:20,936][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Benjamin] are: tensor([0.0037, 0.2673, 0.1499, 0.1580, 0.4211], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:20,937][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Benjamin] are: tensor([2.6898e-05, 4.1020e-02, 8.1240e-01, 1.0208e-01, 4.4469e-02],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:20,939][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Benjamin] are: tensor([0.0032, 0.1687, 0.1773, 0.3525, 0.2983], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:20,940][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Benjamin] are: tensor([0.0094, 0.2515, 0.3855, 0.1188, 0.2347], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:20,942][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Benjamin] are: tensor([0.1800, 0.1954, 0.3140, 0.0701, 0.2406], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:20,943][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Benjamin] are: tensor([0.0029, 0.2186, 0.3355, 0.2653, 0.1778], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:20,945][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Benjamin] are: tensor([0.6494, 0.0197, 0.1661, 0.0410, 0.1239], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:20,947][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Benjamin] are: tensor([0.1136, 0.1905, 0.1226, 0.1295, 0.4438], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:20,948][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Benjamin] are: tensor([0.0031, 0.5001, 0.1797, 0.2353, 0.0818], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:20,949][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Benjamin] are: tensor([3.0944e-05, 8.0460e-01, 4.8234e-02, 1.4633e-01, 8.0626e-04],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:20,950][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Benjamin] are: tensor([1.8177e-04, 3.3397e-01, 3.5997e-02, 6.2234e-01, 7.5106e-03],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:20,952][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Benjamin] are: tensor([0.0028, 0.2740, 0.0505, 0.4152, 0.2574], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:20,954][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.0025, 0.1861, 0.1766, 0.1356, 0.2413, 0.2580], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:20,955][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ had] are: tensor([7.9474e-05, 4.6021e-02, 6.8677e-01, 1.2259e-01, 7.2494e-02, 7.2043e-02],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:20,957][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.0044, 0.1296, 0.1490, 0.2541, 0.2145, 0.2484], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:20,957][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.0041, 0.2075, 0.3141, 0.1103, 0.1990, 0.1650], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:20,958][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.0826, 0.1264, 0.3230, 0.1028, 0.3073, 0.0579], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:20,959][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.0039, 0.1815, 0.2569, 0.2086, 0.1438, 0.2053], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:20,960][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.2803, 0.0227, 0.1211, 0.0422, 0.0853, 0.4484], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:20,961][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.0374, 0.1533, 0.0715, 0.1143, 0.2578, 0.3657], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:20,963][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.0007, 0.5727, 0.0918, 0.1722, 0.0408, 0.1218], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:20,964][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ had] are: tensor([3.4538e-03, 8.2683e-01, 2.8919e-02, 6.8320e-02, 5.4224e-04, 7.1935e-02],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:20,965][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ had] are: tensor([1.4390e-04, 3.5518e-01, 3.2174e-02, 5.8154e-01, 1.2321e-02, 1.8646e-02],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:20,966][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0043, 0.1816, 0.0611, 0.3717, 0.3247, 0.0566], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:20,968][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0004, 0.1913, 0.1587, 0.0706, 0.3194, 0.2587, 0.0008],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:20,969][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ a] are: tensor([6.1581e-06, 5.3510e-02, 6.7807e-01, 4.2283e-02, 3.0258e-02, 1.9584e-01,
        3.1240e-05], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:20,971][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0003, 0.2380, 0.1194, 0.2310, 0.1767, 0.2304, 0.0042],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:20,972][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0059, 0.1612, 0.3186, 0.1254, 0.1919, 0.1871, 0.0098],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:20,974][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0988, 0.1627, 0.1742, 0.1151, 0.1981, 0.1150, 0.1362],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:20,976][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0011, 0.1271, 0.2475, 0.1738, 0.2156, 0.2130, 0.0219],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:20,978][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0114, 0.0651, 0.1785, 0.0596, 0.1106, 0.5587, 0.0162],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:20,979][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0151, 0.2481, 0.1671, 0.1363, 0.1808, 0.2146, 0.0380],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:20,981][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0019, 0.1570, 0.3416, 0.1072, 0.1072, 0.2819, 0.0032],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:20,983][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0016, 0.5922, 0.0583, 0.2453, 0.0153, 0.0841, 0.0033],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:20,983][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ a] are: tensor([1.5725e-05, 6.0654e-01, 5.3467e-02, 2.6875e-01, 9.7953e-03, 6.1385e-02,
        4.7305e-05], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:20,984][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0014, 0.2021, 0.1461, 0.1153, 0.1902, 0.3402, 0.0047],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:20,985][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.0012, 0.1127, 0.0864, 0.1447, 0.0948, 0.1475, 0.0024, 0.4103],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:20,986][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ long] are: tensor([2.4971e-05, 4.7449e-02, 6.0434e-01, 1.3489e-01, 2.7760e-02, 8.0602e-02,
        2.1539e-04, 1.0472e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:20,988][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.0035, 0.0972, 0.1035, 0.1934, 0.1460, 0.1742, 0.0247, 0.2576],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:20,989][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ long] are: tensor([0.0030, 0.1557, 0.2674, 0.0809, 0.1442, 0.1288, 0.0048, 0.2152],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:20,991][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.0699, 0.1415, 0.1799, 0.0791, 0.1618, 0.0508, 0.1282, 0.1887],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:20,993][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ long] are: tensor([0.0020, 0.1528, 0.2024, 0.1725, 0.1219, 0.1765, 0.0176, 0.1541],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:20,994][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.1665, 0.0078, 0.0453, 0.0154, 0.0295, 0.1585, 0.1530, 0.4240],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:20,996][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.0144, 0.1312, 0.0650, 0.1239, 0.1872, 0.2526, 0.0422, 0.1836],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:20,998][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.0004, 0.3067, 0.1739, 0.1861, 0.0281, 0.1020, 0.0018, 0.2011],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:20,999][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ long] are: tensor([3.9149e-04, 8.5896e-01, 1.1094e-02, 5.9696e-02, 3.0227e-04, 6.2674e-02,
        1.4994e-03, 5.3867e-03], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:21,000][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ long] are: tensor([2.2324e-05, 2.5894e-01, 3.0576e-02, 6.8469e-01, 6.3027e-03, 1.7356e-02,
        9.8869e-05, 2.0159e-03], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:21,002][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ long] are: tensor([0.0018, 0.1371, 0.0431, 0.2776, 0.2390, 0.0807, 0.0101, 0.2106],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:21,004][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.0005, 0.0527, 0.0551, 0.0801, 0.0476, 0.1261, 0.0012, 0.3417, 0.2949],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:21,005][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([1.7819e-05, 2.4441e-02, 3.6402e-01, 5.1630e-02, 1.7084e-02, 5.6547e-02,
        1.1810e-04, 6.3358e-02, 4.2278e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:21,006][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.0012, 0.0766, 0.0755, 0.1447, 0.1032, 0.1353, 0.0108, 0.2241, 0.2287],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:21,008][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([0.0016, 0.0928, 0.1587, 0.0562, 0.0943, 0.0936, 0.0031, 0.1276, 0.3721],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:21,009][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.0492, 0.0768, 0.2147, 0.0352, 0.1568, 0.0359, 0.0748, 0.1336, 0.2230],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:21,010][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([0.0006, 0.1352, 0.2091, 0.1596, 0.1036, 0.1452, 0.0087, 0.1455, 0.0925],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:21,011][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.2518, 0.0031, 0.0464, 0.0095, 0.0195, 0.1154, 0.2031, 0.2857, 0.0656],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:21,011][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.0080, 0.0527, 0.0276, 0.0531, 0.0662, 0.1009, 0.0270, 0.0657, 0.5989],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:21,013][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.0004, 0.1991, 0.2379, 0.0972, 0.0524, 0.0898, 0.0013, 0.0879, 0.2339],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:21,014][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([2.1356e-04, 9.2508e-01, 5.8137e-03, 3.1399e-02, 9.7892e-05, 2.4543e-02,
        8.2659e-04, 3.0144e-03, 9.0154e-03], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:21,015][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([8.2707e-05, 2.6460e-01, 5.0285e-02, 6.3636e-01, 9.0526e-03, 2.7960e-02,
        3.1169e-04, 2.6320e-03, 8.7183e-03], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:21,017][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([0.0021, 0.0948, 0.0390, 0.2767, 0.2208, 0.0606, 0.0103, 0.0694, 0.2263],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:21,019][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0007, 0.0649, 0.0345, 0.0425, 0.0856, 0.0707, 0.0021, 0.3058, 0.3372,
        0.0560], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:21,020][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [,] are: tensor([1.0755e-05, 1.8422e-02, 3.0995e-01, 4.1183e-02, 2.2979e-02, 4.2484e-02,
        1.0945e-04, 4.8964e-02, 4.7790e-01, 3.7995e-02], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:21,022][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0012, 0.0703, 0.0771, 0.1243, 0.1039, 0.1176, 0.0089, 0.2015, 0.1629,
        0.1323], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:21,024][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0015, 0.0870, 0.1440, 0.0489, 0.0879, 0.0775, 0.0032, 0.1249, 0.3562,
        0.0689], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:21,025][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0317, 0.0593, 0.1932, 0.0320, 0.1885, 0.0279, 0.0653, 0.1025, 0.2846,
        0.0150], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:21,027][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0019, 0.1547, 0.1686, 0.1538, 0.0901, 0.1215, 0.0088, 0.1108, 0.0666,
        0.1233], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:21,029][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.1038, 0.0076, 0.0471, 0.0149, 0.0346, 0.1653, 0.1305, 0.3475, 0.1240,
        0.0248], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:21,030][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0032, 0.0828, 0.0450, 0.0646, 0.1544, 0.1239, 0.0134, 0.0789, 0.2977,
        0.1361], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:21,032][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [,] are: tensor([1.2300e-04, 2.8324e-01, 9.1117e-02, 1.1493e-01, 2.3453e-02, 8.1026e-02,
        6.3647e-04, 9.5341e-02, 8.9380e-02, 2.2075e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:21,033][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [,] are: tensor([3.9383e-04, 6.8349e-01, 3.8102e-02, 8.2407e-02, 1.4704e-03, 9.5475e-02,
        1.7481e-03, 2.1168e-02, 6.2129e-02, 1.3616e-02], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:21,034][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [,] are: tensor([4.0391e-05, 2.7349e-01, 4.8173e-02, 5.7828e-01, 1.6138e-02, 1.8901e-02,
        2.1278e-04, 4.1743e-03, 1.0880e-02, 4.9712e-02], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:21,035][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [,] are: tensor([2.8584e-04, 4.9409e-02, 2.0334e-02, 1.1525e-01, 2.0089e-01, 2.5373e-02,
        2.0100e-03, 7.2567e-02, 3.4632e-01, 1.6757e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:21,036][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0008, 0.1324, 0.0324, 0.0762, 0.1144, 0.1000, 0.0023, 0.2006, 0.2463,
        0.0624, 0.0320], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:21,036][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ and] are: tensor([1.5737e-05, 2.0437e-02, 2.8419e-01, 5.3477e-02, 2.9274e-02, 5.2077e-02,
        1.5724e-04, 6.0165e-02, 4.2487e-01, 3.7284e-02, 3.8050e-02],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:21,038][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0012, 0.0540, 0.0615, 0.1082, 0.0896, 0.0957, 0.0097, 0.1696, 0.1487,
        0.1194, 0.1423], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:21,039][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0015, 0.0789, 0.1239, 0.0515, 0.0728, 0.0749, 0.0034, 0.1178, 0.3203,
        0.0711, 0.0840], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:21,041][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0436, 0.0741, 0.1851, 0.0392, 0.2098, 0.0367, 0.0824, 0.0732, 0.2158,
        0.0152, 0.0247], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:21,043][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0015, 0.1324, 0.1559, 0.1279, 0.0709, 0.1052, 0.0067, 0.0945, 0.0500,
        0.1076, 0.1474], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:21,044][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0792, 0.0083, 0.0409, 0.0177, 0.0327, 0.1850, 0.1046, 0.3343, 0.1194,
        0.0279, 0.0499], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:21,045][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0037, 0.0481, 0.0326, 0.0683, 0.1083, 0.1246, 0.0140, 0.0601, 0.2993,
        0.1473, 0.0938], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:21,047][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0006, 0.1320, 0.0875, 0.1335, 0.0303, 0.1234, 0.0023, 0.0947, 0.0983,
        0.1129, 0.1845], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:21,048][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ and] are: tensor([1.4546e-04, 4.5981e-01, 4.0518e-02, 1.8085e-01, 3.6007e-03, 1.6534e-01,
        1.0603e-03, 2.6386e-02, 8.7267e-02, 2.6010e-02, 9.0163e-03],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:21,050][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ and] are: tensor([5.5119e-05, 2.8735e-01, 3.6462e-02, 5.1530e-01, 1.3570e-02, 2.4649e-02,
        2.7497e-04, 4.3085e-03, 9.0670e-03, 5.2730e-02, 5.6232e-02],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:21,051][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0003, 0.0385, 0.0192, 0.1317, 0.1587, 0.0294, 0.0023, 0.0442, 0.2197,
        0.1487, 0.2072], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:21,053][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([5.9945e-05, 1.7147e-01, 3.6173e-02, 6.3986e-02, 1.0609e-01, 1.4666e-01,
        2.2414e-04, 1.9767e-01, 1.5766e-01, 3.8491e-02, 1.8022e-02, 6.3496e-02],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:21,054][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([1.4583e-06, 5.9468e-02, 2.6719e-01, 7.3751e-02, 1.4842e-02, 9.0365e-02,
        1.4751e-05, 5.9969e-02, 3.0347e-01, 5.8762e-02, 4.2054e-02, 3.0112e-02],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:21,056][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.0004, 0.0592, 0.0533, 0.0955, 0.0764, 0.0876, 0.0036, 0.1519, 0.1208,
        0.1113, 0.1338, 0.1063], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:21,058][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([0.0011, 0.1369, 0.1164, 0.0642, 0.0715, 0.0838, 0.0017, 0.1075, 0.2411,
        0.0697, 0.0800, 0.0260], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:21,059][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.0088, 0.0962, 0.1685, 0.0408, 0.2092, 0.0296, 0.0251, 0.0906, 0.1951,
        0.0133, 0.0177, 0.1052], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:21,060][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([0.0004, 0.1017, 0.1381, 0.1141, 0.0712, 0.1158, 0.0046, 0.1050, 0.0659,
        0.0991, 0.1492, 0.0350], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:21,061][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.0143, 0.0078, 0.0262, 0.0135, 0.0210, 0.1605, 0.0203, 0.3118, 0.0945,
        0.0219, 0.0388, 0.2693], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:21,062][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.0010, 0.1390, 0.0501, 0.0643, 0.1347, 0.1148, 0.0046, 0.0564, 0.2170,
        0.1280, 0.0683, 0.0219], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:21,063][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([9.4644e-05, 1.2969e-01, 6.3250e-02, 9.3052e-02, 2.1328e-02, 9.4971e-02,
        4.6735e-04, 7.2944e-02, 1.1804e-01, 1.7037e-01, 2.1009e-01, 2.5698e-02],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:21,064][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([3.2209e-06, 6.1955e-01, 2.7421e-02, 1.5109e-01, 8.3354e-04, 1.5179e-01,
        2.7738e-05, 1.0596e-02, 3.0920e-02, 5.6183e-03, 1.9929e-03, 1.5775e-04],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:21,065][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([1.0433e-06, 5.0089e-01, 1.0465e-02, 4.2616e-01, 2.2805e-03, 1.3566e-02,
        6.2169e-06, 7.3628e-04, 1.4574e-03, 2.4442e-02, 1.9959e-02, 3.8195e-05],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:21,066][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([8.9781e-05, 5.6043e-02, 3.1446e-02, 1.3819e-01, 9.7367e-02, 7.1770e-02,
        5.3104e-04, 1.0018e-01, 1.3932e-01, 1.0492e-01, 1.5765e-01, 1.0249e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:21,068][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Melissa] are: tensor([2.0531e-04, 2.6136e-01, 4.6051e-02, 9.9088e-02, 9.0377e-02, 8.8326e-02,
        4.0894e-04, 1.4058e-01, 7.9276e-02, 6.5498e-02, 2.8187e-02, 5.7078e-02,
        4.3558e-02], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:21,069][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Melissa] are: tensor([1.8336e-06, 4.1893e-02, 3.4151e-01, 5.5322e-02, 1.1264e-02, 4.7810e-02,
        1.4559e-05, 2.0647e-02, 1.0185e-01, 5.1080e-02, 3.4573e-02, 2.1972e-02,
        2.7206e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:21,071][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Melissa] are: tensor([0.0002, 0.0554, 0.0468, 0.1050, 0.0639, 0.0780, 0.0020, 0.1506, 0.1080,
        0.0983, 0.1378, 0.1010, 0.0530], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:21,072][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Melissa] are: tensor([0.0008, 0.1090, 0.1080, 0.0513, 0.0598, 0.0686, 0.0011, 0.0786, 0.1633,
        0.0626, 0.0687, 0.0305, 0.1977], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:21,074][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Melissa] are: tensor([0.0429, 0.0676, 0.1487, 0.0289, 0.0849, 0.0106, 0.0623, 0.0436, 0.0972,
        0.0122, 0.0171, 0.1006, 0.2833], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:21,076][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Melissa] are: tensor([0.0007, 0.0911, 0.1330, 0.1083, 0.0766, 0.1010, 0.0070, 0.0940, 0.0593,
        0.0876, 0.1302, 0.0329, 0.0783], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:21,078][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Melissa] are: tensor([0.0439, 0.0084, 0.0439, 0.0126, 0.0266, 0.1106, 0.0457, 0.2863, 0.0708,
        0.0240, 0.0341, 0.1894, 0.1037], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:21,080][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Melissa] are: tensor([0.0034, 0.0878, 0.0586, 0.0688, 0.1533, 0.1220, 0.0133, 0.0463, 0.1863,
        0.1269, 0.0489, 0.0250, 0.0593], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:21,081][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Melissa] are: tensor([1.5681e-04, 2.1403e-01, 8.8167e-02, 7.5698e-02, 2.1978e-02, 5.6750e-02,
        6.1247e-04, 4.6386e-02, 6.1921e-02, 1.7733e-01, 1.8778e-01, 1.6969e-02,
        5.2224e-02], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:21,082][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Melissa] are: tensor([4.4816e-05, 6.0867e-01, 1.9473e-02, 1.7421e-01, 2.6383e-03, 9.5566e-02,
        3.4633e-04, 1.6879e-02, 6.1611e-02, 1.3080e-02, 5.9278e-03, 1.2443e-03,
        3.1263e-04], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:21,083][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Melissa] are: tensor([2.1265e-05, 5.0961e-01, 1.2229e-02, 3.7112e-01, 1.8722e-03, 1.2096e-02,
        7.4773e-05, 6.6584e-04, 1.1306e-03, 4.7953e-02, 4.2972e-02, 5.0294e-05,
        2.0317e-04], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:21,085][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Melissa] are: tensor([1.4906e-04, 1.2640e-01, 2.1999e-02, 1.6144e-01, 5.5680e-02, 4.5181e-02,
        6.6623e-04, 7.9359e-02, 5.5795e-02, 1.1601e-01, 1.5965e-01, 5.7446e-02,
        1.2021e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:21,086][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.0002, 0.0909, 0.0315, 0.0778, 0.0473, 0.0815, 0.0005, 0.1506, 0.1961,
        0.0593, 0.0252, 0.0948, 0.0327, 0.1115], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:21,087][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ said] are: tensor([5.4873e-06, 4.0544e-02, 1.3990e-01, 5.3829e-02, 1.0538e-02, 2.5193e-02,
        4.7099e-05, 2.4100e-02, 1.3513e-01, 4.4123e-02, 3.4151e-02, 3.6635e-02,
        1.0481e-01, 3.5100e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:21,088][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.0003, 0.0488, 0.0465, 0.0881, 0.0609, 0.0734, 0.0035, 0.1290, 0.1111,
        0.0935, 0.1197, 0.0996, 0.0590, 0.0666], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:21,089][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ said] are: tensor([0.0004, 0.0716, 0.0792, 0.0392, 0.0445, 0.0487, 0.0010, 0.0624, 0.1693,
        0.0508, 0.0586, 0.0269, 0.1493, 0.1980], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:21,090][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.0136, 0.0387, 0.1779, 0.0499, 0.1410, 0.0214, 0.0313, 0.0564, 0.0917,
        0.0108, 0.0168, 0.0741, 0.1951, 0.0814], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:21,092][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ said] are: tensor([0.0009, 0.0794, 0.1320, 0.0975, 0.0556, 0.0819, 0.0062, 0.0763, 0.0446,
        0.0853, 0.1182, 0.0233, 0.0691, 0.1298], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:21,094][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.0470, 0.0059, 0.0366, 0.0168, 0.0250, 0.1056, 0.0620, 0.2309, 0.0823,
        0.0217, 0.0292, 0.1664, 0.0873, 0.0833], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:21,095][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.0047, 0.0581, 0.0346, 0.0669, 0.0592, 0.0902, 0.0159, 0.0635, 0.1567,
        0.1027, 0.0593, 0.0155, 0.0278, 0.2449], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:21,097][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ said] are: tensor([8.4278e-05, 1.8635e-01, 7.4137e-02, 8.4619e-02, 2.3773e-02, 1.0419e-01,
        4.7026e-04, 4.1743e-02, 6.0217e-02, 1.3269e-01, 1.1319e-01, 1.1195e-02,
        3.1670e-02, 1.3567e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:21,098][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ said] are: tensor([1.4153e-04, 6.9107e-01, 4.2593e-02, 1.3028e-01, 3.3201e-04, 7.0482e-02,
        4.9521e-04, 6.8585e-03, 1.3591e-02, 6.2115e-03, 1.9131e-03, 9.4140e-05,
        1.0137e-04, 3.5837e-02], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:21,099][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ said] are: tensor([1.8002e-05, 3.6846e-01, 1.7131e-02, 4.4611e-01, 3.8888e-03, 1.1347e-02,
        8.5914e-05, 1.4576e-03, 4.8677e-03, 5.1475e-02, 4.4281e-02, 1.3406e-04,
        3.6739e-04, 5.0375e-02], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:21,101][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ said] are: tensor([2.5078e-04, 1.3761e-02, 1.0284e-02, 6.2679e-02, 3.7378e-02, 1.1870e-02,
        1.4882e-03, 3.9668e-02, 7.6641e-02, 6.6311e-02, 7.6288e-02, 9.2305e-02,
        1.1869e-01, 3.9239e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:21,102][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ to] are: tensor([1.0357e-04, 5.3829e-02, 1.7122e-02, 3.8878e-02, 3.7481e-02, 5.9358e-02,
        3.6432e-04, 1.3414e-01, 1.9954e-01, 4.7455e-02, 1.9087e-02, 8.6418e-02,
        4.7446e-02, 9.9877e-02, 1.5890e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:21,103][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ to] are: tensor([1.5582e-06, 1.0199e-02, 7.8258e-02, 2.0622e-02, 1.0568e-02, 1.8429e-02,
        1.8158e-05, 1.8959e-02, 2.1158e-01, 2.2673e-02, 1.9732e-02, 2.7134e-02,
        1.3876e-01, 2.0230e-01, 2.2078e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:21,105][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0005, 0.0399, 0.0425, 0.0815, 0.0580, 0.0659, 0.0046, 0.1158, 0.0955,
        0.0877, 0.1051, 0.0878, 0.0532, 0.0557, 0.1064], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:21,107][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0004, 0.0556, 0.0646, 0.0313, 0.0362, 0.0431, 0.0008, 0.0564, 0.1588,
        0.0425, 0.0504, 0.0230, 0.1363, 0.1774, 0.1231], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:21,109][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0064, 0.0250, 0.0919, 0.0243, 0.0703, 0.0200, 0.0153, 0.0467, 0.1333,
        0.0111, 0.0185, 0.0766, 0.2895, 0.0932, 0.0778], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:21,110][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0009, 0.0766, 0.1085, 0.0859, 0.0499, 0.0748, 0.0053, 0.0679, 0.0404,
        0.0763, 0.1040, 0.0249, 0.0614, 0.1170, 0.1064], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:21,112][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0243, 0.0053, 0.0307, 0.0106, 0.0215, 0.0926, 0.0326, 0.2305, 0.0882,
        0.0196, 0.0300, 0.1785, 0.1103, 0.0658, 0.0596], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:21,113][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0013, 0.0354, 0.0360, 0.0425, 0.0778, 0.0748, 0.0057, 0.0361, 0.1786,
        0.0930, 0.0580, 0.0155, 0.0555, 0.2080, 0.0818], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:21,114][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ to] are: tensor([5.0811e-05, 1.1531e-01, 4.6286e-02, 6.1112e-02, 1.2551e-02, 9.4090e-02,
        3.0885e-04, 4.3659e-02, 5.1618e-02, 1.0318e-01, 9.1434e-02, 1.4925e-02,
        2.6379e-02, 6.7440e-02, 2.7165e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:21,115][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ to] are: tensor([4.9672e-05, 5.6514e-01, 2.5827e-02, 9.6063e-02, 8.1979e-04, 1.5130e-01,
        3.4696e-04, 1.5894e-02, 2.9896e-02, 1.0564e-02, 2.7032e-03, 2.8877e-04,
        2.3419e-04, 8.8913e-02, 1.1963e-02], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:21,116][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ to] are: tensor([9.5010e-06, 2.7532e-01, 1.8065e-02, 4.6555e-01, 6.3127e-03, 1.3708e-02,
        5.1530e-05, 1.6753e-03, 6.4219e-03, 5.1088e-02, 4.7675e-02, 2.3114e-04,
        5.1424e-04, 4.2491e-02, 7.0887e-02], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:21,117][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ to] are: tensor([2.9709e-05, 4.7713e-03, 4.8798e-03, 2.6816e-02, 2.6239e-02, 4.7017e-03,
        2.0770e-04, 1.2924e-02, 5.9522e-02, 3.4934e-02, 4.5022e-02, 3.0443e-02,
        9.0873e-02, 1.9233e-01, 4.6630e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:21,225][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:31:21,226][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:21,228][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:21,229][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:21,230][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:21,231][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:21,232][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:21,232][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:21,233][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:21,234][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:21,235][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:21,236][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:21,236][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:21,237][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.1187, 0.8813], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:21,238][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0103, 0.9897], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:21,239][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0435, 0.9565], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:21,240][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.1432, 0.8568], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:21,242][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.8848, 0.1152], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:21,243][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.1075, 0.8925], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:21,245][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.2148, 0.7852], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:21,246][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.3293, 0.6707], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:21,248][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0059, 0.9941], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:21,250][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0558, 0.9442], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:21,251][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0025, 0.9975], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:21,253][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0186, 0.9814], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:21,254][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Melissa] are: tensor([0.0108, 0.7084, 0.2808], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:21,255][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Melissa] are: tensor([4.6363e-05, 5.3386e-02, 9.4657e-01], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:21,257][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Melissa] are: tensor([0.0068, 0.4625, 0.5306], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:21,259][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Melissa] are: tensor([0.0046, 0.3181, 0.6773], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:21,260][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Melissa] are: tensor([0.4948, 0.1618, 0.3434], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:21,261][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Melissa] are: tensor([0.0041, 0.7377, 0.2581], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:21,262][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Melissa] are: tensor([0.0075, 0.1558, 0.8368], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:21,263][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Melissa] are: tensor([0.2508, 0.3352, 0.4140], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:21,263][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Melissa] are: tensor([0.0027, 0.5795, 0.4178], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:21,264][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Melissa] are: tensor([0.0050, 0.9606, 0.0344], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:21,265][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Melissa] are: tensor([7.4430e-04, 9.5690e-01, 4.2355e-02], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:21,267][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Melissa] are: tensor([0.0075, 0.7407, 0.2518], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:21,268][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0205, 0.4640, 0.1815, 0.3340], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:21,269][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([1.3204e-04, 5.3945e-02, 7.6291e-01, 1.8301e-01], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:21,271][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0027, 0.2304, 0.0593, 0.7076], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:21,272][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0070, 0.1846, 0.3094, 0.4990], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:21,274][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.4345, 0.2179, 0.2460, 0.1016], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:21,275][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0016, 0.6014, 0.3217, 0.0753], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:21,277][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0087, 0.1073, 0.7112, 0.1728], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:21,279][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0977, 0.2588, 0.3074, 0.3361], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:21,280][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0024, 0.4082, 0.2255, 0.3639], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:21,282][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([8.0774e-04, 8.2680e-01, 4.8043e-02, 1.2435e-01], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:21,283][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([1.8944e-04, 3.1968e-01, 2.8757e-02, 6.5137e-01], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:21,284][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0019, 0.2025, 0.0917, 0.7039], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:21,286][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Benjamin] are: tensor([0.0037, 0.2673, 0.1499, 0.1580, 0.4211], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:21,287][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Benjamin] are: tensor([2.6898e-05, 4.1020e-02, 8.1240e-01, 1.0208e-01, 4.4469e-02],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:21,288][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Benjamin] are: tensor([0.0022, 0.0959, 0.0417, 0.2912, 0.5690], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:21,288][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Benjamin] are: tensor([0.0067, 0.1440, 0.3218, 0.2599, 0.2676], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:21,289][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Benjamin] are: tensor([0.2503, 0.2238, 0.2260, 0.0612, 0.2387], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:21,290][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Benjamin] are: tensor([2.0468e-04, 7.0945e-01, 2.1092e-01, 7.0309e-02, 9.1210e-03],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:21,291][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Benjamin] are: tensor([0.0042, 0.0514, 0.4333, 0.0638, 0.4473], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:21,293][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Benjamin] are: tensor([0.1136, 0.1905, 0.1226, 0.1295, 0.4438], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:21,295][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Benjamin] are: tensor([0.0031, 0.5001, 0.1797, 0.2353, 0.0818], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:21,296][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Benjamin] are: tensor([3.0944e-05, 8.0460e-01, 4.8234e-02, 1.4633e-01, 8.0626e-04],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:21,297][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Benjamin] are: tensor([1.8177e-04, 3.3397e-01, 3.5997e-02, 6.2234e-01, 7.5106e-03],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:21,298][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Benjamin] are: tensor([0.0028, 0.2740, 0.0505, 0.4152, 0.2574], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:21,300][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.0025, 0.1861, 0.1766, 0.1356, 0.2413, 0.2580], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:21,301][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([7.9474e-05, 4.6021e-02, 6.8677e-01, 1.2259e-01, 7.2494e-02, 7.2043e-02],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:21,303][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.0020, 0.1251, 0.0380, 0.2804, 0.3406, 0.2140], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:21,304][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.0021, 0.0873, 0.2578, 0.2178, 0.1937, 0.2413], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:21,306][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.1191, 0.1433, 0.2677, 0.1028, 0.3200, 0.0471], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:21,308][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.0083, 0.6106, 0.1140, 0.0403, 0.0038, 0.2230], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:21,309][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.0036, 0.0311, 0.2925, 0.0454, 0.2957, 0.3316], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:21,311][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.0374, 0.1533, 0.0715, 0.1143, 0.2578, 0.3657], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:21,313][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.0007, 0.5727, 0.0918, 0.1722, 0.0408, 0.1218], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:21,314][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([3.4538e-03, 8.2683e-01, 2.8919e-02, 6.8320e-02, 5.4224e-04, 7.1935e-02],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:21,314][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([1.4390e-04, 3.5518e-01, 3.2174e-02, 5.8154e-01, 1.2321e-02, 1.8646e-02],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:21,315][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.0043, 0.1816, 0.0611, 0.3717, 0.3247, 0.0566], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:21,316][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0004, 0.1913, 0.1587, 0.0706, 0.3194, 0.2587, 0.0008],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:21,317][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([6.1581e-06, 5.3510e-02, 6.7807e-01, 4.2283e-02, 3.0258e-02, 1.9584e-01,
        3.1240e-05], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:21,319][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0005, 0.0767, 0.1013, 0.1439, 0.2252, 0.4506, 0.0019],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:21,320][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0054, 0.0904, 0.3101, 0.1280, 0.1909, 0.2642, 0.0110],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:21,322][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.1065, 0.1678, 0.1638, 0.1136, 0.1986, 0.1049, 0.1447],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:21,324][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0082, 0.4261, 0.1420, 0.1284, 0.0719, 0.2068, 0.0166],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:21,325][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0008, 0.0820, 0.3051, 0.0456, 0.1876, 0.3770, 0.0019],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:21,327][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0151, 0.2481, 0.1671, 0.1363, 0.1808, 0.2146, 0.0380],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:21,329][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0019, 0.1570, 0.3416, 0.1072, 0.1072, 0.2819, 0.0032],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:21,330][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0016, 0.5922, 0.0583, 0.2453, 0.0153, 0.0841, 0.0033],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:21,331][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([1.5725e-05, 6.0654e-01, 5.3467e-02, 2.6875e-01, 9.7953e-03, 6.1385e-02,
        4.7305e-05], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:21,333][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0014, 0.2021, 0.1461, 0.1153, 0.1902, 0.3402, 0.0047],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:21,335][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.0012, 0.1127, 0.0864, 0.1447, 0.0948, 0.1475, 0.0024, 0.4103],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:21,336][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([2.4971e-05, 4.7449e-02, 6.0434e-01, 1.3489e-01, 2.7760e-02, 8.0602e-02,
        2.1539e-04, 1.0472e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:21,338][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([0.0008, 0.0791, 0.0439, 0.1990, 0.2484, 0.1758, 0.0040, 0.2491],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:21,339][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([0.0008, 0.0448, 0.2061, 0.1195, 0.0946, 0.1386, 0.0034, 0.3922],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:21,340][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.0781, 0.1574, 0.1599, 0.0884, 0.1609, 0.0443, 0.1437, 0.1672],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:21,341][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([0.0006, 0.5831, 0.0706, 0.0495, 0.0041, 0.2612, 0.0024, 0.0285],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:21,342][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([4.4594e-04, 7.9940e-03, 6.5842e-02, 1.2068e-02, 7.9658e-02, 9.4060e-02,
        1.7077e-03, 7.3822e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:21,342][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.0144, 0.1312, 0.0650, 0.1239, 0.1872, 0.2526, 0.0422, 0.1836],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:21,344][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.0004, 0.3067, 0.1739, 0.1861, 0.0281, 0.1020, 0.0018, 0.2011],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:21,345][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([3.9149e-04, 8.5896e-01, 1.1094e-02, 5.9696e-02, 3.0227e-04, 6.2674e-02,
        1.4994e-03, 5.3867e-03], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:21,346][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([2.2324e-05, 2.5894e-01, 3.0576e-02, 6.8469e-01, 6.3027e-03, 1.7356e-02,
        9.8869e-05, 2.0159e-03], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:21,348][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([0.0018, 0.1371, 0.0431, 0.2776, 0.2390, 0.0807, 0.0101, 0.2106],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:21,350][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.0005, 0.0527, 0.0551, 0.0801, 0.0476, 0.1261, 0.0012, 0.3417, 0.2949],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:21,351][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([1.7819e-05, 2.4441e-02, 3.6402e-01, 5.1630e-02, 1.7084e-02, 5.6547e-02,
        1.1810e-04, 6.3358e-02, 4.2278e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:21,353][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([0.0007, 0.0605, 0.0288, 0.2072, 0.1508, 0.2011, 0.0035, 0.2185, 0.1290],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:21,354][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([5.5313e-04, 2.0344e-02, 6.8822e-02, 6.4824e-02, 5.0587e-02, 9.9083e-02,
        2.5877e-03, 1.2781e-01, 5.6539e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:21,356][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.0562, 0.0862, 0.2007, 0.0408, 0.1584, 0.0301, 0.0857, 0.1181, 0.2238],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:21,357][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([3.6411e-04, 6.1414e-01, 9.6542e-02, 4.0873e-02, 3.0270e-03, 1.7736e-01,
        1.7799e-03, 2.3454e-02, 4.2463e-02], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:21,359][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.0006, 0.0034, 0.1037, 0.0108, 0.0506, 0.1002, 0.0020, 0.5678, 0.1609],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:21,360][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.0080, 0.0527, 0.0276, 0.0531, 0.0662, 0.1009, 0.0270, 0.0657, 0.5989],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:21,362][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([0.0004, 0.1991, 0.2379, 0.0972, 0.0524, 0.0898, 0.0013, 0.0879, 0.2339],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:21,363][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([2.1356e-04, 9.2508e-01, 5.8137e-03, 3.1399e-02, 9.7892e-05, 2.4543e-02,
        8.2659e-04, 3.0144e-03, 9.0154e-03], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:21,364][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([8.2707e-05, 2.6460e-01, 5.0285e-02, 6.3636e-01, 9.0526e-03, 2.7960e-02,
        3.1169e-04, 2.6320e-03, 8.7183e-03], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:21,366][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([0.0021, 0.0948, 0.0390, 0.2767, 0.2208, 0.0606, 0.0103, 0.0694, 0.2263],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:21,366][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0007, 0.0649, 0.0345, 0.0425, 0.0856, 0.0707, 0.0021, 0.3058, 0.3372,
        0.0560], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:21,367][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([1.0755e-05, 1.8422e-02, 3.0995e-01, 4.1183e-02, 2.2979e-02, 4.2484e-02,
        1.0945e-04, 4.8964e-02, 4.7790e-01, 3.7995e-02], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:21,368][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([1.3769e-04, 5.0553e-02, 1.3983e-02, 2.1386e-01, 2.0539e-01, 1.2671e-01,
        1.2318e-03, 2.2565e-01, 1.0863e-01, 5.3851e-02], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:21,369][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([1.9152e-04, 1.5711e-02, 5.0072e-02, 5.1697e-02, 4.3509e-02, 6.5900e-02,
        1.2402e-03, 1.5103e-01, 5.0652e-01, 1.1413e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:21,370][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0351, 0.0696, 0.1729, 0.0366, 0.1893, 0.0237, 0.0733, 0.0908, 0.2922,
        0.0165], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:21,372][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0004, 0.3577, 0.2017, 0.0527, 0.0091, 0.2818, 0.0018, 0.0321, 0.0540,
        0.0087], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:21,373][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([3.3422e-04, 6.0671e-03, 7.0179e-02, 1.0750e-02, 7.7306e-02, 8.4739e-02,
        1.5422e-03, 4.7649e-01, 2.5428e-01, 1.8307e-02], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:21,375][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0032, 0.0828, 0.0450, 0.0646, 0.1544, 0.1239, 0.0134, 0.0789, 0.2977,
        0.1361], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:21,376][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([1.2300e-04, 2.8324e-01, 9.1117e-02, 1.1493e-01, 2.3453e-02, 8.1026e-02,
        6.3647e-04, 9.5341e-02, 8.9380e-02, 2.2075e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:21,377][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([3.9383e-04, 6.8349e-01, 3.8102e-02, 8.2407e-02, 1.4704e-03, 9.5475e-02,
        1.7481e-03, 2.1168e-02, 6.2129e-02, 1.3616e-02], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:21,379][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([4.0391e-05, 2.7349e-01, 4.8173e-02, 5.7828e-01, 1.6138e-02, 1.8901e-02,
        2.1278e-04, 4.1743e-03, 1.0880e-02, 4.9712e-02], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:21,380][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([2.8584e-04, 4.9409e-02, 2.0334e-02, 1.1525e-01, 2.0089e-01, 2.5373e-02,
        2.0100e-03, 7.2567e-02, 3.4632e-01, 1.6757e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:21,382][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0008, 0.1324, 0.0324, 0.0762, 0.1144, 0.1000, 0.0023, 0.2006, 0.2463,
        0.0624, 0.0320], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:21,383][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([1.5737e-05, 2.0437e-02, 2.8419e-01, 5.3477e-02, 2.9274e-02, 5.2077e-02,
        1.5724e-04, 6.0165e-02, 4.2487e-01, 3.7284e-02, 3.8050e-02],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:21,384][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([1.9550e-04, 3.9822e-02, 1.3912e-02, 1.8823e-01, 1.9958e-01, 1.0393e-01,
        1.5469e-03, 2.0468e-01, 9.0820e-02, 4.9033e-02, 1.0825e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:21,386][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0008, 0.0173, 0.0453, 0.0789, 0.0379, 0.0770, 0.0036, 0.1468, 0.3438,
        0.1461, 0.1026], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:21,387][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0471, 0.0852, 0.1654, 0.0453, 0.2106, 0.0323, 0.0906, 0.0644, 0.2162,
        0.0167, 0.0263], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:21,389][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([1.6203e-04, 2.6222e-01, 1.8224e-01, 6.6462e-02, 1.5169e-02, 3.8190e-01,
        9.0540e-04, 3.1928e-02, 4.4268e-02, 1.0305e-02, 4.4362e-03],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:21,390][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([4.1045e-04, 7.3706e-03, 6.0153e-02, 1.3663e-02, 7.5308e-02, 1.0745e-01,
        1.7558e-03, 4.6609e-01, 2.2686e-01, 2.1711e-02, 1.9239e-02],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:21,392][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0037, 0.0481, 0.0326, 0.0683, 0.1083, 0.1246, 0.0140, 0.0601, 0.2993,
        0.1473, 0.0938], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:21,393][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0006, 0.1320, 0.0875, 0.1335, 0.0303, 0.1234, 0.0023, 0.0947, 0.0983,
        0.1129, 0.1845], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:21,393][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([1.4546e-04, 4.5981e-01, 4.0518e-02, 1.8085e-01, 3.6007e-03, 1.6534e-01,
        1.0603e-03, 2.6386e-02, 8.7267e-02, 2.6010e-02, 9.0163e-03],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:21,394][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([5.5119e-05, 2.8735e-01, 3.6462e-02, 5.1530e-01, 1.3570e-02, 2.4649e-02,
        2.7497e-04, 4.3085e-03, 9.0670e-03, 5.2730e-02, 5.6232e-02],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:21,395][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0003, 0.0385, 0.0192, 0.1317, 0.1587, 0.0294, 0.0023, 0.0442, 0.2197,
        0.1487, 0.2072], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:21,397][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([5.9945e-05, 1.7147e-01, 3.6173e-02, 6.3986e-02, 1.0609e-01, 1.4666e-01,
        2.2414e-04, 1.9767e-01, 1.5766e-01, 3.8491e-02, 1.8022e-02, 6.3496e-02],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:21,398][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([1.4583e-06, 5.9468e-02, 2.6719e-01, 7.3751e-02, 1.4842e-02, 9.0365e-02,
        1.4751e-05, 5.9969e-02, 3.0347e-01, 5.8762e-02, 4.2054e-02, 3.0112e-02],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:21,399][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([6.0799e-05, 6.2337e-02, 1.4646e-02, 1.4951e-01, 1.3699e-01, 1.2615e-01,
        5.1019e-04, 2.1386e-01, 6.9191e-02, 4.3121e-02, 7.6607e-02, 1.0702e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:21,401][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([0.0002, 0.0444, 0.0485, 0.1470, 0.0424, 0.1229, 0.0011, 0.1196, 0.2109,
        0.1408, 0.0931, 0.0291], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:21,402][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.0094, 0.1152, 0.1484, 0.0464, 0.2047, 0.0255, 0.0270, 0.0816, 0.1974,
        0.0148, 0.0191, 0.1104], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:21,404][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([3.4641e-05, 3.8043e-01, 7.4577e-02, 5.8564e-02, 5.9839e-03, 4.1744e-01,
        2.6118e-04, 2.1305e-02, 3.5780e-02, 3.9991e-03, 1.1282e-03, 5.0350e-04],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:21,405][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([3.6419e-05, 1.2205e-02, 3.8539e-02, 1.1041e-02, 4.8054e-02, 1.0460e-01,
        1.5776e-04, 4.4567e-01, 1.5192e-01, 1.5682e-02, 1.3113e-02, 1.5898e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:21,407][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.0010, 0.1390, 0.0501, 0.0643, 0.1347, 0.1148, 0.0046, 0.0564, 0.2170,
        0.1280, 0.0683, 0.0219], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:21,408][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([9.4644e-05, 1.2969e-01, 6.3250e-02, 9.3052e-02, 2.1328e-02, 9.4971e-02,
        4.6735e-04, 7.2944e-02, 1.1804e-01, 1.7037e-01, 2.1009e-01, 2.5698e-02],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:21,409][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([3.2209e-06, 6.1955e-01, 2.7421e-02, 1.5109e-01, 8.3354e-04, 1.5179e-01,
        2.7738e-05, 1.0596e-02, 3.0920e-02, 5.6183e-03, 1.9929e-03, 1.5775e-04],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:21,410][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([1.0433e-06, 5.0089e-01, 1.0465e-02, 4.2616e-01, 2.2805e-03, 1.3566e-02,
        6.2169e-06, 7.3628e-04, 1.4574e-03, 2.4442e-02, 1.9959e-02, 3.8195e-05],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:21,412][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([8.9781e-05, 5.6043e-02, 3.1446e-02, 1.3819e-01, 9.7367e-02, 7.1770e-02,
        5.3104e-04, 1.0018e-01, 1.3932e-01, 1.0492e-01, 1.5765e-01, 1.0249e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:21,413][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Melissa] are: tensor([2.0531e-04, 2.6136e-01, 4.6051e-02, 9.9088e-02, 9.0377e-02, 8.8326e-02,
        4.0894e-04, 1.4058e-01, 7.9276e-02, 6.5498e-02, 2.8187e-02, 5.7078e-02,
        4.3558e-02], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:21,414][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Melissa] are: tensor([1.8336e-06, 4.1893e-02, 3.4151e-01, 5.5322e-02, 1.1264e-02, 4.7810e-02,
        1.4559e-05, 2.0647e-02, 1.0185e-01, 5.1080e-02, 3.4573e-02, 2.1972e-02,
        2.7206e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:21,416][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Melissa] are: tensor([4.5623e-05, 3.4038e-02, 2.2149e-02, 1.7761e-01, 9.6771e-02, 1.1009e-01,
        3.4776e-04, 2.0965e-01, 4.8181e-02, 6.2789e-02, 1.1285e-01, 1.0398e-01,
        2.1504e-02], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:21,417][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Melissa] are: tensor([1.4342e-04, 5.6118e-02, 6.8610e-02, 1.2146e-01, 3.4999e-02, 8.6964e-02,
        6.2765e-04, 6.7332e-02, 1.4250e-01, 1.6636e-01, 1.0017e-01, 5.0710e-02,
        1.0401e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:21,418][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Melissa] are: tensor([0.0494, 0.0801, 0.1244, 0.0312, 0.0810, 0.0093, 0.0717, 0.0394, 0.1002,
        0.0139, 0.0191, 0.1095, 0.2708], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:21,419][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Melissa] are: tensor([6.2868e-05, 3.5166e-01, 1.0717e-01, 9.2382e-02, 1.1829e-02, 3.0464e-01,
        5.0158e-04, 4.1972e-02, 7.0636e-02, 9.7918e-03, 3.4766e-03, 2.0954e-03,
        3.7781e-03], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:21,420][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Melissa] are: tensor([1.2530e-04, 1.9847e-02, 7.7735e-02, 1.6268e-02, 6.4843e-02, 8.0511e-02,
        4.0824e-04, 3.3243e-01, 1.0288e-01, 2.4521e-02, 2.0618e-02, 1.1823e-01,
        1.4158e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:21,421][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Melissa] are: tensor([0.0034, 0.0878, 0.0586, 0.0688, 0.1533, 0.1220, 0.0133, 0.0463, 0.1863,
        0.1269, 0.0489, 0.0250, 0.0593], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:21,422][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Melissa] are: tensor([1.5681e-04, 2.1403e-01, 8.8167e-02, 7.5698e-02, 2.1978e-02, 5.6750e-02,
        6.1247e-04, 4.6386e-02, 6.1921e-02, 1.7733e-01, 1.8778e-01, 1.6969e-02,
        5.2224e-02], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:21,423][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Melissa] are: tensor([4.4816e-05, 6.0867e-01, 1.9473e-02, 1.7421e-01, 2.6383e-03, 9.5566e-02,
        3.4633e-04, 1.6879e-02, 6.1611e-02, 1.3080e-02, 5.9278e-03, 1.2443e-03,
        3.1263e-04], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:21,424][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Melissa] are: tensor([2.1265e-05, 5.0961e-01, 1.2229e-02, 3.7112e-01, 1.8722e-03, 1.2096e-02,
        7.4773e-05, 6.6584e-04, 1.1306e-03, 4.7953e-02, 4.2972e-02, 5.0294e-05,
        2.0317e-04], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:21,425][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Melissa] are: tensor([1.4906e-04, 1.2640e-01, 2.1999e-02, 1.6144e-01, 5.5680e-02, 4.5181e-02,
        6.6623e-04, 7.9359e-02, 5.5795e-02, 1.1601e-01, 1.5965e-01, 5.7446e-02,
        1.2021e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:21,427][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.0002, 0.0909, 0.0315, 0.0778, 0.0473, 0.0815, 0.0005, 0.1506, 0.1961,
        0.0593, 0.0252, 0.0948, 0.0327, 0.1115], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:21,428][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([5.4873e-06, 4.0544e-02, 1.3990e-01, 5.3829e-02, 1.0538e-02, 2.5193e-02,
        4.7099e-05, 2.4100e-02, 1.3513e-01, 4.4123e-02, 3.4151e-02, 3.6635e-02,
        1.0481e-01, 3.5100e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:21,430][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([1.1756e-04, 4.5131e-02, 1.3093e-02, 1.4270e-01, 9.1029e-02, 7.9255e-02,
        1.0798e-03, 1.2203e-01, 5.2014e-02, 4.8956e-02, 9.1613e-02, 1.3186e-01,
        1.1178e-02, 1.6994e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:21,431][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([4.2835e-05, 1.0914e-02, 1.6344e-02, 3.7054e-02, 9.9353e-03, 2.7412e-02,
        2.6552e-04, 2.9540e-02, 9.8320e-02, 7.6256e-02, 3.9943e-02, 2.3337e-02,
        3.2141e-02, 5.9850e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:21,433][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([0.0160, 0.0486, 0.1619, 0.0590, 0.1511, 0.0194, 0.0373, 0.0502, 0.0924,
        0.0120, 0.0181, 0.0796, 0.1792, 0.0753], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:21,434][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([2.5993e-04, 3.8685e-01, 1.2498e-01, 5.9559e-02, 3.9356e-03, 2.6257e-01,
        1.1349e-03, 1.2494e-02, 2.6122e-02, 7.9081e-03, 2.3052e-03, 5.1121e-04,
        2.2815e-03, 1.0908e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:21,435][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([2.3103e-04, 5.7940e-03, 5.3969e-02, 1.5032e-02, 5.1667e-02, 5.5824e-02,
        1.0030e-03, 3.0221e-01, 1.4881e-01, 1.8445e-02, 1.2321e-02, 1.3146e-01,
        1.3892e-01, 6.4307e-02], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:21,437][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.0047, 0.0581, 0.0346, 0.0669, 0.0592, 0.0902, 0.0159, 0.0635, 0.1567,
        0.1027, 0.0593, 0.0155, 0.0278, 0.2449], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:21,438][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([8.4278e-05, 1.8635e-01, 7.4137e-02, 8.4619e-02, 2.3773e-02, 1.0419e-01,
        4.7026e-04, 4.1743e-02, 6.0217e-02, 1.3269e-01, 1.1319e-01, 1.1195e-02,
        3.1670e-02, 1.3567e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:21,440][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([1.4153e-04, 6.9107e-01, 4.2593e-02, 1.3028e-01, 3.3201e-04, 7.0482e-02,
        4.9521e-04, 6.8585e-03, 1.3591e-02, 6.2115e-03, 1.9131e-03, 9.4140e-05,
        1.0137e-04, 3.5837e-02], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:21,441][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([1.8002e-05, 3.6846e-01, 1.7131e-02, 4.4611e-01, 3.8888e-03, 1.1347e-02,
        8.5914e-05, 1.4576e-03, 4.8677e-03, 5.1475e-02, 4.4281e-02, 1.3406e-04,
        3.6739e-04, 5.0375e-02], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:21,442][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([2.5078e-04, 1.3761e-02, 1.0284e-02, 6.2679e-02, 3.7378e-02, 1.1870e-02,
        1.4882e-03, 3.9668e-02, 7.6641e-02, 6.6311e-02, 7.6288e-02, 9.2305e-02,
        1.1869e-01, 3.9239e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:21,443][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([1.0357e-04, 5.3829e-02, 1.7122e-02, 3.8878e-02, 3.7481e-02, 5.9358e-02,
        3.6432e-04, 1.3414e-01, 1.9954e-01, 4.7455e-02, 1.9087e-02, 8.6418e-02,
        4.7446e-02, 9.9877e-02, 1.5890e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:21,445][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([1.5582e-06, 1.0199e-02, 7.8258e-02, 2.0622e-02, 1.0568e-02, 1.8429e-02,
        1.8158e-05, 1.8959e-02, 2.1158e-01, 2.2673e-02, 1.9732e-02, 2.7134e-02,
        1.3876e-01, 2.0230e-01, 2.2078e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:21,445][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([3.8200e-05, 2.4743e-02, 6.1506e-03, 1.1112e-01, 7.0276e-02, 6.0208e-02,
        3.7651e-04, 9.2065e-02, 4.7760e-02, 3.6584e-02, 7.0923e-02, 1.2365e-01,
        8.6337e-03, 1.2381e-01, 2.2366e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:21,446][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([2.9200e-05, 6.3110e-03, 1.0952e-02, 2.4071e-02, 6.3346e-03, 2.4173e-02,
        2.0319e-04, 3.0049e-02, 9.2759e-02, 5.5753e-02, 3.0449e-02, 2.1213e-02,
        2.6949e-02, 4.6558e-01, 2.0517e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:21,447][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0071, 0.0335, 0.0867, 0.0304, 0.0777, 0.0180, 0.0175, 0.0409, 0.1365,
        0.0126, 0.0201, 0.0823, 0.2706, 0.0884, 0.0777], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:21,448][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([8.9828e-05, 2.9889e-01, 1.2313e-01, 5.0172e-02, 5.6588e-03, 2.9074e-01,
        5.8705e-04, 2.0352e-02, 3.4564e-02, 6.9916e-03, 2.0477e-03, 1.0380e-03,
        3.9760e-03, 1.4830e-01, 1.3460e-02], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:21,450][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([1.0886e-04, 4.0788e-03, 3.6074e-02, 6.0180e-03, 3.9760e-02, 4.0300e-02,
        4.6908e-04, 2.7632e-01, 1.5098e-01, 1.2003e-02, 9.5011e-03, 1.2747e-01,
        1.9364e-01, 4.1114e-02, 6.2163e-02], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:21,451][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0013, 0.0354, 0.0360, 0.0425, 0.0778, 0.0748, 0.0057, 0.0361, 0.1786,
        0.0930, 0.0580, 0.0155, 0.0555, 0.2080, 0.0818], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:21,452][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([5.0811e-05, 1.1531e-01, 4.6286e-02, 6.1112e-02, 1.2551e-02, 9.4090e-02,
        3.0885e-04, 4.3659e-02, 5.1618e-02, 1.0318e-01, 9.1434e-02, 1.4925e-02,
        2.6379e-02, 6.7440e-02, 2.7165e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:21,454][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([4.9672e-05, 5.6514e-01, 2.5827e-02, 9.6063e-02, 8.1979e-04, 1.5130e-01,
        3.4696e-04, 1.5894e-02, 2.9896e-02, 1.0564e-02, 2.7032e-03, 2.8877e-04,
        2.3419e-04, 8.8913e-02, 1.1963e-02], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:21,455][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([9.5010e-06, 2.7532e-01, 1.8065e-02, 4.6555e-01, 6.3127e-03, 1.3708e-02,
        5.1530e-05, 1.6753e-03, 6.4219e-03, 5.1088e-02, 4.7675e-02, 2.3114e-04,
        5.1424e-04, 4.2491e-02, 7.0887e-02], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:21,456][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([2.9709e-05, 4.7713e-03, 4.8798e-03, 2.6816e-02, 2.6239e-02, 4.7017e-03,
        2.0770e-04, 1.2924e-02, 5.9522e-02, 3.4934e-02, 4.5022e-02, 3.0443e-02,
        9.0873e-02, 1.9233e-01, 4.6630e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:21,460][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:31:21,461][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[2088],
        [  41],
        [ 134],
        [  35],
        [   1],
        [  21],
        [  20],
        [   2],
        [  19],
        [   5],
        [   7],
        [  17],
        [  20],
        [  11],
        [   3]], device='cuda:0')
[2024-07-24 10:31:21,463][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[1932],
        [  48],
        [ 134],
        [  38],
        [   1],
        [  22],
        [  11],
        [   2],
        [  20],
        [   4],
        [   7],
        [  17],
        [  24],
        [  12],
        [   6]], device='cuda:0')
[2024-07-24 10:31:21,464][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[45024],
        [44745],
        [47504],
        [48446],
        [49813],
        [49486],
        [49604],
        [48866],
        [48521],
        [48767],
        [49017],
        [48992],
        [49061],
        [49103],
        [49059]], device='cuda:0')
[2024-07-24 10:31:21,466][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[21186],
        [34581],
        [24807],
        [26307],
        [26900],
        [28262],
        [26614],
        [28803],
        [33499],
        [34159],
        [34148],
        [34242],
        [30305],
        [34672],
        [34659]], device='cuda:0')
[2024-07-24 10:31:21,468][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[45075],
        [34632],
        [37765],
        [32556],
        [44572],
        [41768],
        [40422],
        [39356],
        [38232],
        [38197],
        [36008],
        [34230],
        [33789],
        [33603],
        [33784]], device='cuda:0')
[2024-07-24 10:31:21,470][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[16223],
        [40796],
        [32425],
        [31128],
        [29123],
        [26611],
        [25255],
        [24014],
        [20927],
        [21028],
        [20685],
        [21546],
        [20464],
        [16550],
        [15545]], device='cuda:0')
[2024-07-24 10:31:21,471][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[29811],
        [21081],
        [22276],
        [21641],
        [17802],
        [17519],
        [17117],
        [14446],
        [ 9390],
        [ 8050],
        [ 9701],
        [ 8823],
        [ 9476],
        [10188],
        [ 7627]], device='cuda:0')
[2024-07-24 10:31:21,473][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[18549],
        [24647],
        [30717],
        [32879],
        [31982],
        [29550],
        [29039],
        [29169],
        [30026],
        [30382],
        [31461],
        [31160],
        [31329],
        [30522],
        [31541]], device='cuda:0')
[2024-07-24 10:31:21,474][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[ 518],
        [ 472],
        [ 297],
        [ 458],
        [2391],
        [1544],
        [1806],
        [ 552],
        [ 487],
        [ 676],
        [ 693],
        [ 619],
        [ 513],
        [ 574],
        [ 577]], device='cuda:0')
[2024-07-24 10:31:21,476][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[45895],
        [ 1861],
        [ 1163],
        [ 1084],
        [   14],
        [  224],
        [  308],
        [  486],
        [ 1331],
        [  464],
        [  809],
        [  572],
        [  461],
        [ 1254],
        [ 1005]], device='cuda:0')
[2024-07-24 10:31:21,478][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[29144],
        [20951],
        [20570],
        [19871],
        [19384],
        [19102],
        [16968],
        [16782],
        [16769],
        [15068],
        [14961],
        [14768],
        [15246],
        [15211],
        [15232]], device='cuda:0')
[2024-07-24 10:31:21,479][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[46224],
        [45272],
        [45184],
        [45722],
        [45823],
        [45638],
        [46390],
        [45592],
        [45459],
        [46417],
        [47017],
        [46400],
        [46677],
        [46346],
        [46853]], device='cuda:0')
[2024-07-24 10:31:21,481][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[26802],
        [ 8849],
        [ 9142],
        [ 9435],
        [ 9873],
        [10078],
        [ 9781],
        [10006],
        [10583],
        [11600],
        [11684],
        [ 9424],
        [ 9787],
        [10452],
        [12368]], device='cuda:0')
[2024-07-24 10:31:21,483][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[21441],
        [38476],
        [39091],
        [41699],
        [42375],
        [42587],
        [41762],
        [41554],
        [41811],
        [41783],
        [42330],
        [41627],
        [40882],
        [38951],
        [40860]], device='cuda:0')
[2024-07-24 10:31:21,484][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[10975],
        [ 4368],
        [ 6817],
        [ 3147],
        [ 6571],
        [ 5669],
        [ 9562],
        [ 6339],
        [ 5001],
        [ 6089],
        [ 5059],
        [ 6434],
        [ 4680],
        [ 7617],
        [ 4710]], device='cuda:0')
[2024-07-24 10:31:21,486][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[ 4567],
        [29195],
        [31487],
        [32899],
        [29410],
        [32190],
        [31324],
        [33945],
        [36680],
        [36871],
        [36068],
        [35367],
        [34733],
        [37693],
        [38101]], device='cuda:0')
[2024-07-24 10:31:21,488][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[33510],
        [10660],
        [ 6923],
        [ 7466],
        [ 7733],
        [ 8423],
        [ 7859],
        [ 7658],
        [ 6819],
        [ 7010],
        [ 7173],
        [ 7746],
        [ 6780],
        [10337],
        [ 9237]], device='cuda:0')
[2024-07-24 10:31:21,489][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[34676],
        [19603],
        [24844],
        [21040],
        [16867],
        [17588],
        [18841],
        [20119],
        [21946],
        [21283],
        [21014],
        [22831],
        [23474],
        [23415],
        [24257]], device='cuda:0')
[2024-07-24 10:31:21,491][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[ 4251],
        [15656],
        [13550],
        [10431],
        [12269],
        [13157],
        [13808],
        [18362],
        [21104],
        [21157],
        [19712],
        [17480],
        [16033],
        [15885],
        [15875]], device='cuda:0')
[2024-07-24 10:31:21,493][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[12439],
        [13575],
        [13451],
        [12634],
        [12427],
        [11237],
        [11310],
        [ 9965],
        [ 9947],
        [ 9858],
        [ 9671],
        [ 9492],
        [ 9838],
        [ 9193],
        [ 9770]], device='cuda:0')
[2024-07-24 10:31:21,494][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[18270],
        [ 8739],
        [ 8015],
        [ 7815],
        [ 8107],
        [10618],
        [10618],
        [11110],
        [10141],
        [11421],
        [12841],
        [13006],
        [11672],
        [11445],
        [12042]], device='cuda:0')
[2024-07-24 10:31:21,496][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[19128],
        [15815],
        [16563],
        [15535],
        [17581],
        [16631],
        [16712],
        [ 8783],
        [ 8868],
        [ 9175],
        [ 9782],
        [12253],
        [10434],
        [11195],
        [10340]], device='cuda:0')
[2024-07-24 10:31:21,498][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[22549],
        [27227],
        [41359],
        [35362],
        [24357],
        [23279],
        [27937],
        [25585],
        [15864],
        [20261],
        [19965],
        [21418],
        [22517],
        [20103],
        [19458]], device='cuda:0')
[2024-07-24 10:31:21,500][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[7520],
        [3067],
        [3585],
        [3045],
        [3119],
        [2979],
        [3380],
        [2896],
        [3573],
        [2927],
        [2960],
        [2929],
        [2877],
        [2950],
        [3224]], device='cuda:0')
[2024-07-24 10:31:21,501][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[15069],
        [ 1450],
        [ 1414],
        [ 1407],
        [ 1418],
        [ 1456],
        [ 1467],
        [ 1446],
        [ 1422],
        [ 1339],
        [ 1444],
        [ 1481],
        [ 1404],
        [ 1435],
        [ 1519]], device='cuda:0')
[2024-07-24 10:31:21,503][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[25744],
        [35977],
        [36449],
        [41623],
        [41629],
        [41632],
        [40327],
        [41934],
        [42081],
        [42138],
        [42151],
        [40939],
        [40975],
        [41933],
        [42572]], device='cuda:0')
[2024-07-24 10:31:21,504][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[13271],
        [ 7846],
        [ 6826],
        [ 4253],
        [ 3053],
        [ 2495],
        [ 2632],
        [ 2476],
        [ 1661],
        [ 1055],
        [ 1218],
        [ 1470],
        [ 2133],
        [ 1243],
        [  714]], device='cuda:0')
[2024-07-24 10:31:21,506][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[23310],
        [36819],
        [33157],
        [38836],
        [41840],
        [41639],
        [40852],
        [42314],
        [43743],
        [43827],
        [43448],
        [42418],
        [42304],
        [42604],
        [43245]], device='cuda:0')
[2024-07-24 10:31:21,508][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[34176],
        [36241],
        [36630],
        [42542],
        [39818],
        [41521],
        [38104],
        [41022],
        [39403],
        [38473],
        [40554],
        [39766],
        [40925],
        [35369],
        [39747]], device='cuda:0')
[2024-07-24 10:31:21,509][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[10490],
        [10490],
        [10490],
        [10490],
        [10490],
        [10490],
        [10490],
        [10490],
        [10490],
        [10490],
        [10490],
        [10490],
        [10490],
        [10490],
        [10490]], device='cuda:0')
[2024-07-24 10:31:21,626][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:31:21,627][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:21,629][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:21,630][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:21,631][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:21,633][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:21,634][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:21,635][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:21,637][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:21,638][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:21,639][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:21,640][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:21,641][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:21,642][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.6060, 0.3940], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:21,642][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.1366, 0.8634], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:21,643][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0888, 0.9112], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:21,645][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.2806, 0.7194], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:21,646][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.4169, 0.5831], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:21,648][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.6844, 0.3156], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:21,649][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0863, 0.9137], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:21,651][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.4646, 0.5354], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:21,652][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.6035, 0.3965], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:21,654][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [,] are: tensor([9.9981e-01, 1.9125e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:21,655][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.9987, 0.0013], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:21,657][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0660, 0.9340], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:21,658][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Melissa] are: tensor([0.1442, 0.2139, 0.6419], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:21,660][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Melissa] are: tensor([0.0966, 0.7757, 0.1277], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:21,662][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Melissa] are: tensor([0.0827, 0.8551, 0.0622], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:21,663][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Melissa] are: tensor([0.2494, 0.6877, 0.0629], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:21,665][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Melissa] are: tensor([0.1387, 0.3618, 0.4995], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:21,666][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Melissa] are: tensor([0.3154, 0.1640, 0.5205], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:21,667][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Melissa] are: tensor([0.0527, 0.9198, 0.0275], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:21,668][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Melissa] are: tensor([0.4116, 0.5689, 0.0195], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:21,669][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Melissa] are: tensor([0.1184, 0.2302, 0.6514], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:21,669][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Melissa] are: tensor([9.9718e-01, 1.4702e-06, 2.8190e-03], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:21,670][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Melissa] are: tensor([9.9503e-01, 3.8515e-04, 4.5840e-03], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:21,672][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Melissa] are: tensor([0.0218, 0.2966, 0.6816], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:21,673][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.2120, 0.2064, 0.2256, 0.3560], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:21,675][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.1014, 0.6169, 0.1090, 0.1727], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:21,676][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0334, 0.5118, 0.0696, 0.3852], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:21,678][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.1113, 0.5594, 0.1114, 0.2179], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:21,679][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.1240, 0.3607, 0.3240, 0.1913], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:21,681][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.2561, 0.1850, 0.3897, 0.1692], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:21,683][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0442, 0.7995, 0.0330, 0.1232], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:21,684][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.2942, 0.5315, 0.0357, 0.1386], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:21,686][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.2534, 0.1428, 0.4657, 0.1380], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:21,687][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.9027, 0.0019, 0.0882, 0.0072], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:21,689][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ and] are: tensor([9.8724e-01, 4.1367e-04, 1.2218e-02, 1.3338e-04], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:21,690][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0019, 0.2392, 0.6891, 0.0698], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:21,692][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Benjamin] are: tensor([0.1203, 0.1369, 0.2404, 0.2394, 0.2630], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:21,693][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Benjamin] are: tensor([0.0855, 0.6157, 0.0680, 0.1161, 0.1148], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:21,693][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Benjamin] are: tensor([0.0420, 0.5323, 0.0443, 0.3542, 0.0272], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:21,694][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Benjamin] are: tensor([0.1089, 0.6896, 0.0430, 0.1452, 0.0133], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:21,695][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Benjamin] are: tensor([0.0454, 0.1314, 0.1901, 0.0920, 0.5412], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:21,696][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Benjamin] are: tensor([0.1906, 0.0944, 0.1917, 0.0893, 0.4339], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:21,698][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Benjamin] are: tensor([0.0356, 0.8091, 0.0211, 0.1168, 0.0174], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:21,699][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Benjamin] are: tensor([0.2687, 0.5749, 0.0193, 0.0939, 0.0433], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:21,701][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Benjamin] are: tensor([0.0406, 0.1265, 0.3590, 0.1467, 0.3272], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:21,702][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Benjamin] are: tensor([1.7994e-01, 9.5336e-05, 5.1797e-02, 3.2482e-04, 7.6784e-01],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:21,703][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Benjamin] are: tensor([9.6010e-01, 9.4020e-04, 9.3937e-03, 3.2939e-04, 2.9237e-02],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:21,705][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Benjamin] are: tensor([0.0010, 0.0835, 0.2656, 0.0194, 0.6304], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:21,706][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.0747, 0.0916, 0.1567, 0.1765, 0.1906, 0.3099], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:21,708][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.0661, 0.4501, 0.0891, 0.1145, 0.1188, 0.1614], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:21,709][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.0259, 0.2808, 0.0377, 0.2622, 0.0326, 0.3609], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:21,711][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.0763, 0.5478, 0.0253, 0.0981, 0.0082, 0.2443], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:21,713][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.0331, 0.1137, 0.1701, 0.0623, 0.4252, 0.1956], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:21,714][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.1509, 0.1101, 0.1555, 0.0971, 0.3940, 0.0924], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:21,716][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.0361, 0.7234, 0.0207, 0.0899, 0.0172, 0.1128], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:21,718][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.2997, 0.4772, 0.0221, 0.1031, 0.0509, 0.0469], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:21,719][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.0361, 0.1281, 0.2744, 0.1448, 0.2691, 0.1476], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:21,719][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ had] are: tensor([5.0465e-01, 2.4238e-04, 2.6828e-02, 9.3160e-04, 4.0503e-01, 6.2318e-02],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:21,720][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ had] are: tensor([9.8946e-01, 8.1557e-04, 5.2141e-03, 1.1980e-04, 3.8928e-03, 5.0061e-04],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:21,721][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0089, 0.0818, 0.2135, 0.0213, 0.3747, 0.2999], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:21,722][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.2377, 0.0948, 0.0747, 0.1451, 0.1023, 0.1378, 0.2075],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:21,723][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0397, 0.3685, 0.0569, 0.0835, 0.1441, 0.1966, 0.1107],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:21,725][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0162, 0.2811, 0.0245, 0.1645, 0.0133, 0.4716, 0.0288],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:21,726][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0436, 0.4134, 0.0591, 0.1148, 0.0203, 0.3035, 0.0454],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:21,728][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0418, 0.1085, 0.1293, 0.0822, 0.2788, 0.2726, 0.0869],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:21,730][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.1374, 0.0643, 0.2266, 0.0570, 0.3445, 0.0413, 0.1291],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:21,731][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0420, 0.6623, 0.0255, 0.0634, 0.0196, 0.1341, 0.0532],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:21,733][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.2984, 0.2569, 0.0134, 0.0592, 0.0494, 0.0439, 0.2787],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:21,734][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ a] are: tensor([4.5424e-05, 2.0147e-01, 9.2002e-02, 3.6158e-01, 2.2187e-01, 1.1917e-01,
        3.8634e-03], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:21,735][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ a] are: tensor([6.2686e-01, 4.5135e-03, 1.1474e-01, 8.9810e-04, 2.3982e-01, 5.4140e-04,
        1.2630e-02], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:21,736][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ a] are: tensor([2.3404e-04, 5.8021e-01, 1.1932e-02, 2.3879e-01, 4.4467e-02, 1.1818e-01,
        6.1895e-03], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:21,738][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0113, 0.4812, 0.0878, 0.2130, 0.0025, 0.0185, 0.1858],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:21,740][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.0367, 0.0795, 0.2042, 0.1358, 0.1657, 0.1732, 0.0448, 0.1601],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:21,742][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ long] are: tensor([0.0248, 0.3474, 0.0512, 0.0734, 0.1054, 0.1555, 0.0833, 0.1588],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:21,743][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.0105, 0.2834, 0.0260, 0.2268, 0.0157, 0.4043, 0.0203, 0.0130],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:21,745][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ long] are: tensor([0.0344, 0.5099, 0.0290, 0.0886, 0.0077, 0.2555, 0.0398, 0.0349],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:21,745][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.0262, 0.0768, 0.1055, 0.0405, 0.4006, 0.1446, 0.0623, 0.1434],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:21,746][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ long] are: tensor([0.1035, 0.0550, 0.2002, 0.0430, 0.4072, 0.0347, 0.1187, 0.0377],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:21,747][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.0266, 0.6866, 0.0199, 0.0765, 0.0156, 0.1224, 0.0372, 0.0152],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:21,748][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.2317, 0.3815, 0.0183, 0.0706, 0.0381, 0.0251, 0.2264, 0.0083],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:21,750][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.0149, 0.0965, 0.1899, 0.1317, 0.2051, 0.1066, 0.0861, 0.1691],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:21,751][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ long] are: tensor([6.9309e-01, 5.5680e-05, 1.8868e-03, 1.0906e-04, 2.7046e-01, 1.9785e-03,
        3.0844e-02, 1.5770e-03], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:21,752][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.3666, 0.0537, 0.0480, 0.0081, 0.0342, 0.0149, 0.4485, 0.0261],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:21,754][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ long] are: tensor([0.0017, 0.1927, 0.1942, 0.0473, 0.2518, 0.2373, 0.0018, 0.0734],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:21,756][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.0612, 0.0630, 0.0973, 0.0972, 0.1085, 0.1605, 0.0701, 0.1163, 0.2260],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:21,757][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([0.0385, 0.3292, 0.0480, 0.0697, 0.0761, 0.1102, 0.0880, 0.1043, 0.1360],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:21,759][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.0127, 0.2413, 0.0222, 0.2363, 0.0133, 0.4264, 0.0244, 0.0167, 0.0068],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:21,761][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([0.0230, 0.5181, 0.0295, 0.0969, 0.0050, 0.2301, 0.0303, 0.0337, 0.0334],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:21,762][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.0141, 0.0698, 0.1386, 0.0418, 0.2671, 0.1727, 0.0374, 0.1300, 0.1283],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:21,764][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([0.0786, 0.0480, 0.1329, 0.0461, 0.2620, 0.0404, 0.0973, 0.0328, 0.2619],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:21,766][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.0257, 0.6834, 0.0173, 0.0843, 0.0112, 0.1218, 0.0333, 0.0122, 0.0107],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:21,768][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.2369, 0.3934, 0.0167, 0.0633, 0.0305, 0.0288, 0.2006, 0.0086, 0.0213],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:21,769][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.0078, 0.0881, 0.1639, 0.1099, 0.1791, 0.1002, 0.0528, 0.1574, 0.1407],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:21,771][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.1516, 0.0007, 0.0274, 0.0012, 0.4264, 0.0229, 0.0657, 0.0095, 0.2947],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:21,771][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.2005, 0.1564, 0.0860, 0.0203, 0.0593, 0.0228, 0.3678, 0.0325, 0.0543],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:21,772][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([0.0037, 0.2696, 0.4112, 0.0512, 0.1016, 0.1104, 0.0020, 0.0420, 0.0083],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:21,773][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0928, 0.0604, 0.0741, 0.1096, 0.0928, 0.1158, 0.0910, 0.0902, 0.1484,
        0.1248], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:21,774][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0280, 0.2466, 0.0439, 0.0497, 0.0944, 0.1049, 0.0731, 0.1012, 0.1861,
        0.0721], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:21,776][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0206, 0.2636, 0.0268, 0.1903, 0.0170, 0.3547, 0.0337, 0.0173, 0.0076,
        0.0683], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:21,777][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0470, 0.4022, 0.0401, 0.0868, 0.0127, 0.2067, 0.0544, 0.0487, 0.0501,
        0.0513], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:21,779][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0283, 0.0894, 0.1015, 0.0428, 0.2430, 0.1528, 0.0585, 0.1501, 0.1060,
        0.0277], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:21,780][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0867, 0.0460, 0.1443, 0.0361, 0.2785, 0.0290, 0.0959, 0.0343, 0.2261,
        0.0232], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:21,782][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0325, 0.6388, 0.0183, 0.0496, 0.0161, 0.0862, 0.0415, 0.0190, 0.0138,
        0.0843], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:21,784][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.2372, 0.2740, 0.0179, 0.0528, 0.0467, 0.0330, 0.2326, 0.0123, 0.0250,
        0.0686], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:21,785][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0850, 0.0461, 0.1457, 0.0471, 0.1054, 0.0635, 0.1853, 0.1560, 0.1247,
        0.0412], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:21,787][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [,] are: tensor([5.2803e-04, 1.3659e-06, 4.3718e-04, 1.0981e-05, 3.4766e-02, 1.4945e-03,
        2.6044e-04, 2.1779e-04, 9.6217e-01, 1.1042e-04], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:21,788][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.3817, 0.0197, 0.3274, 0.0029, 0.1179, 0.0058, 0.0748, 0.0258, 0.0418,
        0.0022], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:21,789][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [,] are: tensor([2.3548e-05, 1.7516e-02, 6.5813e-02, 5.6563e-03, 7.7270e-01, 1.1185e-01,
        7.3699e-06, 1.6223e-02, 7.5697e-03, 2.6409e-03], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:21,791][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0796, 0.0540, 0.0547, 0.0945, 0.0737, 0.1109, 0.0816, 0.0652, 0.1080,
        0.1060, 0.1718], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:21,793][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0281, 0.2285, 0.0462, 0.0550, 0.0991, 0.1167, 0.0729, 0.0904, 0.1554,
        0.0651, 0.0426], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:21,794][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0129, 0.2496, 0.0243, 0.1753, 0.0160, 0.3588, 0.0245, 0.0149, 0.0060,
        0.0602, 0.0577], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:21,796][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0433, 0.3847, 0.0374, 0.0807, 0.0142, 0.2193, 0.0475, 0.0532, 0.0521,
        0.0429, 0.0247], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:21,797][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0272, 0.0913, 0.0845, 0.0480, 0.2235, 0.1693, 0.0579, 0.1485, 0.0987,
        0.0282, 0.0229], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:21,798][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0880, 0.0500, 0.1229, 0.0403, 0.2688, 0.0315, 0.0933, 0.0382, 0.2097,
        0.0242, 0.0331], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:21,799][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0255, 0.6060, 0.0171, 0.0569, 0.0153, 0.1023, 0.0352, 0.0183, 0.0111,
        0.0803, 0.0319], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:21,800][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.2124, 0.2820, 0.0134, 0.0596, 0.0421, 0.0353, 0.2100, 0.0110, 0.0187,
        0.0607, 0.0548], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:21,801][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.1031, 0.0365, 0.1393, 0.0349, 0.0871, 0.0543, 0.2279, 0.1516, 0.1098,
        0.0296, 0.0258], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:21,802][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ and] are: tensor([1.1162e-04, 4.4117e-06, 1.3729e-04, 3.6683e-05, 1.5914e-02, 3.1625e-03,
        3.9945e-04, 1.3776e-04, 9.7952e-01, 4.7797e-04, 9.7710e-05],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:21,804][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ and] are: tensor([8.6716e-01, 9.6461e-04, 3.1728e-02, 1.5693e-04, 1.1793e-02, 5.3567e-04,
        7.8525e-02, 3.0284e-03, 5.9209e-03, 9.2618e-05, 9.8363e-05],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:21,805][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ and] are: tensor([4.7218e-06, 1.3006e-02, 2.3006e-02, 2.4508e-03, 7.0505e-01, 2.3283e-01,
        1.7906e-06, 1.5676e-02, 4.4753e-03, 1.3808e-03, 2.1183e-03],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:21,806][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.0533, 0.0477, 0.0489, 0.0803, 0.0633, 0.1016, 0.0594, 0.0742, 0.1242,
        0.0855, 0.1259, 0.1358], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:21,808][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([0.0166, 0.2389, 0.0411, 0.0527, 0.0890, 0.1336, 0.0498, 0.0921, 0.1335,
        0.0583, 0.0341, 0.0602], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:21,809][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.0039, 0.2052, 0.0160, 0.1485, 0.0097, 0.4956, 0.0112, 0.0100, 0.0038,
        0.0495, 0.0438, 0.0026], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:21,811][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([0.0339, 0.4132, 0.0326, 0.0916, 0.0123, 0.2387, 0.0408, 0.0368, 0.0346,
        0.0346, 0.0217, 0.0092], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:21,813][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.0132, 0.0560, 0.0592, 0.0384, 0.1997, 0.2030, 0.0371, 0.1529, 0.1080,
        0.0268, 0.0208, 0.0848], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:21,815][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([0.0625, 0.0391, 0.1065, 0.0342, 0.2757, 0.0345, 0.0795, 0.0359, 0.1894,
        0.0229, 0.0317, 0.0880], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:21,816][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.0138, 0.5668, 0.0175, 0.0536, 0.0134, 0.1569, 0.0238, 0.0149, 0.0099,
        0.0946, 0.0293, 0.0054], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:21,818][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.1755, 0.3033, 0.0105, 0.0445, 0.0398, 0.0319, 0.1825, 0.0101, 0.0207,
        0.0781, 0.0515, 0.0517], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:21,820][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.0187, 0.0496, 0.1303, 0.0641, 0.1170, 0.0665, 0.0697, 0.1356, 0.1101,
        0.0571, 0.0674, 0.1138], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:21,822][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([0.0158, 0.0009, 0.0103, 0.0008, 0.2668, 0.0224, 0.0061, 0.0089, 0.6319,
        0.0079, 0.0014, 0.0268], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:21,823][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.2357, 0.0722, 0.1348, 0.0057, 0.0824, 0.0100, 0.0890, 0.0510, 0.0236,
        0.0039, 0.0033, 0.2884], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:21,823][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([3.7193e-05, 1.5412e-01, 8.5420e-02, 1.3466e-02, 3.8680e-01, 2.2914e-01,
        1.5319e-05, 3.7859e-02, 7.3808e-03, 6.9463e-03, 7.6908e-03, 7.1130e-02],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:21,824][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Melissa] are: tensor([0.0299, 0.0322, 0.0658, 0.0561, 0.0770, 0.1070, 0.0404, 0.0776, 0.1519,
        0.0680, 0.0871, 0.1176, 0.0895], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:21,825][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Melissa] are: tensor([0.0189, 0.2745, 0.0363, 0.0570, 0.0793, 0.1314, 0.0557, 0.0670, 0.0968,
        0.0727, 0.0434, 0.0514, 0.0157], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:21,827][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Melissa] are: tensor([0.0087, 0.2547, 0.0113, 0.1802, 0.0083, 0.3949, 0.0188, 0.0086, 0.0028,
        0.0574, 0.0506, 0.0032, 0.0004], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:21,828][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Melissa] are: tensor([0.0325, 0.4218, 0.0264, 0.0901, 0.0086, 0.2206, 0.0353, 0.0467, 0.0471,
        0.0339, 0.0238, 0.0103, 0.0027], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:21,830][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Melissa] are: tensor([0.0070, 0.0408, 0.0615, 0.0331, 0.1927, 0.2005, 0.0271, 0.1329, 0.1049,
        0.0243, 0.0187, 0.0728, 0.0836], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:21,832][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Melissa] are: tensor([0.0493, 0.0404, 0.0712, 0.0307, 0.1906, 0.0303, 0.0591, 0.0233, 0.1283,
        0.0249, 0.0297, 0.0887, 0.2334], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:21,833][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Melissa] are: tensor([0.0147, 0.5849, 0.0116, 0.0618, 0.0089, 0.1356, 0.0221, 0.0087, 0.0055,
        0.1051, 0.0370, 0.0033, 0.0007], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:21,835][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Melissa] are: tensor([0.1842, 0.3248, 0.0067, 0.0410, 0.0275, 0.0221, 0.1730, 0.0063, 0.0142,
        0.0951, 0.0589, 0.0348, 0.0114], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:21,837][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Melissa] are: tensor([0.0107, 0.0473, 0.1110, 0.0585, 0.1154, 0.0566, 0.0478, 0.1035, 0.0928,
        0.0535, 0.0655, 0.1116, 0.1258], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:21,838][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Melissa] are: tensor([3.3320e-01, 1.0090e-05, 6.3195e-03, 4.7365e-05, 1.4358e-01, 1.9027e-03,
        1.0355e-02, 5.1824e-04, 4.5416e-01, 2.2418e-04, 9.8322e-05, 1.1004e-02,
        3.8592e-02], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:21,840][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Melissa] are: tensor([6.9100e-01, 5.1952e-03, 1.7785e-02, 5.7036e-04, 8.9671e-03, 9.8224e-04,
        1.8627e-01, 2.5225e-03, 5.3986e-03, 4.0999e-04, 4.5933e-04, 3.6899e-02,
        4.3540e-02], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:21,841][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Melissa] are: tensor([3.4807e-04, 5.5195e-02, 4.7236e-02, 4.7787e-03, 3.7764e-01, 7.5626e-02,
        1.1175e-04, 1.9877e-02, 6.7318e-03, 4.8067e-03, 5.5710e-03, 1.1289e-01,
        2.8919e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:21,843][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.0622, 0.0361, 0.0257, 0.0617, 0.0534, 0.1046, 0.0649, 0.0440, 0.0860,
        0.0855, 0.1395, 0.0853, 0.0422, 0.1089], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:21,844][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ said] are: tensor([0.0234, 0.2482, 0.0402, 0.0670, 0.0702, 0.1097, 0.0582, 0.0658, 0.0845,
        0.0627, 0.0478, 0.0610, 0.0192, 0.0421], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:21,846][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.0072, 0.1759, 0.0236, 0.1941, 0.0167, 0.3887, 0.0180, 0.0161, 0.0058,
        0.0552, 0.0549, 0.0057, 0.0011, 0.0369], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:21,848][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ said] are: tensor([0.0272, 0.3569, 0.0391, 0.0957, 0.0118, 0.2136, 0.0327, 0.0514, 0.0562,
        0.0367, 0.0282, 0.0114, 0.0040, 0.0350], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:21,849][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.0065, 0.0414, 0.0737, 0.0280, 0.1509, 0.1611, 0.0187, 0.1155, 0.0876,
        0.0181, 0.0153, 0.0592, 0.0655, 0.1585], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:21,850][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ said] are: tensor([0.0436, 0.0484, 0.0727, 0.0436, 0.1748, 0.0344, 0.0545, 0.0226, 0.1164,
        0.0295, 0.0424, 0.0932, 0.1448, 0.0790], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:21,851][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.0155, 0.5613, 0.0176, 0.0694, 0.0129, 0.1083, 0.0247, 0.0146, 0.0084,
        0.0903, 0.0397, 0.0059, 0.0011, 0.0301], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:21,852][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.1614, 0.2830, 0.0125, 0.0548, 0.0340, 0.0287, 0.1503, 0.0098, 0.0213,
        0.0806, 0.0631, 0.0416, 0.0162, 0.0427], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:21,853][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.0079, 0.0461, 0.1044, 0.0541, 0.0994, 0.0560, 0.0438, 0.1050, 0.0898,
        0.0540, 0.0603, 0.0962, 0.1225, 0.0606], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:21,854][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ said] are: tensor([9.9395e-02, 4.2771e-05, 1.3464e-02, 6.7050e-05, 1.2210e-01, 6.3135e-03,
        1.1980e-02, 8.3297e-03, 5.8903e-01, 9.0852e-04, 1.5613e-04, 2.1326e-02,
        7.4419e-02, 5.2466e-02], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:21,856][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.3211, 0.0250, 0.1343, 0.0036, 0.0635, 0.0062, 0.1484, 0.0408, 0.0404,
        0.0054, 0.0031, 0.0706, 0.1308, 0.0067], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:21,857][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ said] are: tensor([0.0051, 0.0326, 0.2182, 0.0093, 0.2509, 0.0809, 0.0006, 0.0269, 0.0112,
        0.0056, 0.0048, 0.0964, 0.2479, 0.0094], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:21,859][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0540, 0.0369, 0.0248, 0.0554, 0.0450, 0.0842, 0.0571, 0.0422, 0.0797,
        0.0649, 0.1067, 0.0900, 0.0442, 0.0971, 0.1180], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:21,861][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0204, 0.2117, 0.0262, 0.0442, 0.0758, 0.1091, 0.0566, 0.0823, 0.1294,
        0.0552, 0.0328, 0.0597, 0.0228, 0.0376, 0.0363], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:21,862][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0062, 0.1948, 0.0160, 0.1483, 0.0114, 0.4512, 0.0147, 0.0112, 0.0045,
        0.0467, 0.0451, 0.0033, 0.0007, 0.0290, 0.0166], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:21,864][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0336, 0.2817, 0.0389, 0.0794, 0.0152, 0.2540, 0.0408, 0.0604, 0.0623,
        0.0427, 0.0253, 0.0113, 0.0048, 0.0354, 0.0142], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:21,866][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0118, 0.0482, 0.0464, 0.0271, 0.1556, 0.1441, 0.0297, 0.1217, 0.0854,
        0.0188, 0.0140, 0.0666, 0.0618, 0.1334, 0.0353], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:21,868][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0497, 0.0298, 0.0684, 0.0219, 0.1764, 0.0178, 0.0505, 0.0231, 0.1548,
        0.0158, 0.0194, 0.0670, 0.1923, 0.0475, 0.0654], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:21,869][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0158, 0.5812, 0.0120, 0.0497, 0.0117, 0.0992, 0.0243, 0.0165, 0.0105,
        0.0877, 0.0283, 0.0056, 0.0011, 0.0282, 0.0283], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:21,871][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.1758, 0.2501, 0.0082, 0.0392, 0.0303, 0.0248, 0.1642, 0.0086, 0.0178,
        0.0600, 0.0458, 0.0372, 0.0148, 0.0310, 0.0922], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:21,873][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0469, 0.0347, 0.1109, 0.0365, 0.0822, 0.0483, 0.1122, 0.1160, 0.0889,
        0.0319, 0.0315, 0.0719, 0.1076, 0.0491, 0.0315], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:21,874][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ to] are: tensor([4.2319e-05, 2.9053e-05, 5.9713e-04, 2.4642e-04, 3.2456e-02, 8.4130e-03,
        2.7396e-04, 1.3178e-03, 9.2150e-01, 3.1843e-03, 9.5250e-04, 6.4173e-04,
        3.4685e-03, 2.1994e-02, 4.8860e-03], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:21,875][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.2000, 0.0050, 0.1159, 0.0006, 0.0508, 0.0018, 0.0399, 0.0138, 0.0173,
        0.0006, 0.0005, 0.3411, 0.2011, 0.0007, 0.0109], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:21,876][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ to] are: tensor([1.5563e-05, 6.1652e-03, 2.9341e-02, 1.5843e-03, 4.8270e-01, 7.5610e-02,
        3.1304e-06, 1.1052e-02, 3.0940e-03, 1.0157e-03, 1.4993e-03, 4.4104e-02,
        2.8638e-01, 6.2091e-04, 5.6813e-02], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:21,992][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:31:21,993][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:21,994][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:21,996][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:21,997][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:21,998][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:21,998][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:21,998][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:21,999][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:21,999][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:21,999][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:22,000][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:22,000][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:31:22,000][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.6060, 0.3940], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:22,001][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.1366, 0.8634], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:22,002][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0888, 0.9112], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:22,004][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.2806, 0.7194], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:22,005][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.4169, 0.5831], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:22,006][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.6844, 0.3156], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:22,008][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0863, 0.9137], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:22,009][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.4646, 0.5354], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:22,011][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.1003, 0.8997], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:22,012][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.2249, 0.7751], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:22,013][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0464, 0.9536], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:22,015][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.1908, 0.8092], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:31:22,016][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Melissa] are: tensor([0.1442, 0.2139, 0.6419], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:22,017][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Melissa] are: tensor([0.0966, 0.7757, 0.1277], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:22,017][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Melissa] are: tensor([0.0827, 0.8551, 0.0622], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:22,018][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Melissa] are: tensor([0.2494, 0.6877, 0.0629], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:22,018][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Melissa] are: tensor([0.1387, 0.3618, 0.4995], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:22,018][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Melissa] are: tensor([0.3154, 0.1640, 0.5205], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:22,019][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Melissa] are: tensor([0.0527, 0.9198, 0.0275], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:22,019][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Melissa] are: tensor([0.4116, 0.5689, 0.0195], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:22,019][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Melissa] are: tensor([0.0070, 0.0979, 0.8951], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:22,020][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Melissa] are: tensor([0.1528, 0.6268, 0.2204], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:22,020][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Melissa] are: tensor([0.0267, 0.3572, 0.6160], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:22,022][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Melissa] are: tensor([0.0578, 0.3937, 0.5485], device='cuda:0') for source tokens [Then, Melissa]
[2024-07-24 10:31:22,023][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.2120, 0.2064, 0.2256, 0.3560], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:22,024][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.1014, 0.6169, 0.1090, 0.1727], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:22,026][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0334, 0.5118, 0.0696, 0.3852], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:22,027][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.1113, 0.5594, 0.1114, 0.2179], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:22,028][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.1240, 0.3607, 0.3240, 0.1913], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:22,030][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.2561, 0.1850, 0.3897, 0.1692], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:22,031][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0442, 0.7995, 0.0330, 0.1232], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:22,032][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2942, 0.5315, 0.0357, 0.1386], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:22,034][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0104, 0.1077, 0.4700, 0.4120], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:22,035][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0938, 0.6540, 0.1891, 0.0631], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:22,037][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0088, 0.1693, 0.4283, 0.3937], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:22,038][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0318, 0.2115, 0.3274, 0.4293], device='cuda:0') for source tokens [Then, Melissa and]
[2024-07-24 10:31:22,039][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Benjamin] are: tensor([0.1203, 0.1369, 0.2404, 0.2394, 0.2630], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:22,041][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Benjamin] are: tensor([0.0855, 0.6157, 0.0680, 0.1161, 0.1148], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:22,042][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Benjamin] are: tensor([0.0420, 0.5323, 0.0443, 0.3542, 0.0272], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:22,044][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Benjamin] are: tensor([0.1089, 0.6896, 0.0430, 0.1452, 0.0133], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:22,044][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Benjamin] are: tensor([0.0454, 0.1314, 0.1901, 0.0920, 0.5412], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:22,044][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Benjamin] are: tensor([0.1906, 0.0944, 0.1917, 0.0893, 0.4339], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:22,045][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Benjamin] are: tensor([0.0356, 0.8091, 0.0211, 0.1168, 0.0174], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:22,045][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Benjamin] are: tensor([0.2687, 0.5749, 0.0193, 0.0939, 0.0433], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:22,045][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Benjamin] are: tensor([0.0053, 0.0607, 0.4598, 0.4203, 0.0538], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:22,046][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Benjamin] are: tensor([0.0930, 0.6452, 0.0958, 0.0333, 0.1327], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:22,046][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Benjamin] are: tensor([0.0098, 0.2052, 0.2434, 0.3858, 0.1558], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:22,047][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Benjamin] are: tensor([0.0447, 0.3009, 0.2575, 0.3698, 0.0271], device='cuda:0') for source tokens [Then, Melissa and Benjamin]
[2024-07-24 10:31:22,049][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.0747, 0.0916, 0.1567, 0.1765, 0.1906, 0.3099], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:22,050][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.0661, 0.4501, 0.0891, 0.1145, 0.1188, 0.1614], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:22,051][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.0259, 0.2808, 0.0377, 0.2622, 0.0326, 0.3609], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:22,053][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.0763, 0.5478, 0.0253, 0.0981, 0.0082, 0.2443], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:22,054][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.0331, 0.1137, 0.1701, 0.0623, 0.4252, 0.1956], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:22,055][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.1509, 0.1101, 0.1555, 0.0971, 0.3940, 0.0924], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:22,057][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.0361, 0.7234, 0.0207, 0.0899, 0.0172, 0.1128], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:22,058][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.2997, 0.4772, 0.0221, 0.1031, 0.0509, 0.0469], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:22,060][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.0033, 0.0546, 0.4997, 0.3618, 0.0543, 0.0262], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:22,061][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.0502, 0.6175, 0.0957, 0.0278, 0.1222, 0.0866], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:22,063][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.0055, 0.0996, 0.1024, 0.1637, 0.0743, 0.5544], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:22,064][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.0110, 0.0934, 0.1116, 0.1354, 0.0107, 0.6379], device='cuda:0') for source tokens [Then, Melissa and Benjamin had]
[2024-07-24 10:31:22,065][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.2377, 0.0948, 0.0747, 0.1451, 0.1023, 0.1378, 0.2075],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:22,067][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0397, 0.3685, 0.0569, 0.0835, 0.1441, 0.1966, 0.1107],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:22,068][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0162, 0.2811, 0.0245, 0.1645, 0.0133, 0.4716, 0.0288],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:22,069][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0436, 0.4134, 0.0591, 0.1148, 0.0203, 0.3035, 0.0454],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:22,070][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0418, 0.1085, 0.1293, 0.0822, 0.2788, 0.2726, 0.0869],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:22,070][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.1374, 0.0643, 0.2266, 0.0570, 0.3445, 0.0413, 0.1291],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:22,071][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0420, 0.6623, 0.0255, 0.0634, 0.0196, 0.1341, 0.0532],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:22,071][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.2984, 0.2569, 0.0134, 0.0592, 0.0494, 0.0439, 0.2787],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:22,071][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0050, 0.0712, 0.5758, 0.2777, 0.0481, 0.0187, 0.0035],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:22,072][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0983, 0.3557, 0.1600, 0.0216, 0.1127, 0.1204, 0.1313],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:22,072][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0008, 0.0466, 0.2052, 0.1131, 0.1038, 0.5229, 0.0075],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:22,073][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0152, 0.0838, 0.1441, 0.1106, 0.0167, 0.4954, 0.1342],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a]
[2024-07-24 10:31:22,073][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.0367, 0.0795, 0.2042, 0.1358, 0.1657, 0.1732, 0.0448, 0.1601],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:22,075][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([0.0248, 0.3474, 0.0512, 0.0734, 0.1054, 0.1555, 0.0833, 0.1588],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:22,076][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([0.0105, 0.2834, 0.0260, 0.2268, 0.0157, 0.4043, 0.0203, 0.0130],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:22,077][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([0.0344, 0.5099, 0.0290, 0.0886, 0.0077, 0.2555, 0.0398, 0.0349],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:22,079][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.0262, 0.0768, 0.1055, 0.0405, 0.4006, 0.1446, 0.0623, 0.1434],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:22,080][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([0.1035, 0.0550, 0.2002, 0.0430, 0.4072, 0.0347, 0.1187, 0.0377],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:22,082][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.0266, 0.6866, 0.0199, 0.0765, 0.0156, 0.1224, 0.0372, 0.0152],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:22,083][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.2317, 0.3815, 0.0183, 0.0706, 0.0381, 0.0251, 0.2264, 0.0083],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:22,085][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.0020, 0.0489, 0.4585, 0.4489, 0.0260, 0.0068, 0.0011, 0.0078],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:22,086][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([0.0442, 0.4342, 0.1285, 0.0162, 0.1590, 0.1011, 0.0710, 0.0459],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:22,087][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([4.4217e-04, 4.5033e-02, 9.0861e-02, 1.0314e-01, 6.2917e-02, 4.9396e-01,
        4.2226e-03, 1.9942e-01], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:22,088][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([0.0125, 0.1340, 0.0986, 0.1667, 0.0073, 0.3976, 0.0771, 0.1062],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long]
[2024-07-24 10:31:22,090][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.0612, 0.0630, 0.0973, 0.0972, 0.1085, 0.1605, 0.0701, 0.1163, 0.2260],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:22,091][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([0.0385, 0.3292, 0.0480, 0.0697, 0.0761, 0.1102, 0.0880, 0.1043, 0.1360],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:22,093][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([0.0127, 0.2413, 0.0222, 0.2363, 0.0133, 0.4264, 0.0244, 0.0167, 0.0068],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:22,094][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([0.0230, 0.5181, 0.0295, 0.0969, 0.0050, 0.2301, 0.0303, 0.0337, 0.0334],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:22,096][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.0141, 0.0698, 0.1386, 0.0418, 0.2671, 0.1727, 0.0374, 0.1300, 0.1283],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:22,096][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([0.0786, 0.0480, 0.1329, 0.0461, 0.2620, 0.0404, 0.0973, 0.0328, 0.2619],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:22,097][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.0257, 0.6834, 0.0173, 0.0843, 0.0112, 0.1218, 0.0333, 0.0122, 0.0107],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:22,097][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.2369, 0.3934, 0.0167, 0.0633, 0.0305, 0.0288, 0.2006, 0.0086, 0.0213],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:22,098][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([0.0033, 0.0497, 0.4985, 0.3803, 0.0368, 0.0096, 0.0019, 0.0117, 0.0082],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:22,098][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([0.0559, 0.4882, 0.0966, 0.0205, 0.1007, 0.0994, 0.0755, 0.0289, 0.0343],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:22,098][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.0006, 0.0392, 0.0740, 0.0959, 0.0376, 0.2731, 0.0044, 0.1417, 0.3335],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:22,099][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([0.0085, 0.1097, 0.0770, 0.1203, 0.0045, 0.2665, 0.0503, 0.0653, 0.2981],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument]
[2024-07-24 10:31:22,100][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0928, 0.0604, 0.0741, 0.1096, 0.0928, 0.1158, 0.0910, 0.0902, 0.1484,
        0.1248], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:22,102][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0280, 0.2466, 0.0439, 0.0497, 0.0944, 0.1049, 0.0731, 0.1012, 0.1861,
        0.0721], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:22,103][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0206, 0.2636, 0.0268, 0.1903, 0.0170, 0.3547, 0.0337, 0.0173, 0.0076,
        0.0683], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:22,105][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0470, 0.4022, 0.0401, 0.0868, 0.0127, 0.2067, 0.0544, 0.0487, 0.0501,
        0.0513], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:22,106][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0283, 0.0894, 0.1015, 0.0428, 0.2430, 0.1528, 0.0585, 0.1501, 0.1060,
        0.0277], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:22,107][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0867, 0.0460, 0.1443, 0.0361, 0.2785, 0.0290, 0.0959, 0.0343, 0.2261,
        0.0232], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:22,109][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0325, 0.6388, 0.0183, 0.0496, 0.0161, 0.0862, 0.0415, 0.0190, 0.0138,
        0.0843], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:22,110][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.2372, 0.2740, 0.0179, 0.0528, 0.0467, 0.0330, 0.2326, 0.0123, 0.0250,
        0.0686], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:22,112][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0018, 0.0522, 0.6064, 0.2742, 0.0335, 0.0075, 0.0012, 0.0125, 0.0084,
        0.0023], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:22,113][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0614, 0.3955, 0.1169, 0.0175, 0.1239, 0.0970, 0.0865, 0.0373, 0.0417,
        0.0223], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:22,115][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0005, 0.0311, 0.0924, 0.0592, 0.0531, 0.2371, 0.0045, 0.1424, 0.2500,
        0.1297], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:22,116][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0020, 0.0228, 0.0338, 0.0294, 0.0029, 0.1187, 0.0216, 0.0551, 0.3339,
        0.3799], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument,]
[2024-07-24 10:31:22,118][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0796, 0.0540, 0.0547, 0.0945, 0.0737, 0.1109, 0.0816, 0.0652, 0.1080,
        0.1060, 0.1718], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:22,119][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0281, 0.2285, 0.0462, 0.0550, 0.0991, 0.1167, 0.0729, 0.0904, 0.1554,
        0.0651, 0.0426], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:22,121][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0129, 0.2496, 0.0243, 0.1753, 0.0160, 0.3588, 0.0245, 0.0149, 0.0060,
        0.0602, 0.0577], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:22,122][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0433, 0.3847, 0.0374, 0.0807, 0.0142, 0.2193, 0.0475, 0.0532, 0.0521,
        0.0429, 0.0247], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:22,122][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0272, 0.0913, 0.0845, 0.0480, 0.2235, 0.1693, 0.0579, 0.1485, 0.0987,
        0.0282, 0.0229], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:22,123][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0880, 0.0500, 0.1229, 0.0403, 0.2688, 0.0315, 0.0933, 0.0382, 0.2097,
        0.0242, 0.0331], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:22,123][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0255, 0.6060, 0.0171, 0.0569, 0.0153, 0.1023, 0.0352, 0.0183, 0.0111,
        0.0803, 0.0319], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:22,124][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2124, 0.2820, 0.0134, 0.0596, 0.0421, 0.0353, 0.2100, 0.0110, 0.0187,
        0.0607, 0.0548], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:22,124][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0030, 0.0653, 0.5489, 0.2812, 0.0403, 0.0115, 0.0022, 0.0157, 0.0115,
        0.0041, 0.0162], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:22,124][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0508, 0.4160, 0.0951, 0.0233, 0.1032, 0.1159, 0.0762, 0.0326, 0.0332,
        0.0254, 0.0283], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:22,125][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0006, 0.0278, 0.0637, 0.0599, 0.0587, 0.2410, 0.0046, 0.1371, 0.2179,
        0.1176, 0.0710], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:22,126][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0023, 0.0227, 0.0295, 0.0353, 0.0034, 0.1365, 0.0212, 0.0495, 0.2254,
        0.3366, 0.1378], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and]
[2024-07-24 10:31:22,128][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.0533, 0.0477, 0.0489, 0.0803, 0.0633, 0.1016, 0.0594, 0.0742, 0.1242,
        0.0855, 0.1259, 0.1358], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:22,129][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([0.0166, 0.2389, 0.0411, 0.0527, 0.0890, 0.1336, 0.0498, 0.0921, 0.1335,
        0.0583, 0.0341, 0.0602], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:22,131][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([0.0039, 0.2052, 0.0160, 0.1485, 0.0097, 0.4956, 0.0112, 0.0100, 0.0038,
        0.0495, 0.0438, 0.0026], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:22,132][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([0.0339, 0.4132, 0.0326, 0.0916, 0.0123, 0.2387, 0.0408, 0.0368, 0.0346,
        0.0346, 0.0217, 0.0092], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:22,133][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.0132, 0.0560, 0.0592, 0.0384, 0.1997, 0.2030, 0.0371, 0.1529, 0.1080,
        0.0268, 0.0208, 0.0848], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:22,134][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([0.0625, 0.0391, 0.1065, 0.0342, 0.2757, 0.0345, 0.0795, 0.0359, 0.1894,
        0.0229, 0.0317, 0.0880], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:22,136][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.0138, 0.5668, 0.0175, 0.0536, 0.0134, 0.1569, 0.0238, 0.0149, 0.0099,
        0.0946, 0.0293, 0.0054], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:22,137][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.1755, 0.3033, 0.0105, 0.0445, 0.0398, 0.0319, 0.1825, 0.0101, 0.0207,
        0.0781, 0.0515, 0.0517], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:22,139][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.0019, 0.0470, 0.4939, 0.3476, 0.0467, 0.0144, 0.0014, 0.0132, 0.0095,
        0.0027, 0.0133, 0.0085], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:22,140][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([0.0327, 0.4026, 0.0800, 0.0181, 0.0851, 0.1696, 0.0577, 0.0332, 0.0374,
        0.0287, 0.0252, 0.0298], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:22,141][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([2.3893e-04, 2.2389e-02, 9.2521e-02, 5.0935e-02, 5.5888e-02, 3.0307e-01,
        2.5627e-03, 1.4282e-01, 1.7777e-01, 9.3569e-02, 5.4815e-02, 3.4218e-03],
       device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:22,143][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([0.0014, 0.0223, 0.0425, 0.0361, 0.0039, 0.2080, 0.0161, 0.0554, 0.2196,
        0.2610, 0.1155, 0.0183], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards]
[2024-07-24 10:31:22,144][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Melissa] are: tensor([0.0299, 0.0322, 0.0658, 0.0561, 0.0770, 0.1070, 0.0404, 0.0776, 0.1519,
        0.0680, 0.0871, 0.1176, 0.0895], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:22,145][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Melissa] are: tensor([0.0189, 0.2745, 0.0363, 0.0570, 0.0793, 0.1314, 0.0557, 0.0670, 0.0968,
        0.0727, 0.0434, 0.0514, 0.0157], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:22,147][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Melissa] are: tensor([0.0087, 0.2547, 0.0113, 0.1802, 0.0083, 0.3949, 0.0188, 0.0086, 0.0028,
        0.0574, 0.0506, 0.0032, 0.0004], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:22,148][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Melissa] are: tensor([0.0325, 0.4218, 0.0264, 0.0901, 0.0086, 0.2206, 0.0353, 0.0467, 0.0471,
        0.0339, 0.0238, 0.0103, 0.0027], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:22,149][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Melissa] are: tensor([0.0070, 0.0408, 0.0615, 0.0331, 0.1927, 0.2005, 0.0271, 0.1329, 0.1049,
        0.0243, 0.0187, 0.0728, 0.0836], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:22,149][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Melissa] are: tensor([0.0493, 0.0404, 0.0712, 0.0307, 0.1906, 0.0303, 0.0591, 0.0233, 0.1283,
        0.0249, 0.0297, 0.0887, 0.2334], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:22,150][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Melissa] are: tensor([0.0147, 0.5849, 0.0116, 0.0618, 0.0089, 0.1356, 0.0221, 0.0087, 0.0055,
        0.1051, 0.0370, 0.0033, 0.0007], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:22,150][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Melissa] are: tensor([0.1842, 0.3248, 0.0067, 0.0410, 0.0275, 0.0221, 0.1730, 0.0063, 0.0142,
        0.0951, 0.0589, 0.0348, 0.0114], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:22,151][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Melissa] are: tensor([0.0009, 0.0356, 0.5453, 0.3264, 0.0409, 0.0096, 0.0008, 0.0134, 0.0049,
        0.0016, 0.0115, 0.0058, 0.0033], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:22,151][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Melissa] are: tensor([0.0278, 0.3737, 0.0531, 0.0176, 0.0886, 0.1521, 0.0486, 0.0274, 0.0258,
        0.0339, 0.0349, 0.0327, 0.0839], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:22,152][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Melissa] are: tensor([0.0006, 0.0332, 0.0742, 0.0707, 0.0554, 0.2245, 0.0048, 0.1256, 0.2007,
        0.1054, 0.0771, 0.0057, 0.0222], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:22,154][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Melissa] are: tensor([0.0013, 0.0382, 0.0569, 0.0497, 0.0045, 0.1752, 0.0122, 0.0529, 0.1831,
        0.2756, 0.1203, 0.0211, 0.0090], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa]
[2024-07-24 10:31:22,155][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.0622, 0.0361, 0.0257, 0.0617, 0.0534, 0.1046, 0.0649, 0.0440, 0.0860,
        0.0855, 0.1395, 0.0853, 0.0422, 0.1089], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:22,157][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([0.0234, 0.2482, 0.0402, 0.0670, 0.0702, 0.1097, 0.0582, 0.0658, 0.0845,
        0.0627, 0.0478, 0.0610, 0.0192, 0.0421], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:22,158][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([0.0072, 0.1759, 0.0236, 0.1941, 0.0167, 0.3887, 0.0180, 0.0161, 0.0058,
        0.0552, 0.0549, 0.0057, 0.0011, 0.0369], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:22,159][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([0.0272, 0.3569, 0.0391, 0.0957, 0.0118, 0.2136, 0.0327, 0.0514, 0.0562,
        0.0367, 0.0282, 0.0114, 0.0040, 0.0350], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:22,160][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([0.0065, 0.0414, 0.0737, 0.0280, 0.1509, 0.1611, 0.0187, 0.1155, 0.0876,
        0.0181, 0.0153, 0.0592, 0.0655, 0.1585], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:22,162][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([0.0436, 0.0484, 0.0727, 0.0436, 0.1748, 0.0344, 0.0545, 0.0226, 0.1164,
        0.0295, 0.0424, 0.0932, 0.1448, 0.0790], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:22,163][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([0.0155, 0.5613, 0.0176, 0.0694, 0.0129, 0.1083, 0.0247, 0.0146, 0.0084,
        0.0903, 0.0397, 0.0059, 0.0011, 0.0301], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:22,165][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.1614, 0.2830, 0.0125, 0.0548, 0.0340, 0.0287, 0.1503, 0.0098, 0.0213,
        0.0806, 0.0631, 0.0416, 0.0162, 0.0427], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:22,166][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([0.0018, 0.0395, 0.4573, 0.2887, 0.0429, 0.0209, 0.0023, 0.0263, 0.0142,
        0.0073, 0.0299, 0.0142, 0.0106, 0.0441], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:22,168][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([0.0327, 0.3984, 0.0610, 0.0222, 0.0824, 0.0932, 0.0483, 0.0238, 0.0217,
        0.0247, 0.0278, 0.0360, 0.0477, 0.0800], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:22,169][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([0.0008, 0.0310, 0.0594, 0.0685, 0.0466, 0.2887, 0.0050, 0.1039, 0.1390,
        0.1093, 0.0709, 0.0052, 0.0167, 0.0549], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:22,171][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([0.0010, 0.0178, 0.0384, 0.0393, 0.0029, 0.1922, 0.0090, 0.0448, 0.1433,
        0.2005, 0.1031, 0.0119, 0.0053, 0.1907], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said]
[2024-07-24 10:31:22,172][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0540, 0.0369, 0.0248, 0.0554, 0.0450, 0.0842, 0.0571, 0.0422, 0.0797,
        0.0649, 0.1067, 0.0900, 0.0442, 0.0971, 0.1180], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:22,174][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0204, 0.2117, 0.0262, 0.0442, 0.0758, 0.1091, 0.0566, 0.0823, 0.1294,
        0.0552, 0.0328, 0.0597, 0.0228, 0.0376, 0.0363], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:22,175][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0062, 0.1948, 0.0160, 0.1483, 0.0114, 0.4512, 0.0147, 0.0112, 0.0045,
        0.0467, 0.0451, 0.0033, 0.0007, 0.0290, 0.0166], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:22,175][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0336, 0.2817, 0.0389, 0.0794, 0.0152, 0.2540, 0.0408, 0.0604, 0.0623,
        0.0427, 0.0253, 0.0113, 0.0048, 0.0354, 0.0142], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:22,176][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0118, 0.0482, 0.0464, 0.0271, 0.1556, 0.1441, 0.0297, 0.1217, 0.0854,
        0.0188, 0.0140, 0.0666, 0.0618, 0.1334, 0.0353], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:22,176][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0497, 0.0298, 0.0684, 0.0219, 0.1764, 0.0178, 0.0505, 0.0231, 0.1548,
        0.0158, 0.0194, 0.0670, 0.1923, 0.0475, 0.0654], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:22,176][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0158, 0.5812, 0.0120, 0.0497, 0.0117, 0.0992, 0.0243, 0.0165, 0.0105,
        0.0877, 0.0283, 0.0056, 0.0011, 0.0282, 0.0283], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:22,177][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.1758, 0.2501, 0.0082, 0.0392, 0.0303, 0.0248, 0.1642, 0.0086, 0.0178,
        0.0600, 0.0458, 0.0372, 0.0148, 0.0310, 0.0922], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:22,177][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0015, 0.0462, 0.4686, 0.2811, 0.0351, 0.0107, 0.0015, 0.0162, 0.0094,
        0.0034, 0.0164, 0.0082, 0.0055, 0.0354, 0.0606], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:22,178][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0344, 0.3143, 0.0484, 0.0131, 0.0613, 0.0883, 0.0513, 0.0239, 0.0263,
        0.0214, 0.0199, 0.0225, 0.0605, 0.0788, 0.1357], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:22,180][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0003, 0.0196, 0.0736, 0.0428, 0.0487, 0.2219, 0.0027, 0.1277, 0.2057,
        0.0918, 0.0510, 0.0034, 0.0197, 0.0494, 0.0417], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:22,181][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0014, 0.0165, 0.0280, 0.0246, 0.0022, 0.0992, 0.0140, 0.0391, 0.1965,
        0.2331, 0.0932, 0.0131, 0.0075, 0.1805, 0.0509], device='cuda:0') for source tokens [Then, Melissa and Benjamin had a long argument, and afterwards Melissa said to]
[2024-07-24 10:31:22,182][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:31:22,184][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[2029],
        [   8],
        [  42],
        [   7],
        [   1],
        [   6],
        [   3],
        [   1],
        [   4],
        [   1],
        [   1],
        [   1],
        [   6],
        [   2],
        [   1]], device='cuda:0')
[2024-07-24 10:31:22,186][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[2060],
        [   8],
        [  44],
        [   7],
        [   1],
        [   5],
        [   3],
        [   1],
        [   3],
        [   1],
        [   2],
        [   2],
        [   5],
        [   2],
        [   2]], device='cuda:0')
[2024-07-24 10:31:22,187][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[7068],
        [5594],
        [6400],
        [6341],
        [6996],
        [8144],
        [8174],
        [8235],
        [8403],
        [8195],
        [8485],
        [8562],
        [8971],
        [8990],
        [8998]], device='cuda:0')
[2024-07-24 10:31:22,189][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[ 1148],
        [11853],
        [15313],
        [16424],
        [21668],
        [27964],
        [31321],
        [33590],
        [33616],
        [36490],
        [36035],
        [36152],
        [34464],
        [33698],
        [35932]], device='cuda:0')
[2024-07-24 10:31:22,190][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 2910],
        [28894],
        [32160],
        [39225],
        [39080],
        [37321],
        [34379],
        [35646],
        [35381],
        [35805],
        [35939],
        [34685],
        [35195],
        [36048],
        [34644]], device='cuda:0')
[2024-07-24 10:31:22,191][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[41919],
        [44818],
        [44915],
        [45740],
        [45417],
        [45025],
        [44970],
        [44988],
        [45003],
        [45055],
        [44998],
        [45020],
        [45019],
        [44987],
        [44845]], device='cuda:0')
[2024-07-24 10:31:22,193][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[31044],
        [30630],
        [24981],
        [27971],
        [30272],
        [30827],
        [31422],
        [30726],
        [30518],
        [30803],
        [31217],
        [32208],
        [32014],
        [32061],
        [32528]], device='cuda:0')
[2024-07-24 10:31:22,194][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[43707],
        [44455],
        [38680],
        [40676],
        [39062],
        [39370],
        [40127],
        [39828],
        [40713],
        [40717],
        [41095],
        [39892],
        [38143],
        [39596],
        [39344]], device='cuda:0')
[2024-07-24 10:31:22,196][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[19170],
        [23998],
        [24501],
        [22999],
        [23682],
        [25824],
        [26868],
        [26428],
        [26220],
        [26984],
        [26723],
        [27535],
        [26736],
        [27319],
        [27901]], device='cuda:0')
[2024-07-24 10:31:22,197][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[45928],
        [37245],
        [36595],
        [34798],
        [34324],
        [34699],
        [39016],
        [37455],
        [37567],
        [38151],
        [37513],
        [37438],
        [37475],
        [37760],
        [38306]], device='cuda:0')
[2024-07-24 10:31:22,199][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[ 9654],
        [10076],
        [ 7577],
        [ 7644],
        [ 7667],
        [ 7735],
        [ 7860],
        [ 7827],
        [ 7803],
        [ 7856],
        [ 7886],
        [ 7886],
        [ 7865],
        [ 7859],
        [ 7854]], device='cuda:0')
[2024-07-24 10:31:22,200][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[16480],
        [16466],
        [16316],
        [13242],
        [  544],
        [  756],
        [ 1516],
        [  847],
        [ 2609],
        [14632],
        [15136],
        [ 7616],
        [ 9047],
        [10941],
        [14592]], device='cuda:0')
[2024-07-24 10:31:22,202][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[36266],
        [36165],
        [36428],
        [36673],
        [40839],
        [37093],
        [15835],
        [29428],
        [26059],
        [34255],
        [38419],
        [27403],
        [34823],
        [32929],
        [29906]], device='cuda:0')
[2024-07-24 10:31:22,203][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[28514],
        [ 5318],
        [ 8673],
        [ 8219],
        [  487],
        [ 1839],
        [ 4200],
        [ 2580],
        [ 4843],
        [  249],
        [  355],
        [ 1179],
        [  945],
        [ 2051],
        [  594]], device='cuda:0')
[2024-07-24 10:31:22,204][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[13847],
        [12399],
        [10548],
        [12536],
        [12762],
        [14403],
        [11101],
        [13452],
        [12084],
        [12131],
        [13159],
        [14342],
        [12125],
        [10425],
        [11439]], device='cuda:0')
[2024-07-24 10:31:22,205][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[18312],
        [21007],
        [23877],
        [24159],
        [22957],
        [22114],
        [22161],
        [22669],
        [20315],
        [20909],
        [20943],
        [20188],
        [21596],
        [21574],
        [21334]], device='cuda:0')
[2024-07-24 10:31:22,206][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[16574],
        [28673],
        [25810],
        [24951],
        [25070],
        [22732],
        [22085],
        [23828],
        [24005],
        [24075],
        [23801],
        [23849],
        [23922],
        [23795],
        [23789]], device='cuda:0')
[2024-07-24 10:31:22,207][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[38162],
        [33546],
        [33880],
        [33660],
        [33720],
        [36644],
        [37450],
        [37101],
        [37327],
        [37174],
        [37157],
        [37670],
        [37127],
        [37536],
        [37772]], device='cuda:0')
[2024-07-24 10:31:22,209][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[16583],
        [14735],
        [15508],
        [16506],
        [15938],
        [18052],
        [18738],
        [18952],
        [18946],
        [19651],
        [19774],
        [19453],
        [19574],
        [19663],
        [20119]], device='cuda:0')
[2024-07-24 10:31:22,210][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[18455],
        [ 5928],
        [ 9722],
        [ 9164],
        [ 9928],
        [ 9088],
        [ 8492],
        [ 9893],
        [10257],
        [10071],
        [ 9834],
        [10001],
        [10093],
        [10344],
        [10170]], device='cuda:0')
[2024-07-24 10:31:22,212][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[5583],
        [3694],
        [3471],
        [3698],
        [4755],
        [4911],
        [4583],
        [4810],
        [5560],
        [5523],
        [5590],
        [6330],
        [7179],
        [7176],
        [7256]], device='cuda:0')
[2024-07-24 10:31:22,213][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[20839],
        [ 8165],
        [ 7905],
        [ 7182],
        [ 7108],
        [ 6145],
        [ 5550],
        [ 5723],
        [ 5676],
        [ 4998],
        [ 4796],
        [ 4638],
        [ 4743],
        [ 4526],
        [ 4534]], device='cuda:0')
[2024-07-24 10:31:22,215][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[21606],
        [19683],
        [20190],
        [21010],
        [20878],
        [21357],
        [21323],
        [21454],
        [21622],
        [21636],
        [21936],
        [22375],
        [22200],
        [22843],
        [23488]], device='cuda:0')
[2024-07-24 10:31:22,216][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[22035],
        [22780],
        [23239],
        [23127],
        [23123],
        [23138],
        [23150],
        [23131],
        [23140],
        [23173],
        [23139],
        [23122],
        [23143],
        [23064],
        [23063]], device='cuda:0')
[2024-07-24 10:31:22,218][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[23419],
        [15289],
        [15988],
        [15708],
        [14285],
        [13991],
        [14113],
        [14092],
        [14267],
        [13859],
        [13461],
        [12799],
        [12485],
        [12601],
        [12105]], device='cuda:0')
[2024-07-24 10:31:22,219][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[ 8830],
        [13305],
        [22492],
        [26622],
        [26122],
        [23001],
        [23557],
        [23524],
        [22395],
        [22841],
        [23057],
        [23190],
        [23573],
        [23528],
        [23155]], device='cuda:0')
[2024-07-24 10:31:22,220][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[13711],
        [11134],
        [10731],
        [ 9470],
        [ 9412],
        [ 6857],
        [ 6976],
        [ 7120],
        [ 8607],
        [ 9181],
        [ 8784],
        [ 8641],
        [ 8579],
        [ 8651],
        [ 8979]], device='cuda:0')
[2024-07-24 10:31:22,222][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[18362],
        [26609],
        [23758],
        [22875],
        [22646],
        [22890],
        [22694],
        [22022],
        [21486],
        [21305],
        [21451],
        [21363],
        [21162],
        [20607],
        [20411]], device='cuda:0')
[2024-07-24 10:31:22,223][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[32742],
        [29871],
        [35482],
        [33128],
        [32108],
        [32225],
        [34659],
        [33762],
        [33562],
        [33437],
        [32547],
        [31851],
        [34052],
        [36554],
        [34902]], device='cuda:0')
[2024-07-24 10:31:22,225][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[7659],
        [7659],
        [7659],
        [7659],
        [7659],
        [7659],
        [7659],
        [7659],
        [7659],
        [7659],
        [7659],
        [7659],
        [7659],
        [7659],
        [7659]], device='cuda:0')
