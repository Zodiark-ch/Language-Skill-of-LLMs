[2024-07-24 10:24:09,439][explain_satisfiability.py][line:287][INFO] ############ CASE TEXT isThen, Erica and Joshua went to the office. Erica gave a basketball to
[2024-07-24 10:24:09,439][explain_satisfiability.py][line:288][INFO] ############ CASE Prediction is  Joshua
[2024-07-24 10:24:09,439][explain_satisfiability.py][line:289][INFO] ############ Refined Forward Graph
[2024-07-24 10:24:09,439][explain_satisfiability.py][line:290][INFO] ****** Layer 1
[2024-07-24 10:24:09,439][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 0
[2024-07-24 10:24:09,440][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,440][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 1
[2024-07-24 10:24:09,440][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit24', 'circuit27']
[2024-07-24 10:24:09,440][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 2
[2024-07-24 10:24:09,441][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit23', 'circuit26']
[2024-07-24 10:24:09,441][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 3
[2024-07-24 10:24:09,441][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,442][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 4
[2024-07-24 10:24:09,442][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit4', 'circuit5', 'circuit6', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,442][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 5
[2024-07-24 10:24:09,442][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit7', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,443][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 6
[2024-07-24 10:24:09,443][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit6', 'circuit7', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,443][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 7
[2024-07-24 10:24:09,443][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit3', 'circuit7', 'circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,444][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 8
[2024-07-24 10:24:09,444][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,444][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 9
[2024-07-24 10:24:09,444][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit2', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,444][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 10
[2024-07-24 10:24:09,445][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit6', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,445][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 11
[2024-07-24 10:24:09,445][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,445][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 12
[2024-07-24 10:24:09,445][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit2', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:24:09,445][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 13
[2024-07-24 10:24:09,446][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,446][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 14
[2024-07-24 10:24:09,446][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:24:09,446][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 15
[2024-07-24 10:24:09,446][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,446][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 16
[2024-07-24 10:24:09,446][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,447][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 17
[2024-07-24 10:24:09,447][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:24:09,447][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 18
[2024-07-24 10:24:09,447][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit4', 'circuit5', 'circuit6', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,447][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 19
[2024-07-24 10:24:09,447][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit3', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,447][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 20
[2024-07-24 10:24:09,448][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit22', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,448][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 21
[2024-07-24 10:24:09,448][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,448][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 22
[2024-07-24 10:24:09,448][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,448][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 23
[2024-07-24 10:24:09,449][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit26']
[2024-07-24 10:24:09,449][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 24
[2024-07-24 10:24:09,449][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:24:09,449][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 25
[2024-07-24 10:24:09,449][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:24:09,449][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 26
[2024-07-24 10:24:09,449][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,450][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 27
[2024-07-24 10:24:09,450][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,450][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 28
[2024-07-24 10:24:09,450][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,450][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 0
[2024-07-24 10:24:09,450][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit5', 'circuit7', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,451][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,451][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 1
[2024-07-24 10:24:09,451][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,451][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,451][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 2
[2024-07-24 10:24:09,451][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:24:09,451][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit12', 'circuit14', 'circuit15', 'circuit19', 'circuit22']
[2024-07-24 10:24:09,452][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 3
[2024-07-24 10:24:09,452][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit18', 'circuit20', 'circuit23', 'circuit24']
[2024-07-24 10:24:09,452][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,452][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 4
[2024-07-24 10:24:09,452][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit21']
[2024-07-24 10:24:09,452][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit25']
[2024-07-24 10:24:09,452][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 5
[2024-07-24 10:24:09,453][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:24:09,453][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,453][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 6
[2024-07-24 10:24:09,453][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:24:09,453][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit2']
[2024-07-24 10:24:09,453][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 7
[2024-07-24 10:24:09,454][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,454][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:24:09,454][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 8
[2024-07-24 10:24:09,454][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit24', 'circuit26']
[2024-07-24 10:24:09,454][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit17', 'circuit24', 'circuit26']
[2024-07-24 10:24:09,454][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 9
[2024-07-24 10:24:09,454][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,455][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit5', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:24:09,455][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 10
[2024-07-24 10:24:09,455][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit24', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,455][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit24']
[2024-07-24 10:24:09,455][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 11
[2024-07-24 10:24:09,455][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:24:09,456][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit2', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:24:09,456][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 12
[2024-07-24 10:24:09,456][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit24', 'circuit26']
[2024-07-24 10:24:09,456][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,456][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 13
[2024-07-24 10:24:09,456][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit5', 'circuit7', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,456][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,457][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 14
[2024-07-24 10:24:09,457][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:24:09,457][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,457][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 15
[2024-07-24 10:24:09,457][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,457][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit7', 'circuit8', 'circuit13', 'circuit26']
[2024-07-24 10:24:09,457][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 16
[2024-07-24 10:24:09,458][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:24:09,458][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,458][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 17
[2024-07-24 10:24:09,458][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit3', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,458][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit4', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:24:09,458][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 18
[2024-07-24 10:24:09,459][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:24:09,459][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit17', 'circuit21', 'circuit22']
[2024-07-24 10:24:09,459][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 19
[2024-07-24 10:24:09,459][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:24:09,459][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit23', 'circuit24']
[2024-07-24 10:24:09,459][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 20
[2024-07-24 10:24:09,459][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:24:09,460][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,460][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 21
[2024-07-24 10:24:09,460][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:24:09,460][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,460][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 22
[2024-07-24 10:24:09,460][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:24:09,460][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,461][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 23
[2024-07-24 10:24:09,461][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit24']
[2024-07-24 10:24:09,461][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit23', 'circuit24']
[2024-07-24 10:24:09,461][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 24
[2024-07-24 10:24:09,461][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:24:09,461][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit20', 'circuit23', 'circuit24']
[2024-07-24 10:24:09,461][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 25
[2024-07-24 10:24:09,462][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,462][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit26']
[2024-07-24 10:24:09,462][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 26
[2024-07-24 10:24:09,462][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,462][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,462][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 27
[2024-07-24 10:24:09,463][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,463][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,463][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 28
[2024-07-24 10:24:09,463][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,463][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,463][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 0
[2024-07-24 10:24:09,463][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,464][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit5', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,464][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,464][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 1
[2024-07-24 10:24:09,464][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:24:09,464][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit3', 'circuit4', 'circuit13', 'circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:24:09,464][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:24:09,464][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 2
[2024-07-24 10:24:09,465][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,465][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit6', 'circuit7', 'circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,465][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit6', 'circuit7', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,465][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 3
[2024-07-24 10:24:09,465][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:24:09,465][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit26']
[2024-07-24 10:24:09,465][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:24:09,466][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 4
[2024-07-24 10:24:09,466][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit20', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,466][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit18', 'circuit19', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:24:09,466][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:24:09,466][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 5
[2024-07-24 10:24:09,466][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit6', 'circuit7', 'circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,467][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,467][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit7', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,467][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 6
[2024-07-24 10:24:09,467][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,467][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit4', 'circuit5', 'circuit6', 'circuit8', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,467][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit4', 'circuit6', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,467][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 7
[2024-07-24 10:24:09,468][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit5', 'circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,468][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:24:09,468][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,468][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 8
[2024-07-24 10:24:09,468][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit5', 'circuit8', 'circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:24:09,468][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21']
[2024-07-24 10:24:09,469][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:24:09,469][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 9
[2024-07-24 10:24:09,469][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit2', 'circuit7', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,469][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit6', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,469][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,469][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 10
[2024-07-24 10:24:09,469][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:24:09,470][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit4', 'circuit10', 'circuit11', 'circuit12', 'circuit14', 'circuit17']
[2024-07-24 10:24:09,470][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit17', 'circuit23']
[2024-07-24 10:24:09,470][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 11
[2024-07-24 10:24:09,470][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,470][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:24:09,470][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit4', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,471][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 12
[2024-07-24 10:24:09,471][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:24:09,471][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,471][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:24:09,471][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 13
[2024-07-24 10:24:09,471][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit4', 'circuit5', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,471][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,472][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,472][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 14
[2024-07-24 10:24:09,472][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,472][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit10', 'circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:24:09,472][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:24:09,472][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 15
[2024-07-24 10:24:09,473][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,473][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit4', 'circuit5', 'circuit6', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:24:09,473][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:24:09,473][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 16
[2024-07-24 10:24:09,473][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit7', 'circuit8', 'circuit11', 'circuit14', 'circuit27']
[2024-07-24 10:24:09,473][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit23', 'circuit27']
[2024-07-24 10:24:09,473][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,474][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 17
[2024-07-24 10:24:09,474][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,474][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,474][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,474][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 18
[2024-07-24 10:24:09,474][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,474][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,475][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit1', 'circuit4', 'circuit5', 'circuit7', 'circuit8', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,475][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 19
[2024-07-24 10:24:09,475][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:24:09,475][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit9', 'circuit13', 'circuit16', 'circuit17', 'circuit20']
[2024-07-24 10:24:09,475][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:24:09,475][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 20
[2024-07-24 10:24:09,476][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,476][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:24:09,476][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,476][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 21
[2024-07-24 10:24:09,476][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,476][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,476][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit4', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:24:09,477][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 22
[2024-07-24 10:24:09,477][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:24:09,477][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit17', 'circuit20', 'circuit23', 'circuit24']
[2024-07-24 10:24:09,477][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,477][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 23
[2024-07-24 10:24:09,477][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:24:09,478][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,478][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,478][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 24
[2024-07-24 10:24:09,478][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:24:09,478][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit20', 'circuit21', 'circuit24']
[2024-07-24 10:24:09,478][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:24:09,478][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 25
[2024-07-24 10:24:09,479][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,479][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit1', 'circuit11', 'circuit12']
[2024-07-24 10:24:09,479][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2']
[2024-07-24 10:24:09,479][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 26
[2024-07-24 10:24:09,479][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,479][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,480][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,480][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 27
[2024-07-24 10:24:09,480][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,480][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,480][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,480][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 28
[2024-07-24 10:24:09,480][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,481][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,481][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,481][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 0
[2024-07-24 10:24:09,481][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit2', 'circuit3', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,481][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,481][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,482][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit4', 'circuit5', 'circuit7', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,482][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 1
[2024-07-24 10:24:09,482][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,482][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,482][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,482][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit13']
[2024-07-24 10:24:09,482][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 2
[2024-07-24 10:24:09,483][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit5', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,483][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit5', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,483][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit5', 'circuit8', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,483][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit2', 'circuit8', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,483][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 3
[2024-07-24 10:24:09,483][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit6', 'circuit7', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,484][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit4', 'circuit5', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:24:09,484][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit24']
[2024-07-24 10:24:09,484][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit15', 'circuit20', 'circuit21', 'circuit25']
[2024-07-24 10:24:09,484][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 4
[2024-07-24 10:24:09,484][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit26']
[2024-07-24 10:24:09,484][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit20']
[2024-07-24 10:24:09,484][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit26']
[2024-07-24 10:24:09,485][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit17', 'circuit19', 'circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:24:09,485][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 5
[2024-07-24 10:24:09,485][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,485][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit2', 'circuit14', 'circuit26']
[2024-07-24 10:24:09,485][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit24']
[2024-07-24 10:24:09,485][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,485][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 6
[2024-07-24 10:24:09,486][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit20', 'circuit24', 'circuit27']
[2024-07-24 10:24:09,486][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,486][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit22']
[2024-07-24 10:24:09,486][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit25']
[2024-07-24 10:24:09,486][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 7
[2024-07-24 10:24:09,486][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,487][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit4', 'circuit6', 'circuit7', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,487][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit6', 'circuit14', 'circuit15', 'circuit26']
[2024-07-24 10:24:09,487][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:24:09,487][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 8
[2024-07-24 10:24:09,487][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit19', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,487][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit2', 'circuit5', 'circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:24:09,487][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,488][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,488][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 9
[2024-07-24 10:24:09,488][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,488][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,488][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,488][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit1', 'circuit14', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,489][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 10
[2024-07-24 10:24:09,489][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit2', 'circuit3', 'circuit9', 'circuit10', 'circuit12', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:24:09,489][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit20']
[2024-07-24 10:24:09,489][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit20', 'circuit22']
[2024-07-24 10:24:09,489][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit16', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:24:09,489][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 11
[2024-07-24 10:24:09,489][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:24:09,490][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,490][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,490][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,490][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 12
[2024-07-24 10:24:09,490][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9']
[2024-07-24 10:24:09,490][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit16', 'circuit22']
[2024-07-24 10:24:09,491][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16']
[2024-07-24 10:24:09,491][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23']
[2024-07-24 10:24:09,491][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 13
[2024-07-24 10:24:09,491][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,491][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,491][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,491][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,492][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 14
[2024-07-24 10:24:09,492][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit15', 'circuit19', 'circuit20', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,492][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,492][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,492][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit17', 'circuit21', 'circuit23', 'circuit25']
[2024-07-24 10:24:09,492][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 15
[2024-07-24 10:24:09,493][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:24:09,493][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:24:09,493][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:24:09,493][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:24:09,493][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 16
[2024-07-24 10:24:09,493][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,493][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit21']
[2024-07-24 10:24:09,494][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13']
[2024-07-24 10:24:09,494][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:24:09,494][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 17
[2024-07-24 10:24:09,494][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit27']
[2024-07-24 10:24:09,494][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit20', 'circuit25']
[2024-07-24 10:24:09,494][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:24:09,494][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:24:09,495][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 18
[2024-07-24 10:24:09,495][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,495][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit21', 'circuit22']
[2024-07-24 10:24:09,495][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,495][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,495][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 19
[2024-07-24 10:24:09,496][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,496][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,496][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,496][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,496][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 20
[2024-07-24 10:24:09,496][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,496][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit5', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:24:09,497][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit17', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:24:09,497][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:24:09,497][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 21
[2024-07-24 10:24:09,497][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit27']
[2024-07-24 10:24:09,497][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit27']
[2024-07-24 10:24:09,497][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,498][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit21', 'circuit27']
[2024-07-24 10:24:09,498][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 22
[2024-07-24 10:24:09,498][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit15']
[2024-07-24 10:24:09,498][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit6', 'circuit9', 'circuit10', 'circuit13', 'circuit15', 'circuit20']
[2024-07-24 10:24:09,498][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit26']
[2024-07-24 10:24:09,498][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,498][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 23
[2024-07-24 10:24:09,499][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit12', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:24:09,499][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,499][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,499][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,499][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 24
[2024-07-24 10:24:09,499][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit6', 'circuit9', 'circuit10', 'circuit12', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,499][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit25']
[2024-07-24 10:24:09,500][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:24:09,500][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:24:09,500][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 25
[2024-07-24 10:24:09,500][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,500][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,500][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,501][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,501][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 26
[2024-07-24 10:24:09,501][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,501][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,501][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,501][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,501][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 27
[2024-07-24 10:24:09,502][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,502][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,502][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,502][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,502][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 28
[2024-07-24 10:24:09,502][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,503][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,503][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,503][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,503][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 0
[2024-07-24 10:24:09,503][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,503][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit5', 'circuit6', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,503][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,504][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit5', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,504][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,504][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 1
[2024-07-24 10:24:09,504][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit6', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,504][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit4', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:24:09,504][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:24:09,505][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:24:09,505][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,505][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 2
[2024-07-24 10:24:09,505][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit6', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,505][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,505][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:24:09,505][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:24:09,506][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,506][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 3
[2024-07-24 10:24:09,506][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit6', 'circuit9', 'circuit10', 'circuit22', 'circuit23', 'circuit28']
[2024-07-24 10:24:09,506][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:24:09,506][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:24:09,506][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit25']
[2024-07-24 10:24:09,507][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit23', 'circuit24']
[2024-07-24 10:24:09,507][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 4
[2024-07-24 10:24:09,507][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,507][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit17']
[2024-07-24 10:24:09,507][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14']
[2024-07-24 10:24:09,507][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:24:09,507][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit21', 'circuit24', 'circuit27']
[2024-07-24 10:24:09,508][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 5
[2024-07-24 10:24:09,508][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:24:09,508][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit17', 'circuit20']
[2024-07-24 10:24:09,508][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:24:09,508][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit21', 'circuit23', 'circuit25']
[2024-07-24 10:24:09,508][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit24']
[2024-07-24 10:24:09,509][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 6
[2024-07-24 10:24:09,509][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit5', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,509][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit3', 'circuit4', 'circuit5', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,509][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit6', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,509][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,509][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,509][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 7
[2024-07-24 10:24:09,510][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,510][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,510][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,510][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:24:09,510][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,510][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 8
[2024-07-24 10:24:09,511][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit7', 'circuit8', 'circuit13', 'circuit14', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit24']
[2024-07-24 10:24:09,511][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit1', 'circuit2', 'circuit9', 'circuit12', 'circuit13', 'circuit21', 'circuit24']
[2024-07-24 10:24:09,511][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit14', 'circuit15', 'circuit16', 'circuit18']
[2024-07-24 10:24:09,511][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit16', 'circuit21', 'circuit23', 'circuit24']
[2024-07-24 10:24:09,511][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,511][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 9
[2024-07-24 10:24:09,511][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,512][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit5', 'circuit6', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,512][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,512][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit15', 'circuit16', 'circuit19', 'circuit21', 'circuit25', 'circuit26']
[2024-07-24 10:24:09,512][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:24:09,512][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 10
[2024-07-24 10:24:09,512][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit6', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,513][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit5', 'circuit6', 'circuit7', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:24:09,513][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:24:09,513][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:24:09,513][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:24:09,513][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 11
[2024-07-24 10:24:09,513][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit27']
[2024-07-24 10:24:09,513][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit21']
[2024-07-24 10:24:09,514][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit15', 'circuit22']
[2024-07-24 10:24:09,514][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14']
[2024-07-24 10:24:09,514][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit18', 'circuit19', 'circuit22']
[2024-07-24 10:24:09,514][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 12
[2024-07-24 10:24:09,514][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit2', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:24:09,514][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,514][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,515][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,515][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit19']
[2024-07-24 10:24:09,515][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 13
[2024-07-24 10:24:09,515][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,515][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit4', 'circuit5', 'circuit6', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,515][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,516][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,516][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit3', 'circuit5', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,516][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 14
[2024-07-24 10:24:09,516][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit27']
[2024-07-24 10:24:09,516][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,516][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,516][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:24:09,517][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit17']
[2024-07-24 10:24:09,517][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 15
[2024-07-24 10:24:09,517][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,517][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit3']
[2024-07-24 10:24:09,517][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit27']
[2024-07-24 10:24:09,517][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,518][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,518][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 16
[2024-07-24 10:24:09,518][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit18', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:24:09,518][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,518][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14']
[2024-07-24 10:24:09,518][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit15', 'circuit25']
[2024-07-24 10:24:09,518][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit15', 'circuit17', 'circuit19']
[2024-07-24 10:24:09,519][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 17
[2024-07-24 10:24:09,519][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:24:09,519][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,519][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit20']
[2024-07-24 10:24:09,519][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,519][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,519][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 18
[2024-07-24 10:24:09,520][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit24']
[2024-07-24 10:24:09,520][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,520][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,520][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,520][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,520][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 19
[2024-07-24 10:24:09,521][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,521][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,521][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,521][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,521][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,521][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 20
[2024-07-24 10:24:09,521][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,522][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,522][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,522][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,522][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,522][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 21
[2024-07-24 10:24:09,522][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit17']
[2024-07-24 10:24:09,522][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit20']
[2024-07-24 10:24:09,523][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,523][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit21', 'circuit23', 'circuit25']
[2024-07-24 10:24:09,523][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,523][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 22
[2024-07-24 10:24:09,523][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:24:09,523][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,524][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,524][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,524][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,524][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 23
[2024-07-24 10:24:09,524][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:24:09,524][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit19', 'circuit20', 'circuit21', 'circuit24']
[2024-07-24 10:24:09,524][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:24:09,525][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,525][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,525][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 24
[2024-07-24 10:24:09,525][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:24:09,525][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,525][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,525][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:24:09,526][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:24:09,526][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 25
[2024-07-24 10:24:09,526][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,526][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,526][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,526][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,527][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,527][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 26
[2024-07-24 10:24:09,527][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,527][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,527][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,527][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,527][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,528][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 27
[2024-07-24 10:24:09,528][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,528][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,528][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,528][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,528][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,529][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 28
[2024-07-24 10:24:09,529][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,529][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,529][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,529][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,529][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,529][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 0
[2024-07-24 10:24:09,530][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit2', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,530][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,530][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,530][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,530][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,530][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit8', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,531][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 1
[2024-07-24 10:24:09,531][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit27']
[2024-07-24 10:24:09,531][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit9', 'circuit10', 'circuit16', 'circuit17']
[2024-07-24 10:24:09,531][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit13', 'circuit15', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:24:09,531][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:24:09,531][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,532][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit23']
[2024-07-24 10:24:09,532][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 2
[2024-07-24 10:24:09,532][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,532][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,532][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,532][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit16', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:24:09,532][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:24:09,533][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit23']
[2024-07-24 10:24:09,533][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 3
[2024-07-24 10:24:09,533][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,533][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit17', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:24:09,533][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit13', 'circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:24:09,533][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:24:09,533][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit11', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:24:09,534][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:24:09,534][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 4
[2024-07-24 10:24:09,534][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit7', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,534][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit8', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:24:09,534][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,534][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:24:09,535][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit14', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,535][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:24:09,535][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 5
[2024-07-24 10:24:09,535][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,535][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23']
[2024-07-24 10:24:09,535][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:24:09,536][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:24:09,536][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit24']
[2024-07-24 10:24:09,536][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:24:09,536][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 6
[2024-07-24 10:24:09,536][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,536][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit2', 'circuit4', 'circuit5', 'circuit10', 'circuit16', 'circuit26']
[2024-07-24 10:24:09,536][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit26']
[2024-07-24 10:24:09,537][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit16', 'circuit17', 'circuit20', 'circuit21']
[2024-07-24 10:24:09,537][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit14', 'circuit20', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:24:09,537][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit13', 'circuit19', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:24:09,537][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 7
[2024-07-24 10:24:09,537][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,537][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit8', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,537][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:24:09,538][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit1', 'circuit5', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,538][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit5', 'circuit6', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,538][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,538][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 8
[2024-07-24 10:24:09,538][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit2', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit26']
[2024-07-24 10:24:09,538][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:24:09,539][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13']
[2024-07-24 10:24:09,539][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit21', 'circuit27']
[2024-07-24 10:24:09,539][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit5', 'circuit15', 'circuit24', 'circuit26']
[2024-07-24 10:24:09,539][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,539][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 9
[2024-07-24 10:24:09,539][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit24']
[2024-07-24 10:24:09,539][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,540][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,540][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,540][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,540][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,540][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 10
[2024-07-24 10:24:09,540][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit27']
[2024-07-24 10:24:09,541][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,541][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,541][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,541][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,541][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:24:09,541][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 11
[2024-07-24 10:24:09,541][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,542][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit17', 'circuit19', 'circuit20', 'circuit24']
[2024-07-24 10:24:09,542][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit15', 'circuit19', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:24:09,542][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit16', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:24:09,542][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit13', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:24:09,542][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:24:09,542][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 12
[2024-07-24 10:24:09,542][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit28']
[2024-07-24 10:24:09,543][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit4', 'circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit17', 'circuit21', 'circuit25']
[2024-07-24 10:24:09,543][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit25']
[2024-07-24 10:24:09,543][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21']
[2024-07-24 10:24:09,543][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,543][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit17', 'circuit20', 'circuit22', 'circuit23']
[2024-07-24 10:24:09,543][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 13
[2024-07-24 10:24:09,544][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit8', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,544][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,544][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,544][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit4', 'circuit5', 'circuit8', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,544][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit3', 'circuit5', 'circuit8', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,544][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit6', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,544][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 14
[2024-07-24 10:24:09,545][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:24:09,545][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit20']
[2024-07-24 10:24:09,545][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit22', 'circuit23']
[2024-07-24 10:24:09,545][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit24', 'circuit25']
[2024-07-24 10:24:09,545][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,545][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,546][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 15
[2024-07-24 10:24:09,546][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,546][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,546][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,546][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,546][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,546][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,547][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 16
[2024-07-24 10:24:09,547][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,547][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15']
[2024-07-24 10:24:09,547][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit17', 'circuit26']
[2024-07-24 10:24:09,547][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:24:09,547][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,548][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,548][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 17
[2024-07-24 10:24:09,548][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit23', 'circuit27']
[2024-07-24 10:24:09,548][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,548][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,548][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,548][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14']
[2024-07-24 10:24:09,549][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,549][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 18
[2024-07-24 10:24:09,549][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,549][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:24:09,549][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15']
[2024-07-24 10:24:09,549][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,550][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,550][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit18']
[2024-07-24 10:24:09,550][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 19
[2024-07-24 10:24:09,550][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,550][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit4', 'circuit13', 'circuit14', 'circuit21']
[2024-07-24 10:24:09,550][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit8', 'circuit13', 'circuit14', 'circuit23', 'circuit24']
[2024-07-24 10:24:09,550][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit17', 'circuit18', 'circuit21']
[2024-07-24 10:24:09,551][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit24']
[2024-07-24 10:24:09,551][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit15', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:24:09,551][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 20
[2024-07-24 10:24:09,551][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,551][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit17', 'circuit18', 'circuit26']
[2024-07-24 10:24:09,551][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit20']
[2024-07-24 10:24:09,551][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:24:09,552][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit15', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:24:09,552][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit10', 'circuit11', 'circuit13', 'circuit26']
[2024-07-24 10:24:09,552][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 21
[2024-07-24 10:24:09,552][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit27']
[2024-07-24 10:24:09,552][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,552][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,553][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,553][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,553][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,553][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 22
[2024-07-24 10:24:09,553][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,553][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit9']
[2024-07-24 10:24:09,553][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit22', 'circuit24']
[2024-07-24 10:24:09,554][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit25']
[2024-07-24 10:24:09,554][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:24:09,554][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit15', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:24:09,554][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 23
[2024-07-24 10:24:09,554][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,554][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit4', 'circuit5', 'circuit10', 'circuit14', 'circuit26']
[2024-07-24 10:24:09,554][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:24:09,555][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:24:09,555][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,555][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,555][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 24
[2024-07-24 10:24:09,555][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,555][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit10', 'circuit11', 'circuit13', 'circuit15', 'circuit18', 'circuit22', 'circuit24']
[2024-07-24 10:24:09,556][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,556][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit16', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:24:09,556][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:24:09,556][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:24:09,556][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 25
[2024-07-24 10:24:09,556][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:24:09,556][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit10', 'circuit16', 'circuit21']
[2024-07-24 10:24:09,557][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:24:09,557][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:24:09,557][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,557][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit23']
[2024-07-24 10:24:09,557][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 26
[2024-07-24 10:24:09,557][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,558][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,558][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,558][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,558][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,558][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,558][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 27
[2024-07-24 10:24:09,558][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,559][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,559][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,559][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,559][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,559][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,560][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 28
[2024-07-24 10:24:09,560][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,560][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,560][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,560][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,560][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,561][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,561][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 0
[2024-07-24 10:24:09,561][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit4', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,561][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,561][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit7', 'circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,561][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,561][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit5', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,562][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit6', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,562][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit2', 'circuit7', 'circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,562][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 1
[2024-07-24 10:24:09,562][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:24:09,562][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit16', 'circuit17']
[2024-07-24 10:24:09,562][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16']
[2024-07-24 10:24:09,563][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,563][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,563][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,563][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,563][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 2
[2024-07-24 10:24:09,563][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit28']
[2024-07-24 10:24:09,563][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit8', 'circuit14', 'circuit16', 'circuit17', 'circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:24:09,564][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit23', 'circuit24']
[2024-07-24 10:24:09,564][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,564][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,564][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit24']
[2024-07-24 10:24:09,564][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,564][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 3
[2024-07-24 10:24:09,564][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:24:09,565][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,565][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,565][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:24:09,565][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,565][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit15', 'circuit16', 'circuit20', 'circuit21', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:24:09,565][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,566][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 4
[2024-07-24 10:24:09,566][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:24:09,566][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit2', 'circuit9', 'circuit13', 'circuit14', 'circuit17', 'circuit20']
[2024-07-24 10:24:09,566][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:24:09,566][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit23', 'circuit25']
[2024-07-24 10:24:09,566][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,566][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,567][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,567][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 5
[2024-07-24 10:24:09,567][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,567][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit5', 'circuit14']
[2024-07-24 10:24:09,567][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0']
[2024-07-24 10:24:09,567][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0']
[2024-07-24 10:24:09,568][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit1', 'circuit7', 'circuit8', 'circuit14', 'circuit26']
[2024-07-24 10:24:09,568][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,568][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,568][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 6
[2024-07-24 10:24:09,568][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit12']
[2024-07-24 10:24:09,568][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit8']
[2024-07-24 10:24:09,568][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit2', 'circuit13', 'circuit27']
[2024-07-24 10:24:09,569][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,569][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,569][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,569][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,569][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 7
[2024-07-24 10:24:09,569][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:24:09,570][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15']
[2024-07-24 10:24:09,570][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:24:09,570][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:24:09,570][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:24:09,570][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit15', 'circuit17', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:24:09,570][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:24:09,570][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 8
[2024-07-24 10:24:09,571][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit12', 'circuit24', 'circuit27']
[2024-07-24 10:24:09,571][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,571][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,571][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,571][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,571][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit15', 'circuit17', 'circuit20']
[2024-07-24 10:24:09,572][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit24']
[2024-07-24 10:24:09,572][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 9
[2024-07-24 10:24:09,572][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,572][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,572][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,572][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,572][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,573][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,573][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,573][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 10
[2024-07-24 10:24:09,573][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit24']
[2024-07-24 10:24:09,573][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14']
[2024-07-24 10:24:09,573][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit26']
[2024-07-24 10:24:09,573][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,574][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,574][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,574][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,574][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 11
[2024-07-24 10:24:09,574][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,574][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,575][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,575][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,575][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,575][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,575][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,575][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 12
[2024-07-24 10:24:09,575][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,576][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1']
[2024-07-24 10:24:09,576][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit10']
[2024-07-24 10:24:09,576][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit6', 'circuit12', 'circuit13', 'circuit27']
[2024-07-24 10:24:09,576][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,576][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit8', 'circuit11']
[2024-07-24 10:24:09,576][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,576][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 13
[2024-07-24 10:24:09,577][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit6', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,577][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit6', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,577][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,577][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,577][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,577][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit2', 'circuit7', 'circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,578][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,578][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 14
[2024-07-24 10:24:09,578][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit27']
[2024-07-24 10:24:09,578][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,578][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,578][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit2', 'circuit4', 'circuit13', 'circuit26']
[2024-07-24 10:24:09,578][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,579][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit24']
[2024-07-24 10:24:09,579][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,579][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 15
[2024-07-24 10:24:09,579][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,579][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit3', 'circuit4', 'circuit15', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:24:09,579][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,579][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit18', 'circuit19', 'circuit21', 'circuit24', 'circuit25']
[2024-07-24 10:24:09,580][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit22', 'circuit24']
[2024-07-24 10:24:09,580][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit22', 'circuit23']
[2024-07-24 10:24:09,580][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,580][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 16
[2024-07-24 10:24:09,580][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,580][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit16']
[2024-07-24 10:24:09,580][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:24:09,581][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,581][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,581][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,581][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,581][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 17
[2024-07-24 10:24:09,581][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit27']
[2024-07-24 10:24:09,582][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,582][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,582][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,582][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,582][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,582][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,582][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 18
[2024-07-24 10:24:09,583][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,583][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,583][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,583][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,583][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit15', 'circuit26']
[2024-07-24 10:24:09,583][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit14', 'circuit15', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:24:09,583][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,584][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 19
[2024-07-24 10:24:09,584][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit21']
[2024-07-24 10:24:09,584][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,584][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,584][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,584][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,585][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,585][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,585][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 20
[2024-07-24 10:24:09,585][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit26']
[2024-07-24 10:24:09,585][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,585][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,585][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,586][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,586][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit15', 'circuit24']
[2024-07-24 10:24:09,586][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,586][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 21
[2024-07-24 10:24:09,586][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit22', 'circuit24']
[2024-07-24 10:24:09,586][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13']
[2024-07-24 10:24:09,587][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,587][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,587][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,587][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,587][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,587][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 22
[2024-07-24 10:24:09,587][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,588][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,588][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,588][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,588][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,588][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,588][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,588][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 23
[2024-07-24 10:24:09,589][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:24:09,589][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,589][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,589][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,589][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,589][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,590][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,590][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 24
[2024-07-24 10:24:09,590][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,590][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,590][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,590][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,590][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,591][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,591][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,591][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 25
[2024-07-24 10:24:09,591][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,591][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,591][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,591][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,592][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,592][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,592][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,592][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 26
[2024-07-24 10:24:09,592][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,592][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,593][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,593][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,593][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,593][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,593][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,593][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 27
[2024-07-24 10:24:09,593][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,594][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,594][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,594][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,594][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,594][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,594][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,595][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 28
[2024-07-24 10:24:09,595][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,595][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,595][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,595][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,595][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,596][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,596][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,596][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 0
[2024-07-24 10:24:09,596][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit6', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,596][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit5', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,596][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit5', 'circuit6', 'circuit8', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,596][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,597][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit5', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,597][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,597][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit7', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,597][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit6', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,597][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 1
[2024-07-24 10:24:09,597][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit20', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,598][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit17']
[2024-07-24 10:24:09,598][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,598][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,598][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,598][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit23', 'circuit24']
[2024-07-24 10:24:09,598][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,598][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit20']
[2024-07-24 10:24:09,599][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 2
[2024-07-24 10:24:09,599][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,599][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit2', 'circuit7', 'circuit18', 'circuit23', 'circuit24']
[2024-07-24 10:24:09,599][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit5', 'circuit13', 'circuit14']
[2024-07-24 10:24:09,599][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14']
[2024-07-24 10:24:09,599][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit13', 'circuit14', 'circuit17', 'circuit18']
[2024-07-24 10:24:09,600][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0']
[2024-07-24 10:24:09,600][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,600][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit25']
[2024-07-24 10:24:09,600][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 3
[2024-07-24 10:24:09,600][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit23', 'circuit26']
[2024-07-24 10:24:09,600][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit1', 'circuit6', 'circuit11', 'circuit13', 'circuit26']
[2024-07-24 10:24:09,600][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,601][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit19', 'circuit20', 'circuit21', 'circuit25']
[2024-07-24 10:24:09,601][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit24', 'circuit27']
[2024-07-24 10:24:09,601][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit14', 'circuit16']
[2024-07-24 10:24:09,601][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,601][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,601][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 4
[2024-07-24 10:24:09,601][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,602][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,602][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,602][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,602][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,602][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,602][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,603][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,603][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 5
[2024-07-24 10:24:09,603][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,603][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit5', 'circuit14']
[2024-07-24 10:24:09,603][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17']
[2024-07-24 10:24:09,603][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,603][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit24', 'circuit25']
[2024-07-24 10:24:09,604][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,604][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,604][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,604][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 6
[2024-07-24 10:24:09,604][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit12', 'circuit27']
[2024-07-24 10:24:09,604][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,605][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit27']
[2024-07-24 10:24:09,605][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,605][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,605][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,605][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,605][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,605][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 7
[2024-07-24 10:24:09,606][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit20']
[2024-07-24 10:24:09,606][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit10', 'circuit15', 'circuit18']
[2024-07-24 10:24:09,606][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:24:09,606][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:24:09,606][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,606][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,606][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,607][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,607][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 8
[2024-07-24 10:24:09,607][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,607][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit2', 'circuit4', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit25']
[2024-07-24 10:24:09,607][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:24:09,607][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:24:09,608][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:24:09,608][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,608][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit21', 'circuit24', 'circuit25']
[2024-07-24 10:24:09,608][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit22', 'circuit25']
[2024-07-24 10:24:09,608][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 9
[2024-07-24 10:24:09,608][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,608][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit5', 'circuit10']
[2024-07-24 10:24:09,609][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,609][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,609][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,609][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,609][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,609][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,610][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 10
[2024-07-24 10:24:09,610][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit27']
[2024-07-24 10:24:09,610][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,610][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,610][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,610][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,610][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,611][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,611][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,611][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 11
[2024-07-24 10:24:09,611][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,611][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit21']
[2024-07-24 10:24:09,611][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,611][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,612][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,612][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,612][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,612][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,612][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 12
[2024-07-24 10:24:09,612][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,613][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit5', 'circuit10']
[2024-07-24 10:24:09,613][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,613][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,613][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,613][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,613][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,613][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0']
[2024-07-24 10:24:09,614][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 13
[2024-07-24 10:24:09,614][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit6', 'circuit7', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,614][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit5', 'circuit8', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,614][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,614][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit4', 'circuit10', 'circuit11', 'circuit12', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,614][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit2', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,615][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit3', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,615][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit7', 'circuit8', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,615][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit6', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,615][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 14
[2024-07-24 10:24:09,615][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit24', 'circuit27']
[2024-07-24 10:24:09,615][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit17']
[2024-07-24 10:24:09,615][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit27']
[2024-07-24 10:24:09,616][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,616][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,616][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,616][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,616][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,616][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 15
[2024-07-24 10:24:09,617][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit23']
[2024-07-24 10:24:09,617][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,617][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,617][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,617][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,617][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,617][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,618][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,618][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 16
[2024-07-24 10:24:09,618][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:24:09,618][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,618][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,618][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,618][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,619][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,619][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,619][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,619][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 17
[2024-07-24 10:24:09,619][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,619][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,620][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,620][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,620][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,620][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,620][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,620][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,620][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 18
[2024-07-24 10:24:09,621][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,621][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,621][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,621][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,621][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,621][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,621][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,622][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,622][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 19
[2024-07-24 10:24:09,622][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,622][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,622][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,622][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit1']
[2024-07-24 10:24:09,623][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,623][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,623][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,623][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,623][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 20
[2024-07-24 10:24:09,623][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,623][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,624][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,624][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,624][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,624][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,624][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,624][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,624][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 21
[2024-07-24 10:24:09,625][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:24:09,625][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,625][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,625][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:24:09,625][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit24', 'circuit25']
[2024-07-24 10:24:09,625][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,626][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,626][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,626][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 22
[2024-07-24 10:24:09,626][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:24:09,626][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,626][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,626][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,627][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,627][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,627][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,627][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,627][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 23
[2024-07-24 10:24:09,627][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:24:09,628][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,628][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,628][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,628][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,628][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,628][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,628][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,629][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 24
[2024-07-24 10:24:09,629][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,629][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,629][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,629][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,629][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,629][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,630][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,630][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,630][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 25
[2024-07-24 10:24:09,630][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,630][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,630][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,631][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,631][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,631][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,631][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,631][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,631][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 26
[2024-07-24 10:24:09,631][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,632][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,632][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,632][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,632][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,632][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,632][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,633][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,633][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 27
[2024-07-24 10:24:09,633][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,633][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,633][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,633][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,634][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,634][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,634][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,634][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,634][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 28
[2024-07-24 10:24:09,634][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,634][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,635][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,635][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,635][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,635][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,635][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,635][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,636][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 0
[2024-07-24 10:24:09,636][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit5', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,636][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,636][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit5', 'circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,636][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,636][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit3', 'circuit5', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,636][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit2', 'circuit8', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,637][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit7', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,637][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit4', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:24:09,637][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,637][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 1
[2024-07-24 10:24:09,637][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:24:09,637][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,638][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17']
[2024-07-24 10:24:09,638][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,638][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,638][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit22', 'circuit24']
[2024-07-24 10:24:09,638][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,638][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,638][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:24:09,639][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 2
[2024-07-24 10:24:09,639][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:24:09,639][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit2', 'circuit13', 'circuit14', 'circuit15']
[2024-07-24 10:24:09,639][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,639][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0']
[2024-07-24 10:24:09,639][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit16']
[2024-07-24 10:24:09,639][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit14', 'circuit15']
[2024-07-24 10:24:09,640][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,640][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,640][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:24:09,640][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 3
[2024-07-24 10:24:09,640][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,640][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,640][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,641][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,641][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,641][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,641][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,641][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,641][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit3']
[2024-07-24 10:24:09,641][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 4
[2024-07-24 10:24:09,642][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,642][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,642][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,642][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,642][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,642][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,643][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,643][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit13']
[2024-07-24 10:24:09,643][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:24:09,643][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 5
[2024-07-24 10:24:09,643][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit24', 'circuit27']
[2024-07-24 10:24:09,643][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,643][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,644][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,644][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,644][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,644][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,644][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,644][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:24:09,644][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 6
[2024-07-24 10:24:09,645][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit24']
[2024-07-24 10:24:09,645][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,645][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,645][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,645][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,645][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,645][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,646][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,646][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:24:09,646][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 7
[2024-07-24 10:24:09,646][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,646][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit24']
[2024-07-24 10:24:09,646][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,647][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,647][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,647][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,647][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,647][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit18']
[2024-07-24 10:24:09,647][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:24:09,647][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 8
[2024-07-24 10:24:09,648][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:24:09,648][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,648][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,648][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,648][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,648][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,648][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,649][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,649][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:24:09,649][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 9
[2024-07-24 10:24:09,649][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit17', 'circuit18', 'circuit22']
[2024-07-24 10:24:09,649][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,649][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,650][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,650][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,650][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,650][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,650][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,650][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:24:09,650][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 10
[2024-07-24 10:24:09,651][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,651][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,651][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,651][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,651][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,651][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,651][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,652][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,652][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:24:09,652][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 11
[2024-07-24 10:24:09,652][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,652][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,652][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,653][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,653][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,653][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,653][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,653][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,653][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:24:09,653][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 12
[2024-07-24 10:24:09,654][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,654][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,654][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,654][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,654][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,654][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,654][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit19', 'circuit20', 'circuit21']
[2024-07-24 10:24:09,655][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,655][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:24:09,655][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 13
[2024-07-24 10:24:09,655][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,655][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit24', 'circuit26']
[2024-07-24 10:24:09,655][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:24:09,656][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit20', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:24:09,656][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit24']
[2024-07-24 10:24:09,656][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit24']
[2024-07-24 10:24:09,656][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0']
[2024-07-24 10:24:09,656][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0']
[2024-07-24 10:24:09,656][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit25']
[2024-07-24 10:24:09,656][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 14
[2024-07-24 10:24:09,657][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,657][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,657][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,657][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,657][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,657][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,658][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,658][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,658][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:24:09,658][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 15
[2024-07-24 10:24:09,658][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,658][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,658][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,659][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,659][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,659][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,659][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,659][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,659][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:24:09,659][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 16
[2024-07-24 10:24:09,660][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,660][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,660][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,660][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,660][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,660][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,660][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,661][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,661][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:24:09,661][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 17
[2024-07-24 10:24:09,661][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,661][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,661][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,662][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,662][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,662][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,662][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,662][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,662][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:24:09,662][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 18
[2024-07-24 10:24:09,663][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,663][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,663][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,663][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,663][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,663][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,663][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,664][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,664][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:24:09,664][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 19
[2024-07-24 10:24:09,664][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,664][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,664][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,664][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,665][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,665][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,665][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,665][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,665][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:24:09,665][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 20
[2024-07-24 10:24:09,665][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,666][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,666][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,666][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,666][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,666][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,666][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,667][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,667][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:24:09,667][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 21
[2024-07-24 10:24:09,667][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,667][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,667][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,667][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,668][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,668][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,668][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,668][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,668][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:24:09,668][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 22
[2024-07-24 10:24:09,668][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,669][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,669][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,669][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,669][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,669][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,669][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,669][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,670][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:24:09,670][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 23
[2024-07-24 10:24:09,670][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,670][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,670][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,670][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,670][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,671][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,671][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,671][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,671][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:24:09,671][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 24
[2024-07-24 10:24:09,671][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,672][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,672][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,672][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,672][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,672][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,672][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,672][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,673][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:24:09,673][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 25
[2024-07-24 10:24:09,673][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,673][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,673][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,673][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,673][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,674][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,674][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,674][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,674][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:24:09,674][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 26
[2024-07-24 10:24:09,674][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,674][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,675][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,675][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,675][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,675][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,675][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,675][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,676][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,676][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 27
[2024-07-24 10:24:09,676][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,676][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,676][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,676][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,676][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,677][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,677][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,677][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,677][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,677][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 28
[2024-07-24 10:24:09,677][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,678][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,678][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,678][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,678][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,678][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,678][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,678][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,679][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,679][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 0
[2024-07-24 10:24:09,679][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit6', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,679][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:24:09,679][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,679][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:24:09,680][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:24:09,680][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit4', 'circuit8', 'circuit12', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:24:09,680][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:24:09,680][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit3', 'circuit8', 'circuit13', 'circuit14', 'circuit17', 'circuit18', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:24:09,680][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:24:09,680][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit27']
[2024-07-24 10:24:09,680][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 1
[2024-07-24 10:24:09,681][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,681][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,681][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,681][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,681][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,681][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,681][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,682][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,682][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:24:09,682][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:24:09,682][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 2
[2024-07-24 10:24:09,682][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,682][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit20']
[2024-07-24 10:24:09,683][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,683][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,683][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,683][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,683][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,683][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit17']
[2024-07-24 10:24:09,683][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:24:09,684][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:24:09,684][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 3
[2024-07-24 10:24:09,684][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,684][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,684][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit4']
[2024-07-24 10:24:09,684][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,684][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,685][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,685][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,685][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,685][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:24:09,685][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:24:09,685][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 4
[2024-07-24 10:24:09,685][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,686][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,686][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,686][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,686][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,686][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,686][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,687][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,687][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:24:09,687][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:24:09,687][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 5
[2024-07-24 10:24:09,687][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,687][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,687][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,688][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,688][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,688][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,688][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,688][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,688][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:24:09,688][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:24:09,689][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 6
[2024-07-24 10:24:09,689][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,689][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,689][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,689][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,689][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,689][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,690][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,690][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,690][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:24:09,690][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:24:09,690][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 7
[2024-07-24 10:24:09,690][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,691][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,691][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,691][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,691][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,691][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,691][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,691][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,692][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:24:09,692][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:24:09,692][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 8
[2024-07-24 10:24:09,692][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,692][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,692][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,692][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,693][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,693][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,693][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,693][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,693][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:24:09,693][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:24:09,693][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 9
[2024-07-24 10:24:09,694][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,694][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,694][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,694][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,694][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,694][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,695][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,695][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,695][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:24:09,695][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:24:09,695][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 10
[2024-07-24 10:24:09,695][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,695][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,696][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,696][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,696][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,696][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,696][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,696][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,696][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:24:09,697][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:24:09,697][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 11
[2024-07-24 10:24:09,697][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:24:09,697][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit19']
[2024-07-24 10:24:09,697][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,697][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,698][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,698][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,698][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,698][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit24']
[2024-07-24 10:24:09,698][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:24:09,698][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:24:09,698][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 12
[2024-07-24 10:24:09,699][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,699][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,699][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,699][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,699][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,699][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,699][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,700][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,700][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:24:09,700][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:24:09,700][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 13
[2024-07-24 10:24:09,700][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,700][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit4', 'circuit7', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:24:09,700][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit7', 'circuit8', 'circuit13', 'circuit25', 'circuit27']
[2024-07-24 10:24:09,701][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0']
[2024-07-24 10:24:09,701][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit14', 'circuit25']
[2024-07-24 10:24:09,701][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0']
[2024-07-24 10:24:09,701][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0']
[2024-07-24 10:24:09,701][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit20']
[2024-07-24 10:24:09,701][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit24']
[2024-07-24 10:24:09,702][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit14', 'circuit20', 'circuit24', 'circuit25']
[2024-07-24 10:24:09,702][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 14
[2024-07-24 10:24:09,702][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,702][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,702][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,702][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,702][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,703][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,703][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,703][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,703][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:24:09,703][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:24:09,703][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 15
[2024-07-24 10:24:09,703][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,704][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,704][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,704][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,704][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,704][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,704][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,704][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,705][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:24:09,705][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:24:09,705][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 16
[2024-07-24 10:24:09,705][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,705][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,705][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,706][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,706][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,706][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,706][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,706][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,706][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:24:09,706][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:24:09,707][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 17
[2024-07-24 10:24:09,707][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,707][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,707][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,707][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,707][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,707][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,708][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,708][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,708][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:24:09,708][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:24:09,708][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 18
[2024-07-24 10:24:09,708][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,708][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,709][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,709][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,709][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,709][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,709][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,709][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,710][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:24:09,710][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:24:09,710][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 19
[2024-07-24 10:24:09,710][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,710][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,710][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,710][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,711][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,711][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,711][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,711][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,711][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:24:09,711][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:24:09,711][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 20
[2024-07-24 10:24:09,712][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,712][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,712][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,712][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,712][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,712][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,712][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,713][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,713][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:24:09,713][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:24:09,713][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 21
[2024-07-24 10:24:09,713][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,713][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,714][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,714][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,714][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,714][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,714][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,714][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,714][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:24:09,715][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:24:09,715][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 22
[2024-07-24 10:24:09,715][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,715][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,715][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,715][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,715][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,716][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,716][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,716][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,716][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:24:09,716][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:24:09,716][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 23
[2024-07-24 10:24:09,716][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,717][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,717][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,717][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,717][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,717][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,717][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,718][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,718][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:24:09,718][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:24:09,718][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 24
[2024-07-24 10:24:09,718][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,718][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,718][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,719][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,719][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,719][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,719][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,719][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,719][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:24:09,719][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:24:09,720][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 25
[2024-07-24 10:24:09,720][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,720][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,720][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,720][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,720][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,720][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,721][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,721][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,721][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:24:09,721][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:24:09,721][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 26
[2024-07-24 10:24:09,721][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,721][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,722][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,722][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,722][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,722][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,722][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,722][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,723][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,723][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,723][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 27
[2024-07-24 10:24:09,723][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,723][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,723][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,724][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,724][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,724][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,724][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,724][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,724][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,724][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,725][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 28
[2024-07-24 10:24:09,725][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,725][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,725][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,725][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,725][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,726][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,726][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,726][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,726][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,726][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,726][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 0
[2024-07-24 10:24:09,726][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,727][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit5', 'circuit13', 'circuit14', 'circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit25']
[2024-07-24 10:24:09,727][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:24:09,727][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:24:09,727][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:24:09,727][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:24:09,727][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit19', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:24:09,727][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit14', 'circuit17', 'circuit18', 'circuit20', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:24:09,728][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit12', 'circuit14', 'circuit23', 'circuit24']
[2024-07-24 10:24:09,728][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit7', 'circuit9', 'circuit13', 'circuit15', 'circuit16']
[2024-07-24 10:24:09,728][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:24:09,728][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 1
[2024-07-24 10:24:09,728][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:24:09,728][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,729][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,729][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,729][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,729][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,729][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,729][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,729][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:24:09,730][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:24:09,730][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:24:09,730][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 2
[2024-07-24 10:24:09,730][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,730][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,730][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,730][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,731][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,731][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,731][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,731][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,731][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:24:09,731][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:24:09,732][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:24:09,732][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 3
[2024-07-24 10:24:09,732][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,732][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,732][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,732][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,732][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,733][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,733][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,733][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,733][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:24:09,733][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:24:09,733][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:24:09,733][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 4
[2024-07-24 10:24:09,734][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,734][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,734][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,734][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,734][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,734][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,734][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,735][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,735][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:24:09,735][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:24:09,735][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:24:09,735][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 5
[2024-07-24 10:24:09,735][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,736][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,736][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,736][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,736][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,736][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,736][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,736][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,737][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:24:09,737][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:24:09,737][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:24:09,737][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 6
[2024-07-24 10:24:09,737][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,737][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,737][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,738][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,738][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,738][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,738][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,738][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,738][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:24:09,738][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:24:09,739][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:24:09,739][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 7
[2024-07-24 10:24:09,739][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,739][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,739][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,739][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,740][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,740][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,740][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,740][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,740][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:24:09,740][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:24:09,740][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:24:09,741][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 8
[2024-07-24 10:24:09,741][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,741][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,741][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,741][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,741][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,741][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,742][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,742][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,742][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:24:09,742][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:24:09,742][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:24:09,742][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 9
[2024-07-24 10:24:09,742][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,743][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit26']
[2024-07-24 10:24:09,743][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15']
[2024-07-24 10:24:09,743][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,743][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,743][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,743][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,744][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,744][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:24:09,744][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:24:09,744][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit9', 'circuit11']
[2024-07-24 10:24:09,744][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 10
[2024-07-24 10:24:09,744][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,744][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,745][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,745][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,745][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,745][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,745][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,745][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,745][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:24:09,746][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:24:09,746][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:24:09,746][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 11
[2024-07-24 10:24:09,746][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,746][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,746][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,746][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,747][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,747][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,747][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,747][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,747][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:24:09,747][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:24:09,748][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:24:09,748][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 12
[2024-07-24 10:24:09,748][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,748][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,748][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,748][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,748][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,749][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,749][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,749][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,749][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:24:09,749][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:24:09,749][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:24:09,749][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 13
[2024-07-24 10:24:09,750][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit24', 'circuit26']
[2024-07-24 10:24:09,750][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:24:09,750][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,750][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,750][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,750][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,750][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,751][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,751][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit13', 'circuit19']
[2024-07-24 10:24:09,751][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit13', 'circuit19', 'circuit22', 'circuit25']
[2024-07-24 10:24:09,751][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:24:09,751][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 14
[2024-07-24 10:24:09,751][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,752][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,752][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,752][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,752][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,752][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,752][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,752][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,753][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:24:09,753][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:24:09,753][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:24:09,753][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 15
[2024-07-24 10:24:09,753][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,753][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,753][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,754][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,754][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,754][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,754][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,754][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,754][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:24:09,754][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:24:09,755][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:24:09,755][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 16
[2024-07-24 10:24:09,755][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,755][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,755][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,755][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,756][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,756][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,756][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,756][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,756][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:24:09,756][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:24:09,756][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:24:09,757][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 17
[2024-07-24 10:24:09,757][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,757][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,757][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,757][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,757][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,757][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,758][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,758][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,758][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:24:09,758][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:24:09,758][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:24:09,758][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 18
[2024-07-24 10:24:09,758][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,759][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,759][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,759][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,759][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,759][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,759][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,760][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,760][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:24:09,760][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:24:09,760][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:24:09,760][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 19
[2024-07-24 10:24:09,760][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,760][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,761][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,761][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,761][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,761][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,761][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,761][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,761][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:24:09,762][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:24:09,762][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:24:09,762][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 20
[2024-07-24 10:24:09,762][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,762][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,762][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,762][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,763][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,763][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,763][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,763][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,763][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:24:09,763][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:24:09,764][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:24:09,764][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 21
[2024-07-24 10:24:09,764][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,764][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,764][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,764][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,764][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,765][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,765][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,765][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,765][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:24:09,765][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:24:09,765][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:24:09,765][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 22
[2024-07-24 10:24:09,766][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,766][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,766][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,766][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,766][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,766][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,766][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,767][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,767][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:24:09,767][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:24:09,767][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:24:09,767][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 23
[2024-07-24 10:24:09,767][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,768][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,768][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,768][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,768][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,768][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,768][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,768][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,769][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:24:09,769][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:24:09,769][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:24:09,769][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 24
[2024-07-24 10:24:09,769][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,769][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,769][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,770][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,770][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,770][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,770][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,770][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,770][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:24:09,771][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:24:09,771][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:24:09,771][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 25
[2024-07-24 10:24:09,771][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:24:09,771][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:24:09,771][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:24:09,771][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:24:09,772][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:24:09,772][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:24:09,772][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:24:09,772][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:24:09,772][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:24:09,772][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:24:09,772][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:24:09,773][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 26
[2024-07-24 10:24:09,773][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,773][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,773][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,773][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,773][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,774][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,774][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,774][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,774][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,774][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,774][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,774][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 27
[2024-07-24 10:24:09,775][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,775][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,775][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,775][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,775][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,775][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,776][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,776][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,776][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,776][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,776][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,776][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 28
[2024-07-24 10:24:09,776][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,777][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,777][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,777][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,777][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,777][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,777][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,778][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,778][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,778][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:09,778][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:24:11,496][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:24:11,497][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:11,498][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:11,498][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:11,499][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:11,500][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:11,500][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:11,501][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:11,502][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:11,502][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:11,504][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:11,505][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:11,506][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:11,508][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.9675, 0.0325], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:11,509][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0065, 0.9935], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:11,511][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.6358, 0.3642], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:11,512][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.6853, 0.3147], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:11,513][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.9772, 0.0228], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:11,513][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.2539, 0.7461], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:11,514][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.9881, 0.0119], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:11,516][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.9119, 0.0881], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:11,517][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.3215, 0.6785], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:11,519][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.7118, 0.2882], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:11,520][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.7102, 0.2898], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:11,522][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.6916, 0.3084], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:11,523][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Erica] are: tensor([0.3611, 0.4078, 0.2311], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:11,525][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Erica] are: tensor([3.0591e-05, 3.9905e-05, 9.9993e-01], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:11,526][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Erica] are: tensor([0.6859, 0.2179, 0.0962], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:11,527][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Erica] are: tensor([6.8032e-03, 2.7842e-04, 9.9292e-01], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:11,529][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Erica] are: tensor([0.0210, 0.0023, 0.9767], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:11,530][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Erica] are: tensor([1.7761e-03, 5.3109e-07, 9.9822e-01], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:11,532][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Erica] are: tensor([0.3287, 0.3790, 0.2922], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:11,533][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Erica] are: tensor([0.4337, 0.3073, 0.2590], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:11,535][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Erica] are: tensor([0.5538, 0.3519, 0.0943], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:11,536][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Erica] are: tensor([0.5986, 0.3334, 0.0680], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:11,538][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Erica] are: tensor([0.4074, 0.2732, 0.3195], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:11,540][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Erica] are: tensor([0.3770, 0.4747, 0.1483], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:11,541][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.6410, 0.0726, 0.2297, 0.0566], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:11,542][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ and] are: tensor([2.3033e-03, 3.9260e-02, 1.5832e-04, 9.5828e-01], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:11,544][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.2380, 0.1782, 0.0355, 0.5483], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:11,545][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.1136, 0.3885, 0.0227, 0.4752], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:11,547][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.3397, 0.1539, 0.2276, 0.2787], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:11,549][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1230, 0.1969, 0.0073, 0.6727], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:11,550][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.5507, 0.0263, 0.4030, 0.0200], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:11,552][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.2068, 0.1573, 0.3992, 0.2368], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:11,554][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0676, 0.4737, 0.0145, 0.4442], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:11,555][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.4189, 0.2339, 0.1299, 0.2173], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:11,557][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.4153, 0.3093, 0.0713, 0.2041], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:11,558][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.4486, 0.1959, 0.0996, 0.2560], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:11,560][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Joshua] are: tensor([0.1817, 0.2540, 0.1307, 0.2128, 0.2208], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:11,561][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Joshua] are: tensor([1.2426e-04, 1.8502e-04, 5.4570e-04, 2.8354e-05, 9.9912e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:11,562][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Joshua] are: tensor([0.4689, 0.3002, 0.0543, 0.1271, 0.0494], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:11,563][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Joshua] are: tensor([1.6382e-02, 1.0883e-04, 9.8409e-03, 4.5046e-04, 9.7322e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:11,563][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Joshua] are: tensor([5.1277e-03, 5.5280e-04, 1.6916e-02, 4.8573e-04, 9.7692e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:11,564][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Joshua] are: tensor([2.0450e-02, 4.6271e-06, 1.9241e-04, 3.4591e-07, 9.7935e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:11,565][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Joshua] are: tensor([0.1708, 0.2005, 0.1972, 0.1115, 0.3201], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:11,567][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Joshua] are: tensor([0.1864, 0.1544, 0.1757, 0.3939, 0.0897], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:11,568][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Joshua] are: tensor([0.2704, 0.1833, 0.1605, 0.1533, 0.2325], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:11,570][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Joshua] are: tensor([0.3839, 0.2319, 0.1720, 0.1878, 0.0245], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:11,571][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Joshua] are: tensor([0.3282, 0.2074, 0.0669, 0.1241, 0.2734], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:11,573][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Joshua] are: tensor([0.2714, 0.1985, 0.1176, 0.2537, 0.1588], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:11,574][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ went] are: tensor([0.3259, 0.0786, 0.0827, 0.0783, 0.1340, 0.3004], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:11,576][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ went] are: tensor([0.0015, 0.0018, 0.0015, 0.0014, 0.0018, 0.9921], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:11,578][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ went] are: tensor([0.4727, 0.1360, 0.0384, 0.1928, 0.0633, 0.0968], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:11,579][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ went] are: tensor([1.4938e-02, 7.5117e-04, 3.5144e-04, 1.2519e-03, 6.1286e-04, 9.8209e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:11,580][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ went] are: tensor([0.3394, 0.0510, 0.0277, 0.0687, 0.0370, 0.4762], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:11,582][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ went] are: tensor([5.7747e-02, 1.8507e-04, 5.1230e-05, 3.0792e-05, 7.6613e-05, 9.4191e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:11,583][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ went] are: tensor([0.2408, 0.0461, 0.3718, 0.0360, 0.2628, 0.0424], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:11,585][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ went] are: tensor([0.1546, 0.1019, 0.1320, 0.2460, 0.1316, 0.2339], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:11,586][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.2107, 0.2732, 0.0817, 0.3100, 0.0725, 0.0519], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:11,588][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ went] are: tensor([0.3138, 0.1824, 0.1342, 0.1793, 0.0831, 0.1073], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:11,590][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ went] are: tensor([0.2927, 0.1904, 0.0629, 0.1465, 0.0488, 0.2587], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:11,592][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ went] are: tensor([0.3891, 0.1484, 0.0778, 0.1986, 0.0816, 0.1045], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:11,593][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.4024, 0.0539, 0.1518, 0.0439, 0.1067, 0.2155, 0.0257],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:11,594][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ to] are: tensor([4.2430e-03, 2.1515e-02, 4.0956e-04, 5.3066e-02, 9.8148e-05, 6.8592e-04,
        9.1998e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:11,596][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.2784, 0.1463, 0.0428, 0.1625, 0.0417, 0.0788, 0.2496],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:11,598][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0197, 0.0109, 0.0007, 0.0182, 0.0038, 0.4607, 0.4861],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:11,599][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.1079, 0.0122, 0.0148, 0.0246, 0.0475, 0.6531, 0.1399],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:11,601][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0919, 0.0988, 0.0038, 0.1075, 0.0029, 0.0137, 0.6814],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:11,603][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.2659, 0.0173, 0.1309, 0.0133, 0.1273, 0.0776, 0.3678],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:11,604][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0929, 0.0502, 0.0651, 0.1086, 0.1700, 0.2725, 0.2408],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:11,606][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0255, 0.1992, 0.0057, 0.2977, 0.0070, 0.0545, 0.4104],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:11,608][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.2575, 0.1648, 0.0917, 0.1695, 0.0544, 0.0855, 0.1765],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:11,609][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.2414, 0.2102, 0.0680, 0.1866, 0.0362, 0.0819, 0.1758],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:11,611][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.3038, 0.1261, 0.0950, 0.1437, 0.0825, 0.1019, 0.1470],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:11,613][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.4445, 0.0449, 0.2232, 0.0291, 0.1127, 0.1028, 0.0168, 0.0261],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:11,613][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ the] are: tensor([3.1849e-03, 2.6311e-02, 1.8747e-04, 5.2425e-02, 5.7419e-05, 1.4419e-04,
        7.6587e-02, 8.4110e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:11,614][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.2430, 0.1327, 0.0353, 0.1302, 0.0481, 0.1072, 0.2661, 0.0374],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:11,615][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0287, 0.0115, 0.0030, 0.0203, 0.0137, 0.0833, 0.1756, 0.6640],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:11,616][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.1964, 0.0302, 0.0279, 0.0451, 0.0793, 0.3226, 0.1403, 0.1581],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:11,618][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.1120, 0.1532, 0.0090, 0.1133, 0.0130, 0.0380, 0.1203, 0.4410],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:11,620][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.2189, 0.0045, 0.4332, 0.0040, 0.2700, 0.0594, 0.0074, 0.0026],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:11,621][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0822, 0.0349, 0.0615, 0.0793, 0.0835, 0.1460, 0.2158, 0.2967],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:11,623][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0145, 0.1257, 0.0056, 0.1864, 0.0098, 0.0462, 0.1837, 0.4281],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:11,625][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.2427, 0.1390, 0.0864, 0.1397, 0.0495, 0.0759, 0.1452, 0.1216],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:11,626][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.2613, 0.1659, 0.0563, 0.1417, 0.0406, 0.0427, 0.1096, 0.1819],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:11,628][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.2610, 0.1083, 0.0930, 0.1224, 0.0834, 0.0891, 0.1164, 0.1264],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:11,629][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ office] are: tensor([0.2152, 0.1113, 0.1625, 0.0811, 0.1136, 0.0932, 0.0726, 0.1094, 0.0410],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:11,631][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ office] are: tensor([1.2297e-04, 7.5145e-04, 2.5410e-03, 3.9185e-04, 1.3649e-05, 2.6148e-04,
        1.4064e-04, 7.3074e-05, 9.9570e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:11,632][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ office] are: tensor([0.3050, 0.1294, 0.0749, 0.1068, 0.0395, 0.0705, 0.1084, 0.0908, 0.0746],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:11,634][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ office] are: tensor([1.0794e-02, 2.5583e-04, 2.0199e-05, 4.5238e-04, 4.0253e-04, 6.4268e-03,
        5.1534e-03, 4.9120e-03, 9.7158e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:11,635][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ office] are: tensor([0.1782, 0.0059, 0.0091, 0.0074, 0.0324, 0.0382, 0.0184, 0.0201, 0.6903],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:11,636][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ office] are: tensor([6.7204e-03, 8.2676e-06, 2.1539e-04, 1.6333e-06, 3.3348e-06, 1.6711e-05,
        4.3968e-08, 4.3309e-07, 9.9303e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:11,638][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ office] are: tensor([0.1906, 0.0332, 0.3764, 0.0270, 0.1643, 0.0348, 0.0275, 0.0180, 0.1282],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:11,640][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ office] are: tensor([0.0496, 0.0484, 0.0013, 0.0645, 0.0143, 0.1036, 0.1991, 0.3326, 0.1865],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:11,641][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ office] are: tensor([0.1554, 0.1083, 0.0580, 0.1689, 0.0183, 0.1001, 0.1300, 0.2102, 0.0507],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:11,643][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ office] are: tensor([0.2204, 0.1253, 0.1289, 0.1118, 0.0869, 0.0855, 0.0991, 0.1003, 0.0418],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:11,645][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ office] are: tensor([0.1501, 0.1116, 0.0899, 0.1074, 0.0275, 0.0539, 0.0831, 0.0753, 0.3013],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:11,646][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ office] are: tensor([0.3655, 0.1283, 0.0912, 0.1122, 0.0533, 0.0486, 0.0962, 0.0439, 0.0607],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:11,648][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.4614, 0.0168, 0.2119, 0.0139, 0.0859, 0.1128, 0.0100, 0.0373, 0.0400,
        0.0102], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:11,649][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [.] are: tensor([3.4871e-03, 4.5845e-02, 5.1684e-04, 8.3929e-03, 7.8011e-05, 4.5718e-04,
        5.8469e-03, 4.1441e-04, 2.3785e-04, 9.3472e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:11,651][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.4101, 0.0593, 0.0483, 0.0458, 0.0625, 0.2218, 0.0538, 0.0250, 0.0209,
        0.0526], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:11,653][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0293, 0.0074, 0.0017, 0.0108, 0.0079, 0.0592, 0.0727, 0.1761, 0.1323,
        0.5026], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:11,655][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0652, 0.0265, 0.0190, 0.0562, 0.0170, 0.0946, 0.1148, 0.1191, 0.1393,
        0.3482], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:11,656][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.1359, 0.1967, 0.0276, 0.1197, 0.0163, 0.0465, 0.0783, 0.0815, 0.0304,
        0.2672], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:11,658][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.2801, 0.0083, 0.3373, 0.0059, 0.1887, 0.0347, 0.0097, 0.0050, 0.1267,
        0.0035], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:11,660][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0410, 0.0154, 0.0250, 0.0336, 0.0494, 0.0670, 0.0741, 0.1540, 0.1145,
        0.4261], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:11,661][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.0184, 0.1690, 0.0060, 0.1294, 0.0065, 0.0108, 0.1059, 0.1480, 0.0143,
        0.3917], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:11,662][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.1929, 0.1114, 0.0858, 0.1125, 0.0604, 0.0768, 0.1068, 0.0917, 0.0566,
        0.1051], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:11,663][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.1550, 0.1377, 0.0814, 0.1328, 0.0446, 0.0727, 0.1096, 0.0745, 0.0541,
        0.1376], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:11,664][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.2608, 0.0928, 0.0854, 0.0929, 0.0639, 0.0717, 0.0831, 0.0455, 0.0721,
        0.1319], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:11,665][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Erica] are: tensor([0.1061, 0.1157, 0.0917, 0.0998, 0.0512, 0.0083, 0.1282, 0.0696, 0.1451,
        0.0957, 0.0886], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:11,666][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Erica] are: tensor([1.3495e-05, 1.0040e-05, 5.5608e-01, 9.1863e-06, 1.9845e-05, 1.0681e-05,
        8.8860e-06, 1.1706e-05, 5.2017e-05, 1.9217e-06, 4.4378e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:11,667][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Erica] are: tensor([0.2815, 0.0897, 0.0888, 0.0730, 0.0212, 0.0706, 0.0626, 0.1368, 0.0456,
        0.0582, 0.0720], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:11,668][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Erica] are: tensor([8.4276e-04, 4.0463e-06, 1.5247e-02, 4.5508e-06, 2.2498e-04, 1.0857e-04,
        3.3909e-05, 6.3718e-05, 1.8187e-04, 7.4637e-05, 9.8321e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:11,670][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Erica] are: tensor([2.3313e-03, 2.2899e-04, 7.6244e-02, 1.1710e-04, 5.7190e-03, 3.4527e-04,
        1.6733e-04, 3.3172e-04, 5.1124e-04, 8.9212e-04, 9.1311e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:11,671][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Erica] are: tensor([2.3353e-04, 4.5572e-08, 6.1430e-01, 6.0691e-09, 8.4997e-07, 5.3672e-08,
        1.0902e-09, 4.3404e-10, 4.5603e-07, 1.0274e-09, 3.8547e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:11,672][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Erica] are: tensor([0.0970, 0.1547, 0.1875, 0.0952, 0.0624, 0.0230, 0.0143, 0.0971, 0.0521,
        0.0576, 0.1591], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:11,674][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Erica] are: tensor([0.0556, 0.0181, 0.0268, 0.0415, 0.0221, 0.0476, 0.0955, 0.1154, 0.0473,
        0.3124, 0.2176], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:11,676][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Erica] are: tensor([0.1866, 0.1364, 0.0441, 0.1416, 0.1224, 0.0319, 0.0633, 0.1113, 0.0417,
        0.0848, 0.0359], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:11,677][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Erica] are: tensor([0.1997, 0.1302, 0.0307, 0.1162, 0.0825, 0.0529, 0.0924, 0.1030, 0.0645,
        0.1025, 0.0254], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:11,679][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Erica] are: tensor([0.0939, 0.0882, 0.2901, 0.0817, 0.0278, 0.0303, 0.0643, 0.0512, 0.0287,
        0.0511, 0.1927], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:11,681][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Erica] are: tensor([0.0854, 0.1048, 0.0595, 0.1022, 0.0563, 0.0946, 0.0755, 0.0457, 0.1171,
        0.1769, 0.0820], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:11,683][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.2006, 0.0225, 0.0882, 0.0263, 0.0405, 0.2105, 0.0183, 0.0182, 0.0654,
        0.0165, 0.1053, 0.1876], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:11,684][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([4.4849e-04, 9.0977e-04, 1.1261e-04, 1.9247e-03, 2.0443e-03, 7.7232e-03,
        9.7823e-04, 2.7360e-04, 2.3384e-04, 7.4898e-05, 5.1202e-05, 9.8523e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:11,685][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.2240, 0.0609, 0.0528, 0.0692, 0.0293, 0.0816, 0.1098, 0.0693, 0.0765,
        0.0922, 0.0478, 0.0866], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:11,687][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([2.0224e-03, 2.2037e-05, 6.8738e-06, 2.8892e-05, 2.6462e-05, 1.1571e-03,
        1.2856e-04, 2.0832e-04, 5.3178e-04, 6.9841e-04, 6.7840e-04, 9.9449e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:11,688][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.1241, 0.0119, 0.0132, 0.0134, 0.0247, 0.0393, 0.0315, 0.0214, 0.0384,
        0.0440, 0.0764, 0.5616], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:11,690][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([4.3205e-02, 2.6894e-05, 5.1149e-05, 2.5130e-05, 3.2811e-04, 9.5717e-03,
        3.0519e-06, 1.1468e-05, 1.4749e-05, 1.9245e-06, 1.1932e-05, 9.4675e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:11,691][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.1140, 0.0154, 0.2129, 0.0146, 0.1206, 0.0253, 0.0115, 0.0149, 0.1434,
        0.0133, 0.2849, 0.0291], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:11,693][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0308, 0.0099, 0.0139, 0.0178, 0.0240, 0.0197, 0.0435, 0.0740, 0.0460,
        0.2841, 0.2214, 0.2150], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:11,695][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.1063, 0.1131, 0.0217, 0.1384, 0.0223, 0.0437, 0.1232, 0.1638, 0.0697,
        0.1279, 0.0257, 0.0443], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:11,696][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.1459, 0.0833, 0.0828, 0.0861, 0.0500, 0.0739, 0.0873, 0.0716, 0.0614,
        0.1011, 0.0905, 0.0662], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:11,698][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.1118, 0.0837, 0.0555, 0.0863, 0.0472, 0.0995, 0.0865, 0.0610, 0.0306,
        0.0746, 0.0457, 0.2175], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:11,700][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.2586, 0.0921, 0.0478, 0.1133, 0.0377, 0.0461, 0.0981, 0.0426, 0.0354,
        0.1122, 0.0461, 0.0700], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:11,702][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.2581, 0.0228, 0.1508, 0.0176, 0.0615, 0.0531, 0.0133, 0.0243, 0.0485,
        0.0177, 0.2024, 0.1099, 0.0201], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:11,703][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ a] are: tensor([8.0969e-04, 2.6744e-03, 3.4047e-04, 2.9528e-03, 1.3186e-04, 9.5774e-05,
        9.1645e-03, 3.0477e-02, 2.4415e-04, 6.0093e-04, 1.6542e-04, 2.2122e-04,
        9.5212e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:11,705][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.1275, 0.0696, 0.0374, 0.0978, 0.0309, 0.0707, 0.1631, 0.0223, 0.0319,
        0.1959, 0.0379, 0.0944, 0.0207], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:11,706][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ a] are: tensor([7.3359e-03, 1.0240e-03, 2.6980e-04, 9.4099e-04, 1.1057e-03, 2.1351e-03,
        4.2277e-03, 1.7716e-02, 3.3458e-03, 2.7914e-02, 1.6580e-02, 1.3984e-01,
        7.7756e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:11,708][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0367, 0.0052, 0.0056, 0.0061, 0.0090, 0.0641, 0.0163, 0.0176, 0.0331,
        0.0221, 0.0404, 0.5507, 0.1932], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:11,710][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0311, 0.0948, 0.0057, 0.0777, 0.0034, 0.0099, 0.0847, 0.2055, 0.0099,
        0.0293, 0.0017, 0.0071, 0.4393], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:11,711][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.1376, 0.0036, 0.1889, 0.0033, 0.1113, 0.0552, 0.0069, 0.0027, 0.1138,
        0.0026, 0.2991, 0.0701, 0.0048], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:11,712][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0236, 0.0061, 0.0067, 0.0111, 0.0107, 0.0209, 0.0207, 0.0350, 0.0274,
        0.1886, 0.1164, 0.2674, 0.2656], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:11,713][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0102, 0.0528, 0.0034, 0.0892, 0.0048, 0.0221, 0.0936, 0.2247, 0.0130,
        0.1204, 0.0054, 0.0275, 0.3327], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:11,714][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.1395, 0.0882, 0.0612, 0.0943, 0.0345, 0.0501, 0.0958, 0.0822, 0.0596,
        0.0819, 0.0604, 0.0683, 0.0838], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:11,715][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.1148, 0.0950, 0.0415, 0.1030, 0.0393, 0.0374, 0.1016, 0.1116, 0.0423,
        0.0697, 0.0316, 0.0420, 0.1700], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:11,717][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.1956, 0.0765, 0.0697, 0.0727, 0.0508, 0.0574, 0.0813, 0.0435, 0.0511,
        0.0910, 0.0733, 0.0791, 0.0583], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:11,719][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ basketball] are: tensor([0.1030, 0.0905, 0.0864, 0.0662, 0.0915, 0.0215, 0.0463, 0.0331, 0.0708,
        0.0547, 0.0835, 0.0615, 0.0403, 0.1507], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:11,720][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ basketball] are: tensor([4.4612e-04, 1.7275e-04, 4.8540e-04, 1.0042e-04, 6.1206e-04, 1.0059e-03,
        3.3537e-05, 6.3864e-05, 1.3624e-04, 1.4939e-05, 2.0558e-04, 8.9363e-05,
        7.0978e-05, 9.9656e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:11,722][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ basketball] are: tensor([0.1857, 0.0458, 0.0785, 0.0807, 0.0500, 0.0387, 0.0611, 0.0718, 0.0342,
        0.0579, 0.0599, 0.0278, 0.0658, 0.1422], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:11,723][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ basketball] are: tensor([5.8637e-04, 3.3268e-07, 6.3533e-06, 4.9638e-07, 1.4559e-05, 6.2521e-05,
        5.5169e-06, 5.0292e-06, 9.4163e-04, 2.1242e-05, 4.2435e-04, 6.3107e-04,
        9.1883e-05, 9.9721e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:11,725][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ basketball] are: tensor([0.0191, 0.0024, 0.0102, 0.0012, 0.0032, 0.0042, 0.0014, 0.0025, 0.0046,
        0.0105, 0.0485, 0.0068, 0.0121, 0.8732], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:11,726][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ basketball] are: tensor([2.3617e-03, 3.7164e-07, 1.8018e-05, 7.2508e-08, 1.6371e-04, 6.6502e-06,
        9.8368e-09, 2.1095e-07, 5.0087e-06, 4.7528e-09, 5.5938e-06, 3.1262e-07,
        3.3175e-08, 9.9744e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:11,728][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ basketball] are: tensor([0.1069, 0.0614, 0.1853, 0.0338, 0.0812, 0.0211, 0.0197, 0.0395, 0.0839,
        0.0521, 0.1747, 0.0181, 0.0300, 0.0924], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:11,729][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ basketball] are: tensor([0.0586, 0.0159, 0.0050, 0.0213, 0.0042, 0.0288, 0.0316, 0.0524, 0.1114,
        0.1274, 0.0362, 0.1176, 0.2670, 0.1228], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:11,731][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ basketball] are: tensor([0.1298, 0.0758, 0.0275, 0.0822, 0.0180, 0.0408, 0.0646, 0.0961, 0.0949,
        0.0630, 0.0257, 0.0487, 0.1053, 0.1278], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:11,733][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ basketball] are: tensor([0.1442, 0.0767, 0.1491, 0.0671, 0.0663, 0.0330, 0.0556, 0.0556, 0.0404,
        0.0616, 0.1469, 0.0448, 0.0501, 0.0086], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:11,735][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ basketball] are: tensor([0.1434, 0.0831, 0.0397, 0.0827, 0.0356, 0.0542, 0.0667, 0.0621, 0.0280,
        0.0521, 0.0257, 0.0207, 0.0491, 0.2570], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:11,737][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ basketball] are: tensor([0.0869, 0.0861, 0.0613, 0.0670, 0.0494, 0.0724, 0.0830, 0.0397, 0.0505,
        0.0966, 0.0716, 0.1169, 0.0562, 0.0623], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:11,738][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.2256, 0.0219, 0.0790, 0.0183, 0.0539, 0.1168, 0.0104, 0.0256, 0.0260,
        0.0174, 0.1084, 0.1251, 0.0262, 0.1308, 0.0144], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:11,740][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ to] are: tensor([2.3316e-03, 6.6641e-03, 9.2799e-05, 1.9415e-02, 4.3480e-05, 2.4620e-04,
        4.5084e-01, 1.0428e-03, 6.9978e-05, 4.1255e-03, 4.9678e-05, 3.8131e-04,
        6.5948e-04, 7.1252e-06, 5.1403e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:11,742][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1297, 0.0570, 0.0253, 0.0783, 0.0229, 0.0439, 0.1213, 0.0226, 0.0221,
        0.2172, 0.0237, 0.0579, 0.0205, 0.0176, 0.1401], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:11,743][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ to] are: tensor([2.7312e-03, 2.4656e-04, 9.7268e-06, 1.6896e-04, 2.3299e-05, 2.8310e-03,
        2.0029e-03, 2.7026e-03, 4.6435e-04, 4.4331e-03, 3.6234e-04, 2.4924e-01,
        7.3600e-02, 4.8676e-02, 6.1251e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:11,745][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0288, 0.0019, 0.0015, 0.0030, 0.0031, 0.0607, 0.0112, 0.0068, 0.0268,
        0.0112, 0.0107, 0.3270, 0.0751, 0.2092, 0.2230], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:11,746][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0265, 0.0375, 0.0017, 0.0480, 0.0013, 0.0078, 0.3656, 0.1326, 0.0010,
        0.0168, 0.0005, 0.0041, 0.0988, 0.0008, 0.2570], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:11,748][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1034, 0.0050, 0.0579, 0.0043, 0.0565, 0.0331, 0.1534, 0.0030, 0.0547,
        0.0049, 0.0902, 0.0515, 0.0054, 0.1024, 0.2745], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:11,750][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0224, 0.0042, 0.0048, 0.0070, 0.0089, 0.0126, 0.0083, 0.0191, 0.0249,
        0.0875, 0.0606, 0.1231, 0.1627, 0.1762, 0.2777], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:11,752][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0071, 0.0526, 0.0018, 0.0916, 0.0023, 0.0187, 0.1175, 0.1548, 0.0084,
        0.1212, 0.0024, 0.0184, 0.1811, 0.0127, 0.2095], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:11,753][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.1165, 0.0722, 0.0488, 0.0794, 0.0326, 0.0444, 0.0795, 0.0712, 0.0477,
        0.0716, 0.0486, 0.0616, 0.0767, 0.0530, 0.0961], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:11,755][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0943, 0.0774, 0.0412, 0.0927, 0.0268, 0.0600, 0.1072, 0.0752, 0.0380,
        0.0738, 0.0345, 0.0559, 0.0769, 0.0412, 0.1048], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:11,757][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.1759, 0.0695, 0.0653, 0.0714, 0.0463, 0.0573, 0.0706, 0.0339, 0.0379,
        0.0765, 0.0659, 0.0763, 0.0445, 0.0370, 0.0718], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:11,769][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:24:11,771][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:11,772][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:11,773][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:11,775][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:11,776][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:11,777][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:11,778][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:11,778][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:11,779][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:11,780][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:11,781][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:11,781][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:11,782][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.9675, 0.0325], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:11,783][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0065, 0.9935], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:11,783][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.6358, 0.3642], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:11,784][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.6853, 0.3147], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:11,785][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.9772, 0.0228], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:11,786][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.2539, 0.7461], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:11,786][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.9881, 0.0119], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:11,787][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.9119, 0.0881], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:11,789][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.3215, 0.6785], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:11,790][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.7118, 0.2882], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:11,792][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.7102, 0.2898], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:11,793][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.6916, 0.3084], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:11,795][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Erica] are: tensor([0.3611, 0.4078, 0.2311], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:11,796][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Erica] are: tensor([3.0591e-05, 3.9905e-05, 9.9993e-01], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:11,798][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Erica] are: tensor([0.6859, 0.2179, 0.0962], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:11,799][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Erica] are: tensor([6.8032e-03, 2.7842e-04, 9.9292e-01], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:11,800][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Erica] are: tensor([0.0210, 0.0023, 0.9767], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:11,801][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Erica] are: tensor([1.7761e-03, 5.3109e-07, 9.9822e-01], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:11,803][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Erica] are: tensor([0.3287, 0.3790, 0.2922], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:11,805][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Erica] are: tensor([0.4337, 0.3073, 0.2590], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:11,806][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Erica] are: tensor([0.5538, 0.3519, 0.0943], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:11,808][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Erica] are: tensor([0.5986, 0.3334, 0.0680], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:11,810][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Erica] are: tensor([0.4074, 0.2732, 0.3195], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:11,811][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Erica] are: tensor([0.3770, 0.4747, 0.1483], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:11,813][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.6410, 0.0726, 0.2297, 0.0566], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:11,814][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([2.3033e-03, 3.9260e-02, 1.5832e-04, 9.5828e-01], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:11,816][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.2380, 0.1782, 0.0355, 0.5483], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:11,817][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.1136, 0.3885, 0.0227, 0.4752], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:11,819][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.3397, 0.1539, 0.2276, 0.2787], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:11,821][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.1230, 0.1969, 0.0073, 0.6727], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:11,822][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.5507, 0.0263, 0.4030, 0.0200], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:11,824][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2068, 0.1573, 0.3992, 0.2368], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:11,825][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0676, 0.4737, 0.0145, 0.4442], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:11,826][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.4189, 0.2339, 0.1299, 0.2173], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:11,827][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.4153, 0.3093, 0.0713, 0.2041], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:11,828][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.4486, 0.1959, 0.0996, 0.2560], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:11,829][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Joshua] are: tensor([0.1817, 0.2540, 0.1307, 0.2128, 0.2208], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:11,830][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Joshua] are: tensor([1.2426e-04, 1.8502e-04, 5.4570e-04, 2.8354e-05, 9.9912e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:11,831][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Joshua] are: tensor([0.4689, 0.3002, 0.0543, 0.1271, 0.0494], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:11,832][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Joshua] are: tensor([1.6382e-02, 1.0883e-04, 9.8409e-03, 4.5046e-04, 9.7322e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:11,833][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Joshua] are: tensor([5.1277e-03, 5.5280e-04, 1.6916e-02, 4.8573e-04, 9.7692e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:11,834][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Joshua] are: tensor([2.0450e-02, 4.6271e-06, 1.9241e-04, 3.4591e-07, 9.7935e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:11,836][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Joshua] are: tensor([0.1708, 0.2005, 0.1972, 0.1115, 0.3201], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:11,838][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Joshua] are: tensor([0.1864, 0.1544, 0.1757, 0.3939, 0.0897], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:11,839][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Joshua] are: tensor([0.2704, 0.1833, 0.1605, 0.1533, 0.2325], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:11,841][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Joshua] are: tensor([0.3839, 0.2319, 0.1720, 0.1878, 0.0245], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:11,842][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Joshua] are: tensor([0.3282, 0.2074, 0.0669, 0.1241, 0.2734], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:11,844][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Joshua] are: tensor([0.2714, 0.1985, 0.1176, 0.2537, 0.1588], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:11,845][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([0.3259, 0.0786, 0.0827, 0.0783, 0.1340, 0.3004], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:11,847][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([0.0015, 0.0018, 0.0015, 0.0014, 0.0018, 0.9921], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:11,849][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([0.4727, 0.1360, 0.0384, 0.1928, 0.0633, 0.0968], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:11,850][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([1.4938e-02, 7.5117e-04, 3.5144e-04, 1.2519e-03, 6.1286e-04, 9.8209e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:11,852][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([0.3394, 0.0510, 0.0277, 0.0687, 0.0370, 0.4762], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:11,853][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([5.7747e-02, 1.8507e-04, 5.1230e-05, 3.0792e-05, 7.6613e-05, 9.4191e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:11,854][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([0.2408, 0.0461, 0.3718, 0.0360, 0.2628, 0.0424], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:11,856][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([0.1546, 0.1019, 0.1320, 0.2460, 0.1316, 0.2339], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:11,858][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([0.2107, 0.2732, 0.0817, 0.3100, 0.0725, 0.0519], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:11,859][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([0.3138, 0.1824, 0.1342, 0.1793, 0.0831, 0.1073], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:11,861][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([0.2927, 0.1904, 0.0629, 0.1465, 0.0488, 0.2587], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:11,863][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([0.3891, 0.1484, 0.0778, 0.1986, 0.0816, 0.1045], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:11,864][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.4024, 0.0539, 0.1518, 0.0439, 0.1067, 0.2155, 0.0257],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:11,866][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([4.2430e-03, 2.1515e-02, 4.0956e-04, 5.3066e-02, 9.8148e-05, 6.8592e-04,
        9.1998e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:11,867][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.2784, 0.1463, 0.0428, 0.1625, 0.0417, 0.0788, 0.2496],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:11,869][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0197, 0.0109, 0.0007, 0.0182, 0.0038, 0.4607, 0.4861],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:11,871][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.1079, 0.0122, 0.0148, 0.0246, 0.0475, 0.6531, 0.1399],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:11,872][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0919, 0.0988, 0.0038, 0.1075, 0.0029, 0.0137, 0.6814],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:11,874][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.2659, 0.0173, 0.1309, 0.0133, 0.1273, 0.0776, 0.3678],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:11,876][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0929, 0.0502, 0.0651, 0.1086, 0.1700, 0.2725, 0.2408],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:11,876][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0255, 0.1992, 0.0057, 0.2977, 0.0070, 0.0545, 0.4104],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:11,877][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.2575, 0.1648, 0.0917, 0.1695, 0.0544, 0.0855, 0.1765],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:11,878][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.2414, 0.2102, 0.0680, 0.1866, 0.0362, 0.0819, 0.1758],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:11,879][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.3038, 0.1261, 0.0950, 0.1437, 0.0825, 0.1019, 0.1470],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:11,880][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.4445, 0.0449, 0.2232, 0.0291, 0.1127, 0.1028, 0.0168, 0.0261],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:11,881][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([3.1849e-03, 2.6311e-02, 1.8747e-04, 5.2425e-02, 5.7419e-05, 1.4419e-04,
        7.6587e-02, 8.4110e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:11,883][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.2430, 0.1327, 0.0353, 0.1302, 0.0481, 0.1072, 0.2661, 0.0374],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:11,884][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0287, 0.0115, 0.0030, 0.0203, 0.0137, 0.0833, 0.1756, 0.6640],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:11,886][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.1964, 0.0302, 0.0279, 0.0451, 0.0793, 0.3226, 0.1403, 0.1581],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:11,888][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.1120, 0.1532, 0.0090, 0.1133, 0.0130, 0.0380, 0.1203, 0.4410],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:11,889][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.2189, 0.0045, 0.4332, 0.0040, 0.2700, 0.0594, 0.0074, 0.0026],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:11,891][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0822, 0.0349, 0.0615, 0.0793, 0.0835, 0.1460, 0.2158, 0.2967],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:11,893][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0145, 0.1257, 0.0056, 0.1864, 0.0098, 0.0462, 0.1837, 0.4281],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:11,894][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.2427, 0.1390, 0.0864, 0.1397, 0.0495, 0.0759, 0.1452, 0.1216],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:11,896][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.2613, 0.1659, 0.0563, 0.1417, 0.0406, 0.0427, 0.1096, 0.1819],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:11,898][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.2610, 0.1083, 0.0930, 0.1224, 0.0834, 0.0891, 0.1164, 0.1264],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:11,899][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ office] are: tensor([0.2152, 0.1113, 0.1625, 0.0811, 0.1136, 0.0932, 0.0726, 0.1094, 0.0410],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:11,900][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ office] are: tensor([1.2297e-04, 7.5145e-04, 2.5410e-03, 3.9185e-04, 1.3649e-05, 2.6148e-04,
        1.4064e-04, 7.3074e-05, 9.9570e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:11,902][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ office] are: tensor([0.3050, 0.1294, 0.0749, 0.1068, 0.0395, 0.0705, 0.1084, 0.0908, 0.0746],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:11,903][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ office] are: tensor([1.0794e-02, 2.5583e-04, 2.0199e-05, 4.5238e-04, 4.0253e-04, 6.4268e-03,
        5.1534e-03, 4.9120e-03, 9.7158e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:11,905][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ office] are: tensor([0.1782, 0.0059, 0.0091, 0.0074, 0.0324, 0.0382, 0.0184, 0.0201, 0.6903],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:11,906][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ office] are: tensor([6.7204e-03, 8.2676e-06, 2.1539e-04, 1.6333e-06, 3.3348e-06, 1.6711e-05,
        4.3968e-08, 4.3309e-07, 9.9303e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:11,908][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ office] are: tensor([0.1906, 0.0332, 0.3764, 0.0270, 0.1643, 0.0348, 0.0275, 0.0180, 0.1282],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:11,910][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ office] are: tensor([0.0496, 0.0484, 0.0013, 0.0645, 0.0143, 0.1036, 0.1991, 0.3326, 0.1865],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:11,911][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ office] are: tensor([0.1554, 0.1083, 0.0580, 0.1689, 0.0183, 0.1001, 0.1300, 0.2102, 0.0507],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:11,913][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ office] are: tensor([0.2204, 0.1253, 0.1289, 0.1118, 0.0869, 0.0855, 0.0991, 0.1003, 0.0418],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:11,915][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ office] are: tensor([0.1501, 0.1116, 0.0899, 0.1074, 0.0275, 0.0539, 0.0831, 0.0753, 0.3013],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:11,916][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ office] are: tensor([0.3655, 0.1283, 0.0912, 0.1122, 0.0533, 0.0486, 0.0962, 0.0439, 0.0607],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:11,918][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.4614, 0.0168, 0.2119, 0.0139, 0.0859, 0.1128, 0.0100, 0.0373, 0.0400,
        0.0102], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:11,919][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([3.4871e-03, 4.5845e-02, 5.1684e-04, 8.3929e-03, 7.8011e-05, 4.5718e-04,
        5.8469e-03, 4.1441e-04, 2.3785e-04, 9.3472e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:11,921][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.4101, 0.0593, 0.0483, 0.0458, 0.0625, 0.2218, 0.0538, 0.0250, 0.0209,
        0.0526], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:11,923][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.0293, 0.0074, 0.0017, 0.0108, 0.0079, 0.0592, 0.0727, 0.1761, 0.1323,
        0.5026], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:11,924][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.0652, 0.0265, 0.0190, 0.0562, 0.0170, 0.0946, 0.1148, 0.1191, 0.1393,
        0.3482], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:11,926][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.1359, 0.1967, 0.0276, 0.1197, 0.0163, 0.0465, 0.0783, 0.0815, 0.0304,
        0.2672], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:11,927][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.2801, 0.0083, 0.3373, 0.0059, 0.1887, 0.0347, 0.0097, 0.0050, 0.1267,
        0.0035], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:11,928][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0410, 0.0154, 0.0250, 0.0336, 0.0494, 0.0670, 0.0741, 0.1540, 0.1145,
        0.4261], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:11,929][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.0184, 0.1690, 0.0060, 0.1294, 0.0065, 0.0108, 0.1059, 0.1480, 0.0143,
        0.3917], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:11,930][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.1929, 0.1114, 0.0858, 0.1125, 0.0604, 0.0768, 0.1068, 0.0917, 0.0566,
        0.1051], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:11,932][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.1550, 0.1377, 0.0814, 0.1328, 0.0446, 0.0727, 0.1096, 0.0745, 0.0541,
        0.1376], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:11,933][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.2608, 0.0928, 0.0854, 0.0929, 0.0639, 0.0717, 0.0831, 0.0455, 0.0721,
        0.1319], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:11,935][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Erica] are: tensor([0.1061, 0.1157, 0.0917, 0.0998, 0.0512, 0.0083, 0.1282, 0.0696, 0.1451,
        0.0957, 0.0886], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:11,936][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Erica] are: tensor([1.3495e-05, 1.0040e-05, 5.5608e-01, 9.1863e-06, 1.9845e-05, 1.0681e-05,
        8.8860e-06, 1.1706e-05, 5.2017e-05, 1.9217e-06, 4.4378e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:11,938][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Erica] are: tensor([0.2815, 0.0897, 0.0888, 0.0730, 0.0212, 0.0706, 0.0626, 0.1368, 0.0456,
        0.0582, 0.0720], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:11,939][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Erica] are: tensor([8.4276e-04, 4.0463e-06, 1.5247e-02, 4.5508e-06, 2.2498e-04, 1.0857e-04,
        3.3909e-05, 6.3718e-05, 1.8187e-04, 7.4637e-05, 9.8321e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:11,940][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Erica] are: tensor([2.3313e-03, 2.2899e-04, 7.6244e-02, 1.1710e-04, 5.7190e-03, 3.4527e-04,
        1.6733e-04, 3.3172e-04, 5.1124e-04, 8.9212e-04, 9.1311e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:11,941][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Erica] are: tensor([2.3353e-04, 4.5572e-08, 6.1430e-01, 6.0691e-09, 8.4997e-07, 5.3672e-08,
        1.0902e-09, 4.3404e-10, 4.5603e-07, 1.0274e-09, 3.8547e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:11,943][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Erica] are: tensor([0.0970, 0.1547, 0.1875, 0.0952, 0.0624, 0.0230, 0.0143, 0.0971, 0.0521,
        0.0576, 0.1591], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:11,945][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Erica] are: tensor([0.0556, 0.0181, 0.0268, 0.0415, 0.0221, 0.0476, 0.0955, 0.1154, 0.0473,
        0.3124, 0.2176], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:11,947][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Erica] are: tensor([0.1866, 0.1364, 0.0441, 0.1416, 0.1224, 0.0319, 0.0633, 0.1113, 0.0417,
        0.0848, 0.0359], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:11,948][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Erica] are: tensor([0.1997, 0.1302, 0.0307, 0.1162, 0.0825, 0.0529, 0.0924, 0.1030, 0.0645,
        0.1025, 0.0254], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:11,950][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Erica] are: tensor([0.0939, 0.0882, 0.2901, 0.0817, 0.0278, 0.0303, 0.0643, 0.0512, 0.0287,
        0.0511, 0.1927], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:11,952][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Erica] are: tensor([0.0854, 0.1048, 0.0595, 0.1022, 0.0563, 0.0946, 0.0755, 0.0457, 0.1171,
        0.1769, 0.0820], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:11,953][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.2006, 0.0225, 0.0882, 0.0263, 0.0405, 0.2105, 0.0183, 0.0182, 0.0654,
        0.0165, 0.1053, 0.1876], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:11,955][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([4.4849e-04, 9.0977e-04, 1.1261e-04, 1.9247e-03, 2.0443e-03, 7.7232e-03,
        9.7823e-04, 2.7360e-04, 2.3384e-04, 7.4898e-05, 5.1202e-05, 9.8523e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:11,956][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.2240, 0.0609, 0.0528, 0.0692, 0.0293, 0.0816, 0.1098, 0.0693, 0.0765,
        0.0922, 0.0478, 0.0866], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:11,958][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([2.0224e-03, 2.2037e-05, 6.8738e-06, 2.8892e-05, 2.6462e-05, 1.1571e-03,
        1.2856e-04, 2.0832e-04, 5.3178e-04, 6.9841e-04, 6.7840e-04, 9.9449e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:11,959][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.1241, 0.0119, 0.0132, 0.0134, 0.0247, 0.0393, 0.0315, 0.0214, 0.0384,
        0.0440, 0.0764, 0.5616], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:11,960][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([4.3205e-02, 2.6894e-05, 5.1149e-05, 2.5130e-05, 3.2811e-04, 9.5717e-03,
        3.0519e-06, 1.1468e-05, 1.4749e-05, 1.9245e-06, 1.1932e-05, 9.4675e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:11,962][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.1140, 0.0154, 0.2129, 0.0146, 0.1206, 0.0253, 0.0115, 0.0149, 0.1434,
        0.0133, 0.2849, 0.0291], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:11,964][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0308, 0.0099, 0.0139, 0.0178, 0.0240, 0.0197, 0.0435, 0.0740, 0.0460,
        0.2841, 0.2214, 0.2150], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:11,966][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.1063, 0.1131, 0.0217, 0.1384, 0.0223, 0.0437, 0.1232, 0.1638, 0.0697,
        0.1279, 0.0257, 0.0443], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:11,967][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.1459, 0.0833, 0.0828, 0.0861, 0.0500, 0.0739, 0.0873, 0.0716, 0.0614,
        0.1011, 0.0905, 0.0662], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:11,969][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.1118, 0.0837, 0.0555, 0.0863, 0.0472, 0.0995, 0.0865, 0.0610, 0.0306,
        0.0746, 0.0457, 0.2175], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:11,971][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.2586, 0.0921, 0.0478, 0.1133, 0.0377, 0.0461, 0.0981, 0.0426, 0.0354,
        0.1122, 0.0461, 0.0700], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:11,972][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.2581, 0.0228, 0.1508, 0.0176, 0.0615, 0.0531, 0.0133, 0.0243, 0.0485,
        0.0177, 0.2024, 0.1099, 0.0201], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:11,974][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([8.0969e-04, 2.6744e-03, 3.4047e-04, 2.9528e-03, 1.3186e-04, 9.5774e-05,
        9.1645e-03, 3.0477e-02, 2.4415e-04, 6.0093e-04, 1.6542e-04, 2.2122e-04,
        9.5212e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:11,976][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.1275, 0.0696, 0.0374, 0.0978, 0.0309, 0.0707, 0.1631, 0.0223, 0.0319,
        0.1959, 0.0379, 0.0944, 0.0207], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:11,977][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([7.3359e-03, 1.0240e-03, 2.6980e-04, 9.4099e-04, 1.1057e-03, 2.1351e-03,
        4.2277e-03, 1.7716e-02, 3.3458e-03, 2.7914e-02, 1.6580e-02, 1.3984e-01,
        7.7756e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:11,978][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0367, 0.0052, 0.0056, 0.0061, 0.0090, 0.0641, 0.0163, 0.0176, 0.0331,
        0.0221, 0.0404, 0.5507, 0.1932], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:11,979][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0311, 0.0948, 0.0057, 0.0777, 0.0034, 0.0099, 0.0847, 0.2055, 0.0099,
        0.0293, 0.0017, 0.0071, 0.4393], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:11,979][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.1376, 0.0036, 0.1889, 0.0033, 0.1113, 0.0552, 0.0069, 0.0027, 0.1138,
        0.0026, 0.2991, 0.0701, 0.0048], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:11,981][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0236, 0.0061, 0.0067, 0.0111, 0.0107, 0.0209, 0.0207, 0.0350, 0.0274,
        0.1886, 0.1164, 0.2674, 0.2656], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:11,983][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0102, 0.0528, 0.0034, 0.0892, 0.0048, 0.0221, 0.0936, 0.2247, 0.0130,
        0.1204, 0.0054, 0.0275, 0.3327], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:11,985][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.1395, 0.0882, 0.0612, 0.0943, 0.0345, 0.0501, 0.0958, 0.0822, 0.0596,
        0.0819, 0.0604, 0.0683, 0.0838], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:11,986][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.1148, 0.0950, 0.0415, 0.1030, 0.0393, 0.0374, 0.1016, 0.1116, 0.0423,
        0.0697, 0.0316, 0.0420, 0.1700], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:11,988][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.1956, 0.0765, 0.0697, 0.0727, 0.0508, 0.0574, 0.0813, 0.0435, 0.0511,
        0.0910, 0.0733, 0.0791, 0.0583], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:11,990][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ basketball] are: tensor([0.1030, 0.0905, 0.0864, 0.0662, 0.0915, 0.0215, 0.0463, 0.0331, 0.0708,
        0.0547, 0.0835, 0.0615, 0.0403, 0.1507], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:11,991][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ basketball] are: tensor([4.4612e-04, 1.7275e-04, 4.8540e-04, 1.0042e-04, 6.1206e-04, 1.0059e-03,
        3.3537e-05, 6.3864e-05, 1.3624e-04, 1.4939e-05, 2.0558e-04, 8.9363e-05,
        7.0978e-05, 9.9656e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:11,993][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ basketball] are: tensor([0.1857, 0.0458, 0.0785, 0.0807, 0.0500, 0.0387, 0.0611, 0.0718, 0.0342,
        0.0579, 0.0599, 0.0278, 0.0658, 0.1422], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:11,994][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ basketball] are: tensor([5.8637e-04, 3.3268e-07, 6.3533e-06, 4.9638e-07, 1.4559e-05, 6.2521e-05,
        5.5169e-06, 5.0292e-06, 9.4163e-04, 2.1242e-05, 4.2435e-04, 6.3107e-04,
        9.1883e-05, 9.9721e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:11,996][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ basketball] are: tensor([0.0191, 0.0024, 0.0102, 0.0012, 0.0032, 0.0042, 0.0014, 0.0025, 0.0046,
        0.0105, 0.0485, 0.0068, 0.0121, 0.8732], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:11,997][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ basketball] are: tensor([2.3617e-03, 3.7164e-07, 1.8018e-05, 7.2508e-08, 1.6371e-04, 6.6502e-06,
        9.8368e-09, 2.1095e-07, 5.0087e-06, 4.7528e-09, 5.5938e-06, 3.1262e-07,
        3.3175e-08, 9.9744e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:11,999][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ basketball] are: tensor([0.1069, 0.0614, 0.1853, 0.0338, 0.0812, 0.0211, 0.0197, 0.0395, 0.0839,
        0.0521, 0.1747, 0.0181, 0.0300, 0.0924], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:12,000][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ basketball] are: tensor([0.0586, 0.0159, 0.0050, 0.0213, 0.0042, 0.0288, 0.0316, 0.0524, 0.1114,
        0.1274, 0.0362, 0.1176, 0.2670, 0.1228], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:12,002][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ basketball] are: tensor([0.1298, 0.0758, 0.0275, 0.0822, 0.0180, 0.0408, 0.0646, 0.0961, 0.0949,
        0.0630, 0.0257, 0.0487, 0.1053, 0.1278], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:12,004][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ basketball] are: tensor([0.1442, 0.0767, 0.1491, 0.0671, 0.0663, 0.0330, 0.0556, 0.0556, 0.0404,
        0.0616, 0.1469, 0.0448, 0.0501, 0.0086], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:12,006][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ basketball] are: tensor([0.1434, 0.0831, 0.0397, 0.0827, 0.0356, 0.0542, 0.0667, 0.0621, 0.0280,
        0.0521, 0.0257, 0.0207, 0.0491, 0.2570], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:12,008][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ basketball] are: tensor([0.0869, 0.0861, 0.0613, 0.0670, 0.0494, 0.0724, 0.0830, 0.0397, 0.0505,
        0.0966, 0.0716, 0.1169, 0.0562, 0.0623], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:12,009][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.2256, 0.0219, 0.0790, 0.0183, 0.0539, 0.1168, 0.0104, 0.0256, 0.0260,
        0.0174, 0.1084, 0.1251, 0.0262, 0.1308, 0.0144], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:12,011][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([2.3316e-03, 6.6641e-03, 9.2799e-05, 1.9415e-02, 4.3480e-05, 2.4620e-04,
        4.5084e-01, 1.0428e-03, 6.9978e-05, 4.1255e-03, 4.9678e-05, 3.8131e-04,
        6.5948e-04, 7.1252e-06, 5.1403e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:12,013][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1297, 0.0570, 0.0253, 0.0783, 0.0229, 0.0439, 0.1213, 0.0226, 0.0221,
        0.2172, 0.0237, 0.0579, 0.0205, 0.0176, 0.1401], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:12,014][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([2.7312e-03, 2.4656e-04, 9.7268e-06, 1.6896e-04, 2.3299e-05, 2.8310e-03,
        2.0029e-03, 2.7026e-03, 4.6435e-04, 4.4331e-03, 3.6234e-04, 2.4924e-01,
        7.3600e-02, 4.8676e-02, 6.1251e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:12,016][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0288, 0.0019, 0.0015, 0.0030, 0.0031, 0.0607, 0.0112, 0.0068, 0.0268,
        0.0112, 0.0107, 0.3270, 0.0751, 0.2092, 0.2230], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:12,017][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0265, 0.0375, 0.0017, 0.0480, 0.0013, 0.0078, 0.3656, 0.1326, 0.0010,
        0.0168, 0.0005, 0.0041, 0.0988, 0.0008, 0.2570], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:12,019][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.1034, 0.0050, 0.0579, 0.0043, 0.0565, 0.0331, 0.1534, 0.0030, 0.0547,
        0.0049, 0.0902, 0.0515, 0.0054, 0.1024, 0.2745], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:12,021][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0224, 0.0042, 0.0048, 0.0070, 0.0089, 0.0126, 0.0083, 0.0191, 0.0249,
        0.0875, 0.0606, 0.1231, 0.1627, 0.1762, 0.2777], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:12,023][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0071, 0.0526, 0.0018, 0.0916, 0.0023, 0.0187, 0.1175, 0.1548, 0.0084,
        0.1212, 0.0024, 0.0184, 0.1811, 0.0127, 0.2095], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:12,024][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.1165, 0.0722, 0.0488, 0.0794, 0.0326, 0.0444, 0.0795, 0.0712, 0.0477,
        0.0716, 0.0486, 0.0616, 0.0767, 0.0530, 0.0961], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:12,026][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0943, 0.0774, 0.0412, 0.0927, 0.0268, 0.0600, 0.1072, 0.0752, 0.0380,
        0.0738, 0.0345, 0.0559, 0.0769, 0.0412, 0.1048], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:12,027][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.1759, 0.0695, 0.0653, 0.0714, 0.0463, 0.0573, 0.0706, 0.0339, 0.0379,
        0.0765, 0.0659, 0.0763, 0.0445, 0.0370, 0.0718], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:12,031][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:24:12,032][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 4986],
        [  940],
        [  646],
        [ 5486],
        [    1],
        [15178],
        [ 9042],
        [14502],
        [13776],
        [ 2520],
        [ 2971],
        [ 8937],
        [16435],
        [ 3669],
        [15358]], device='cuda:0')
[2024-07-24 10:24:12,034][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[28952],
        [32647],
        [ 2614],
        [35903],
        [    1],
        [38752],
        [37553],
        [27283],
        [42098],
        [42060],
        [ 1880],
        [31006],
        [25300],
        [23100],
        [35333]], device='cuda:0')
[2024-07-24 10:24:12,036][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[ 1423],
        [ 1434],
        [11767],
        [ 7037],
        [13095],
        [ 6512],
        [ 7588],
        [ 9416],
        [12527],
        [ 9349],
        [21441],
        [18099],
        [28676],
        [18478],
        [15215]], device='cuda:0')
[2024-07-24 10:24:12,037][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[30231],
        [ 3812],
        [16887],
        [14397],
        [ 2058],
        [31862],
        [23968],
        [45140],
        [21566],
        [ 2498],
        [17457],
        [15414],
        [38704],
        [18714],
        [24152]], device='cuda:0')
[2024-07-24 10:24:12,039][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 4099],
        [ 5573],
        [ 5275],
        [17015],
        [ 7272],
        [ 7836],
        [16768],
        [16219],
        [12026],
        [ 8898],
        [10790],
        [12809],
        [17346],
        [16163],
        [23318]], device='cuda:0')
[2024-07-24 10:24:12,041][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[33184],
        [32911],
        [40935],
        [22642],
        [ 1025],
        [34639],
        [32576],
        [38656],
        [31044],
        [36572],
        [38876],
        [20136],
        [34938],
        [ 5010],
        [23625]], device='cuda:0')
[2024-07-24 10:24:12,043][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[ 9663],
        [ 9427],
        [12400],
        [ 3848],
        [  247],
        [ 3715],
        [ 3146],
        [ 2597],
        [11026],
        [ 2087],
        [14487],
        [ 6673],
        [ 7039],
        [ 6267],
        [ 3673]], device='cuda:0')
[2024-07-24 10:24:12,044][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[24970],
        [32332],
        [ 2228],
        [27959],
        [ 1023],
        [18396],
        [29305],
        [21993],
        [28848],
        [29252],
        [ 2298],
        [24393],
        [20519],
        [ 2438],
        [26627]], device='cuda:0')
[2024-07-24 10:24:12,046][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[10744],
        [11127],
        [21727],
        [ 5792],
        [ 2879],
        [  948],
        [10975],
        [  929],
        [ 2557],
        [ 1770],
        [21279],
        [ 3549],
        [ 3117],
        [ 8739],
        [14328]], device='cuda:0')
[2024-07-24 10:24:12,047][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[ 8666],
        [ 9443],
        [19596],
        [32928],
        [32584],
        [25773],
        [18477],
        [27284],
        [38084],
        [22144],
        [26771],
        [20682],
        [27873],
        [40192],
        [34948]], device='cuda:0')
[2024-07-24 10:24:12,049][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[ 9746],
        [ 4122],
        [ 6330],
        [ 9563],
        [ 7528],
        [ 6343],
        [ 9968],
        [ 8104],
        [ 6472],
        [ 5995],
        [ 3572],
        [ 4599],
        [ 8195],
        [13865],
        [ 8337]], device='cuda:0')
[2024-07-24 10:24:12,051][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[19050],
        [33959],
        [34135],
        [37432],
        [34478],
        [32203],
        [40186],
        [40230],
        [33757],
        [39204],
        [39797],
        [34328],
        [38871],
        [20873],
        [40268]], device='cuda:0')
[2024-07-24 10:24:12,052][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[12883],
        [ 2834],
        [ 2753],
        [  717],
        [ 2638],
        [  983],
        [  631],
        [ 2335],
        [ 1365],
        [  711],
        [ 4704],
        [  822],
        [ 3532],
        [10537],
        [ 1385]], device='cuda:0')
[2024-07-24 10:24:12,054][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[33745],
        [19874],
        [ 8987],
        [12141],
        [ 6826],
        [11129],
        [ 8560],
        [14105],
        [12801],
        [12817],
        [ 9481],
        [11849],
        [13356],
        [10392],
        [11392]], device='cuda:0')
[2024-07-24 10:24:12,056][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 8324],
        [ 4160],
        [ 1171],
        [10942],
        [    1],
        [44511],
        [16066],
        [38447],
        [42596],
        [ 4540],
        [ 1606],
        [37571],
        [36797],
        [12912],
        [15926]], device='cuda:0')
[2024-07-24 10:24:12,057][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[13998],
        [13469],
        [12822],
        [11323],
        [ 8727],
        [ 6156],
        [ 7946],
        [ 8603],
        [12673],
        [ 8720],
        [18133],
        [10267],
        [12026],
        [ 9067],
        [ 8887]], device='cuda:0')
[2024-07-24 10:24:12,059][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[11492],
        [26250],
        [15062],
        [15263],
        [18432],
        [13875],
        [ 9976],
        [ 6320],
        [15509],
        [29958],
        [11794],
        [18520],
        [ 6810],
        [17851],
        [ 9561]], device='cuda:0')
[2024-07-24 10:24:12,060][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[38851],
        [40386],
        [40730],
        [47156],
        [41650],
        [44134],
        [42896],
        [43119],
        [44354],
        [42677],
        [44877],
        [43854],
        [41806],
        [41030],
        [38184]], device='cuda:0')
[2024-07-24 10:24:12,062][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[18556],
        [17447],
        [ 8188],
        [26973],
        [10355],
        [ 5783],
        [13256],
        [11769],
        [10456],
        [17232],
        [ 6187],
        [14709],
        [13752],
        [27291],
        [21924]], device='cuda:0')
[2024-07-24 10:24:12,064][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[19546],
        [19328],
        [46403],
        [15423],
        [33042],
        [18751],
        [19362],
        [15135],
        [17004],
        [ 9456],
        [46135],
        [16976],
        [11914],
        [33537],
        [13847]], device='cuda:0')
[2024-07-24 10:24:12,065][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[24269],
        [19406],
        [39786],
        [23076],
        [20127],
        [23951],
        [21493],
        [16467],
        [19390],
        [20575],
        [40164],
        [18009],
        [16045],
        [36309],
        [19551]], device='cuda:0')
[2024-07-24 10:24:12,067][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[33236],
        [33698],
        [36197],
        [29156],
        [ 3538],
        [ 6424],
        [25912],
        [ 7724],
        [ 7027],
        [ 9238],
        [28510],
        [10284],
        [12895],
        [ 7000],
        [28862]], device='cuda:0')
[2024-07-24 10:24:12,069][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[ 4476],
        [ 4648],
        [ 8025],
        [10056],
        [ 2779],
        [ 2315],
        [ 1350],
        [ 2767],
        [ 2014],
        [15596],
        [18161],
        [24605],
        [16051],
        [ 3876],
        [ 2968]], device='cuda:0')
[2024-07-24 10:24:12,070][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[35960],
        [24375],
        [31275],
        [21724],
        [31069],
        [23829],
        [17637],
        [16367],
        [16038],
        [20029],
        [21152],
        [16090],
        [17630],
        [22236],
        [18479]], device='cuda:0')
[2024-07-24 10:24:12,072][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[30546],
        [26019],
        [25936],
        [25707],
        [26009],
        [28808],
        [29263],
        [30054],
        [30781],
        [28689],
        [28022],
        [30510],
        [30833],
        [30624],
        [31893]], device='cuda:0')
[2024-07-24 10:24:12,073][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[46216],
        [47361],
        [40090],
        [46579],
        [42585],
        [42918],
        [45392],
        [43975],
        [37861],
        [43880],
        [35519],
        [43805],
        [40484],
        [34802],
        [42037]], device='cuda:0')
[2024-07-24 10:24:12,075][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[13554],
        [15277],
        [31590],
        [22358],
        [27120],
        [19191],
        [22499],
        [17423],
        [17482],
        [20367],
        [24256],
        [20838],
        [19579],
        [27067],
        [22807]], device='cuda:0')
[2024-07-24 10:24:12,077][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[10093],
        [ 8559],
        [10537],
        [10420],
        [15675],
        [19367],
        [16877],
        [22105],
        [19828],
        [16147],
        [13063],
        [14509],
        [19383],
        [18143],
        [18309]], device='cuda:0')
[2024-07-24 10:24:12,078][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[35146],
        [41228],
        [46925],
        [32743],
        [50257],
        [ 4666],
        [27975],
        [ 7274],
        [ 5097],
        [41822],
        [46301],
        [ 9475],
        [ 9124],
        [30793],
        [28435]], device='cuda:0')
[2024-07-24 10:24:12,080][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[22516],
        [22516],
        [22516],
        [22516],
        [22516],
        [22516],
        [22516],
        [22516],
        [22516],
        [22516],
        [22516],
        [22516],
        [22516],
        [22516],
        [22516]], device='cuda:0')
[2024-07-24 10:24:12,107][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:24:12,108][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:12,109][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:12,110][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:12,111][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:12,111][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:12,112][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:12,113][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:12,113][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:12,114][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:12,115][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:12,115][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:12,117][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:12,118][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0016, 0.9984], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:12,119][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [,] are: tensor([9.9938e-01, 6.1494e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:12,120][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [,] are: tensor([9.9977e-01, 2.2701e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:12,122][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.6514, 0.3486], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:12,123][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.9770, 0.0230], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:12,124][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.8501, 0.1499], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:12,126][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.9303, 0.0697], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:12,127][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.9833, 0.0167], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:12,129][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.6072, 0.3928], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:12,130][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [,] are: tensor([8.5607e-05, 9.9991e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:12,131][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [,] are: tensor([1.4238e-05, 9.9999e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:12,133][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.1294, 0.8706], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:12,134][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Erica] are: tensor([2.5993e-04, 8.3288e-01, 1.6686e-01], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:12,135][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Erica] are: tensor([0.8338, 0.1313, 0.0350], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:12,137][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Erica] are: tensor([0.9411, 0.0186, 0.0403], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:12,139][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Erica] are: tensor([0.4814, 0.2783, 0.2403], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:12,140][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Erica] are: tensor([0.8519, 0.0688, 0.0793], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:12,142][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Erica] are: tensor([0.6511, 0.2332, 0.1156], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:12,144][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Erica] are: tensor([0.3875, 0.0883, 0.5242], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:12,145][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Erica] are: tensor([0.7344, 0.1306, 0.1350], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:12,147][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Erica] are: tensor([0.6323, 0.2436, 0.1241], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:12,148][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Erica] are: tensor([0.0008, 0.6502, 0.3490], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:12,150][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Erica] are: tensor([2.7956e-04, 7.3722e-01, 2.6250e-01], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:12,151][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Erica] are: tensor([5.1307e-04, 5.4629e-03, 9.9402e-01], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:12,152][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ and] are: tensor([3.1034e-04, 2.2775e-01, 1.0203e-01, 6.6991e-01], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:12,152][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.7271, 0.0200, 0.2520, 0.0010], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:12,153][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.5779, 0.0072, 0.0305, 0.3844], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:12,154][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.3655, 0.1997, 0.1815, 0.2533], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:12,155][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.8071, 0.0398, 0.0828, 0.0704], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:12,157][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.5368, 0.2179, 0.0170, 0.2282], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:12,158][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.5429, 0.1468, 0.1924, 0.1178], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:12,160][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.5707, 0.0479, 0.2054, 0.1760], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:12,161][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.5060, 0.3088, 0.1384, 0.0468], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:12,162][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ and] are: tensor([3.9029e-05, 1.9197e-01, 2.5459e-01, 5.5340e-01], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:12,163][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ and] are: tensor([4.3239e-04, 5.2010e-01, 2.3059e-01, 2.4888e-01], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:12,164][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ and] are: tensor([5.9244e-03, 5.9293e-03, 1.7380e-07, 9.8815e-01], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:12,166][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Joshua] are: tensor([4.7038e-05, 1.7517e-01, 3.9458e-02, 6.6004e-01, 1.2528e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:12,167][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Joshua] are: tensor([0.7077, 0.1282, 0.0533, 0.1019, 0.0089], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:12,169][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Joshua] are: tensor([0.4783, 0.0141, 0.0312, 0.3842, 0.0922], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:12,170][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Joshua] are: tensor([0.2959, 0.1717, 0.1493, 0.2150, 0.1681], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:12,172][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Joshua] are: tensor([0.6215, 0.0796, 0.0884, 0.0959, 0.1147], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:12,174][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Joshua] are: tensor([0.3267, 0.2624, 0.1786, 0.1713, 0.0610], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:12,175][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Joshua] are: tensor([0.2453, 0.0292, 0.3685, 0.0426, 0.3144], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:12,177][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Joshua] are: tensor([0.4266, 0.0564, 0.3195, 0.1550, 0.0425], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:12,179][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Joshua] are: tensor([0.6699, 0.2001, 0.0858, 0.0326, 0.0116], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:12,180][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Joshua] are: tensor([1.6304e-04, 3.0240e-01, 1.5128e-01, 5.2741e-01, 1.8747e-02],
       device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:12,181][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Joshua] are: tensor([0.0004, 0.4023, 0.2000, 0.2404, 0.1569], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:12,182][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Joshua] are: tensor([1.4599e-02, 1.1911e-02, 8.1768e-05, 5.2105e-02, 9.2130e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:12,184][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ went] are: tensor([6.0759e-05, 1.3211e-01, 4.2310e-02, 4.7952e-01, 1.3007e-01, 2.1593e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:12,185][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ went] are: tensor([0.5327, 0.0352, 0.1890, 0.0793, 0.1606, 0.0032], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:12,187][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ went] are: tensor([0.4131, 0.0134, 0.0349, 0.2765, 0.0912, 0.1710], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:12,189][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ went] are: tensor([0.2621, 0.1483, 0.1294, 0.1872, 0.1466, 0.1264], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:12,190][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ went] are: tensor([0.5598, 0.0510, 0.0939, 0.0735, 0.1076, 0.1143], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:12,192][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ went] are: tensor([0.5641, 0.1420, 0.0319, 0.1167, 0.0234, 0.1219], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:12,194][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ went] are: tensor([0.5248, 0.0937, 0.1356, 0.0967, 0.0927, 0.0564], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:12,195][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ went] are: tensor([0.4600, 0.0613, 0.1777, 0.0998, 0.1241, 0.0770], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:12,197][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.5585, 0.2065, 0.0880, 0.0321, 0.0157, 0.0991], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:12,198][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ went] are: tensor([1.8511e-04, 1.4505e-01, 2.1049e-01, 6.1508e-01, 1.6291e-02, 1.2907e-02],
       device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:12,200][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ went] are: tensor([0.0004, 0.3090, 0.1704, 0.1781, 0.1366, 0.2056], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:12,201][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ went] are: tensor([1.4603e-03, 2.2811e-02, 1.0862e-06, 2.8676e-02, 8.8885e-07, 9.4705e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:12,202][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ to] are: tensor([1.3295e-04, 8.0585e-02, 3.5385e-02, 2.2276e-01, 7.9972e-02, 1.1399e-01,
        4.6718e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:12,203][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ to] are: tensor([8.8246e-01, 5.7527e-03, 4.5944e-02, 1.7540e-02, 4.2022e-02, 6.1815e-03,
        9.8444e-05], device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:12,203][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.2825, 0.0071, 0.0240, 0.1556, 0.0687, 0.1292, 0.3329],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:12,204][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.2148, 0.1207, 0.1118, 0.1527, 0.1273, 0.1089, 0.1638],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:12,206][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.4593, 0.0433, 0.0846, 0.0590, 0.1187, 0.1101, 0.1250],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:12,207][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.3312, 0.0635, 0.0272, 0.0782, 0.0083, 0.0140, 0.4776],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:12,209][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.2210, 0.1068, 0.1091, 0.1969, 0.1457, 0.1266, 0.0939],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:12,211][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.3931, 0.0458, 0.1484, 0.1045, 0.1179, 0.0798, 0.1106],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:12,212][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.4655, 0.2050, 0.1031, 0.0302, 0.0222, 0.1133, 0.0608],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:12,213][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ to] are: tensor([6.0280e-05, 1.3703e-01, 3.1451e-01, 4.8859e-01, 1.8388e-02, 1.9841e-02,
        2.1578e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:12,215][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0007, 0.2518, 0.1386, 0.1453, 0.1147, 0.1810, 0.1679],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:12,216][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ to] are: tensor([1.0545e-05, 2.2697e-04, 9.5568e-08, 5.5616e-03, 4.5654e-09, 1.2944e-08,
        9.9420e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:12,217][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ the] are: tensor([9.7479e-05, 4.7717e-02, 2.4052e-02, 1.2182e-01, 5.1863e-02, 6.6446e-02,
        2.6520e-01, 4.2280e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:12,218][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ the] are: tensor([8.9566e-01, 1.7371e-02, 2.9802e-02, 2.4152e-02, 1.1932e-02, 1.7750e-02,
        2.4546e-03, 8.8245e-04], device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:12,220][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.2452, 0.0067, 0.0194, 0.1241, 0.0560, 0.1021, 0.2299, 0.2167],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:12,222][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.1823, 0.1012, 0.0951, 0.1278, 0.1084, 0.0921, 0.1376, 0.1556],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:12,223][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.4263, 0.0402, 0.0682, 0.0554, 0.0976, 0.0972, 0.1042, 0.1108],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:12,225][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.3945, 0.2053, 0.0379, 0.1274, 0.0193, 0.0310, 0.1051, 0.0794],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:12,227][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.1446, 0.0649, 0.1384, 0.1714, 0.2457, 0.0512, 0.1106, 0.0733],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:12,228][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.3585, 0.0297, 0.1475, 0.0761, 0.0841, 0.0858, 0.0777, 0.1405],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:12,230][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.2846, 0.1572, 0.0703, 0.0223, 0.0146, 0.0768, 0.0452, 0.3289],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:12,231][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ the] are: tensor([4.5359e-05, 8.9637e-02, 3.8026e-01, 3.8731e-01, 1.9454e-02, 1.8021e-02,
        1.3848e-02, 9.1428e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:12,233][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0008, 0.1938, 0.1235, 0.1281, 0.1075, 0.1592, 0.1480, 0.1393],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:12,234][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ the] are: tensor([5.9991e-03, 1.9531e-02, 3.2629e-06, 1.3981e-01, 7.3113e-06, 1.3090e-06,
        1.6136e-03, 8.3303e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:12,235][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ office] are: tensor([7.6769e-06, 2.6270e-02, 7.0489e-03, 9.8356e-02, 1.7921e-02, 3.9628e-02,
        2.4678e-01, 4.4924e-01, 1.1475e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:12,237][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ office] are: tensor([9.2012e-01, 4.1831e-03, 3.2843e-02, 1.0766e-02, 1.6868e-02, 9.5000e-03,
        4.0040e-04, 5.2424e-03, 7.8790e-05], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:12,238][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ office] are: tensor([0.2225, 0.0073, 0.0193, 0.1536, 0.0560, 0.0878, 0.2328, 0.1813, 0.0394],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:12,240][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ office] are: tensor([0.1788, 0.0976, 0.0854, 0.1207, 0.0964, 0.0826, 0.1251, 0.1407, 0.0728],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:12,242][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ office] are: tensor([0.4657, 0.0370, 0.0520, 0.0537, 0.0723, 0.0791, 0.0924, 0.0836, 0.0641],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:12,243][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ office] are: tensor([0.3010, 0.1455, 0.0353, 0.0794, 0.0341, 0.0722, 0.0869, 0.1334, 0.1122],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:12,245][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ office] are: tensor([0.1035, 0.0550, 0.0673, 0.0872, 0.0241, 0.0237, 0.0764, 0.0395, 0.5234],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:12,247][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ office] are: tensor([0.2824, 0.0297, 0.0821, 0.0787, 0.0955, 0.1300, 0.0605, 0.0888, 0.1523],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:12,248][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ office] are: tensor([0.3525, 0.1374, 0.0604, 0.0204, 0.0127, 0.0701, 0.0317, 0.2867, 0.0282],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:12,250][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ office] are: tensor([0.0004, 0.0875, 0.2199, 0.2730, 0.0141, 0.0345, 0.0360, 0.2433, 0.0914],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:12,252][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ office] are: tensor([0.0007, 0.1835, 0.1142, 0.1184, 0.0922, 0.1330, 0.1271, 0.1105, 0.1203],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:12,253][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ office] are: tensor([1.0171e-02, 1.7687e-02, 4.2644e-05, 1.6680e-01, 7.2701e-08, 5.4776e-06,
        9.6939e-04, 2.4505e-06, 8.0433e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:12,254][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [.] are: tensor([6.5509e-05, 2.9477e-02, 1.3616e-02, 7.3887e-02, 2.7910e-02, 3.8184e-02,
        1.5396e-01, 2.5641e-01, 1.0637e-01, 3.0012e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:12,254][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [.] are: tensor([9.6939e-01, 1.3001e-03, 1.5406e-02, 1.4549e-03, 8.0811e-03, 3.2207e-03,
        8.5980e-05, 7.1916e-04, 2.3857e-04, 1.0661e-04], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:12,255][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.1893, 0.0044, 0.0179, 0.0785, 0.0459, 0.0742, 0.1451, 0.1336, 0.0393,
        0.2718], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:12,257][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.1577, 0.0868, 0.0790, 0.1073, 0.0898, 0.0764, 0.1146, 0.1304, 0.0686,
        0.0894], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:12,258][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.3445, 0.0307, 0.0631, 0.0377, 0.0884, 0.0827, 0.0710, 0.0692, 0.0929,
        0.1196], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:12,260][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.3605, 0.1335, 0.0295, 0.1305, 0.0163, 0.0453, 0.0555, 0.0800, 0.0218,
        0.1271], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:12,262][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0712, 0.0124, 0.1897, 0.0451, 0.1462, 0.0290, 0.0345, 0.0152, 0.4034,
        0.0534], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:12,264][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.2717, 0.0208, 0.1101, 0.0656, 0.0834, 0.0785, 0.0680, 0.0780, 0.1527,
        0.0712], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:12,265][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.2711, 0.1373, 0.0631, 0.0195, 0.0174, 0.0730, 0.0442, 0.2813, 0.0374,
        0.0558], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:12,266][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [.] are: tensor([1.7198e-05, 8.5004e-02, 2.1436e-01, 2.8961e-01, 1.3646e-02, 1.3244e-02,
        1.0585e-02, 6.0037e-02, 2.8655e-01, 2.6937e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:12,268][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.0011, 0.1436, 0.0932, 0.0975, 0.0817, 0.1199, 0.1119, 0.0933, 0.1077,
        0.1501], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:12,269][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [.] are: tensor([4.9821e-02, 6.1379e-02, 2.0749e-03, 5.0705e-01, 1.7727e-04, 1.6008e-04,
        1.2466e-01, 1.0479e-02, 6.3686e-04, 2.4356e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:12,270][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Erica] are: tensor([4.0414e-06, 1.4973e-02, 2.4219e-03, 5.8210e-02, 8.5532e-03, 2.2716e-02,
        1.5176e-01, 3.2032e-01, 5.1942e-02, 3.6612e-01, 2.9763e-03],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:12,272][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Erica] are: tensor([0.7739, 0.0408, 0.0214, 0.0721, 0.0259, 0.0233, 0.0040, 0.0182, 0.0026,
        0.0111, 0.0068], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:12,274][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Erica] are: tensor([0.1506, 0.0090, 0.0135, 0.1106, 0.0393, 0.0665, 0.1606, 0.1208, 0.0279,
        0.2620, 0.0393], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:12,276][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Erica] are: tensor([0.1499, 0.0864, 0.0725, 0.1054, 0.0817, 0.0720, 0.1080, 0.1222, 0.0639,
        0.0854, 0.0525], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:12,277][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Erica] are: tensor([0.3324, 0.0442, 0.0514, 0.0469, 0.0758, 0.0686, 0.0733, 0.0682, 0.0490,
        0.1150, 0.0751], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:12,279][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Erica] are: tensor([0.1194, 0.1008, 0.0569, 0.0740, 0.2162, 0.0142, 0.0553, 0.0936, 0.0117,
        0.1900, 0.0679], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:12,281][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Erica] are: tensor([0.0904, 0.0623, 0.2019, 0.0370, 0.0807, 0.0393, 0.0713, 0.0499, 0.0542,
        0.2268, 0.0861], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:12,283][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Erica] are: tensor([0.1357, 0.0563, 0.0288, 0.0581, 0.0757, 0.0962, 0.0661, 0.1649, 0.1486,
        0.1512, 0.0183], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:12,284][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Erica] are: tensor([0.3262, 0.1254, 0.0471, 0.0187, 0.0094, 0.0570, 0.0268, 0.2879, 0.0235,
        0.0407, 0.0373], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:12,285][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Erica] are: tensor([5.3302e-05, 8.3282e-02, 1.2029e-01, 9.5039e-02, 2.9110e-02, 2.2142e-02,
        6.2182e-02, 3.4820e-01, 8.8478e-02, 1.0941e-01, 4.1812e-02],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:12,287][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Erica] are: tensor([0.0008, 0.1236, 0.0828, 0.0909, 0.0804, 0.1139, 0.1056, 0.0956, 0.1002,
        0.1358, 0.0704], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:12,288][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Erica] are: tensor([1.2723e-04, 1.6459e-03, 4.2413e-01, 6.9113e-03, 7.5158e-06, 1.6294e-07,
        1.2111e-02, 1.6841e-07, 1.2176e-06, 3.0322e-01, 2.5185e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:12,290][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([6.6200e-06, 1.8668e-02, 6.4543e-03, 6.1673e-02, 1.8329e-02, 2.8532e-02,
        1.4695e-01, 2.7775e-01, 7.6709e-02, 3.1145e-01, 9.2314e-03, 4.4248e-02],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:12,291][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.3800, 0.0183, 0.2360, 0.0312, 0.1961, 0.0065, 0.0019, 0.0356, 0.0114,
        0.0062, 0.0725, 0.0044], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:12,293][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.1526, 0.0076, 0.0177, 0.0831, 0.0379, 0.0658, 0.1386, 0.0974, 0.0322,
        0.2102, 0.0599, 0.0969], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:12,295][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.1399, 0.0785, 0.0692, 0.0978, 0.0785, 0.0679, 0.1027, 0.1164, 0.0605,
        0.0805, 0.0512, 0.0568], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:12,296][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.2944, 0.0285, 0.0445, 0.0399, 0.0521, 0.0607, 0.0732, 0.0605, 0.0454,
        0.1193, 0.0894, 0.0921], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:12,298][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.3084, 0.0962, 0.0294, 0.0630, 0.0058, 0.1180, 0.0609, 0.0863, 0.0394,
        0.0988, 0.0151, 0.0788], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:12,300][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0998, 0.0322, 0.0517, 0.0608, 0.0588, 0.0723, 0.0588, 0.0455, 0.2849,
        0.0886, 0.0632, 0.0832], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:12,302][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.1974, 0.0466, 0.0721, 0.0606, 0.0432, 0.0389, 0.0682, 0.0801, 0.2054,
        0.1108, 0.0402, 0.0365], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:12,303][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.2948, 0.1264, 0.0517, 0.0179, 0.0105, 0.0613, 0.0295, 0.2637, 0.0259,
        0.0401, 0.0427, 0.0355], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:12,304][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([1.1160e-04, 8.7712e-02, 1.8164e-01, 2.9881e-01, 1.5216e-02, 1.1750e-02,
        3.1841e-02, 1.2619e-01, 1.4917e-01, 5.4692e-02, 2.5966e-02, 1.6897e-02],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:12,304][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0005, 0.1179, 0.0779, 0.0865, 0.0703, 0.1084, 0.0981, 0.0788, 0.0878,
        0.1254, 0.0617, 0.0868], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:12,305][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([7.5706e-04, 9.2454e-03, 3.0196e-06, 4.6191e-02, 2.8217e-06, 6.8892e-06,
        1.7508e-02, 6.3934e-08, 1.2639e-07, 3.0032e-01, 1.8735e-06, 6.2596e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:12,307][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ a] are: tensor([4.9050e-05, 2.6145e-02, 1.3244e-02, 5.8758e-02, 2.5907e-02, 3.1601e-02,
        1.1546e-01, 1.8374e-01, 9.1196e-02, 2.1772e-01, 1.7681e-02, 4.2429e-02,
        1.7607e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:12,308][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.6594, 0.0352, 0.0512, 0.0189, 0.0761, 0.0169, 0.0062, 0.0448, 0.0035,
        0.0112, 0.0199, 0.0562, 0.0008], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:12,310][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.1345, 0.0069, 0.0159, 0.0580, 0.0362, 0.0538, 0.1070, 0.0929, 0.0335,
        0.1606, 0.0565, 0.0896, 0.1546], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:12,312][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.1238, 0.0711, 0.0660, 0.0894, 0.0753, 0.0642, 0.0965, 0.1100, 0.0579,
        0.0757, 0.0501, 0.0544, 0.0657], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:12,314][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.2375, 0.0266, 0.0402, 0.0341, 0.0508, 0.0533, 0.0651, 0.0677, 0.0567,
        0.0965, 0.0839, 0.0918, 0.0957], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:12,315][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.3021, 0.1393, 0.0263, 0.1026, 0.0134, 0.0352, 0.0739, 0.0750, 0.0272,
        0.0900, 0.0133, 0.0418, 0.0599], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:12,317][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0900, 0.0543, 0.0934, 0.0734, 0.0767, 0.0395, 0.0651, 0.0481, 0.2438,
        0.0653, 0.0494, 0.0611, 0.0399], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:12,319][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.2164, 0.0335, 0.0880, 0.0498, 0.0520, 0.0400, 0.0593, 0.0808, 0.1114,
        0.0781, 0.0461, 0.0599, 0.0847], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:12,320][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.2274, 0.1199, 0.0472, 0.0158, 0.0102, 0.0526, 0.0320, 0.2481, 0.0243,
        0.0416, 0.0419, 0.0311, 0.1079], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:12,322][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ a] are: tensor([2.8396e-05, 3.5405e-02, 2.8078e-01, 1.6787e-01, 1.0240e-02, 1.7567e-02,
        7.2997e-03, 6.2778e-02, 3.2869e-01, 1.3396e-02, 2.6210e-02, 3.8558e-02,
        1.1174e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:12,323][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0008, 0.0993, 0.0695, 0.0758, 0.0628, 0.0936, 0.0916, 0.0793, 0.0844,
        0.1148, 0.0578, 0.0865, 0.0838], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:12,325][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ a] are: tensor([1.7444e-05, 2.9254e-04, 9.6742e-07, 1.9571e-03, 3.6549e-08, 2.4333e-07,
        9.4421e-04, 1.5611e-05, 3.5769e-09, 9.9414e-03, 6.3126e-07, 2.8849e-07,
        9.8683e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:12,326][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ basketball] are: tensor([1.9947e-06, 1.0900e-02, 2.5991e-03, 4.2715e-02, 7.6306e-03, 1.6015e-02,
        1.0726e-01, 2.0802e-01, 4.4214e-02, 2.4941e-01, 3.5083e-03, 2.4525e-02,
        2.1858e-01, 6.4622e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:12,327][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ basketball] are: tensor([8.1733e-01, 2.3967e-02, 5.6978e-02, 3.2725e-02, 1.1751e-02, 1.1576e-02,
        9.9454e-04, 6.7369e-03, 3.4282e-04, 5.1418e-03, 1.1097e-02, 7.6622e-03,
        1.3537e-02, 1.6426e-04], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:12,329][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ basketball] are: tensor([0.1217, 0.0102, 0.0181, 0.0697, 0.0354, 0.0548, 0.1036, 0.0790, 0.0348,
        0.1539, 0.0519, 0.0861, 0.1164, 0.0643], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:12,331][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ basketball] are: tensor([0.1277, 0.0732, 0.0619, 0.0895, 0.0695, 0.0607, 0.0919, 0.1039, 0.0542,
        0.0724, 0.0446, 0.0508, 0.0608, 0.0392], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:12,333][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ basketball] are: tensor([0.1768, 0.0276, 0.0420, 0.0377, 0.0517, 0.0472, 0.0641, 0.0553, 0.0510,
        0.1003, 0.0801, 0.0798, 0.0784, 0.1081], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:12,335][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ basketball] are: tensor([0.1293, 0.0744, 0.0399, 0.0415, 0.0133, 0.0636, 0.0307, 0.0916, 0.0320,
        0.0690, 0.0161, 0.0256, 0.0904, 0.2825], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:12,336][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ basketball] are: tensor([0.1372, 0.0803, 0.0090, 0.0398, 0.0136, 0.0215, 0.0585, 0.0534, 0.0736,
        0.0591, 0.0031, 0.0679, 0.0500, 0.3329], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:12,338][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ basketball] are: tensor([0.1688, 0.0369, 0.2184, 0.0511, 0.0513, 0.0199, 0.0643, 0.0704, 0.0963,
        0.0378, 0.0741, 0.0242, 0.0778, 0.0089], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:12,340][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ basketball] are: tensor([0.3081, 0.0983, 0.0381, 0.0160, 0.0068, 0.0451, 0.0200, 0.2353, 0.0181,
        0.0320, 0.0292, 0.0264, 0.1061, 0.0205], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:12,342][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ basketball] are: tensor([0.0005, 0.0568, 0.1116, 0.1769, 0.0169, 0.0159, 0.0537, 0.2038, 0.0750,
        0.1198, 0.0406, 0.0215, 0.0702, 0.0369], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:12,343][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ basketball] are: tensor([0.0007, 0.1004, 0.0631, 0.0783, 0.0512, 0.0835, 0.0858, 0.0678, 0.0755,
        0.1072, 0.0508, 0.0812, 0.0697, 0.0846], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:12,345][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ basketball] are: tensor([1.1620e-03, 9.7136e-03, 1.4221e-06, 4.1764e-02, 1.6972e-06, 7.5746e-06,
        3.1388e-04, 8.8766e-06, 9.2385e-07, 3.2047e-01, 7.5202e-07, 6.2929e-08,
        1.6759e-05, 6.2654e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:12,346][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ to] are: tensor([2.0728e-05, 1.6870e-02, 6.9610e-03, 4.4531e-02, 1.4573e-02, 2.1183e-02,
        8.7525e-02, 1.5294e-01, 5.8531e-02, 1.8152e-01, 9.1762e-03, 2.9215e-02,
        1.5527e-01, 6.9255e-02, 1.5243e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:12,347][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ to] are: tensor([8.9606e-01, 3.3457e-03, 2.9596e-02, 1.3191e-02, 2.4423e-02, 4.0277e-03,
        8.8187e-05, 5.6370e-03, 9.2249e-04, 2.3922e-04, 6.4508e-03, 8.7895e-03,
        5.5318e-03, 1.6600e-03, 3.3198e-05], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:12,349][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1070, 0.0058, 0.0153, 0.0399, 0.0318, 0.0459, 0.0818, 0.0664, 0.0244,
        0.1130, 0.0501, 0.0814, 0.1041, 0.0602, 0.1729], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:12,351][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.1115, 0.0634, 0.0584, 0.0793, 0.0665, 0.0572, 0.0863, 0.0985, 0.0518,
        0.0679, 0.0446, 0.0488, 0.0586, 0.0390, 0.0681], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:12,353][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.1806, 0.0203, 0.0359, 0.0251, 0.0446, 0.0425, 0.0546, 0.0484, 0.0389,
        0.0762, 0.0708, 0.0844, 0.0762, 0.0873, 0.1142], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:12,354][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.1253, 0.0245, 0.0137, 0.0440, 0.0041, 0.0120, 0.2435, 0.0451, 0.0068,
        0.0413, 0.0080, 0.0097, 0.0508, 0.0159, 0.3552], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:12,355][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0743, 0.0325, 0.0331, 0.0686, 0.0374, 0.0575, 0.0343, 0.0394, 0.1839,
        0.0586, 0.0334, 0.1664, 0.0701, 0.0675, 0.0430], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:12,356][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.1704, 0.0293, 0.0524, 0.0449, 0.0374, 0.0383, 0.0473, 0.0595, 0.0717,
        0.0657, 0.0222, 0.0552, 0.0721, 0.1760, 0.0576], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:12,357][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.2101, 0.1075, 0.0486, 0.0146, 0.0110, 0.0547, 0.0316, 0.2266, 0.0247,
        0.0341, 0.0429, 0.0305, 0.0955, 0.0368, 0.0308], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:12,358][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ to] are: tensor([1.7028e-05, 3.4213e-02, 2.3298e-01, 1.4097e-01, 8.1608e-03, 1.5461e-02,
        5.2295e-03, 5.7482e-02, 2.7805e-01, 1.0325e-02, 1.7102e-02, 3.6794e-02,
        9.0572e-03, 1.5120e-01, 2.9625e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:12,359][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0012, 0.0777, 0.0581, 0.0627, 0.0528, 0.0831, 0.0777, 0.0637, 0.0684,
        0.0947, 0.0470, 0.0747, 0.0653, 0.0851, 0.0878], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:12,361][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ to] are: tensor([3.6069e-06, 9.9078e-05, 4.0039e-08, 2.3680e-03, 2.0041e-09, 4.5537e-09,
        4.5992e-01, 1.5276e-08, 1.0115e-10, 3.3997e-03, 2.9251e-08, 2.8516e-09,
        2.0725e-07, 8.2007e-10, 5.3421e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:12,390][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:24:12,391][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:12,392][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:12,394][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:12,395][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:12,396][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:12,397][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:12,399][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:12,400][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:12,401][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:12,402][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:12,403][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:12,403][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:12,404][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.2480, 0.7520], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:12,406][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.6593, 0.3407], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:12,407][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.9987, 0.0013], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:12,409][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.5366, 0.4634], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:12,411][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.9119, 0.0881], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:12,412][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0154, 0.9846], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:12,414][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.3110, 0.6890], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:12,415][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.9939, 0.0061], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:12,417][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.7598, 0.2402], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:12,418][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0044, 0.9956], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:12,420][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.2802, 0.7198], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:12,422][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.1272, 0.8728], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:12,423][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Erica] are: tensor([0.0366, 0.3656, 0.5978], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:12,425][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Erica] are: tensor([0.8308, 0.1665, 0.0026], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:12,426][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Erica] are: tensor([0.8558, 0.0526, 0.0916], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:12,428][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Erica] are: tensor([0.4607, 0.2812, 0.2581], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:12,430][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Erica] are: tensor([0.7743, 0.1180, 0.1077], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:12,431][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Erica] are: tensor([9.3659e-02, 9.0634e-01, 4.0085e-07], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:12,432][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Erica] are: tensor([0.2783, 0.3495, 0.3722], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:12,434][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Erica] are: tensor([0.5422, 0.2701, 0.1877], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:12,435][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Erica] are: tensor([0.7465, 0.1640, 0.0896], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:12,437][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Erica] are: tensor([0.0113, 0.9849, 0.0038], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:12,439][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Erica] are: tensor([0.1613, 0.3640, 0.4747], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:12,440][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Erica] are: tensor([4.8092e-04, 5.2714e-03, 9.9425e-01], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:12,441][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0321, 0.2224, 0.5088, 0.2367], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:12,443][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.8325, 0.1580, 0.0027, 0.0067], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:12,445][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.5018, 0.0267, 0.0822, 0.3893], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:12,446][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.3145, 0.1744, 0.2822, 0.2289], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:12,448][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.6989, 0.0725, 0.1203, 0.1082], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:12,449][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([9.2034e-03, 9.9078e-01, 2.4185e-07, 1.7530e-05], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:12,451][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0580, 0.1392, 0.4840, 0.3188], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:12,452][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2828, 0.0279, 0.3650, 0.3242], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:12,453][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.6622, 0.2049, 0.1032, 0.0297], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:12,453][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([1.5905e-03, 9.9251e-01, 5.9460e-04, 5.3021e-03], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:12,454][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.1162, 0.2698, 0.3792, 0.2348], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:12,455][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([5.7312e-03, 5.6686e-03, 1.7871e-07, 9.8860e-01], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:12,456][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Joshua] are: tensor([0.0093, 0.1450, 0.5072, 0.1722, 0.1663], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:12,458][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Joshua] are: tensor([0.8377, 0.1508, 0.0023, 0.0066, 0.0026], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:12,459][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Joshua] are: tensor([0.3855, 0.0379, 0.0683, 0.3876, 0.1207], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:12,461][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Joshua] are: tensor([0.2831, 0.1659, 0.2012, 0.1888, 0.1610], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:12,462][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Joshua] are: tensor([0.5854, 0.1053, 0.0913, 0.1137, 0.1042], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:12,463][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Joshua] are: tensor([4.7282e-02, 9.5272e-01, 3.6324e-08, 1.0426e-06, 3.8485e-08],
       device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:12,465][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Joshua] are: tensor([0.1277, 0.1764, 0.2061, 0.2832, 0.2066], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:12,467][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Joshua] are: tensor([0.1396, 0.0375, 0.6194, 0.1907, 0.0128], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:12,468][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Joshua] are: tensor([0.7694, 0.1358, 0.0592, 0.0236, 0.0121], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:12,470][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Joshua] are: tensor([0.0029, 0.9173, 0.0048, 0.0194, 0.0556], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:12,472][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Joshua] are: tensor([0.0949, 0.2157, 0.2804, 0.1875, 0.2215], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:12,473][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Joshua] are: tensor([1.3656e-02, 1.1306e-02, 8.0886e-05, 5.3179e-02, 9.2178e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:12,474][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([0.0170, 0.1068, 0.1611, 0.1486, 0.1256, 0.4408], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:12,476][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([0.8426, 0.1452, 0.0021, 0.0058, 0.0023, 0.0019], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:12,478][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([0.3308, 0.0365, 0.0781, 0.2595, 0.1218, 0.1733], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:12,479][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([0.2028, 0.1312, 0.1671, 0.1446, 0.1579, 0.1964], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:12,481][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([0.5068, 0.0727, 0.1003, 0.0860, 0.1054, 0.1287], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:12,482][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([1.0631e-02, 9.8936e-01, 8.2875e-08, 3.1719e-06, 8.5798e-08, 1.2194e-06],
       device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:12,484][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([0.0467, 0.1069, 0.2338, 0.2316, 0.2114, 0.1696], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:12,485][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([0.1437, 0.0670, 0.4160, 0.1330, 0.2001, 0.0403], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:12,487][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([0.6716, 0.1478, 0.0678, 0.0232, 0.0188, 0.0708], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:12,488][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([1.6288e-03, 7.4840e-01, 3.6788e-04, 1.9290e-03, 2.9247e-02, 2.1843e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:12,490][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([0.0703, 0.1693, 0.2291, 0.1429, 0.1793, 0.2090], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:12,491][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([1.4357e-03, 2.2760e-02, 1.1366e-06, 2.9553e-02, 9.4617e-07, 9.4625e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:12,493][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0100, 0.0652, 0.1247, 0.0773, 0.0856, 0.5428, 0.0945],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:12,494][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.8730, 0.1160, 0.0016, 0.0045, 0.0019, 0.0016, 0.0014],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:12,496][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.2592, 0.0217, 0.0635, 0.1507, 0.0994, 0.1394, 0.2662],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:12,498][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.1793, 0.0887, 0.1558, 0.1109, 0.1398, 0.1828, 0.1426],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:12,499][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.4449, 0.0627, 0.0851, 0.0719, 0.1021, 0.1123, 0.1210],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:12,501][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([6.6433e-03, 9.9334e-01, 1.8592e-07, 4.8088e-06, 1.6062e-07, 1.3914e-06,
        1.2773e-05], device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:12,502][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0153, 0.0454, 0.1123, 0.0824, 0.0938, 0.0841, 0.5667],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:12,503][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.1186, 0.0469, 0.2741, 0.1924, 0.1366, 0.0508, 0.1805],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:12,504][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.6105, 0.1430, 0.0802, 0.0201, 0.0268, 0.0765, 0.0429],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:12,504][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([1.6715e-03, 8.8115e-01, 6.6184e-04, 3.4113e-03, 3.4230e-02, 7.5382e-02,
        3.4959e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:12,506][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0620, 0.1447, 0.2030, 0.1227, 0.1606, 0.1843, 0.1227],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:12,507][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([1.0225e-05, 2.2196e-04, 9.8375e-08, 5.5992e-03, 4.8270e-09, 1.3111e-08,
        9.9417e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:12,509][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0115, 0.0695, 0.1296, 0.0948, 0.0856, 0.2298, 0.1958, 0.1835],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:12,511][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.8642, 0.1230, 0.0017, 0.0047, 0.0020, 0.0017, 0.0015, 0.0012],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:12,512][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.2185, 0.0197, 0.0480, 0.1338, 0.0790, 0.1122, 0.1990, 0.1898],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:12,514][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.1745, 0.0816, 0.1281, 0.1039, 0.1175, 0.1469, 0.1052, 0.1424],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:12,516][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.4339, 0.0553, 0.0669, 0.0644, 0.0817, 0.0974, 0.0995, 0.1007],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:12,517][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([1.6134e-02, 9.8386e-01, 5.0123e-08, 1.6670e-06, 3.9072e-08, 3.7183e-07,
        1.7363e-06, 4.8929e-07], device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:12,518][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0097, 0.0350, 0.1078, 0.0680, 0.0842, 0.0611, 0.5700, 0.0642],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:12,520][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0672, 0.0173, 0.2588, 0.1045, 0.0715, 0.0636, 0.0922, 0.3249],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:12,522][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.4038, 0.1166, 0.0589, 0.0156, 0.0191, 0.0578, 0.0349, 0.2933],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:12,523][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([1.3079e-03, 7.4056e-01, 5.3415e-04, 2.8220e-03, 3.7161e-02, 1.6764e-01,
        1.8975e-03, 4.8082e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:12,525][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0566, 0.1283, 0.1822, 0.1110, 0.1440, 0.1629, 0.1077, 0.1073],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:12,526][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([5.8048e-03, 1.9230e-02, 3.4341e-06, 1.4223e-01, 7.8159e-06, 1.3709e-06,
        1.7073e-03, 8.3102e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:12,527][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ office] are: tensor([0.0028, 0.0497, 0.0789, 0.0730, 0.0543, 0.3404, 0.1594, 0.1919, 0.0495],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:12,529][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ office] are: tensor([0.7156, 0.2424, 0.0041, 0.0124, 0.0048, 0.0045, 0.0044, 0.0035, 0.0083],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:12,531][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ office] are: tensor([0.1503, 0.0231, 0.0465, 0.1663, 0.0806, 0.0976, 0.2253, 0.1597, 0.0507],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:12,532][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ office] are: tensor([0.1463, 0.0766, 0.1179, 0.1140, 0.1057, 0.1310, 0.1154, 0.1039, 0.0892],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:12,534][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ office] are: tensor([0.3967, 0.0576, 0.0560, 0.0664, 0.0710, 0.0872, 0.0939, 0.0860, 0.0854],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:12,535][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ office] are: tensor([1.1589e-02, 9.8759e-01, 5.0229e-06, 4.1673e-05, 5.6151e-06, 4.1658e-05,
        7.5613e-05, 3.5500e-05, 6.1928e-04], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:12,537][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ office] are: tensor([0.0100, 0.0256, 0.0426, 0.0648, 0.0466, 0.0440, 0.3187, 0.0549, 0.3928],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:12,539][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ office] are: tensor([0.0932, 0.0192, 0.1082, 0.1393, 0.1100, 0.1784, 0.0736, 0.1681, 0.1100],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:12,541][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ office] are: tensor([0.4595, 0.1051, 0.0501, 0.0164, 0.0170, 0.0554, 0.0256, 0.2497, 0.0213],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:12,542][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ office] are: tensor([0.0010, 0.7316, 0.0017, 0.0059, 0.0679, 0.1774, 0.0012, 0.0123, 0.0011],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:12,544][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ office] are: tensor([0.0512, 0.1167, 0.1534, 0.1000, 0.1215, 0.1388, 0.0949, 0.0932, 0.1302],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:12,545][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ office] are: tensor([9.7685e-03, 1.7321e-02, 4.2693e-05, 1.6916e-01, 7.3150e-08, 5.5575e-06,
        9.8656e-04, 2.4202e-06, 8.0271e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:12,547][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.0097, 0.0539, 0.1390, 0.0706, 0.0873, 0.1657, 0.1022, 0.1589, 0.0866,
        0.1261], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:12,548][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([8.8857e-01, 9.8582e-02, 1.3845e-03, 3.6858e-03, 1.5078e-03, 1.3017e-03,
        1.1329e-03, 9.3813e-04, 2.3591e-03, 5.3766e-04], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:12,550][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.1413, 0.0119, 0.0415, 0.0865, 0.0629, 0.0825, 0.1325, 0.1212, 0.0483,
        0.2715], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:12,552][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.1435, 0.0711, 0.1111, 0.0960, 0.0978, 0.1201, 0.1003, 0.0940, 0.1233,
        0.0428], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:12,553][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.3160, 0.0468, 0.0655, 0.0481, 0.0717, 0.0825, 0.0719, 0.0688, 0.1085,
        0.1202], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:12,553][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([5.4836e-02, 9.4515e-01, 3.5853e-08, 8.5941e-07, 4.5652e-08, 3.1928e-07,
        1.1496e-06, 2.3534e-07, 1.2686e-05, 2.8725e-08], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:12,554][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.0062, 0.0187, 0.0559, 0.0375, 0.0447, 0.0344, 0.2828, 0.0447, 0.3431,
        0.1319], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:12,555][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0569, 0.0109, 0.2076, 0.1048, 0.1127, 0.0749, 0.0864, 0.1447, 0.1071,
        0.0939], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:12,557][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.3800, 0.1070, 0.0527, 0.0144, 0.0217, 0.0557, 0.0364, 0.2773, 0.0273,
        0.0275], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:12,558][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([2.0022e-03, 8.0313e-01, 2.0717e-03, 8.1589e-03, 8.2404e-02, 7.0721e-02,
        1.9085e-03, 1.5403e-02, 6.5990e-04, 1.3543e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:12,560][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.0445, 0.1035, 0.1448, 0.0888, 0.1149, 0.1322, 0.0866, 0.0831, 0.1240,
        0.0777], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:12,561][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([4.8730e-02, 6.0490e-02, 2.1727e-03, 5.0795e-01, 1.8761e-04, 1.6650e-04,
        1.2722e-01, 1.0647e-02, 6.5749e-04, 2.4178e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:12,562][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Erica] are: tensor([0.0043, 0.0461, 0.0804, 0.0541, 0.0793, 0.1832, 0.0928, 0.2075, 0.0510,
        0.1388, 0.0625], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:12,564][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Erica] are: tensor([0.8014, 0.1650, 0.0028, 0.0088, 0.0033, 0.0034, 0.0032, 0.0028, 0.0061,
        0.0019, 0.0013], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:12,566][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Erica] are: tensor([0.0935, 0.0191, 0.0244, 0.1175, 0.0473, 0.0659, 0.1526, 0.1194, 0.0296,
        0.2878, 0.0428], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:12,567][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Erica] are: tensor([0.1507, 0.0726, 0.0804, 0.0961, 0.0867, 0.1159, 0.0932, 0.0944, 0.0811,
        0.0456, 0.0833], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:12,569][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Erica] are: tensor([0.3036, 0.0643, 0.0486, 0.0546, 0.0642, 0.0683, 0.0688, 0.0661, 0.0640,
        0.1237, 0.0736], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:12,570][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Erica] are: tensor([1.7203e-02, 9.8265e-01, 7.2072e-07, 9.9890e-06, 1.4030e-06, 3.0116e-06,
        2.3610e-05, 3.0343e-06, 1.0398e-04, 5.1267e-07, 7.3447e-07],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:12,572][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Erica] are: tensor([0.0171, 0.0275, 0.0363, 0.0454, 0.0384, 0.0315, 0.2862, 0.0473, 0.2617,
        0.1484, 0.0601], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:12,574][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Erica] are: tensor([0.0184, 0.0521, 0.0124, 0.0444, 0.0529, 0.0683, 0.0551, 0.3599, 0.0556,
        0.2780, 0.0030], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:12,575][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Erica] are: tensor([0.4355, 0.0996, 0.0406, 0.0153, 0.0132, 0.0480, 0.0228, 0.2601, 0.0189,
        0.0220, 0.0239], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:12,577][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Erica] are: tensor([0.0030, 0.5396, 0.0028, 0.0140, 0.0607, 0.3287, 0.0022, 0.0163, 0.0034,
        0.0275, 0.0018], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:12,579][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Erica] are: tensor([0.0427, 0.0931, 0.1233, 0.0809, 0.0982, 0.1141, 0.0768, 0.0746, 0.1060,
        0.0693, 0.1211], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:12,580][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Erica] are: tensor([1.2488e-04, 1.6561e-03, 4.2888e-01, 7.2248e-03, 7.6715e-06, 1.6890e-07,
        1.2487e-02, 1.6961e-07, 1.2233e-06, 2.9494e-01, 2.5468e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:12,582][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.0055, 0.0444, 0.0660, 0.0539, 0.0467, 0.2263, 0.0998, 0.1307, 0.0466,
        0.1284, 0.0498, 0.1019], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:12,583][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([8.6254e-01, 1.2052e-01, 1.5909e-03, 4.6746e-03, 1.7087e-03, 1.5474e-03,
        1.4692e-03, 1.2201e-03, 2.8212e-03, 7.2779e-04, 6.4904e-04, 5.3576e-04],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:12,585][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.1069, 0.0183, 0.0354, 0.0892, 0.0483, 0.0702, 0.1294, 0.0867, 0.0367,
        0.2150, 0.0679, 0.0961], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:12,586][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.1203, 0.0593, 0.0785, 0.0785, 0.0751, 0.1058, 0.0936, 0.0761, 0.0744,
        0.0373, 0.0885, 0.1126], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:12,588][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.2494, 0.0475, 0.0482, 0.0490, 0.0513, 0.0668, 0.0659, 0.0570, 0.0612,
        0.1165, 0.0781, 0.1092], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:12,590][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([1.5932e-02, 9.8403e-01, 7.8110e-08, 2.7929e-06, 9.3263e-08, 1.2420e-06,
        4.4247e-06, 1.1738e-06, 2.6256e-05, 1.8094e-07, 2.7010e-07, 3.2001e-07],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:12,591][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.0043, 0.0116, 0.0428, 0.0289, 0.0321, 0.0261, 0.2416, 0.0322, 0.3105,
        0.1022, 0.0731, 0.0945], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:12,593][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0370, 0.0388, 0.0941, 0.0746, 0.0364, 0.0144, 0.0860, 0.1505, 0.2245,
        0.2046, 0.0319, 0.0071], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:12,595][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.4137, 0.1005, 0.0453, 0.0142, 0.0153, 0.0506, 0.0241, 0.2358, 0.0205,
        0.0214, 0.0268, 0.0317], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:12,596][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([9.1949e-04, 8.0882e-01, 5.5301e-04, 3.8532e-03, 3.3133e-02, 6.2230e-02,
        3.4320e-03, 5.1212e-02, 6.3708e-04, 1.7403e-02, 4.0888e-04, 1.7393e-02],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:12,598][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0343, 0.0824, 0.1135, 0.0701, 0.0897, 0.1061, 0.0691, 0.0655, 0.0967,
        0.0616, 0.1118, 0.0993], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:12,599][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([7.3729e-04, 9.2596e-03, 3.1545e-06, 4.7800e-02, 3.0119e-06, 7.0344e-06,
        1.8075e-02, 6.6037e-08, 1.3123e-07, 2.9850e-01, 1.9820e-06, 6.2561e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:12,601][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0046, 0.0347, 0.0655, 0.0481, 0.0573, 0.1447, 0.0855, 0.1292, 0.0419,
        0.1058, 0.0551, 0.1083, 0.1194], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:12,602][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([8.8774e-01, 9.8348e-02, 1.2971e-03, 3.6302e-03, 1.4706e-03, 1.3119e-03,
        1.1458e-03, 9.3815e-04, 2.2791e-03, 5.6443e-04, 5.0599e-04, 4.5759e-04,
        3.1025e-04], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:12,603][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.1077, 0.0157, 0.0323, 0.0638, 0.0473, 0.0578, 0.0990, 0.0890, 0.0384,
        0.1587, 0.0610, 0.0894, 0.1400], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:12,604][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.1089, 0.0515, 0.0760, 0.0636, 0.0727, 0.0876, 0.0705, 0.0849, 0.0778,
        0.0344, 0.0849, 0.0977, 0.0894], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:12,605][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.2369, 0.0382, 0.0372, 0.0395, 0.0421, 0.0511, 0.0575, 0.0571, 0.0660,
        0.1027, 0.0730, 0.1035, 0.0952], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:12,606][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([1.7538e-02, 9.8244e-01, 5.9462e-08, 2.0065e-06, 6.5143e-08, 8.1509e-07,
        2.4692e-06, 6.6744e-07, 1.1433e-05, 1.1464e-07, 1.6032e-07, 2.6857e-07,
        1.4630e-07], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:12,608][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0030, 0.0107, 0.0502, 0.0235, 0.0317, 0.0217, 0.2412, 0.0229, 0.3234,
        0.0863, 0.0844, 0.0787, 0.0223], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:12,609][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0469, 0.0410, 0.1597, 0.0744, 0.0532, 0.0238, 0.0822, 0.1522, 0.0707,
        0.1332, 0.0300, 0.0249, 0.1078], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:12,611][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.3442, 0.0929, 0.0416, 0.0114, 0.0149, 0.0440, 0.0259, 0.2410, 0.0193,
        0.0192, 0.0261, 0.0282, 0.0912], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:12,612][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([7.7651e-04, 8.3186e-01, 3.7551e-04, 2.1009e-03, 3.2738e-02, 6.6942e-02,
        2.3961e-03, 2.6800e-02, 2.5248e-04, 1.3366e-02, 2.8867e-04, 2.0131e-02,
        1.9684e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:12,614][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0331, 0.0757, 0.1062, 0.0657, 0.0837, 0.0967, 0.0634, 0.0621, 0.0918,
        0.0572, 0.1051, 0.0942, 0.0652], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:12,615][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([1.6967e-05, 2.8996e-04, 1.0059e-06, 2.0410e-03, 3.9172e-08, 2.5056e-07,
        9.8637e-04, 1.5840e-05, 3.7430e-09, 9.8950e-03, 6.7054e-07, 2.9760e-07,
        9.8675e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:12,617][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ basketball] are: tensor([0.0016, 0.0277, 0.0595, 0.0347, 0.0322, 0.1456, 0.0672, 0.1214, 0.0445,
        0.0909, 0.0420, 0.0863, 0.1797, 0.0667], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:12,618][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ basketball] are: tensor([8.1878e-01, 1.4794e-01, 2.6856e-03, 8.2622e-03, 2.9836e-03, 2.9506e-03,
        2.8220e-03, 2.3965e-03, 5.5123e-03, 1.6628e-03, 1.3964e-03, 1.2369e-03,
        9.7441e-04, 4.0272e-04], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:12,620][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ basketball] are: tensor([0.1094, 0.0171, 0.0316, 0.0732, 0.0420, 0.0562, 0.0945, 0.0740, 0.0366,
        0.1520, 0.0537, 0.0859, 0.1042, 0.0697], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:12,622][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ basketball] are: tensor([0.1050, 0.0505, 0.0715, 0.0699, 0.0663, 0.0826, 0.0775, 0.0620, 0.0648,
        0.0357, 0.0796, 0.0962, 0.0693, 0.0692], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:12,624][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ basketball] are: tensor([0.1925, 0.0470, 0.0390, 0.0430, 0.0425, 0.0504, 0.0541, 0.0493, 0.0587,
        0.0874, 0.0620, 0.0901, 0.0772, 0.1069], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:12,625][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ basketball] are: tensor([2.2748e-02, 9.7680e-01, 2.7171e-06, 2.5023e-05, 3.7353e-06, 2.7206e-05,
        4.3134e-05, 1.4232e-05, 2.5267e-04, 2.6667e-06, 3.8252e-06, 7.2810e-06,
        2.4552e-06, 6.3957e-05], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:12,627][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ basketball] are: tensor([0.0101, 0.0188, 0.0233, 0.0424, 0.0266, 0.0254, 0.1953, 0.0362, 0.1960,
        0.1040, 0.0365, 0.0848, 0.0382, 0.1624], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:12,629][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ basketball] are: tensor([0.0137, 0.0188, 0.4970, 0.0465, 0.0330, 0.0038, 0.0823, 0.0805, 0.0373,
        0.0222, 0.0864, 0.0030, 0.0747, 0.0005], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:12,630][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ basketball] are: tensor([0.4180, 0.0784, 0.0324, 0.0138, 0.0095, 0.0390, 0.0172, 0.2175, 0.0149,
        0.0177, 0.0189, 0.0249, 0.0811, 0.0167], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:12,631][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ basketball] are: tensor([1.0131e-03, 5.5356e-01, 4.5966e-03, 1.5785e-02, 1.0646e-01, 1.7619e-01,
        1.3806e-03, 4.5993e-03, 2.7169e-03, 3.7872e-02, 2.9298e-03, 3.1729e-02,
        3.8951e-04, 6.0778e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:12,633][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ basketball] are: tensor([0.0296, 0.0720, 0.0949, 0.0620, 0.0753, 0.0882, 0.0594, 0.0569, 0.0822,
        0.0527, 0.0934, 0.0868, 0.0584, 0.0882], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:12,635][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ basketball] are: tensor([1.1428e-03, 9.8132e-03, 1.4684e-06, 4.4224e-02, 1.7735e-06, 7.9009e-06,
        3.3325e-04, 9.1401e-06, 9.5477e-07, 3.2256e-01, 7.7427e-07, 6.5897e-08,
        1.7434e-05, 6.2188e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:12,636][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0035, 0.0276, 0.0540, 0.0327, 0.0380, 0.2065, 0.0378, 0.0872, 0.0384,
        0.0845, 0.0419, 0.1390, 0.1277, 0.0479, 0.0332], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:12,638][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([8.7915e-01, 1.0423e-01, 1.4898e-03, 4.1986e-03, 1.6579e-03, 1.5204e-03,
        1.3161e-03, 1.1260e-03, 2.5720e-03, 6.7489e-04, 6.0406e-04, 5.4668e-04,
        3.9269e-04, 1.7574e-04, 3.4414e-04], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:12,639][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0849, 0.0143, 0.0336, 0.0449, 0.0427, 0.0517, 0.0774, 0.0636, 0.0285,
        0.1101, 0.0532, 0.0826, 0.0901, 0.0707, 0.1517], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:12,641][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0916, 0.0382, 0.0678, 0.0510, 0.0639, 0.0864, 0.0668, 0.0619, 0.0678,
        0.0276, 0.0779, 0.0934, 0.0670, 0.0687, 0.0699], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:12,643][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.1836, 0.0304, 0.0329, 0.0298, 0.0367, 0.0411, 0.0465, 0.0415, 0.0477,
        0.0764, 0.0596, 0.0889, 0.0747, 0.1039, 0.1063], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:12,644][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([7.5899e-03, 9.9228e-01, 3.6059e-07, 1.2753e-05, 5.1930e-07, 7.3139e-06,
        2.2675e-05, 6.8419e-06, 4.3556e-05, 1.2511e-06, 9.2437e-07, 1.9270e-06,
        1.5129e-06, 9.3067e-06, 2.0766e-05], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:12,646][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0046, 0.0142, 0.0309, 0.0247, 0.0256, 0.0239, 0.1427, 0.0221, 0.1993,
        0.0619, 0.0482, 0.0715, 0.0242, 0.1859, 0.1204], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:12,648][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0275, 0.0317, 0.0747, 0.0767, 0.0352, 0.0211, 0.0690, 0.1209, 0.0321,
        0.1116, 0.0100, 0.0220, 0.1190, 0.1963, 0.0521], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:12,650][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.3300, 0.0842, 0.0431, 0.0110, 0.0166, 0.0455, 0.0260, 0.2171, 0.0197,
        0.0178, 0.0267, 0.0280, 0.0807, 0.0284, 0.0252], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:12,651][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([9.8714e-04, 7.8789e-01, 1.1622e-03, 3.8023e-03, 3.9501e-02, 7.8857e-02,
        2.6968e-03, 2.0069e-02, 4.9404e-04, 1.2694e-02, 7.5602e-04, 2.8773e-02,
        1.7323e-03, 1.9082e-02, 1.5044e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:12,653][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0281, 0.0653, 0.0915, 0.0556, 0.0728, 0.0835, 0.0552, 0.0527, 0.0783,
        0.0489, 0.0905, 0.0810, 0.0552, 0.0865, 0.0550], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:12,654][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([3.5002e-06, 9.6990e-05, 4.1009e-08, 2.3863e-03, 2.1027e-09, 4.6407e-09,
        4.6061e-01, 1.5404e-08, 1.0494e-10, 3.2972e-03, 3.0751e-08, 2.9384e-09,
        2.1267e-07, 8.1264e-10, 5.3361e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:12,658][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:24:12,659][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[11340],
        [ 3953],
        [ 2759],
        [ 5902],
        [    1],
        [20720],
        [ 8321],
        [10464],
        [19308],
        [10074],
        [ 3991],
        [11023],
        [16839],
        [ 5847],
        [16378]], device='cuda:0')
[2024-07-24 10:24:12,660][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 9586],
        [ 7926],
        [ 1686],
        [17307],
        [    1],
        [31961],
        [23265],
        [25668],
        [19091],
        [15115],
        [ 7136],
        [23328],
        [22763],
        [ 7591],
        [28739]], device='cuda:0')
[2024-07-24 10:24:12,662][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[38715],
        [39094],
        [39358],
        [39338],
        [39642],
        [39886],
        [37636],
        [36374],
        [35873],
        [35611],
        [34843],
        [35639],
        [36487],
        [36092],
        [36282]], device='cuda:0')
[2024-07-24 10:24:12,664][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[4334],
        [4334],
        [4110],
        [3182],
        [4172],
        [3859],
        [3950],
        [4249],
        [4174],
        [4231],
        [4409],
        [5076],
        [4630],
        [4247],
        [4230]], device='cuda:0')
[2024-07-24 10:24:12,666][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 6981],
        [ 6985],
        [ 7513],
        [10182],
        [13589],
        [15844],
        [18908],
        [17594],
        [18027],
        [13937],
        [14303],
        [14513],
        [15892],
        [17214],
        [18641]], device='cuda:0')
[2024-07-24 10:24:12,667][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[ 825],
        [ 770],
        [ 909],
        [ 974],
        [1098],
        [1235],
        [1357],
        [1457],
        [1506],
        [1556],
        [1611],
        [1724],
        [1831],
        [1827],
        [1951]], device='cuda:0')
[2024-07-24 10:24:12,669][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[10830],
        [11329],
        [10376],
        [ 8662],
        [ 5720],
        [ 5116],
        [ 4675],
        [ 5944],
        [ 7019],
        [10207],
        [ 9686],
        [ 9008],
        [ 9815],
        [11877],
        [ 9440]], device='cuda:0')
[2024-07-24 10:24:12,671][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[39782],
        [41027],
        [40470],
        [39300],
        [39444],
        [35887],
        [39180],
        [39408],
        [37706],
        [38079],
        [39656],
        [33610],
        [36860],
        [33002],
        [34859]], device='cuda:0')
[2024-07-24 10:24:12,672][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[41861],
        [43171],
        [43619],
        [45573],
        [12825],
        [35222],
        [28990],
        [17875],
        [50129],
        [48968],
        [43269],
        [49542],
        [48902],
        [39548],
        [48329]], device='cuda:0')
[2024-07-24 10:24:12,674][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[37327],
        [37107],
        [26732],
        [33259],
        [18650],
        [ 9956],
        [13293],
        [16740],
        [20795],
        [22126],
        [25484],
        [30743],
        [26089],
        [16144],
        [20289]], device='cuda:0')
[2024-07-24 10:24:12,676][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[32077],
        [42072],
        [41199],
        [43137],
        [40449],
        [41894],
        [42874],
        [44409],
        [43731],
        [44467],
        [43866],
        [44133],
        [44801],
        [44147],
        [44890]], device='cuda:0')
[2024-07-24 10:24:12,677][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[47898],
        [13717],
        [11803],
        [ 7174],
        [ 8294],
        [ 7302],
        [ 7510],
        [ 7463],
        [ 7263],
        [ 7285],
        [ 7305],
        [ 7196],
        [ 8171],
        [ 7644],
        [10194]], device='cuda:0')
[2024-07-24 10:24:12,679][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[25918],
        [ 8442],
        [ 6121],
        [ 2811],
        [ 3252],
        [ 2748],
        [ 2461],
        [ 2037],
        [ 1894],
        [ 1901],
        [ 2076],
        [ 2385],
        [ 2037],
        [ 1861],
        [ 1910]], device='cuda:0')
[2024-07-24 10:24:12,681][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[35461],
        [ 8368],
        [41152],
        [10905],
        [47264],
        [30478],
        [18509],
        [26352],
        [23830],
        [10717],
        [27633],
        [16870],
        [28605],
        [28571],
        [18790]], device='cuda:0')
[2024-07-24 10:24:12,682][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[10528],
        [12681],
        [ 1104],
        [12893],
        [  996],
        [38314],
        [11428],
        [ 5758],
        [30825],
        [10128],
        [ 7320],
        [ 3086],
        [ 8605],
        [16747],
        [ 6064]], device='cuda:0')
[2024-07-24 10:24:12,684][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[14099],
        [10896],
        [ 7875],
        [ 8955],
        [ 8602],
        [12264],
        [12400],
        [12691],
        [13894],
        [13789],
        [14059],
        [14473],
        [12563],
        [11211],
        [11965]], device='cuda:0')
[2024-07-24 10:24:12,686][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[18936],
        [17613],
        [18569],
        [18577],
        [18607],
        [18631],
        [18726],
        [18721],
        [18164],
        [18825],
        [18595],
        [18760],
        [18840],
        [18691],
        [18834]], device='cuda:0')
[2024-07-24 10:24:12,687][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[18115],
        [18105],
        [14562],
        [13530],
        [11451],
        [ 9098],
        [ 9446],
        [10185],
        [10050],
        [10163],
        [10313],
        [10021],
        [10037],
        [ 9552],
        [ 9266]], device='cuda:0')
[2024-07-24 10:24:12,689][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[1246],
        [2489],
        [2016],
        [2218],
        [2385],
        [2146],
        [2350],
        [2295],
        [2111],
        [2193],
        [2315],
        [2188],
        [2287],
        [2515],
        [2575]], device='cuda:0')
[2024-07-24 10:24:12,690][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[ 9197],
        [10036],
        [10562],
        [12385],
        [13125],
        [12200],
        [12485],
        [12534],
        [11816],
        [10155],
        [10167],
        [10291],
        [10345],
        [10305],
        [10258]], device='cuda:0')
[2024-07-24 10:24:12,692][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[27013],
        [19676],
        [20396],
        [19607],
        [19969],
        [19621],
        [19584],
        [19685],
        [19595],
        [20029],
        [19690],
        [19679],
        [19703],
        [19739],
        [19592]], device='cuda:0')
[2024-07-24 10:24:12,694][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[36236],
        [37837],
        [35541],
        [33615],
        [34099],
        [31235],
        [28835],
        [28549],
        [24778],
        [23647],
        [23927],
        [22394],
        [22143],
        [22689],
        [20859]], device='cuda:0')
[2024-07-24 10:24:12,695][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[13344],
        [13338],
        [11454],
        [ 6757],
        [20355],
        [35203],
        [10081],
        [25465],
        [40520],
        [33509],
        [26523],
        [31925],
        [23969],
        [32339],
        [45854]], device='cuda:0')
[2024-07-24 10:24:12,697][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[34484],
        [32075],
        [32751],
        [32616],
        [33078],
        [33309],
        [33492],
        [34009],
        [33966],
        [34327],
        [34256],
        [34533],
        [34861],
        [34562],
        [34915]], device='cuda:0')
[2024-07-24 10:24:12,699][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[10982],
        [19953],
        [20047],
        [20013],
        [21730],
        [27046],
        [23012],
        [26954],
        [27633],
        [25029],
        [32802],
        [24106],
        [23807],
        [32366],
        [25090]], device='cuda:0')
[2024-07-24 10:24:12,700][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[15921],
        [15759],
        [14881],
        [14695],
        [14451],
        [14826],
        [14846],
        [14787],
        [14718],
        [14618],
        [14557],
        [14467],
        [14467],
        [14460],
        [14446]], device='cuda:0')
[2024-07-24 10:24:12,702][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[12468],
        [10548],
        [20590],
        [ 9716],
        [23900],
        [18256],
        [ 7875],
        [ 7678],
        [14503],
        [ 9532],
        [ 9104],
        [10085],
        [10371],
        [ 9000],
        [ 8157]], device='cuda:0')
[2024-07-24 10:24:12,703][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[30874],
        [41401],
        [38506],
        [45591],
        [36684],
        [34802],
        [41695],
        [37261],
        [34105],
        [42575],
        [38180],
        [37689],
        [38445],
        [38976],
        [32562]], device='cuda:0')
[2024-07-24 10:24:12,705][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[26767],
        [31814],
        [44238],
        [31784],
        [45073],
        [ 5538],
        [34940],
        [34253],
        [10771],
        [34573],
        [27862],
        [37930],
        [30525],
        [24545],
        [40573]], device='cuda:0')
[2024-07-24 10:24:12,707][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[14493],
        [14493],
        [14493],
        [14493],
        [14493],
        [14493],
        [14493],
        [14493],
        [14493],
        [14493],
        [14493],
        [14493],
        [14493],
        [14493],
        [14493]], device='cuda:0')
[2024-07-24 10:24:12,746][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:24:12,747][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:12,749][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:12,750][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:12,751][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:12,751][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:12,752][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:12,753][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:12,754][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:12,754][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:12,755][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:12,756][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:12,756][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:12,757][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [,] are: tensor([9.9999e-01, 7.5793e-06], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:12,758][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.3440, 0.6560], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:12,758][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.6622, 0.3378], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:12,760][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.4100, 0.5900], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:12,761][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.5211, 0.4789], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:12,763][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.1661, 0.8339], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:12,765][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.4506, 0.5494], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:12,766][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.6421, 0.3580], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:12,768][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.9514, 0.0486], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:12,769][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.9826, 0.0174], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:12,771][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.9799, 0.0201], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:12,773][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.8138, 0.1862], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:12,774][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Erica] are: tensor([9.9729e-01, 8.7208e-04, 1.8423e-03], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:12,775][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Erica] are: tensor([0.1483, 0.3532, 0.4985], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:12,777][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Erica] are: tensor([0.1896, 0.2918, 0.5186], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:12,778][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Erica] are: tensor([0.0587, 0.5573, 0.3841], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:12,780][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Erica] are: tensor([0.1966, 0.5941, 0.2093], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:12,782][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Erica] are: tensor([0.0300, 0.8994, 0.0705], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:12,782][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Erica] are: tensor([0.2878, 0.3290, 0.3831], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:12,783][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Erica] are: tensor([0.4687, 0.2637, 0.2676], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:12,784][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Erica] are: tensor([0.9073, 0.0378, 0.0549], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:12,785][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Erica] are: tensor([0.9856, 0.0101, 0.0042], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:12,786][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Erica] are: tensor([0.9468, 0.0363, 0.0170], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:12,788][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Erica] are: tensor([0.3991, 0.1207, 0.4801], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:12,789][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ and] are: tensor([9.8552e-01, 4.8205e-06, 1.4476e-02, 3.0354e-06], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:12,790][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0988, 0.1923, 0.4800, 0.2288], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:12,792][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0765, 0.0674, 0.7724, 0.0837], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:12,793][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.1468, 0.2790, 0.3221, 0.2521], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:12,795][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.1125, 0.4394, 0.1720, 0.2761], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:12,796][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0472, 0.5783, 0.3411, 0.0334], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:12,798][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.1339, 0.1366, 0.2741, 0.4555], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:12,800][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.3608, 0.2219, 0.3213, 0.0960], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:12,801][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.8340, 0.0329, 0.0480, 0.0851], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:12,803][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.9780, 0.0064, 0.0025, 0.0131], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:12,804][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.9354, 0.0359, 0.0181, 0.0106], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:12,806][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.2644, 0.1121, 0.4671, 0.1564], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:12,807][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Joshua] are: tensor([9.9527e-01, 6.5451e-04, 3.0754e-03, 5.1866e-04, 4.8327e-04],
       device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:12,809][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Joshua] are: tensor([0.0902, 0.2231, 0.2869, 0.2306, 0.1691], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:12,810][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Joshua] are: tensor([0.0568, 0.0982, 0.4842, 0.2100, 0.1508], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:12,812][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Joshua] are: tensor([0.0361, 0.2892, 0.1736, 0.2638, 0.2373], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:12,814][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Joshua] are: tensor([0.0500, 0.2398, 0.3187, 0.3585, 0.0330], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:12,815][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Joshua] are: tensor([0.0124, 0.5193, 0.2342, 0.2238, 0.0103], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:12,817][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Joshua] are: tensor([0.0274, 0.0211, 0.0635, 0.1463, 0.7416], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:12,818][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Joshua] are: tensor([0.2309, 0.1967, 0.1944, 0.0967, 0.2814], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:12,820][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Joshua] are: tensor([0.8251, 0.0262, 0.0393, 0.0856, 0.0237], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:12,822][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Joshua] are: tensor([0.9729, 0.0063, 0.0021, 0.0138, 0.0049], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:12,823][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Joshua] are: tensor([0.9765, 0.0087, 0.0026, 0.0020, 0.0102], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:12,825][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Joshua] are: tensor([0.2149, 0.0688, 0.2782, 0.1728, 0.2653], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:12,826][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ went] are: tensor([9.9590e-01, 1.2125e-04, 2.9630e-03, 1.0250e-04, 8.5183e-04, 5.8037e-05],
       device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:12,828][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ went] are: tensor([0.0655, 0.1586, 0.2515, 0.1745, 0.1499, 0.2001], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:12,829][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ went] are: tensor([0.0790, 0.1033, 0.3669, 0.2568, 0.1570, 0.0369], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:12,831][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ went] are: tensor([0.0380, 0.2323, 0.1337, 0.1987, 0.1752, 0.2222], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:12,833][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ went] are: tensor([0.1272, 0.1897, 0.1389, 0.3987, 0.0492, 0.0963], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:12,833][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ went] are: tensor([0.0229, 0.3826, 0.1574, 0.2690, 0.1575, 0.0106], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:12,834][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ went] are: tensor([0.0130, 0.0091, 0.0262, 0.0680, 0.4250, 0.4588], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:12,835][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ went] are: tensor([0.1482, 0.1484, 0.1565, 0.0765, 0.2209, 0.2495], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:12,836][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.8204, 0.0220, 0.0362, 0.0848, 0.0238, 0.0127], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:12,837][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ went] are: tensor([0.9654, 0.0068, 0.0022, 0.0164, 0.0054, 0.0038], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:12,839][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ went] are: tensor([0.9358, 0.0166, 0.0064, 0.0044, 0.0213, 0.0155], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:12,840][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ went] are: tensor([0.1493, 0.0823, 0.2615, 0.1232, 0.1985, 0.1853], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:12,842][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ to] are: tensor([9.9653e-01, 1.8011e-06, 2.5036e-03, 1.0815e-06, 9.2567e-04, 2.7251e-05,
        1.3585e-05], device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:12,843][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0486, 0.1093, 0.2309, 0.1224, 0.1420, 0.1474, 0.1995],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:12,845][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0520, 0.0385, 0.2545, 0.1395, 0.0944, 0.4110, 0.0100],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:12,846][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0367, 0.1631, 0.1292, 0.1482, 0.1661, 0.1965, 0.1603],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:12,848][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0598, 0.1094, 0.1326, 0.1986, 0.0985, 0.2206, 0.1804],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:12,850][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0205, 0.1772, 0.2463, 0.2186, 0.3226, 0.0106, 0.0041],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:12,851][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0067, 0.0048, 0.0167, 0.0293, 0.2556, 0.2883, 0.3986],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:12,853][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.1296, 0.0980, 0.1492, 0.0519, 0.2234, 0.2611, 0.0868],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:12,855][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.7662, 0.0280, 0.0434, 0.0853, 0.0289, 0.0151, 0.0330],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:12,856][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.9696, 0.0057, 0.0018, 0.0124, 0.0043, 0.0027, 0.0036],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:12,858][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.8802, 0.0253, 0.0113, 0.0069, 0.0369, 0.0231, 0.0163],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:12,860][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.1328, 0.0540, 0.1566, 0.1095, 0.1704, 0.2557, 0.1210],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:12,861][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ the] are: tensor([9.9914e-01, 1.5805e-06, 6.9433e-04, 8.9661e-07, 1.3865e-04, 7.5628e-06,
        5.9501e-06, 9.7016e-06], device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:12,862][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0433, 0.0833, 0.2005, 0.0990, 0.1414, 0.1240, 0.1756, 0.1329],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:12,864][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0472, 0.0344, 0.1906, 0.1382, 0.1048, 0.3800, 0.0926, 0.0121],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:12,866][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0368, 0.1472, 0.1069, 0.1373, 0.1365, 0.1665, 0.1376, 0.1311],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:12,867][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0739, 0.1327, 0.0740, 0.2011, 0.0847, 0.0670, 0.2325, 0.1341],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:12,869][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0283, 0.2954, 0.1805, 0.2857, 0.1319, 0.0224, 0.0534, 0.0026],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:12,871][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0020, 0.0021, 0.0095, 0.0167, 0.1382, 0.1500, 0.2164, 0.4651],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:12,873][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.1072, 0.0844, 0.1302, 0.0467, 0.1838, 0.2186, 0.0754, 0.1537],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:12,874][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.7468, 0.0251, 0.0417, 0.0773, 0.0253, 0.0137, 0.0296, 0.0404],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:12,876][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.9403, 0.0082, 0.0028, 0.0168, 0.0067, 0.0043, 0.0053, 0.0155],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:12,878][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.8929, 0.0198, 0.0083, 0.0056, 0.0279, 0.0181, 0.0124, 0.0150],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:12,879][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.1438, 0.0623, 0.1222, 0.1351, 0.1055, 0.2138, 0.1557, 0.0618],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:12,880][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ office] are: tensor([9.9864e-01, 1.5194e-05, 1.0200e-03, 1.1929e-05, 2.1895e-04, 1.7121e-05,
        3.8177e-05, 3.1852e-05, 6.8258e-06], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:12,882][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ office] are: tensor([0.0405, 0.0976, 0.1223, 0.1106, 0.0767, 0.1159, 0.1305, 0.1181, 0.1878],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:12,883][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ office] are: tensor([0.0317, 0.0304, 0.1701, 0.0830, 0.1034, 0.3950, 0.0498, 0.0709, 0.0657],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:12,884][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ office] are: tensor([0.0293, 0.1326, 0.0889, 0.1186, 0.1122, 0.1415, 0.1170, 0.1123, 0.1477],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:12,885][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ office] are: tensor([0.0179, 0.1365, 0.0557, 0.1626, 0.0303, 0.1062, 0.2075, 0.2526, 0.0308],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:12,886][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ office] are: tensor([0.0118, 0.1748, 0.2965, 0.0939, 0.2197, 0.0252, 0.1198, 0.0547, 0.0038],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:12,887][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ office] are: tensor([0.0017, 0.0021, 0.0075, 0.0164, 0.1001, 0.0970, 0.1640, 0.3388, 0.2724],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:12,889][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ office] are: tensor([0.0947, 0.0819, 0.0955, 0.0420, 0.1306, 0.1649, 0.0726, 0.1083, 0.2095],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:12,890][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ office] are: tensor([0.7256, 0.0228, 0.0361, 0.0775, 0.0229, 0.0129, 0.0306, 0.0427, 0.0290],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:12,892][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ office] are: tensor([0.9157, 0.0090, 0.0029, 0.0199, 0.0072, 0.0050, 0.0068, 0.0196, 0.0139],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:12,894][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ office] are: tensor([0.8849, 0.0188, 0.0076, 0.0051, 0.0261, 0.0165, 0.0114, 0.0140, 0.0157],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:12,895][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ office] are: tensor([0.1389, 0.0514, 0.1652, 0.1040, 0.1438, 0.1339, 0.0935, 0.0814, 0.0880],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:12,896][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [.] are: tensor([9.8403e-01, 1.9164e-06, 1.1019e-02, 1.2480e-06, 4.6209e-03, 1.0050e-04,
        2.8152e-05, 1.0919e-04, 8.8201e-05, 6.5399e-07], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:12,898][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.0302, 0.0544, 0.1452, 0.0686, 0.1012, 0.0872, 0.1306, 0.0977, 0.1733,
        0.1114], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:12,900][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.0190, 0.0097, 0.1760, 0.0378, 0.1276, 0.3060, 0.0302, 0.0327, 0.2504,
        0.0105], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:12,902][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0574, 0.0892, 0.1059, 0.0821, 0.1208, 0.1295, 0.1005, 0.0931, 0.1293,
        0.0921], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:12,903][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0302, 0.0703, 0.1416, 0.1195, 0.0853, 0.0852, 0.1502, 0.2049, 0.0293,
        0.0835], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:12,905][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.0349, 0.1900, 0.1682, 0.2034, 0.1236, 0.0389, 0.1104, 0.0349, 0.0761,
        0.0199], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:12,907][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0019, 0.0012, 0.0056, 0.0069, 0.0781, 0.0817, 0.1073, 0.2153, 0.1918,
        0.3100], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:12,908][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0715, 0.0554, 0.1029, 0.0319, 0.1569, 0.1759, 0.0548, 0.1090, 0.1999,
        0.0418], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:12,910][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.7418, 0.0206, 0.0340, 0.0635, 0.0191, 0.0097, 0.0224, 0.0329, 0.0212,
        0.0349], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:12,912][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.9181, 0.0081, 0.0028, 0.0155, 0.0061, 0.0038, 0.0046, 0.0142, 0.0100,
        0.0168], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:12,913][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.8153, 0.0247, 0.0123, 0.0074, 0.0407, 0.0248, 0.0177, 0.0217, 0.0238,
        0.0116], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:12,915][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.1418, 0.0395, 0.1061, 0.1111, 0.1019, 0.1553, 0.1411, 0.0763, 0.0714,
        0.0556], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:12,917][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Erica] are: tensor([9.9786e-01, 1.9376e-05, 1.2551e-03, 1.4597e-05, 6.0096e-04, 4.5061e-05,
        3.9685e-05, 5.4705e-05, 2.6977e-05, 8.2497e-06, 7.0408e-05],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:12,918][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Erica] are: tensor([0.0367, 0.0893, 0.1027, 0.0910, 0.0595, 0.0932, 0.1119, 0.0950, 0.1431,
        0.0973, 0.0802], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:12,920][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Erica] are: tensor([0.0286, 0.0371, 0.0619, 0.0777, 0.0854, 0.2380, 0.0528, 0.0822, 0.2520,
        0.0406, 0.0437], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:12,922][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Erica] are: tensor([0.0229, 0.0938, 0.0739, 0.0926, 0.0924, 0.1108, 0.0862, 0.0867, 0.1135,
        0.1138, 0.1133], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:12,923][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Erica] are: tensor([0.0328, 0.1022, 0.0338, 0.1112, 0.0368, 0.0794, 0.2162, 0.2085, 0.0242,
        0.1127, 0.0422], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:12,925][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Erica] are: tensor([0.0145, 0.3426, 0.0268, 0.1571, 0.0843, 0.0210, 0.1052, 0.0590, 0.0704,
        0.1020, 0.0172], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:12,927][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Erica] are: tensor([0.0012, 0.0008, 0.0031, 0.0069, 0.0237, 0.0210, 0.0416, 0.0664, 0.0525,
        0.1706, 0.6123], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:12,928][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Erica] are: tensor([0.0818, 0.0630, 0.0869, 0.0386, 0.1301, 0.1379, 0.0516, 0.0833, 0.1691,
        0.0380, 0.1197], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:12,930][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Erica] are: tensor([0.7041, 0.0212, 0.0337, 0.0681, 0.0194, 0.0108, 0.0259, 0.0373, 0.0249,
        0.0373, 0.0173], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:12,932][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Erica] are: tensor([0.9099, 0.0085, 0.0026, 0.0146, 0.0058, 0.0038, 0.0050, 0.0146, 0.0107,
        0.0178, 0.0068], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:12,933][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Erica] are: tensor([0.8407, 0.0195, 0.0085, 0.0062, 0.0241, 0.0176, 0.0123, 0.0149, 0.0168,
        0.0100, 0.0295], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:12,934][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Erica] are: tensor([0.1177, 0.0369, 0.1011, 0.0629, 0.1263, 0.1240, 0.0806, 0.0761, 0.1145,
        0.0453, 0.1147], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:12,935][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([9.9825e-01, 2.2992e-06, 1.2975e-03, 1.4364e-06, 3.6422e-04, 1.4260e-05,
        1.0439e-05, 1.8996e-05, 9.8497e-06, 8.3311e-07, 3.0192e-05, 3.9188e-06],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:12,936][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0263, 0.0590, 0.1091, 0.0676, 0.0665, 0.0788, 0.1030, 0.0768, 0.1496,
        0.0837, 0.0998, 0.0798], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:12,937][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0389, 0.0481, 0.1476, 0.1190, 0.1035, 0.0760, 0.0378, 0.0623, 0.1278,
        0.0556, 0.1089, 0.0743], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:12,938][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.0239, 0.0862, 0.0690, 0.0808, 0.0818, 0.1001, 0.0800, 0.0750, 0.1026,
        0.1015, 0.1041, 0.0949], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:12,940][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.0326, 0.0808, 0.0595, 0.1453, 0.0361, 0.0443, 0.1547, 0.1520, 0.0178,
        0.1752, 0.0808, 0.0209], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:12,942][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.0162, 0.2246, 0.1940, 0.1016, 0.0566, 0.0152, 0.0498, 0.0563, 0.0644,
        0.0714, 0.1481, 0.0018], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:12,943][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([6.5587e-04, 4.3350e-04, 1.6095e-03, 3.7713e-03, 1.5899e-02, 1.4017e-02,
        2.7826e-02, 4.9355e-02, 3.7191e-02, 1.2987e-01, 4.5517e-01, 2.6419e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:12,945][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0585, 0.0702, 0.0707, 0.0320, 0.0949, 0.1249, 0.0559, 0.0859, 0.1343,
        0.0364, 0.1054, 0.1308], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:12,946][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.6670, 0.0206, 0.0327, 0.0698, 0.0206, 0.0111, 0.0284, 0.0401, 0.0271,
        0.0417, 0.0195, 0.0215], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:12,948][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.8806, 0.0083, 0.0027, 0.0173, 0.0064, 0.0044, 0.0059, 0.0176, 0.0132,
        0.0220, 0.0082, 0.0135], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:12,950][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.8509, 0.0156, 0.0064, 0.0046, 0.0196, 0.0149, 0.0098, 0.0116, 0.0135,
        0.0077, 0.0229, 0.0226], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:12,952][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0868, 0.0428, 0.1319, 0.0489, 0.0927, 0.0947, 0.0745, 0.0809, 0.0828,
        0.0354, 0.1485, 0.0801], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:12,953][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ a] are: tensor([9.9902e-01, 2.0832e-06, 7.8025e-04, 1.2168e-06, 1.2418e-04, 5.6904e-06,
        8.0685e-06, 1.1650e-05, 5.3497e-06, 7.1955e-07, 1.9385e-05, 6.1254e-06,
        1.4626e-05], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:12,955][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0232, 0.0430, 0.1114, 0.0519, 0.0762, 0.0640, 0.0923, 0.0657, 0.1389,
        0.0765, 0.1143, 0.0786, 0.0640], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:12,956][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0519, 0.0279, 0.0746, 0.0922, 0.0611, 0.1295, 0.0279, 0.0258, 0.1553,
        0.0233, 0.0596, 0.2633, 0.0076], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:12,958][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0199, 0.0818, 0.0598, 0.0776, 0.0710, 0.0875, 0.0705, 0.0689, 0.0890,
        0.0986, 0.0979, 0.0889, 0.0886], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:12,960][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0417, 0.0718, 0.0626, 0.1430, 0.0471, 0.0412, 0.1325, 0.1196, 0.0250,
        0.1039, 0.0807, 0.0427, 0.0883], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:12,962][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0174, 0.1834, 0.1218, 0.0891, 0.1180, 0.0245, 0.0572, 0.0183, 0.1318,
        0.1084, 0.0902, 0.0388, 0.0010], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:12,963][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ a] are: tensor([3.1985e-04, 2.0254e-04, 9.8506e-04, 1.7866e-03, 1.0989e-02, 9.8722e-03,
        1.7588e-02, 3.3521e-02, 2.6723e-02, 7.3547e-02, 2.9290e-01, 1.9208e-01,
        3.3948e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:12,965][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0458, 0.0510, 0.0694, 0.0240, 0.0925, 0.1050, 0.0372, 0.0742, 0.1319,
        0.0290, 0.1154, 0.1217, 0.1029], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:12,966][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.6636, 0.0209, 0.0343, 0.0635, 0.0198, 0.0105, 0.0235, 0.0333, 0.0226,
        0.0345, 0.0165, 0.0193, 0.0377], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:12,968][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.9016, 0.0075, 0.0023, 0.0129, 0.0050, 0.0031, 0.0038, 0.0113, 0.0084,
        0.0139, 0.0055, 0.0091, 0.0157], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:12,970][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.9109, 0.0084, 0.0027, 0.0021, 0.0106, 0.0076, 0.0049, 0.0060, 0.0070,
        0.0040, 0.0129, 0.0127, 0.0102], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:12,971][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0912, 0.0342, 0.0879, 0.0534, 0.0831, 0.1187, 0.0769, 0.0477, 0.0527,
        0.0384, 0.1291, 0.1368, 0.0499], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:12,973][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ basketball] are: tensor([9.9621e-01, 1.1860e-05, 2.5492e-03, 9.1150e-06, 7.4185e-04, 5.8443e-05,
        5.2495e-05, 5.9442e-05, 3.5512e-05, 5.7763e-06, 9.5742e-05, 5.1058e-05,
        6.6908e-05, 5.3292e-05], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:12,974][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ basketball] are: tensor([0.0280, 0.0804, 0.0694, 0.0795, 0.0386, 0.0754, 0.0827, 0.0767, 0.1090,
        0.0757, 0.0496, 0.0564, 0.0702, 0.1084], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:12,976][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ basketball] are: tensor([0.0195, 0.0183, 0.0750, 0.0546, 0.0482, 0.1136, 0.0206, 0.0379, 0.0993,
        0.0185, 0.0573, 0.3334, 0.0644, 0.0393], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:12,978][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ basketball] are: tensor([0.0193, 0.0732, 0.0549, 0.0683, 0.0640, 0.0768, 0.0611, 0.0614, 0.0775,
        0.0833, 0.0844, 0.0770, 0.0780, 0.1207], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:12,980][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ basketball] are: tensor([0.0251, 0.0811, 0.0369, 0.0962, 0.0111, 0.0622, 0.1135, 0.1290, 0.0344,
        0.1044, 0.0433, 0.0532, 0.1263, 0.0832], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:12,982][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ basketball] are: tensor([0.0160, 0.1938, 0.1211, 0.0853, 0.0629, 0.0208, 0.1258, 0.0086, 0.0539,
        0.0477, 0.0855, 0.1587, 0.0189, 0.0009], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:12,983][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ basketball] are: tensor([3.0018e-04, 1.8551e-04, 8.6587e-04, 1.7056e-03, 6.8195e-03, 5.5136e-03,
        1.2054e-02, 2.0178e-02, 1.5517e-02, 5.2049e-02, 2.0476e-01, 1.0787e-01,
        1.9242e-01, 3.7975e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:12,984][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ basketball] are: tensor([0.0450, 0.0679, 0.0687, 0.0291, 0.0828, 0.0959, 0.0379, 0.0569, 0.1152,
        0.0283, 0.0923, 0.1005, 0.0811, 0.0983], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:12,985][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ basketball] are: tensor([0.6276, 0.0223, 0.0336, 0.0656, 0.0205, 0.0116, 0.0255, 0.0366, 0.0257,
        0.0383, 0.0197, 0.0221, 0.0441, 0.0067], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:12,986][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ basketball] are: tensor([0.8644, 0.0091, 0.0027, 0.0152, 0.0062, 0.0042, 0.0053, 0.0152, 0.0118,
        0.0189, 0.0078, 0.0130, 0.0218, 0.0043], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:12,986][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ basketball] are: tensor([0.8614, 0.0113, 0.0041, 0.0031, 0.0137, 0.0105, 0.0066, 0.0079, 0.0097,
        0.0056, 0.0159, 0.0154, 0.0123, 0.0226], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:12,988][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ basketball] are: tensor([0.0905, 0.0320, 0.0887, 0.0431, 0.0735, 0.1328, 0.0553, 0.0374, 0.0823,
        0.0263, 0.1172, 0.1100, 0.0463, 0.0645], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:12,989][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ to] are: tensor([9.9809e-01, 9.9522e-07, 1.3626e-03, 5.3801e-07, 4.3356e-04, 1.2086e-05,
        5.3246e-06, 1.5873e-05, 1.1098e-05, 2.7097e-07, 1.7913e-05, 3.9336e-06,
        1.8647e-05, 1.6085e-05, 7.2227e-06], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:12,991][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0184, 0.0435, 0.0751, 0.0475, 0.0484, 0.0541, 0.0751, 0.0588, 0.0944,
        0.0625, 0.0694, 0.0572, 0.0556, 0.1242, 0.1158], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:12,993][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0177, 0.0124, 0.0791, 0.0450, 0.0262, 0.1435, 0.0027, 0.0236, 0.1533,
        0.0087, 0.0648, 0.2891, 0.0585, 0.0717, 0.0036], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:12,995][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0183, 0.0623, 0.0491, 0.0583, 0.0577, 0.0693, 0.0562, 0.0554, 0.0718,
        0.0731, 0.0761, 0.0705, 0.0715, 0.1119, 0.0986], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:12,997][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0228, 0.0491, 0.0549, 0.0857, 0.0358, 0.0849, 0.0765, 0.0837, 0.0135,
        0.0923, 0.0722, 0.0868, 0.0986, 0.0507, 0.0923], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:12,998][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0111, 0.0985, 0.1373, 0.1356, 0.1930, 0.0063, 0.0020, 0.0177, 0.1116,
        0.0185, 0.0943, 0.1252, 0.0078, 0.0394, 0.0017], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:13,000][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ to] are: tensor([2.0746e-04, 1.5383e-04, 6.3316e-04, 1.1713e-03, 6.4125e-03, 5.6744e-03,
        1.0858e-02, 2.0772e-02, 1.5166e-02, 4.4727e-02, 1.4260e-01, 1.0307e-01,
        1.8423e-01, 2.6611e-01, 1.9822e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:13,001][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0434, 0.0427, 0.0609, 0.0209, 0.0838, 0.0973, 0.0308, 0.0589, 0.1040,
        0.0236, 0.0938, 0.1098, 0.0814, 0.0983, 0.0504], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:13,003][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.6386, 0.0205, 0.0319, 0.0587, 0.0189, 0.0097, 0.0216, 0.0317, 0.0208,
        0.0327, 0.0158, 0.0184, 0.0364, 0.0054, 0.0390], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:13,005][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.9073, 0.0062, 0.0018, 0.0106, 0.0039, 0.0023, 0.0029, 0.0094, 0.0062,
        0.0114, 0.0043, 0.0070, 0.0132, 0.0021, 0.0115], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:13,007][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.7888, 0.0156, 0.0062, 0.0042, 0.0213, 0.0137, 0.0097, 0.0120, 0.0130,
        0.0072, 0.0225, 0.0231, 0.0207, 0.0294, 0.0126], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:13,008][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0754, 0.0304, 0.0668, 0.0466, 0.0751, 0.1194, 0.0559, 0.0486, 0.0455,
        0.0373, 0.0904, 0.0974, 0.0548, 0.0847, 0.0715], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:13,036][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:24:13,037][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:13,037][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:13,038][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:13,039][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:13,040][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:13,040][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:13,041][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:13,042][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:13,042][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:13,043][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:13,044][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:13,044][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:13,045][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.4370, 0.5630], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:13,046][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0040, 0.9960], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:13,046][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0416, 0.9584], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:13,048][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.6453, 0.3547], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:13,049][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([9.9979e-01, 2.0947e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:13,051][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0325, 0.9675], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:13,052][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.3430, 0.6570], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:13,052][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.4864, 0.5136], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:13,053][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.4062, 0.5938], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:13,054][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0925, 0.9075], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:13,054][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0877, 0.9123], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:13,056][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.4481, 0.5519], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:13,058][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Erica] are: tensor([0.2568, 0.3868, 0.3563], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:13,059][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Erica] are: tensor([1.1128e-04, 8.7722e-01, 1.2266e-01], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:13,060][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Erica] are: tensor([0.0133, 0.5602, 0.4265], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:13,062][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Erica] are: tensor([0.6309, 0.1706, 0.1985], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:13,063][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Erica] are: tensor([0.6166, 0.3732, 0.0102], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:13,065][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Erica] are: tensor([0.0099, 0.7553, 0.2348], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:13,066][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Erica] are: tensor([0.0944, 0.2125, 0.6931], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:13,068][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Erica] are: tensor([0.4566, 0.3780, 0.1654], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:13,069][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Erica] are: tensor([0.2515, 0.5514, 0.1971], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:13,071][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Erica] are: tensor([0.0223, 0.4225, 0.5552], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:13,073][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Erica] are: tensor([0.0060, 0.2148, 0.7792], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:13,074][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Erica] are: tensor([0.3361, 0.4247, 0.2392], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:13,076][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.1685, 0.2630, 0.3102, 0.2583], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:13,077][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0327, 0.3159, 0.1395, 0.5119], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:13,079][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0096, 0.2417, 0.2840, 0.4647], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:13,081][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.3379, 0.1505, 0.1919, 0.3198], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:13,082][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.5862, 0.3987, 0.0065, 0.0087], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:13,084][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0116, 0.4378, 0.3191, 0.2316], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:13,086][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0830, 0.1649, 0.4935, 0.2586], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:13,087][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.3431, 0.3490, 0.2610, 0.0469], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:13,089][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.1613, 0.3248, 0.2500, 0.2640], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:13,090][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0066, 0.1783, 0.7421, 0.0730], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:13,092][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0126, 0.1830, 0.6397, 0.1647], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:13,093][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.2455, 0.2861, 0.1565, 0.3119], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:13,095][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Joshua] are: tensor([0.1125, 0.1941, 0.1933, 0.2815, 0.2186], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:13,096][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Joshua] are: tensor([1.2315e-05, 1.0158e-01, 1.5694e-02, 8.7495e-01, 7.7654e-03],
       device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:13,098][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Joshua] are: tensor([0.0032, 0.1586, 0.1252, 0.4160, 0.2970], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:13,099][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Joshua] are: tensor([0.4235, 0.0875, 0.1089, 0.2680, 0.1122], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:13,101][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Joshua] are: tensor([0.0151, 0.2159, 0.3463, 0.4222, 0.0005], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:13,103][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Joshua] are: tensor([0.0030, 0.3702, 0.2271, 0.3295, 0.0702], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:13,103][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Joshua] are: tensor([0.0491, 0.1108, 0.3331, 0.1650, 0.3420], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:13,104][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Joshua] are: tensor([0.2929, 0.3563, 0.1293, 0.0654, 0.1560], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:13,105][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Joshua] are: tensor([0.1351, 0.3505, 0.1441, 0.3202, 0.0501], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:13,106][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Joshua] are: tensor([0.0041, 0.1492, 0.6594, 0.1079, 0.0793], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:13,107][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Joshua] are: tensor([0.0028, 0.1241, 0.4165, 0.1044, 0.3522], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:13,109][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Joshua] are: tensor([0.1868, 0.2451, 0.1350, 0.2737, 0.1594], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:13,110][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([0.0817, 0.1464, 0.1977, 0.2103, 0.2704, 0.0934], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:13,112][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([9.9552e-06, 9.9789e-02, 1.3607e-02, 8.7046e-01, 6.9485e-03, 9.1893e-03],
       device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:13,113][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([0.0030, 0.1078, 0.0981, 0.2507, 0.2425, 0.2980], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:13,114][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([0.3181, 0.0828, 0.1020, 0.2558, 0.1131, 0.1283], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:13,116][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([8.9322e-01, 4.3113e-02, 2.2899e-03, 6.1032e-02, 2.7398e-04, 7.0281e-05],
       device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:13,117][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([0.0046, 0.3012, 0.1651, 0.2930, 0.1593, 0.0768], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:13,119][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([0.0376, 0.0841, 0.2452, 0.1195, 0.2538, 0.2599], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:13,120][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([0.2163, 0.3280, 0.1141, 0.0622, 0.1264, 0.1530], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:13,122][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([0.1020, 0.2563, 0.1405, 0.2042, 0.1027, 0.1943], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:13,124][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([0.0074, 0.1911, 0.4065, 0.1187, 0.1731, 0.1033], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:13,125][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([0.0026, 0.0904, 0.3080, 0.0735, 0.2584, 0.2671], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:13,127][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([0.1623, 0.2157, 0.1219, 0.2387, 0.1457, 0.1156], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:13,129][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0970, 0.1293, 0.1457, 0.1779, 0.1899, 0.1004, 0.1598],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:13,130][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([1.3497e-04, 1.2246e-01, 2.5036e-02, 6.6392e-01, 1.6301e-02, 1.9333e-02,
        1.5282e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:13,132][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0031, 0.0820, 0.0864, 0.1645, 0.2067, 0.2733, 0.1840],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:13,133][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.2711, 0.0734, 0.0914, 0.2046, 0.0961, 0.1101, 0.1534],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:13,134][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([1.3945e-01, 2.2496e-03, 1.7800e-02, 7.1491e-03, 5.0396e-02, 7.8248e-01,
        4.8248e-04], device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:13,136][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0068, 0.2152, 0.1937, 0.2490, 0.1886, 0.0842, 0.0626],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:13,138][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0333, 0.0725, 0.1971, 0.1109, 0.2069, 0.2271, 0.1523],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:13,139][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.1899, 0.2340, 0.1259, 0.0433, 0.1508, 0.1835, 0.0726],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:13,141][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0469, 0.1205, 0.0681, 0.1393, 0.0682, 0.4728, 0.0841],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:13,143][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0089, 0.1218, 0.4298, 0.0771, 0.2084, 0.1381, 0.0158],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:13,144][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0055, 0.0905, 0.2430, 0.0884, 0.2300, 0.2502, 0.0924],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:13,146][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.1502, 0.1901, 0.1028, 0.2072, 0.1214, 0.0948, 0.1335],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:13,148][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0696, 0.1018, 0.1274, 0.1414, 0.2063, 0.0983, 0.1715, 0.0837],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:13,149][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([7.5215e-05, 9.5984e-02, 1.8521e-02, 6.2853e-01, 1.1522e-02, 1.4234e-02,
        1.3524e-01, 9.5895e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:13,150][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0016, 0.0548, 0.0692, 0.1269, 0.1716, 0.2150, 0.1739, 0.1869],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:13,152][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.3110, 0.0568, 0.0700, 0.1696, 0.0664, 0.0750, 0.1062, 0.1451],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:13,153][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([8.5995e-01, 2.6143e-02, 1.4107e-03, 7.4021e-02, 2.4474e-02, 1.1497e-03,
        1.2309e-02, 5.3845e-04], device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:13,154][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.0055, 0.2171, 0.1676, 0.2318, 0.1380, 0.0917, 0.1057, 0.0427],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:13,155][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0296, 0.0616, 0.1750, 0.0972, 0.1873, 0.2008, 0.1378, 0.1107],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:13,156][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.2037, 0.2003, 0.1000, 0.0391, 0.1107, 0.1483, 0.0667, 0.1313],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:13,157][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0507, 0.1241, 0.1067, 0.1499, 0.0690, 0.2398, 0.1962, 0.0637],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:13,158][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0083, 0.1360, 0.3621, 0.0847, 0.1716, 0.1272, 0.0466, 0.0634],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:13,159][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0042, 0.0747, 0.2336, 0.0743, 0.2093, 0.2134, 0.0748, 0.1156],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:13,161][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.1322, 0.1686, 0.0921, 0.1853, 0.1096, 0.0869, 0.1204, 0.1048],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:13,163][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ office] are: tensor([0.0593, 0.1037, 0.1504, 0.1065, 0.1802, 0.0872, 0.1213, 0.0800, 0.1114],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:13,164][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ office] are: tensor([1.8012e-05, 8.3074e-02, 1.2985e-02, 6.5812e-01, 7.3357e-03, 9.3713e-03,
        1.1204e-01, 7.5654e-02, 4.1396e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:13,165][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ office] are: tensor([0.0011, 0.0465, 0.0444, 0.1146, 0.1129, 0.1653, 0.1860, 0.2261, 0.1032],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:13,167][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ office] are: tensor([0.2325, 0.0538, 0.0652, 0.1593, 0.0668, 0.0757, 0.1078, 0.1465, 0.0923],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:13,169][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ office] are: tensor([0.0072, 0.3257, 0.0146, 0.1614, 0.0580, 0.1877, 0.0981, 0.1356, 0.0116],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:13,170][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ office] are: tensor([0.0026, 0.2003, 0.1578, 0.1716, 0.1367, 0.0731, 0.1229, 0.0779, 0.0572],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:13,172][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ office] are: tensor([0.0240, 0.0534, 0.1529, 0.0818, 0.1619, 0.1703, 0.1134, 0.0909, 0.1515],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:13,174][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ office] are: tensor([0.1748, 0.1694, 0.0857, 0.0363, 0.0954, 0.1298, 0.0658, 0.0895, 0.1533],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:13,176][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ office] are: tensor([0.0523, 0.1264, 0.0620, 0.1373, 0.0330, 0.1891, 0.1926, 0.1069, 0.1004],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:13,177][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ office] are: tensor([0.0022, 0.0922, 0.3240, 0.0717, 0.1785, 0.1408, 0.0273, 0.1279, 0.0354],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:13,179][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ office] are: tensor([0.0017, 0.0729, 0.2050, 0.0554, 0.1891, 0.1626, 0.0498, 0.0966, 0.1669],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:13,181][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ office] are: tensor([0.1164, 0.1520, 0.0837, 0.1677, 0.0995, 0.0791, 0.1092, 0.0963, 0.0961],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:13,182][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.0573, 0.0774, 0.0962, 0.0979, 0.1557, 0.0842, 0.1229, 0.0836, 0.1117,
        0.1133], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:13,184][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.0090, 0.1063, 0.0418, 0.1870, 0.0393, 0.0401, 0.1080, 0.0948, 0.0819,
        0.2918], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:13,186][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.0018, 0.0396, 0.0527, 0.0793, 0.1201, 0.1440, 0.1205, 0.1291, 0.1092,
        0.2036], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:13,188][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.1414, 0.0453, 0.0579, 0.1161, 0.0643, 0.0746, 0.0960, 0.1275, 0.0871,
        0.1898], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:13,189][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([2.8044e-02, 1.8993e-03, 2.8525e-01, 1.0179e-02, 6.0359e-01, 2.6220e-02,
        7.5580e-03, 3.6265e-02, 7.2338e-04, 2.6994e-04], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:13,190][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.0060, 0.1705, 0.1230, 0.1689, 0.1086, 0.0781, 0.1007, 0.0599, 0.1099,
        0.0743], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:13,192][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.0229, 0.0471, 0.1301, 0.0809, 0.1453, 0.1585, 0.1135, 0.0913, 0.1408,
        0.0697], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:13,194][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.1638, 0.1418, 0.1110, 0.0285, 0.1271, 0.1375, 0.0470, 0.0936, 0.1367,
        0.0129], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:13,196][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.0534, 0.0937, 0.0971, 0.0975, 0.0779, 0.1751, 0.1379, 0.0851, 0.1179,
        0.0643], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:13,197][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.0074, 0.0837, 0.2408, 0.0782, 0.1034, 0.1208, 0.0348, 0.1118, 0.1405,
        0.0785], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:13,199][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.0039, 0.0577, 0.1960, 0.0588, 0.1878, 0.1420, 0.0577, 0.1038, 0.1539,
        0.0383], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:13,201][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.1131, 0.1367, 0.0723, 0.1494, 0.0841, 0.0654, 0.0936, 0.0799, 0.0809,
        0.1247], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:13,203][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Erica] are: tensor([0.0454, 0.0705, 0.0644, 0.0947, 0.1201, 0.0764, 0.1294, 0.0786, 0.1276,
        0.1190, 0.0738], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:13,204][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Erica] are: tensor([3.7969e-05, 4.3064e-02, 7.3212e-03, 2.5079e-01, 4.4184e-03, 5.4844e-03,
        5.3189e-02, 3.6872e-02, 2.2773e-02, 4.9433e-01, 8.1712e-02],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:13,205][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Erica] are: tensor([0.0005, 0.0257, 0.0199, 0.0752, 0.0625, 0.1063, 0.1263, 0.1804, 0.0655,
        0.2429, 0.0948], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:13,205][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Erica] are: tensor([0.2173, 0.0357, 0.0441, 0.1120, 0.0426, 0.0477, 0.0675, 0.0935, 0.0604,
        0.1681, 0.1113], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:13,206][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Erica] are: tensor([8.6867e-02, 5.7294e-02, 1.2353e-03, 8.8301e-02, 2.4906e-02, 8.0793e-03,
        4.7486e-01, 2.5044e-01, 1.0031e-03, 6.6695e-03, 3.4411e-04],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:13,207][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Erica] are: tensor([0.0024, 0.1917, 0.0581, 0.1695, 0.0878, 0.0583, 0.1047, 0.0783, 0.1007,
        0.1047, 0.0436], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:13,209][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Erica] are: tensor([0.0170, 0.0390, 0.1226, 0.0655, 0.1282, 0.1317, 0.0942, 0.0750, 0.1205,
        0.0579, 0.1483], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:13,210][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Erica] are: tensor([0.1671, 0.1312, 0.0683, 0.0432, 0.0998, 0.1273, 0.0612, 0.0940, 0.1401,
        0.0222, 0.0456], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:13,212][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Erica] are: tensor([0.0472, 0.1089, 0.0438, 0.1156, 0.0292, 0.1436, 0.1964, 0.0852, 0.1011,
        0.0869, 0.0421], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:13,214][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Erica] are: tensor([0.0040, 0.0781, 0.0964, 0.0553, 0.1328, 0.1358, 0.0310, 0.1510, 0.1519,
        0.0928, 0.0712], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:13,215][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Erica] are: tensor([0.0010, 0.0466, 0.1686, 0.0336, 0.1672, 0.1553, 0.0295, 0.0695, 0.1470,
        0.0248, 0.1571], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:13,217][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Erica] are: tensor([0.0951, 0.1240, 0.0642, 0.1367, 0.0763, 0.0611, 0.0844, 0.0733, 0.0727,
        0.1125, 0.0996], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:13,219][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.0423, 0.0718, 0.0749, 0.0846, 0.0952, 0.0854, 0.1184, 0.0667, 0.1256,
        0.1106, 0.0838, 0.0405], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:13,220][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([5.1618e-05, 3.8867e-02, 7.6912e-03, 2.2878e-01, 4.7392e-03, 5.7969e-03,
        5.1806e-02, 3.7205e-02, 2.1844e-02, 4.6695e-01, 8.3115e-02, 5.3158e-02],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:13,222][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.0007, 0.0230, 0.0258, 0.0561, 0.0715, 0.0876, 0.0941, 0.1144, 0.0648,
        0.1850, 0.1394, 0.1377], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:13,224][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.1535, 0.0322, 0.0405, 0.0978, 0.0414, 0.0472, 0.0671, 0.0929, 0.0596,
        0.1602, 0.1122, 0.0953], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:13,225][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([4.9341e-01, 7.7313e-02, 3.0811e-02, 1.4071e-01, 2.0981e-02, 1.4418e-03,
        2.6505e-02, 2.6409e-02, 1.2826e-04, 1.7669e-01, 5.5536e-03, 4.5949e-05],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:13,227][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.0027, 0.1654, 0.1036, 0.1460, 0.0681, 0.0552, 0.0880, 0.0724, 0.0923,
        0.0981, 0.0771, 0.0311], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:13,228][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.0159, 0.0362, 0.1058, 0.0575, 0.1160, 0.1181, 0.0817, 0.0628, 0.1080,
        0.0509, 0.1378, 0.1093], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:13,230][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.1346, 0.1832, 0.0694, 0.0345, 0.0766, 0.1155, 0.0682, 0.0915, 0.1036,
        0.0171, 0.0444, 0.0614], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:13,232][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.0478, 0.1053, 0.0634, 0.0961, 0.0396, 0.0977, 0.1615, 0.0837, 0.0879,
        0.0735, 0.0594, 0.0842], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:13,233][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.0033, 0.0653, 0.1865, 0.0447, 0.0982, 0.0833, 0.0247, 0.1021, 0.1108,
        0.1137, 0.1464, 0.0211], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:13,235][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0016, 0.0419, 0.1431, 0.0373, 0.1180, 0.1551, 0.0345, 0.0610, 0.1170,
        0.0245, 0.1420, 0.1241], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:13,237][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.0858, 0.1120, 0.0599, 0.1227, 0.0711, 0.0568, 0.0775, 0.0677, 0.0672,
        0.1021, 0.0934, 0.0838], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:13,239][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0384, 0.0577, 0.0671, 0.0915, 0.1336, 0.0550, 0.1031, 0.0621, 0.1017,
        0.1068, 0.0783, 0.0499, 0.0548], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:13,240][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([9.5213e-05, 4.0212e-02, 8.7182e-03, 2.0098e-01, 5.8277e-03, 7.0034e-03,
        5.2878e-02, 3.8958e-02, 2.4456e-02, 3.9961e-01, 8.5556e-02, 5.6580e-02,
        7.9127e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:13,242][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0006, 0.0195, 0.0279, 0.0462, 0.0736, 0.0966, 0.0700, 0.0756, 0.0668,
        0.1208, 0.1614, 0.1541, 0.0869], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:13,244][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.2006, 0.0300, 0.0359, 0.0923, 0.0322, 0.0353, 0.0512, 0.0715, 0.0450,
        0.1345, 0.0852, 0.0750, 0.1113], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:13,245][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([8.6495e-01, 2.9225e-02, 1.1681e-02, 4.7307e-02, 2.0262e-02, 2.2331e-03,
        6.1451e-03, 3.5798e-03, 1.0458e-03, 8.1331e-03, 3.0754e-03, 1.9905e-03,
        3.7280e-04], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:13,247][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0033, 0.1360, 0.0955, 0.1210, 0.0892, 0.0668, 0.0756, 0.0495, 0.1104,
        0.0918, 0.0752, 0.0708, 0.0149], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:13,248][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0149, 0.0322, 0.0949, 0.0551, 0.1056, 0.1120, 0.0783, 0.0616, 0.1019,
        0.0487, 0.1285, 0.1072, 0.0591], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:13,250][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.1243, 0.1549, 0.0761, 0.0278, 0.0801, 0.0979, 0.0442, 0.0874, 0.1173,
        0.0149, 0.0474, 0.0536, 0.0741], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:13,252][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0277, 0.0616, 0.0582, 0.0752, 0.0387, 0.1220, 0.0899, 0.0498, 0.1064,
        0.0525, 0.0556, 0.2290, 0.0332], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:13,254][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0044, 0.0719, 0.1872, 0.0468, 0.0810, 0.0781, 0.0259, 0.0500, 0.1073,
        0.0882, 0.1437, 0.0746, 0.0410], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:13,255][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0028, 0.0406, 0.1365, 0.0397, 0.1112, 0.1172, 0.0396, 0.0634, 0.1119,
        0.0269, 0.1344, 0.1117, 0.0642], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:13,256][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0833, 0.1053, 0.0555, 0.1148, 0.0660, 0.0527, 0.0726, 0.0625, 0.0626,
        0.0947, 0.0858, 0.0779, 0.0663], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:13,257][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ basketball] are: tensor([0.0329, 0.0552, 0.0805, 0.0662, 0.0947, 0.0619, 0.0846, 0.0485, 0.0903,
        0.0906, 0.0918, 0.0635, 0.0471, 0.0923], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:13,257][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ basketball] are: tensor([4.2743e-05, 4.6541e-02, 8.9532e-03, 2.2327e-01, 5.3436e-03, 6.7369e-03,
        5.1398e-02, 3.5040e-02, 2.3518e-02, 3.8458e-01, 6.5546e-02, 4.5935e-02,
        6.3916e-02, 3.9181e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:13,259][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ basketball] are: tensor([0.0003, 0.0166, 0.0151, 0.0486, 0.0407, 0.0687, 0.0790, 0.1007, 0.0448,
        0.1506, 0.0768, 0.1262, 0.1317, 0.1001], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:13,261][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ basketball] are: tensor([0.1427, 0.0244, 0.0318, 0.0773, 0.0314, 0.0352, 0.0509, 0.0705, 0.0449,
        0.1244, 0.0880, 0.0763, 0.1140, 0.0882], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:13,263][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ basketball] are: tensor([0.0872, 0.1365, 0.0081, 0.2623, 0.0017, 0.0898, 0.0724, 0.0727, 0.1519,
        0.0904, 0.0021, 0.0100, 0.0139, 0.0011], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:13,264][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ basketball] are: tensor([0.0017, 0.1320, 0.0946, 0.1147, 0.0739, 0.0573, 0.0838, 0.0344, 0.0897,
        0.0714, 0.0723, 0.1066, 0.0318, 0.0360], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:13,266][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ basketball] are: tensor([0.0124, 0.0298, 0.0868, 0.0435, 0.0904, 0.0906, 0.0606, 0.0480, 0.0825,
        0.0402, 0.1040, 0.0814, 0.0458, 0.1840], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:13,268][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ basketball] are: tensor([0.1101, 0.1900, 0.0584, 0.0368, 0.0657, 0.0918, 0.0481, 0.0688, 0.1146,
        0.0169, 0.0377, 0.0485, 0.0694, 0.0432], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:13,270][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ basketball] are: tensor([0.0333, 0.0807, 0.0371, 0.0751, 0.0249, 0.1399, 0.1189, 0.0534, 0.0655,
        0.0520, 0.0354, 0.1393, 0.0521, 0.0925], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:13,271][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ basketball] are: tensor([0.0019, 0.0521, 0.2034, 0.0354, 0.0657, 0.0907, 0.0178, 0.0681, 0.0777,
        0.0576, 0.1537, 0.0697, 0.0680, 0.0382], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:13,273][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ basketball] are: tensor([0.0014, 0.0429, 0.1217, 0.0310, 0.1130, 0.1146, 0.0289, 0.0488, 0.1282,
        0.0223, 0.1146, 0.1084, 0.0543, 0.0699], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:13,275][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ basketball] are: tensor([0.0774, 0.0981, 0.0509, 0.1080, 0.0603, 0.0473, 0.0668, 0.0576, 0.0574,
        0.0898, 0.0812, 0.0726, 0.0621, 0.0707], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:13,277][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0381, 0.0540, 0.0629, 0.0724, 0.0851, 0.0427, 0.0627, 0.0443, 0.0876,
        0.0807, 0.0698, 0.0456, 0.0524, 0.1283, 0.0732], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:13,278][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0003, 0.0438, 0.0110, 0.1517, 0.0082, 0.0093, 0.0522, 0.0397, 0.0283,
        0.2804, 0.0810, 0.0530, 0.0706, 0.0450, 0.1255], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:13,280][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0005, 0.0152, 0.0196, 0.0398, 0.0523, 0.0761, 0.0479, 0.0763, 0.0481,
        0.1115, 0.1056, 0.1282, 0.0850, 0.1116, 0.0824], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:13,282][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.1318, 0.0246, 0.0299, 0.0715, 0.0284, 0.0314, 0.0439, 0.0612, 0.0392,
        0.1076, 0.0728, 0.0645, 0.0954, 0.0737, 0.1241], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:13,283][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([8.7794e-02, 1.1225e-03, 8.8918e-03, 4.9095e-03, 2.4611e-02, 5.9315e-01,
        2.8391e-04, 3.3164e-03, 2.8147e-04, 5.3407e-03, 9.4000e-03, 2.5971e-01,
        1.0218e-03, 1.9546e-05, 1.4476e-04], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:13,285][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0026, 0.1022, 0.1011, 0.1193, 0.0924, 0.0408, 0.0285, 0.0434, 0.0950,
        0.0601, 0.0813, 0.0983, 0.0300, 0.0824, 0.0227], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:13,287][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0117, 0.0268, 0.0760, 0.0430, 0.0807, 0.0834, 0.0581, 0.0471, 0.0766,
        0.0392, 0.1006, 0.0799, 0.0455, 0.1735, 0.0580], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:13,289][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0991, 0.1329, 0.0707, 0.0272, 0.0848, 0.1027, 0.0412, 0.0784, 0.0864,
        0.0156, 0.0491, 0.0584, 0.0651, 0.0545, 0.0339], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:13,291][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0185, 0.0517, 0.0304, 0.0612, 0.0300, 0.1888, 0.0365, 0.0401, 0.0624,
        0.0417, 0.0293, 0.2064, 0.0468, 0.1221, 0.0340], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:13,292][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0034, 0.0482, 0.1671, 0.0296, 0.0772, 0.0558, 0.0061, 0.0709, 0.1021,
        0.0518, 0.1277, 0.0638, 0.0932, 0.0971, 0.0058], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:13,294][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0022, 0.0412, 0.1083, 0.0401, 0.1019, 0.1144, 0.0401, 0.0594, 0.0819,
        0.0227, 0.1070, 0.1070, 0.0613, 0.0719, 0.0408], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:13,296][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0770, 0.0937, 0.0477, 0.1010, 0.0567, 0.0449, 0.0629, 0.0530, 0.0534,
        0.0811, 0.0728, 0.0664, 0.0558, 0.0642, 0.0693], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:13,300][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:24:13,302][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[11696],
        [ 6176],
        [ 3869],
        [ 7296],
        [  624],
        [23294],
        [10091],
        [12419],
        [ 6735],
        [ 6875],
        [ 6084],
        [11763],
        [15245],
        [ 9938],
        [16841]], device='cuda:0')
[2024-07-24 10:24:13,303][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[11563],
        [ 3392],
        [ 3103],
        [ 3518],
        [  163],
        [18406],
        [ 6803],
        [ 9693],
        [ 7990],
        [ 4814],
        [ 4930],
        [ 6915],
        [10629],
        [ 7254],
        [10845]], device='cuda:0')
[2024-07-24 10:24:13,305][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[18486],
        [18486],
        [18489],
        [18290],
        [18474],
        [18456],
        [18456],
        [18480],
        [18479],
        [18300],
        [18477],
        [18474],
        [18480],
        [18459],
        [18473]], device='cuda:0')
[2024-07-24 10:24:13,307][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[13276],
        [11867],
        [ 9879],
        [ 9650],
        [ 8704],
        [ 7311],
        [ 7705],
        [ 7372],
        [ 7140],
        [ 6747],
        [ 7066],
        [ 6938],
        [ 7013],
        [ 7375],
        [ 7648]], device='cuda:0')
[2024-07-24 10:24:13,308][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[20792],
        [26217],
        [20809],
        [16173],
        [17838],
        [19215],
        [21149],
        [22697],
        [19456],
        [14791],
        [15909],
        [17970],
        [23309],
        [24817],
        [22609]], device='cuda:0')
[2024-07-24 10:24:13,310][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[24013],
        [24149],
        [23835],
        [23413],
        [23170],
        [24059],
        [24897],
        [25407],
        [25807],
        [25233],
        [24914],
        [24973],
        [25132],
        [25628],
        [26050]], device='cuda:0')
[2024-07-24 10:24:13,311][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[ 6908],
        [ 9031],
        [11716],
        [12568],
        [12556],
        [10480],
        [ 8939],
        [ 9978],
        [11340],
        [10483],
        [11244],
        [11657],
        [10727],
        [10426],
        [10211]], device='cuda:0')
[2024-07-24 10:24:13,313][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[29952],
        [ 8640],
        [ 6360],
        [ 7104],
        [ 5990],
        [ 5501],
        [ 6598],
        [ 6206],
        [ 8779],
        [ 7402],
        [ 8035],
        [ 9044],
        [ 7327],
        [ 8611],
        [ 7369]], device='cuda:0')
[2024-07-24 10:24:13,315][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[34101],
        [24316],
        [27690],
        [24664],
        [33723],
        [34017],
        [30421],
        [24828],
        [25672],
        [24598],
        [27900],
        [31180],
        [28472],
        [37171],
        [33977]], device='cuda:0')
[2024-07-24 10:24:13,317][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[25252],
        [25530],
        [29499],
        [29233],
        [33159],
        [30911],
        [30378],
        [27361],
        [25425],
        [26080],
        [26890],
        [25003],
        [24533],
        [26059],
        [25573]], device='cuda:0')
[2024-07-24 10:24:13,318][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[19174],
        [19148],
        [19791],
        [20051],
        [20140],
        [20172],
        [20284],
        [20344],
        [20418],
        [20575],
        [20921],
        [21141],
        [21306],
        [21572],
        [21504]], device='cuda:0')
[2024-07-24 10:24:13,320][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[38836],
        [38887],
        [38906],
        [38944],
        [38957],
        [38969],
        [38954],
        [39024],
        [39045],
        [39069],
        [39077],
        [39087],
        [39042],
        [39078],
        [39036]], device='cuda:0')
[2024-07-24 10:24:13,322][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[14845],
        [16755],
        [20144],
        [21448],
        [17269],
        [21904],
        [28236],
        [26939],
        [27561],
        [34602],
        [31737],
        [30693],
        [24541],
        [29824],
        [36861]], device='cuda:0')
[2024-07-24 10:24:13,323][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[33932],
        [34479],
        [31122],
        [33615],
        [34921],
        [30480],
        [30990],
        [33303],
        [31060],
        [31889],
        [27394],
        [25274],
        [23247],
        [20981],
        [22740]], device='cuda:0')
[2024-07-24 10:24:13,325][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 9880],
        [16865],
        [ 7941],
        [23571],
        [ 8905],
        [23303],
        [24851],
        [24678],
        [10914],
        [16692],
        [ 8682],
        [19222],
        [22305],
        [24633],
        [22686]], device='cuda:0')
[2024-07-24 10:24:13,327][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[29650],
        [26215],
        [27593],
        [27408],
        [27027],
        [26006],
        [26321],
        [26876],
        [26912],
        [25873],
        [25880],
        [25064],
        [25515],
        [24787],
        [25219]], device='cuda:0')
[2024-07-24 10:24:13,328][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[4339],
        [2244],
        [1995],
        [3598],
        [4389],
        [4367],
        [3906],
        [3825],
        [3846],
        [2862],
        [3880],
        [3762],
        [3465],
        [3501],
        [2786]], device='cuda:0')
[2024-07-24 10:24:13,330][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[11562],
        [16402],
        [15985],
        [17511],
        [18243],
        [16795],
        [17071],
        [18173],
        [17932],
        [17501],
        [17545],
        [16437],
        [15913],
        [16075],
        [15890]], device='cuda:0')
[2024-07-24 10:24:13,331][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[10655],
        [11208],
        [11536],
        [12047],
        [11749],
        [11707],
        [11475],
        [11041],
        [10746],
        [10769],
        [10806],
        [10769],
        [10688],
        [10663],
        [10564]], device='cuda:0')
[2024-07-24 10:24:13,333][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[17698],
        [17695],
        [ 8367],
        [ 7311],
        [ 2889],
        [16371],
        [12517],
        [16602],
        [ 2436],
        [11036],
        [ 3412],
        [ 7783],
        [16998],
        [ 3021],
        [ 9266]], device='cuda:0')
[2024-07-24 10:24:13,335][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[8317],
        [8936],
        [6809],
        [5823],
        [5994],
        [5795],
        [5472],
        [6104],
        [6343],
        [6200],
        [6424],
        [5970],
        [5856],
        [6226],
        [6219]], device='cuda:0')
[2024-07-24 10:24:13,336][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[11565],
        [11693],
        [13407],
        [12241],
        [12325],
        [12383],
        [11666],
        [11173],
        [11264],
        [11072],
        [11241],
        [11224],
        [11021],
        [11569],
        [11263]], device='cuda:0')
[2024-07-24 10:24:13,338][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[ 667],
        [4054],
        [1966],
        [2699],
        [3897],
        [3506],
        [2857],
        [1670],
        [1550],
        [1520],
        [1531],
        [2331],
        [1763],
        [2117],
        [1954]], device='cuda:0')
[2024-07-24 10:24:13,340][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[11296],
        [12701],
        [11961],
        [13637],
        [14526],
        [11355],
        [ 8072],
        [11050],
        [11750],
        [11499],
        [12118],
        [12705],
        [12813],
        [11915],
        [11493]], device='cuda:0')
[2024-07-24 10:24:13,341][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[16720],
        [16300],
        [22670],
        [24803],
        [24439],
        [22496],
        [23446],
        [22793],
        [22709],
        [20374],
        [19888],
        [21331],
        [20897],
        [21827],
        [21518]], device='cuda:0')
[2024-07-24 10:24:13,343][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[25910],
        [34333],
        [14062],
        [16339],
        [12412],
        [10304],
        [12533],
        [10220],
        [11048],
        [12381],
        [10366],
        [10315],
        [10089],
        [10170],
        [10820]], device='cuda:0')
[2024-07-24 10:24:13,344][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[12896],
        [13267],
        [14810],
        [15589],
        [17022],
        [17655],
        [18587],
        [19294],
        [19887],
        [20526],
        [21523],
        [22201],
        [22815],
        [23700],
        [24355]], device='cuda:0')
[2024-07-24 10:24:13,346][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[32828],
        [28036],
        [31604],
        [28697],
        [29044],
        [29014],
        [29040],
        [29678],
        [32615],
        [29549],
        [32339],
        [31043],
        [30426],
        [32756],
        [30433]], device='cuda:0')
[2024-07-24 10:24:13,348][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[44354],
        [23304],
        [37061],
        [24868],
        [40595],
        [20097],
        [32844],
        [21365],
        [37279],
        [45349],
        [43082],
        [28785],
        [24247],
        [30294],
        [37061]], device='cuda:0')
[2024-07-24 10:24:13,349][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[38862],
        [38862],
        [38862],
        [38862],
        [38862],
        [38862],
        [38862],
        [38862],
        [38862],
        [38862],
        [38862],
        [38862],
        [38862],
        [38862],
        [38862]], device='cuda:0')
[2024-07-24 10:24:13,389][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:24:13,391][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:13,392][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:13,393][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:13,395][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:13,396][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:13,397][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:13,399][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:13,400][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:13,401][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:13,402][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:13,404][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:13,405][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:13,406][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [,] are: tensor([9.9996e-01, 4.1100e-05], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:13,407][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [,] are: tensor([1.5198e-04, 9.9985e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:13,409][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0916, 0.9084], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:13,411][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.5389, 0.4611], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:13,412][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.9026, 0.0974], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:13,413][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [,] are: tensor([9.9959e-01, 4.1406e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:13,415][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.4350, 0.5650], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:13,417][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.5750, 0.4250], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:13,418][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [,] are: tensor([8.5565e-04, 9.9914e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:13,418][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.6926, 0.3074], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:13,419][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.4932, 0.5068], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:13,420][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.4644, 0.5356], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:13,420][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Erica] are: tensor([9.5636e-01, 1.3455e-06, 4.3640e-02], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:13,421][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Erica] are: tensor([6.9346e-06, 1.2100e-01, 8.7899e-01], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:13,423][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Erica] are: tensor([0.5685, 0.4041, 0.0274], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:13,424][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Erica] are: tensor([0.1101, 0.8552, 0.0347], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:13,426][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Erica] are: tensor([0.9215, 0.0435, 0.0350], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:13,427][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Erica] are: tensor([9.9402e-01, 5.3398e-03, 6.3812e-04], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:13,428][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Erica] are: tensor([0.9888, 0.0036, 0.0076], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:13,430][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Erica] are: tensor([0.4240, 0.2957, 0.2803], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:13,431][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Erica] are: tensor([0.0072, 0.2150, 0.7778], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:13,433][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Erica] are: tensor([0.5141, 0.2760, 0.2098], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:13,435][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Erica] are: tensor([0.3375, 0.3073, 0.3552], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:13,436][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Erica] are: tensor([0.3034, 0.3916, 0.3051], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:13,437][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ and] are: tensor([9.9820e-01, 1.2037e-04, 1.6385e-05, 1.6626e-03], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:13,439][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ and] are: tensor([7.2543e-06, 4.1905e-03, 1.6796e-01, 8.2784e-01], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:13,440][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0616, 0.7264, 0.1387, 0.0732], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:13,442][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.2127, 0.4768, 0.1558, 0.1547], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:13,443][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.8486, 0.0908, 0.0448, 0.0158], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:13,445][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ and] are: tensor([9.9927e-01, 4.0499e-04, 1.0823e-04, 2.2172e-04], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:13,446][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.8968, 0.0509, 0.0414, 0.0109], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:13,448][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.3550, 0.2140, 0.2786, 0.1524], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:13,450][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0009, 0.0595, 0.7500, 0.1896], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:13,451][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.4227, 0.1932, 0.1715, 0.2126], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:13,453][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.2287, 0.2496, 0.2986, 0.2231], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:13,454][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.2163, 0.2793, 0.2505, 0.2539], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:13,455][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Joshua] are: tensor([9.9938e-01, 7.9117e-07, 2.0829e-06, 3.8434e-06, 6.1554e-04],
       device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:13,456][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Joshua] are: tensor([2.2800e-07, 1.0955e-03, 3.1999e-02, 8.0045e-01, 1.6645e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:13,458][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Joshua] are: tensor([0.2149, 0.2481, 0.0248, 0.4100, 0.1022], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:13,460][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Joshua] are: tensor([0.1052, 0.5199, 0.0858, 0.2734, 0.0157], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:13,461][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Joshua] are: tensor([0.6733, 0.0693, 0.1818, 0.0377, 0.0379], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:13,462][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Joshua] are: tensor([9.9524e-01, 1.9596e-03, 3.9701e-04, 1.9215e-03, 4.8206e-04],
       device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:13,464][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Joshua] are: tensor([0.7121, 0.0011, 0.1937, 0.0817, 0.0114], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:13,465][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Joshua] are: tensor([0.3083, 0.1913, 0.1875, 0.1423, 0.1706], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:13,467][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Joshua] are: tensor([4.5526e-04, 5.2748e-03, 3.6099e-01, 6.2464e-02, 5.7082e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:13,468][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Joshua] are: tensor([0.2904, 0.1880, 0.1618, 0.2112, 0.1486], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:13,469][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Joshua] are: tensor([0.1944, 0.1900, 0.2288, 0.1740, 0.2128], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:13,470][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Joshua] are: tensor([0.1695, 0.2399, 0.1971, 0.2209, 0.1726], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:13,470][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ went] are: tensor([9.9791e-01, 3.5120e-05, 2.9105e-06, 4.8891e-05, 1.8715e-07, 2.0043e-03],
       device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:13,471][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ went] are: tensor([2.2862e-05, 3.7661e-05, 1.7039e-04, 1.2066e-02, 6.6043e-04, 9.8704e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:13,472][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ went] are: tensor([0.0381, 0.0781, 0.1350, 0.4083, 0.3317, 0.0088], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:13,474][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ went] are: tensor([0.1964, 0.2614, 0.0892, 0.4047, 0.0463, 0.0020], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:13,475][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ went] are: tensor([0.6199, 0.0949, 0.0799, 0.0443, 0.0897, 0.0713], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:13,476][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ went] are: tensor([9.9576e-01, 1.6083e-03, 1.6217e-04, 1.4847e-03, 1.7350e-04, 8.1254e-04],
       device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:13,478][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ went] are: tensor([0.8496, 0.0009, 0.0513, 0.0896, 0.0017, 0.0069], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:13,479][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ went] are: tensor([0.2400, 0.1707, 0.1847, 0.1307, 0.1679, 0.1060], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:13,481][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.0068, 0.0036, 0.2752, 0.0555, 0.4790, 0.1798], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:13,483][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ went] are: tensor([0.3329, 0.1429, 0.1241, 0.1680, 0.1068, 0.1253], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:13,484][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ went] are: tensor([0.1909, 0.1497, 0.1843, 0.1435, 0.1758, 0.1558], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:13,486][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ went] are: tensor([0.1580, 0.1876, 0.1662, 0.1930, 0.1457, 0.1494], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:13,487][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ to] are: tensor([9.9877e-01, 6.3882e-06, 3.0335e-06, 2.1287e-05, 1.4636e-06, 4.9758e-06,
        1.1920e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:13,488][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ to] are: tensor([1.3794e-06, 1.4871e-05, 1.2036e-04, 6.6893e-03, 9.8825e-04, 7.9026e-01,
        2.0192e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:13,490][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0065, 0.0874, 0.0545, 0.2241, 0.5566, 0.0580, 0.0131],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:13,492][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.1571, 0.3050, 0.1947, 0.1519, 0.0812, 0.1074, 0.0028],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:13,493][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.8465, 0.0364, 0.0455, 0.0142, 0.0236, 0.0153, 0.0185],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:13,495][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ to] are: tensor([9.8809e-01, 2.9109e-03, 7.3682e-04, 3.3923e-03, 5.5741e-04, 2.9714e-03,
        1.3362e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:13,496][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ to] are: tensor([9.9255e-01, 4.7937e-04, 1.4252e-04, 1.1823e-04, 7.8416e-06, 2.7507e-05,
        6.6761e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:13,497][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.2253, 0.1378, 0.1623, 0.1010, 0.1555, 0.1221, 0.0960],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:13,499][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0055, 0.0208, 0.2821, 0.0776, 0.2798, 0.2150, 0.1192],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:13,501][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.2987, 0.1196, 0.1059, 0.1346, 0.1105, 0.1294, 0.1014],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:13,502][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.1552, 0.1332, 0.1609, 0.1263, 0.1571, 0.1382, 0.1290],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:13,504][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.1169, 0.1558, 0.1418, 0.1523, 0.1378, 0.1281, 0.1673],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:13,505][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ the] are: tensor([9.9357e-01, 8.6773e-06, 3.0007e-05, 8.0251e-05, 1.2018e-06, 5.7050e-06,
        1.6927e-05, 6.2871e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:13,506][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ the] are: tensor([3.2416e-05, 1.3203e-06, 1.0882e-05, 2.7503e-04, 3.7171e-05, 2.1927e-02,
        5.8548e-03, 9.7186e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:13,508][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0154, 0.0874, 0.0265, 0.1164, 0.2724, 0.0573, 0.3960, 0.0286],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:13,509][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.1944, 0.3289, 0.0769, 0.1433, 0.2100, 0.0314, 0.0098, 0.0053],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:13,511][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.8228, 0.0442, 0.0429, 0.0125, 0.0249, 0.0155, 0.0170, 0.0202],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:13,513][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.9630, 0.0075, 0.0016, 0.0090, 0.0015, 0.0072, 0.0031, 0.0069],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:13,514][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ the] are: tensor([9.9095e-01, 6.0717e-04, 2.8787e-05, 5.9158e-05, 2.7254e-06, 7.0750e-06,
        2.3546e-03, 5.9933e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:13,516][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.2006, 0.1206, 0.1446, 0.0866, 0.1425, 0.1113, 0.0888, 0.1049],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:13,518][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0371, 0.0106, 0.3037, 0.0396, 0.2095, 0.1549, 0.1329, 0.1117],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:13,519][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.2507, 0.1054, 0.0972, 0.1218, 0.1032, 0.1138, 0.1180, 0.0900],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:13,520][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.1506, 0.1162, 0.1416, 0.1075, 0.1340, 0.1176, 0.1080, 0.1245],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:13,521][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0990, 0.1404, 0.1199, 0.1337, 0.1170, 0.1087, 0.1566, 0.1246],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:13,522][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ office] are: tensor([9.9507e-01, 6.2660e-07, 6.8403e-06, 3.9748e-06, 1.0894e-08, 1.6983e-07,
        1.2477e-06, 3.1047e-05, 4.8901e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:13,522][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ office] are: tensor([5.6526e-06, 4.7801e-07, 1.0833e-06, 9.8339e-05, 3.8241e-06, 3.9751e-03,
        1.4852e-03, 3.2139e-01, 6.7304e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:13,524][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ office] are: tensor([0.0049, 0.0271, 0.0037, 0.0735, 0.0587, 0.0505, 0.4467, 0.3279, 0.0070],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:13,525][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ office] are: tensor([0.0870, 0.3853, 0.0457, 0.2520, 0.1720, 0.0236, 0.0193, 0.0094, 0.0056],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:13,527][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ office] are: tensor([0.8610, 0.0196, 0.0591, 0.0049, 0.0343, 0.0067, 0.0040, 0.0054, 0.0050],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:13,529][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ office] are: tensor([0.9358, 0.0142, 0.0022, 0.0166, 0.0023, 0.0087, 0.0046, 0.0107, 0.0049],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:13,530][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ office] are: tensor([1.9524e-01, 5.7040e-05, 1.1034e-03, 2.0137e-03, 7.1057e-05, 6.0609e-04,
        1.5248e-01, 6.4742e-01, 1.0065e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:13,531][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ office] are: tensor([0.1662, 0.1125, 0.1048, 0.0874, 0.1162, 0.1109, 0.0905, 0.1021, 0.1094],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:13,533][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ office] are: tensor([0.1359, 0.0048, 0.0510, 0.0168, 0.0151, 0.0251, 0.0412, 0.0403, 0.6697],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:13,535][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ office] are: tensor([0.1900, 0.1081, 0.1047, 0.1200, 0.0913, 0.1148, 0.1019, 0.0917, 0.0774],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:13,536][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ office] are: tensor([0.1058, 0.1058, 0.1272, 0.0936, 0.1194, 0.1080, 0.0986, 0.1101, 0.1314],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:13,538][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ office] are: tensor([0.0852, 0.1164, 0.1018, 0.1150, 0.0978, 0.1102, 0.1411, 0.1232, 0.1092],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:13,539][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [.] are: tensor([9.9907e-01, 2.7388e-05, 8.4667e-06, 1.5437e-04, 6.0320e-06, 9.4883e-06,
        9.9620e-05, 5.3641e-04, 1.6002e-05, 7.0746e-05], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:13,540][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [.] are: tensor([3.6192e-06, 2.1292e-06, 2.4942e-05, 1.7114e-04, 4.1138e-05, 4.6339e-03,
        1.2946e-03, 1.6749e-01, 8.2309e-01, 3.2540e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:13,542][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [.] are: tensor([5.5810e-04, 1.5635e-02, 1.0686e-03, 2.0907e-02, 2.8539e-02, 3.4269e-03,
        5.6908e-02, 8.4045e-01, 2.1476e-02, 1.1029e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:13,543][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.2596, 0.1347, 0.0997, 0.1249, 0.2074, 0.0587, 0.0132, 0.0249, 0.0724,
        0.0045], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:13,545][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.9484, 0.0097, 0.0197, 0.0021, 0.0077, 0.0015, 0.0019, 0.0021, 0.0025,
        0.0044], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:13,547][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.9403, 0.0113, 0.0037, 0.0122, 0.0022, 0.0067, 0.0037, 0.0079, 0.0051,
        0.0069], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:13,548][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [.] are: tensor([9.5370e-01, 1.1561e-04, 8.2741e-06, 6.7165e-06, 2.2426e-07, 1.4606e-06,
        1.9031e-04, 1.2148e-03, 2.8562e-05, 4.4736e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:13,550][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.1677, 0.0936, 0.1048, 0.0665, 0.1063, 0.0917, 0.0672, 0.0912, 0.1257,
        0.0852], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:13,551][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.1306, 0.0174, 0.1072, 0.0267, 0.0469, 0.0368, 0.0399, 0.0212, 0.3818,
        0.1915], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:13,553][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.1967, 0.0914, 0.0846, 0.1073, 0.0814, 0.0861, 0.0851, 0.0937, 0.0730,
        0.1006], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:13,555][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.0964, 0.0909, 0.1122, 0.0833, 0.1105, 0.0985, 0.0918, 0.1050, 0.1262,
        0.0852], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:13,556][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0839, 0.1076, 0.0942, 0.0986, 0.0949, 0.0839, 0.1205, 0.1071, 0.0983,
        0.1111], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:13,558][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Erica] are: tensor([9.2417e-01, 9.9969e-07, 6.0206e-02, 4.4250e-06, 7.1496e-07, 6.6786e-07,
        1.1256e-06, 2.2431e-05, 1.3950e-06, 9.8638e-07, 1.5593e-02],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:13,559][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Erica] are: tensor([1.2752e-07, 1.4777e-06, 3.5957e-06, 1.1135e-04, 1.3129e-05, 4.9640e-03,
        3.1342e-03, 2.6608e-01, 6.9104e-01, 3.3320e-02, 1.3299e-03],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:13,561][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Erica] are: tensor([0.0160, 0.0148, 0.0008, 0.0349, 0.0240, 0.0050, 0.0703, 0.7510, 0.0049,
        0.0753, 0.0031], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:13,562][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Erica] are: tensor([0.0865, 0.4809, 0.0317, 0.2215, 0.1008, 0.0187, 0.0120, 0.0108, 0.0226,
        0.0046, 0.0099], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:13,564][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Erica] are: tensor([0.8323, 0.0279, 0.0170, 0.0052, 0.0467, 0.0052, 0.0051, 0.0075, 0.0093,
        0.0171, 0.0266], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:13,566][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Erica] are: tensor([0.8409, 0.0248, 0.0052, 0.0358, 0.0056, 0.0193, 0.0100, 0.0193, 0.0150,
        0.0152, 0.0088], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:13,567][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Erica] are: tensor([7.6204e-01, 5.7262e-06, 2.7194e-05, 6.2161e-05, 3.3721e-07, 3.7854e-06,
        3.0941e-03, 6.2076e-02, 5.6823e-05, 1.7041e-01, 2.2198e-03],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:13,569][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Erica] are: tensor([0.1455, 0.0883, 0.0752, 0.0652, 0.0903, 0.0935, 0.0660, 0.0865, 0.1108,
        0.0894, 0.0892], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:13,570][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Erica] are: tensor([6.3207e-03, 2.9206e-04, 2.7188e-03, 1.7544e-03, 1.2654e-03, 1.1809e-02,
        8.5442e-03, 2.0768e-02, 4.7707e-01, 4.1272e-01, 5.6731e-02],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:13,571][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Erica] are: tensor([0.1768, 0.0885, 0.0710, 0.1045, 0.0603, 0.0857, 0.0909, 0.0814, 0.0664,
        0.1006, 0.0740], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:13,572][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Erica] are: tensor([0.0930, 0.0909, 0.1067, 0.0780, 0.1009, 0.0888, 0.0804, 0.0899, 0.1084,
        0.0695, 0.0934], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:13,573][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Erica] are: tensor([0.0706, 0.0972, 0.0733, 0.0949, 0.0738, 0.0908, 0.1227, 0.1043, 0.0985,
        0.0981, 0.0758], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:13,574][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([9.9805e-01, 1.2899e-05, 2.2573e-06, 1.0288e-04, 1.1515e-06, 7.7515e-06,
        2.2285e-04, 4.0839e-05, 1.0976e-06, 2.5706e-05, 5.1500e-07, 1.5317e-03],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:13,575][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([1.4933e-06, 1.2034e-06, 2.5337e-06, 1.6182e-04, 4.3036e-06, 4.2872e-03,
        1.5208e-03, 1.8762e-01, 6.8658e-01, 5.6553e-02, 2.9905e-03, 6.0271e-02],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:13,577][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0015, 0.0113, 0.0075, 0.0243, 0.0181, 0.0019, 0.0807, 0.7111, 0.0036,
        0.1054, 0.0328, 0.0017], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:13,578][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.1677, 0.3265, 0.0612, 0.2748, 0.0884, 0.0120, 0.0194, 0.0078, 0.0156,
        0.0049, 0.0209, 0.0009], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:13,580][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.9026, 0.0134, 0.0124, 0.0046, 0.0117, 0.0067, 0.0028, 0.0064, 0.0058,
        0.0099, 0.0175, 0.0062], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:13,581][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([9.6713e-01, 4.7802e-03, 8.1577e-04, 4.8633e-03, 9.8539e-04, 3.2514e-03,
        1.8976e-03, 4.4976e-03, 2.9890e-03, 3.4401e-03, 2.3109e-03, 3.0427e-03],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:13,583][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([6.2480e-01, 1.0479e-04, 4.9736e-04, 3.6702e-04, 1.5575e-05, 5.1778e-05,
        5.4247e-03, 4.7494e-02, 7.3296e-04, 3.0806e-01, 5.9022e-03, 6.5444e-03],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:13,584][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.1302, 0.0810, 0.0856, 0.0571, 0.0817, 0.0747, 0.0606, 0.0827, 0.1026,
        0.0832, 0.1004, 0.0601], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:13,586][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.0148, 0.0017, 0.0085, 0.0049, 0.0030, 0.0107, 0.0129, 0.0244, 0.2387,
        0.3619, 0.0936, 0.2249], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:13,588][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.1735, 0.0870, 0.0683, 0.0916, 0.0594, 0.0753, 0.0874, 0.0773, 0.0628,
        0.0956, 0.0731, 0.0487], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:13,590][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0903, 0.0788, 0.0941, 0.0712, 0.0898, 0.0795, 0.0732, 0.0834, 0.1008,
        0.0676, 0.0928, 0.0786], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:13,591][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0672, 0.0896, 0.0776, 0.0878, 0.0732, 0.0741, 0.1081, 0.0930, 0.0919,
        0.0964, 0.0819, 0.0593], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:13,593][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ a] are: tensor([9.8491e-01, 8.9398e-06, 3.9926e-05, 6.2227e-05, 1.4954e-06, 1.5157e-05,
        6.9938e-05, 5.3178e-04, 7.9649e-06, 3.7638e-05, 1.2670e-05, 1.7253e-06,
        1.4304e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:13,594][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ a] are: tensor([5.1589e-05, 1.0006e-06, 2.5001e-06, 9.1830e-05, 5.8368e-06, 2.2585e-03,
        7.4082e-04, 1.1663e-01, 4.9986e-01, 2.9290e-02, 2.8628e-03, 4.9402e-02,
        2.9880e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:13,596][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0059, 0.0339, 0.0067, 0.0832, 0.1213, 0.0139, 0.1083, 0.0822, 0.1433,
        0.2608, 0.0439, 0.0808, 0.0159], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:13,597][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.1379, 0.3662, 0.0745, 0.1476, 0.1231, 0.0479, 0.0137, 0.0096, 0.0337,
        0.0044, 0.0315, 0.0085, 0.0016], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:13,599][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.8499, 0.0207, 0.0242, 0.0059, 0.0090, 0.0054, 0.0055, 0.0064, 0.0070,
        0.0191, 0.0268, 0.0080, 0.0118], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:13,601][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.8709, 0.0173, 0.0041, 0.0187, 0.0038, 0.0136, 0.0062, 0.0141, 0.0088,
        0.0108, 0.0080, 0.0123, 0.0114], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:13,602][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ a] are: tensor([9.6776e-01, 1.9511e-04, 6.0173e-06, 1.7366e-05, 2.9173e-07, 9.3963e-07,
        2.0376e-04, 1.0926e-03, 4.0958e-05, 2.6202e-02, 2.3322e-05, 1.3334e-03,
        3.1288e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:13,604][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.1217, 0.0734, 0.0799, 0.0524, 0.0795, 0.0665, 0.0541, 0.0692, 0.1104,
        0.0789, 0.0967, 0.0650, 0.0522], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:13,606][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.5292, 0.0029, 0.0168, 0.0042, 0.0009, 0.0020, 0.0072, 0.0023, 0.0702,
        0.0974, 0.0616, 0.1526, 0.0527], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:13,608][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.1734, 0.0735, 0.0668, 0.0849, 0.0681, 0.0790, 0.0759, 0.0590, 0.0528,
        0.0803, 0.0711, 0.0648, 0.0504], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:13,609][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0964, 0.0716, 0.0861, 0.0660, 0.0820, 0.0699, 0.0644, 0.0744, 0.0915,
        0.0607, 0.0861, 0.0718, 0.0790], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:13,611][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0616, 0.0867, 0.0759, 0.0822, 0.0736, 0.0701, 0.0963, 0.0815, 0.0808,
        0.0920, 0.0792, 0.0578, 0.0623], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:13,612][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ basketball] are: tensor([9.9701e-01, 1.7872e-06, 5.8550e-07, 6.8034e-06, 2.9440e-08, 1.3902e-06,
        2.4999e-07, 1.1072e-05, 3.2488e-07, 6.1999e-06, 6.9034e-08, 1.0267e-08,
        6.4569e-06, 2.9572e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:13,613][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ basketball] are: tensor([1.3199e-07, 6.1155e-07, 1.8974e-06, 1.1530e-04, 1.2363e-06, 3.1374e-03,
        7.6505e-04, 1.2532e-01, 1.5529e-01, 2.1191e-02, 1.3290e-03, 4.8672e-02,
        6.4187e-01, 2.3036e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:13,615][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ basketball] are: tensor([0.0066, 0.0199, 0.0014, 0.0574, 0.0102, 0.0259, 0.0831, 0.1813, 0.0065,
        0.0271, 0.0075, 0.0500, 0.5061, 0.0169], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:13,617][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ basketball] are: tensor([0.1429, 0.4598, 0.0473, 0.1804, 0.0538, 0.0221, 0.0152, 0.0070, 0.0194,
        0.0029, 0.0147, 0.0105, 0.0017, 0.0224], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:13,619][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ basketball] are: tensor([0.7124, 0.0263, 0.0653, 0.0074, 0.0324, 0.0072, 0.0050, 0.0067, 0.0105,
        0.0193, 0.0686, 0.0254, 0.0104, 0.0030], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:13,620][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ basketball] are: tensor([0.8921, 0.0104, 0.0025, 0.0169, 0.0025, 0.0072, 0.0043, 0.0097, 0.0075,
        0.0116, 0.0068, 0.0118, 0.0106, 0.0061], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:13,621][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ basketball] are: tensor([6.6339e-01, 3.8622e-06, 3.1728e-05, 2.4102e-05, 4.8687e-07, 2.3899e-06,
        1.1362e-03, 1.2953e-02, 2.6068e-05, 2.0255e-01, 1.8152e-03, 7.1261e-03,
        1.0944e-01, 1.5036e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:13,622][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ basketball] are: tensor([0.1145, 0.0718, 0.0689, 0.0525, 0.0704, 0.0709, 0.0546, 0.0638, 0.0906,
        0.0707, 0.0793, 0.0697, 0.0555, 0.0670], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:13,623][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ basketball] are: tensor([0.0351, 0.0007, 0.0062, 0.0022, 0.0011, 0.0034, 0.0045, 0.0062, 0.0981,
        0.1301, 0.0647, 0.2720, 0.3119, 0.0637], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:13,624][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ basketball] are: tensor([0.1444, 0.0700, 0.0639, 0.0791, 0.0592, 0.0851, 0.0736, 0.0563, 0.0537,
        0.0723, 0.0634, 0.0522, 0.0543, 0.0725], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:13,626][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ basketball] are: tensor([0.0682, 0.0704, 0.0830, 0.0621, 0.0791, 0.0706, 0.0645, 0.0716, 0.0854,
        0.0577, 0.0754, 0.0662, 0.0725, 0.0735], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:13,627][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ basketball] are: tensor([0.0527, 0.0773, 0.0651, 0.0763, 0.0610, 0.0675, 0.0948, 0.0784, 0.0812,
        0.0783, 0.0666, 0.0595, 0.0654, 0.0759], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:13,629][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ to] are: tensor([9.9827e-01, 6.5300e-06, 2.1086e-06, 1.7622e-05, 1.3974e-06, 3.9074e-06,
        1.2280e-03, 5.5864e-05, 2.8741e-07, 1.3152e-05, 6.6050e-07, 1.7309e-06,
        1.8372e-05, 6.1813e-07, 3.7936e-04], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:13,630][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ to] are: tensor([5.4441e-05, 1.2805e-06, 2.5174e-06, 1.0760e-04, 4.0108e-06, 2.2533e-03,
        5.9740e-04, 1.1126e-01, 2.6175e-01, 1.1550e-02, 1.5936e-03, 3.3306e-02,
        2.5418e-01, 2.5320e-02, 2.9802e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:13,632][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0005, 0.0073, 0.0029, 0.0215, 0.0231, 0.0044, 0.0006, 0.3416, 0.0217,
        0.0341, 0.0305, 0.0768, 0.3135, 0.1150, 0.0065], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:13,633][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.1161, 0.2648, 0.1723, 0.1163, 0.0767, 0.0811, 0.0034, 0.0185, 0.0337,
        0.0055, 0.0659, 0.0107, 0.0039, 0.0301, 0.0011], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:13,635][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.9202, 0.0105, 0.0147, 0.0025, 0.0060, 0.0016, 0.0032, 0.0027, 0.0016,
        0.0093, 0.0128, 0.0015, 0.0049, 0.0024, 0.0059], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:13,637][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.8714, 0.0112, 0.0040, 0.0154, 0.0031, 0.0099, 0.0052, 0.0114, 0.0079,
        0.0107, 0.0076, 0.0115, 0.0112, 0.0088, 0.0108], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:13,638][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ to] are: tensor([9.9425e-01, 1.5396e-04, 8.8599e-07, 2.5594e-06, 2.8707e-08, 1.0099e-07,
        1.4595e-05, 7.5231e-05, 1.8407e-06, 2.2624e-03, 1.3665e-06, 1.3319e-04,
        3.4159e-04, 9.5559e-06, 2.7505e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:13,640][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.1079, 0.0615, 0.0715, 0.0448, 0.0722, 0.0578, 0.0430, 0.0623, 0.0959,
        0.0639, 0.0830, 0.0592, 0.0543, 0.0797, 0.0431], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:13,642][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.5277, 0.0088, 0.0147, 0.0050, 0.0006, 0.0007, 0.0030, 0.0014, 0.0133,
        0.0296, 0.0077, 0.0136, 0.0153, 0.0720, 0.2866], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:13,643][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.1628, 0.0639, 0.0569, 0.0736, 0.0597, 0.0688, 0.0549, 0.0599, 0.0448,
        0.0709, 0.0583, 0.0491, 0.0534, 0.0724, 0.0505], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:13,645][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0776, 0.0618, 0.0733, 0.0577, 0.0718, 0.0604, 0.0568, 0.0643, 0.0803,
        0.0540, 0.0749, 0.0630, 0.0685, 0.0714, 0.0641], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:13,647][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0525, 0.0740, 0.0663, 0.0719, 0.0649, 0.0589, 0.0790, 0.0700, 0.0668,
        0.0787, 0.0674, 0.0512, 0.0592, 0.0694, 0.0699], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:13,689][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:24:13,691][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:13,692][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:13,693][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:13,695][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:13,696][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:13,697][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:13,697][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:13,698][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:13,699][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:13,700][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:13,700][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:13,701][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:13,702][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([1.0000e+00, 1.2845e-06], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:13,702][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.4803, 0.5197], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:13,703][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.8250, 0.1750], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:13,704][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.6642, 0.3358], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:13,704][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.4577, 0.5423], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:13,705][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.6157, 0.3843], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:13,706][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([9.2546e-05, 9.9991e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:13,706][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.5280, 0.4720], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:13,708][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.8439, 0.1561], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:13,710][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.2646, 0.7354], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:13,711][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.3156, 0.6844], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:13,713][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.8458, 0.1542], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:13,714][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Erica] are: tensor([9.9044e-01, 2.3608e-05, 9.5344e-03], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:13,716][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Erica] are: tensor([0.3208, 0.3551, 0.3241], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:13,717][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Erica] are: tensor([0.4458, 0.4394, 0.1148], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:13,719][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Erica] are: tensor([0.6010, 0.3121, 0.0869], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:13,721][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Erica] are: tensor([0.4475, 0.2044, 0.3480], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:13,722][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Erica] are: tensor([0.4465, 0.3527, 0.2007], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:13,723][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Erica] are: tensor([1.9849e-06, 9.2924e-01, 7.0754e-02], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:13,725][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Erica] are: tensor([0.3463, 0.4057, 0.2480], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:13,726][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Erica] are: tensor([0.0582, 0.9368, 0.0051], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:13,728][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Erica] are: tensor([0.0780, 0.6652, 0.2569], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:13,729][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Erica] are: tensor([0.2939, 0.3812, 0.3249], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:13,731][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Erica] are: tensor([0.0112, 0.9522, 0.0366], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:13,732][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([9.8194e-01, 4.6775e-05, 1.6364e-02, 1.6515e-03], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:13,734][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.2387, 0.2611, 0.2436, 0.2566], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:13,735][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0777, 0.0366, 0.8613, 0.0245], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:13,735][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.4036, 0.2312, 0.0734, 0.2918], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:13,736][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.3804, 0.1804, 0.2736, 0.1657], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:13,737][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.4020, 0.2252, 0.2202, 0.1525], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:13,738][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([1.9288e-06, 3.4491e-01, 1.1865e-01, 5.3643e-01], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:13,739][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2958, 0.3143, 0.2213, 0.1686], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:13,741][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.2113, 0.2881, 0.4852, 0.0155], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:13,742][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0707, 0.3194, 0.2008, 0.4092], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:13,744][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.2376, 0.3698, 0.1942, 0.1984], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:13,746][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.1283, 0.4896, 0.0464, 0.3357], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:13,747][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Joshua] are: tensor([9.9392e-01, 3.7021e-06, 5.7604e-03, 2.7845e-04, 3.5897e-05],
       device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:13,748][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Joshua] are: tensor([0.1889, 0.2133, 0.1964, 0.2102, 0.1912], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:13,750][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Joshua] are: tensor([0.1818, 0.0514, 0.1686, 0.5177, 0.0804], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:13,752][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Joshua] are: tensor([0.3685, 0.2133, 0.0542, 0.2499, 0.1142], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:13,753][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Joshua] are: tensor([0.2857, 0.1175, 0.2084, 0.1115, 0.2769], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:13,755][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Joshua] are: tensor([0.3236, 0.2173, 0.1658, 0.1621, 0.1312], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:13,756][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Joshua] are: tensor([9.2668e-07, 2.2323e-01, 2.2593e-02, 6.7396e-01, 8.0218e-02],
       device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:13,758][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Joshua] are: tensor([0.2108, 0.3088, 0.1902, 0.1436, 0.1467], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:13,759][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Joshua] are: tensor([0.0404, 0.6973, 0.0534, 0.1086, 0.1003], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:13,761][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Joshua] are: tensor([0.0268, 0.3202, 0.1497, 0.3653, 0.1379], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:13,763][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Joshua] are: tensor([0.2124, 0.2717, 0.1776, 0.1281, 0.2101], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:13,764][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Joshua] are: tensor([0.0054, 0.2303, 0.0431, 0.6735, 0.0478], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:13,765][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([9.8842e-01, 1.1285e-05, 1.0400e-02, 7.2523e-04, 9.0365e-05, 3.5182e-04],
       device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:13,767][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([0.1564, 0.1768, 0.1637, 0.1744, 0.1602, 0.1685], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:13,769][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([0.0082, 0.0051, 0.5086, 0.1338, 0.3416, 0.0026], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:13,770][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([0.2621, 0.1645, 0.0516, 0.2119, 0.1001, 0.2097], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:13,772][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([0.3277, 0.0946, 0.1451, 0.0861, 0.1535, 0.1931], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:13,774][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([0.2141, 0.1555, 0.1323, 0.2014, 0.1309, 0.1658], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:13,775][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([3.0976e-07, 1.6284e-01, 2.5454e-02, 5.2160e-01, 5.1816e-02, 2.3828e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:13,776][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([0.1887, 0.2381, 0.1642, 0.1300, 0.1400, 0.1391], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:13,778][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([0.0346, 0.1672, 0.3193, 0.2058, 0.2635, 0.0096], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:13,780][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([0.0271, 0.2261, 0.1295, 0.3201, 0.0925, 0.2046], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:13,781][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([0.1214, 0.2634, 0.1461, 0.1308, 0.1813, 0.1571], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:13,783][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([0.0084, 0.2355, 0.0228, 0.6906, 0.0304, 0.0124], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:13,784][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([9.8619e-01, 1.7846e-05, 1.1961e-02, 8.7863e-04, 1.3900e-04, 4.5740e-04,
        3.5447e-04], device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:13,785][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.1324, 0.1510, 0.1400, 0.1483, 0.1364, 0.1434, 0.1485],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:13,786][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([2.0793e-02, 6.0652e-03, 2.3759e-01, 7.4796e-02, 5.6042e-01, 1.0020e-01,
        1.3060e-04], device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:13,787][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.2512, 0.1328, 0.0471, 0.1578, 0.0904, 0.1716, 0.1491],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:13,788][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.3086, 0.0927, 0.1239, 0.0693, 0.1217, 0.1469, 0.1370],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:13,789][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.2586, 0.1527, 0.1223, 0.1041, 0.1397, 0.1130, 0.1096],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:13,790][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([6.3740e-08, 3.2677e-02, 1.2121e-02, 7.5567e-02, 1.9954e-02, 2.7667e-02,
        8.3201e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:13,791][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.1679, 0.2025, 0.1632, 0.1173, 0.1365, 0.1338, 0.0789],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:13,793][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0203, 0.3077, 0.0553, 0.1230, 0.4468, 0.0373, 0.0097],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:13,795][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0279, 0.1558, 0.0993, 0.2196, 0.1203, 0.2736, 0.1036],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:13,796][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0952, 0.2323, 0.1199, 0.1164, 0.1300, 0.1333, 0.1729],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:13,798][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0191, 0.1842, 0.0154, 0.3364, 0.0297, 0.0151, 0.4000],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:13,799][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([9.7688e-01, 5.0506e-05, 1.6964e-02, 1.7385e-03, 2.9484e-04, 9.3502e-04,
        7.2594e-04, 2.4136e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:13,801][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.1150, 0.1308, 0.1213, 0.1289, 0.1183, 0.1244, 0.1284, 0.1329],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:13,803][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0469, 0.0022, 0.0945, 0.0350, 0.4958, 0.2699, 0.0544, 0.0012],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:13,804][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.2193, 0.1282, 0.0415, 0.1441, 0.0795, 0.1601, 0.1305, 0.0967],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:13,806][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.2465, 0.0746, 0.1023, 0.0625, 0.1010, 0.1306, 0.1224, 0.1602],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:13,808][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.2262, 0.1225, 0.1548, 0.0846, 0.1179, 0.0908, 0.0925, 0.1107],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:13,809][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([5.4891e-08, 9.6230e-03, 3.2865e-03, 2.2253e-02, 4.5391e-03, 7.7298e-03,
        2.6781e-01, 6.8476e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:13,811][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.1526, 0.1664, 0.1456, 0.1096, 0.1303, 0.1255, 0.0823, 0.0875],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:13,812][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0234, 0.1535, 0.2271, 0.0518, 0.3565, 0.0894, 0.0852, 0.0130],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:13,814][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0309, 0.1252, 0.0979, 0.1968, 0.1262, 0.1845, 0.1886, 0.0497],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:13,816][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.1234, 0.1837, 0.1126, 0.0816, 0.1489, 0.1506, 0.0874, 0.1119],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:13,817][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0061, 0.0883, 0.0045, 0.1562, 0.0142, 0.0074, 0.5585, 0.1647],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:13,818][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ office] are: tensor([9.9099e-01, 6.2379e-06, 7.5858e-03, 4.2411e-04, 5.5074e-05, 1.8171e-04,
        1.4599e-04, 5.7156e-04, 3.7200e-05], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:13,820][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ office] are: tensor([0.1028, 0.1159, 0.1077, 0.1144, 0.1053, 0.1111, 0.1149, 0.1188, 0.1089],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:13,822][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ office] are: tensor([0.0220, 0.0090, 0.0338, 0.0684, 0.1933, 0.3078, 0.2269, 0.1348, 0.0041],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:13,823][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ office] are: tensor([0.1661, 0.1215, 0.0332, 0.1573, 0.0642, 0.1450, 0.1380, 0.0984, 0.0764],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:13,825][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ office] are: tensor([0.2476, 0.0886, 0.0922, 0.0494, 0.0880, 0.0888, 0.0908, 0.1317, 0.1227],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:13,827][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ office] are: tensor([0.1507, 0.1382, 0.1071, 0.0989, 0.0777, 0.1185, 0.0951, 0.1204, 0.0935],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:13,828][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ office] are: tensor([1.2873e-07, 1.3742e-03, 2.3121e-04, 3.0138e-03, 6.0941e-04, 1.8017e-03,
        3.8717e-02, 1.9615e-01, 7.5810e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:13,830][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ office] are: tensor([0.1430, 0.1318, 0.1301, 0.1037, 0.1217, 0.1316, 0.0840, 0.0908, 0.0633],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:13,831][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ office] are: tensor([0.0068, 0.1358, 0.1477, 0.1402, 0.3260, 0.0376, 0.1872, 0.0164, 0.0023],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:13,833][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ office] are: tensor([0.0138, 0.1501, 0.1028, 0.1745, 0.0737, 0.1619, 0.1395, 0.0669, 0.1167],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:13,835][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ office] are: tensor([0.1379, 0.1585, 0.1009, 0.0812, 0.0990, 0.1032, 0.0873, 0.0630, 0.1689],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:13,836][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ office] are: tensor([5.0035e-04, 7.8494e-02, 1.5841e-03, 8.6541e-02, 6.4050e-03, 4.1102e-03,
        5.4112e-01, 2.7858e-01, 2.6655e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:13,837][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([9.9146e-01, 4.2252e-06, 7.0850e-03, 3.9613e-04, 4.5332e-05, 1.8923e-04,
        1.3862e-04, 6.3775e-04, 3.5212e-05, 3.5042e-06], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:13,837][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.0901, 0.1029, 0.0971, 0.1021, 0.0948, 0.0997, 0.1021, 0.1062, 0.0979,
        0.1073], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:13,838][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.0885, 0.0081, 0.0673, 0.0681, 0.3326, 0.0866, 0.0477, 0.1260, 0.1736,
        0.0014], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:13,840][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.1818, 0.1107, 0.0353, 0.1254, 0.0650, 0.1332, 0.1138, 0.0835, 0.0739,
        0.0773], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:13,842][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.2224, 0.0731, 0.0819, 0.0506, 0.0708, 0.0941, 0.0887, 0.1211, 0.1339,
        0.0634], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:13,844][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.1862, 0.0899, 0.1022, 0.0651, 0.0894, 0.0873, 0.0877, 0.1131, 0.0922,
        0.0869], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:13,845][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([1.1450e-07, 1.4718e-03, 2.3744e-03, 5.0379e-03, 2.3775e-03, 2.3815e-03,
        4.4415e-02, 1.2648e-01, 7.2144e-01, 9.4017e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:13,846][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.1337, 0.1079, 0.1359, 0.1018, 0.1285, 0.1311, 0.0916, 0.0885, 0.0520,
        0.0291], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:13,848][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.0453, 0.2033, 0.0657, 0.0689, 0.1118, 0.0680, 0.0590, 0.1399, 0.1237,
        0.1144], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:13,849][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.0198, 0.1150, 0.0868, 0.1839, 0.0799, 0.1064, 0.0927, 0.0927, 0.1216,
        0.1011], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:13,851][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.1392, 0.1940, 0.0831, 0.0744, 0.0943, 0.0632, 0.0767, 0.0628, 0.1078,
        0.1044], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:13,853][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.0036, 0.0801, 0.0075, 0.1400, 0.0171, 0.0091, 0.3284, 0.3477, 0.0135,
        0.0529], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:13,854][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Erica] are: tensor([9.8808e-01, 1.2502e-05, 9.1841e-03, 6.4332e-04, 9.8449e-05, 3.4498e-04,
        2.5558e-04, 8.7871e-04, 6.5946e-05, 7.1369e-06, 4.3420e-04],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:13,856][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Erica] are: tensor([0.0828, 0.0948, 0.0870, 0.0932, 0.0848, 0.0894, 0.0921, 0.0955, 0.0877,
        0.0969, 0.0958], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:13,858][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Erica] are: tensor([0.0719, 0.0201, 0.0113, 0.1096, 0.1432, 0.0301, 0.1498, 0.3962, 0.0188,
        0.0409, 0.0081], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:13,859][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Erica] are: tensor([0.1759, 0.1037, 0.0274, 0.1253, 0.0555, 0.1299, 0.1051, 0.0852, 0.0701,
        0.0786, 0.0434], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:13,861][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Erica] are: tensor([0.1559, 0.0534, 0.0666, 0.0403, 0.0838, 0.0849, 0.0919, 0.1224, 0.1391,
        0.0694, 0.0921], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:13,863][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Erica] are: tensor([0.1249, 0.1039, 0.0612, 0.0627, 0.0488, 0.1303, 0.1103, 0.1208, 0.0819,
        0.0930, 0.0623], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:13,864][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Erica] are: tensor([5.7259e-09, 5.0232e-04, 2.6149e-04, 1.7343e-03, 4.5592e-04, 1.8498e-03,
        4.5707e-02, 1.1727e-01, 7.6417e-01, 6.7305e-02, 7.3732e-04],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:13,866][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Erica] are: tensor([0.1258, 0.1329, 0.1168, 0.0960, 0.1116, 0.1132, 0.0738, 0.0764, 0.0606,
        0.0326, 0.0604], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:13,867][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Erica] are: tensor([0.0143, 0.2304, 0.0033, 0.0639, 0.1072, 0.0726, 0.0737, 0.0293, 0.0462,
        0.3469, 0.0122], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:13,869][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Erica] are: tensor([0.0113, 0.1209, 0.0496, 0.1680, 0.0382, 0.1053, 0.1462, 0.0666, 0.1069,
        0.1257, 0.0612], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:13,871][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Erica] are: tensor([0.0976, 0.1083, 0.0791, 0.0701, 0.0960, 0.0787, 0.0844, 0.1004, 0.1140,
        0.0698, 0.1018], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:13,873][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Erica] are: tensor([0.0019, 0.0613, 0.0019, 0.0921, 0.0083, 0.0090, 0.3916, 0.2867, 0.0124,
        0.1178, 0.0170], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:13,874][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([9.8772e-01, 1.0480e-05, 9.4677e-03, 6.3856e-04, 8.8306e-05, 2.8253e-04,
        2.2718e-04, 8.5114e-04, 5.5055e-05, 6.7170e-06, 5.2436e-04, 1.3151e-04],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:13,875][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0751, 0.0857, 0.0796, 0.0845, 0.0779, 0.0819, 0.0844, 0.0877, 0.0807,
        0.0890, 0.0884, 0.0852], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:13,877][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([3.1791e-03, 3.2898e-03, 1.8314e-01, 2.7937e-02, 1.7010e-01, 6.4648e-03,
        7.4140e-02, 4.0426e-01, 1.6412e-02, 1.8368e-02, 9.2309e-02, 3.9024e-04],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:13,878][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.1353, 0.0895, 0.0270, 0.1146, 0.0503, 0.1137, 0.0992, 0.0731, 0.0643,
        0.0707, 0.0399, 0.1224], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:13,880][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.1945, 0.0564, 0.0616, 0.0397, 0.0521, 0.0743, 0.0742, 0.1059, 0.1098,
        0.0560, 0.0745, 0.1009], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:13,882][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.1004, 0.0894, 0.0904, 0.0622, 0.0733, 0.0846, 0.0609, 0.0981, 0.0551,
        0.1309, 0.0919, 0.0628], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:13,883][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([5.6178e-09, 8.0256e-04, 3.6560e-04, 3.0857e-03, 5.7817e-04, 1.4540e-03,
        3.3498e-02, 1.1832e-01, 7.7738e-01, 5.7277e-02, 3.5184e-04, 6.8839e-03],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:13,885][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.1173, 0.1303, 0.1120, 0.0867, 0.1030, 0.1052, 0.0693, 0.0744, 0.0544,
        0.0318, 0.0580, 0.0577], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:13,886][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.0542, 0.1987, 0.0161, 0.0761, 0.0422, 0.1487, 0.0516, 0.0259, 0.1400,
        0.1902, 0.0398, 0.0166], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:13,887][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.0131, 0.1240, 0.0481, 0.1301, 0.0365, 0.0926, 0.1580, 0.0674, 0.0943,
        0.1235, 0.0593, 0.0533], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:13,888][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0762, 0.1352, 0.0590, 0.0753, 0.0726, 0.1014, 0.0916, 0.0659, 0.0872,
        0.0713, 0.0745, 0.0900], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:13,888][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.0060, 0.0813, 0.0053, 0.2372, 0.0098, 0.0050, 0.3373, 0.1400, 0.0029,
        0.1083, 0.0412, 0.0257], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:13,890][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([9.7720e-01, 3.6660e-05, 1.4953e-02, 1.4250e-03, 2.4044e-04, 7.9341e-04,
        5.7953e-04, 1.8672e-03, 1.6870e-04, 2.2594e-05, 9.5239e-04, 2.7985e-04,
        1.4816e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:13,891][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0686, 0.0792, 0.0733, 0.0779, 0.0714, 0.0750, 0.0772, 0.0801, 0.0740,
        0.0814, 0.0811, 0.0780, 0.0829], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:13,892][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([1.1717e-02, 3.8395e-03, 2.8826e-02, 3.7082e-02, 4.4555e-01, 4.1525e-02,
        2.8125e-02, 1.4964e-02, 3.3406e-01, 1.7711e-02, 2.1549e-02, 1.4978e-02,
        6.9407e-05], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:13,894][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.1367, 0.0859, 0.0272, 0.0952, 0.0472, 0.1059, 0.0849, 0.0606, 0.0621,
        0.0627, 0.0392, 0.1129, 0.0794], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:13,896][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.1847, 0.0470, 0.0551, 0.0369, 0.0480, 0.0700, 0.0660, 0.0876, 0.0945,
        0.0481, 0.0604, 0.0912, 0.1106], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:13,897][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.1597, 0.0978, 0.0716, 0.0521, 0.0718, 0.0695, 0.0524, 0.0952, 0.0469,
        0.1070, 0.0639, 0.0482, 0.0639], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:13,899][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([1.3081e-09, 1.8792e-03, 1.9860e-03, 7.5757e-03, 2.9282e-03, 9.7764e-04,
        3.5730e-02, 8.4091e-02, 7.4215e-01, 4.7269e-02, 2.0058e-04, 6.2379e-03,
        6.8974e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:13,900][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.1072, 0.1084, 0.1096, 0.0854, 0.1016, 0.0976, 0.0691, 0.0707, 0.0521,
        0.0307, 0.0558, 0.0605, 0.0512], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:13,902][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0408, 0.1376, 0.0445, 0.0429, 0.1181, 0.0875, 0.0400, 0.0110, 0.0608,
        0.1887, 0.1136, 0.1074, 0.0071], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:13,904][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0213, 0.0906, 0.0618, 0.1254, 0.0690, 0.1161, 0.1035, 0.0304, 0.0717,
        0.0726, 0.0738, 0.1349, 0.0287], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:13,905][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0879, 0.1039, 0.0701, 0.0581, 0.0995, 0.0754, 0.0596, 0.0653, 0.0861,
        0.0615, 0.0912, 0.0778, 0.0635], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:13,907][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0387, 0.0905, 0.0015, 0.1196, 0.0060, 0.0067, 0.2626, 0.1359, 0.0035,
        0.1052, 0.0166, 0.0689, 0.1441], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:13,908][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ basketball] are: tensor([9.7760e-01, 2.2586e-05, 1.4161e-02, 1.2359e-03, 2.0303e-04, 6.8154e-04,
        5.5502e-04, 1.8999e-03, 1.7830e-04, 2.0899e-05, 1.1401e-03, 2.6302e-04,
        1.5600e-03, 4.7468e-04], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:13,910][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ basketball] are: tensor([0.0638, 0.0730, 0.0677, 0.0720, 0.0661, 0.0697, 0.0720, 0.0744, 0.0684,
        0.0756, 0.0749, 0.0724, 0.0771, 0.0732], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:13,912][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ basketball] are: tensor([0.0306, 0.0067, 0.0539, 0.1181, 0.1323, 0.3315, 0.1021, 0.1083, 0.0384,
        0.0060, 0.0317, 0.0231, 0.0108, 0.0066], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:13,914][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ basketball] are: tensor([0.0964, 0.0763, 0.0217, 0.0994, 0.0389, 0.0950, 0.0857, 0.0625, 0.0508,
        0.0594, 0.0318, 0.1016, 0.0852, 0.0951], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:13,915][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ basketball] are: tensor([0.1157, 0.0299, 0.0368, 0.0265, 0.0412, 0.0539, 0.0603, 0.0806, 0.0868,
        0.0486, 0.0598, 0.0674, 0.1002, 0.1924], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:13,917][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ basketball] are: tensor([0.1020, 0.0981, 0.0840, 0.0423, 0.0513, 0.0809, 0.0547, 0.0633, 0.0532,
        0.1079, 0.0765, 0.0663, 0.0564, 0.0631], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:13,919][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ basketball] are: tensor([3.8806e-08, 7.4081e-04, 2.6081e-04, 2.4285e-03, 4.2718e-04, 1.3140e-03,
        5.8826e-02, 1.6181e-01, 4.4152e-01, 1.6529e-01, 1.0738e-03, 1.0407e-02,
        1.5502e-01, 8.7399e-04], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:13,920][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ basketball] are: tensor([0.1078, 0.1207, 0.1030, 0.0776, 0.0902, 0.0918, 0.0573, 0.0640, 0.0499,
        0.0246, 0.0545, 0.0539, 0.0447, 0.0599], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:13,922][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ basketball] are: tensor([0.0262, 0.1280, 0.0547, 0.0687, 0.0685, 0.0374, 0.1016, 0.0226, 0.0185,
        0.1704, 0.1229, 0.1506, 0.0248, 0.0049], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:13,924][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ basketball] are: tensor([0.0102, 0.0972, 0.0510, 0.1109, 0.0497, 0.1227, 0.1128, 0.0364, 0.0816,
        0.0702, 0.0557, 0.0713, 0.0479, 0.0824], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:13,926][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ basketball] are: tensor([0.0878, 0.1112, 0.0612, 0.0629, 0.0654, 0.0565, 0.0622, 0.0465, 0.0939,
        0.0495, 0.0772, 0.0763, 0.0359, 0.1137], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:13,928][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ basketball] are: tensor([0.0020, 0.0244, 0.0009, 0.0487, 0.0021, 0.0014, 0.1892, 0.1285, 0.0028,
        0.0721, 0.0083, 0.0320, 0.4439, 0.0436], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:13,929][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([9.8151e-01, 2.1645e-05, 1.2075e-02, 1.0090e-03, 1.8027e-04, 6.3242e-04,
        4.3694e-04, 1.3535e-03, 1.1635e-04, 1.4350e-05, 7.5932e-04, 2.0702e-04,
        1.0481e-03, 3.4691e-04, 2.8433e-04], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:13,931][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0589, 0.0680, 0.0630, 0.0670, 0.0616, 0.0646, 0.0666, 0.0690, 0.0636,
        0.0700, 0.0696, 0.0671, 0.0714, 0.0681, 0.0715], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:13,932][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([1.2991e-02, 4.4444e-03, 1.0180e-01, 4.1511e-02, 2.6796e-01, 4.6553e-02,
        1.8338e-04, 1.6242e-01, 2.1350e-01, 4.9819e-03, 5.3083e-02, 4.0251e-02,
        5.8326e-03, 4.4441e-02, 5.3553e-05], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:13,934][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.1241, 0.0734, 0.0236, 0.0821, 0.0418, 0.0873, 0.0718, 0.0546, 0.0470,
        0.0521, 0.0325, 0.0890, 0.0680, 0.0895, 0.0632], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:13,936][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.1421, 0.0437, 0.0418, 0.0275, 0.0360, 0.0495, 0.0499, 0.0700, 0.0704,
        0.0381, 0.0475, 0.0667, 0.0841, 0.1291, 0.1036], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:13,937][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.1221, 0.0816, 0.0613, 0.0489, 0.0631, 0.0549, 0.0484, 0.0752, 0.0502,
        0.0831, 0.0626, 0.0534, 0.0623, 0.0800, 0.0529], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:13,937][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([1.9298e-09, 3.8062e-03, 5.5258e-03, 9.2584e-03, 5.5065e-03, 9.1111e-04,
        3.7896e-02, 8.6646e-02, 6.0018e-01, 5.4630e-02, 1.4550e-04, 5.9004e-03,
        1.0618e-01, 9.8340e-05, 8.3314e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:13,938][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.1015, 0.0935, 0.1096, 0.0776, 0.0950, 0.0967, 0.0620, 0.0616, 0.0408,
        0.0210, 0.0480, 0.0533, 0.0431, 0.0661, 0.0302], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:13,939][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0115, 0.1931, 0.0293, 0.0688, 0.1423, 0.0371, 0.0068, 0.0791, 0.0706,
        0.0892, 0.0409, 0.0960, 0.0344, 0.0827, 0.0182], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:13,941][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0107, 0.0783, 0.0446, 0.1126, 0.0586, 0.1204, 0.0504, 0.0472, 0.0583,
        0.0736, 0.0505, 0.0929, 0.0491, 0.1128, 0.0401], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:13,943][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0455, 0.1039, 0.0520, 0.0525, 0.0650, 0.0673, 0.0826, 0.0450, 0.0631,
        0.0559, 0.0682, 0.0958, 0.0359, 0.0850, 0.0824], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:13,944][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([8.2224e-03, 1.3809e-02, 5.1667e-04, 1.8523e-02, 1.4913e-03, 6.4998e-04,
        2.2455e-02, 3.6077e-02, 9.1142e-04, 1.1420e-02, 4.6876e-03, 1.1158e-02,
        1.0465e-01, 4.4909e-02, 7.2052e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:13,948][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:24:13,949][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[11683],
        [ 6764],
        [ 7175],
        [10886],
        [ 6090],
        [30292],
        [15489],
        [15922],
        [ 6570],
        [14482],
        [ 4197],
        [17140],
        [24802],
        [20175],
        [25075]], device='cuda:0')
[2024-07-24 10:24:13,951][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[11417],
        [ 5105],
        [ 4554],
        [ 5774],
        [ 5558],
        [23878],
        [ 9340],
        [10227],
        [ 4942],
        [ 6906],
        [ 7411],
        [13642],
        [14209],
        [10343],
        [15225]], device='cuda:0')
[2024-07-24 10:24:13,953][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[ 821],
        [ 821],
        [1136],
        [ 817],
        [ 819],
        [ 828],
        [ 822],
        [ 809],
        [ 831],
        [ 820],
        [1507],
        [ 831],
        [ 861],
        [ 843],
        [ 823]], device='cuda:0')
[2024-07-24 10:24:13,954][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[21453],
        [31261],
        [31224],
        [37637],
        [40095],
        [45073],
        [45011],
        [42818],
        [45132],
        [44837],
        [44708],
        [44821],
        [45015],
        [43620],
        [44049]], device='cuda:0')
[2024-07-24 10:24:13,956][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[29145],
        [23162],
        [25484],
        [19438],
        [19428],
        [12390],
        [12425],
        [12210],
        [ 6731],
        [ 2371],
        [ 3351],
        [ 3313],
        [12052],
        [24279],
        [11751]], device='cuda:0')
[2024-07-24 10:24:13,958][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[45200],
        [28319],
        [17712],
        [20218],
        [20134],
        [24444],
        [23299],
        [28053],
        [25007],
        [31640],
        [22548],
        [24133],
        [24058],
        [21782],
        [21963]], device='cuda:0')
[2024-07-24 10:24:13,960][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[47986],
        [48759],
        [48809],
        [48577],
        [47010],
        [45761],
        [48408],
        [48084],
        [48834],
        [48607],
        [48734],
        [48420],
        [48114],
        [46482],
        [48536]], device='cuda:0')
[2024-07-24 10:24:13,961][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[30902],
        [30844],
        [29674],
        [30696],
        [29444],
        [29571],
        [27187],
        [21094],
        [17295],
        [18116],
        [12050],
        [22610],
        [13058],
        [14034],
        [12941]], device='cuda:0')
[2024-07-24 10:24:13,963][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[14310],
        [ 1927],
        [13806],
        [ 9851],
        [ 6018],
        [ 8818],
        [14202],
        [14184],
        [15744],
        [13278],
        [10885],
        [ 9415],
        [13575],
        [ 9072],
        [14144]], device='cuda:0')
[2024-07-24 10:24:13,964][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[40282],
        [40817],
        [40448],
        [40615],
        [39761],
        [40593],
        [41242],
        [41366],
        [41178],
        [41134],
        [41223],
        [41335],
        [41436],
        [41809],
        [41819]], device='cuda:0')
[2024-07-24 10:24:13,966][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[15456],
        [43764],
        [40280],
        [38657],
        [40842],
        [39212],
        [37499],
        [37204],
        [13403],
        [19489],
        [15812],
        [15056],
        [13861],
        [14193],
        [24292]], device='cuda:0')
[2024-07-24 10:24:13,968][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[15226],
        [14225],
        [13004],
        [12897],
        [ 9855],
        [ 9663],
        [ 9926],
        [10658],
        [11625],
        [12576],
        [12772],
        [13125],
        [13056],
        [13378],
        [13519]], device='cuda:0')
[2024-07-24 10:24:13,969][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[ 4949],
        [12233],
        [15874],
        [20588],
        [22934],
        [24293],
        [27239],
        [27844],
        [28238],
        [29211],
        [28947],
        [29040],
        [29018],
        [29719],
        [29824]], device='cuda:0')
[2024-07-24 10:24:13,971][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[40931],
        [36011],
        [36888],
        [35674],
        [34635],
        [35635],
        [34679],
        [34987],
        [35774],
        [34729],
        [35116],
        [35061],
        [35520],
        [35527],
        [35126]], device='cuda:0')
[2024-07-24 10:24:13,973][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[22755],
        [35456],
        [11383],
        [16157],
        [ 4461],
        [32717],
        [22268],
        [27209],
        [24441],
        [21038],
        [ 2274],
        [19553],
        [30772],
        [32090],
        [23076]], device='cuda:0')
[2024-07-24 10:24:13,974][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[20900],
        [20900],
        [20610],
        [20378],
        [20733],
        [20564],
        [20516],
        [20267],
        [20644],
        [20658],
        [20559],
        [20549],
        [20266],
        [20284],
        [20380]], device='cuda:0')
[2024-07-24 10:24:13,976][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[25419],
        [25301],
        [25389],
        [25392],
        [25685],
        [25659],
        [25533],
        [25157],
        [25280],
        [25046],
        [25049],
        [24969],
        [24736],
        [24764],
        [24670]], device='cuda:0')
[2024-07-24 10:24:13,977][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[18738],
        [11834],
        [ 7324],
        [12402],
        [14659],
        [10959],
        [10033],
        [ 8221],
        [ 7684],
        [12880],
        [10483],
        [ 8946],
        [15349],
        [ 7570],
        [14587]], device='cuda:0')
[2024-07-24 10:24:13,979][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[20274],
        [22140],
        [22960],
        [24417],
        [25070],
        [25618],
        [25872],
        [25873],
        [25853],
        [25898],
        [26041],
        [25880],
        [25972],
        [25990],
        [26396]], device='cuda:0')
[2024-07-24 10:24:13,981][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[24743],
        [15010],
        [13060],
        [12104],
        [ 9867],
        [11801],
        [12504],
        [12058],
        [12071],
        [12124],
        [10461],
        [12023],
        [12792],
        [11828],
        [13039]], device='cuda:0')
[2024-07-24 10:24:13,982][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[ 9693],
        [22458],
        [33620],
        [29738],
        [33064],
        [29458],
        [29406],
        [27740],
        [27813],
        [26818],
        [26592],
        [27550],
        [26241],
        [26586],
        [24918]], device='cuda:0')
[2024-07-24 10:24:13,984][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[ 1472],
        [13801],
        [14539],
        [17900],
        [18024],
        [21125],
        [17095],
        [13210],
        [26781],
        [25505],
        [26289],
        [26597],
        [26954],
        [22485],
        [25064]], device='cuda:0')
[2024-07-24 10:24:13,986][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[12966],
        [14629],
        [14307],
        [13983],
        [13722],
        [13216],
        [12935],
        [13048],
        [12694],
        [12691],
        [12613],
        [12401],
        [12267],
        [12299],
        [12049]], device='cuda:0')
[2024-07-24 10:24:13,987][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[11317],
        [13004],
        [20783],
        [10255],
        [19848],
        [ 8127],
        [ 8636],
        [ 8878],
        [12431],
        [14614],
        [16727],
        [17319],
        [16275],
        [18974],
        [16007]], device='cuda:0')
[2024-07-24 10:24:13,989][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[39057],
        [27828],
        [27205],
        [26465],
        [22993],
        [24427],
        [24798],
        [25133],
        [27124],
        [26406],
        [27719],
        [27958],
        [27145],
        [27609],
        [27075]], device='cuda:0')
[2024-07-24 10:24:13,991][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[30365],
        [37732],
        [26076],
        [26452],
        [21539],
        [19016],
        [22665],
        [20803],
        [20493],
        [24804],
        [20655],
        [20848],
        [19781],
        [17634],
        [19728]], device='cuda:0')
[2024-07-24 10:24:13,992][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 3230],
        [ 4352],
        [11024],
        [15931],
        [24606],
        [24115],
        [27763],
        [29142],
        [27874],
        [28334],
        [28923],
        [30111],
        [30825],
        [37637],
        [32575]], device='cuda:0')
[2024-07-24 10:24:13,994][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[30741],
        [23363],
        [24102],
        [24283],
        [21187],
        [25013],
        [25352],
        [26972],
        [24449],
        [22085],
        [22406],
        [23064],
        [21136],
        [22102],
        [21867]], device='cuda:0')
[2024-07-24 10:24:13,995][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[24976],
        [14915],
        [15800],
        [ 9314],
        [10236],
        [ 7346],
        [ 7602],
        [ 7613],
        [ 8710],
        [ 8600],
        [13345],
        [ 7883],
        [ 7858],
        [13674],
        [ 7904]], device='cuda:0')
[2024-07-24 10:24:13,996][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[26484],
        [26484],
        [26484],
        [26484],
        [26484],
        [26484],
        [26484],
        [26484],
        [26484],
        [26484],
        [26484],
        [26484],
        [26484],
        [26484],
        [26484]], device='cuda:0')
[2024-07-24 10:24:14,047][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:24:14,048][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:14,048][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:14,049][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:14,050][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:14,050][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:14,051][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:14,052][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:14,052][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:14,053][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:14,054][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:14,054][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:14,055][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:14,056][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.3312, 0.6688], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:14,056][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.8937, 0.1063], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:14,057][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.5465, 0.4535], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:14,059][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.4321, 0.5679], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:14,059][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.8327, 0.1673], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:14,060][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.4709, 0.5291], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:14,061][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.4694, 0.5306], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:14,062][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.6501, 0.3499], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:14,063][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.7716, 0.2284], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:14,065][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0224, 0.9776], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:14,066][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.4204, 0.5796], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:14,067][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [,] are: tensor([4.6231e-05, 9.9995e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:14,069][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Erica] are: tensor([0.0055, 0.9783, 0.0162], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:14,071][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Erica] are: tensor([0.7651, 0.0016, 0.2333], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:14,072][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Erica] are: tensor([0.4109, 0.3187, 0.2703], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:14,074][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Erica] are: tensor([0.4239, 0.4543, 0.1218], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:14,075][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Erica] are: tensor([0.9238, 0.0334, 0.0428], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:14,077][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Erica] are: tensor([0.0378, 0.0422, 0.9200], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:14,078][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Erica] are: tensor([0.3422, 0.3296, 0.3282], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:14,080][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Erica] are: tensor([0.6350, 0.1559, 0.2091], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:14,082][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Erica] are: tensor([0.6148, 0.2074, 0.1778], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:14,083][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Erica] are: tensor([0.0117, 0.4937, 0.4946], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:14,085][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Erica] are: tensor([0.1739, 0.3263, 0.4998], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:14,086][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Erica] are: tensor([6.5161e-06, 6.4806e-01, 3.5194e-01], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:14,088][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0146, 0.9217, 0.0116, 0.0521], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:14,089][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.4867, 0.0094, 0.2088, 0.2950], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:14,091][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.2750, 0.2245, 0.2158, 0.2847], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:14,092][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.3258, 0.3568, 0.1351, 0.1823], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:14,094][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.3861, 0.1461, 0.1444, 0.3235], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:14,096][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0209, 0.0385, 0.9176, 0.0229], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:14,097][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.2440, 0.2555, 0.2633, 0.2373], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:14,099][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.3814, 0.1966, 0.1863, 0.2357], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:14,100][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.5241, 0.1667, 0.1441, 0.1651], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:14,102][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0078, 0.3426, 0.3478, 0.3018], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:14,104][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.2159, 0.2452, 0.3495, 0.1894], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:14,105][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ and] are: tensor([4.9848e-06, 3.9659e-01, 2.4147e-01, 3.6194e-01], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:14,106][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Joshua] are: tensor([0.0023, 0.9575, 0.0044, 0.0210, 0.0148], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:14,107][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Joshua] are: tensor([9.6676e-01, 2.9199e-04, 3.8701e-03, 8.7288e-03, 2.0349e-02],
       device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:14,108][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Joshua] are: tensor([0.2388, 0.1821, 0.1561, 0.2527, 0.1702], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:14,109][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Joshua] are: tensor([0.2699, 0.3484, 0.0920, 0.2047, 0.0850], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:14,109][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Joshua] are: tensor([0.7833, 0.0198, 0.0264, 0.1550, 0.0156], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:14,110][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Joshua] are: tensor([0.0229, 0.0325, 0.5948, 0.0321, 0.3177], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:14,112][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Joshua] are: tensor([0.1847, 0.1981, 0.2060, 0.1903, 0.2208], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:14,113][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Joshua] are: tensor([0.4720, 0.0847, 0.1219, 0.0890, 0.2324], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:14,115][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Joshua] are: tensor([0.4664, 0.1453, 0.1252, 0.1439, 0.1192], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:14,117][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Joshua] are: tensor([0.0059, 0.2566, 0.2627, 0.2319, 0.2428], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:14,118][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Joshua] are: tensor([0.1171, 0.2791, 0.3044, 0.1861, 0.1133], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:14,119][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Joshua] are: tensor([4.2121e-06, 3.1035e-01, 1.8496e-01, 2.7498e-01, 2.2971e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:14,121][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ went] are: tensor([0.0300, 0.8520, 0.0034, 0.0369, 0.0167, 0.0609], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:14,123][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ went] are: tensor([0.9735, 0.0028, 0.0044, 0.0031, 0.0032, 0.0130], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:14,124][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ went] are: tensor([0.2068, 0.1554, 0.1359, 0.2114, 0.1473, 0.1432], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:14,126][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ went] are: tensor([0.2209, 0.2778, 0.1003, 0.1723, 0.0812, 0.1475], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:14,128][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ went] are: tensor([0.7547, 0.0236, 0.0310, 0.1582, 0.0187, 0.0138], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:14,129][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ went] are: tensor([0.0073, 0.0112, 0.5259, 0.0180, 0.3504, 0.0872], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:14,131][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ went] are: tensor([0.1477, 0.1662, 0.1728, 0.1576, 0.1925, 0.1632], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:14,133][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ went] are: tensor([0.4213, 0.0581, 0.0949, 0.0446, 0.1635, 0.2176], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:14,134][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.2770, 0.1324, 0.1127, 0.1312, 0.1128, 0.2339], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:14,136][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ went] are: tensor([0.0046, 0.2047, 0.2131, 0.1823, 0.1961, 0.1992], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:14,137][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ went] are: tensor([0.1005, 0.2006, 0.1988, 0.1334, 0.0732, 0.2935], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:14,139][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ went] are: tensor([2.3726e-06, 2.4949e-01, 1.5159e-01, 2.2535e-01, 2.1174e-01, 1.6182e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:14,140][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0035, 0.5633, 0.0051, 0.0297, 0.0171, 0.3685, 0.0128],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:14,141][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ to] are: tensor([2.0432e-01, 4.7193e-04, 6.8087e-03, 1.0193e-02, 4.1738e-02, 2.2706e-01,
        5.0941e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:14,143][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1761, 0.1344, 0.1187, 0.1813, 0.1287, 0.1260, 0.1347],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:14,145][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.2045, 0.2592, 0.0874, 0.1385, 0.0753, 0.1390, 0.0960],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:14,146][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.5440, 0.0480, 0.0611, 0.2031, 0.0436, 0.0312, 0.0690],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:14,148][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0032, 0.0085, 0.5210, 0.0128, 0.3309, 0.1074, 0.0162],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:14,150][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1152, 0.1399, 0.1476, 0.1371, 0.1605, 0.1397, 0.1601],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:14,151][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.3132, 0.0660, 0.0768, 0.0600, 0.1408, 0.1935, 0.1497],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:14,153][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.2965, 0.1058, 0.0934, 0.1057, 0.0935, 0.1870, 0.1181],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:14,154][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0039, 0.1741, 0.1757, 0.1561, 0.1668, 0.1690, 0.1544],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:14,156][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.1197, 0.1783, 0.1905, 0.1323, 0.0549, 0.1540, 0.1702],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:14,157][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ to] are: tensor([3.3322e-06, 2.1394e-01, 1.2945e-01, 1.9246e-01, 1.7912e-01, 1.4689e-01,
        1.3814e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:14,158][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0032, 0.5811, 0.0030, 0.0258, 0.0128, 0.3102, 0.0331, 0.0307],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:14,159][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ the] are: tensor([1.1664e-01, 2.3968e-04, 1.1846e-03, 8.5112e-03, 7.9156e-03, 1.0570e-01,
        4.5411e-01, 3.0571e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:14,160][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.1618, 0.1219, 0.1018, 0.1657, 0.1098, 0.1083, 0.1164, 0.1143],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:14,160][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.1706, 0.2264, 0.0774, 0.1360, 0.0699, 0.1229, 0.0950, 0.1018],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:14,161][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.5654, 0.0396, 0.0486, 0.1725, 0.0321, 0.0234, 0.0566, 0.0618],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:14,163][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0034, 0.0062, 0.5283, 0.0066, 0.2829, 0.1165, 0.0378, 0.0182],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:14,165][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.1062, 0.1164, 0.1219, 0.1132, 0.1340, 0.1181, 0.1397, 0.1506],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:14,166][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.2271, 0.0660, 0.0698, 0.0567, 0.1430, 0.2041, 0.1468, 0.0865],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:14,168][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.2696, 0.0943, 0.0844, 0.0958, 0.0854, 0.1693, 0.1075, 0.0936],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:14,169][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0031, 0.1493, 0.1523, 0.1340, 0.1434, 0.1447, 0.1341, 0.1390],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:14,171][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.1044, 0.1538, 0.1590, 0.1082, 0.0508, 0.1842, 0.1314, 0.1083],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:14,172][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ the] are: tensor([6.3282e-06, 1.8694e-01, 1.0551e-01, 1.6288e-01, 1.4007e-01, 1.1889e-01,
        1.1893e-01, 1.6678e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:14,174][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ office] are: tensor([0.0090, 0.4634, 0.0068, 0.0247, 0.0227, 0.2576, 0.0324, 0.0558, 0.1276],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:14,175][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ office] are: tensor([5.3483e-01, 1.1191e-04, 6.4934e-04, 2.0314e-03, 1.6032e-03, 1.7327e-02,
        1.3410e-01, 1.4142e-01, 1.6793e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:14,176][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ office] are: tensor([0.1412, 0.1069, 0.0931, 0.1486, 0.0997, 0.0981, 0.1053, 0.1044, 0.1027],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:14,178][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ office] are: tensor([0.1574, 0.1999, 0.0642, 0.1162, 0.0606, 0.1142, 0.0881, 0.1147, 0.0848],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:14,180][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ office] are: tensor([0.6047, 0.0303, 0.0361, 0.1606, 0.0214, 0.0175, 0.0487, 0.0508, 0.0299],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:14,181][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ office] are: tensor([0.0101, 0.0161, 0.2772, 0.0208, 0.2047, 0.2299, 0.1013, 0.0561, 0.0838],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:14,183][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ office] are: tensor([0.0882, 0.0991, 0.1049, 0.1003, 0.1143, 0.1063, 0.1258, 0.1364, 0.1247],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:14,185][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ office] are: tensor([0.2579, 0.0426, 0.0653, 0.0398, 0.1241, 0.1867, 0.0985, 0.0480, 0.1372],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:14,187][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ office] are: tensor([0.2358, 0.0841, 0.0711, 0.0828, 0.0729, 0.1503, 0.0935, 0.0818, 0.1277],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:14,188][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ office] are: tensor([0.0030, 0.1314, 0.1345, 0.1172, 0.1237, 0.1265, 0.1176, 0.1231, 0.1230],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:14,190][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ office] are: tensor([0.0875, 0.1466, 0.1085, 0.0953, 0.0466, 0.1339, 0.1424, 0.1089, 0.1302],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:14,191][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ office] are: tensor([1.1196e-05, 1.5431e-01, 9.1130e-02, 1.3737e-01, 1.1620e-01, 1.0263e-01,
        9.9743e-02, 1.4427e-01, 1.5432e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:14,193][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.0044, 0.3953, 0.0025, 0.0259, 0.0093, 0.2467, 0.0493, 0.0549, 0.1674,
        0.0442], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:14,195][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.3540, 0.0016, 0.0052, 0.0069, 0.0031, 0.1923, 0.1694, 0.1830, 0.0520,
        0.0326], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:14,196][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.1162, 0.0895, 0.0865, 0.1132, 0.0916, 0.0889, 0.0926, 0.0938, 0.0944,
        0.1333], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:14,198][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.1270, 0.1617, 0.0697, 0.1052, 0.0609, 0.1167, 0.0710, 0.1044, 0.0962,
        0.0873], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:14,200][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.2091, 0.0755, 0.0756, 0.1555, 0.0636, 0.0470, 0.0706, 0.0783, 0.0535,
        0.1713], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:14,202][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.0043, 0.0081, 0.4019, 0.0093, 0.2788, 0.1207, 0.0295, 0.0498, 0.0878,
        0.0098], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:14,203][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0669, 0.0883, 0.0984, 0.0933, 0.1045, 0.0945, 0.1096, 0.1176, 0.1105,
        0.1162], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:14,205][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.1525, 0.0637, 0.0582, 0.0683, 0.1229, 0.1706, 0.1352, 0.0785, 0.1214,
        0.0287], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:14,207][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.2289, 0.0778, 0.0673, 0.0773, 0.0681, 0.1349, 0.0849, 0.0743, 0.1191,
        0.0673], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:14,208][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.0025, 0.1164, 0.1179, 0.1040, 0.1085, 0.1132, 0.1047, 0.1086, 0.1079,
        0.1163], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:14,210][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.1037, 0.1225, 0.1299, 0.0816, 0.0361, 0.1014, 0.1044, 0.0669, 0.1064,
        0.1471], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:14,211][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [.] are: tensor([4.1917e-06, 1.2904e-01, 7.5825e-02, 1.1659e-01, 1.0125e-01, 8.5134e-02,
        8.3840e-02, 1.2129e-01, 1.2852e-01, 1.5849e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:14,213][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Erica] are: tensor([0.0166, 0.2287, 0.0014, 0.0048, 0.0062, 0.0541, 0.0056, 0.0164, 0.0384,
        0.0159, 0.6119], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:14,214][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Erica] are: tensor([2.6860e-01, 7.5325e-05, 1.8791e-04, 9.9155e-04, 3.2507e-04, 5.1815e-02,
        6.1099e-02, 1.0573e-01, 3.7630e-01, 9.7055e-02, 3.7811e-02],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:14,215][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Erica] are: tensor([0.1137, 0.0840, 0.0699, 0.1108, 0.0734, 0.0730, 0.0787, 0.0776, 0.0758,
        0.1311, 0.1121], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:14,216][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Erica] are: tensor([0.1407, 0.1798, 0.0465, 0.1043, 0.0462, 0.0942, 0.0796, 0.0932, 0.0825,
        0.0847, 0.0483], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:14,218][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Erica] are: tensor([0.3372, 0.0320, 0.0402, 0.1248, 0.0275, 0.0199, 0.0445, 0.0478, 0.0307,
        0.1555, 0.1398], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:14,219][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Erica] are: tensor([0.0089, 0.0071, 0.1612, 0.0102, 0.1240, 0.1289, 0.0540, 0.0561, 0.0661,
        0.0285, 0.3551], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:14,221][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Erica] are: tensor([0.0669, 0.0770, 0.0836, 0.0807, 0.0894, 0.0851, 0.1004, 0.1067, 0.0959,
        0.1076, 0.1067], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:14,223][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Erica] are: tensor([0.2623, 0.0486, 0.0605, 0.0524, 0.1049, 0.1523, 0.0993, 0.0541, 0.1171,
        0.0211, 0.0272], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:14,224][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Erica] are: tensor([0.2109, 0.0710, 0.0597, 0.0705, 0.0630, 0.1285, 0.0796, 0.0698, 0.1078,
        0.0617, 0.0775], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:14,226][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Erica] are: tensor([0.0025, 0.1041, 0.1063, 0.0927, 0.0960, 0.1016, 0.0946, 0.0980, 0.0976,
        0.1064, 0.1003], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:14,228][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Erica] are: tensor([0.0470, 0.0979, 0.1414, 0.0571, 0.0518, 0.0982, 0.0777, 0.0765, 0.1039,
        0.1233, 0.1252], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:14,229][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Erica] are: tensor([1.1142e-05, 1.2201e-01, 6.5251e-02, 1.0631e-01, 8.4206e-02, 7.6948e-02,
        7.6864e-02, 1.0391e-01, 1.0251e-01, 1.4132e-01, 1.2066e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:14,231][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.0118, 0.1601, 0.0008, 0.0102, 0.0027, 0.0329, 0.0105, 0.0151, 0.0280,
        0.0091, 0.5701, 0.1488], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:14,232][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([5.0171e-01, 1.5203e-03, 1.4933e-03, 2.7098e-03, 4.2592e-04, 1.1144e-02,
        7.4775e-02, 4.6721e-02, 7.7999e-02, 1.3984e-01, 1.2304e-01, 1.8616e-02],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:14,234][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0976, 0.0730, 0.0647, 0.0974, 0.0690, 0.0682, 0.0728, 0.0725, 0.0714,
        0.1170, 0.1049, 0.0915], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:14,235][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.1063, 0.1561, 0.0541, 0.0914, 0.0457, 0.0889, 0.0701, 0.0869, 0.0758,
        0.0828, 0.0526, 0.0891], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:14,237][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.3054, 0.0303, 0.0373, 0.1101, 0.0256, 0.0196, 0.0418, 0.0464, 0.0295,
        0.1391, 0.1281, 0.0869], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:14,239][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.0031, 0.0043, 0.1759, 0.0071, 0.1601, 0.0258, 0.0208, 0.0318, 0.0452,
        0.0129, 0.4815, 0.0315], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:14,241][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0586, 0.0694, 0.0761, 0.0728, 0.0822, 0.0756, 0.0894, 0.0963, 0.0889,
        0.0959, 0.0989, 0.0959], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:14,242][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.2578, 0.0415, 0.0583, 0.0379, 0.0990, 0.1413, 0.0756, 0.0402, 0.1038,
        0.0156, 0.0226, 0.1065], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:14,244][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.1517, 0.0673, 0.0570, 0.0662, 0.0575, 0.1190, 0.0744, 0.0651, 0.1034,
        0.0586, 0.0729, 0.1069], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:14,246][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.0020, 0.0943, 0.0967, 0.0839, 0.0885, 0.0932, 0.0868, 0.0902, 0.0890,
        0.0981, 0.0933, 0.0840], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:14,247][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0575, 0.0900, 0.0798, 0.0641, 0.0362, 0.1276, 0.0903, 0.0702, 0.1082,
        0.1252, 0.0719, 0.0789], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:14,249][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([5.0293e-06, 1.0166e-01, 6.1038e-02, 9.1515e-02, 7.8347e-02, 6.8908e-02,
        6.6676e-02, 8.7766e-02, 9.3719e-02, 1.1729e-01, 1.1334e-01, 1.1973e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:14,250][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ a] are: tensor([2.2223e-04, 2.8899e-02, 2.6890e-04, 2.0476e-03, 1.6471e-03, 3.0251e-02,
        3.6390e-03, 3.2109e-03, 1.8739e-02, 1.0282e-02, 2.6257e-01, 6.3443e-01,
        3.7955e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:14,251][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ a] are: tensor([5.6625e-02, 8.4827e-05, 7.4082e-04, 2.8305e-03, 1.2269e-03, 1.4894e-01,
        1.4522e-01, 1.2444e-01, 2.8852e-02, 4.6062e-02, 4.4452e-02, 8.5140e-02,
        3.1539e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:14,253][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0934, 0.0685, 0.0582, 0.0911, 0.0615, 0.0611, 0.0656, 0.0646, 0.0636,
        0.1077, 0.0938, 0.0821, 0.0890], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:14,255][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.1198, 0.1527, 0.0462, 0.0861, 0.0406, 0.0765, 0.0637, 0.0686, 0.0680,
        0.0837, 0.0472, 0.0924, 0.0546], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:14,257][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.2656, 0.0267, 0.0371, 0.0980, 0.0268, 0.0199, 0.0399, 0.0440, 0.0280,
        0.1215, 0.1120, 0.0771, 0.1035], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:14,258][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0016, 0.0027, 0.1740, 0.0031, 0.1920, 0.0336, 0.0220, 0.0167, 0.0256,
        0.0094, 0.4656, 0.0464, 0.0072], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:14,260][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0566, 0.0642, 0.0688, 0.0644, 0.0756, 0.0664, 0.0787, 0.0841, 0.0806,
        0.0868, 0.0913, 0.0875, 0.0950], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:14,262][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.1785, 0.0376, 0.0462, 0.0352, 0.0926, 0.1472, 0.0935, 0.0466, 0.1074,
        0.0159, 0.0204, 0.0910, 0.0878], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:14,263][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.1687, 0.0603, 0.0530, 0.0610, 0.0533, 0.1069, 0.0675, 0.0599, 0.0942,
        0.0537, 0.0689, 0.0989, 0.0536], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:14,264][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0016, 0.0859, 0.0875, 0.0769, 0.0829, 0.0850, 0.0784, 0.0815, 0.0823,
        0.0900, 0.0886, 0.0786, 0.0808], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:14,265][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0424, 0.0962, 0.0987, 0.0619, 0.0361, 0.0916, 0.0797, 0.0584, 0.0852,
        0.1230, 0.0901, 0.0614, 0.0753], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:14,266][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ a] are: tensor([1.8971e-06, 8.5996e-02, 4.8630e-02, 7.3972e-02, 6.4535e-02, 5.5541e-02,
        5.2031e-02, 7.5941e-02, 8.1778e-02, 1.0390e-01, 9.5906e-02, 1.0536e-01,
        1.5640e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:14,267][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ basketball] are: tensor([1.0507e-02, 8.7697e-02, 2.7071e-04, 1.8990e-03, 8.3164e-04, 2.8410e-02,
        2.0203e-03, 3.8280e-03, 1.2556e-02, 4.6060e-03, 1.9436e-01, 1.9199e-01,
        2.6486e-03, 4.5838e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:14,268][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ basketball] are: tensor([5.4780e-01, 2.8252e-04, 4.8710e-04, 1.2450e-03, 4.5180e-04, 1.3352e-02,
        3.5686e-02, 2.5369e-02, 5.8776e-02, 7.5985e-02, 2.3240e-02, 1.8944e-02,
        1.6279e-01, 3.5583e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:14,270][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ basketball] are: tensor([0.0817, 0.0628, 0.0539, 0.0812, 0.0577, 0.0563, 0.0605, 0.0599, 0.0588,
        0.0962, 0.0852, 0.0746, 0.0815, 0.0896], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:14,272][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ basketball] are: tensor([0.1116, 0.1356, 0.0414, 0.0817, 0.0361, 0.0769, 0.0564, 0.0738, 0.0614,
        0.0676, 0.0418, 0.0911, 0.0665, 0.0582], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:14,273][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ basketball] are: tensor([0.1672, 0.0297, 0.0396, 0.0934, 0.0324, 0.0230, 0.0412, 0.0450, 0.0285,
        0.1104, 0.1128, 0.0792, 0.1008, 0.0967], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:14,275][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ basketball] are: tensor([0.0041, 0.0059, 0.1693, 0.0044, 0.1622, 0.0970, 0.0317, 0.0149, 0.0239,
        0.0137, 0.3701, 0.0497, 0.0163, 0.0366], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:14,277][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ basketball] are: tensor([0.0528, 0.0584, 0.0626, 0.0600, 0.0676, 0.0626, 0.0733, 0.0773, 0.0718,
        0.0792, 0.0823, 0.0796, 0.0882, 0.0843], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:14,278][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ basketball] are: tensor([0.2038, 0.0318, 0.0465, 0.0344, 0.0795, 0.1300, 0.0715, 0.0329, 0.0969,
        0.0129, 0.0189, 0.0840, 0.0632, 0.0937], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:14,280][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ basketball] are: tensor([0.1488, 0.0576, 0.0489, 0.0572, 0.0493, 0.0997, 0.0619, 0.0554, 0.0846,
        0.0502, 0.0618, 0.0907, 0.0501, 0.0839], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:14,282][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ basketball] are: tensor([0.0019, 0.0802, 0.0826, 0.0710, 0.0760, 0.0777, 0.0723, 0.0763, 0.0758,
        0.0831, 0.0803, 0.0713, 0.0750, 0.0765], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:14,284][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ basketball] are: tensor([0.0419, 0.0890, 0.0741, 0.0512, 0.0345, 0.0844, 0.0647, 0.0527, 0.0506,
        0.1169, 0.0662, 0.0610, 0.0731, 0.1400], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:14,285][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ basketball] are: tensor([2.9047e-06, 7.8211e-02, 4.3804e-02, 6.8630e-02, 5.6133e-02, 4.9268e-02,
        4.8917e-02, 6.9516e-02, 7.1796e-02, 8.9863e-02, 8.1528e-02, 8.6298e-02,
        1.3445e-01, 1.2158e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:14,286][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ to] are: tensor([9.5028e-04, 2.5429e-02, 3.0252e-04, 1.5422e-03, 8.4866e-04, 2.7361e-02,
        9.2305e-04, 5.6098e-03, 1.0417e-02, 5.2613e-03, 1.9857e-01, 2.3320e-01,
        4.7809e-03, 4.7510e-01, 9.7065e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:14,287][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ to] are: tensor([5.7479e-02, 2.6655e-05, 4.1981e-04, 1.5340e-03, 1.3117e-03, 1.0544e-01,
        9.7006e-02, 1.0093e-01, 1.9120e-02, 1.0899e-02, 1.6500e-02, 2.8696e-02,
        3.1918e-01, 5.2542e-02, 1.8892e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:14,289][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0779, 0.0578, 0.0498, 0.0747, 0.0522, 0.0518, 0.0553, 0.0546, 0.0541,
        0.0873, 0.0776, 0.0679, 0.0732, 0.0808, 0.0850], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:14,291][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0979, 0.1308, 0.0427, 0.0717, 0.0369, 0.0727, 0.0486, 0.0694, 0.0622,
        0.0657, 0.0434, 0.0874, 0.0601, 0.0620, 0.0486], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:14,293][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.1652, 0.0295, 0.0382, 0.0833, 0.0300, 0.0226, 0.0392, 0.0422, 0.0281,
        0.0978, 0.0976, 0.0675, 0.0868, 0.0789, 0.0933], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:14,294][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0014, 0.0035, 0.1919, 0.0050, 0.1347, 0.0528, 0.0060, 0.0224, 0.0373,
        0.0092, 0.3942, 0.0464, 0.0235, 0.0631, 0.0086], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:14,296][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0416, 0.0540, 0.0600, 0.0571, 0.0639, 0.0584, 0.0666, 0.0722, 0.0667,
        0.0719, 0.0738, 0.0734, 0.0794, 0.0774, 0.0837], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:14,298][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.1685, 0.0373, 0.0409, 0.0341, 0.0737, 0.1091, 0.0850, 0.0489, 0.0840,
        0.0164, 0.0177, 0.0709, 0.0778, 0.0757, 0.0601], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:14,300][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.1459, 0.0531, 0.0465, 0.0530, 0.0467, 0.0933, 0.0586, 0.0517, 0.0820,
        0.0465, 0.0596, 0.0861, 0.0469, 0.0793, 0.0509], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:14,302][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0015, 0.0753, 0.0751, 0.0668, 0.0708, 0.0738, 0.0671, 0.0704, 0.0711,
        0.0779, 0.0751, 0.0674, 0.0697, 0.0738, 0.0642], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:14,303][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0530, 0.0866, 0.0793, 0.0587, 0.0226, 0.0605, 0.0752, 0.0543, 0.0641,
        0.0993, 0.0739, 0.0393, 0.0759, 0.0892, 0.0682], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:14,304][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ to] are: tensor([1.1955e-06, 6.7147e-02, 3.7590e-02, 5.9419e-02, 5.1178e-02, 4.4277e-02,
        4.1711e-02, 6.0163e-02, 6.3214e-02, 8.0258e-02, 7.1833e-02, 8.1608e-02,
        1.2715e-01, 1.1879e-01, 9.5657e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:14,348][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:24:14,349][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:14,350][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:14,350][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:14,351][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:14,352][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:14,352][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:14,353][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:14,354][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:14,355][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:14,356][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:14,356][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:14,357][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:14,358][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.1917, 0.8083], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:14,359][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.2879, 0.7121], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:14,360][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.8036, 0.1964], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:14,362][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.4300, 0.5700], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:14,363][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.2426, 0.7574], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:14,365][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.4273, 0.5727], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:14,367][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.5302, 0.4698], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:14,368][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.5303, 0.4697], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:14,370][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.5369, 0.4631], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:14,371][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.2715, 0.7285], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:14,373][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.6012, 0.3988], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:14,375][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.9647, 0.0353], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:14,376][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Erica] are: tensor([0.0702, 0.7307, 0.1991], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:14,378][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Erica] are: tensor([0.2083, 0.4257, 0.3661], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:14,379][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Erica] are: tensor([0.5741, 0.1532, 0.2726], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:14,380][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Erica] are: tensor([0.2448, 0.3905, 0.3647], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:14,381][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Erica] are: tensor([0.1884, 0.5683, 0.2434], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:14,382][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Erica] are: tensor([0.0330, 0.9155, 0.0515], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:14,382][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Erica] are: tensor([0.3986, 0.3604, 0.2410], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:14,383][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Erica] are: tensor([0.2068, 0.0592, 0.7339], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:14,385][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Erica] are: tensor([0.4039, 0.3161, 0.2800], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:14,386][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Erica] are: tensor([0.1972, 0.3934, 0.4094], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:14,388][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Erica] are: tensor([0.3866, 0.2740, 0.3395], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:14,389][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Erica] are: tensor([2.1552e-07, 1.0000e+00, 6.5100e-10], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:14,390][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0353, 0.3399, 0.1349, 0.4898], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:14,392][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.1232, 0.3016, 0.2721, 0.3031], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:14,394][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.4931, 0.1696, 0.2424, 0.0949], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:14,395][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.1717, 0.2688, 0.3255, 0.2340], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:14,397][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.1657, 0.3939, 0.1949, 0.2456], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:14,398][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0233, 0.9158, 0.0408, 0.0201], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:14,400][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.3363, 0.2997, 0.2022, 0.1619], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:14,402][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0386, 0.0368, 0.1134, 0.8112], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:14,403][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.3227, 0.2427, 0.2110, 0.2236], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:14,405][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.1145, 0.2984, 0.3150, 0.2721], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:14,406][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.4209, 0.2289, 0.1731, 0.1772], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:14,407][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([8.8421e-08, 9.9993e-01, 6.5437e-05, 3.5295e-06], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:14,409][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Joshua] are: tensor([0.0227, 0.3123, 0.0856, 0.3811, 0.1983], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:14,411][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Joshua] are: tensor([0.1070, 0.2408, 0.2101, 0.2407, 0.2014], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:14,412][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Joshua] are: tensor([0.5478, 0.0922, 0.2475, 0.0570, 0.0555], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:14,414][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Joshua] are: tensor([0.1309, 0.2023, 0.2212, 0.2146, 0.2310], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:14,416][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Joshua] are: tensor([0.0889, 0.3520, 0.1775, 0.1824, 0.1991], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:14,417][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Joshua] are: tensor([0.0113, 0.8687, 0.0171, 0.0256, 0.0773], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:14,419][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Joshua] are: tensor([0.2809, 0.2562, 0.1651, 0.1321, 0.1656], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:14,420][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Joshua] are: tensor([0.0980, 0.0148, 0.4796, 0.1693, 0.2383], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:14,422][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Joshua] are: tensor([0.2607, 0.2012, 0.1781, 0.1873, 0.1728], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:14,424][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Joshua] are: tensor([0.1245, 0.2332, 0.2304, 0.2216, 0.1903], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:14,425][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Joshua] are: tensor([0.3370, 0.1966, 0.2087, 0.1141, 0.1435], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:14,427][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Joshua] are: tensor([3.9486e-10, 1.0000e+00, 1.4021e-08, 2.1545e-07, 2.1400e-08],
       device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:14,428][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([0.0318, 0.2168, 0.0667, 0.3995, 0.1640, 0.1212], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:14,430][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([0.0917, 0.1908, 0.1749, 0.2051, 0.1759, 0.1615], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:14,431][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([0.4667, 0.0991, 0.2154, 0.0721, 0.0453, 0.1014], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:14,432][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([0.0680, 0.1448, 0.2420, 0.1687, 0.2398, 0.1366], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:14,432][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([0.0594, 0.2383, 0.1351, 0.1507, 0.1515, 0.2651], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:14,433][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([0.0140, 0.8003, 0.0183, 0.0298, 0.0824, 0.0551], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:14,435][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([0.2467, 0.2199, 0.1433, 0.1141, 0.1491, 0.1270], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:14,436][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([0.0419, 0.0463, 0.2121, 0.3909, 0.0779, 0.2309], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:14,438][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([0.2116, 0.1685, 0.1478, 0.1571, 0.1441, 0.1708], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:14,440][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([0.1091, 0.1733, 0.1812, 0.1518, 0.1460, 0.2386], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:14,441][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([0.2556, 0.1691, 0.1298, 0.1073, 0.1005, 0.2377], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:14,442][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([1.0295e-06, 9.8986e-01, 1.5361e-06, 1.5596e-05, 9.1560e-03, 9.6169e-04],
       device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:14,444][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0356, 0.1992, 0.0712, 0.3074, 0.1496, 0.1091, 0.1279],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:14,446][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0713, 0.1612, 0.1517, 0.1657, 0.1473, 0.1405, 0.1624],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:14,448][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.3190, 0.1102, 0.2345, 0.0631, 0.0494, 0.1333, 0.0903],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:14,449][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0783, 0.1319, 0.1720, 0.1300, 0.1826, 0.1479, 0.1572],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:14,451][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0757, 0.2587, 0.1264, 0.1482, 0.1336, 0.1747, 0.0827],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:14,453][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0064, 0.6789, 0.0210, 0.0306, 0.0870, 0.1559, 0.0203],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:14,454][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.2178, 0.1948, 0.1292, 0.1045, 0.1355, 0.1183, 0.0999],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:14,456][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0425, 0.0285, 0.1649, 0.4751, 0.0640, 0.0397, 0.1853],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:14,458][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.1871, 0.1455, 0.1276, 0.1341, 0.1250, 0.1461, 0.1346],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:14,459][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0593, 0.1429, 0.1310, 0.1179, 0.1142, 0.2100, 0.2246],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:14,461][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.2382, 0.1549, 0.1155, 0.1185, 0.0966, 0.1564, 0.1200],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:14,462][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([9.0995e-10, 9.0963e-01, 1.4262e-06, 1.1121e-06, 1.7039e-03, 8.8657e-02,
        2.1897e-06], device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:14,463][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0244, 0.1959, 0.0555, 0.2525, 0.1149, 0.0906, 0.1032, 0.1630],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:14,465][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0590, 0.1440, 0.1282, 0.1441, 0.1272, 0.1246, 0.1448, 0.1281],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:14,467][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.4037, 0.0910, 0.2472, 0.0456, 0.0441, 0.0831, 0.0636, 0.0216],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:14,468][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0636, 0.1125, 0.1546, 0.1204, 0.1727, 0.1199, 0.1522, 0.1041],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:14,470][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0667, 0.2087, 0.1178, 0.1222, 0.1197, 0.1719, 0.0667, 0.1263],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:14,472][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.0077, 0.6811, 0.0159, 0.0220, 0.0662, 0.1295, 0.0383, 0.0393],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:14,474][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.2043, 0.1771, 0.1166, 0.0924, 0.1227, 0.1050, 0.0889, 0.0929],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:14,475][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0101, 0.0094, 0.0851, 0.0461, 0.0655, 0.0240, 0.0410, 0.7188],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:14,477][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.1640, 0.1274, 0.1114, 0.1176, 0.1087, 0.1285, 0.1179, 0.1245],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:14,479][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0369, 0.1036, 0.1091, 0.0875, 0.1027, 0.1519, 0.1895, 0.2187],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:14,481][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.2321, 0.1305, 0.1215, 0.0927, 0.0923, 0.1587, 0.0820, 0.0902],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:14,481][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([7.8214e-10, 9.7818e-01, 3.1470e-08, 4.1922e-06, 1.0393e-04, 2.1691e-02,
        2.1778e-05, 1.7801e-07], device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:14,482][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ office] are: tensor([0.0336, 0.1273, 0.0376, 0.2456, 0.0873, 0.0834, 0.1028, 0.1584, 0.1241],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:14,483][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ office] are: tensor([0.0525, 0.1242, 0.1127, 0.1300, 0.1138, 0.1073, 0.1292, 0.1185, 0.1118],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:14,484][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ office] are: tensor([0.2221, 0.1051, 0.1495, 0.0803, 0.0649, 0.1612, 0.0812, 0.0430, 0.0926],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:14,485][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ office] are: tensor([0.0593, 0.0912, 0.1234, 0.0930, 0.1423, 0.1010, 0.1242, 0.1248, 0.1409],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:14,487][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ office] are: tensor([0.0537, 0.1511, 0.1061, 0.1035, 0.0971, 0.1663, 0.0566, 0.1000, 0.1658],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:14,489][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ office] are: tensor([0.0122, 0.6446, 0.0097, 0.0197, 0.0370, 0.0963, 0.0337, 0.0524, 0.0945],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:14,490][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ office] are: tensor([0.1879, 0.1641, 0.1056, 0.0837, 0.1057, 0.0922, 0.0789, 0.0820, 0.0998],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:14,492][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ office] are: tensor([0.0171, 0.0187, 0.0521, 0.3820, 0.0244, 0.0145, 0.0665, 0.3520, 0.0728],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:14,494][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ office] are: tensor([0.1451, 0.1125, 0.0987, 0.1044, 0.0966, 0.1140, 0.1058, 0.1111, 0.1119],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:14,495][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ office] are: tensor([0.0511, 0.0890, 0.0835, 0.0762, 0.0669, 0.1243, 0.1594, 0.2191, 0.1304],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:14,497][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ office] are: tensor([0.2094, 0.1457, 0.0784, 0.0797, 0.0800, 0.1028, 0.0882, 0.0903, 0.1254],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:14,498][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ office] are: tensor([1.2753e-08, 9.9840e-01, 8.3597e-09, 6.3213e-07, 4.5850e-05, 1.5351e-03,
        7.0757e-07, 1.7955e-06, 1.1884e-05], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:14,500][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.0145, 0.1155, 0.0321, 0.1636, 0.0788, 0.0662, 0.0726, 0.1248, 0.1146,
        0.2172], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:14,502][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.0466, 0.1124, 0.1029, 0.1128, 0.1018, 0.0975, 0.1141, 0.1060, 0.1027,
        0.1032], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:14,503][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.2053, 0.0847, 0.2003, 0.0498, 0.0357, 0.1260, 0.0711, 0.0230, 0.1072,
        0.0970], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:14,505][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.0515, 0.0720, 0.1123, 0.0746, 0.1168, 0.1196, 0.1063, 0.1168, 0.1516,
        0.0784], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:14,507][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.0540, 0.1295, 0.0887, 0.0931, 0.0994, 0.1448, 0.0554, 0.1031, 0.1518,
        0.0802], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:14,509][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.0079, 0.4426, 0.0141, 0.0230, 0.0848, 0.1199, 0.0368, 0.0599, 0.1321,
        0.0789], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:14,510][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.1634, 0.1445, 0.0968, 0.0775, 0.1032, 0.0900, 0.0752, 0.0800, 0.0986,
        0.0708], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:14,512][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0154, 0.0153, 0.0593, 0.3548, 0.0281, 0.0103, 0.0522, 0.3951, 0.0250,
        0.0444], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:14,514][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.1223, 0.1012, 0.0901, 0.0954, 0.0887, 0.1037, 0.0951, 0.1003, 0.1024,
        0.1008], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:14,515][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.0304, 0.0710, 0.0733, 0.0615, 0.0623, 0.1032, 0.1301, 0.1579, 0.1105,
        0.1998], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:14,517][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.1833, 0.1128, 0.0710, 0.0704, 0.0563, 0.1075, 0.0787, 0.0671, 0.1301,
        0.1229], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:14,518][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([3.1930e-10, 7.5327e-01, 4.5700e-07, 3.7678e-06, 3.2220e-03, 2.1965e-01,
        7.7192e-05, 5.0405e-05, 2.3683e-02, 3.9284e-05], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:14,520][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Erica] are: tensor([0.0151, 0.0936, 0.0221, 0.1460, 0.0556, 0.0575, 0.0661, 0.1205, 0.0975,
        0.2033, 0.1229], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:14,522][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Erica] are: tensor([0.0464, 0.1045, 0.0878, 0.1047, 0.0884, 0.0867, 0.1045, 0.0972, 0.0921,
        0.0966, 0.0911], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:14,523][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Erica] are: tensor([0.2469, 0.0743, 0.1331, 0.0370, 0.0394, 0.0812, 0.0483, 0.0137, 0.0933,
        0.0759, 0.1567], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:14,525][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Erica] are: tensor([0.0598, 0.0798, 0.0862, 0.0691, 0.0929, 0.0749, 0.1027, 0.0808, 0.1430,
        0.0784, 0.1324], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:14,527][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Erica] are: tensor([0.0659, 0.1428, 0.0977, 0.0863, 0.0947, 0.1177, 0.0532, 0.0857, 0.1264,
        0.0690, 0.0607], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:14,528][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Erica] are: tensor([0.0377, 0.3305, 0.0042, 0.0076, 0.0152, 0.0525, 0.0137, 0.0331, 0.0350,
        0.0951, 0.3753], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:14,530][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Erica] are: tensor([0.1652, 0.1426, 0.0893, 0.0702, 0.0890, 0.0772, 0.0658, 0.0666, 0.0837,
        0.0603, 0.0901], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:14,531][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Erica] are: tensor([0.0277, 0.0097, 0.1117, 0.0765, 0.0431, 0.0352, 0.0675, 0.4234, 0.0927,
        0.0102, 0.1024], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:14,532][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Erica] are: tensor([0.1231, 0.0936, 0.0817, 0.0861, 0.0797, 0.0943, 0.0874, 0.0915, 0.0922,
        0.0927, 0.0777], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:14,533][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Erica] are: tensor([0.0571, 0.0579, 0.0522, 0.0518, 0.0390, 0.0809, 0.1152, 0.1431, 0.0872,
        0.1819, 0.1338], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:14,534][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Erica] are: tensor([0.1500, 0.0934, 0.1129, 0.0506, 0.0702, 0.0963, 0.0580, 0.0727, 0.1032,
        0.0817, 0.1110], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:14,535][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Erica] are: tensor([2.7592e-05, 9.8794e-01, 1.1029e-10, 9.8775e-08, 1.3594e-06, 5.5703e-05,
        1.7900e-08, 1.0370e-07, 1.1767e-06, 1.2902e-05, 1.1958e-02],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:14,537][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.0156, 0.0877, 0.0199, 0.1543, 0.0485, 0.0460, 0.0600, 0.1047, 0.0821,
        0.1856, 0.1036, 0.0921], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:14,539][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0359, 0.0945, 0.0859, 0.0978, 0.0856, 0.0770, 0.0968, 0.0882, 0.0890,
        0.0894, 0.0886, 0.0712], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:14,540][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.1912, 0.1197, 0.1358, 0.0409, 0.0300, 0.0518, 0.0633, 0.0253, 0.0756,
        0.0868, 0.1483, 0.0312], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:14,542][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.0263, 0.0619, 0.0890, 0.0581, 0.1038, 0.0673, 0.0867, 0.0744, 0.1266,
        0.0809, 0.1555, 0.0694], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:14,544][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.0493, 0.1158, 0.0886, 0.0771, 0.0817, 0.1199, 0.0479, 0.0870, 0.1379,
        0.0700, 0.0541, 0.0707], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:14,545][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.0056, 0.1445, 0.0046, 0.0089, 0.0176, 0.0183, 0.0043, 0.0154, 0.0322,
        0.0308, 0.6215, 0.0965], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:14,547][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.1418, 0.1274, 0.0821, 0.0654, 0.0854, 0.0746, 0.0635, 0.0666, 0.0816,
        0.0599, 0.0921, 0.0596], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:14,549][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0224, 0.0206, 0.0488, 0.3210, 0.0155, 0.0470, 0.0809, 0.2120, 0.0192,
        0.0516, 0.0645, 0.0967], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:14,551][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.1126, 0.0856, 0.0740, 0.0788, 0.0719, 0.0865, 0.0794, 0.0838, 0.0845,
        0.0847, 0.0706, 0.0877], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:14,552][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.0331, 0.0529, 0.0530, 0.0445, 0.0434, 0.0748, 0.0958, 0.1204, 0.0817,
        0.1647, 0.1436, 0.0919], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:14,554][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.1578, 0.0775, 0.0527, 0.0553, 0.0614, 0.1263, 0.0558, 0.0571, 0.1043,
        0.0883, 0.0575, 0.1058], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:14,555][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([1.3787e-10, 2.0838e-07, 5.0393e-11, 1.3744e-11, 2.7207e-08, 1.2760e-06,
        1.0249e-10, 8.2371e-12, 7.5185e-07, 2.8887e-10, 9.9973e-01, 2.6813e-04],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:14,557][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0156, 0.1019, 0.0258, 0.1380, 0.0520, 0.0484, 0.0555, 0.0873, 0.0820,
        0.1685, 0.0894, 0.0848, 0.0508], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:14,559][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0368, 0.0885, 0.0795, 0.0878, 0.0780, 0.0753, 0.0886, 0.0796, 0.0789,
        0.0808, 0.0815, 0.0690, 0.0756], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:14,561][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.1713, 0.0617, 0.1601, 0.0329, 0.0330, 0.0531, 0.0414, 0.0179, 0.0672,
        0.0729, 0.2180, 0.0396, 0.0307], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:14,562][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0318, 0.0581, 0.0772, 0.0657, 0.0850, 0.0636, 0.0830, 0.0631, 0.1122,
        0.0811, 0.1382, 0.0935, 0.0476], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:14,564][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0507, 0.1254, 0.0838, 0.0779, 0.0720, 0.1035, 0.0498, 0.0808, 0.1222,
        0.0641, 0.0504, 0.0622, 0.0572], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:14,566][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0021, 0.1137, 0.0039, 0.0052, 0.0244, 0.0224, 0.0067, 0.0166, 0.0386,
        0.0427, 0.5855, 0.1296, 0.0086], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:14,568][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.1332, 0.1176, 0.0773, 0.0617, 0.0823, 0.0712, 0.0601, 0.0632, 0.0788,
        0.0572, 0.0888, 0.0575, 0.0512], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:14,569][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0050, 0.0124, 0.0249, 0.0962, 0.0160, 0.0180, 0.0413, 0.5560, 0.0603,
        0.0169, 0.0409, 0.0335, 0.0786], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:14,571][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.1043, 0.0789, 0.0685, 0.0723, 0.0669, 0.0792, 0.0727, 0.0768, 0.0776,
        0.0778, 0.0653, 0.0805, 0.0792], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:14,573][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0136, 0.0486, 0.0490, 0.0407, 0.0463, 0.0717, 0.0950, 0.1071, 0.0753,
        0.1558, 0.1426, 0.0848, 0.0694], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:14,575][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.1130, 0.0831, 0.0709, 0.0572, 0.0610, 0.0909, 0.0482, 0.0534, 0.0888,
        0.0945, 0.0878, 0.0891, 0.0620], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:14,576][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([4.5436e-12, 1.0446e-04, 1.6128e-10, 6.6477e-10, 4.4015e-07, 1.4350e-04,
        6.4123e-09, 2.1448e-10, 1.5739e-06, 7.2495e-08, 9.2072e-01, 7.9025e-02,
        2.2358e-10], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:14,578][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ basketball] are: tensor([0.0186, 0.0665, 0.0158, 0.1241, 0.0343, 0.0494, 0.0566, 0.0741, 0.0661,
        0.1716, 0.0759, 0.0988, 0.0487, 0.0993], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:14,580][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ basketball] are: tensor([0.0355, 0.0826, 0.0714, 0.0832, 0.0694, 0.0683, 0.0835, 0.0752, 0.0733,
        0.0755, 0.0731, 0.0644, 0.0731, 0.0716], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:14,581][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ basketball] are: tensor([0.1124, 0.0512, 0.1636, 0.0359, 0.0303, 0.0849, 0.0395, 0.0219, 0.0978,
        0.0678, 0.1881, 0.0378, 0.0429, 0.0258], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:14,581][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ basketball] are: tensor([0.0392, 0.0521, 0.0741, 0.0565, 0.0817, 0.0575, 0.0698, 0.0647, 0.0956,
        0.0608, 0.1173, 0.0760, 0.0530, 0.1017], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:14,582][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ basketball] are: tensor([0.0656, 0.1174, 0.0757, 0.0719, 0.0773, 0.1001, 0.0481, 0.0775, 0.1169,
        0.0583, 0.0432, 0.0510, 0.0532, 0.0439], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:14,583][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ basketball] are: tensor([0.0287, 0.2049, 0.0027, 0.0030, 0.0070, 0.0148, 0.0043, 0.0057, 0.0149,
        0.0196, 0.2518, 0.0446, 0.0035, 0.3945], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:14,585][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ basketball] are: tensor([0.1337, 0.1172, 0.0748, 0.0595, 0.0747, 0.0657, 0.0564, 0.0573, 0.0700,
        0.0524, 0.0763, 0.0503, 0.0446, 0.0670], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:14,587][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ basketball] are: tensor([0.0137, 0.0319, 0.0416, 0.3018, 0.0182, 0.0230, 0.0734, 0.1788, 0.0978,
        0.0137, 0.0368, 0.0347, 0.0327, 0.1018], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:14,588][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ basketball] are: tensor([0.0969, 0.0730, 0.0641, 0.0676, 0.0624, 0.0735, 0.0681, 0.0717, 0.0721,
        0.0722, 0.0610, 0.0747, 0.0739, 0.0688], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:14,590][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ basketball] are: tensor([0.0329, 0.0462, 0.0405, 0.0389, 0.0328, 0.0610, 0.0843, 0.1110, 0.0678,
        0.1288, 0.1010, 0.0777, 0.0762, 0.1010], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:14,592][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ basketball] are: tensor([0.1243, 0.0913, 0.0542, 0.0441, 0.0621, 0.0799, 0.0455, 0.0462, 0.0484,
        0.0914, 0.0578, 0.0709, 0.0470, 0.1371], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:14,593][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ basketball] are: tensor([1.6705e-07, 6.7069e-03, 6.3351e-11, 1.8276e-10, 3.5005e-08, 9.3416e-06,
        3.4032e-10, 5.7750e-10, 1.2102e-07, 5.6044e-09, 1.4295e-01, 3.2021e-03,
        1.7247e-09, 8.4713e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:14,595][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0186, 0.0826, 0.0230, 0.1033, 0.0438, 0.0405, 0.0399, 0.0637, 0.0623,
        0.1175, 0.0620, 0.0612, 0.0381, 0.0735, 0.1700], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:14,596][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0297, 0.0739, 0.0695, 0.0752, 0.0668, 0.0640, 0.0735, 0.0698, 0.0687,
        0.0698, 0.0715, 0.0567, 0.0683, 0.0710, 0.0716], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:14,598][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1612, 0.0634, 0.1337, 0.0350, 0.0290, 0.0770, 0.0493, 0.0150, 0.0653,
        0.0609, 0.1626, 0.0486, 0.0294, 0.0244, 0.0454], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:14,600][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0304, 0.0481, 0.0641, 0.0469, 0.0676, 0.0572, 0.0548, 0.0609, 0.0931,
        0.0571, 0.1067, 0.0803, 0.0567, 0.1147, 0.0614], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:14,602][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0520, 0.1181, 0.0782, 0.0772, 0.0721, 0.0898, 0.0520, 0.0683, 0.0969,
        0.0555, 0.0475, 0.0580, 0.0515, 0.0397, 0.0433], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:14,603][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0024, 0.0757, 0.0017, 0.0037, 0.0058, 0.0192, 0.0020, 0.0079, 0.0150,
        0.0241, 0.1820, 0.0767, 0.0080, 0.5615, 0.0142], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:14,605][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.1207, 0.1044, 0.0686, 0.0556, 0.0723, 0.0638, 0.0532, 0.0559, 0.0690,
        0.0498, 0.0771, 0.0504, 0.0449, 0.0672, 0.0470], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:14,607][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0172, 0.0157, 0.0609, 0.2128, 0.0244, 0.0173, 0.0741, 0.2017, 0.0143,
        0.0187, 0.0780, 0.0421, 0.0377, 0.1147, 0.0706], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:14,609][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0900, 0.0689, 0.0598, 0.0631, 0.0584, 0.0690, 0.0631, 0.0667, 0.0672,
        0.0677, 0.0567, 0.0698, 0.0687, 0.0642, 0.0667], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:14,610][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0196, 0.0462, 0.0396, 0.0353, 0.0348, 0.0634, 0.0682, 0.0873, 0.0631,
        0.1293, 0.1103, 0.0728, 0.0568, 0.1071, 0.0664], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:14,612][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.1154, 0.0731, 0.0527, 0.0525, 0.0408, 0.0734, 0.0503, 0.0491, 0.0706,
        0.0763, 0.0650, 0.0669, 0.0546, 0.1074, 0.0519], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:14,614][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([3.0676e-13, 1.1613e-07, 1.6115e-13, 9.6327e-14, 1.6754e-10, 5.0899e-08,
        2.7896e-13, 5.6398e-13, 6.5416e-09, 1.9122e-11, 2.9955e-04, 3.0910e-05,
        3.7014e-12, 9.9967e-01, 2.3204e-09], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:14,617][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:24:14,619][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[11135],
        [ 5891],
        [ 9546],
        [10966],
        [20024],
        [17623],
        [10854],
        [12027],
        [ 8553],
        [14277],
        [ 7194],
        [17254],
        [18124],
        [19693],
        [22492]], device='cuda:0')
[2024-07-24 10:24:14,621][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[10953],
        [ 2330],
        [ 4635],
        [ 4876],
        [18007],
        [15270],
        [ 6298],
        [ 6709],
        [ 1828],
        [ 6465],
        [ 2676],
        [ 9296],
        [13950],
        [13278],
        [14144]], device='cuda:0')
[2024-07-24 10:24:14,623][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[18086],
        [10777],
        [10375],
        [10814],
        [10488],
        [11827],
        [20182],
        [18602],
        [13753],
        [13144],
        [ 9983],
        [12754],
        [26093],
        [16701],
        [17827]], device='cuda:0')
[2024-07-24 10:24:14,625][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[14098],
        [18607],
        [18027],
        [24170],
        [14524],
        [15003],
        [24458],
        [26076],
        [24446],
        [28124],
        [26495],
        [26521],
        [28604],
        [23987],
        [26903]], device='cuda:0')
[2024-07-24 10:24:14,626][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[19689],
        [19003],
        [16479],
        [15865],
        [15450],
        [15354],
        [15305],
        [15225],
        [15293],
        [15529],
        [15850],
        [15865],
        [15819],
        [15499],
        [15828]], device='cuda:0')
[2024-07-24 10:24:14,628][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[8658],
        [8809],
        [9053],
        [9417],
        [7623],
        [6804],
        [6725],
        [6760],
        [6569],
        [6447],
        [6772],
        [7252],
        [7190],
        [6990],
        [6883]], device='cuda:0')
[2024-07-24 10:24:14,629][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[15694],
        [20705],
        [17990],
        [22101],
        [18374],
        [18940],
        [20943],
        [21394],
        [21522],
        [23977],
        [22594],
        [22994],
        [23467],
        [23370],
        [23556]], device='cuda:0')
[2024-07-24 10:24:14,631][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[33701],
        [40510],
        [50001],
        [49999],
        [49882],
        [49707],
        [49657],
        [49561],
        [47017],
        [49091],
        [49330],
        [49916],
        [49909],
        [49553],
        [49631]], device='cuda:0')
[2024-07-24 10:24:14,633][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[44344],
        [43667],
        [43194],
        [44091],
        [43887],
        [44503],
        [45386],
        [45846],
        [46003],
        [46270],
        [46182],
        [46158],
        [46348],
        [46416],
        [46583]], device='cuda:0')
[2024-07-24 10:24:14,634][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[18744],
        [17696],
        [16347],
        [15430],
        [13073],
        [11715],
        [11573],
        [11082],
        [10386],
        [10298],
        [10837],
        [10703],
        [10422],
        [10556],
        [10810]], device='cuda:0')
[2024-07-24 10:24:14,636][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[17661],
        [22247],
        [25747],
        [27053],
        [28407],
        [29853],
        [29917],
        [30355],
        [30721],
        [30578],
        [30756],
        [30470],
        [30412],
        [29910],
        [30023]], device='cuda:0')
[2024-07-24 10:24:14,637][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[ 7572],
        [ 8818],
        [ 9650],
        [ 9920],
        [10587],
        [11086],
        [11224],
        [11441],
        [12077],
        [11944],
        [12001],
        [11977],
        [11957],
        [12337],
        [12198]], device='cuda:0')
[2024-07-24 10:24:14,639][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[33534],
        [34048],
        [31918],
        [32723],
        [32269],
        [32651],
        [33084],
        [33756],
        [33832],
        [33296],
        [33059],
        [33653],
        [33809],
        [33963],
        [34199]], device='cuda:0')
[2024-07-24 10:24:14,641][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[35715],
        [31883],
        [33430],
        [34031],
        [34743],
        [34737],
        [34718],
        [34969],
        [35683],
        [36163],
        [36564],
        [36975],
        [37077],
        [37112],
        [37322]], device='cuda:0')
[2024-07-24 10:24:14,642][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 5127],
        [12123],
        [ 2489],
        [ 9571],
        [ 2840],
        [ 2231],
        [ 5168],
        [ 4463],
        [ 8622],
        [23885],
        [ 3204],
        [ 3177],
        [ 3602],
        [  374],
        [ 8327]], device='cuda:0')
[2024-07-24 10:24:14,644][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[11360],
        [27186],
        [27252],
        [25701],
        [25317],
        [24162],
        [24027],
        [24137],
        [23783],
        [23233],
        [23192],
        [22980],
        [23134],
        [22698],
        [23181]], device='cuda:0')
[2024-07-24 10:24:14,646][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[13094],
        [14187],
        [15908],
        [15769],
        [15074],
        [15497],
        [14605],
        [14635],
        [14282],
        [15069],
        [15366],
        [15565],
        [15824],
        [15439],
        [15000]], device='cuda:0')
[2024-07-24 10:24:14,648][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[5614],
        [7724],
        [4932],
        [5586],
        [5133],
        [5329],
        [5504],
        [5150],
        [5684],
        [5337],
        [4040],
        [4722],
        [3641],
        [3789],
        [4340]], device='cuda:0')
[2024-07-24 10:24:14,649][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[15248],
        [10254],
        [14468],
        [13491],
        [11051],
        [11804],
        [11565],
        [11228],
        [ 9555],
        [ 9204],
        [10177],
        [10339],
        [10061],
        [ 9653],
        [ 9343]], device='cuda:0')
[2024-07-24 10:24:14,651][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[26405],
        [ 4686],
        [ 3990],
        [ 3713],
        [ 2966],
        [ 1401],
        [ 1676],
        [ 1495],
        [ 1269],
        [ 1418],
        [ 1605],
        [ 1260],
        [ 1351],
        [ 1308],
        [ 1293]], device='cuda:0')
[2024-07-24 10:24:14,652][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[ 2010],
        [14684],
        [18127],
        [18330],
        [16838],
        [15171],
        [11862],
        [11478],
        [11733],
        [ 8977],
        [19866],
        [21186],
        [20706],
        [19952],
        [18799]], device='cuda:0')
[2024-07-24 10:24:14,654][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[4036],
        [3321],
        [3416],
        [3684],
        [3682],
        [3632],
        [3708],
        [3754],
        [3771],
        [3859],
        [3842],
        [3864],
        [3912],
        [4083],
        [4148]], device='cuda:0')
[2024-07-24 10:24:14,656][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[45117],
        [39983],
        [15438],
        [14831],
        [12172],
        [14140],
        [15963],
        [17658],
        [16947],
        [17309],
        [16780],
        [18940],
        [18835],
        [17070],
        [17804]], device='cuda:0')
[2024-07-24 10:24:14,657][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[8925],
        [5723],
        [5913],
        [5978],
        [5683],
        [5706],
        [5762],
        [5993],
        [6195],
        [6336],
        [6456],
        [6485],
        [6594],
        [6639],
        [6711]], device='cuda:0')
[2024-07-24 10:24:14,659][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[17354],
        [ 6370],
        [ 5227],
        [ 5228],
        [ 4324],
        [ 3928],
        [ 4372],
        [ 4208],
        [ 4012],
        [ 3680],
        [ 3512],
        [ 3291],
        [ 3300],
        [ 3190],
        [ 3113]], device='cuda:0')
[2024-07-24 10:24:14,661][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[16813],
        [16632],
        [18778],
        [18105],
        [19119],
        [16727],
        [19182],
        [21433],
        [22008],
        [20338],
        [19613],
        [17807],
        [19053],
        [18919],
        [20140]], device='cuda:0')
[2024-07-24 10:24:14,662][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[14583],
        [14994],
        [31795],
        [31794],
        [31795],
        [31644],
        [32164],
        [31936],
        [31805],
        [31319],
        [31527],
        [12989],
        [14068],
        [13358],
        [13948]], device='cuda:0')
[2024-07-24 10:24:14,664][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[43605],
        [44160],
        [41539],
        [41949],
        [42922],
        [43417],
        [43563],
        [43270],
        [43574],
        [44212],
        [42084],
        [43326],
        [43330],
        [44081],
        [44065]], device='cuda:0')
[2024-07-24 10:24:14,665][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[43337],
        [33428],
        [47545],
        [40013],
        [46881],
        [48995],
        [45357],
        [46149],
        [46712],
        [37083],
        [48669],
        [49073],
        [47324],
        [50136],
        [46124]], device='cuda:0')
[2024-07-24 10:24:14,667][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[6081],
        [6081],
        [6081],
        [6081],
        [6081],
        [6081],
        [6081],
        [6081],
        [6081],
        [6081],
        [6081],
        [6081],
        [6081],
        [6081],
        [6081]], device='cuda:0')
[2024-07-24 10:24:14,723][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:24:14,724][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:14,726][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:14,727][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:14,729][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:14,730][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:14,731][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:14,733][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:14,734][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:14,736][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:14,737][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:14,739][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:14,740][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:14,741][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.9662, 0.0338], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:14,742][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0188, 0.9812], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:14,743][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0052, 0.9948], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:14,744][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.2821, 0.7179], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:14,745][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0254, 0.9746], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:14,747][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.4363, 0.5637], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:14,748][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.9532, 0.0468], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:14,750][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.1425, 0.8575], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:14,751][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.7822, 0.2178], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:14,753][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.6605, 0.3395], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:14,755][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.3938, 0.6062], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:14,756][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.2391, 0.7609], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:14,758][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Erica] are: tensor([0.9037, 0.0360, 0.0602], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:14,759][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Erica] are: tensor([6.3401e-01, 3.6599e-01, 4.7746e-06], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:14,761][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Erica] are: tensor([0.0025, 0.4842, 0.5133], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:14,762][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Erica] are: tensor([0.1515, 0.4241, 0.4245], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:14,764][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Erica] are: tensor([0.0192, 0.5086, 0.4722], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:14,765][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Erica] are: tensor([0.7403, 0.0614, 0.1983], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:14,767][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Erica] are: tensor([0.9033, 0.0485, 0.0483], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:14,769][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Erica] are: tensor([0.0590, 0.4627, 0.4783], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:14,770][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Erica] are: tensor([0.6881, 0.1786, 0.1334], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:14,772][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Erica] are: tensor([0.6006, 0.1895, 0.2099], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:14,773][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Erica] are: tensor([0.2536, 0.3390, 0.4074], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:14,775][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Erica] are: tensor([0.1440, 0.3582, 0.4978], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:14,776][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.8630, 0.0304, 0.0639, 0.0426], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:14,778][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0298, 0.8388, 0.0089, 0.1225], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:14,780][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0014, 0.3182, 0.3413, 0.3391], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:14,781][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.1062, 0.2952, 0.2954, 0.3032], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:14,783][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0073, 0.3398, 0.3294, 0.3235], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:14,785][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1942, 0.1299, 0.6230, 0.0530], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:14,786][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.8875, 0.0402, 0.0418, 0.0305], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:14,788][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0479, 0.3212, 0.3103, 0.3205], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:14,790][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.5528, 0.1640, 0.1306, 0.1526], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:14,791][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.3730, 0.1982, 0.2119, 0.2169], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:14,792][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.1927, 0.2474, 0.3006, 0.2593], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:14,793][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0726, 0.2291, 0.2724, 0.4259], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:14,793][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Joshua] are: tensor([0.8635, 0.0220, 0.0459, 0.0331, 0.0354], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:14,794][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Joshua] are: tensor([5.9585e-01, 3.9805e-01, 7.1054e-05, 5.7713e-03, 2.5505e-04],
       device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:14,795][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Joshua] are: tensor([0.0010, 0.2312, 0.2452, 0.2454, 0.2773], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:14,797][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Joshua] are: tensor([0.0818, 0.2216, 0.2227, 0.2329, 0.2411], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:14,799][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Joshua] are: tensor([0.0074, 0.2564, 0.2382, 0.2509, 0.2471], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:14,800][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Joshua] are: tensor([0.5389, 0.0724, 0.2078, 0.0212, 0.1597], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:14,802][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Joshua] are: tensor([0.8355, 0.0443, 0.0428, 0.0342, 0.0431], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:14,803][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Joshua] are: tensor([0.0264, 0.2249, 0.2467, 0.2445, 0.2574], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:14,805][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Joshua] are: tensor([0.5448, 0.1334, 0.0972, 0.1249, 0.0996], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:14,807][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Joshua] are: tensor([0.4269, 0.1308, 0.1476, 0.1501, 0.1447], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:14,808][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Joshua] are: tensor([0.1574, 0.1924, 0.2297, 0.2008, 0.2197], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:14,810][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Joshua] are: tensor([0.0590, 0.1919, 0.3051, 0.2266, 0.2175], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:14,811][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ went] are: tensor([0.9002, 0.0114, 0.0305, 0.0216, 0.0225, 0.0138], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:14,813][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ went] are: tensor([6.6868e-01, 3.3038e-01, 1.6668e-06, 9.3621e-04, 3.2532e-06, 6.5992e-07],
       device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:14,814][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ went] are: tensor([0.0009, 0.1819, 0.1921, 0.1905, 0.2158, 0.2187], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:14,816][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ went] are: tensor([0.0655, 0.1834, 0.1844, 0.1883, 0.1991, 0.1793], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:14,818][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ went] are: tensor([0.0067, 0.2072, 0.1930, 0.2023, 0.1998, 0.1911], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:14,819][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ went] are: tensor([0.1105, 0.0705, 0.2857, 0.0519, 0.2838, 0.1976], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:14,821][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ went] are: tensor([0.7950, 0.0420, 0.0408, 0.0339, 0.0443, 0.0440], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:14,823][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ went] are: tensor([0.0269, 0.1977, 0.1946, 0.2103, 0.2217, 0.1488], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:14,824][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.4568, 0.1269, 0.0944, 0.1179, 0.0971, 0.1069], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:14,826][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ went] are: tensor([0.4113, 0.1024, 0.1206, 0.1285, 0.1216, 0.1156], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:14,827][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ went] are: tensor([0.1314, 0.1629, 0.1957, 0.1688, 0.1880, 0.1532], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:14,829][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ went] are: tensor([0.0728, 0.1348, 0.1558, 0.1801, 0.0912, 0.3653], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:14,831][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.8922, 0.0113, 0.0298, 0.0207, 0.0220, 0.0133, 0.0107],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:14,832][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ to] are: tensor([3.2872e-01, 6.5480e-01, 2.0018e-04, 9.9714e-03, 3.4132e-04, 1.3019e-04,
        5.8345e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:14,834][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0007, 0.1491, 0.1592, 0.1583, 0.1800, 0.1830, 0.1697],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:14,835][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0552, 0.1528, 0.1544, 0.1576, 0.1665, 0.1492, 0.1642],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:14,837][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0040, 0.1714, 0.1625, 0.1647, 0.1691, 0.1662, 0.1621],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:14,839][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.1197, 0.1727, 0.2863, 0.0449, 0.2426, 0.0927, 0.0411],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:14,840][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.7678, 0.0400, 0.0390, 0.0309, 0.0412, 0.0415, 0.0396],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:14,842][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0261, 0.1587, 0.1550, 0.1607, 0.1795, 0.1355, 0.1844],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:14,843][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.4289, 0.1156, 0.0848, 0.1058, 0.0863, 0.0937, 0.0849],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:14,843][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.3423, 0.0952, 0.1139, 0.1168, 0.1145, 0.1117, 0.1056],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:14,844][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.1065, 0.1376, 0.1678, 0.1430, 0.1580, 0.1298, 0.1572],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:14,846][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0313, 0.1283, 0.1525, 0.1970, 0.0863, 0.2416, 0.1629],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:14,847][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.9262, 0.0061, 0.0217, 0.0133, 0.0145, 0.0077, 0.0060, 0.0046],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:14,848][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ the] are: tensor([7.5281e-01, 2.4546e-01, 3.7472e-06, 1.5030e-03, 1.0786e-05, 1.4044e-06,
        1.7115e-04, 4.1520e-05], device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:14,850][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0005, 0.1277, 0.1360, 0.1344, 0.1524, 0.1554, 0.1439, 0.1496],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:14,852][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0502, 0.1300, 0.1312, 0.1341, 0.1416, 0.1270, 0.1399, 0.1462],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:14,853][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0030, 0.1471, 0.1405, 0.1411, 0.1452, 0.1439, 0.1422, 0.1369],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:14,855][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0593, 0.0747, 0.2439, 0.0384, 0.2479, 0.0728, 0.0691, 0.1939],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:14,857][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.7196, 0.0413, 0.0390, 0.0327, 0.0415, 0.0424, 0.0414, 0.0420],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:14,858][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0190, 0.1416, 0.1391, 0.1453, 0.1537, 0.1068, 0.1658, 0.1287],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:14,860][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.4179, 0.1044, 0.0757, 0.0954, 0.0769, 0.0832, 0.0760, 0.0706],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:14,862][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.3445, 0.0843, 0.0977, 0.1031, 0.0975, 0.0926, 0.0884, 0.0918],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:14,864][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0905, 0.1199, 0.1493, 0.1278, 0.1426, 0.1158, 0.1401, 0.1140],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:14,865][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0311, 0.1102, 0.1591, 0.1529, 0.1167, 0.2037, 0.0867, 0.1395],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:14,867][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ office] are: tensor([0.8941, 0.0087, 0.0264, 0.0171, 0.0187, 0.0111, 0.0086, 0.0068, 0.0085],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:14,869][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ office] are: tensor([0.3812, 0.4834, 0.0029, 0.0448, 0.0080, 0.0022, 0.0216, 0.0096, 0.0462],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:14,870][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ office] are: tensor([0.0005, 0.1111, 0.1180, 0.1165, 0.1324, 0.1346, 0.1244, 0.1300, 0.1324],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:14,872][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ office] are: tensor([0.0473, 0.1132, 0.1133, 0.1173, 0.1224, 0.1116, 0.1236, 0.1292, 0.1221],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:14,874][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ office] are: tensor([0.0034, 0.1291, 0.1202, 0.1265, 0.1265, 0.1234, 0.1271, 0.1234, 0.1204],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:14,875][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ office] are: tensor([0.0605, 0.0869, 0.1504, 0.0285, 0.1434, 0.0849, 0.0258, 0.0811, 0.3384],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:14,877][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ office] are: tensor([0.6815, 0.0392, 0.0368, 0.0310, 0.0378, 0.0389, 0.0384, 0.0394, 0.0569],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:14,879][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ office] are: tensor([0.0177, 0.1178, 0.1253, 0.1264, 0.1367, 0.0853, 0.1420, 0.1113, 0.1376],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:14,881][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ office] are: tensor([0.3589, 0.0982, 0.0724, 0.0932, 0.0755, 0.0831, 0.0751, 0.0703, 0.0732],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:14,882][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ office] are: tensor([0.2755, 0.0844, 0.0930, 0.0964, 0.0894, 0.0890, 0.0865, 0.0895, 0.0963],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:14,884][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ office] are: tensor([0.0891, 0.1079, 0.1332, 0.1134, 0.1271, 0.1042, 0.1265, 0.1032, 0.0954],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:14,886][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ office] are: tensor([0.0399, 0.0866, 0.1496, 0.1146, 0.0859, 0.1905, 0.0693, 0.0803, 0.1832],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:14,887][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.8390, 0.0120, 0.0371, 0.0238, 0.0265, 0.0156, 0.0131, 0.0097, 0.0122,
        0.0111], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:14,889][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.0009, 0.0536, 0.0768, 0.0924, 0.1249, 0.2257, 0.1845, 0.1033, 0.0283,
        0.1096], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:14,891][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.0004, 0.0977, 0.1046, 0.1035, 0.1181, 0.1206, 0.1113, 0.1158, 0.1186,
        0.1095], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:14,892][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0410, 0.1006, 0.1009, 0.1037, 0.1086, 0.0986, 0.1085, 0.1137, 0.1083,
        0.1159], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:14,893][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0024, 0.1142, 0.1102, 0.1100, 0.1126, 0.1116, 0.1104, 0.1091, 0.1084,
        0.1110], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:14,893][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.0149, 0.0561, 0.2105, 0.0403, 0.2528, 0.0526, 0.0314, 0.0723, 0.1592,
        0.1100], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:14,894][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.6871, 0.0326, 0.0320, 0.0259, 0.0338, 0.0336, 0.0334, 0.0346, 0.0542,
        0.0329], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:14,896][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0134, 0.1029, 0.1058, 0.1079, 0.1118, 0.0825, 0.1249, 0.1008, 0.1330,
        0.1169], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:14,898][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.3003, 0.0914, 0.0717, 0.0850, 0.0734, 0.0792, 0.0712, 0.0686, 0.0736,
        0.0855], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:14,899][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.2441, 0.0752, 0.0862, 0.0859, 0.0855, 0.0843, 0.0793, 0.0836, 0.0926,
        0.0832], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:14,901][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.0821, 0.1015, 0.1268, 0.1051, 0.1187, 0.0952, 0.1175, 0.0958, 0.0859,
        0.0714], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:14,903][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0246, 0.0907, 0.1096, 0.1540, 0.0623, 0.1482, 0.0848, 0.0756, 0.1536,
        0.0966], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:14,904][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Erica] are: tensor([0.9143, 0.0098, 0.0180, 0.0108, 0.0120, 0.0062, 0.0056, 0.0044, 0.0057,
        0.0058, 0.0074], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:14,906][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Erica] are: tensor([0.1860, 0.3459, 0.0074, 0.0450, 0.0153, 0.0063, 0.0235, 0.0160, 0.0439,
        0.2593, 0.0513], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:14,908][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Erica] are: tensor([0.0004, 0.0882, 0.0931, 0.0922, 0.1039, 0.1066, 0.0980, 0.1021, 0.1042,
        0.0962, 0.1150], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:14,910][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Erica] are: tensor([0.0406, 0.0889, 0.0884, 0.0923, 0.0960, 0.0885, 0.0984, 0.1027, 0.0972,
        0.1044, 0.1027], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:14,911][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Erica] are: tensor([0.0033, 0.1039, 0.0958, 0.1021, 0.1004, 0.0989, 0.1013, 0.0990, 0.0964,
        0.1021, 0.0968], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:14,913][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Erica] are: tensor([0.0315, 0.0312, 0.3605, 0.0247, 0.2045, 0.0318, 0.0135, 0.0192, 0.0800,
        0.0513, 0.1517], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:14,915][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Erica] are: tensor([0.6543, 0.0348, 0.0321, 0.0270, 0.0315, 0.0328, 0.0320, 0.0335, 0.0482,
        0.0326, 0.0411], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:14,916][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Erica] are: tensor([0.0103, 0.0955, 0.0979, 0.0999, 0.1055, 0.0699, 0.1126, 0.0918, 0.1197,
        0.1067, 0.0903], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:14,918][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Erica] are: tensor([0.3203, 0.0810, 0.0601, 0.0766, 0.0624, 0.0694, 0.0620, 0.0583, 0.0614,
        0.0755, 0.0731], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:14,920][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Erica] are: tensor([0.2408, 0.0734, 0.0758, 0.0789, 0.0741, 0.0731, 0.0692, 0.0725, 0.0809,
        0.0726, 0.0886], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:14,922][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Erica] are: tensor([0.0823, 0.0952, 0.1133, 0.0948, 0.1056, 0.0865, 0.1061, 0.0845, 0.0776,
        0.0632, 0.0908], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:14,923][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Erica] are: tensor([0.0293, 0.0716, 0.1067, 0.0904, 0.0778, 0.1487, 0.0528, 0.0751, 0.1537,
        0.0732, 0.1205], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:14,925][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.8561, 0.0158, 0.0235, 0.0157, 0.0158, 0.0100, 0.0104, 0.0079, 0.0096,
        0.0110, 0.0128, 0.0114], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:14,926][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([3.1816e-01, 4.4449e-01, 3.2890e-04, 1.1350e-02, 7.5757e-04, 1.7436e-04,
        2.5799e-03, 1.0582e-03, 7.9734e-03, 1.9625e-01, 1.3682e-02, 3.1921e-03],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:14,928][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0003, 0.0794, 0.0841, 0.0830, 0.0946, 0.0960, 0.0886, 0.0928, 0.0944,
        0.0878, 0.1053, 0.0936], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:14,930][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.0349, 0.0813, 0.0810, 0.0838, 0.0881, 0.0805, 0.0893, 0.0935, 0.0881,
        0.0946, 0.0937, 0.0912], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:14,931][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.0025, 0.0954, 0.0891, 0.0931, 0.0926, 0.0903, 0.0925, 0.0908, 0.0882,
        0.0929, 0.0887, 0.0839], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:14,933][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.0100, 0.0455, 0.0932, 0.0179, 0.1252, 0.0331, 0.0230, 0.0741, 0.1444,
        0.1379, 0.1575, 0.1383], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:14,935][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.6348, 0.0305, 0.0305, 0.0250, 0.0308, 0.0316, 0.0304, 0.0313, 0.0480,
        0.0301, 0.0416, 0.0354], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:14,937][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0083, 0.0873, 0.0933, 0.0912, 0.0962, 0.0683, 0.1103, 0.0846, 0.1037,
        0.0998, 0.0858, 0.0712], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:14,938][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.2826, 0.0767, 0.0566, 0.0742, 0.0590, 0.0668, 0.0609, 0.0562, 0.0592,
        0.0740, 0.0705, 0.0633], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:14,940][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.2210, 0.0662, 0.0707, 0.0735, 0.0696, 0.0671, 0.0629, 0.0664, 0.0746,
        0.0673, 0.0837, 0.0770], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:14,941][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0765, 0.0886, 0.1078, 0.0892, 0.1009, 0.0799, 0.0967, 0.0791, 0.0712,
        0.0598, 0.0858, 0.0645], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:14,942][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0183, 0.0622, 0.0905, 0.0972, 0.0569, 0.1232, 0.0586, 0.0698, 0.1270,
        0.0545, 0.0981, 0.1437], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:14,943][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.8631, 0.0139, 0.0224, 0.0151, 0.0153, 0.0088, 0.0092, 0.0069, 0.0085,
        0.0092, 0.0110, 0.0095, 0.0072], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:14,944][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ a] are: tensor([7.1952e-01, 2.0515e-01, 8.2650e-06, 1.3674e-03, 2.1073e-05, 3.1886e-06,
        2.2440e-04, 8.6748e-05, 1.0876e-03, 6.9764e-02, 2.5446e-03, 1.7347e-04,
        4.3295e-05], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:14,945][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0003, 0.0723, 0.0770, 0.0759, 0.0862, 0.0881, 0.0813, 0.0847, 0.0865,
        0.0802, 0.0964, 0.0858, 0.0853], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:14,947][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0286, 0.0754, 0.0748, 0.0770, 0.0811, 0.0726, 0.0801, 0.0839, 0.0806,
        0.0866, 0.0871, 0.0852, 0.0870], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:14,948][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0019, 0.0870, 0.0829, 0.0847, 0.0860, 0.0861, 0.0846, 0.0826, 0.0827,
        0.0861, 0.0827, 0.0794, 0.0733], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:14,950][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0146, 0.0152, 0.0436, 0.0057, 0.0387, 0.0203, 0.0118, 0.0422, 0.0813,
        0.0909, 0.1595, 0.1065, 0.3699], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:14,952][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.5788, 0.0318, 0.0312, 0.0256, 0.0344, 0.0343, 0.0333, 0.0341, 0.0537,
        0.0328, 0.0443, 0.0395, 0.0262], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:14,954][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0116, 0.0824, 0.0812, 0.0831, 0.0879, 0.0691, 0.0935, 0.0741, 0.0946,
        0.0903, 0.0778, 0.0833, 0.0712], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:14,955][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.2748, 0.0728, 0.0528, 0.0703, 0.0548, 0.0622, 0.0562, 0.0521, 0.0547,
        0.0692, 0.0650, 0.0597, 0.0554], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:14,957][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.2197, 0.0603, 0.0644, 0.0670, 0.0629, 0.0605, 0.0572, 0.0600, 0.0685,
        0.0606, 0.0768, 0.0702, 0.0717], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:14,959][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0678, 0.0817, 0.1023, 0.0850, 0.0960, 0.0760, 0.0929, 0.0753, 0.0674,
        0.0563, 0.0821, 0.0605, 0.0567], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:14,961][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0162, 0.0524, 0.0895, 0.0781, 0.0732, 0.1252, 0.0503, 0.0719, 0.1331,
        0.0545, 0.0935, 0.1000, 0.0620], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:14,962][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ basketball] are: tensor([0.8182, 0.0185, 0.0251, 0.0175, 0.0187, 0.0117, 0.0111, 0.0093, 0.0116,
        0.0118, 0.0135, 0.0114, 0.0088, 0.0128], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:14,964][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ basketball] are: tensor([0.2384, 0.3665, 0.0019, 0.0278, 0.0051, 0.0013, 0.0100, 0.0055, 0.0224,
        0.2439, 0.0296, 0.0079, 0.0028, 0.0368], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:14,966][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ basketball] are: tensor([0.0003, 0.0669, 0.0707, 0.0698, 0.0791, 0.0800, 0.0739, 0.0772, 0.0783,
        0.0727, 0.0870, 0.0775, 0.0773, 0.0893], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:14,968][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ basketball] are: tensor([0.0299, 0.0686, 0.0689, 0.0713, 0.0746, 0.0681, 0.0751, 0.0784, 0.0743,
        0.0802, 0.0790, 0.0780, 0.0819, 0.0718], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:14,969][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ basketball] are: tensor([0.0022, 0.0809, 0.0753, 0.0797, 0.0778, 0.0762, 0.0791, 0.0773, 0.0755,
        0.0795, 0.0755, 0.0724, 0.0718, 0.0768], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:14,971][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ basketball] are: tensor([0.0757, 0.0414, 0.0650, 0.0073, 0.0299, 0.0242, 0.0072, 0.0247, 0.1174,
        0.1375, 0.0452, 0.1336, 0.1800, 0.1109], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:14,973][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ basketball] are: tensor([0.5829, 0.0301, 0.0280, 0.0235, 0.0287, 0.0300, 0.0288, 0.0294, 0.0440,
        0.0288, 0.0379, 0.0336, 0.0241, 0.0502], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:14,975][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ basketball] are: tensor([0.0123, 0.0814, 0.0750, 0.0817, 0.0809, 0.0528, 0.0912, 0.0722, 0.0884,
        0.0859, 0.0698, 0.0609, 0.0711, 0.0764], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:14,976][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ basketball] are: tensor([0.2782, 0.0649, 0.0490, 0.0626, 0.0503, 0.0570, 0.0514, 0.0482, 0.0510,
        0.0621, 0.0606, 0.0555, 0.0512, 0.0578], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:14,978][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ basketball] are: tensor([0.1451, 0.0646, 0.0641, 0.0642, 0.0627, 0.0643, 0.0602, 0.0624, 0.0682,
        0.0621, 0.0711, 0.0672, 0.0690, 0.0748], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:14,980][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ basketball] are: tensor([0.0704, 0.0752, 0.0922, 0.0753, 0.0890, 0.0711, 0.0835, 0.0687, 0.0624,
        0.0516, 0.0752, 0.0583, 0.0540, 0.0731], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:14,982][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ basketball] are: tensor([0.0241, 0.0485, 0.0944, 0.0538, 0.0676, 0.1237, 0.0331, 0.0521, 0.1064,
        0.0464, 0.0950, 0.0852, 0.0396, 0.1299], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:14,984][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.8401, 0.0135, 0.0230, 0.0150, 0.0156, 0.0094, 0.0093, 0.0070, 0.0091,
        0.0095, 0.0124, 0.0097, 0.0075, 0.0109, 0.0079], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:14,986][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.2318, 0.3641, 0.0017, 0.0145, 0.0034, 0.0014, 0.0176, 0.0099, 0.0271,
        0.2250, 0.0229, 0.0086, 0.0055, 0.0496, 0.0167], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:14,987][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0003, 0.0610, 0.0650, 0.0643, 0.0728, 0.0745, 0.0686, 0.0711, 0.0728,
        0.0673, 0.0805, 0.0721, 0.0714, 0.0836, 0.0749], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:14,989][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0255, 0.0639, 0.0642, 0.0657, 0.0691, 0.0625, 0.0686, 0.0720, 0.0690,
        0.0741, 0.0741, 0.0728, 0.0752, 0.0674, 0.0760], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:14,990][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0015, 0.0747, 0.0712, 0.0723, 0.0740, 0.0731, 0.0708, 0.0718, 0.0711,
        0.0735, 0.0711, 0.0688, 0.0659, 0.0734, 0.0670], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:14,991][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0193, 0.0580, 0.1383, 0.0117, 0.0968, 0.0256, 0.0117, 0.0334, 0.0548,
        0.0873, 0.1247, 0.0656, 0.1447, 0.0811, 0.0472], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:14,992][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.5762, 0.0267, 0.0263, 0.0206, 0.0272, 0.0280, 0.0266, 0.0283, 0.0441,
        0.0272, 0.0375, 0.0327, 0.0222, 0.0503, 0.0260], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:14,993][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0099, 0.0691, 0.0676, 0.0688, 0.0763, 0.0580, 0.0786, 0.0659, 0.0829,
        0.0769, 0.0654, 0.0643, 0.0669, 0.0678, 0.0816], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:14,995][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.2613, 0.0641, 0.0467, 0.0616, 0.0480, 0.0537, 0.0485, 0.0457, 0.0485,
        0.0608, 0.0577, 0.0532, 0.0491, 0.0552, 0.0457], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:14,996][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.1737, 0.0520, 0.0569, 0.0571, 0.0558, 0.0553, 0.0507, 0.0548, 0.0612,
        0.0536, 0.0676, 0.0623, 0.0651, 0.0728, 0.0611], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:14,998][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0625, 0.0703, 0.0887, 0.0705, 0.0825, 0.0658, 0.0814, 0.0640, 0.0574,
        0.0473, 0.0725, 0.0523, 0.0494, 0.0685, 0.0669], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:15,000][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0130, 0.0543, 0.0724, 0.0834, 0.0439, 0.1117, 0.0673, 0.0534, 0.0848,
        0.0526, 0.0763, 0.0854, 0.0374, 0.0860, 0.0781], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:15,057][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:24:15,058][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:15,059][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:15,061][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:15,062][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:15,063][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:15,064][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:15,065][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:15,065][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:15,066][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:15,067][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:15,067][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:15,068][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:15,069][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.2530, 0.7470], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:15,070][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.8420, 0.1580], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:15,070][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.7704, 0.2296], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:15,072][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.8868, 0.1132], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:15,073][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.9339, 0.0661], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:15,075][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.9485, 0.0515], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:15,076][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.8748, 0.1252], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:15,078][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0901, 0.9099], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:15,079][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0614, 0.9386], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:15,081][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0398, 0.9602], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:15,083][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.2993, 0.7007], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:15,084][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.9804, 0.0196], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:15,086][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Erica] are: tensor([0.0625, 0.8727, 0.0647], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:15,087][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Erica] are: tensor([0.4163, 0.2633, 0.3204], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:15,089][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Erica] are: tensor([0.6293, 0.2084, 0.1624], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:15,090][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Erica] are: tensor([0.2640, 0.4287, 0.3073], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:15,092][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Erica] are: tensor([0.5968, 0.3314, 0.0719], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:15,094][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Erica] are: tensor([0.9321, 0.0414, 0.0265], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:15,095][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Erica] are: tensor([0.4251, 0.5350, 0.0399], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:15,097][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Erica] are: tensor([0.0492, 0.4372, 0.5136], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:15,099][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Erica] are: tensor([0.0275, 0.5537, 0.4189], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:15,100][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Erica] are: tensor([0.0117, 0.5489, 0.4394], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:15,102][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Erica] are: tensor([0.1370, 0.3668, 0.4963], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:15,103][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Erica] are: tensor([0.9263, 0.0548, 0.0190], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:15,105][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0908, 0.3872, 0.4935, 0.0284], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:15,106][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.3793, 0.1964, 0.2392, 0.1850], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:15,107][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.5266, 0.1880, 0.1674, 0.1180], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:15,107][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.6211, 0.1350, 0.1691, 0.0748], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:15,108][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.6141, 0.1629, 0.0962, 0.1268], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:15,109][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.9604, 0.0202, 0.0176, 0.0017], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:15,110][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.4941, 0.3105, 0.1495, 0.0460], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:15,112][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0316, 0.3095, 0.3172, 0.3416], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:15,114][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0255, 0.2911, 0.4636, 0.2199], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:15,115][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0119, 0.3618, 0.3130, 0.3134], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:15,117][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.1501, 0.2423, 0.3046, 0.3029], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:15,118][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.9593, 0.0169, 0.0070, 0.0169], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:15,120][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Joshua] are: tensor([0.1108, 0.3862, 0.0793, 0.4104, 0.0132], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:15,122][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Joshua] are: tensor([0.3921, 0.1200, 0.1780, 0.1465, 0.1633], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:15,123][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Joshua] are: tensor([0.4050, 0.1712, 0.1299, 0.1001, 0.1938], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:15,125][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Joshua] are: tensor([0.2047, 0.1962, 0.1848, 0.1539, 0.2604], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:15,126][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Joshua] are: tensor([0.3971, 0.2211, 0.0485, 0.2915, 0.0418], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:15,128][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Joshua] are: tensor([0.9579, 0.0157, 0.0181, 0.0044, 0.0039], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:15,130][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Joshua] are: tensor([0.1575, 0.7136, 0.0446, 0.0573, 0.0270], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:15,131][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Joshua] are: tensor([0.0167, 0.1865, 0.2220, 0.2180, 0.3569], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:15,133][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Joshua] are: tensor([0.0293, 0.2458, 0.1804, 0.2608, 0.2837], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:15,135][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Joshua] are: tensor([0.0068, 0.2824, 0.2525, 0.2431, 0.2152], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:15,136][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Joshua] are: tensor([0.0944, 0.1809, 0.2219, 0.2145, 0.2884], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:15,138][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Joshua] are: tensor([0.9534, 0.0195, 0.0083, 0.0134, 0.0054], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:15,140][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([0.0418, 0.5761, 0.0500, 0.3153, 0.0090, 0.0078], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:15,141][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([0.1572, 0.1798, 0.1599, 0.1677, 0.1754, 0.1600], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:15,143][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([0.3752, 0.1409, 0.1161, 0.0815, 0.1771, 0.1093], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:15,145][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([0.3329, 0.1059, 0.1074, 0.0815, 0.1484, 0.2239], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:15,146][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([0.5307, 0.1616, 0.0405, 0.1869, 0.0409, 0.0395], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:15,148][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([0.8539, 0.0751, 0.0348, 0.0173, 0.0124, 0.0066], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:15,149][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([0.2942, 0.3228, 0.0529, 0.0801, 0.1109, 0.1391], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:15,151][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([0.0183, 0.1409, 0.1635, 0.1741, 0.2669, 0.2364], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:15,153][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([0.0438, 0.1694, 0.1484, 0.2354, 0.3118, 0.0913], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:15,154][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([0.0062, 0.2198, 0.1980, 0.1877, 0.1859, 0.2025], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:15,156][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([0.0539, 0.1752, 0.1977, 0.2100, 0.1924, 0.1709], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:15,157][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([0.9049, 0.0314, 0.0101, 0.0195, 0.0087, 0.0253], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:15,158][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0505, 0.3793, 0.0822, 0.1341, 0.0155, 0.3329, 0.0056],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:15,158][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.2170, 0.0990, 0.1433, 0.1080, 0.1482, 0.1594, 0.1251],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:15,159][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.3307, 0.1325, 0.1057, 0.0809, 0.1706, 0.1116, 0.0680],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:15,161][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.2684, 0.0809, 0.0904, 0.0510, 0.1262, 0.2777, 0.1055],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:15,162][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.2930, 0.2262, 0.0544, 0.2018, 0.0653, 0.0998, 0.0596],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:15,164][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.8734, 0.0425, 0.0372, 0.0095, 0.0170, 0.0151, 0.0052],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:15,166][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.2208, 0.2405, 0.0551, 0.0275, 0.0566, 0.3599, 0.0397],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:15,167][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0115, 0.1101, 0.1315, 0.1370, 0.2283, 0.2114, 0.1701],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:15,169][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0144, 0.1185, 0.1632, 0.1667, 0.3152, 0.1511, 0.0710],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:15,171][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0057, 0.1830, 0.1586, 0.1594, 0.1581, 0.1794, 0.1558],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:15,172][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0671, 0.1381, 0.1597, 0.1699, 0.1617, 0.1498, 0.1536],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:15,174][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.9019, 0.0263, 0.0121, 0.0157, 0.0102, 0.0119, 0.0220],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:15,175][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0255, 0.6023, 0.0226, 0.2701, 0.0040, 0.0287, 0.0415, 0.0052],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:15,177][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.1322, 0.1204, 0.1259, 0.1127, 0.1264, 0.1259, 0.1213, 0.1352],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:15,179][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.2880, 0.1287, 0.1018, 0.0765, 0.1641, 0.1045, 0.0690, 0.0674],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:15,180][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.2295, 0.0696, 0.0842, 0.0468, 0.1182, 0.2598, 0.1040, 0.0878],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:15,182][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.3467, 0.1433, 0.0456, 0.1255, 0.0465, 0.1012, 0.0982, 0.0931],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:15,184][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.9424, 0.0221, 0.0184, 0.0030, 0.0060, 0.0025, 0.0042, 0.0014],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:15,185][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.2130, 0.2558, 0.0220, 0.0452, 0.0417, 0.3132, 0.0911, 0.0180],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:15,187][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0100, 0.0946, 0.1105, 0.1121, 0.1786, 0.1674, 0.1377, 0.1891],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:15,189][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0162, 0.1424, 0.1228, 0.1458, 0.2582, 0.1485, 0.1208, 0.0452],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:15,190][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0047, 0.1600, 0.1360, 0.1390, 0.1382, 0.1584, 0.1349, 0.1287],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:15,192][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0506, 0.1142, 0.1363, 0.1505, 0.1479, 0.1056, 0.1246, 0.1703],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:15,194][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.8937, 0.0225, 0.0103, 0.0131, 0.0088, 0.0127, 0.0145, 0.0245],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:15,195][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ office] are: tensor([0.0137, 0.3966, 0.0379, 0.2879, 0.0143, 0.0897, 0.0564, 0.0915, 0.0121],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:15,197][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ office] are: tensor([0.1698, 0.0730, 0.0882, 0.0974, 0.1037, 0.1001, 0.1279, 0.1286, 0.1114],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:15,199][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ office] are: tensor([0.2268, 0.1114, 0.0960, 0.0690, 0.1515, 0.0972, 0.0674, 0.0701, 0.1106],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:15,201][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ office] are: tensor([0.1943, 0.0699, 0.0723, 0.0474, 0.1249, 0.2050, 0.1221, 0.1096, 0.0544],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:15,202][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ office] are: tensor([0.1971, 0.1318, 0.0241, 0.1437, 0.0296, 0.0465, 0.1461, 0.2271, 0.0539],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:15,204][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ office] are: tensor([0.9537, 0.0118, 0.0070, 0.0035, 0.0081, 0.0038, 0.0040, 0.0045, 0.0036],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:15,206][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ office] are: tensor([0.2484, 0.2629, 0.0338, 0.0286, 0.0300, 0.2585, 0.0621, 0.0393, 0.0363],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:15,207][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ office] are: tensor([0.0098, 0.0765, 0.1014, 0.0970, 0.1608, 0.1363, 0.1189, 0.1789, 0.1203],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:15,207][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ office] are: tensor([0.0091, 0.1299, 0.0770, 0.1340, 0.1735, 0.1612, 0.0969, 0.0802, 0.1382],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:15,208][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ office] are: tensor([0.0030, 0.1430, 0.1249, 0.1244, 0.1271, 0.1357, 0.1191, 0.1126, 0.1102],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:15,209][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ office] are: tensor([0.0414, 0.0944, 0.1231, 0.1173, 0.1154, 0.0838, 0.0979, 0.1407, 0.1860],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:15,210][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ office] are: tensor([0.8189, 0.0475, 0.0135, 0.0237, 0.0090, 0.0205, 0.0270, 0.0270, 0.0128],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:15,212][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.0218, 0.0578, 0.0783, 0.0598, 0.0283, 0.0783, 0.0327, 0.1237, 0.4947,
        0.0247], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:15,213][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.2738, 0.0563, 0.0967, 0.0606, 0.0987, 0.0933, 0.0773, 0.1102, 0.0830,
        0.0500], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:15,215][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.2026, 0.1060, 0.0904, 0.0655, 0.1407, 0.0937, 0.0575, 0.0600, 0.1045,
        0.0790], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:15,217][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.1423, 0.0661, 0.0883, 0.0396, 0.1209, 0.2432, 0.0964, 0.0844, 0.0696,
        0.0492], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:15,218][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.2152, 0.0952, 0.0541, 0.1052, 0.0441, 0.0670, 0.0731, 0.1858, 0.0825,
        0.0777], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:15,220][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.8450, 0.0250, 0.0472, 0.0130, 0.0192, 0.0138, 0.0112, 0.0072, 0.0119,
        0.0065], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:15,222][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.1842, 0.2120, 0.0283, 0.0486, 0.0376, 0.1728, 0.0976, 0.0440, 0.0975,
        0.0773], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:15,223][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0094, 0.0712, 0.0790, 0.0860, 0.1321, 0.1277, 0.1084, 0.1500, 0.1002,
        0.1361], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:15,225][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.0114, 0.0761, 0.1306, 0.0961, 0.2289, 0.1162, 0.0571, 0.0679, 0.1810,
        0.0347], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:15,227][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.0034, 0.1253, 0.1086, 0.1091, 0.1070, 0.1232, 0.1079, 0.1004, 0.1123,
        0.1028], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:15,228][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.0435, 0.0862, 0.0961, 0.1083, 0.1051, 0.0791, 0.0927, 0.1370, 0.1350,
        0.1170], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:15,230][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.8015, 0.0392, 0.0163, 0.0217, 0.0109, 0.0131, 0.0271, 0.0210, 0.0139,
        0.0355], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:15,232][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Erica] are: tensor([0.0150, 0.2767, 0.0184, 0.3426, 0.0055, 0.0688, 0.0689, 0.0681, 0.0152,
        0.1116, 0.0092], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:15,234][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Erica] are: tensor([0.1176, 0.0790, 0.0818, 0.0827, 0.1003, 0.0903, 0.0939, 0.0942, 0.0889,
        0.0963, 0.0751], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:15,235][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Erica] are: tensor([0.2324, 0.0833, 0.0693, 0.0523, 0.1000, 0.0687, 0.0463, 0.0509, 0.0791,
        0.0682, 0.1494], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:15,237][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Erica] are: tensor([0.0576, 0.0796, 0.0531, 0.0493, 0.1025, 0.1907, 0.1048, 0.1151, 0.0660,
        0.1104, 0.0708], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:15,239][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Erica] are: tensor([0.1782, 0.1074, 0.0209, 0.1410, 0.0228, 0.0470, 0.0993, 0.1941, 0.0439,
        0.1183, 0.0270], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:15,240][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Erica] are: tensor([0.8174, 0.0290, 0.0164, 0.0211, 0.0290, 0.0256, 0.0139, 0.0090, 0.0146,
        0.0171, 0.0070], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:15,242][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Erica] are: tensor([0.3689, 0.2655, 0.0083, 0.0159, 0.0125, 0.0729, 0.0235, 0.0264, 0.0302,
        0.0920, 0.0839], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:15,244][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Erica] are: tensor([0.0099, 0.0524, 0.0681, 0.0684, 0.1026, 0.0971, 0.0827, 0.1153, 0.0772,
        0.1197, 0.2067], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:15,246][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Erica] are: tensor([0.0050, 0.0921, 0.0692, 0.0771, 0.1579, 0.1299, 0.0645, 0.0682, 0.1535,
        0.0968, 0.0859], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:15,247][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Erica] are: tensor([0.0018, 0.1174, 0.0938, 0.0996, 0.1034, 0.1152, 0.0954, 0.0909, 0.1018,
        0.0966, 0.0841], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:15,249][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Erica] are: tensor([0.0306, 0.0849, 0.1148, 0.0998, 0.0774, 0.0695, 0.0800, 0.1114, 0.1111,
        0.1096, 0.1108], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:15,251][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Erica] are: tensor([0.7960, 0.0525, 0.0114, 0.0244, 0.0071, 0.0170, 0.0195, 0.0234, 0.0113,
        0.0162, 0.0213], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:15,252][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.0139, 0.3955, 0.0480, 0.2178, 0.0134, 0.0088, 0.0294, 0.0819, 0.0360,
        0.1242, 0.0275, 0.0036], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:15,254][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0858, 0.0800, 0.0737, 0.0723, 0.0750, 0.0911, 0.0883, 0.0980, 0.0813,
        0.0967, 0.0825, 0.0753], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:15,256][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.1787, 0.0742, 0.0682, 0.0466, 0.1079, 0.0669, 0.0447, 0.0494, 0.0812,
        0.0628, 0.1580, 0.0614], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:15,257][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.1541, 0.0545, 0.0611, 0.0389, 0.0695, 0.1336, 0.0848, 0.1105, 0.0466,
        0.0802, 0.0756, 0.0906], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:15,258][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.1928, 0.0973, 0.0241, 0.1163, 0.0281, 0.0377, 0.0928, 0.1817, 0.0560,
        0.1168, 0.0338, 0.0226], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:15,259][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.8501, 0.0370, 0.0291, 0.0058, 0.0105, 0.0104, 0.0080, 0.0068, 0.0097,
        0.0097, 0.0209, 0.0018], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:15,260][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.1552, 0.0519, 0.0146, 0.0145, 0.0213, 0.1089, 0.0379, 0.0201, 0.0724,
        0.0342, 0.3029, 0.1662], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:15,261][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0095, 0.0575, 0.0691, 0.0654, 0.0985, 0.0855, 0.0757, 0.1040, 0.0687,
        0.0988, 0.1717, 0.0955], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:15,263][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.0098, 0.0789, 0.0902, 0.0878, 0.1164, 0.0864, 0.0808, 0.0628, 0.1465,
        0.0782, 0.1041, 0.0581], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:15,265][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.0031, 0.1048, 0.0922, 0.0881, 0.0903, 0.1015, 0.0893, 0.0842, 0.0922,
        0.0865, 0.0839, 0.0839], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:15,266][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0344, 0.0686, 0.0904, 0.0896, 0.0820, 0.0614, 0.0773, 0.1154, 0.1215,
        0.1023, 0.0869, 0.0701], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:15,268][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.7933, 0.0297, 0.0089, 0.0212, 0.0095, 0.0166, 0.0192, 0.0157, 0.0097,
        0.0221, 0.0168, 0.0373], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:15,269][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([8.8694e-03, 3.5061e-01, 1.0670e-02, 3.0421e-01, 1.8896e-03, 2.2383e-02,
        4.4941e-02, 1.5690e-02, 1.8147e-02, 2.0938e-01, 5.7293e-03, 7.3609e-03,
        1.1571e-04], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:15,271][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0675, 0.0846, 0.0711, 0.0769, 0.0757, 0.0759, 0.0776, 0.0799, 0.0761,
        0.0948, 0.0631, 0.0842, 0.0726], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:15,273][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.1677, 0.0732, 0.0635, 0.0468, 0.1030, 0.0658, 0.0419, 0.0442, 0.0812,
        0.0603, 0.1569, 0.0617, 0.0337], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:15,274][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.1262, 0.0432, 0.0493, 0.0326, 0.0712, 0.1650, 0.0719, 0.0657, 0.0622,
        0.0606, 0.0627, 0.1320, 0.0576], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:15,276][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.1563, 0.0927, 0.0260, 0.1088, 0.0298, 0.0764, 0.0847, 0.1236, 0.0727,
        0.1352, 0.0399, 0.0343, 0.0196], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:15,278][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.7835, 0.0541, 0.0334, 0.0148, 0.0128, 0.0113, 0.0098, 0.0062, 0.0105,
        0.0169, 0.0161, 0.0280, 0.0026], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:15,279][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0726, 0.0616, 0.0119, 0.0147, 0.0246, 0.1824, 0.0440, 0.0125, 0.0656,
        0.0623, 0.1911, 0.2484, 0.0083], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:15,281][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0066, 0.0532, 0.0581, 0.0568, 0.0870, 0.0819, 0.0694, 0.0938, 0.0644,
        0.0890, 0.1491, 0.0892, 0.1015], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:15,283][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0118, 0.0840, 0.0722, 0.0899, 0.1253, 0.0862, 0.0697, 0.0393, 0.1423,
        0.0703, 0.0835, 0.1050, 0.0205], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:15,285][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0028, 0.0951, 0.0819, 0.0823, 0.0811, 0.0942, 0.0808, 0.0768, 0.0815,
        0.0808, 0.0755, 0.0862, 0.0810], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:15,286][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0283, 0.0642, 0.0785, 0.0789, 0.0824, 0.0634, 0.0666, 0.0977, 0.1190,
        0.0855, 0.0754, 0.0618, 0.0982], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:15,288][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.6195, 0.0409, 0.0186, 0.0291, 0.0150, 0.0271, 0.0315, 0.0331, 0.0198,
        0.0267, 0.0501, 0.0293, 0.0593], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:15,290][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ basketball] are: tensor([0.0115, 0.5074, 0.0648, 0.1265, 0.0114, 0.0656, 0.0107, 0.0190, 0.0445,
        0.0510, 0.0524, 0.0212, 0.0040, 0.0098], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:15,292][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ basketball] are: tensor([0.0766, 0.0751, 0.0637, 0.0747, 0.0589, 0.0675, 0.0828, 0.0818, 0.0641,
        0.0747, 0.0613, 0.0849, 0.0774, 0.0563], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:15,294][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ basketball] are: tensor([0.1510, 0.0708, 0.0608, 0.0406, 0.0904, 0.0560, 0.0398, 0.0431, 0.0621,
        0.0545, 0.1385, 0.0555, 0.0320, 0.1049], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:15,296][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ basketball] are: tensor([0.1238, 0.0462, 0.0363, 0.0324, 0.0579, 0.1427, 0.0924, 0.0750, 0.0327,
        0.0661, 0.0476, 0.1094, 0.0821, 0.0555], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:15,297][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ basketball] are: tensor([0.1554, 0.0865, 0.0226, 0.1191, 0.0202, 0.0344, 0.0939, 0.1313, 0.0522,
        0.0914, 0.0300, 0.0335, 0.0816, 0.0478], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:15,299][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ basketball] are: tensor([0.8544, 0.0161, 0.0226, 0.0083, 0.0077, 0.0063, 0.0097, 0.0104, 0.0081,
        0.0074, 0.0186, 0.0215, 0.0054, 0.0037], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:15,301][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ basketball] are: tensor([0.1804, 0.1290, 0.0067, 0.0130, 0.0103, 0.1095, 0.0222, 0.0122, 0.0229,
        0.0591, 0.1199, 0.0849, 0.0116, 0.2184], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:15,303][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ basketball] are: tensor([0.0095, 0.0466, 0.0528, 0.0504, 0.0779, 0.0760, 0.0615, 0.0795, 0.0600,
        0.0776, 0.1291, 0.0795, 0.0905, 0.1091], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:15,305][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ basketball] are: tensor([0.0043, 0.0770, 0.0536, 0.0762, 0.1109, 0.0728, 0.0711, 0.0443, 0.1195,
        0.0663, 0.0607, 0.1164, 0.0446, 0.0824], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:15,306][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ basketball] are: tensor([0.0018, 0.0869, 0.0793, 0.0763, 0.0754, 0.0889, 0.0751, 0.0694, 0.0781,
        0.0729, 0.0736, 0.0764, 0.0717, 0.0743], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:15,307][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ basketball] are: tensor([0.0314, 0.0616, 0.0753, 0.0795, 0.0793, 0.0580, 0.0663, 0.0873, 0.1025,
        0.0867, 0.0702, 0.0490, 0.0893, 0.0637], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:15,307][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ basketball] are: tensor([0.7715, 0.0477, 0.0129, 0.0196, 0.0076, 0.0145, 0.0167, 0.0218, 0.0071,
        0.0182, 0.0245, 0.0137, 0.0181, 0.0061], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:15,308][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0154, 0.1271, 0.0258, 0.0345, 0.0062, 0.1368, 0.0021, 0.1409, 0.2263,
        0.2260, 0.0157, 0.0181, 0.0083, 0.0147, 0.0022], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:15,310][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.1017, 0.0500, 0.0699, 0.0518, 0.0748, 0.0736, 0.0606, 0.0755, 0.0731,
        0.0530, 0.0625, 0.0639, 0.0677, 0.0687, 0.0533], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:15,312][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1391, 0.0647, 0.0544, 0.0401, 0.0863, 0.0570, 0.0341, 0.0370, 0.0640,
        0.0509, 0.1288, 0.0521, 0.0290, 0.1193, 0.0432], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:15,314][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.1059, 0.0413, 0.0471, 0.0258, 0.0616, 0.1526, 0.0525, 0.0532, 0.0533,
        0.0479, 0.0597, 0.1043, 0.0639, 0.0802, 0.0506], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:15,315][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0742, 0.0978, 0.0259, 0.1041, 0.0306, 0.0516, 0.0346, 0.1769, 0.0758,
        0.0999, 0.0348, 0.0371, 0.0679, 0.0684, 0.0204], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:15,317][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.7216, 0.0516, 0.0414, 0.0109, 0.0217, 0.0193, 0.0058, 0.0120, 0.0203,
        0.0152, 0.0259, 0.0165, 0.0059, 0.0279, 0.0041], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:15,319][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.1375, 0.0458, 0.0089, 0.0053, 0.0080, 0.0943, 0.0092, 0.0120, 0.0296,
        0.0281, 0.1262, 0.1125, 0.0085, 0.3489, 0.0252], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:15,321][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0067, 0.0408, 0.0459, 0.0471, 0.0725, 0.0703, 0.0563, 0.0776, 0.0538,
        0.0749, 0.1219, 0.0757, 0.0832, 0.0977, 0.0758], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:15,322][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0061, 0.0524, 0.0666, 0.0695, 0.1259, 0.0662, 0.0302, 0.0493, 0.1241,
        0.0361, 0.0766, 0.0802, 0.0458, 0.1414, 0.0297], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:15,324][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0022, 0.0815, 0.0706, 0.0707, 0.0700, 0.0798, 0.0686, 0.0654, 0.0730,
        0.0678, 0.0649, 0.0734, 0.0699, 0.0752, 0.0671], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:15,326][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0296, 0.0544, 0.0638, 0.0683, 0.0697, 0.0610, 0.0628, 0.0828, 0.1058,
        0.0718, 0.0618, 0.0560, 0.0821, 0.0666, 0.0633], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:15,328][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.7248, 0.0312, 0.0106, 0.0182, 0.0096, 0.0153, 0.0284, 0.0191, 0.0116,
        0.0189, 0.0248, 0.0240, 0.0247, 0.0064, 0.0324], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:15,332][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:24:15,333][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[10613],
        [12721],
        [14946],
        [ 9391],
        [22683],
        [20797],
        [14065],
        [16579],
        [ 6342],
        [10612],
        [ 5522],
        [18496],
        [14803],
        [13964],
        [16850]], device='cuda:0')
[2024-07-24 10:24:15,335][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[11133],
        [11757],
        [ 8786],
        [14125],
        [24292],
        [22665],
        [14505],
        [15968],
        [ 7188],
        [15236],
        [ 7179],
        [16935],
        [16637],
        [20744],
        [22877]], device='cuda:0')
[2024-07-24 10:24:15,337][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[13680],
        [14386],
        [16046],
        [16936],
        [16904],
        [15898],
        [16021],
        [15260],
        [16019],
        [17410],
        [15547],
        [17164],
        [17037],
        [18344],
        [17586]], device='cuda:0')
[2024-07-24 10:24:15,339][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[22129],
        [  499],
        [ 1893],
        [  446],
        [ 1574],
        [ 2250],
        [  732],
        [ 3615],
        [  722],
        [  940],
        [  592],
        [  771],
        [ 3107],
        [  649],
        [  607]], device='cuda:0')
[2024-07-24 10:24:15,340][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[27399],
        [29214],
        [29578],
        [29597],
        [29771],
        [30159],
        [30229],
        [30388],
        [30535],
        [30483],
        [30736],
        [30897],
        [30960],
        [31067],
        [30993]], device='cuda:0')
[2024-07-24 10:24:15,342][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[6606],
        [4283],
        [3470],
        [3283],
        [3145],
        [3083],
        [3045],
        [3035],
        [2949],
        [2937],
        [2867],
        [2820],
        [2846],
        [2818],
        [2815]], device='cuda:0')
[2024-07-24 10:24:15,344][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[2758],
        [5008],
        [2610],
        [2918],
        [2306],
        [2805],
        [3159],
        [3410],
        [3464],
        [3869],
        [3577],
        [3535],
        [3930],
        [3845],
        [4018]], device='cuda:0')
[2024-07-24 10:24:15,345][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[ 2580],
        [16646],
        [ 9613],
        [30545],
        [19000],
        [29375],
        [28563],
        [28804],
        [25006],
        [27313],
        [30220],
        [25919],
        [24787],
        [21645],
        [24927]], device='cuda:0')
[2024-07-24 10:24:15,347][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[13973],
        [14165],
        [14654],
        [14460],
        [15086],
        [14896],
        [14756],
        [14556],
        [14402],
        [14136],
        [14094],
        [13945],
        [13804],
        [13568],
        [13393]], device='cuda:0')
[2024-07-24 10:24:15,348][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[10810],
        [38156],
        [39621],
        [40710],
        [38342],
        [39528],
        [39596],
        [40504],
        [40298],
        [40144],
        [40405],
        [40627],
        [41265],
        [40590],
        [41019]], device='cuda:0')
[2024-07-24 10:24:15,350][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[37042],
        [34987],
        [33895],
        [29760],
        [29225],
        [26467],
        [24916],
        [23694],
        [21686],
        [20343],
        [20963],
        [20165],
        [19708],
        [19760],
        [19347]], device='cuda:0')
[2024-07-24 10:24:15,352][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[40568],
        [30691],
        [29050],
        [16963],
        [20720],
        [19916],
        [16090],
        [16384],
        [12997],
        [11296],
        [11506],
        [10665],
        [10693],
        [ 8380],
        [ 9495]], device='cuda:0')
[2024-07-24 10:24:15,353][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[11203],
        [11581],
        [10174],
        [10073],
        [ 9399],
        [ 9143],
        [ 9735],
        [ 9796],
        [ 9612],
        [ 9599],
        [10242],
        [10503],
        [10879],
        [11441],
        [12188]], device='cuda:0')
[2024-07-24 10:24:15,355][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[ 6198],
        [19833],
        [13709],
        [15221],
        [26785],
        [21085],
        [20125],
        [23274],
        [21371],
        [20967],
        [20192],
        [19211],
        [19689],
        [21092],
        [18688]], device='cuda:0')
[2024-07-24 10:24:15,357][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[28030],
        [ 5912],
        [ 8097],
        [  849],
        [ 1182],
        [  183],
        [  720],
        [ 1069],
        [ 1444],
        [ 1099],
        [ 2142],
        [ 2527],
        [ 2834],
        [ 2027],
        [ 3824]], device='cuda:0')
[2024-07-24 10:24:15,358][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[48761],
        [40501],
        [40220],
        [38675],
        [38460],
        [39034],
        [37536],
        [38848],
        [36949],
        [30151],
        [37480],
        [38335],
        [39200],
        [38948],
        [35010]], device='cuda:0')
[2024-07-24 10:24:15,360][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[31576],
        [33952],
        [44184],
        [43341],
        [41568],
        [41694],
        [40286],
        [40837],
        [40357],
        [39616],
        [40556],
        [40287],
        [40170],
        [40012],
        [39587]], device='cuda:0')
[2024-07-24 10:24:15,361][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[8552],
        [7389],
        [7082],
        [6342],
        [6896],
        [6997],
        [6842],
        [6836],
        [6466],
        [6612],
        [7493],
        [7671],
        [7885],
        [8171],
        [7911]], device='cuda:0')
[2024-07-24 10:24:15,363][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[24681],
        [27787],
        [27837],
        [28778],
        [28441],
        [26201],
        [24881],
        [25359],
        [25748],
        [25703],
        [26325],
        [25730],
        [25115],
        [25806],
        [25611]], device='cuda:0')
[2024-07-24 10:24:15,364][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[ 3175],
        [ 4168],
        [10644],
        [ 9972],
        [11253],
        [10949],
        [12691],
        [13241],
        [13419],
        [13352],
        [13238],
        [13121],
        [12798],
        [13026],
        [13620]], device='cuda:0')
[2024-07-24 10:24:15,366][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[36558],
        [37421],
        [37809],
        [37219],
        [37261],
        [38770],
        [38390],
        [37503],
        [37196],
        [38714],
        [38737],
        [38793],
        [39599],
        [38734],
        [40407]], device='cuda:0')
[2024-07-24 10:24:15,368][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[43006],
        [42643],
        [39159],
        [35222],
        [40326],
        [40680],
        [43144],
        [43377],
        [43274],
        [42706],
        [43809],
        [39505],
        [42167],
        [38952],
        [35744]], device='cuda:0')
[2024-07-24 10:24:15,370][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[26012],
        [19740],
        [17332],
        [16312],
        [18296],
        [20232],
        [21027],
        [21398],
        [21776],
        [21662],
        [21339],
        [21576],
        [21831],
        [22341],
        [22527]], device='cuda:0')
[2024-07-24 10:24:15,371][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[43106],
        [ 4473],
        [ 4636],
        [ 4544],
        [ 4119],
        [ 4181],
        [ 4257],
        [ 4156],
        [ 3619],
        [ 3402],
        [ 3355],
        [ 3409],
        [ 3411],
        [ 3205],
        [ 3102]], device='cuda:0')
[2024-07-24 10:24:15,373][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[33893],
        [41242],
        [42349],
        [42441],
        [42520],
        [42105],
        [41874],
        [41672],
        [41844],
        [41815],
        [42015],
        [41900],
        [41620],
        [41789],
        [41637]], device='cuda:0')
[2024-07-24 10:24:15,375][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[3833],
        [2533],
        [2351],
        [2246],
        [2688],
        [2979],
        [2750],
        [2544],
        [2300],
        [2361],
        [2316],
        [2401],
        [2505],
        [2392],
        [2386]], device='cuda:0')
[2024-07-24 10:24:15,376][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[39983],
        [40352],
        [40443],
        [41122],
        [41326],
        [41698],
        [41430],
        [41593],
        [39087],
        [37844],
        [36846],
        [37494],
        [24365],
        [35995],
        [32032]], device='cuda:0')
[2024-07-24 10:24:15,378][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[ 8729],
        [15761],
        [13506],
        [15506],
        [13379],
        [12870],
        [12934],
        [12618],
        [13307],
        [13975],
        [12819],
        [14582],
        [14621],
        [14628],
        [15985]], device='cuda:0')
[2024-07-24 10:24:15,380][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[ 5377],
        [35826],
        [22052],
        [35650],
        [33525],
        [39341],
        [39254],
        [36020],
        [33312],
        [40077],
        [35377],
        [36687],
        [32168],
        [33641],
        [31355]], device='cuda:0')
[2024-07-24 10:24:15,381][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[9017],
        [9017],
        [9017],
        [9017],
        [9017],
        [9017],
        [9017],
        [9017],
        [9017],
        [9017],
        [9017],
        [9017],
        [9017],
        [9017],
        [9017]], device='cuda:0')
[2024-07-24 10:24:15,436][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:24:15,438][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:15,439][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:15,441][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:15,442][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:15,443][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:15,445][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:15,446][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:15,447][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:15,448][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:15,448][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:15,449][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:15,450][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:15,451][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0109, 0.9891], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:15,451][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.5093, 0.4907], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:15,452][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.5029, 0.4971], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:15,453][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.9464, 0.0536], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:15,453][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0173, 0.9827], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:15,454][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.5447, 0.4553], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:15,455][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.3478, 0.6522], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:15,456][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.9921, 0.0079], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:15,457][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [,] are: tensor([9.9933e-01, 6.7445e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:15,459][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.1301, 0.8699], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:15,461][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.4561, 0.5439], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:15,462][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.5511, 0.4489], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:15,463][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Erica] are: tensor([0.0069, 0.4972, 0.4959], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:15,465][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Erica] are: tensor([0.3180, 0.3522, 0.3298], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:15,467][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Erica] are: tensor([0.3349, 0.3206, 0.3445], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:15,467][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Erica] are: tensor([0.7788, 0.1093, 0.1119], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:15,468][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Erica] are: tensor([0.0076, 0.5038, 0.4886], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:15,469][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Erica] are: tensor([0.3912, 0.3018, 0.3070], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:15,470][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Erica] are: tensor([0.3762, 0.2925, 0.3313], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:15,472][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Erica] are: tensor([0.7206, 0.2054, 0.0740], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:15,473][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Erica] are: tensor([9.9910e-01, 7.6598e-04, 1.3598e-04], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:15,474][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Erica] are: tensor([0.0427, 0.6369, 0.3204], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:15,476][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Erica] are: tensor([0.2944, 0.3763, 0.3293], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:15,477][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Erica] are: tensor([0.1526, 0.3833, 0.4640], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:15,479][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0033, 0.3343, 0.3347, 0.3277], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:15,481][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.2361, 0.2504, 0.2380, 0.2755], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:15,482][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.2500, 0.2462, 0.2707, 0.2330], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:15,484][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.8132, 0.0805, 0.0714, 0.0348], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:15,485][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0052, 0.3435, 0.3319, 0.3194], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:15,487][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.3022, 0.2291, 0.2333, 0.2355], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:15,489][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.1686, 0.2524, 0.2747, 0.3042], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:15,490][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.9511, 0.0149, 0.0305, 0.0036], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:15,491][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ and] are: tensor([9.9757e-01, 1.4782e-03, 4.1169e-04, 5.3959e-04], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:15,493][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0259, 0.1702, 0.4383, 0.3655], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:15,495][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.2056, 0.2816, 0.2510, 0.2618], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:15,496][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.1899, 0.2205, 0.4138, 0.1757], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:15,498][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Joshua] are: tensor([0.0035, 0.2497, 0.2484, 0.2452, 0.2532], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:15,500][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Joshua] are: tensor([0.1849, 0.2020, 0.1885, 0.2219, 0.2027], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:15,501][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Joshua] are: tensor([0.1980, 0.1903, 0.2084, 0.1798, 0.2234], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:15,503][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Joshua] are: tensor([0.6960, 0.0964, 0.0861, 0.0561, 0.0653], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:15,504][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Joshua] are: tensor([0.0040, 0.2620, 0.2537, 0.2441, 0.2362], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:15,506][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Joshua] are: tensor([0.2496, 0.1818, 0.1848, 0.1861, 0.1977], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:15,508][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Joshua] are: tensor([0.1907, 0.1324, 0.2132, 0.1927, 0.2710], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:15,509][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Joshua] are: tensor([0.7008, 0.1590, 0.0446, 0.0400, 0.0557], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:15,510][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Joshua] are: tensor([9.9823e-01, 6.8238e-04, 1.4551e-04, 5.0395e-04, 4.3805e-04],
       device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:15,512][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Joshua] are: tensor([0.0192, 0.2292, 0.1455, 0.5399, 0.0661], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:15,514][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Joshua] are: tensor([0.1734, 0.2280, 0.2049, 0.2097, 0.1841], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:15,515][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Joshua] are: tensor([0.1026, 0.2155, 0.3078, 0.1801, 0.1940], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:15,517][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ went] are: tensor([0.0026, 0.1931, 0.1940, 0.1902, 0.1985, 0.2216], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:15,518][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ went] are: tensor([0.1718, 0.1713, 0.1593, 0.1889, 0.1691, 0.1395], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:15,518][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ went] are: tensor([0.1693, 0.1603, 0.1749, 0.1497, 0.1863, 0.1595], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:15,519][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ went] are: tensor([0.7126, 0.0675, 0.0669, 0.0408, 0.0522, 0.0600], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:15,520][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ went] are: tensor([0.0032, 0.2140, 0.2072, 0.1992, 0.1931, 0.1833], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:15,522][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ went] are: tensor([0.2126, 0.1509, 0.1538, 0.1546, 0.1652, 0.1628], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:15,523][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ went] are: tensor([0.2136, 0.1365, 0.1534, 0.1662, 0.1696, 0.1608], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:15,525][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ went] are: tensor([0.7601, 0.0971, 0.0395, 0.0366, 0.0491, 0.0176], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:15,526][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ went] are: tensor([9.9703e-01, 7.3787e-04, 1.1888e-04, 3.6644e-04, 4.6288e-04, 1.2854e-03],
       device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:15,527][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ went] are: tensor([0.0062, 0.1670, 0.0670, 0.5213, 0.2130, 0.0255], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:15,529][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ went] are: tensor([0.1426, 0.1939, 0.1717, 0.1803, 0.1534, 0.1581], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:15,530][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ went] are: tensor([0.0799, 0.1745, 0.2661, 0.1542, 0.1726, 0.1526], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:15,532][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0015, 0.1594, 0.1609, 0.1575, 0.1655, 0.1854, 0.1697],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:15,534][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.1518, 0.1460, 0.1412, 0.1597, 0.1463, 0.1201, 0.1349],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:15,535][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1311, 0.1367, 0.1532, 0.1323, 0.1650, 0.1453, 0.1365],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:15,537][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.7107, 0.0662, 0.0543, 0.0310, 0.0376, 0.0435, 0.0566],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:15,539][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0027, 0.1798, 0.1743, 0.1673, 0.1621, 0.1542, 0.1595],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:15,540][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.1799, 0.1295, 0.1317, 0.1328, 0.1416, 0.1402, 0.1442],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:15,542][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1102, 0.0906, 0.1397, 0.1510, 0.1840, 0.1715, 0.1529],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:15,544][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.8228, 0.0352, 0.0348, 0.0142, 0.0597, 0.0221, 0.0113],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:15,545][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ to] are: tensor([9.9551e-01, 5.0051e-04, 1.3099e-04, 2.5786e-04, 3.8738e-04, 1.3185e-03,
        1.8963e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:15,546][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0084, 0.0701, 0.1426, 0.1902, 0.2135, 0.2074, 0.1677],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:15,548][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.1156, 0.1694, 0.1528, 0.1591, 0.1346, 0.1361, 0.1323],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:15,550][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0855, 0.1382, 0.2603, 0.1151, 0.1748, 0.1438, 0.0822],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:15,551][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0012, 0.1356, 0.1372, 0.1341, 0.1408, 0.1577, 0.1449, 0.1486],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:15,553][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.1255, 0.1279, 0.1237, 0.1412, 0.1277, 0.1055, 0.1184, 0.1301],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:15,555][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.1247, 0.1212, 0.1329, 0.1140, 0.1429, 0.1226, 0.1189, 0.1228],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:15,556][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.7652, 0.0516, 0.0396, 0.0217, 0.0256, 0.0287, 0.0373, 0.0303],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:15,558][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0024, 0.1545, 0.1492, 0.1436, 0.1391, 0.1323, 0.1368, 0.1422],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:15,560][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.1625, 0.1123, 0.1147, 0.1153, 0.1230, 0.1211, 0.1251, 0.1260],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:15,561][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.1029, 0.1070, 0.1257, 0.1354, 0.1453, 0.1362, 0.1254, 0.1221],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:15,563][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.8739, 0.0240, 0.0218, 0.0084, 0.0369, 0.0207, 0.0096, 0.0047],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:15,564][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ the] are: tensor([9.9284e-01, 4.8563e-04, 1.0646e-04, 3.1435e-04, 3.4624e-04, 1.5892e-03,
        2.8128e-03, 1.5052e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:15,566][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0042, 0.0691, 0.0629, 0.2697, 0.0818, 0.0762, 0.3365, 0.0994],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:15,567][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.1088, 0.1504, 0.1327, 0.1391, 0.1191, 0.1186, 0.1161, 0.1151],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:15,568][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0836, 0.1280, 0.2432, 0.1045, 0.1509, 0.1370, 0.0856, 0.0671],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:15,569][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ office] are: tensor([0.0016, 0.1195, 0.1203, 0.1179, 0.1226, 0.1369, 0.1262, 0.1289, 0.1262],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:15,570][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ office] are: tensor([0.1119, 0.1105, 0.1053, 0.1238, 0.1095, 0.0935, 0.1043, 0.1127, 0.1284],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:15,571][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ office] are: tensor([0.1111, 0.1089, 0.1200, 0.1027, 0.1280, 0.1106, 0.1058, 0.1095, 0.1034],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:15,572][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ office] are: tensor([0.7233, 0.0432, 0.0380, 0.0230, 0.0275, 0.0331, 0.0454, 0.0380, 0.0285],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:15,574][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ office] are: tensor([0.0023, 0.1359, 0.1313, 0.1263, 0.1225, 0.1167, 0.1204, 0.1251, 0.1196],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:15,576][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ office] are: tensor([0.1443, 0.1005, 0.1021, 0.1031, 0.1094, 0.1085, 0.1122, 0.1128, 0.1070],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:15,577][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ office] are: tensor([0.0807, 0.1029, 0.0955, 0.1295, 0.1131, 0.1161, 0.1194, 0.1051, 0.1378],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:15,579][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ office] are: tensor([0.5806, 0.1001, 0.0532, 0.0383, 0.0710, 0.0409, 0.0305, 0.0200, 0.0654],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:15,580][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ office] are: tensor([9.9162e-01, 4.7944e-04, 1.1749e-04, 2.5491e-04, 4.0725e-04, 1.3913e-03,
        2.8147e-03, 2.4169e-03, 5.0173e-04], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:15,582][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ office] are: tensor([0.0017, 0.0696, 0.0296, 0.2624, 0.1366, 0.0839, 0.2174, 0.1603, 0.0385],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:15,583][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ office] are: tensor([0.0953, 0.1288, 0.1176, 0.1225, 0.1063, 0.1068, 0.1039, 0.1038, 0.1150],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:15,585][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ office] are: tensor([0.0641, 0.1268, 0.2023, 0.1101, 0.1321, 0.1101, 0.0839, 0.0708, 0.0998],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:15,587][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.0011, 0.1048, 0.1059, 0.1036, 0.1087, 0.1217, 0.1122, 0.1150, 0.1140,
        0.1129], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:15,589][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.0982, 0.1030, 0.0939, 0.1113, 0.0995, 0.0825, 0.0916, 0.0994, 0.1135,
        0.1071], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:15,590][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.0915, 0.0981, 0.1100, 0.0949, 0.1193, 0.1043, 0.0975, 0.1031, 0.0958,
        0.0854], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:15,592][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.7854, 0.0395, 0.0321, 0.0164, 0.0179, 0.0219, 0.0279, 0.0242, 0.0161,
        0.0187], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:15,594][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0020, 0.1210, 0.1168, 0.1127, 0.1091, 0.1037, 0.1072, 0.1114, 0.1066,
        0.1096], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:15,596][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.1248, 0.0903, 0.0918, 0.0927, 0.0988, 0.0975, 0.1005, 0.1015, 0.0964,
        0.1057], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:15,597][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0284, 0.0457, 0.0916, 0.1015, 0.1390, 0.1364, 0.1142, 0.0873, 0.1507,
        0.1052], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:15,599][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.8733, 0.0155, 0.0180, 0.0050, 0.0280, 0.0145, 0.0063, 0.0043, 0.0302,
        0.0050], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:15,600][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [.] are: tensor([9.9347e-01, 3.9142e-04, 8.9469e-05, 1.8111e-04, 2.6426e-04, 1.1604e-03,
        1.5875e-03, 1.2801e-03, 5.4791e-04, 1.0246e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:15,602][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.0056, 0.0184, 0.0652, 0.0753, 0.1124, 0.0816, 0.1657, 0.1703, 0.1537,
        0.1519], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:15,603][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.0811, 0.1206, 0.1097, 0.1150, 0.0972, 0.0969, 0.0940, 0.0939, 0.1047,
        0.0868], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:15,605][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0774, 0.1002, 0.2056, 0.0811, 0.1320, 0.1015, 0.0619, 0.0643, 0.1095,
        0.0667], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:15,607][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Erica] are: tensor([0.0016, 0.0955, 0.0956, 0.0943, 0.0975, 0.1082, 0.1004, 0.1024, 0.1001,
        0.1014, 0.1030], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:15,609][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Erica] are: tensor([0.1049, 0.0889, 0.0833, 0.0972, 0.0853, 0.0726, 0.0818, 0.0899, 0.1004,
        0.0953, 0.1003], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:15,610][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Erica] are: tensor([0.0885, 0.0897, 0.0995, 0.0850, 0.1070, 0.0923, 0.0871, 0.0918, 0.0859,
        0.0778, 0.0952], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:15,612][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Erica] are: tensor([0.6110, 0.0417, 0.0395, 0.0293, 0.0292, 0.0406, 0.0536, 0.0446, 0.0358,
        0.0440, 0.0309], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:15,614][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Erica] are: tensor([0.0017, 0.1082, 0.1043, 0.1006, 0.0978, 0.0927, 0.0960, 0.0997, 0.0952,
        0.0978, 0.1059], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:15,616][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Erica] are: tensor([0.1162, 0.0802, 0.0822, 0.0830, 0.0878, 0.0869, 0.0902, 0.0906, 0.0860,
        0.0951, 0.1017], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:15,617][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Erica] are: tensor([0.1062, 0.0718, 0.0875, 0.1037, 0.1015, 0.0984, 0.0936, 0.0824, 0.0896,
        0.0684, 0.0970], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:15,618][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Erica] are: tensor([0.4606, 0.1468, 0.0437, 0.0348, 0.0578, 0.0435, 0.0264, 0.0249, 0.0734,
        0.0373, 0.0509], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:15,619][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Erica] are: tensor([9.9758e-01, 9.5258e-05, 1.4107e-05, 7.0513e-05, 6.3062e-05, 2.8460e-04,
        4.4089e-04, 3.6807e-04, 1.1357e-04, 4.0822e-04, 5.6562e-04],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:15,620][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Erica] are: tensor([0.0047, 0.0594, 0.0284, 0.1621, 0.1096, 0.1157, 0.0970, 0.1051, 0.0739,
        0.2132, 0.0309], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:15,621][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Erica] are: tensor([0.0822, 0.1076, 0.0985, 0.1003, 0.0876, 0.0884, 0.0848, 0.0844, 0.0950,
        0.0796, 0.0915], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:15,622][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Erica] are: tensor([0.0443, 0.1232, 0.1431, 0.0934, 0.0957, 0.0999, 0.0779, 0.0648, 0.0879,
        0.0826, 0.0872], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:15,624][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.0012, 0.0858, 0.0865, 0.0844, 0.0886, 0.0983, 0.0906, 0.0925, 0.0914,
        0.0909, 0.0945, 0.0953], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:15,626][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0996, 0.0825, 0.0757, 0.0897, 0.0783, 0.0657, 0.0735, 0.0807, 0.0924,
        0.0865, 0.0904, 0.0849], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:15,627][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0809, 0.0828, 0.0915, 0.0781, 0.0986, 0.0850, 0.0813, 0.0854, 0.0787,
        0.0725, 0.0889, 0.0762], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:15,629][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.5840, 0.0490, 0.0385, 0.0291, 0.0298, 0.0364, 0.0492, 0.0456, 0.0339,
        0.0477, 0.0316, 0.0253], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:15,631][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.0016, 0.0985, 0.0953, 0.0918, 0.0890, 0.0845, 0.0874, 0.0907, 0.0866,
        0.0892, 0.0967, 0.0888], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:15,632][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.1099, 0.0732, 0.0753, 0.0755, 0.0803, 0.0787, 0.0819, 0.0823, 0.0781,
        0.0867, 0.0933, 0.0848], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:15,634][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0603, 0.0777, 0.0780, 0.0974, 0.0912, 0.0877, 0.0855, 0.0786, 0.0929,
        0.0794, 0.0873, 0.0838], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:15,636][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.6798, 0.0463, 0.0351, 0.0185, 0.0464, 0.0229, 0.0173, 0.0126, 0.0482,
        0.0155, 0.0454, 0.0118], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:15,637][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([9.9298e-01, 1.4542e-04, 3.7006e-05, 6.6232e-05, 1.2209e-04, 3.4734e-04,
        6.0881e-04, 5.0585e-04, 2.2610e-04, 5.5004e-04, 1.6688e-03, 2.7447e-03],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:15,639][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.0015, 0.0511, 0.0641, 0.0976, 0.0700, 0.0526, 0.1152, 0.1142, 0.1062,
        0.2270, 0.0865, 0.0139], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:15,641][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0682, 0.0988, 0.0891, 0.0923, 0.0799, 0.0801, 0.0784, 0.0787, 0.0866,
        0.0735, 0.0827, 0.0917], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:15,642][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0373, 0.0959, 0.1614, 0.0802, 0.0975, 0.0860, 0.0620, 0.0605, 0.0913,
        0.0684, 0.1026, 0.0569], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:15,644][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0007, 0.0775, 0.0781, 0.0765, 0.0804, 0.0899, 0.0829, 0.0849, 0.0841,
        0.0836, 0.0871, 0.0877, 0.0866], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:15,646][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0816, 0.0754, 0.0714, 0.0822, 0.0738, 0.0611, 0.0695, 0.0770, 0.0874,
        0.0802, 0.0855, 0.0765, 0.0785], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:15,648][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0749, 0.0771, 0.0857, 0.0729, 0.0930, 0.0799, 0.0758, 0.0793, 0.0738,
        0.0667, 0.0822, 0.0702, 0.0685], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:15,649][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.6226, 0.0480, 0.0348, 0.0235, 0.0246, 0.0284, 0.0366, 0.0341, 0.0264,
        0.0366, 0.0262, 0.0220, 0.0360], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:15,651][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0016, 0.0901, 0.0871, 0.0838, 0.0814, 0.0773, 0.0798, 0.0829, 0.0793,
        0.0814, 0.0880, 0.0811, 0.0863], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:15,653][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.1035, 0.0682, 0.0698, 0.0695, 0.0740, 0.0722, 0.0751, 0.0755, 0.0719,
        0.0792, 0.0857, 0.0779, 0.0778], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:15,655][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0736, 0.0649, 0.0804, 0.0849, 0.0877, 0.0861, 0.0779, 0.0759, 0.0839,
        0.0634, 0.0846, 0.0742, 0.0624], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:15,656][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.7625, 0.0219, 0.0224, 0.0076, 0.0368, 0.0209, 0.0110, 0.0060, 0.0488,
        0.0095, 0.0368, 0.0113, 0.0045], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:15,658][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ a] are: tensor([9.6411e-01, 3.9626e-04, 1.1853e-04, 3.0305e-04, 3.6863e-04, 1.5658e-03,
        2.8845e-03, 1.8420e-03, 7.6431e-04, 3.1298e-03, 5.4760e-03, 1.3570e-02,
        5.4744e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:15,660][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0015, 0.0445, 0.0305, 0.1565, 0.0463, 0.0336, 0.1150, 0.0623, 0.0999,
        0.2874, 0.0385, 0.0588, 0.0252], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:15,661][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0628, 0.0927, 0.0830, 0.0855, 0.0734, 0.0739, 0.0712, 0.0722, 0.0802,
        0.0669, 0.0770, 0.0840, 0.0772], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:15,663][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0477, 0.0866, 0.1573, 0.0730, 0.0972, 0.0921, 0.0593, 0.0493, 0.0836,
        0.0614, 0.0941, 0.0615, 0.0369], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:15,665][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ basketball] are: tensor([0.0014, 0.0731, 0.0729, 0.0719, 0.0739, 0.0827, 0.0768, 0.0782, 0.0759,
        0.0766, 0.0779, 0.0793, 0.0789, 0.0806], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:15,667][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ basketball] are: tensor([0.0878, 0.0725, 0.0662, 0.0769, 0.0666, 0.0571, 0.0641, 0.0700, 0.0798,
        0.0754, 0.0767, 0.0725, 0.0772, 0.0571], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:15,668][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ basketball] are: tensor([0.0663, 0.0713, 0.0804, 0.0684, 0.0870, 0.0746, 0.0699, 0.0740, 0.0695,
        0.0624, 0.0774, 0.0668, 0.0647, 0.0673], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:15,669][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ basketball] are: tensor([0.5453, 0.0398, 0.0339, 0.0251, 0.0259, 0.0322, 0.0426, 0.0411, 0.0315,
        0.0403, 0.0300, 0.0267, 0.0418, 0.0437], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:15,669][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ basketball] are: tensor([0.0014, 0.0827, 0.0801, 0.0772, 0.0749, 0.0712, 0.0737, 0.0764, 0.0731,
        0.0750, 0.0812, 0.0747, 0.0798, 0.0786], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:15,671][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ basketball] are: tensor([0.0920, 0.0630, 0.0643, 0.0645, 0.0682, 0.0674, 0.0700, 0.0703, 0.0668,
        0.0738, 0.0797, 0.0730, 0.0728, 0.0741], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:15,672][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ basketball] are: tensor([0.0649, 0.0710, 0.0692, 0.0808, 0.0797, 0.0793, 0.0755, 0.0695, 0.0747,
        0.0635, 0.0734, 0.0660, 0.0556, 0.0770], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:15,674][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ basketball] are: tensor([0.4629, 0.1170, 0.0315, 0.0395, 0.0482, 0.0426, 0.0319, 0.0221, 0.0575,
        0.0371, 0.0391, 0.0244, 0.0163, 0.0297], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:15,675][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ basketball] are: tensor([9.9401e-01, 8.1777e-05, 1.8502e-05, 3.9300e-05, 5.1736e-05, 2.0106e-04,
        3.6768e-04, 2.8505e-04, 9.5426e-05, 2.7844e-04, 6.6879e-04, 2.4510e-03,
        8.1169e-04, 6.3601e-04], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:15,677][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ basketball] are: tensor([0.0010, 0.0387, 0.0208, 0.1403, 0.0303, 0.0269, 0.1365, 0.0941, 0.0485,
        0.1948, 0.0284, 0.1311, 0.0938, 0.0148], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:15,678][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ basketball] are: tensor([0.0619, 0.0865, 0.0774, 0.0790, 0.0696, 0.0679, 0.0660, 0.0661, 0.0755,
        0.0621, 0.0721, 0.0759, 0.0683, 0.0717], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:15,680][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ basketball] are: tensor([0.0416, 0.0889, 0.1361, 0.0683, 0.0843, 0.0830, 0.0623, 0.0500, 0.0830,
        0.0617, 0.0875, 0.0627, 0.0404, 0.0502], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:15,682][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0007, 0.0663, 0.0668, 0.0654, 0.0686, 0.0767, 0.0707, 0.0726, 0.0715,
        0.0712, 0.0738, 0.0746, 0.0738, 0.0776, 0.0698], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:15,684][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0765, 0.0686, 0.0635, 0.0716, 0.0645, 0.0534, 0.0592, 0.0663, 0.0748,
        0.0692, 0.0741, 0.0665, 0.0691, 0.0552, 0.0675], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:15,685][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0592, 0.0671, 0.0761, 0.0657, 0.0834, 0.0728, 0.0665, 0.0714, 0.0662,
        0.0577, 0.0716, 0.0622, 0.0610, 0.0628, 0.0565], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:15,687][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.6313, 0.0348, 0.0276, 0.0178, 0.0192, 0.0219, 0.0268, 0.0243, 0.0199,
        0.0254, 0.0192, 0.0176, 0.0276, 0.0319, 0.0546], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:15,689][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0013, 0.0770, 0.0742, 0.0714, 0.0694, 0.0659, 0.0681, 0.0707, 0.0678,
        0.0695, 0.0753, 0.0692, 0.0737, 0.0727, 0.0737], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:15,691][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0846, 0.0588, 0.0599, 0.0602, 0.0637, 0.0628, 0.0650, 0.0655, 0.0622,
        0.0688, 0.0741, 0.0679, 0.0678, 0.0692, 0.0695], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:15,693][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0392, 0.0340, 0.0656, 0.0691, 0.0854, 0.0858, 0.0730, 0.0624, 0.0841,
        0.0548, 0.0891, 0.0681, 0.0541, 0.0888, 0.0465], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:15,694][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.6487, 0.0351, 0.0288, 0.0140, 0.0462, 0.0244, 0.0131, 0.0126, 0.0556,
        0.0148, 0.0406, 0.0200, 0.0095, 0.0255, 0.0111], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:15,696][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ to] are: tensor([9.8837e-01, 9.1346e-05, 3.1545e-05, 5.0254e-05, 8.0321e-05, 3.1314e-04,
        4.0551e-04, 3.8513e-04, 2.0701e-04, 4.6309e-04, 1.2123e-03, 3.4516e-03,
        1.4580e-03, 1.2873e-03, 2.1921e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:15,698][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0028, 0.0210, 0.0426, 0.0545, 0.0588, 0.0548, 0.0457, 0.1156, 0.1328,
        0.1749, 0.0520, 0.0770, 0.0682, 0.0480, 0.0514], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:15,699][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0513, 0.0822, 0.0738, 0.0769, 0.0652, 0.0648, 0.0621, 0.0640, 0.0718,
        0.0573, 0.0682, 0.0725, 0.0655, 0.0678, 0.0566], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:15,701][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0397, 0.0775, 0.1451, 0.0643, 0.0952, 0.0778, 0.0446, 0.0432, 0.0797,
        0.0528, 0.0912, 0.0542, 0.0390, 0.0547, 0.0409], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:15,762][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:24:15,763][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:15,765][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:15,766][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:15,768][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:15,769][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:15,770][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:15,771][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:15,772][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:15,772][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:15,773][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:15,774][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:15,775][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:15,777][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.5447, 0.4553], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:15,778][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.4688, 0.5312], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:15,780][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.4454, 0.5546], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:15,782][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.7732, 0.2268], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:15,783][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0090, 0.9910], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:15,784][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0270, 0.9730], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:15,784][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([1.0000e+00, 1.6711e-06], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:15,785][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.7613, 0.2387], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:15,786][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.3714, 0.6286], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:15,787][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.1396, 0.8604], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:15,788][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.5056, 0.4944], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:15,789][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0390, 0.9610], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:15,791][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Erica] are: tensor([0.2019, 0.4120, 0.3861], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:15,792][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Erica] are: tensor([0.2412, 0.6701, 0.0887], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:15,794][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Erica] are: tensor([0.2945, 0.3470, 0.3585], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:15,796][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Erica] are: tensor([0.5195, 0.1459, 0.3346], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:15,797][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Erica] are: tensor([0.0060, 0.5605, 0.4334], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:15,799][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Erica] are: tensor([0.0141, 0.4918, 0.4942], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:15,800][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Erica] are: tensor([1.0000e+00, 1.4216e-06, 2.6487e-06], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:15,801][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Erica] are: tensor([0.4394, 0.0815, 0.4792], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:15,803][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Erica] are: tensor([0.2331, 0.4490, 0.3179], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:15,804][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Erica] are: tensor([0.0685, 0.3152, 0.6163], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:15,806][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Erica] are: tensor([0.3407, 0.3329, 0.3265], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:15,808][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Erica] are: tensor([0.0162, 0.4008, 0.5831], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:15,809][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.2094, 0.2853, 0.3403, 0.1650], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:15,811][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0348, 0.7563, 0.1025, 0.1064], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:15,813][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.2170, 0.2550, 0.2634, 0.2645], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:15,814][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.6623, 0.0736, 0.1447, 0.1194], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:15,816][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0048, 0.4031, 0.3068, 0.2853], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:15,817][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0083, 0.3424, 0.3385, 0.3107], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:15,819][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([9.9997e-01, 6.1700e-06, 9.2982e-06, 1.3261e-05], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:15,820][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0950, 0.0138, 0.8638, 0.0274], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:15,822][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.1874, 0.2762, 0.2253, 0.3111], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:15,823][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0336, 0.2024, 0.4366, 0.3274], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:15,825][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.2447, 0.2521, 0.2497, 0.2534], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:15,826][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0121, 0.2767, 0.4209, 0.2903], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:15,827][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Joshua] are: tensor([0.1419, 0.2329, 0.2163, 0.1844, 0.2245], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:15,828][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Joshua] are: tensor([0.0829, 0.5318, 0.0813, 0.1298, 0.1742], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:15,829][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Joshua] are: tensor([0.1676, 0.1984, 0.2078, 0.2079, 0.2183], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:15,829][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Joshua] are: tensor([0.5052, 0.0285, 0.2100, 0.1563, 0.1000], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:15,831][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Joshua] are: tensor([0.0034, 0.3475, 0.2338, 0.2415, 0.1737], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:15,832][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Joshua] are: tensor([0.0060, 0.2636, 0.2588, 0.2365, 0.2352], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:15,834][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Joshua] are: tensor([9.9999e-01, 1.8489e-06, 3.2133e-06, 4.5812e-06, 3.3178e-06],
       device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:15,835][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Joshua] are: tensor([0.1735, 0.0402, 0.3732, 0.1803, 0.2329], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:15,837][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Joshua] are: tensor([0.1484, 0.2458, 0.1594, 0.2602, 0.1862], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:15,838][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Joshua] are: tensor([0.0287, 0.1408, 0.2768, 0.2125, 0.3411], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:15,840][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Joshua] are: tensor([0.2048, 0.1957, 0.1943, 0.1964, 0.2087], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:15,841][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Joshua] are: tensor([0.0082, 0.2047, 0.3075, 0.2160, 0.2636], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:15,843][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([0.1339, 0.1795, 0.1959, 0.1348, 0.1695, 0.1864], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:15,845][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([0.0521, 0.3762, 0.0156, 0.0551, 0.0690, 0.4320], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:15,847][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([0.1366, 0.1685, 0.1740, 0.1756, 0.1823, 0.1630], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:15,848][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([0.2685, 0.0592, 0.1543, 0.1508, 0.2468, 0.1204], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:15,850][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([0.0018, 0.2963, 0.2178, 0.2062, 0.1484, 0.1295], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:15,851][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([0.0046, 0.2169, 0.2123, 0.1935, 0.1936, 0.1791], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:15,852][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([9.9998e-01, 2.0298e-06, 3.4900e-06, 5.0311e-06, 3.5899e-06, 2.5807e-06],
       device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:15,854][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([0.0607, 0.0343, 0.3696, 0.1733, 0.3394, 0.0226], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:15,856][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([0.1292, 0.1990, 0.1316, 0.2178, 0.1460, 0.1764], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:15,857][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([0.0260, 0.1139, 0.2028, 0.1714, 0.2452, 0.2408], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:15,859][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([0.1639, 0.1682, 0.1658, 0.1698, 0.1758, 0.1564], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:15,861][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([0.0072, 0.1579, 0.2336, 0.1724, 0.2018, 0.2272], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:15,862][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0971, 0.1777, 0.1931, 0.1185, 0.1681, 0.1665, 0.0790],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:15,864][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0190, 0.2385, 0.0250, 0.0515, 0.0714, 0.5152, 0.0795],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:15,866][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1188, 0.1450, 0.1495, 0.1505, 0.1569, 0.1414, 0.1380],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:15,867][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.3295, 0.0311, 0.1545, 0.0680, 0.2413, 0.1337, 0.0419],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:15,869][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0019, 0.2572, 0.1901, 0.1744, 0.1352, 0.1235, 0.1179],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:15,870][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0038, 0.1848, 0.1820, 0.1662, 0.1660, 0.1540, 0.1432],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:15,871][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([9.9994e-01, 5.1805e-06, 8.5149e-06, 1.1563e-05, 8.5342e-06, 6.1279e-06,
        1.7034e-05], device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:15,873][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0400, 0.0089, 0.2569, 0.0490, 0.5612, 0.0530, 0.0311],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:15,875][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.1645, 0.1679, 0.1165, 0.1633, 0.1162, 0.1355, 0.1362],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:15,876][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0118, 0.0805, 0.1716, 0.1242, 0.2285, 0.2290, 0.1545],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:15,878][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.1401, 0.1460, 0.1436, 0.1456, 0.1519, 0.1345, 0.1383],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:15,878][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0055, 0.1286, 0.2006, 0.1367, 0.1740, 0.1902, 0.1643],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:15,879][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0797, 0.1634, 0.1589, 0.1175, 0.1531, 0.1485, 0.0890, 0.0899],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:15,880][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0404, 0.2291, 0.0191, 0.0383, 0.0655, 0.4391, 0.1025, 0.0661],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:15,881][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.1055, 0.1271, 0.1304, 0.1321, 0.1371, 0.1239, 0.1216, 0.1221],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:15,882][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.2048, 0.0339, 0.1484, 0.0562, 0.2394, 0.1697, 0.0727, 0.0748],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:15,884][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0015, 0.2326, 0.1719, 0.1571, 0.1220, 0.1080, 0.1062, 0.1008],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:15,886][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.0032, 0.1625, 0.1583, 0.1444, 0.1447, 0.1343, 0.1240, 0.1287],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:15,887][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([9.9993e-01, 4.7723e-06, 7.8180e-06, 1.0836e-05, 7.8327e-06, 5.6896e-06,
        1.5884e-05, 1.6242e-05], device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:15,888][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0337, 0.0072, 0.2497, 0.0410, 0.4782, 0.0961, 0.0642, 0.0299],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:15,890][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.1492, 0.1456, 0.0994, 0.1444, 0.0954, 0.1202, 0.1155, 0.1303],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:15,892][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0136, 0.0713, 0.1393, 0.1077, 0.1724, 0.1765, 0.1335, 0.1857],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:15,893][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.1257, 0.1288, 0.1273, 0.1284, 0.1352, 0.1185, 0.1215, 0.1147],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:15,895][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0044, 0.1104, 0.1727, 0.1182, 0.1461, 0.1669, 0.1477, 0.1336],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:15,897][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ office] are: tensor([0.0984, 0.1446, 0.0962, 0.1156, 0.1096, 0.1208, 0.0948, 0.1042, 0.1157],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:15,898][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ office] are: tensor([0.0486, 0.1477, 0.0107, 0.0261, 0.0480, 0.3379, 0.0707, 0.0659, 0.2445],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:15,900][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ office] are: tensor([0.0925, 0.1133, 0.1176, 0.1178, 0.1236, 0.1098, 0.1075, 0.1083, 0.1096],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:15,902][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ office] are: tensor([0.1445, 0.0182, 0.1495, 0.0508, 0.3054, 0.1278, 0.0221, 0.0845, 0.0973],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:15,904][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ office] are: tensor([0.0020, 0.2053, 0.1474, 0.1331, 0.1050, 0.0994, 0.0956, 0.0918, 0.1203],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:15,905][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ office] are: tensor([0.0028, 0.1445, 0.1417, 0.1289, 0.1287, 0.1191, 0.1103, 0.1144, 0.1095],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:15,906][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ office] are: tensor([9.9995e-01, 2.7858e-06, 4.8712e-06, 6.7400e-06, 4.9501e-06, 3.5211e-06,
        1.0167e-05, 1.0389e-05, 6.8666e-06], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:15,908][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ office] are: tensor([0.0441, 0.0098, 0.2832, 0.0497, 0.4370, 0.0494, 0.0416, 0.0261, 0.0591],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:15,910][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ office] are: tensor([0.0890, 0.1360, 0.0833, 0.1355, 0.0813, 0.1037, 0.1110, 0.1314, 0.1288],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:15,911][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ office] are: tensor([0.0102, 0.0556, 0.1055, 0.0874, 0.1401, 0.1458, 0.1090, 0.1546, 0.1916],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:15,913][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ office] are: tensor([0.1145, 0.1120, 0.1107, 0.1128, 0.1191, 0.1052, 0.1076, 0.1012, 0.1169],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:15,915][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ office] are: tensor([0.0044, 0.0956, 0.1448, 0.1024, 0.1235, 0.1394, 0.1270, 0.1175, 0.1454],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:15,916][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.0652, 0.1205, 0.1371, 0.0772, 0.1259, 0.1418, 0.0613, 0.0842, 0.1294,
        0.0574], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:15,918][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.0302, 0.1243, 0.0122, 0.0173, 0.0389, 0.3368, 0.0589, 0.0494, 0.2696,
        0.0624], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:15,920][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.0838, 0.1023, 0.1059, 0.1064, 0.1115, 0.1000, 0.0983, 0.0989, 0.1002,
        0.0926], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:15,922][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.0906, 0.0178, 0.0827, 0.0308, 0.1405, 0.2545, 0.0789, 0.1256, 0.1553,
        0.0233], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:15,923][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.0008, 0.1948, 0.1506, 0.1352, 0.1009, 0.0898, 0.0886, 0.0844, 0.1125,
        0.0423], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:15,925][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.0025, 0.1309, 0.1289, 0.1171, 0.1173, 0.1085, 0.1004, 0.1045, 0.0999,
        0.0900], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:15,926][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([9.9958e-01, 1.8076e-05, 2.6907e-05, 3.5172e-05, 2.6490e-05, 1.9211e-05,
        5.0673e-05, 5.0924e-05, 3.4266e-05, 1.6109e-04], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:15,928][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0303, 0.0072, 0.1804, 0.0291, 0.3895, 0.0725, 0.0650, 0.0636, 0.1452,
        0.0172], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:15,929][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.0907, 0.1092, 0.0761, 0.1111, 0.0742, 0.0929, 0.0937, 0.1128, 0.1122,
        0.1271], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:15,930][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.0052, 0.0447, 0.1068, 0.0726, 0.1542, 0.1522, 0.0968, 0.1455, 0.1812,
        0.0409], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:15,930][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.0998, 0.1048, 0.1023, 0.1044, 0.1092, 0.0954, 0.0980, 0.0912, 0.1049,
        0.0897], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:15,931][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.0035, 0.0833, 0.1310, 0.0883, 0.1121, 0.1253, 0.1089, 0.1049, 0.1322,
        0.1107], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:15,933][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Erica] are: tensor([0.0591, 0.1099, 0.0903, 0.0935, 0.0991, 0.0872, 0.0667, 0.0931, 0.1244,
        0.0724, 0.1044], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:15,934][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Erica] are: tensor([0.0834, 0.0636, 0.0048, 0.0094, 0.0125, 0.1463, 0.0281, 0.0302, 0.1065,
        0.0468, 0.4684], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:15,936][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Erica] are: tensor([0.0786, 0.0933, 0.0970, 0.0965, 0.1015, 0.0903, 0.0886, 0.0893, 0.0908,
        0.0845, 0.0897], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:15,938][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Erica] are: tensor([0.1654, 0.0204, 0.0699, 0.0467, 0.0982, 0.1444, 0.0251, 0.0461, 0.1712,
        0.0534, 0.1592], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:15,940][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Erica] are: tensor([0.0008, 0.1708, 0.1164, 0.1182, 0.0894, 0.0821, 0.0853, 0.0787, 0.1180,
        0.0365, 0.1039], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:15,941][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Erica] are: tensor([0.0026, 0.1184, 0.1167, 0.1054, 0.1064, 0.0985, 0.0908, 0.0937, 0.0906,
        0.0811, 0.0958], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:15,943][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Erica] are: tensor([9.9957e-01, 1.0165e-05, 1.6644e-05, 2.1928e-05, 1.6495e-05, 1.2013e-05,
        3.2424e-05, 3.2685e-05, 2.1929e-05, 1.0725e-04, 1.6344e-04],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:15,944][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Erica] are: tensor([0.1586, 0.0166, 0.1160, 0.0482, 0.1296, 0.0386, 0.0275, 0.0385, 0.1316,
        0.0504, 0.2445], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:15,946][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Erica] are: tensor([0.0439, 0.0972, 0.0596, 0.1039, 0.0673, 0.0859, 0.0945, 0.1167, 0.1179,
        0.1329, 0.0803], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:15,948][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Erica] are: tensor([0.0063, 0.0421, 0.0934, 0.0684, 0.1367, 0.1343, 0.0887, 0.1306, 0.1635,
        0.0415, 0.0945], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:15,949][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Erica] are: tensor([0.0962, 0.0922, 0.0916, 0.0928, 0.0974, 0.0871, 0.0886, 0.0830, 0.0952,
        0.0807, 0.0952], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:15,951][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Erica] are: tensor([0.0038, 0.0760, 0.1084, 0.0791, 0.0940, 0.1102, 0.1000, 0.0931, 0.1157,
        0.1013, 0.1185], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:15,953][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.0588, 0.0900, 0.0914, 0.0679, 0.0912, 0.0900, 0.0567, 0.0767, 0.1379,
        0.0587, 0.1060, 0.0748], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:15,955][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0317, 0.0627, 0.0024, 0.0084, 0.0088, 0.1050, 0.0192, 0.0235, 0.0680,
        0.0554, 0.2636, 0.3512], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:15,956][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.0718, 0.0860, 0.0896, 0.0895, 0.0940, 0.0833, 0.0817, 0.0822, 0.0835,
        0.0778, 0.0825, 0.0781], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:15,958][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.1315, 0.0154, 0.0869, 0.0477, 0.2040, 0.0643, 0.0263, 0.0952, 0.0813,
        0.0281, 0.2054, 0.0140], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:15,960][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.0007, 0.1645, 0.1248, 0.1207, 0.0810, 0.0749, 0.0761, 0.0716, 0.0997,
        0.0375, 0.1040, 0.0445], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:15,962][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.0022, 0.1081, 0.1067, 0.0969, 0.0976, 0.0902, 0.0835, 0.0867, 0.0831,
        0.0746, 0.0886, 0.0816], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:15,963][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([9.9956e-01, 8.3334e-06, 1.3295e-05, 1.7565e-05, 1.3376e-05, 9.8135e-06,
        2.5877e-05, 2.6211e-05, 1.6943e-05, 8.5501e-05, 1.3048e-04, 9.2362e-05],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:15,965][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0217, 0.0067, 0.1207, 0.0275, 0.3146, 0.0196, 0.0416, 0.0457, 0.0638,
        0.0192, 0.3021, 0.0169], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:15,966][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.0570, 0.0962, 0.0570, 0.0976, 0.0584, 0.0761, 0.0832, 0.1027, 0.0995,
        0.1151, 0.0716, 0.0856], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:15,968][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.0069, 0.0427, 0.0869, 0.0646, 0.1171, 0.1136, 0.0784, 0.1162, 0.1408,
        0.0411, 0.0876, 0.1040], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:15,970][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0838, 0.0862, 0.0850, 0.0871, 0.0898, 0.0802, 0.0814, 0.0765, 0.0871,
        0.0744, 0.0872, 0.0813], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:15,972][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.0030, 0.0672, 0.0998, 0.0718, 0.0850, 0.0961, 0.0882, 0.0842, 0.1036,
        0.0909, 0.1105, 0.0997], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:15,973][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0583, 0.0991, 0.0936, 0.0732, 0.0836, 0.0859, 0.0600, 0.0556, 0.0969,
        0.0634, 0.1022, 0.0915, 0.0366], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:15,975][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0071, 0.0281, 0.0042, 0.0075, 0.0154, 0.0991, 0.0249, 0.0229, 0.1000,
        0.0370, 0.3272, 0.3074, 0.0192], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:15,977][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0669, 0.0798, 0.0823, 0.0828, 0.0865, 0.0779, 0.0764, 0.0767, 0.0775,
        0.0723, 0.0758, 0.0727, 0.0724], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:15,978][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0969, 0.0133, 0.0897, 0.0523, 0.1332, 0.0812, 0.0273, 0.0702, 0.1754,
        0.0230, 0.1979, 0.0314, 0.0080], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:15,979][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0007, 0.1512, 0.1147, 0.1063, 0.0823, 0.0750, 0.0750, 0.0706, 0.1005,
        0.0370, 0.0968, 0.0450, 0.0449], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:15,980][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0019, 0.1006, 0.0991, 0.0900, 0.0907, 0.0839, 0.0775, 0.0807, 0.0771,
        0.0693, 0.0824, 0.0760, 0.0708], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:15,981][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([9.9920e-01, 1.2391e-05, 1.9303e-05, 2.5336e-05, 1.9623e-05, 1.4599e-05,
        3.7475e-05, 3.7825e-05, 2.4971e-05, 1.1886e-04, 1.8295e-04, 1.2899e-04,
        1.8065e-04], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:15,982][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0189, 0.0041, 0.1204, 0.0204, 0.2760, 0.0339, 0.0271, 0.0174, 0.1129,
        0.0182, 0.3051, 0.0340, 0.0116], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:15,984][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0720, 0.0893, 0.0548, 0.0872, 0.0540, 0.0702, 0.0735, 0.0867, 0.0847,
        0.0979, 0.0661, 0.0768, 0.0867], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:15,985][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0052, 0.0362, 0.0780, 0.0608, 0.1042, 0.1087, 0.0741, 0.1101, 0.1328,
        0.0359, 0.0795, 0.1041, 0.0703], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:15,987][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0802, 0.0795, 0.0791, 0.0800, 0.0833, 0.0745, 0.0753, 0.0710, 0.0807,
        0.0689, 0.0809, 0.0751, 0.0715], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:15,989][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0031, 0.0629, 0.0926, 0.0662, 0.0792, 0.0915, 0.0826, 0.0756, 0.0939,
        0.0838, 0.1017, 0.0954, 0.0716], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:15,990][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ basketball] are: tensor([0.0458, 0.0839, 0.0717, 0.0650, 0.0692, 0.0815, 0.0634, 0.0612, 0.0906,
        0.0591, 0.0844, 0.0949, 0.0569, 0.0724], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:15,992][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ basketball] are: tensor([0.0544, 0.0271, 0.0028, 0.0046, 0.0055, 0.0613, 0.0134, 0.0131, 0.0428,
        0.0178, 0.2397, 0.2016, 0.0167, 0.2991], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:15,994][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ basketball] are: tensor([0.0623, 0.0743, 0.0771, 0.0766, 0.0811, 0.0720, 0.0703, 0.0707, 0.0714,
        0.0668, 0.0707, 0.0672, 0.0671, 0.0721], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:15,996][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ basketball] are: tensor([0.2115, 0.0137, 0.0646, 0.0424, 0.1423, 0.0894, 0.0148, 0.0366, 0.0571,
        0.0303, 0.1461, 0.0484, 0.0155, 0.0874], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:15,997][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ basketball] are: tensor([0.0009, 0.1525, 0.1099, 0.0999, 0.0724, 0.0639, 0.0692, 0.0657, 0.0958,
        0.0316, 0.0853, 0.0368, 0.0424, 0.0738], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:15,999][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ basketball] are: tensor([0.0021, 0.0936, 0.0933, 0.0843, 0.0845, 0.0779, 0.0724, 0.0749, 0.0718,
        0.0649, 0.0762, 0.0706, 0.0663, 0.0671], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:16,001][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ basketball] are: tensor([9.9903e-01, 1.2106e-05, 2.0291e-05, 2.5302e-05, 2.0313e-05, 1.4696e-05,
        3.7377e-05, 3.7298e-05, 2.5049e-05, 1.1746e-04, 1.7969e-04, 1.2661e-04,
        1.7304e-04, 1.8561e-04], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:16,002][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ basketball] are: tensor([0.0840, 0.0151, 0.0857, 0.0575, 0.2132, 0.0508, 0.0396, 0.0337, 0.0602,
        0.0462, 0.1802, 0.0456, 0.0342, 0.0540], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:16,004][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ basketball] are: tensor([0.0515, 0.0817, 0.0465, 0.0823, 0.0479, 0.0603, 0.0737, 0.0868, 0.0795,
        0.0940, 0.0553, 0.0670, 0.0835, 0.0899], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:16,006][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ basketball] are: tensor([0.0043, 0.0348, 0.0726, 0.0556, 0.0955, 0.1047, 0.0707, 0.1055, 0.1257,
        0.0317, 0.0724, 0.1024, 0.0669, 0.0572], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:16,007][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ basketball] are: tensor([0.0781, 0.0727, 0.0727, 0.0735, 0.0775, 0.0687, 0.0707, 0.0660, 0.0758,
        0.0639, 0.0753, 0.0695, 0.0657, 0.0699], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:16,009][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ basketball] are: tensor([0.0037, 0.0591, 0.0839, 0.0605, 0.0718, 0.0834, 0.0771, 0.0701, 0.0878,
        0.0763, 0.0917, 0.0883, 0.0670, 0.0794], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:16,011][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0429, 0.0780, 0.0919, 0.0552, 0.0736, 0.0808, 0.0370, 0.0546, 0.1109,
        0.0416, 0.0959, 0.0867, 0.0461, 0.0683, 0.0365], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:16,013][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0083, 0.0208, 0.0028, 0.0060, 0.0072, 0.0620, 0.0106, 0.0141, 0.0469,
        0.0199, 0.1525, 0.1759, 0.0184, 0.4374, 0.0171], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:16,015][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0576, 0.0699, 0.0723, 0.0725, 0.0760, 0.0683, 0.0667, 0.0670, 0.0675,
        0.0627, 0.0664, 0.0636, 0.0630, 0.0673, 0.0592], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:16,016][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.1512, 0.0083, 0.0549, 0.0205, 0.0922, 0.0402, 0.0125, 0.0762, 0.0625,
        0.0147, 0.1443, 0.0258, 0.0227, 0.2566, 0.0175], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:16,018][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0006, 0.1394, 0.0993, 0.0894, 0.0725, 0.0674, 0.0675, 0.0638, 0.0908,
        0.0328, 0.0870, 0.0401, 0.0403, 0.0744, 0.0347], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:16,020][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0019, 0.0885, 0.0873, 0.0792, 0.0796, 0.0736, 0.0679, 0.0707, 0.0675,
        0.0606, 0.0721, 0.0666, 0.0621, 0.0626, 0.0599], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:16,021][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([9.9784e-01, 2.3781e-05, 3.7171e-05, 4.6669e-05, 3.6602e-05, 2.7138e-05,
        6.6827e-05, 6.6498e-05, 4.5348e-05, 2.0156e-04, 3.0772e-04, 2.1811e-04,
        2.9285e-04, 3.0811e-04, 4.7664e-04], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:16,023][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0213, 0.0036, 0.1002, 0.0201, 0.2358, 0.0227, 0.0131, 0.0363, 0.0747,
        0.0125, 0.2617, 0.0522, 0.0293, 0.0966, 0.0199], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:16,025][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0725, 0.0788, 0.0497, 0.0731, 0.0462, 0.0576, 0.0587, 0.0692, 0.0690,
        0.0769, 0.0571, 0.0638, 0.0727, 0.0812, 0.0735], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:16,027][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0028, 0.0282, 0.0697, 0.0471, 0.1054, 0.1054, 0.0622, 0.0971, 0.1291,
        0.0266, 0.0699, 0.0978, 0.0626, 0.0586, 0.0374], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:16,029][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0687, 0.0701, 0.0693, 0.0702, 0.0732, 0.0649, 0.0661, 0.0622, 0.0705,
        0.0606, 0.0704, 0.0649, 0.0618, 0.0649, 0.0623], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:16,029][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0024, 0.0525, 0.0809, 0.0557, 0.0702, 0.0773, 0.0671, 0.0636, 0.0817,
        0.0693, 0.0873, 0.0793, 0.0626, 0.0765, 0.0738], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:16,033][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:24:16,035][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[10371],
        [16142],
        [ 6656],
        [ 7428],
        [22840],
        [ 6124],
        [ 4102],
        [ 2316],
        [  984],
        [ 2468],
        [ 1530],
        [ 4906],
        [ 1628],
        [  785],
        [ 2635]], device='cuda:0')
[2024-07-24 10:24:16,037][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[10233],
        [11644],
        [ 9446],
        [ 5333],
        [31754],
        [11365],
        [ 6784],
        [ 8335],
        [ 2623],
        [ 7687],
        [ 3833],
        [12675],
        [ 7038],
        [ 7503],
        [ 8881]], device='cuda:0')
[2024-07-24 10:24:16,038][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[30422],
        [43839],
        [43375],
        [43691],
        [43672],
        [43596],
        [43510],
        [43442],
        [43454],
        [43596],
        [43762],
        [43848],
        [43865],
        [43969],
        [43978]], device='cuda:0')
[2024-07-24 10:24:16,040][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[17626],
        [17557],
        [18580],
        [19745],
        [20610],
        [20854],
        [20882],
        [20688],
        [20389],
        [20286],
        [20320],
        [20286],
        [20093],
        [19875],
        [20013]], device='cuda:0')
[2024-07-24 10:24:16,042][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 8028],
        [28871],
        [34215],
        [36549],
        [36880],
        [37076],
        [37866],
        [37917],
        [38216],
        [38339],
        [38448],
        [38270],
        [37873],
        [37891],
        [38011]], device='cuda:0')
[2024-07-24 10:24:16,044][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[5302],
        [4933],
        [5686],
        [5896],
        [6704],
        [7138],
        [7520],
        [7392],
        [8170],
        [7243],
        [9395],
        [9276],
        [8517],
        [8841],
        [7846]], device='cuda:0')
[2024-07-24 10:24:16,045][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[13202],
        [30255],
        [28900],
        [28868],
        [30135],
        [30585],
        [30555],
        [30549],
        [30276],
        [30551],
        [30871],
        [31156],
        [31365],
        [31426],
        [31772]], device='cuda:0')
[2024-07-24 10:24:16,047][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[1163],
        [1676],
        [1508],
        [1873],
        [1977],
        [1901],
        [1752],
        [1752],
        [1733],
        [1776],
        [1820],
        [1897],
        [1984],
        [1981],
        [1894]], device='cuda:0')
[2024-07-24 10:24:16,048][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[30505],
        [19519],
        [22208],
        [19380],
        [18543],
        [18161],
        [15964],
        [15515],
        [15101],
        [14504],
        [16391],
        [15488],
        [15624],
        [15301],
        [14655]], device='cuda:0')
[2024-07-24 10:24:16,050][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[44019],
        [44049],
        [42948],
        [44362],
        [41974],
        [42384],
        [41626],
        [42576],
        [41436],
        [43165],
        [41079],
        [41784],
        [42189],
        [41208],
        [41393]], device='cuda:0')
[2024-07-24 10:24:16,052][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[28886],
        [28860],
        [28865],
        [28806],
        [28828],
        [28806],
        [28723],
        [28617],
        [28600],
        [28675],
        [28830],
        [28851],
        [28572],
        [28830],
        [28749]], device='cuda:0')
[2024-07-24 10:24:16,053][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[49416],
        [16571],
        [33156],
        [36532],
        [30051],
        [44639],
        [48294],
        [36851],
        [42451],
        [42119],
        [39099],
        [38335],
        [28791],
        [27798],
        [36221]], device='cuda:0')
[2024-07-24 10:24:16,055][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[4742],
        [8108],
        [7523],
        [7284],
        [8146],
        [7478],
        [7542],
        [7419],
        [7940],
        [7913],
        [8035],
        [7711],
        [7322],
        [7396],
        [7449]], device='cuda:0')
[2024-07-24 10:24:16,057][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[35630],
        [36104],
        [33872],
        [33538],
        [30090],
        [30119],
        [29890],
        [30456],
        [30049],
        [30320],
        [30683],
        [29604],
        [29625],
        [29716],
        [29543]], device='cuda:0')
[2024-07-24 10:24:16,058][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 8816],
        [38099],
        [ 6332],
        [18458],
        [ 4101],
        [ 1599],
        [ 2372],
        [ 2518],
        [ 1791],
        [ 4464],
        [ 2652],
        [ 4621],
        [ 2299],
        [  544],
        [ 1146]], device='cuda:0')
[2024-07-24 10:24:16,060][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[17833],
        [19504],
        [18783],
        [18678],
        [15735],
        [13858],
        [13805],
        [13806],
        [13361],
        [12532],
        [13045],
        [13487],
        [14683],
        [15210],
        [14553]], device='cuda:0')
[2024-07-24 10:24:16,061][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[34469],
        [32967],
        [27098],
        [23960],
        [26613],
        [17497],
        [16659],
        [17103],
        [15481],
        [15909],
        [27464],
        [27458],
        [27804],
        [21043],
        [16302]], device='cuda:0')
[2024-07-24 10:24:16,063][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[21362],
        [28257],
        [27931],
        [28370],
        [27304],
        [26308],
        [24438],
        [24074],
        [23824],
        [23548],
        [22898],
        [22514],
        [22156],
        [22184],
        [21290]], device='cuda:0')
[2024-07-24 10:24:16,065][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[17025],
        [17934],
        [19507],
        [12914],
        [15444],
        [18506],
        [20463],
        [17689],
        [16948],
        [19549],
        [20063],
        [17434],
        [19284],
        [23378],
        [20099]], device='cuda:0')
[2024-07-24 10:24:16,066][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[29125],
        [25148],
        [25040],
        [23213],
        [21158],
        [20429],
        [20730],
        [21584],
        [22707],
        [22814],
        [22869],
        [22800],
        [23197],
        [24497],
        [24771]], device='cuda:0')
[2024-07-24 10:24:16,068][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[4863],
        [7387],
        [6118],
        [5859],
        [5372],
        [5111],
        [4934],
        [4830],
        [4649],
        [4605],
        [4625],
        [4573],
        [4519],
        [4450],
        [4426]], device='cuda:0')
[2024-07-24 10:24:16,070][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[48974],
        [48974],
        [48974],
        [48974],
        [48974],
        [48974],
        [48975],
        [48975],
        [48975],
        [48980],
        [48981],
        [48981],
        [48985],
        [48985],
        [48993]], device='cuda:0')
[2024-07-24 10:24:16,072][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[19648],
        [15687],
        [17285],
        [11715],
        [18382],
        [16611],
        [10191],
        [13647],
        [16985],
        [22567],
        [26682],
        [20694],
        [23066],
        [25426],
        [23048]], device='cuda:0')
[2024-07-24 10:24:16,073][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[33353],
        [34275],
        [35361],
        [35204],
        [35126],
        [34986],
        [34736],
        [34620],
        [34488],
        [34682],
        [35076],
        [35219],
        [35288],
        [35145],
        [35241]], device='cuda:0')
[2024-07-24 10:24:16,075][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[8391],
        [6477],
        [3458],
        [3510],
        [3041],
        [3638],
        [3754],
        [3900],
        [4193],
        [4069],
        [3960],
        [3930],
        [3809],
        [3815],
        [3715]], device='cuda:0')
[2024-07-24 10:24:16,076][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[23152],
        [42827],
        [44146],
        [44351],
        [44193],
        [44748],
        [44983],
        [45089],
        [45007],
        [45321],
        [45352],
        [45584],
        [45808],
        [45819],
        [45947]], device='cuda:0')
[2024-07-24 10:24:16,078][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[32041],
        [25835],
        [27152],
        [27643],
        [26293],
        [29346],
        [28047],
        [28377],
        [28536],
        [27846],
        [27969],
        [28341],
        [28183],
        [27984],
        [27444]], device='cuda:0')
[2024-07-24 10:24:16,079][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[13081],
        [12320],
        [13952],
        [17408],
        [15730],
        [16713],
        [17528],
        [17375],
        [17706],
        [16840],
        [13995],
        [14601],
        [13846],
        [13599],
        [15274]], device='cuda:0')
[2024-07-24 10:24:16,081][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[42186],
        [13818],
        [31057],
        [23828],
        [38371],
        [45583],
        [43674],
        [39438],
        [44309],
        [35054],
        [39306],
        [36715],
        [40743],
        [42422],
        [45909]], device='cuda:0')
[2024-07-24 10:24:16,083][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[10988],
        [10988],
        [10988],
        [10988],
        [10988],
        [10988],
        [10988],
        [10988],
        [10988],
        [10988],
        [10988],
        [10988],
        [10988],
        [10988],
        [10988]], device='cuda:0')
[2024-07-24 10:24:16,166][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:24:16,168][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:16,169][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:16,170][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:16,172][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:16,173][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:16,175][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:16,176][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:16,177][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:16,179][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:16,180][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:16,181][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:16,182][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:16,183][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.9725, 0.0275], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:16,184][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0043, 0.9957], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:16,184][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0288, 0.9712], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:16,186][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.2133, 0.7867], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:16,187][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.9381, 0.0619], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:16,189][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.9419, 0.0581], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:16,191][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.9448, 0.0552], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:16,192][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0245, 0.9755], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:16,194][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.3516, 0.6484], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:16,195][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.4110, 0.5890], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:16,197][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0014, 0.9986], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:16,198][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.9484, 0.0516], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:16,200][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Erica] are: tensor([0.7301, 0.2520, 0.0179], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:16,202][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Erica] are: tensor([0.0028, 0.7251, 0.2721], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:16,203][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Erica] are: tensor([0.0057, 0.8903, 0.1041], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:16,205][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Erica] are: tensor([0.0974, 0.5461, 0.3565], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:16,206][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Erica] are: tensor([0.9067, 0.0499, 0.0435], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:16,208][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Erica] are: tensor([0.5865, 0.1942, 0.2193], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:16,210][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Erica] are: tensor([0.9576, 0.0205, 0.0219], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:16,211][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Erica] are: tensor([0.0715, 0.8136, 0.1149], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:16,213][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Erica] are: tensor([0.1410, 0.7434, 0.1156], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:16,214][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Erica] are: tensor([0.2942, 0.3734, 0.3324], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:16,216][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Erica] are: tensor([0.0019, 0.5278, 0.4704], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:16,217][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Erica] are: tensor([0.5628, 0.1867, 0.2505], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:16,219][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.7921, 0.1517, 0.0493, 0.0069], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:16,221][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0023, 0.4565, 0.1984, 0.3427], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:16,222][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0055, 0.3426, 0.5690, 0.0829], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:16,224][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0801, 0.3760, 0.2536, 0.2902], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:16,226][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.8831, 0.0442, 0.0386, 0.0341], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:16,227][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.6037, 0.1032, 0.1618, 0.1313], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:16,229][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.8629, 0.0490, 0.0606, 0.0274], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:16,230][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0070, 0.4443, 0.4931, 0.0556], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:16,232][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0495, 0.7751, 0.1055, 0.0698], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:16,233][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.2106, 0.2765, 0.2514, 0.2615], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:16,233][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ and] are: tensor([2.8243e-04, 1.7481e-01, 4.8956e-01, 3.3534e-01], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:16,234][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.6391, 0.0861, 0.1499, 0.1249], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:16,235][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Joshua] are: tensor([0.8220, 0.1326, 0.0110, 0.0103, 0.0240], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:16,236][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Joshua] are: tensor([0.0025, 0.3258, 0.1739, 0.2660, 0.2318], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:16,238][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Joshua] are: tensor([0.0388, 0.5260, 0.1041, 0.0403, 0.2908], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:16,239][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Joshua] are: tensor([0.0506, 0.2893, 0.1866, 0.2353, 0.2382], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:16,241][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Joshua] are: tensor([0.8509, 0.0406, 0.0357, 0.0331, 0.0398], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:16,243][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Joshua] are: tensor([0.4868, 0.1056, 0.1217, 0.1195, 0.1663], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:16,244][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Joshua] are: tensor([0.9119, 0.0239, 0.0362, 0.0101, 0.0179], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:16,246][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Joshua] are: tensor([0.0281, 0.3406, 0.0994, 0.4995, 0.0324], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:16,247][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Joshua] are: tensor([0.0816, 0.5234, 0.0559, 0.0670, 0.2720], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:16,249][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Joshua] are: tensor([0.1729, 0.2158, 0.1908, 0.2031, 0.2174], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:16,251][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Joshua] are: tensor([0.0006, 0.1009, 0.4866, 0.1788, 0.2331], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:16,252][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Joshua] are: tensor([0.4141, 0.1370, 0.1824, 0.1347, 0.1318], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:16,254][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ went] are: tensor([0.9340, 0.0496, 0.0037, 0.0045, 0.0056, 0.0026], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:16,255][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ went] are: tensor([0.0012, 0.2799, 0.1268, 0.2169, 0.1814, 0.1938], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:16,257][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ went] are: tensor([0.0341, 0.5323, 0.0498, 0.0450, 0.3033, 0.0355], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:16,259][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ went] are: tensor([0.0496, 0.2339, 0.1454, 0.1804, 0.1768, 0.2138], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:16,260][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ went] are: tensor([0.7623, 0.0489, 0.0426, 0.0402, 0.0482, 0.0579], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:16,262][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ went] are: tensor([0.2955, 0.1043, 0.1111, 0.1172, 0.1529, 0.2190], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:16,264][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ went] are: tensor([0.8861, 0.0365, 0.0316, 0.0139, 0.0134, 0.0184], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:16,265][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ went] are: tensor([0.0141, 0.2235, 0.3517, 0.0281, 0.2111, 0.1715], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:16,267][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.0396, 0.1798, 0.0217, 0.0267, 0.1743, 0.5579], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:16,268][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ went] are: tensor([0.1301, 0.1738, 0.1550, 0.1660, 0.1794, 0.1958], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:16,270][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ went] are: tensor([1.1618e-04, 1.3092e-01, 1.0376e-01, 5.0613e-01, 2.0036e-01, 5.8711e-02],
       device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:16,271][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ went] are: tensor([0.4198, 0.1000, 0.1414, 0.1362, 0.1125, 0.0900], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:16,273][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.5164, 0.1374, 0.0508, 0.0096, 0.2051, 0.0753, 0.0054],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:16,275][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0015, 0.2307, 0.1090, 0.1931, 0.1547, 0.1756, 0.1353],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:16,276][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0006, 0.2290, 0.2005, 0.0299, 0.4309, 0.0885, 0.0207],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:16,278][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0352, 0.1944, 0.1232, 0.1502, 0.1611, 0.1906, 0.1451],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:16,279][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.7392, 0.0447, 0.0392, 0.0359, 0.0436, 0.0512, 0.0462],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:16,281][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.2961, 0.0680, 0.0932, 0.0865, 0.1293, 0.2009, 0.1259],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:16,283][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.7272, 0.0704, 0.0663, 0.0361, 0.0398, 0.0490, 0.0113],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:16,283][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0044, 0.1313, 0.1650, 0.0319, 0.1775, 0.4791, 0.0109],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:16,284][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0280, 0.1232, 0.0219, 0.0194, 0.1414, 0.6226, 0.0435],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:16,285][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.1081, 0.1456, 0.1324, 0.1396, 0.1535, 0.1662, 0.1545],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:16,286][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ to] are: tensor([5.9022e-05, 7.7472e-02, 1.6228e-01, 2.7776e-01, 2.6981e-01, 1.2508e-01,
        8.7538e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:16,287][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.4127, 0.0903, 0.1115, 0.1128, 0.0998, 0.0812, 0.0917],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:16,289][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.4461, 0.1892, 0.0424, 0.0181, 0.1493, 0.1079, 0.0230, 0.0240],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:16,291][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0024, 0.1982, 0.1024, 0.1596, 0.1349, 0.1511, 0.1216, 0.1298],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:16,292][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0005, 0.0999, 0.2398, 0.0431, 0.3942, 0.0877, 0.1074, 0.0275],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:16,294][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0319, 0.1725, 0.1124, 0.1353, 0.1363, 0.1626, 0.1296, 0.1192],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:16,296][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.7361, 0.0388, 0.0337, 0.0312, 0.0370, 0.0447, 0.0405, 0.0381],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:16,297][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.2142, 0.0735, 0.0907, 0.0866, 0.1264, 0.1780, 0.1260, 0.1045],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:16,299][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.8263, 0.0421, 0.0456, 0.0220, 0.0248, 0.0291, 0.0068, 0.0033],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:16,300][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0014, 0.1229, 0.1477, 0.0335, 0.0902, 0.4994, 0.0616, 0.0432],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:16,302][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0312, 0.0858, 0.0145, 0.0156, 0.1190, 0.6430, 0.0549, 0.0359],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:16,304][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0953, 0.1264, 0.1145, 0.1213, 0.1330, 0.1434, 0.1334, 0.1325],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:16,305][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ the] are: tensor([6.4196e-05, 1.0914e-01, 1.4529e-01, 2.2285e-01, 2.3221e-01, 7.2771e-02,
        7.7237e-02, 1.4044e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:16,306][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.3858, 0.0791, 0.1050, 0.0952, 0.0906, 0.0654, 0.0798, 0.0990],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:16,308][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ office] are: tensor([0.9227, 0.0390, 0.0047, 0.0047, 0.0098, 0.0068, 0.0021, 0.0028, 0.0073],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:16,310][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ office] are: tensor([0.0024, 0.1789, 0.0828, 0.1423, 0.1178, 0.1357, 0.1119, 0.1169, 0.1114],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:16,312][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ office] are: tensor([0.0060, 0.3597, 0.0939, 0.0169, 0.3459, 0.1284, 0.0199, 0.0199, 0.0095],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:16,313][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ office] are: tensor([0.0270, 0.1541, 0.0961, 0.1249, 0.1175, 0.1412, 0.1161, 0.1101, 0.1131],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:16,315][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ office] are: tensor([0.6767, 0.0390, 0.0344, 0.0320, 0.0386, 0.0464, 0.0425, 0.0404, 0.0499],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:16,317][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ office] are: tensor([0.3219, 0.0468, 0.0727, 0.0614, 0.0924, 0.1334, 0.0878, 0.0774, 0.1063],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:16,318][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ office] are: tensor([9.6208e-01, 8.2878e-03, 1.0012e-02, 4.9927e-03, 5.0015e-03, 6.3955e-03,
        1.6210e-03, 9.1405e-04, 7.0019e-04], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:16,319][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ office] are: tensor([0.0018, 0.1876, 0.0451, 0.0529, 0.0496, 0.2697, 0.0914, 0.2467, 0.0552],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:16,321][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ office] are: tensor([0.0470, 0.0643, 0.0079, 0.0086, 0.0544, 0.3395, 0.0265, 0.0289, 0.4228],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:16,323][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ office] are: tensor([0.0866, 0.1100, 0.0995, 0.1042, 0.1146, 0.1260, 0.1173, 0.1161, 0.1256],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:16,324][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ office] are: tensor([1.0576e-04, 6.2656e-02, 4.8374e-02, 1.6209e-01, 1.7119e-01, 4.7213e-02,
        9.5530e-02, 3.2041e-01, 9.2427e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:16,326][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ office] are: tensor([0.4080, 0.0600, 0.0765, 0.0822, 0.0681, 0.0550, 0.0804, 0.0949, 0.0750],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:16,327][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.4036, 0.1297, 0.0482, 0.0132, 0.1669, 0.0834, 0.0151, 0.0318, 0.0794,
        0.0287], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:16,329][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.0049, 0.1593, 0.0862, 0.1274, 0.1047, 0.1140, 0.0921, 0.0974, 0.0943,
        0.1197], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:16,330][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [.] are: tensor([3.2422e-04, 5.8035e-02, 1.2745e-01, 1.7191e-02, 4.2961e-01, 4.1277e-02,
        1.5255e-02, 1.0434e-01, 1.8655e-01, 1.9960e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:16,332][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0303, 0.1363, 0.0915, 0.1036, 0.1111, 0.1285, 0.0998, 0.0958, 0.0976,
        0.1056], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:16,334][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.6717, 0.0359, 0.0320, 0.0291, 0.0344, 0.0414, 0.0379, 0.0354, 0.0441,
        0.0382], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:16,335][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.4300, 0.0249, 0.0589, 0.0407, 0.0708, 0.1273, 0.0718, 0.0597, 0.0894,
        0.0265], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:16,335][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.8270, 0.0386, 0.0438, 0.0184, 0.0240, 0.0312, 0.0065, 0.0031, 0.0032,
        0.0041], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:16,336][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0021, 0.0472, 0.1055, 0.0104, 0.1163, 0.2327, 0.0379, 0.1735, 0.2605,
        0.0140], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:16,337][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.0301, 0.0418, 0.0093, 0.0064, 0.0633, 0.3450, 0.0277, 0.0222, 0.4365,
        0.0176], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:16,338][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.0769, 0.0985, 0.0890, 0.0941, 0.1029, 0.1120, 0.1048, 0.1038, 0.1117,
        0.1062], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:16,339][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [.] are: tensor([8.1793e-05, 7.9131e-02, 2.3925e-01, 1.1861e-01, 2.5122e-01, 5.3917e-02,
        5.6374e-02, 8.4486e-02, 6.1335e-02, 5.5597e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:16,341][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.3638, 0.0599, 0.0865, 0.0762, 0.0743, 0.0551, 0.0646, 0.0827, 0.0653,
        0.0715], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:16,343][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Erica] are: tensor([0.7118, 0.1083, 0.0097, 0.0184, 0.0256, 0.0260, 0.0094, 0.0247, 0.0362,
        0.0187, 0.0113], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:16,344][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Erica] are: tensor([0.0036, 0.1336, 0.0784, 0.1179, 0.0960, 0.1030, 0.0839, 0.0915, 0.0874,
        0.1127, 0.0919], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:16,346][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Erica] are: tensor([0.0011, 0.4923, 0.0393, 0.0335, 0.1451, 0.0966, 0.0166, 0.0333, 0.0392,
        0.0806, 0.0225], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:16,348][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Erica] are: tensor([0.0228, 0.1244, 0.0787, 0.1005, 0.0966, 0.1175, 0.0947, 0.0900, 0.0903,
        0.0979, 0.0865], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:16,349][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Erica] are: tensor([0.6108, 0.0358, 0.0318, 0.0296, 0.0348, 0.0423, 0.0389, 0.0366, 0.0452,
        0.0402, 0.0540], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:16,351][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Erica] are: tensor([0.2543, 0.0427, 0.0542, 0.0539, 0.0714, 0.1158, 0.0774, 0.0684, 0.0982,
        0.0548, 0.1088], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:16,353][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Erica] are: tensor([0.9041, 0.0183, 0.0195, 0.0089, 0.0122, 0.0129, 0.0026, 0.0017, 0.0033,
        0.0028, 0.0136], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:16,355][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Erica] are: tensor([0.0150, 0.2208, 0.0295, 0.1316, 0.0127, 0.1500, 0.1210, 0.0933, 0.0771,
        0.0626, 0.0864], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:16,356][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Erica] are: tensor([0.0576, 0.0271, 0.0043, 0.0044, 0.0159, 0.0774, 0.0100, 0.0110, 0.1851,
        0.0288, 0.5785], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:16,358][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Erica] are: tensor([0.0737, 0.0886, 0.0793, 0.0834, 0.0906, 0.0996, 0.0935, 0.0922, 0.0995,
        0.0952, 0.1043], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:16,359][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Erica] are: tensor([6.9601e-05, 5.9543e-02, 4.4488e-02, 1.4162e-01, 1.6040e-01, 7.8845e-02,
        7.8623e-02, 1.6470e-01, 8.5969e-02, 1.1187e-01, 7.3868e-02],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:16,361][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Erica] are: tensor([0.2376, 0.0733, 0.0837, 0.0852, 0.0705, 0.0631, 0.0730, 0.0851, 0.0754,
        0.0826, 0.0705], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:16,362][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.7556, 0.0880, 0.0111, 0.0146, 0.0288, 0.0160, 0.0091, 0.0135, 0.0247,
        0.0200, 0.0129, 0.0058], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:16,364][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0027, 0.1222, 0.0748, 0.1017, 0.0940, 0.0920, 0.0792, 0.0832, 0.0794,
        0.0999, 0.0903, 0.0806], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:16,366][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0105, 0.1186, 0.2115, 0.0310, 0.2242, 0.0199, 0.0411, 0.0417, 0.0681,
        0.0528, 0.1575, 0.0230], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:16,368][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.0203, 0.1145, 0.0747, 0.0908, 0.0905, 0.1081, 0.0882, 0.0842, 0.0847,
        0.0879, 0.0811, 0.0750], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:16,369][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.5592, 0.0353, 0.0325, 0.0297, 0.0361, 0.0420, 0.0387, 0.0366, 0.0450,
        0.0401, 0.0545, 0.0504], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:16,371][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.1978, 0.0357, 0.0685, 0.0458, 0.0740, 0.0952, 0.0689, 0.0578, 0.0904,
        0.0376, 0.1348, 0.0935], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:16,373][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.8316, 0.0350, 0.0319, 0.0174, 0.0177, 0.0171, 0.0060, 0.0021, 0.0029,
        0.0033, 0.0210, 0.0139], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:16,375][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0051, 0.0773, 0.0781, 0.0399, 0.0538, 0.0961, 0.0595, 0.0942, 0.0586,
        0.0404, 0.3197, 0.0773], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:16,377][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.0247, 0.0276, 0.0034, 0.0038, 0.0157, 0.0678, 0.0124, 0.0087, 0.1660,
        0.0182, 0.4577, 0.1939], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:16,378][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.0650, 0.0800, 0.0718, 0.0752, 0.0827, 0.0893, 0.0833, 0.0829, 0.0900,
        0.0860, 0.0952, 0.0986], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:16,379][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([4.2875e-05, 6.2662e-02, 6.8788e-02, 1.1873e-01, 1.3676e-01, 5.3557e-02,
        4.9221e-02, 1.3947e-01, 6.8799e-02, 1.6086e-01, 1.2759e-01, 1.3517e-02],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:16,381][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.2374, 0.0571, 0.0667, 0.0786, 0.0599, 0.0551, 0.0650, 0.0793, 0.0646,
        0.0805, 0.0682, 0.0876], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:16,383][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.3650, 0.1345, 0.0301, 0.0199, 0.1094, 0.0946, 0.0181, 0.0253, 0.0719,
        0.0386, 0.0419, 0.0328, 0.0179], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:16,384][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0042, 0.1173, 0.0669, 0.0962, 0.0833, 0.0884, 0.0752, 0.0773, 0.0742,
        0.0904, 0.0787, 0.0770, 0.0709], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:16,385][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0011, 0.1419, 0.2252, 0.0508, 0.2245, 0.0507, 0.0525, 0.0412, 0.0497,
        0.0286, 0.0877, 0.0293, 0.0167], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:16,386][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0192, 0.1067, 0.0707, 0.0840, 0.0872, 0.1023, 0.0826, 0.0768, 0.0810,
        0.0817, 0.0762, 0.0703, 0.0612], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:16,386][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.5721, 0.0324, 0.0295, 0.0265, 0.0321, 0.0376, 0.0344, 0.0324, 0.0396,
        0.0353, 0.0480, 0.0443, 0.0359], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:16,388][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.1275, 0.0408, 0.0585, 0.0501, 0.0774, 0.1042, 0.0718, 0.0607, 0.0932,
        0.0459, 0.1027, 0.1030, 0.0642], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:16,390][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.7613, 0.0446, 0.0447, 0.0222, 0.0243, 0.0290, 0.0066, 0.0025, 0.0041,
        0.0047, 0.0287, 0.0210, 0.0062], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:16,392][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0006, 0.0421, 0.0695, 0.0107, 0.0575, 0.1592, 0.0141, 0.0311, 0.0949,
        0.0259, 0.1544, 0.3371, 0.0028], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:16,393][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0130, 0.0126, 0.0032, 0.0026, 0.0211, 0.1094, 0.0099, 0.0058, 0.1800,
        0.0122, 0.3241, 0.2981, 0.0080], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:16,395][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0569, 0.0733, 0.0665, 0.0703, 0.0767, 0.0836, 0.0778, 0.0773, 0.0837,
        0.0796, 0.0873, 0.0922, 0.0747], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:16,396][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ a] are: tensor([6.7651e-05, 6.5045e-02, 5.8560e-02, 1.6218e-01, 1.4839e-01, 4.2073e-02,
        4.7708e-02, 9.3162e-02, 6.4303e-02, 1.3848e-01, 9.3075e-02, 4.5008e-02,
        4.1949e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:16,398][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.2451, 0.0492, 0.0706, 0.0714, 0.0639, 0.0517, 0.0554, 0.0724, 0.0581,
        0.0658, 0.0571, 0.0764, 0.0628], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:16,400][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ basketball] are: tensor([0.9343, 0.0216, 0.0025, 0.0029, 0.0056, 0.0060, 0.0018, 0.0029, 0.0057,
        0.0041, 0.0027, 0.0017, 0.0022, 0.0060], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:16,401][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ basketball] are: tensor([0.0043, 0.1007, 0.0703, 0.0872, 0.0808, 0.0791, 0.0700, 0.0671, 0.0699,
        0.0808, 0.0814, 0.0719, 0.0625, 0.0740], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:16,403][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ basketball] are: tensor([0.0012, 0.2850, 0.0751, 0.0185, 0.1736, 0.0341, 0.0559, 0.0348, 0.0600,
        0.0571, 0.0330, 0.0512, 0.0147, 0.1059], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:16,405][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ basketball] are: tensor([0.0192, 0.1032, 0.0651, 0.0801, 0.0766, 0.0894, 0.0777, 0.0715, 0.0722,
        0.0800, 0.0715, 0.0659, 0.0592, 0.0683], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:16,406][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ basketball] are: tensor([0.5427, 0.0303, 0.0275, 0.0252, 0.0298, 0.0363, 0.0333, 0.0315, 0.0377,
        0.0337, 0.0459, 0.0430, 0.0346, 0.0485], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:16,408][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ basketball] are: tensor([0.2077, 0.0261, 0.0457, 0.0368, 0.0572, 0.0836, 0.0559, 0.0538, 0.0704,
        0.0323, 0.0916, 0.0934, 0.0618, 0.0835], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:16,410][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ basketball] are: tensor([0.9266, 0.0080, 0.0153, 0.0067, 0.0052, 0.0070, 0.0021, 0.0011, 0.0015,
        0.0017, 0.0114, 0.0086, 0.0021, 0.0028], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:16,412][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ basketball] are: tensor([0.0023, 0.0904, 0.0178, 0.0228, 0.0178, 0.1562, 0.0529, 0.0808, 0.0352,
        0.0335, 0.0596, 0.3508, 0.0577, 0.0220], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:16,414][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ basketball] are: tensor([0.1022, 0.0099, 0.0016, 0.0019, 0.0061, 0.0359, 0.0052, 0.0048, 0.0640,
        0.0076, 0.2063, 0.1703, 0.0101, 0.3741], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:16,415][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ basketball] are: tensor([0.0601, 0.0681, 0.0588, 0.0634, 0.0679, 0.0758, 0.0717, 0.0706, 0.0746,
        0.0731, 0.0789, 0.0833, 0.0686, 0.0853], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:16,417][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ basketball] are: tensor([5.2966e-05, 3.8562e-02, 7.1706e-02, 1.4871e-01, 8.9983e-02, 1.9701e-02,
        4.3247e-02, 1.0961e-01, 5.4147e-02, 7.2820e-02, 1.3257e-01, 9.9716e-02,
        1.0638e-01, 1.2799e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:16,418][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ basketball] are: tensor([0.2815, 0.0428, 0.0530, 0.0576, 0.0519, 0.0396, 0.0517, 0.0619, 0.0474,
        0.0627, 0.0551, 0.0689, 0.0654, 0.0606], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:16,420][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.2752, 0.0809, 0.0433, 0.0088, 0.1862, 0.0721, 0.0064, 0.0216, 0.0844,
        0.0209, 0.0479, 0.0203, 0.0169, 0.1127, 0.0026], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:16,422][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0041, 0.0993, 0.0586, 0.0857, 0.0743, 0.0777, 0.0636, 0.0682, 0.0642,
        0.0817, 0.0686, 0.0661, 0.0610, 0.0712, 0.0558], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:16,423][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ to] are: tensor([1.1881e-04, 1.1741e-01, 1.1569e-01, 1.4560e-02, 2.3995e-01, 4.1199e-02,
        6.8425e-03, 1.6155e-01, 6.9636e-02, 1.4956e-02, 7.5984e-02, 4.5613e-02,
        3.9896e-02, 5.0508e-02, 6.0840e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:16,425][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0163, 0.0918, 0.0610, 0.0726, 0.0785, 0.0924, 0.0704, 0.0688, 0.0683,
        0.0718, 0.0660, 0.0638, 0.0557, 0.0641, 0.0586], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:16,427][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.5252, 0.0298, 0.0269, 0.0242, 0.0290, 0.0345, 0.0311, 0.0297, 0.0363,
        0.0322, 0.0442, 0.0413, 0.0335, 0.0460, 0.0361], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:16,429][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.1755, 0.0248, 0.0437, 0.0355, 0.0590, 0.0922, 0.0556, 0.0506, 0.0704,
        0.0310, 0.0791, 0.0885, 0.0581, 0.0855, 0.0505], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:16,430][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.7187, 0.0423, 0.0428, 0.0226, 0.0248, 0.0364, 0.0072, 0.0030, 0.0056,
        0.0058, 0.0384, 0.0295, 0.0059, 0.0122, 0.0047], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:16,432][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0007, 0.0352, 0.0375, 0.0065, 0.0470, 0.1139, 0.0029, 0.0704, 0.1430,
        0.0090, 0.1096, 0.3183, 0.0326, 0.0700, 0.0033], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:16,434][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0211, 0.0087, 0.0022, 0.0017, 0.0100, 0.0586, 0.0047, 0.0046, 0.0783,
        0.0093, 0.1853, 0.1883, 0.0069, 0.4037, 0.0169], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:16,435][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0490, 0.0624, 0.0565, 0.0598, 0.0653, 0.0713, 0.0665, 0.0661, 0.0711,
        0.0679, 0.0743, 0.0781, 0.0637, 0.0813, 0.0668], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:16,436][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ to] are: tensor([3.0843e-05, 4.4874e-02, 6.5590e-02, 1.1821e-01, 1.6207e-01, 5.4705e-02,
        4.0736e-02, 1.0853e-01, 6.1837e-02, 9.1761e-02, 8.3819e-02, 3.5821e-02,
        7.1827e-02, 3.6664e-02, 2.3520e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:16,436][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.1866, 0.0498, 0.0610, 0.0677, 0.0549, 0.0473, 0.0514, 0.0676, 0.0538,
        0.0616, 0.0518, 0.0717, 0.0613, 0.0606, 0.0529], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:16,513][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:24:16,515][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:16,516][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:16,517][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:16,519][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:16,520][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:16,521][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:16,523][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:16,524][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:16,525][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:16,527][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:16,528][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:16,529][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:16,531][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.8362, 0.1638], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:16,533][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.1595, 0.8405], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:16,534][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0014, 0.9986], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:16,536][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.4764, 0.5236], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:16,537][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.9694, 0.0306], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:16,539][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.9988, 0.0012], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:16,540][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.9201, 0.0799], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:16,541][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.6631, 0.3369], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:16,542][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.3516, 0.6484], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:16,543][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.9620, 0.0380], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:16,543][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0014, 0.9986], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:16,545][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.8977, 0.1023], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:16,546][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Erica] are: tensor([0.5795, 0.1808, 0.2397], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:16,548][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Erica] are: tensor([0.0147, 0.8670, 0.1182], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:16,550][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Erica] are: tensor([0.0009, 0.5831, 0.4160], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:16,551][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Erica] are: tensor([0.2730, 0.1693, 0.5577], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:16,552][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Erica] are: tensor([0.9670, 0.0214, 0.0116], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:16,554][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Erica] are: tensor([0.9803, 0.0122, 0.0076], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:16,555][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Erica] are: tensor([0.3466, 0.2948, 0.3586], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:16,557][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Erica] are: tensor([0.3878, 0.5075, 0.1047], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:16,558][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Erica] are: tensor([0.1410, 0.7434, 0.1156], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:16,560][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Erica] are: tensor([0.4826, 0.4541, 0.0633], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:16,561][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Erica] are: tensor([0.0019, 0.5278, 0.4704], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:16,563][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Erica] are: tensor([0.6018, 0.2416, 0.1566], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:16,565][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.5254, 0.1141, 0.2861, 0.0745], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:16,566][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0285, 0.4580, 0.1126, 0.4009], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:16,568][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0011, 0.3139, 0.2474, 0.4377], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:16,569][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.1228, 0.1202, 0.5908, 0.1662], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:16,571][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.9643, 0.0191, 0.0102, 0.0064], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:16,572][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([9.9441e-01, 2.4176e-03, 2.4048e-03, 7.6893e-04], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:16,574][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.4808, 0.1279, 0.1957, 0.1956], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:16,575][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.7321, 0.1483, 0.0292, 0.0904], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:16,577][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0495, 0.7751, 0.1055, 0.0698], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:16,579][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.8252, 0.1003, 0.0291, 0.0454], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:16,580][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([2.8243e-04, 1.7481e-01, 4.8956e-01, 3.3534e-01], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:16,581][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.7001, 0.1042, 0.1001, 0.0956], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:16,583][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Joshua] are: tensor([0.4436, 0.1030, 0.1760, 0.1056, 0.1718], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:16,584][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Joshua] are: tensor([0.0036, 0.4350, 0.0729, 0.4170, 0.0715], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:16,586][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Joshua] are: tensor([0.0010, 0.2603, 0.2046, 0.3259, 0.2083], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:16,588][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Joshua] are: tensor([0.1502, 0.0573, 0.2270, 0.3165, 0.2490], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:16,589][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Joshua] are: tensor([0.9545, 0.0176, 0.0093, 0.0070, 0.0116], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:16,591][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Joshua] are: tensor([0.9667, 0.0101, 0.0060, 0.0035, 0.0137], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:16,592][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Joshua] are: tensor([0.1835, 0.2237, 0.2096, 0.2729, 0.1103], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:16,592][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Joshua] are: tensor([0.3984, 0.2794, 0.0556, 0.2003, 0.0662], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:16,593][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Joshua] are: tensor([0.0816, 0.5234, 0.0559, 0.0670, 0.2720], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:16,594][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Joshua] are: tensor([0.3463, 0.2669, 0.0341, 0.1848, 0.1680], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:16,595][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Joshua] are: tensor([0.0006, 0.1009, 0.4866, 0.1788, 0.2331], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:16,597][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Joshua] are: tensor([0.4819, 0.1630, 0.1283, 0.1414, 0.0853], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:16,598][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([0.2894, 0.0963, 0.1877, 0.1067, 0.2089, 0.1110], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:16,600][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([0.0024, 0.4318, 0.0607, 0.3932, 0.0571, 0.0548], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:16,601][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([0.0005, 0.1937, 0.1558, 0.2620, 0.1575, 0.2305], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:16,603][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([0.0380, 0.0549, 0.2350, 0.2049, 0.2255, 0.2418], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:16,605][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([0.9399, 0.0187, 0.0090, 0.0071, 0.0106, 0.0147], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:16,606][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([0.9444, 0.0097, 0.0062, 0.0042, 0.0149, 0.0206], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:16,608][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([0.3584, 0.1229, 0.1631, 0.1805, 0.0814, 0.0935], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:16,610][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([0.6411, 0.1069, 0.0349, 0.0529, 0.0421, 0.1220], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:16,611][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([0.0396, 0.1798, 0.0217, 0.0267, 0.1743, 0.5579], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:16,613][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([0.6784, 0.1028, 0.0133, 0.0780, 0.0530, 0.0746], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:16,614][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([1.1618e-04, 1.3092e-01, 1.0376e-01, 5.0613e-01, 2.0036e-01, 5.8711e-02],
       device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:16,616][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([0.2575, 0.1467, 0.1306, 0.2555, 0.1126, 0.0971], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:16,617][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.3316, 0.0670, 0.1525, 0.0593, 0.1904, 0.1336, 0.0656],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:16,619][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0034, 0.3857, 0.0577, 0.3670, 0.0555, 0.0568, 0.0739],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:16,621][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0013, 0.1577, 0.1266, 0.2011, 0.1313, 0.1695, 0.2126],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:16,622][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0433, 0.0268, 0.1368, 0.0793, 0.2860, 0.3755, 0.0522],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:16,624][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.9358, 0.0170, 0.0088, 0.0062, 0.0099, 0.0128, 0.0096],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:16,626][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.9140, 0.0082, 0.0061, 0.0031, 0.0171, 0.0382, 0.0134],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:16,627][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.2664, 0.1242, 0.1578, 0.1918, 0.0977, 0.0745, 0.0875],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:16,629][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.5341, 0.1368, 0.0349, 0.0669, 0.0341, 0.0963, 0.0969],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:16,631][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0280, 0.1232, 0.0219, 0.0194, 0.1414, 0.6226, 0.0435],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:16,632][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.7012, 0.0730, 0.0119, 0.0424, 0.0339, 0.0961, 0.0415],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:16,634][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([5.9022e-05, 7.7472e-02, 1.6228e-01, 2.7776e-01, 2.6981e-01, 1.2508e-01,
        8.7538e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:16,635][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.4448, 0.1223, 0.0766, 0.1356, 0.0784, 0.0695, 0.0728],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:16,637][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.2774, 0.0700, 0.1299, 0.0636, 0.1781, 0.1325, 0.0870, 0.0614],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:16,639][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0028, 0.3803, 0.0549, 0.3590, 0.0528, 0.0505, 0.0692, 0.0306],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:16,640][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0023, 0.1473, 0.1118, 0.1715, 0.1122, 0.1436, 0.1623, 0.1491],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:16,642][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0433, 0.0281, 0.1209, 0.1111, 0.1450, 0.3786, 0.1158, 0.0572],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:16,643][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.9386, 0.0132, 0.0072, 0.0054, 0.0078, 0.0109, 0.0085, 0.0085],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:16,643][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.8674, 0.0103, 0.0075, 0.0051, 0.0228, 0.0548, 0.0254, 0.0068],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:16,644][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.4886, 0.0930, 0.1025, 0.1298, 0.0651, 0.0392, 0.0522, 0.0296],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:16,645][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.3538, 0.1297, 0.0312, 0.0734, 0.0366, 0.1099, 0.1252, 0.1402],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:16,647][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0312, 0.0858, 0.0145, 0.0156, 0.1190, 0.6430, 0.0549, 0.0359],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:16,648][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.5703, 0.0914, 0.0126, 0.0678, 0.0423, 0.1048, 0.0614, 0.0495],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:16,649][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([6.4196e-05, 1.0914e-01, 1.4529e-01, 2.2285e-01, 2.3221e-01, 7.2771e-02,
        7.7237e-02, 1.4044e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:16,651][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.5798, 0.0849, 0.0713, 0.0741, 0.0521, 0.0384, 0.0434, 0.0559],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:16,652][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ office] are: tensor([0.2435, 0.0620, 0.1110, 0.0636, 0.1462, 0.1076, 0.0724, 0.0667, 0.1270],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:16,654][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ office] are: tensor([0.0040, 0.3767, 0.0481, 0.3443, 0.0467, 0.0510, 0.0642, 0.0284, 0.0366],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:16,656][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ office] are: tensor([0.0010, 0.1190, 0.0922, 0.1417, 0.0925, 0.1274, 0.1421, 0.1368, 0.1472],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:16,658][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ office] are: tensor([0.0407, 0.0305, 0.0884, 0.1173, 0.1297, 0.2231, 0.1187, 0.0898, 0.1619],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:16,659][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ office] are: tensor([0.9118, 0.0142, 0.0078, 0.0058, 0.0092, 0.0128, 0.0102, 0.0107, 0.0176],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:16,661][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ office] are: tensor([0.9362, 0.0045, 0.0041, 0.0021, 0.0123, 0.0167, 0.0095, 0.0022, 0.0124],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:16,663][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ office] are: tensor([0.1025, 0.1101, 0.1187, 0.2065, 0.0649, 0.0631, 0.1081, 0.0731, 0.1531],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:16,664][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ office] are: tensor([0.2921, 0.1013, 0.0232, 0.0658, 0.0352, 0.1294, 0.0920, 0.1142, 0.1468],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:16,666][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ office] are: tensor([0.0470, 0.0643, 0.0079, 0.0086, 0.0544, 0.3395, 0.0265, 0.0289, 0.4228],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:16,668][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ office] are: tensor([0.5526, 0.0999, 0.0123, 0.0659, 0.0354, 0.0737, 0.0660, 0.0544, 0.0398],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:16,669][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ office] are: tensor([1.0576e-04, 6.2656e-02, 4.8374e-02, 1.6209e-01, 1.7119e-01, 4.7213e-02,
        9.5530e-02, 3.2041e-01, 9.2427e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:16,671][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ office] are: tensor([0.3487, 0.0891, 0.0654, 0.1270, 0.0609, 0.0405, 0.0783, 0.1173, 0.0729],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:16,672][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.2539, 0.0465, 0.1072, 0.0423, 0.1467, 0.0994, 0.0607, 0.0666, 0.1335,
        0.0431], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:16,674][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.0109, 0.2933, 0.0599, 0.2731, 0.0554, 0.0449, 0.0633, 0.0322, 0.0371,
        0.1299], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:16,676][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.0028, 0.1082, 0.0870, 0.1260, 0.0827, 0.1063, 0.1202, 0.1077, 0.1165,
        0.1427], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:16,677][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.0249, 0.0108, 0.1314, 0.0239, 0.1860, 0.3282, 0.0715, 0.0909, 0.1149,
        0.0175], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:16,679][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.9171, 0.0132, 0.0076, 0.0054, 0.0078, 0.0108, 0.0085, 0.0085, 0.0136,
        0.0075], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:16,680][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([9.7900e-01, 1.0247e-03, 1.3135e-03, 4.3751e-04, 3.4902e-03, 6.8415e-03,
        2.6696e-03, 7.3701e-04, 4.0646e-03, 4.1656e-04], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:16,682][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.2172, 0.1193, 0.1186, 0.1597, 0.0569, 0.0468, 0.0725, 0.0430, 0.0568,
        0.1092], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:16,684][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.1381, 0.1325, 0.0246, 0.0783, 0.0266, 0.0814, 0.1267, 0.1480, 0.1484,
        0.0953], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:16,685][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.0301, 0.0418, 0.0093, 0.0064, 0.0633, 0.3450, 0.0277, 0.0222, 0.4365,
        0.0176], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:16,687][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.6160, 0.0556, 0.0173, 0.0347, 0.0400, 0.0906, 0.0316, 0.0459, 0.0468,
        0.0214], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:16,688][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([8.1793e-05, 7.9131e-02, 2.3925e-01, 1.1861e-01, 2.5122e-01, 5.3917e-02,
        5.6374e-02, 8.4486e-02, 6.1335e-02, 5.5597e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:16,690][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.4584, 0.0549, 0.0775, 0.0695, 0.0565, 0.0422, 0.0510, 0.0757, 0.0594,
        0.0547], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:16,692][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Erica] are: tensor([0.2034, 0.0500, 0.0796, 0.0521, 0.0945, 0.0811, 0.0556, 0.0648, 0.1150,
        0.0509, 0.1530], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:16,693][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Erica] are: tensor([0.0025, 0.3562, 0.0422, 0.3181, 0.0378, 0.0355, 0.0444, 0.0182, 0.0227,
        0.1093, 0.0131], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:16,693][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Erica] are: tensor([0.0009, 0.0917, 0.0706, 0.1125, 0.0667, 0.0922, 0.1111, 0.1030, 0.1085,
        0.1402, 0.1026], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:16,694][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Erica] are: tensor([0.0638, 0.0150, 0.0762, 0.0482, 0.0743, 0.2012, 0.0513, 0.0545, 0.0940,
        0.0262, 0.2952], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:16,696][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Erica] are: tensor([0.8882, 0.0122, 0.0072, 0.0054, 0.0077, 0.0113, 0.0090, 0.0089, 0.0148,
        0.0092, 0.0264], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:16,697][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Erica] are: tensor([0.9152, 0.0065, 0.0025, 0.0025, 0.0090, 0.0203, 0.0081, 0.0032, 0.0117,
        0.0050, 0.0160], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:16,699][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Erica] are: tensor([0.0513, 0.1031, 0.0703, 0.1770, 0.0569, 0.0428, 0.0536, 0.0481, 0.1919,
        0.1296, 0.0755], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:16,700][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Erica] are: tensor([0.1296, 0.0954, 0.0195, 0.0782, 0.0255, 0.1168, 0.0882, 0.0907, 0.1237,
        0.1020, 0.1304], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:16,702][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Erica] are: tensor([0.0576, 0.0271, 0.0043, 0.0044, 0.0159, 0.0774, 0.0100, 0.0110, 0.1851,
        0.0288, 0.5785], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:16,704][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Erica] are: tensor([0.1744, 0.1208, 0.0133, 0.0930, 0.0626, 0.1332, 0.1057, 0.1176, 0.0779,
        0.0661, 0.0353], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:16,705][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Erica] are: tensor([6.9601e-05, 5.9543e-02, 4.4488e-02, 1.4162e-01, 1.6040e-01, 7.8845e-02,
        7.8623e-02, 1.6470e-01, 8.5969e-02, 1.1187e-01, 7.3868e-02],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:16,707][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Erica] are: tensor([0.2382, 0.0881, 0.0550, 0.1059, 0.0446, 0.0666, 0.0723, 0.1075, 0.0839,
        0.0884, 0.0495], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:16,708][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.1510, 0.0404, 0.0885, 0.0441, 0.1186, 0.0643, 0.0523, 0.0533, 0.1136,
        0.0425, 0.1641, 0.0673], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:16,710][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0022, 0.3001, 0.0437, 0.2915, 0.0440, 0.0389, 0.0480, 0.0231, 0.0309,
        0.1320, 0.0208, 0.0246], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:16,712][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.0013, 0.0860, 0.0637, 0.0983, 0.0613, 0.0866, 0.0911, 0.0880, 0.0918,
        0.1252, 0.0900, 0.1169], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:16,714][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.0162, 0.0096, 0.0806, 0.0396, 0.0645, 0.0536, 0.0698, 0.0528, 0.1214,
        0.0260, 0.4452, 0.0206], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:16,715][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.8484, 0.0135, 0.0087, 0.0063, 0.0100, 0.0128, 0.0104, 0.0104, 0.0169,
        0.0105, 0.0307, 0.0213], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:16,717][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.9078, 0.0027, 0.0067, 0.0011, 0.0102, 0.0078, 0.0054, 0.0016, 0.0087,
        0.0012, 0.0424, 0.0044], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:16,719][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.2076, 0.0759, 0.0811, 0.1461, 0.0572, 0.0272, 0.0640, 0.0285, 0.0929,
        0.0977, 0.0705, 0.0513], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:16,720][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.5523, 0.0305, 0.0097, 0.0212, 0.0131, 0.0358, 0.0316, 0.0422, 0.0526,
        0.0387, 0.0676, 0.1046], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:16,722][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.0247, 0.0276, 0.0034, 0.0038, 0.0157, 0.0678, 0.0124, 0.0087, 0.1660,
        0.0182, 0.4577, 0.1939], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:16,724][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.4406, 0.0790, 0.0113, 0.0599, 0.0359, 0.0741, 0.0693, 0.0585, 0.0340,
        0.0413, 0.0285, 0.0676], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:16,725][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([4.2875e-05, 6.2662e-02, 6.8788e-02, 1.1873e-01, 1.3676e-01, 5.3557e-02,
        4.9221e-02, 1.3947e-01, 6.8799e-02, 1.6086e-01, 1.2759e-01, 1.3517e-02],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:16,727][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.2086, 0.0881, 0.0381, 0.0981, 0.0373, 0.0510, 0.0516, 0.0867, 0.0804,
        0.0989, 0.0428, 0.1183], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:16,729][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.1351, 0.0455, 0.0799, 0.0437, 0.1137, 0.0753, 0.0523, 0.0419, 0.1092,
        0.0436, 0.1458, 0.0838, 0.0301], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:16,730][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0020, 0.2789, 0.0443, 0.2902, 0.0411, 0.0376, 0.0522, 0.0237, 0.0287,
        0.1306, 0.0225, 0.0261, 0.0220], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:16,732][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0032, 0.0820, 0.0645, 0.0964, 0.0632, 0.0806, 0.0894, 0.0784, 0.0833,
        0.1044, 0.0754, 0.0974, 0.0817], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:16,734][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0183, 0.0171, 0.0550, 0.0551, 0.0842, 0.1245, 0.0540, 0.0417, 0.1640,
        0.0391, 0.2915, 0.0369, 0.0186], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:16,736][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.8759, 0.0101, 0.0072, 0.0047, 0.0077, 0.0097, 0.0079, 0.0078, 0.0125,
        0.0078, 0.0232, 0.0155, 0.0100], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:16,737][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.7686, 0.0071, 0.0092, 0.0037, 0.0270, 0.0378, 0.0185, 0.0061, 0.0366,
        0.0043, 0.0514, 0.0274, 0.0024], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:16,739][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.2530, 0.0797, 0.0858, 0.0995, 0.0553, 0.0315, 0.0382, 0.0199, 0.0680,
        0.1037, 0.0904, 0.0514, 0.0236], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:16,741][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.1514, 0.0905, 0.0150, 0.0438, 0.0216, 0.0570, 0.0654, 0.0640, 0.0754,
        0.0783, 0.0828, 0.1830, 0.0716], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:16,742][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0130, 0.0126, 0.0032, 0.0026, 0.0211, 0.1094, 0.0099, 0.0058, 0.1800,
        0.0122, 0.3241, 0.2981, 0.0080], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:16,743][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.3503, 0.0757, 0.0132, 0.0477, 0.0366, 0.1091, 0.0609, 0.0517, 0.0450,
        0.0360, 0.0317, 0.1102, 0.0320], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:16,744][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([6.7651e-05, 6.5045e-02, 5.8560e-02, 1.6218e-01, 1.4839e-01, 4.2073e-02,
        4.7708e-02, 9.3162e-02, 6.4303e-02, 1.3848e-01, 9.3075e-02, 4.5008e-02,
        4.1949e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:16,745][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.2616, 0.0471, 0.0446, 0.0753, 0.0392, 0.0456, 0.0427, 0.0781, 0.0601,
        0.0853, 0.0390, 0.1399, 0.0414], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:16,746][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ basketball] are: tensor([0.1477, 0.0391, 0.0664, 0.0376, 0.0871, 0.0727, 0.0478, 0.0411, 0.0826,
        0.0354, 0.1212, 0.0838, 0.0356, 0.1019], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:16,748][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ basketball] are: tensor([0.0021, 0.2724, 0.0445, 0.2943, 0.0426, 0.0389, 0.0539, 0.0216, 0.0318,
        0.1248, 0.0211, 0.0239, 0.0207, 0.0075], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:16,750][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ basketball] are: tensor([0.0015, 0.0689, 0.0560, 0.0812, 0.0498, 0.0664, 0.0776, 0.0736, 0.0767,
        0.0980, 0.0787, 0.0995, 0.0844, 0.0878], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:16,751][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ basketball] are: tensor([0.0629, 0.0138, 0.0700, 0.0421, 0.0512, 0.0850, 0.0626, 0.0275, 0.0434,
        0.0433, 0.3087, 0.0607, 0.0254, 0.1034], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:16,753][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ basketball] are: tensor([0.8725, 0.0094, 0.0055, 0.0039, 0.0056, 0.0082, 0.0066, 0.0066, 0.0097,
        0.0062, 0.0186, 0.0137, 0.0085, 0.0250], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:16,754][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ basketball] are: tensor([9.4126e-01, 1.9155e-03, 1.9666e-03, 8.4519e-04, 6.4367e-03, 6.6552e-03,
        3.4407e-03, 1.3767e-03, 5.7843e-03, 1.2774e-03, 1.5969e-02, 7.6482e-03,
        8.7030e-04, 4.5595e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:16,756][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ basketball] are: tensor([0.0553, 0.0518, 0.0660, 0.1266, 0.0242, 0.0283, 0.0465, 0.0300, 0.1129,
        0.0879, 0.0699, 0.0766, 0.0348, 0.1893], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:16,758][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ basketball] are: tensor([0.1985, 0.0448, 0.0115, 0.0309, 0.0162, 0.0582, 0.0414, 0.0543, 0.0667,
        0.0501, 0.0813, 0.1440, 0.0984, 0.1039], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:16,760][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ basketball] are: tensor([0.1022, 0.0099, 0.0016, 0.0019, 0.0061, 0.0359, 0.0052, 0.0048, 0.0640,
        0.0076, 0.2063, 0.1703, 0.0101, 0.3741], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:16,761][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ basketball] are: tensor([0.3945, 0.0775, 0.0087, 0.0494, 0.0297, 0.0859, 0.0628, 0.0528, 0.0355,
        0.0362, 0.0221, 0.0760, 0.0367, 0.0324], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:16,763][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ basketball] are: tensor([5.2966e-05, 3.8562e-02, 7.1706e-02, 1.4871e-01, 8.9983e-02, 1.9701e-02,
        4.3247e-02, 1.0961e-01, 5.4147e-02, 7.2820e-02, 1.3257e-01, 9.9716e-02,
        1.0638e-01, 1.2799e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:16,765][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ basketball] are: tensor([0.3702, 0.0457, 0.0440, 0.0572, 0.0464, 0.0281, 0.0351, 0.0494, 0.0373,
        0.0512, 0.0547, 0.0779, 0.0512, 0.0516], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:16,766][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.1613, 0.0301, 0.0696, 0.0260, 0.0855, 0.0559, 0.0286, 0.0372, 0.0868,
        0.0300, 0.1347, 0.0701, 0.0314, 0.1228, 0.0300], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:16,768][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0013, 0.2572, 0.0397, 0.2818, 0.0388, 0.0364, 0.0528, 0.0233, 0.0278,
        0.1351, 0.0210, 0.0258, 0.0224, 0.0085, 0.0281], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:16,770][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0031, 0.0663, 0.0542, 0.0788, 0.0525, 0.0662, 0.0793, 0.0677, 0.0716,
        0.0889, 0.0666, 0.0810, 0.0687, 0.0722, 0.0829], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:16,772][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0167, 0.0072, 0.0361, 0.0224, 0.0930, 0.0992, 0.0156, 0.0624, 0.0768,
        0.0173, 0.2228, 0.0639, 0.0322, 0.2104, 0.0240], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:16,773][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.8584, 0.0095, 0.0059, 0.0040, 0.0060, 0.0084, 0.0064, 0.0068, 0.0105,
        0.0064, 0.0191, 0.0142, 0.0094, 0.0256, 0.0092], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:16,775][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.8217, 0.0041, 0.0048, 0.0019, 0.0145, 0.0305, 0.0114, 0.0040, 0.0228,
        0.0032, 0.0301, 0.0191, 0.0026, 0.0209, 0.0085], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:16,777][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.1459, 0.0642, 0.0680, 0.1098, 0.0444, 0.0374, 0.0452, 0.0249, 0.0733,
        0.1005, 0.0698, 0.0573, 0.0199, 0.0981, 0.0412], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:16,779][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.2256, 0.0554, 0.0152, 0.0311, 0.0181, 0.0438, 0.0457, 0.0545, 0.0660,
        0.0465, 0.0704, 0.1204, 0.0676, 0.0963, 0.0433], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:16,780][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0211, 0.0087, 0.0022, 0.0017, 0.0100, 0.0586, 0.0047, 0.0046, 0.0783,
        0.0093, 0.1853, 0.1883, 0.0069, 0.4037, 0.0169], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:16,782][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.4603, 0.0566, 0.0096, 0.0345, 0.0271, 0.0960, 0.0356, 0.0403, 0.0389,
        0.0238, 0.0238, 0.0744, 0.0279, 0.0267, 0.0246], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:16,783][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([3.0843e-05, 4.4874e-02, 6.5590e-02, 1.1821e-01, 1.6207e-01, 5.4705e-02,
        4.0736e-02, 1.0853e-01, 6.1837e-02, 9.1761e-02, 8.3819e-02, 3.5821e-02,
        7.1827e-02, 3.6664e-02, 2.3520e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:16,785][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.1942, 0.0520, 0.0443, 0.0698, 0.0430, 0.0391, 0.0421, 0.0879, 0.0562,
        0.0695, 0.0436, 0.1155, 0.0561, 0.0558, 0.0309], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:16,789][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:24:16,791][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[10367],
        [17532],
        [ 5256],
        [ 4927],
        [30798],
        [ 5267],
        [ 1772],
        [  701],
        [  440],
        [  389],
        [ 1853],
        [ 2119],
        [ 1314],
        [  761],
        [ 1554]], device='cuda:0')
[2024-07-24 10:24:16,793][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[10761],
        [14783],
        [ 5761],
        [ 4909],
        [35207],
        [ 4078],
        [ 2750],
        [ 1401],
        [  524],
        [ 1271],
        [ 1210],
        [ 2987],
        [  848],
        [  511],
        [ 1625]], device='cuda:0')
[2024-07-24 10:24:16,794][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[39879],
        [38564],
        [19659],
        [23286],
        [24880],
        [35615],
        [ 2886],
        [ 2989],
        [34218],
        [ 2276],
        [13729],
        [16816],
        [ 2622],
        [35347],
        [ 1634]], device='cuda:0')
[2024-07-24 10:24:16,795][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[10921],
        [19071],
        [17889],
        [19820],
        [25107],
        [24640],
        [24163],
        [23825],
        [22739],
        [22233],
        [21573],
        [21683],
        [21832],
        [21745],
        [21824]], device='cuda:0')
[2024-07-24 10:24:16,797][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[17561],
        [22665],
        [19950],
        [10051],
        [  288],
        [  292],
        [   28],
        [   50],
        [  154],
        [   20],
        [ 5401],
        [  590],
        [  646],
        [ 1760],
        [  435]], device='cuda:0')
[2024-07-24 10:24:16,799][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[5691],
        [3642],
        [4129],
        [3058],
        [9303],
        [7583],
        [6323],
        [5891],
        [5297],
        [4528],
        [4290],
        [3764],
        [3717],
        [3743],
        [3713]], device='cuda:0')
[2024-07-24 10:24:16,801][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[17083],
        [23284],
        [25325],
        [27506],
        [29908],
        [35008],
        [36165],
        [36492],
        [38522],
        [38761],
        [39980],
        [41048],
        [41020],
        [41913],
        [42356]], device='cuda:0')
[2024-07-24 10:24:16,802][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[24506],
        [21959],
        [14886],
        [17051],
        [29668],
        [24464],
        [24466],
        [23845],
        [23894],
        [24326],
        [23052],
        [23439],
        [23886],
        [24064],
        [24104]], device='cuda:0')
[2024-07-24 10:24:16,804][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[2624],
        [1756],
        [2155],
        [2241],
        [2037],
        [2061],
        [4790],
        [2779],
        [2186],
        [2873],
        [2202],
        [2993],
        [4627],
        [2099],
        [6145]], device='cuda:0')
[2024-07-24 10:24:16,806][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[20975],
        [11820],
        [14893],
        [30490],
        [16254],
        [37107],
        [21412],
        [15861],
        [12797],
        [17761],
        [14075],
        [29579],
        [23473],
        [16065],
        [19787]], device='cuda:0')
[2024-07-24 10:24:16,807][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[ 4596],
        [28812],
        [35332],
        [35943],
        [44993],
        [33866],
        [30961],
        [28995],
        [31547],
        [32009],
        [42035],
        [40823],
        [38531],
        [42388],
        [42529]], device='cuda:0')
[2024-07-24 10:24:16,809][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[48461],
        [46919],
        [47999],
        [46980],
        [45814],
        [45622],
        [45447],
        [45225],
        [45389],
        [45158],
        [45599],
        [45543],
        [45365],
        [45519],
        [45465]], device='cuda:0')
[2024-07-24 10:24:16,811][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[ 5843],
        [11833],
        [15446],
        [13637],
        [43386],
        [35806],
        [45836],
        [41649],
        [27933],
        [44325],
        [29044],
        [26569],
        [29023],
        [21125],
        [30920]], device='cuda:0')
[2024-07-24 10:24:16,812][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[31091],
        [28905],
        [42103],
        [37315],
        [40652],
        [38925],
        [38612],
        [39350],
        [38629],
        [39038],
        [40570],
        [40024],
        [40860],
        [41677],
        [41449]], device='cuda:0')
[2024-07-24 10:24:16,814][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[43546],
        [21915],
        [ 6711],
        [ 8750],
        [ 8318],
        [ 9388],
        [ 9614],
        [ 8473],
        [10402],
        [ 3141],
        [ 6688],
        [ 2115],
        [ 7058],
        [ 5128],
        [ 4940]], device='cuda:0')
[2024-07-24 10:24:16,816][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[ 9858],
        [10275],
        [ 8581],
        [ 8222],
        [ 6638],
        [ 8665],
        [ 9462],
        [ 9863],
        [12575],
        [12859],
        [12126],
        [11592],
        [11917],
        [11965],
        [11823]], device='cuda:0')
[2024-07-24 10:24:16,817][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[40241],
        [45652],
        [45245],
        [44851],
        [44647],
        [44604],
        [44568],
        [44568],
        [44638],
        [44480],
        [44700],
        [44546],
        [44513],
        [44508],
        [44526]], device='cuda:0')
[2024-07-24 10:24:16,819][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[43301],
        [24742],
        [17525],
        [17561],
        [18178],
        [15566],
        [13340],
        [12917],
        [10083],
        [10914],
        [ 8607],
        [ 8554],
        [ 8296],
        [ 7174],
        [ 6701]], device='cuda:0')
[2024-07-24 10:24:16,821][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[14834],
        [ 4723],
        [ 5538],
        [ 4151],
        [12729],
        [16297],
        [24595],
        [16552],
        [10029],
        [16448],
        [ 8959],
        [ 6656],
        [ 6197],
        [ 6007],
        [ 5996]], device='cuda:0')
[2024-07-24 10:24:16,822][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[28867],
        [25030],
        [24752],
        [24173],
        [22826],
        [20424],
        [19554],
        [19749],
        [16573],
        [17085],
        [14472],
        [10536],
        [12133],
        [11344],
        [10032]], device='cuda:0')
[2024-07-24 10:24:16,824][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[34284],
        [34331],
        [34748],
        [34403],
        [33003],
        [34197],
        [34984],
        [34517],
        [36360],
        [35219],
        [36561],
        [34264],
        [30120],
        [35192],
        [34934]], device='cuda:0')
[2024-07-24 10:24:16,825][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[47718],
        [38370],
        [25274],
        [27750],
        [25603],
        [29970],
        [29618],
        [32015],
        [29863],
        [29553],
        [29002],
        [29767],
        [30386],
        [29090],
        [29865]], device='cuda:0')
[2024-07-24 10:24:16,827][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[28487],
        [21018],
        [17196],
        [23558],
        [16534],
        [18657],
        [18287],
        [16504],
        [15068],
        [14862],
        [13681],
        [17201],
        [15270],
        [14314],
        [14284]], device='cuda:0')
[2024-07-24 10:24:16,829][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[44060],
        [28884],
        [17624],
        [14008],
        [14347],
        [ 2738],
        [ 2453],
        [ 2475],
        [ 8482],
        [ 8169],
        [ 9976],
        [ 7699],
        [ 6708],
        [11706],
        [ 9455]], device='cuda:0')
[2024-07-24 10:24:16,830][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[19418],
        [18635],
        [20581],
        [17813],
        [20523],
        [16967],
        [16446],
        [17854],
        [18625],
        [17337],
        [19995],
        [17218],
        [16647],
        [17628],
        [16576]], device='cuda:0')
[2024-07-24 10:24:16,832][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[32885],
        [36038],
        [18630],
        [19300],
        [19594],
        [33522],
        [31999],
        [30231],
        [31173],
        [26028],
        [30142],
        [26298],
        [28420],
        [26365],
        [29042]], device='cuda:0')
[2024-07-24 10:24:16,834][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[21743],
        [18555],
        [13052],
        [14479],
        [12916],
        [14605],
        [14899],
        [14269],
        [14399],
        [12951],
        [12840],
        [11916],
        [10987],
        [10158],
        [10569]], device='cuda:0')
[2024-07-24 10:24:16,835][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[ 4813],
        [16059],
        [29848],
        [30378],
        [29594],
        [29575],
        [28430],
        [30808],
        [30926],
        [30617],
        [32076],
        [36462],
        [36951],
        [36354],
        [36400]], device='cuda:0')
[2024-07-24 10:24:16,837][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[ 1770],
        [25529],
        [41627],
        [35643],
        [42190],
        [35585],
        [34265],
        [37362],
        [36245],
        [44867],
        [41888],
        [45438],
        [42042],
        [43794],
        [42734]], device='cuda:0')
[2024-07-24 10:24:16,838][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[6151],
        [6151],
        [6151],
        [6151],
        [6151],
        [6151],
        [6151],
        [6151],
        [6151],
        [6151],
        [6151],
        [6151],
        [6151],
        [6151],
        [6151]], device='cuda:0')
[2024-07-24 10:24:16,933][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:24:16,934][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:16,936][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:16,937][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:16,939][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:16,940][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:16,941][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:16,943][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:16,944][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:16,945][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:16,945][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:16,946][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:16,947][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:16,948][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.9146, 0.0854], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:16,949][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [,] are: tensor([7.4698e-04, 9.9925e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:16,950][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.7489, 0.2511], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:16,950][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.5507, 0.4493], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:16,951][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.4242, 0.5758], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:16,952][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.7745, 0.2255], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:16,953][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0145, 0.9855], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:16,953][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.1191, 0.8809], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:16,954][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.9822, 0.0178], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:16,955][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.7214, 0.2786], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:16,956][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.9444, 0.0556], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:16,958][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.3602, 0.6398], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:16,959][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Erica] are: tensor([0.8841, 0.0903, 0.0255], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:16,960][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Erica] are: tensor([1.6310e-04, 8.5697e-01, 1.4287e-01], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:16,962][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Erica] are: tensor([0.5262, 0.4427, 0.0311], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:16,963][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Erica] are: tensor([0.4374, 0.4909, 0.0717], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:16,965][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Erica] are: tensor([0.0350, 0.9081, 0.0569], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:16,967][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Erica] are: tensor([0.3384, 0.1341, 0.5276], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:16,968][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Erica] are: tensor([0.0064, 0.5423, 0.4513], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:16,970][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Erica] are: tensor([0.0134, 0.0437, 0.9429], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:16,971][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Erica] are: tensor([0.9404, 0.0357, 0.0239], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:16,973][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Erica] are: tensor([0.3407, 0.2134, 0.4459], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:16,974][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Erica] are: tensor([0.9621, 0.0364, 0.0015], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:16,976][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Erica] are: tensor([0.2377, 0.6407, 0.1216], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:16,978][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.7178, 0.0615, 0.0247, 0.1960], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:16,979][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ and] are: tensor([1.8504e-04, 6.7237e-01, 1.2318e-01, 2.0427e-01], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:16,980][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.6173, 0.2902, 0.0144, 0.0781], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:16,982][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.4261, 0.3216, 0.0429, 0.2094], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:16,984][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0959, 0.7521, 0.0468, 0.1052], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:16,985][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1916, 0.0491, 0.7001, 0.0592], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:16,987][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0037, 0.3859, 0.3057, 0.3047], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:16,989][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0024, 0.0067, 0.1307, 0.8602], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:16,990][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.9548, 0.0133, 0.0203, 0.0116], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:16,992][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.5273, 0.1066, 0.2629, 0.1031], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:16,993][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ and] are: tensor([9.7546e-01, 2.1338e-02, 4.6569e-04, 2.7319e-03], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:16,995][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.2852, 0.3106, 0.0689, 0.3352], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:16,996][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Joshua] are: tensor([0.6790, 0.0590, 0.0121, 0.1974, 0.0525], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:16,997][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Joshua] are: tensor([1.1854e-04, 6.0243e-01, 8.7247e-02, 1.8172e-01, 1.2848e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:16,999][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Joshua] are: tensor([0.3838, 0.3039, 0.0597, 0.2044, 0.0480], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:17,001][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Joshua] are: tensor([0.2835, 0.3344, 0.0279, 0.1744, 0.1797], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:17,002][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Joshua] are: tensor([0.0952, 0.5460, 0.0321, 0.0922, 0.2345], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:17,002][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Joshua] are: tensor([0.1936, 0.0356, 0.2189, 0.1177, 0.4343], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:17,003][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Joshua] are: tensor([0.0029, 0.2850, 0.2284, 0.2295, 0.2541], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:17,004][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Joshua] are: tensor([0.0024, 0.0018, 0.0450, 0.7638, 0.1870], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:17,005][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Joshua] are: tensor([0.8129, 0.0507, 0.0267, 0.0352, 0.0746], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:17,006][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Joshua] are: tensor([0.2239, 0.0991, 0.1870, 0.2162, 0.2738], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:17,008][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Joshua] are: tensor([0.8076, 0.1305, 0.0021, 0.0126, 0.0472], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:17,009][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Joshua] are: tensor([0.1462, 0.2872, 0.0420, 0.3627, 0.1620], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:17,011][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ went] are: tensor([0.6764, 0.0508, 0.0159, 0.1730, 0.0528, 0.0313], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:17,012][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ went] are: tensor([6.2462e-05, 5.6866e-01, 6.3873e-02, 1.4907e-01, 9.7651e-02, 1.2069e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:17,014][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ went] are: tensor([0.8015, 0.0757, 0.0224, 0.0787, 0.0117, 0.0100], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:17,016][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ went] are: tensor([0.1887, 0.2262, 0.0304, 0.1470, 0.1688, 0.2389], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:17,017][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ went] are: tensor([0.0435, 0.2190, 0.0045, 0.0256, 0.0579, 0.6494], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:17,019][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ went] are: tensor([0.0802, 0.0212, 0.3157, 0.0825, 0.3607, 0.1396], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:17,020][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ went] are: tensor([0.0024, 0.2350, 0.1802, 0.1775, 0.2048, 0.2001], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:17,022][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ went] are: tensor([0.0016, 0.0009, 0.0193, 0.2196, 0.0648, 0.6937], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:17,024][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.8297, 0.0170, 0.0088, 0.0115, 0.0202, 0.1128], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:17,025][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ went] are: tensor([0.0712, 0.0913, 0.0914, 0.2758, 0.1458, 0.3245], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:17,027][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ went] are: tensor([0.7491, 0.0961, 0.0011, 0.0081, 0.0250, 0.1205], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:17,029][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ went] are: tensor([0.1493, 0.1129, 0.0155, 0.1326, 0.0914, 0.4983], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:17,030][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.7029, 0.0337, 0.0110, 0.1276, 0.0408, 0.0197, 0.0644],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:17,031][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ to] are: tensor([8.0407e-05, 4.6612e-01, 7.4950e-02, 1.2745e-01, 1.1311e-01, 1.2690e-01,
        9.1386e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:17,033][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.7183, 0.1391, 0.0154, 0.0768, 0.0186, 0.0113, 0.0204],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:17,035][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.1060, 0.1873, 0.0285, 0.1350, 0.1381, 0.2460, 0.1592],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:17,036][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0191, 0.1333, 0.0062, 0.0212, 0.0513, 0.6874, 0.0815],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:17,038][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0642, 0.0127, 0.1865, 0.0385, 0.4096, 0.2352, 0.0532],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:17,040][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0016, 0.2003, 0.1568, 0.1549, 0.1750, 0.1735, 0.1379],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:17,041][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ to] are: tensor([5.8449e-04, 7.6593e-04, 1.4547e-02, 1.4895e-01, 6.8635e-02, 6.1891e-01,
        1.4761e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:17,043][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.7962, 0.0133, 0.0126, 0.0109, 0.0247, 0.1031, 0.0391],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:17,044][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.2101, 0.0448, 0.1208, 0.0874, 0.1575, 0.2609, 0.1185],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:17,045][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ to] are: tensor([9.1389e-01, 1.9311e-02, 4.5403e-04, 2.4067e-03, 9.1643e-03, 4.5373e-02,
        9.3959e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:17,047][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0792, 0.0906, 0.0183, 0.1022, 0.1066, 0.4036, 0.1994],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:17,049][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.6377, 0.0281, 0.0086, 0.1021, 0.0305, 0.0187, 0.0514, 0.1229],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:17,050][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ the] are: tensor([6.2492e-05, 4.0660e-01, 6.5664e-02, 1.2270e-01, 1.0502e-01, 1.0862e-01,
        9.4307e-02, 9.7024e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:17,052][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.7899, 0.0915, 0.0093, 0.0529, 0.0093, 0.0055, 0.0127, 0.0291],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:17,052][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0942, 0.1550, 0.0263, 0.1179, 0.1287, 0.1918, 0.1427, 0.1433],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:17,053][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0201, 0.1009, 0.0070, 0.0213, 0.0491, 0.6067, 0.1053, 0.0896],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:17,054][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0599, 0.0165, 0.1687, 0.0536, 0.3679, 0.1942, 0.1100, 0.0293],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:17,055][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0015, 0.1760, 0.1384, 0.1351, 0.1563, 0.1516, 0.1229, 0.1183],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:17,056][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ the] are: tensor([8.2005e-04, 4.3548e-04, 8.4321e-03, 7.1789e-02, 3.4846e-02, 2.9391e-01,
        6.8858e-02, 5.2091e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:17,057][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.7886, 0.0099, 0.0107, 0.0086, 0.0226, 0.0918, 0.0378, 0.0299],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:17,059][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.1266, 0.0499, 0.0951, 0.1271, 0.1014, 0.2379, 0.1352, 0.1269],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:17,061][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.6924, 0.0577, 0.0014, 0.0075, 0.0302, 0.1499, 0.0292, 0.0318],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:17,062][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0662, 0.0509, 0.0130, 0.0599, 0.0675, 0.2492, 0.1266, 0.3668],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:17,064][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ office] are: tensor([0.5878, 0.0290, 0.0075, 0.1095, 0.0274, 0.0202, 0.0585, 0.1353, 0.0248],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:17,065][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ office] are: tensor([9.6924e-05, 3.3685e-01, 5.1416e-02, 1.0357e-01, 9.1708e-02, 1.0836e-01,
        8.2656e-02, 1.0480e-01, 1.2054e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:17,067][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ office] are: tensor([0.4285, 0.2220, 0.0236, 0.1285, 0.0173, 0.0175, 0.0298, 0.1066, 0.0262],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:17,068][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ office] are: tensor([0.1344, 0.1474, 0.0175, 0.0913, 0.1051, 0.1544, 0.0974, 0.0924, 0.1601],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:17,070][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ office] are: tensor([0.0392, 0.0752, 0.0027, 0.0133, 0.0222, 0.3532, 0.0596, 0.0703, 0.3642],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:17,072][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ office] are: tensor([0.0674, 0.0082, 0.1360, 0.0469, 0.2898, 0.1124, 0.0952, 0.0422, 0.2019],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:17,073][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ office] are: tensor([0.0016, 0.1527, 0.1206, 0.1187, 0.1352, 0.1325, 0.1055, 0.1049, 0.1283],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:17,075][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ office] are: tensor([6.0050e-04, 1.9486e-04, 4.8185e-03, 6.1620e-02, 2.0609e-02, 2.5277e-01,
        5.5356e-02, 5.1784e-01, 8.6195e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:17,076][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ office] are: tensor([0.8433, 0.0044, 0.0030, 0.0034, 0.0064, 0.0329, 0.0149, 0.0136, 0.0782],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:17,078][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ office] are: tensor([0.1239, 0.0529, 0.0539, 0.0880, 0.0288, 0.1109, 0.1020, 0.0784, 0.3612],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:17,079][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ office] are: tensor([6.7890e-01, 4.3144e-02, 6.5696e-04, 5.2581e-03, 1.5802e-02, 1.0655e-01,
        1.6713e-02, 1.8398e-02, 1.1458e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:17,081][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ office] are: tensor([0.1073, 0.0438, 0.0065, 0.0363, 0.0367, 0.2102, 0.0936, 0.2567, 0.2090],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:17,082][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.5461, 0.0298, 0.0127, 0.1136, 0.0376, 0.0177, 0.0564, 0.1042, 0.0241,
        0.0578], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:17,084][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [.] are: tensor([4.4136e-05, 3.3803e-01, 5.8186e-02, 9.0566e-02, 9.1411e-02, 8.8402e-02,
        7.2160e-02, 7.8413e-02, 1.0064e-01, 8.2143e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:17,085][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.3356, 0.2837, 0.0208, 0.1038, 0.0202, 0.0100, 0.0154, 0.0535, 0.0051,
        0.1519], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:17,087][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0911, 0.1251, 0.0152, 0.0777, 0.0802, 0.1300, 0.0985, 0.0958, 0.1167,
        0.1697], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:17,089][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0316, 0.0989, 0.0049, 0.0172, 0.0264, 0.3364, 0.0564, 0.0605, 0.2923,
        0.0754], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:17,090][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.0456, 0.0056, 0.0883, 0.0177, 0.2860, 0.2202, 0.0744, 0.0255, 0.2212,
        0.0155], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:17,092][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0011, 0.1369, 0.1076, 0.1049, 0.1211, 0.1178, 0.0950, 0.0925, 0.1135,
        0.1096], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:17,093][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [.] are: tensor([2.2911e-04, 1.9808e-04, 5.5091e-03, 3.7140e-02, 3.1213e-02, 2.5748e-01,
        5.4037e-02, 4.6935e-01, 1.1328e-01, 3.1567e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:17,095][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.7829, 0.0054, 0.0052, 0.0046, 0.0107, 0.0376, 0.0199, 0.0129, 0.0852,
        0.0356], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:17,097][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.1419, 0.0407, 0.0467, 0.0735, 0.0665, 0.1583, 0.1284, 0.0994, 0.1751,
        0.0695], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:17,098][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.5666, 0.0436, 0.0015, 0.0086, 0.0345, 0.1417, 0.0276, 0.0252, 0.0981,
        0.0527], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:17,100][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0684, 0.0256, 0.0072, 0.0293, 0.0294, 0.1071, 0.0728, 0.2115, 0.1162,
        0.3324], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:17,102][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Erica] are: tensor([0.5092, 0.0384, 0.0095, 0.1080, 0.0236, 0.0212, 0.0610, 0.1172, 0.0404,
        0.0483, 0.0232], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:17,103][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Erica] are: tensor([3.5901e-05, 2.9197e-01, 4.1958e-02, 8.8626e-02, 6.0225e-02, 9.0854e-02,
        6.9241e-02, 7.3690e-02, 9.1440e-02, 8.4550e-02, 1.0741e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:17,104][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Erica] are: tensor([0.2812, 0.2292, 0.0249, 0.1118, 0.0172, 0.0118, 0.0208, 0.0700, 0.0148,
        0.1469, 0.0714], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:17,105][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Erica] are: tensor([0.1388, 0.1084, 0.0154, 0.0402, 0.0531, 0.1153, 0.0789, 0.0703, 0.1536,
        0.1183, 0.1077], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:17,105][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Erica] are: tensor([0.0404, 0.0289, 0.0017, 0.0054, 0.0085, 0.0954, 0.0189, 0.0338, 0.1878,
        0.0707, 0.5084], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:17,107][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Erica] are: tensor([0.0762, 0.0076, 0.0680, 0.0358, 0.1528, 0.0886, 0.0604, 0.0238, 0.1754,
        0.0432, 0.2683], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:17,109][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Erica] are: tensor([0.0011, 0.1201, 0.0942, 0.0954, 0.1048, 0.1072, 0.0858, 0.0827, 0.1001,
        0.0974, 0.1113], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:17,110][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Erica] are: tensor([1.3266e-03, 2.0318e-04, 3.9429e-03, 4.5698e-02, 1.4580e-02, 1.7125e-01,
        3.0061e-02, 2.8856e-01, 5.1662e-02, 2.1616e-02, 3.7110e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:17,112][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Erica] are: tensor([0.6734, 0.0051, 0.0026, 0.0052, 0.0048, 0.0401, 0.0186, 0.0207, 0.0811,
        0.0532, 0.0952], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:17,114][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Erica] are: tensor([0.0986, 0.0270, 0.0805, 0.0629, 0.0543, 0.0804, 0.0586, 0.0897, 0.1662,
        0.1009, 0.1808], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:17,115][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Erica] are: tensor([0.4776, 0.0572, 0.0014, 0.0070, 0.0186, 0.1168, 0.0248, 0.0248, 0.1508,
        0.0664, 0.0546], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:17,117][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Erica] are: tensor([0.0875, 0.0176, 0.0027, 0.0228, 0.0110, 0.0733, 0.0391, 0.1216, 0.0820,
        0.2901, 0.2524], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:17,119][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.3547, 0.0335, 0.0159, 0.1323, 0.0453, 0.0216, 0.0749, 0.1550, 0.0298,
        0.0740, 0.0261, 0.0369], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:17,120][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([8.2412e-05, 2.5365e-01, 3.6748e-02, 8.2950e-02, 6.4428e-02, 8.3138e-02,
        6.5416e-02, 6.9879e-02, 9.6426e-02, 8.3062e-02, 9.3401e-02, 7.0817e-02],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:17,121][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.6584, 0.0624, 0.0098, 0.0341, 0.0057, 0.0088, 0.0136, 0.0360, 0.0053,
        0.0820, 0.0554, 0.0284], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:17,123][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.1257, 0.0762, 0.0150, 0.0458, 0.0690, 0.0825, 0.0555, 0.0596, 0.1403,
        0.1085, 0.1253, 0.0967], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:17,125][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.0513, 0.0379, 0.0014, 0.0062, 0.0108, 0.1267, 0.0278, 0.0296, 0.1416,
        0.0556, 0.2236, 0.2875], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:17,127][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.0486, 0.0068, 0.0933, 0.0220, 0.1934, 0.0609, 0.0474, 0.0214, 0.1290,
        0.0219, 0.3263, 0.0289], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:17,128][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0014, 0.1109, 0.0860, 0.0859, 0.0960, 0.0947, 0.0770, 0.0745, 0.0920,
        0.0903, 0.1032, 0.0880], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:17,130][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([7.4602e-04, 2.0366e-04, 4.1460e-03, 3.3138e-02, 1.5312e-02, 1.3316e-01,
        2.8612e-02, 2.0464e-01, 4.1882e-02, 1.8181e-02, 2.8387e-01, 2.3611e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:17,131][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.6464, 0.0036, 0.0028, 0.0026, 0.0055, 0.0200, 0.0101, 0.0086, 0.0598,
        0.0232, 0.0912, 0.1264], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:17,133][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.0470, 0.0337, 0.0478, 0.1130, 0.0318, 0.0917, 0.0995, 0.0611, 0.1924,
        0.0826, 0.1318, 0.0675], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:17,135][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.5214, 0.0457, 0.0014, 0.0059, 0.0252, 0.0961, 0.0217, 0.0187, 0.1036,
        0.0432, 0.0460, 0.0711], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:17,137][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0330, 0.0134, 0.0032, 0.0176, 0.0146, 0.0604, 0.0388, 0.0915, 0.0670,
        0.2500, 0.2669, 0.1436], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:17,138][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.4951, 0.0204, 0.0090, 0.0755, 0.0258, 0.0145, 0.0412, 0.0881, 0.0209,
        0.0470, 0.0195, 0.0218, 0.1212], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:17,140][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ a] are: tensor([2.8194e-05, 2.9474e-01, 3.7651e-02, 7.8336e-02, 6.3928e-02, 7.5796e-02,
        5.8859e-02, 6.0410e-02, 7.6376e-02, 6.6428e-02, 8.4773e-02, 6.4134e-02,
        3.8542e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:17,141][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.7745, 0.0403, 0.0071, 0.0238, 0.0044, 0.0027, 0.0063, 0.0159, 0.0029,
        0.0622, 0.0409, 0.0099, 0.0089], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:17,143][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0413, 0.0649, 0.0124, 0.0647, 0.0789, 0.1062, 0.0636, 0.0732, 0.1078,
        0.1106, 0.0891, 0.0909, 0.0965], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:17,145][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0129, 0.0381, 0.0023, 0.0099, 0.0130, 0.1887, 0.0336, 0.0300, 0.1210,
        0.0450, 0.1753, 0.2841, 0.0461], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:17,147][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0281, 0.0086, 0.0875, 0.0254, 0.1388, 0.0714, 0.0520, 0.0135, 0.1677,
        0.0232, 0.3243, 0.0501, 0.0095], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:17,148][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0008, 0.1038, 0.0807, 0.0790, 0.0903, 0.0880, 0.0714, 0.0680, 0.0846,
        0.0821, 0.0943, 0.0794, 0.0775], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:17,149][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ a] are: tensor([6.9927e-04, 1.3791e-04, 2.4492e-03, 1.9647e-02, 8.4752e-03, 7.0526e-02,
        1.8212e-02, 1.1452e-01, 2.4861e-02, 1.1001e-02, 1.3454e-01, 1.2158e-01,
        4.7335e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:17,151][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.6118, 0.0027, 0.0043, 0.0027, 0.0070, 0.0255, 0.0118, 0.0078, 0.0695,
        0.0186, 0.0878, 0.1362, 0.0144], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:17,153][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0426, 0.0313, 0.0374, 0.0809, 0.0523, 0.1115, 0.0893, 0.0634, 0.1802,
        0.0849, 0.1029, 0.0767, 0.0467], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:17,154][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.4502, 0.0366, 0.0012, 0.0061, 0.0274, 0.1206, 0.0221, 0.0243, 0.1134,
        0.0464, 0.0632, 0.0750, 0.0134], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:17,155][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0287, 0.0161, 0.0034, 0.0182, 0.0132, 0.0637, 0.0338, 0.0898, 0.0681,
        0.1800, 0.1828, 0.1318, 0.1703], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:17,155][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ basketball] are: tensor([0.5452, 0.0213, 0.0064, 0.0754, 0.0166, 0.0124, 0.0392, 0.0766, 0.0172,
        0.0442, 0.0134, 0.0182, 0.0795, 0.0343], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:17,157][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ basketball] are: tensor([6.5365e-05, 2.5576e-01, 3.6823e-02, 8.1496e-02, 5.7666e-02, 6.8596e-02,
        5.5537e-02, 5.9894e-02, 7.0080e-02, 6.5238e-02, 7.9978e-02, 5.9244e-02,
        4.0511e-02, 6.9116e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:17,158][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ basketball] are: tensor([0.3935, 0.1316, 0.0270, 0.0646, 0.0166, 0.0176, 0.0228, 0.0879, 0.0106,
        0.0743, 0.0670, 0.0222, 0.0443, 0.0201], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:17,160][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ basketball] are: tensor([0.1177, 0.0675, 0.0063, 0.0341, 0.0405, 0.0634, 0.0472, 0.0447, 0.0652,
        0.0840, 0.0595, 0.0812, 0.0399, 0.2489], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:17,162][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ basketball] are: tensor([0.0450, 0.0122, 0.0006, 0.0024, 0.0039, 0.0380, 0.0092, 0.0103, 0.0438,
        0.0241, 0.0894, 0.2297, 0.0468, 0.4445], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:17,163][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ basketball] are: tensor([0.0681, 0.0070, 0.0585, 0.0298, 0.1061, 0.0912, 0.0719, 0.0340, 0.0946,
        0.0247, 0.2116, 0.0633, 0.0340, 0.1052], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:17,165][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ basketball] are: tensor([0.0011, 0.0938, 0.0731, 0.0715, 0.0799, 0.0778, 0.0636, 0.0627, 0.0754,
        0.0743, 0.0852, 0.0706, 0.0707, 0.1004], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:17,166][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ basketball] are: tensor([5.4539e-04, 8.6729e-05, 1.3109e-03, 1.3338e-02, 5.0242e-03, 4.3322e-02,
        1.0686e-02, 6.1660e-02, 1.3045e-02, 4.9130e-03, 7.5694e-02, 7.8921e-02,
        3.0732e-01, 3.8413e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:17,168][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ basketball] are: tensor([0.7530, 0.0022, 0.0019, 0.0017, 0.0021, 0.0096, 0.0063, 0.0057, 0.0229,
        0.0147, 0.0390, 0.0667, 0.0088, 0.0655], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:17,170][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ basketball] are: tensor([0.0737, 0.0463, 0.0324, 0.0940, 0.0385, 0.0943, 0.0802, 0.0452, 0.1334,
        0.0441, 0.0739, 0.0921, 0.0295, 0.1223], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:17,171][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ basketball] are: tensor([6.7403e-01, 1.9019e-02, 4.6795e-04, 2.3359e-03, 6.9002e-03, 3.2059e-02,
        7.2957e-03, 6.3317e-03, 3.3003e-02, 2.1341e-02, 1.3355e-02, 2.1087e-02,
        3.2901e-03, 1.5949e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:17,173][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ basketball] are: tensor([0.0444, 0.0119, 0.0022, 0.0112, 0.0095, 0.0427, 0.0247, 0.0622, 0.0355,
        0.1672, 0.1720, 0.0990, 0.1078, 0.2097], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:17,174][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.4701, 0.0194, 0.0084, 0.0755, 0.0253, 0.0141, 0.0406, 0.0802, 0.0158,
        0.0436, 0.0172, 0.0206, 0.0980, 0.0324, 0.0386], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:17,176][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ to] are: tensor([3.2216e-05, 2.4830e-01, 3.5801e-02, 6.3959e-02, 5.6076e-02, 6.9312e-02,
        4.7860e-02, 5.7050e-02, 6.9394e-02, 6.0139e-02, 7.8615e-02, 5.7978e-02,
        4.0028e-02, 6.7996e-02, 4.7459e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:17,178][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.6081, 0.0949, 0.0131, 0.0457, 0.0106, 0.0076, 0.0116, 0.0352, 0.0043,
        0.0677, 0.0395, 0.0127, 0.0158, 0.0102, 0.0229], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:17,179][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0417, 0.0585, 0.0070, 0.0481, 0.0437, 0.0670, 0.0478, 0.0458, 0.0738,
        0.0896, 0.0476, 0.0642, 0.0566, 0.2297, 0.0789], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:17,181][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0120, 0.0159, 0.0009, 0.0042, 0.0055, 0.0752, 0.0138, 0.0159, 0.0571,
        0.0241, 0.0887, 0.1962, 0.0316, 0.3780, 0.0809], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:17,183][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0362, 0.0040, 0.0654, 0.0118, 0.1339, 0.0813, 0.0192, 0.0134, 0.1039,
        0.0117, 0.2690, 0.0588, 0.0221, 0.1251, 0.0442], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:17,185][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0007, 0.0861, 0.0671, 0.0667, 0.0748, 0.0743, 0.0596, 0.0579, 0.0713,
        0.0688, 0.0795, 0.0675, 0.0663, 0.0964, 0.0632], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:17,186][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ to] are: tensor([2.9774e-04, 6.3077e-05, 1.0830e-03, 8.8267e-03, 4.5334e-03, 3.6269e-02,
        9.4949e-03, 5.7477e-02, 1.2738e-02, 5.3987e-03, 7.7174e-02, 6.1484e-02,
        2.2920e-01, 3.0533e-01, 1.9063e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:17,188][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.6028, 0.0027, 0.0025, 0.0019, 0.0040, 0.0167, 0.0074, 0.0058, 0.0390,
        0.0152, 0.0406, 0.0869, 0.0101, 0.1424, 0.0218], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:17,190][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.1037, 0.0141, 0.0344, 0.0309, 0.0463, 0.0860, 0.0398, 0.0509, 0.1221,
        0.0397, 0.1066, 0.0410, 0.0329, 0.1990, 0.0527], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:17,191][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ to] are: tensor([7.5942e-01, 1.1783e-02, 3.6547e-04, 1.9989e-03, 7.0573e-03, 3.5264e-02,
        6.4774e-03, 7.3788e-03, 2.3590e-02, 1.6728e-02, 1.3842e-02, 2.4930e-02,
        3.9719e-03, 8.2217e-02, 4.9717e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:17,192][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0398, 0.0152, 0.0021, 0.0154, 0.0091, 0.0508, 0.0235, 0.0703, 0.0388,
        0.1516, 0.0979, 0.0869, 0.1265, 0.1756, 0.0965], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:17,278][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:24:17,279][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:17,279][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:17,280][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:17,281][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:17,282][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:17,282][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:17,283][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:17,284][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:17,285][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:17,286][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:17,286][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:17,287][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:17,288][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([9.9995e-01, 4.5317e-05], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:17,288][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0208, 0.9792], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:17,290][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.4851, 0.5149], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:17,291][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.5507, 0.4493], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:17,293][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.2387, 0.7613], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:17,295][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.9201, 0.0799], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:17,296][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.9551, 0.0449], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:17,298][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0141, 0.9859], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:17,299][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([9.9964e-01, 3.6050e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:17,301][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.8933, 0.1067], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:17,302][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.9376, 0.0624], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:17,304][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.4008, 0.5992], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:17,305][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Erica] are: tensor([9.9967e-01, 1.8549e-04, 1.4410e-04], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:17,306][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Erica] are: tensor([0.0126, 0.8314, 0.1560], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:17,308][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Erica] are: tensor([0.3509, 0.2902, 0.3589], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:17,310][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Erica] are: tensor([0.4374, 0.4909, 0.0717], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:17,311][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Erica] are: tensor([0.0215, 0.9632, 0.0153], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:17,313][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Erica] are: tensor([0.4981, 0.4818, 0.0201], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:17,315][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Erica] are: tensor([0.7448, 0.1699, 0.0854], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:17,316][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Erica] are: tensor([0.0062, 0.7598, 0.2340], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:17,318][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Erica] are: tensor([0.8253, 0.1479, 0.0268], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:17,319][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Erica] are: tensor([0.7133, 0.2632, 0.0235], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:17,321][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Erica] are: tensor([0.8001, 0.1835, 0.0163], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:17,323][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Erica] are: tensor([0.1215, 0.8323, 0.0462], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:17,324][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([9.9698e-01, 5.5597e-05, 4.2002e-05, 2.9193e-03], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:17,325][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0343, 0.6261, 0.1714, 0.1683], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:17,327][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.2412, 0.2154, 0.4239, 0.1195], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:17,328][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.4261, 0.3216, 0.0429, 0.2094], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:17,329][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0533, 0.8819, 0.0123, 0.0525], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:17,329][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.6511, 0.3130, 0.0119, 0.0240], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:17,330][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.8060, 0.1067, 0.0481, 0.0392], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:17,332][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0045, 0.5736, 0.1906, 0.2313], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:17,333][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([9.9563e-01, 2.4639e-03, 1.0499e-03, 8.6115e-04], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:17,334][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.3790, 0.5834, 0.0227, 0.0150], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:17,336][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.8672, 0.0954, 0.0067, 0.0307], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:17,337][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.2233, 0.5228, 0.0436, 0.2103], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:17,338][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Joshua] are: tensor([9.9319e-01, 1.3190e-04, 9.3870e-05, 5.7526e-03, 8.3360e-04],
       device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:17,340][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Joshua] are: tensor([0.0144, 0.4398, 0.0910, 0.1909, 0.2640], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:17,342][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Joshua] are: tensor([0.1659, 0.0382, 0.2133, 0.2775, 0.3051], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:17,343][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Joshua] are: tensor([0.2835, 0.3344, 0.0279, 0.1744, 0.1797], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:17,345][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Joshua] are: tensor([0.0387, 0.7360, 0.0060, 0.0421, 0.1772], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:17,346][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Joshua] are: tensor([0.6815, 0.1716, 0.0034, 0.0146, 0.1289], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:17,348][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Joshua] are: tensor([0.5211, 0.1856, 0.0860, 0.1127, 0.0947], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:17,350][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Joshua] are: tensor([0.0039, 0.4501, 0.1362, 0.2045, 0.2053], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:17,351][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Joshua] are: tensor([0.8691, 0.0642, 0.0099, 0.0198, 0.0370], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:17,353][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Joshua] are: tensor([0.8227, 0.1099, 0.0080, 0.0090, 0.0504], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:17,355][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Joshua] are: tensor([0.7584, 0.1404, 0.0068, 0.0302, 0.0642], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:17,356][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Joshua] are: tensor([0.0814, 0.5977, 0.0175, 0.1844, 0.1191], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:17,357][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([9.9189e-01, 1.1691e-04, 7.3063e-05, 6.4937e-03, 7.2854e-04, 7.0262e-04],
       device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:17,359][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([0.0067, 0.4611, 0.0493, 0.1453, 0.1883, 0.1493], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:17,361][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([0.0356, 0.0570, 0.3512, 0.2571, 0.2105, 0.0886], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:17,362][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([0.1887, 0.2262, 0.0304, 0.1470, 0.1688, 0.2389], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:17,363][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([2.6861e-02, 2.1850e-01, 6.2535e-04, 7.7971e-03, 2.2040e-02, 7.2418e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:17,365][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([0.5844, 0.1094, 0.0022, 0.0083, 0.0604, 0.2354], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:17,366][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([0.7465, 0.1137, 0.0284, 0.0256, 0.0430, 0.0428], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:17,368][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([0.0056, 0.3635, 0.0922, 0.1604, 0.1478, 0.2306], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:17,369][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([9.7340e-01, 6.8264e-03, 9.4102e-04, 2.5419e-03, 1.6661e-03, 1.4622e-02],
       device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:17,371][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([0.7713, 0.1547, 0.0051, 0.0062, 0.0208, 0.0419], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:17,372][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([0.7796, 0.0804, 0.0032, 0.0161, 0.0290, 0.0917], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:17,374][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([0.1135, 0.2967, 0.0083, 0.0877, 0.0742, 0.4196], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:17,375][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([9.9533e-01, 3.2030e-05, 2.7739e-05, 2.0467e-03, 2.3189e-04, 1.9410e-04,
        2.1343e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:17,377][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0051, 0.1969, 0.0863, 0.0755, 0.3068, 0.1929, 0.1365],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:17,378][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1057, 0.0374, 0.2222, 0.0641, 0.3223, 0.1331, 0.1151],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:17,379][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.1060, 0.1873, 0.0285, 0.1350, 0.1381, 0.2460, 0.1592],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:17,380][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0175, 0.1101, 0.0014, 0.0077, 0.0258, 0.7769, 0.0605],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:17,381][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.5876, 0.0702, 0.0029, 0.0076, 0.0722, 0.2274, 0.0322],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:17,381][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.7794, 0.0631, 0.0300, 0.0206, 0.0321, 0.0404, 0.0344],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:17,383][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0016, 0.2737, 0.0932, 0.1178, 0.1543, 0.2518, 0.1077],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:17,384][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.9557, 0.0056, 0.0025, 0.0051, 0.0052, 0.0239, 0.0020],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:17,386][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.3286, 0.4114, 0.0131, 0.0138, 0.0683, 0.1278, 0.0369],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:17,387][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.7448, 0.0547, 0.0043, 0.0170, 0.0339, 0.0997, 0.0455],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:17,389][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0617, 0.2210, 0.0122, 0.0839, 0.1088, 0.4155, 0.0970],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:17,390][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([8.4953e-01, 6.5011e-05, 4.4957e-05, 3.8220e-03, 3.8739e-04, 3.5818e-04,
        3.7765e-03, 1.4202e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:17,392][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0112, 0.2129, 0.0669, 0.0773, 0.2944, 0.1242, 0.1345, 0.0786],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:17,393][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0503, 0.0361, 0.1924, 0.0454, 0.3883, 0.0777, 0.1221, 0.0877],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:17,395][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0942, 0.1550, 0.0263, 0.1179, 0.1287, 0.1918, 0.1427, 0.1433],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:17,396][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0091, 0.0653, 0.0011, 0.0062, 0.0218, 0.7457, 0.0790, 0.0720],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:17,398][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.6219, 0.0556, 0.0021, 0.0069, 0.0571, 0.1987, 0.0386, 0.0192],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:17,400][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.8677, 0.0397, 0.0125, 0.0098, 0.0190, 0.0172, 0.0218, 0.0123],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:17,402][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0023, 0.2361, 0.0841, 0.1062, 0.1314, 0.2408, 0.1014, 0.0977],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:17,403][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([9.7296e-01, 3.6776e-03, 7.1699e-04, 2.4553e-03, 1.1854e-03, 1.7407e-02,
        1.1807e-03, 4.1685e-04], device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:17,405][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.4469, 0.3382, 0.0090, 0.0124, 0.0520, 0.0834, 0.0279, 0.0302],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:17,406][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.7118, 0.0520, 0.0046, 0.0173, 0.0358, 0.1006, 0.0458, 0.0321],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:17,408][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0477, 0.1781, 0.0121, 0.0640, 0.0976, 0.3403, 0.0819, 0.1782],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:17,409][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ office] are: tensor([8.7434e-01, 4.9908e-05, 3.9173e-05, 2.5093e-03, 3.4105e-04, 3.1739e-04,
        3.0648e-03, 1.1928e-01, 5.5527e-05], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:17,411][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ office] are: tensor([0.0050, 0.1671, 0.0326, 0.0655, 0.1596, 0.1316, 0.1045, 0.1115, 0.2226],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:17,412][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ office] are: tensor([0.1577, 0.0333, 0.0559, 0.0453, 0.1518, 0.0671, 0.0992, 0.1510, 0.2387],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:17,414][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ office] are: tensor([0.1344, 0.1474, 0.0175, 0.0913, 0.1051, 0.1544, 0.0974, 0.0924, 0.1601],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:17,415][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ office] are: tensor([3.6888e-02, 5.2358e-02, 3.3691e-04, 2.9130e-03, 6.0565e-03, 3.3455e-01,
        4.3361e-02, 5.0737e-02, 4.7280e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:17,416][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ office] are: tensor([7.5443e-01, 1.9211e-02, 4.1335e-04, 1.7465e-03, 8.8233e-03, 5.4662e-02,
        9.8065e-03, 7.4238e-03, 1.4348e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:17,418][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ office] are: tensor([0.6413, 0.0664, 0.0214, 0.0233, 0.0312, 0.0475, 0.0399, 0.0345, 0.0945],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:17,420][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ office] are: tensor([0.0036, 0.2244, 0.0679, 0.1047, 0.0937, 0.1854, 0.0901, 0.0956, 0.1346],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:17,421][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ office] are: tensor([0.8922, 0.0202, 0.0031, 0.0068, 0.0048, 0.0412, 0.0095, 0.0031, 0.0192],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:17,423][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ office] are: tensor([0.5489, 0.2624, 0.0106, 0.0109, 0.0228, 0.0569, 0.0177, 0.0191, 0.0507],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:17,425][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ office] are: tensor([0.7562, 0.0378, 0.0021, 0.0108, 0.0193, 0.0700, 0.0254, 0.0179, 0.0605],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:17,426][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ office] are: tensor([0.1008, 0.1740, 0.0055, 0.0440, 0.0541, 0.2745, 0.0612, 0.1212, 0.1647],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:17,428][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([9.7010e-01, 9.3703e-06, 1.1183e-05, 7.0107e-04, 6.6220e-05, 8.7164e-05,
        7.1516e-04, 2.8073e-02, 1.1793e-05, 2.2370e-04], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:17,429][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.0046, 0.1355, 0.0528, 0.0349, 0.3098, 0.0932, 0.0875, 0.0624, 0.1757,
        0.0436], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:17,430][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.0584, 0.0207, 0.0779, 0.0523, 0.1794, 0.0883, 0.0608, 0.0720, 0.3263,
        0.0640], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:17,431][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.0911, 0.1251, 0.0152, 0.0777, 0.0802, 0.1300, 0.0985, 0.0958, 0.1167,
        0.1697], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:17,432][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.0264, 0.0648, 0.0007, 0.0042, 0.0093, 0.3760, 0.0411, 0.0416, 0.3862,
        0.0498], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:17,433][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.6252, 0.0295, 0.0010, 0.0035, 0.0192, 0.0707, 0.0165, 0.0082, 0.2011,
        0.0252], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:17,435][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.6151, 0.0693, 0.0259, 0.0224, 0.0313, 0.0329, 0.0486, 0.0300, 0.0779,
        0.0466], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:17,436][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0014, 0.1727, 0.0711, 0.0767, 0.1122, 0.1730, 0.0727, 0.0820, 0.1367,
        0.1017], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:17,438][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.8975, 0.0108, 0.0026, 0.0022, 0.0033, 0.0581, 0.0035, 0.0039, 0.0136,
        0.0046], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:17,440][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.4233, 0.3115, 0.0125, 0.0101, 0.0524, 0.0916, 0.0330, 0.0254, 0.0207,
        0.0195], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:17,441][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.7113, 0.0347, 0.0035, 0.0136, 0.0280, 0.0682, 0.0319, 0.0197, 0.0469,
        0.0422], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:17,443][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.0734, 0.1137, 0.0082, 0.0438, 0.0539, 0.1905, 0.0599, 0.1239, 0.1156,
        0.2173], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:17,444][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Erica] are: tensor([8.9892e-01, 6.8106e-05, 6.0064e-05, 2.6363e-03, 3.4707e-04, 4.4269e-04,
        3.0773e-03, 9.1497e-02, 8.8688e-05, 1.1468e-03, 1.7165e-03],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:17,446][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Erica] are: tensor([0.0013, 0.0759, 0.0205, 0.0450, 0.0769, 0.0937, 0.1002, 0.0843, 0.1792,
        0.0954, 0.2276], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:17,448][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Erica] are: tensor([0.0685, 0.0275, 0.0449, 0.1230, 0.0948, 0.0475, 0.0514, 0.0904, 0.2244,
        0.1306, 0.0969], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:17,449][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Erica] are: tensor([0.1388, 0.1084, 0.0154, 0.0402, 0.0531, 0.1153, 0.0789, 0.0703, 0.1536,
        0.1183, 0.1077], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:17,451][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Erica] are: tensor([3.2350e-02, 1.9904e-02, 2.9569e-04, 1.2938e-03, 2.5958e-03, 7.4955e-02,
        1.3493e-02, 2.4688e-02, 2.2763e-01, 5.2785e-02, 5.5001e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:17,452][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Erica] are: tensor([6.2861e-01, 9.5609e-03, 3.3951e-04, 9.8701e-04, 4.1558e-03, 2.2533e-02,
        5.6791e-03, 4.2830e-03, 1.1180e-01, 2.1493e-02, 1.9056e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:17,454][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Erica] are: tensor([0.3319, 0.0780, 0.0237, 0.0337, 0.0307, 0.0722, 0.0650, 0.0480, 0.1238,
        0.0745, 0.1185], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:17,455][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Erica] are: tensor([0.0024, 0.1689, 0.0503, 0.0861, 0.0823, 0.1462, 0.0712, 0.0856, 0.1234,
        0.1025, 0.0810], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:17,457][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Erica] are: tensor([0.3526, 0.0792, 0.0069, 0.0168, 0.0215, 0.1640, 0.0126, 0.0088, 0.1531,
        0.1467, 0.0379], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:17,459][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Erica] are: tensor([0.6639, 0.1418, 0.0120, 0.0059, 0.0352, 0.0650, 0.0103, 0.0149, 0.0163,
        0.0120, 0.0226], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:17,460][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Erica] are: tensor([0.6413, 0.0375, 0.0032, 0.0100, 0.0138, 0.0442, 0.0236, 0.0167, 0.0539,
        0.0466, 0.1093], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:17,462][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Erica] are: tensor([0.0933, 0.0982, 0.0028, 0.0402, 0.0208, 0.1575, 0.0406, 0.0904, 0.0910,
        0.2141, 0.1510], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:17,463][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([8.0966e-01, 8.5912e-05, 7.9480e-05, 4.5919e-03, 6.9487e-04, 4.7185e-04,
        5.4266e-03, 1.7191e-01, 9.7530e-05, 2.2595e-03, 2.3885e-03, 2.3328e-03],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:17,465][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0124, 0.1295, 0.0213, 0.0586, 0.0948, 0.0906, 0.0684, 0.0595, 0.1722,
        0.0994, 0.1411, 0.0523], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:17,467][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.0340, 0.0248, 0.0893, 0.0988, 0.0811, 0.0637, 0.0771, 0.0809, 0.1952,
        0.0495, 0.1678, 0.0377], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:17,469][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.1257, 0.0762, 0.0150, 0.0458, 0.0690, 0.0825, 0.0555, 0.0596, 0.1403,
        0.1085, 0.1253, 0.0967], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:17,470][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([2.6594e-02, 1.6221e-02, 1.4901e-04, 7.8460e-04, 1.7645e-03, 5.5606e-02,
        1.3028e-02, 1.4325e-02, 1.2727e-01, 3.1431e-02, 2.6755e-01, 4.4528e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:17,471][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([5.6984e-01, 8.7667e-03, 3.8918e-04, 7.9124e-04, 5.4494e-03, 1.8317e-02,
        4.9356e-03, 3.0512e-03, 6.9906e-02, 1.0706e-02, 1.6382e-01, 1.4403e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:17,473][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.7863, 0.0324, 0.0086, 0.0092, 0.0101, 0.0119, 0.0126, 0.0079, 0.0274,
        0.0219, 0.0399, 0.0317], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:17,474][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0026, 0.1527, 0.0506, 0.0745, 0.0760, 0.1300, 0.0667, 0.0738, 0.1140,
        0.0939, 0.0777, 0.0873], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:17,476][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([9.5085e-01, 2.9121e-03, 9.2858e-04, 2.5711e-03, 6.2577e-04, 9.3731e-03,
        1.1707e-03, 8.0465e-04, 1.2565e-02, 2.7861e-03, 2.1913e-03, 1.3224e-02],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:17,477][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.6195, 0.1955, 0.0109, 0.0100, 0.0245, 0.0532, 0.0126, 0.0102, 0.0152,
        0.0091, 0.0181, 0.0213], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:17,479][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.6359, 0.0277, 0.0024, 0.0078, 0.0159, 0.0355, 0.0201, 0.0120, 0.0356,
        0.0294, 0.0865, 0.0911], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:17,480][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.0486, 0.0781, 0.0036, 0.0300, 0.0281, 0.1152, 0.0376, 0.0663, 0.0743,
        0.1759, 0.1561, 0.1863], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:17,481][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([5.9711e-01, 5.1766e-05, 4.2871e-05, 3.5971e-03, 3.6570e-04, 3.3413e-04,
        3.7055e-03, 1.3494e-01, 5.9348e-05, 1.6729e-03, 1.4582e-03, 1.3972e-03,
        2.5526e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:17,482][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0029, 0.1200, 0.0216, 0.0432, 0.1165, 0.0729, 0.0741, 0.0484, 0.1356,
        0.0675, 0.1866, 0.0856, 0.0251], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:17,483][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0174, 0.0183, 0.1341, 0.0192, 0.1280, 0.0180, 0.0422, 0.0378, 0.1681,
        0.0559, 0.3166, 0.0150, 0.0292], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:17,484][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0413, 0.0649, 0.0124, 0.0647, 0.0789, 0.1062, 0.0636, 0.0732, 0.1078,
        0.1106, 0.0891, 0.0909, 0.0965], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:17,486][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([4.6150e-03, 1.1625e-02, 1.9020e-04, 1.2832e-03, 2.3027e-03, 1.0855e-01,
        1.4429e-02, 1.3545e-02, 1.1030e-01, 2.2661e-02, 1.8643e-01, 5.0872e-01,
        1.5351e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:17,487][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.2340, 0.0104, 0.0007, 0.0017, 0.0112, 0.0468, 0.0107, 0.0060, 0.1544,
        0.0209, 0.2210, 0.2749, 0.0073], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:17,489][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.4501, 0.0623, 0.0286, 0.0169, 0.0385, 0.0364, 0.0428, 0.0202, 0.0684,
        0.0496, 0.0901, 0.0769, 0.0192], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:17,491][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0021, 0.1298, 0.0526, 0.0662, 0.0808, 0.1379, 0.0607, 0.0641, 0.1057,
        0.0849, 0.0828, 0.0920, 0.0404], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:17,492][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.8281, 0.0063, 0.0018, 0.0060, 0.0015, 0.0317, 0.0034, 0.0014, 0.0150,
        0.0053, 0.0058, 0.0881, 0.0056], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:17,494][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.3069, 0.3321, 0.0113, 0.0164, 0.0503, 0.0836, 0.0392, 0.0320, 0.0349,
        0.0263, 0.0219, 0.0302, 0.0151], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:17,496][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.5111, 0.0274, 0.0030, 0.0106, 0.0237, 0.0584, 0.0268, 0.0181, 0.0491,
        0.0364, 0.1148, 0.1014, 0.0192], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:17,498][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0187, 0.0781, 0.0044, 0.0296, 0.0303, 0.1411, 0.0351, 0.0680, 0.0917,
        0.1256, 0.1258, 0.1783, 0.0733], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:17,499][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ basketball] are: tensor([5.3995e-01, 9.2263e-05, 7.1931e-05, 4.1914e-03, 6.4486e-04, 4.8468e-04,
        4.8197e-03, 1.7534e-01, 8.9503e-05, 2.4490e-03, 2.6457e-03, 1.9825e-03,
        2.6670e-01, 5.3878e-04], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:17,501][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ basketball] are: tensor([0.0050, 0.0775, 0.0259, 0.0765, 0.0776, 0.0475, 0.0804, 0.0596, 0.1154,
        0.0627, 0.1470, 0.0791, 0.0381, 0.1076], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:17,502][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ basketball] are: tensor([0.0810, 0.0303, 0.0711, 0.0605, 0.1036, 0.0633, 0.0354, 0.0932, 0.0781,
        0.0577, 0.1485, 0.0118, 0.0612, 0.1043], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:17,504][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ basketball] are: tensor([0.1177, 0.0675, 0.0063, 0.0341, 0.0405, 0.0634, 0.0472, 0.0447, 0.0652,
        0.0840, 0.0595, 0.0812, 0.0399, 0.2489], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:17,505][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ basketball] are: tensor([5.5922e-02, 9.2606e-03, 8.8830e-05, 4.0170e-04, 8.8084e-04, 2.5156e-02,
        5.5558e-03, 5.4919e-03, 4.1645e-02, 1.6337e-02, 1.2009e-01, 3.3817e-01,
        1.6142e-02, 3.6485e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:17,507][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ basketball] are: tensor([7.7673e-01, 1.7967e-03, 5.9593e-05, 1.5794e-04, 4.9609e-04, 3.2724e-03,
        9.9140e-04, 6.7763e-04, 1.0982e-02, 2.8588e-03, 2.9989e-02, 3.8169e-02,
        1.8620e-03, 1.3196e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:17,509][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ basketball] are: tensor([0.6356, 0.0270, 0.0152, 0.0127, 0.0136, 0.0149, 0.0227, 0.0156, 0.0347,
        0.0298, 0.0481, 0.0455, 0.0152, 0.0694], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:17,510][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ basketball] are: tensor([0.0037, 0.1333, 0.0439, 0.0645, 0.0632, 0.1246, 0.0572, 0.0610, 0.0971,
        0.0828, 0.0661, 0.0786, 0.0431, 0.0809], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:17,512][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ basketball] are: tensor([0.8349, 0.0116, 0.0039, 0.0042, 0.0021, 0.0251, 0.0041, 0.0020, 0.0132,
        0.0088, 0.0129, 0.0426, 0.0088, 0.0257], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:17,514][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ basketball] are: tensor([0.6711, 0.1216, 0.0089, 0.0076, 0.0292, 0.0547, 0.0114, 0.0111, 0.0184,
        0.0080, 0.0175, 0.0212, 0.0055, 0.0140], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:17,516][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ basketball] are: tensor([0.6537, 0.0174, 0.0012, 0.0053, 0.0076, 0.0226, 0.0118, 0.0073, 0.0203,
        0.0225, 0.0488, 0.0523, 0.0077, 0.1215], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:17,517][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ basketball] are: tensor([0.0559, 0.0877, 0.0027, 0.0230, 0.0183, 0.0949, 0.0257, 0.0441, 0.0433,
        0.1356, 0.1072, 0.1345, 0.0447, 0.1824], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:17,519][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([8.4828e-01, 1.8698e-05, 1.9093e-05, 1.3204e-03, 1.5105e-04, 1.3990e-04,
        1.4074e-03, 5.4606e-02, 2.2460e-05, 5.1827e-04, 6.3082e-04, 6.1294e-04,
        8.8501e-02, 1.5538e-04, 3.6121e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:17,520][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0017, 0.0588, 0.0194, 0.0237, 0.0881, 0.0653, 0.0473, 0.0500, 0.1220,
        0.0529, 0.1462, 0.0525, 0.0346, 0.1676, 0.0699], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:17,522][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0437, 0.0095, 0.0708, 0.0219, 0.1131, 0.0268, 0.0319, 0.0610, 0.2261,
        0.0357, 0.1909, 0.0128, 0.0406, 0.0947, 0.0205], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:17,524][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0417, 0.0585, 0.0070, 0.0481, 0.0437, 0.0670, 0.0478, 0.0458, 0.0738,
        0.0896, 0.0476, 0.0642, 0.0566, 0.2297, 0.0789], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:17,525][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([1.5614e-02, 8.0199e-03, 1.3718e-04, 7.4173e-04, 1.4555e-03, 5.7205e-02,
        7.5335e-03, 9.2844e-03, 5.1638e-02, 1.6093e-02, 1.0290e-01, 3.5481e-01,
        1.3277e-02, 3.3055e-01, 3.0747e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:17,526][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([3.3509e-01, 4.8777e-03, 3.2463e-04, 6.9887e-04, 4.0547e-03, 1.9027e-02,
        3.8735e-03, 2.5326e-03, 4.4165e-02, 8.3301e-03, 7.4202e-02, 1.0078e-01,
        3.9429e-03, 3.8020e-01, 1.7907e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:17,528][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.4968, 0.0303, 0.0156, 0.0122, 0.0191, 0.0241, 0.0238, 0.0183, 0.0419,
        0.0342, 0.0510, 0.0501, 0.0167, 0.1355, 0.0306], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:17,530][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0008, 0.1147, 0.0485, 0.0541, 0.0780, 0.1273, 0.0486, 0.0546, 0.1007,
        0.0709, 0.0745, 0.0769, 0.0336, 0.0805, 0.0364], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:17,531][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.8318, 0.0052, 0.0031, 0.0061, 0.0054, 0.0314, 0.0027, 0.0029, 0.0203,
        0.0059, 0.0099, 0.0575, 0.0027, 0.0132, 0.0019], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:17,532][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.1722, 0.3565, 0.0147, 0.0133, 0.0828, 0.1231, 0.0433, 0.0401, 0.0356,
        0.0183, 0.0302, 0.0274, 0.0157, 0.0194, 0.0074], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:17,533][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.5687, 0.0178, 0.0018, 0.0072, 0.0127, 0.0367, 0.0176, 0.0115, 0.0259,
        0.0271, 0.0607, 0.0682, 0.0118, 0.1112, 0.0212], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:17,534][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0351, 0.0763, 0.0029, 0.0274, 0.0208, 0.1144, 0.0241, 0.0549, 0.0526,
        0.1263, 0.0720, 0.1176, 0.0626, 0.1718, 0.0412], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:17,538][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:24:17,540][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[12354],
        [ 7097],
        [ 2480],
        [ 1081],
        [17907],
        [ 1921],
        [  854],
        [  257],
        [  136],
        [   45],
        [  309],
        [   93],
        [   89],
        [  186],
        [   73]], device='cuda:0')
[2024-07-24 10:24:17,542][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[12262],
        [19181],
        [ 4641],
        [ 3295],
        [36607],
        [ 3608],
        [  889],
        [  342],
        [  134],
        [  166],
        [ 1067],
        [  909],
        [  327],
        [  356],
        [  354]], device='cuda:0')
[2024-07-24 10:24:17,543][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[2261],
        [2310],
        [1971],
        [1348],
        [1431],
        [1488],
        [1373],
        [1234],
        [1301],
        [1487],
        [1528],
        [1655],
        [1414],
        [1403],
        [1494]], device='cuda:0')
[2024-07-24 10:24:17,545][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[42779],
        [12479],
        [18850],
        [19910],
        [30087],
        [27636],
        [32552],
        [33287],
        [34454],
        [34309],
        [34854],
        [35374],
        [34283],
        [34939],
        [35374]], device='cuda:0')
[2024-07-24 10:24:17,547][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[18117],
        [12866],
        [13025],
        [14377],
        [13429],
        [14242],
        [13526],
        [16303],
        [18218],
        [17055],
        [18557],
        [19629],
        [19266],
        [20726],
        [19292]], device='cuda:0')
[2024-07-24 10:24:17,548][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[40689],
        [37239],
        [36851],
        [35754],
        [36028],
        [39218],
        [36715],
        [34040],
        [32423],
        [31131],
        [30645],
        [29738],
        [28864],
        [25157],
        [24047]], device='cuda:0')
[2024-07-24 10:24:17,550][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[14421],
        [18751],
        [19647],
        [18710],
        [19582],
        [18868],
        [18384],
        [18175],
        [17863],
        [17722],
        [14109],
        [16447],
        [16643],
        [21826],
        [19820]], device='cuda:0')
[2024-07-24 10:24:17,552][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[ 7740],
        [ 7285],
        [17118],
        [20475],
        [32533],
        [30224],
        [30340],
        [28889],
        [19995],
        [19110],
        [18660],
        [24117],
        [21692],
        [25143],
        [27406]], device='cuda:0')
[2024-07-24 10:24:17,553][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[4744],
        [4444],
        [8001],
        [6782],
        [8229],
        [6530],
        [6518],
        [6381],
        [5922],
        [5715],
        [6361],
        [6374],
        [6328],
        [6223],
        [6311]], device='cuda:0')
[2024-07-24 10:24:17,555][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[29800],
        [26407],
        [19503],
        [17412],
        [17458],
        [15257],
        [14301],
        [11800],
        [11794],
        [12009],
        [13180],
        [11506],
        [10464],
        [10653],
        [10002]], device='cuda:0')
[2024-07-24 10:24:17,556][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[ 6234],
        [ 6334],
        [ 9242],
        [ 9183],
        [33822],
        [17490],
        [19561],
        [19330],
        [12657],
        [17695],
        [32038],
        [38420],
        [38903],
        [29494],
        [35584]], device='cuda:0')
[2024-07-24 10:24:17,558][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[36538],
        [23481],
        [37070],
        [37406],
        [30202],
        [20902],
        [18761],
        [15594],
        [27260],
        [20126],
        [29485],
        [27022],
        [24407],
        [21779],
        [20983]], device='cuda:0')
[2024-07-24 10:24:17,560][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[21593],
        [19880],
        [20246],
        [20595],
        [ 8272],
        [ 7327],
        [12547],
        [ 6280],
        [ 6566],
        [ 5207],
        [ 5401],
        [ 4154],
        [ 4106],
        [ 6073],
        [ 6483]], device='cuda:0')
[2024-07-24 10:24:17,561][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[ 4045],
        [22584],
        [15902],
        [11600],
        [48172],
        [46282],
        [46272],
        [35526],
        [13628],
        [12939],
        [ 3086],
        [ 5251],
        [ 6547],
        [ 6941],
        [ 8344]], device='cuda:0')
[2024-07-24 10:24:17,563][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[17017],
        [ 7161],
        [ 8571],
        [ 8164],
        [ 9674],
        [ 8817],
        [10386],
        [ 8144],
        [ 7705],
        [ 6093],
        [ 6854],
        [ 3562],
        [ 5279],
        [ 6985],
        [ 6279]], device='cuda:0')
[2024-07-24 10:24:17,565][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[9146],
        [9137],
        [9050],
        [8333],
        [7346],
        [7019],
        [7768],
        [2311],
        [2296],
        [4299],
        [2292],
        [2189],
        [1372],
        [1347],
        [1891]], device='cuda:0')
[2024-07-24 10:24:17,566][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[23755],
        [36224],
        [38599],
        [43463],
        [43057],
        [42958],
        [40137],
        [40611],
        [37327],
        [36875],
        [34549],
        [38057],
        [37705],
        [37241],
        [34054]], device='cuda:0')
[2024-07-24 10:24:17,568][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[28922],
        [36611],
        [26049],
        [24155],
        [23119],
        [27229],
        [26303],
        [23991],
        [28193],
        [30366],
        [27215],
        [30161],
        [26016],
        [33470],
        [33319]], device='cuda:0')
[2024-07-24 10:24:17,570][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[46871],
        [16468],
        [16748],
        [12494],
        [13484],
        [13407],
        [14393],
        [12720],
        [15884],
        [18309],
        [22389],
        [22481],
        [20697],
        [17735],
        [18662]], device='cuda:0')
[2024-07-24 10:24:17,571][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[41150],
        [30564],
        [28581],
        [28530],
        [35328],
        [16055],
        [15710],
        [15236],
        [ 6083],
        [ 7329],
        [14635],
        [26177],
        [25628],
        [16584],
        [16776]], device='cuda:0')
[2024-07-24 10:24:17,573][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[38700],
        [36299],
        [24067],
        [26464],
        [27628],
        [26126],
        [25717],
        [25960],
        [33948],
        [30607],
        [27382],
        [23325],
        [15534],
        [30548],
        [14530]], device='cuda:0')
[2024-07-24 10:24:17,575][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[32440],
        [30183],
        [15787],
        [21757],
        [14656],
        [21162],
        [24181],
        [28620],
        [17725],
        [16876],
        [14737],
        [25277],
        [15127],
        [22107],
        [19628]], device='cuda:0')
[2024-07-24 10:24:17,576][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[18506],
        [ 9825],
        [10545],
        [10255],
        [11716],
        [10077],
        [10449],
        [10387],
        [10530],
        [11256],
        [11143],
        [10863],
        [10731],
        [ 9882],
        [10126]], device='cuda:0')
[2024-07-24 10:24:17,578][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[22978],
        [22973],
        [ 8457],
        [22729],
        [10778],
        [22041],
        [20810],
        [22251],
        [13735],
        [15289],
        [16410],
        [18912],
        [22466],
        [13625],
        [16999]], device='cuda:0')
[2024-07-24 10:24:17,580][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[31699],
        [35372],
        [13167],
        [ 5228],
        [29713],
        [18668],
        [ 5067],
        [ 5878],
        [ 6734],
        [ 5425],
        [11082],
        [ 8255],
        [ 4121],
        [10268],
        [ 3832]], device='cuda:0')
[2024-07-24 10:24:17,581][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[ 5000],
        [ 6939],
        [13544],
        [11353],
        [14775],
        [11306],
        [10448],
        [10190],
        [ 9696],
        [10349],
        [12054],
        [ 8062],
        [ 9828],
        [10053],
        [10854]], device='cuda:0')
[2024-07-24 10:24:17,583][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 4594],
        [39266],
        [40183],
        [32874],
        [43066],
        [46861],
        [47306],
        [44959],
        [35137],
        [32309],
        [29103],
        [37401],
        [38669],
        [37919],
        [38233]], device='cuda:0')
[2024-07-24 10:24:17,584][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[10967],
        [12550],
        [29876],
        [24439],
        [18259],
        [23160],
        [26074],
        [29802],
        [35661],
        [33240],
        [35162],
        [31064],
        [34071],
        [31824],
        [34323]], device='cuda:0')
[2024-07-24 10:24:17,586][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[25493],
        [35133],
        [35858],
        [38671],
        [33417],
        [35675],
        [40053],
        [43831],
        [41865],
        [44055],
        [39770],
        [41490],
        [46347],
        [43341],
        [45147]], device='cuda:0')
[2024-07-24 10:24:17,588][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[15656],
        [15656],
        [15656],
        [15656],
        [15656],
        [15656],
        [15656],
        [15656],
        [15656],
        [15656],
        [15656],
        [15656],
        [15656],
        [15656],
        [15656]], device='cuda:0')
[2024-07-24 10:24:17,695][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:24:17,695][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:17,696][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:17,696][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:17,696][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:17,697][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:17,697][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:17,698][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:17,698][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:17,699][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:17,699][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:17,699][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:17,700][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:17,700][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.2564, 0.7436], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:17,700][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0106, 0.9894], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:17,701][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.9473, 0.0527], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:17,701][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.9439, 0.0561], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:17,701][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0531, 0.9469], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:17,702][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.9852, 0.0148], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:17,702][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0016, 0.9984], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:17,702][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.9980, 0.0020], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:17,703][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.7115, 0.2885], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:17,703][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [,] are: tensor([1.0979e-05, 9.9999e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:17,703][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.4774, 0.5226], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:17,704][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [,] are: tensor([5.2030e-04, 9.9948e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:17,705][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Erica] are: tensor([0.1979, 0.6085, 0.1935], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:17,705][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Erica] are: tensor([0.0057, 0.9871, 0.0073], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:17,706][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Erica] are: tensor([0.5902, 0.3767, 0.0331], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:17,706][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Erica] are: tensor([0.2234, 0.7754, 0.0012], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:17,706][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Erica] are: tensor([0.0141, 0.1979, 0.7881], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:17,707][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Erica] are: tensor([0.8975, 0.0758, 0.0267], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:17,707][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Erica] are: tensor([0.0008, 0.7624, 0.2368], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:17,707][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Erica] are: tensor([0.2040, 0.7931, 0.0028], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:17,708][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Erica] are: tensor([0.3433, 0.6341, 0.0227], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:17,708][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Erica] are: tensor([4.0577e-05, 8.8219e-01, 1.1777e-01], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:17,708][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Erica] are: tensor([0.0061, 0.9919, 0.0021], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:17,709][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Erica] are: tensor([5.4324e-04, 9.5640e-01, 4.3058e-02], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:17,709][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.1341, 0.4871, 0.1154, 0.2633], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:17,709][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0499, 0.8461, 0.0104, 0.0936], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:17,710][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.8805, 0.0900, 0.0141, 0.0154], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:17,710][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.5584, 0.4239, 0.0011, 0.0166], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:17,710][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0228, 0.2516, 0.5306, 0.1951], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:17,711][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.9561, 0.0279, 0.0059, 0.0100], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:17,711][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0027, 0.4322, 0.4713, 0.0938], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:17,711][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.9701, 0.0258, 0.0019, 0.0023], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:17,712][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.7356, 0.1655, 0.0833, 0.0156], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:17,712][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ and] are: tensor([3.3171e-05, 5.4019e-01, 8.6552e-02, 3.7322e-01], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:17,712][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0752, 0.9158, 0.0013, 0.0077], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:17,713][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ and] are: tensor([4.8439e-04, 6.5880e-01, 4.9373e-02, 2.9135e-01], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:17,713][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Joshua] are: tensor([0.1256, 0.3660, 0.1246, 0.2061, 0.1778], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:17,713][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Joshua] are: tensor([0.0040, 0.8792, 0.0034, 0.0960, 0.0174], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:17,714][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Joshua] are: tensor([0.6099, 0.2851, 0.0243, 0.0291, 0.0515], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:17,714][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Joshua] are: tensor([5.8464e-01, 3.6408e-01, 1.0613e-04, 1.2407e-02, 3.8768e-02],
       device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:17,714][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Joshua] are: tensor([0.0258, 0.2932, 0.3294, 0.0958, 0.2558], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:17,715][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Joshua] are: tensor([0.7699, 0.0604, 0.0115, 0.0207, 0.1375], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:17,717][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Joshua] are: tensor([0.0009, 0.2353, 0.1884, 0.0763, 0.4992], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:17,718][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Joshua] are: tensor([0.1464, 0.8092, 0.0013, 0.0294, 0.0137], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:17,719][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Joshua] are: tensor([0.7990, 0.1397, 0.0087, 0.0116, 0.0410], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:17,720][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Joshua] are: tensor([1.7848e-05, 4.0600e-01, 5.8774e-02, 2.1905e-01, 3.1617e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:17,721][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Joshua] are: tensor([8.3922e-02, 8.3808e-01, 3.7407e-04, 5.5010e-03, 7.2127e-02],
       device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:17,722][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Joshua] are: tensor([4.5489e-04, 7.0213e-01, 2.8402e-02, 1.5787e-01, 1.1114e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:17,723][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ went] are: tensor([0.0804, 0.2620, 0.0549, 0.1245, 0.0842, 0.3941], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:17,725][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ went] are: tensor([0.0015, 0.7473, 0.0091, 0.1094, 0.1087, 0.0240], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:17,726][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ went] are: tensor([0.6615, 0.1266, 0.0080, 0.0215, 0.0287, 0.1538], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:17,727][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ went] are: tensor([7.9476e-01, 4.4392e-02, 1.3178e-05, 4.6756e-04, 3.5846e-03, 1.5678e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:17,728][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ went] are: tensor([0.0044, 0.2755, 0.1724, 0.0655, 0.1432, 0.3390], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:17,730][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ went] are: tensor([0.6973, 0.0531, 0.0059, 0.0146, 0.0501, 0.1790], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:17,731][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ went] are: tensor([0.0005, 0.1856, 0.0872, 0.0489, 0.4322, 0.2456], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:17,732][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ went] are: tensor([6.6433e-01, 2.6105e-01, 5.0835e-04, 1.7387e-02, 6.2880e-03, 5.0432e-02],
       device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:17,733][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.7431, 0.0947, 0.0124, 0.0063, 0.0223, 0.1212], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:17,734][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ went] are: tensor([7.5138e-06, 4.5238e-01, 1.6572e-02, 3.3746e-01, 1.3525e-01, 5.8327e-02],
       device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:17,735][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ went] are: tensor([8.6594e-02, 2.6814e-01, 9.4348e-05, 9.7329e-04, 1.0886e-02, 6.3331e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:17,736][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ went] are: tensor([1.8409e-04, 3.8295e-01, 2.9246e-02, 1.6475e-01, 1.0080e-01, 3.2207e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:17,737][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0344, 0.2138, 0.0544, 0.1003, 0.0807, 0.3692, 0.1472],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:17,739][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0011, 0.5700, 0.0072, 0.0673, 0.1276, 0.0734, 0.1533],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:17,740][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.6073, 0.1266, 0.0148, 0.0228, 0.0436, 0.1429, 0.0419],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:17,741][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ to] are: tensor([5.9166e-01, 4.6090e-02, 4.4239e-05, 1.6294e-03, 6.6901e-03, 3.4144e-01,
        1.2441e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:17,743][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0232, 0.1527, 0.2567, 0.1943, 0.0847, 0.2208, 0.0675],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:17,744][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.7524, 0.0203, 0.0056, 0.0074, 0.0381, 0.1389, 0.0373],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:17,745][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ to] are: tensor([1.9707e-04, 1.3111e-01, 1.1876e-01, 3.4101e-02, 3.0373e-01, 2.7619e-01,
        1.3590e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:17,747][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.6889, 0.0978, 0.0015, 0.0085, 0.0110, 0.1788, 0.0134],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:17,748][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.3264, 0.1313, 0.0436, 0.0138, 0.1092, 0.3491, 0.0267],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:17,749][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ to] are: tensor([2.5523e-06, 3.3156e-01, 3.3249e-02, 1.8673e-01, 1.7214e-01, 1.1126e-01,
        1.6506e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:17,750][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ to] are: tensor([8.9765e-02, 1.9631e-01, 1.9119e-04, 1.7842e-03, 1.3249e-02, 6.7746e-01,
        2.1243e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:17,751][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ to] are: tensor([1.9478e-04, 3.2432e-01, 1.6787e-02, 1.1361e-01, 5.9599e-02, 1.5802e-01,
        3.2747e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:17,752][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0142, 0.1901, 0.0404, 0.0845, 0.0711, 0.3099, 0.1257, 0.1641],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:17,754][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0050, 0.5959, 0.0097, 0.0976, 0.0937, 0.0177, 0.1422, 0.0382],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:17,755][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.4232, 0.1460, 0.0215, 0.0258, 0.0769, 0.1847, 0.0657, 0.0561],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:17,756][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ the] are: tensor([6.3332e-01, 2.9962e-02, 3.6174e-05, 1.2768e-03, 4.1033e-03, 3.0788e-01,
        1.3367e-02, 1.0050e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:17,757][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0068, 0.0800, 0.2195, 0.0191, 0.0294, 0.6209, 0.0236, 0.0007],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:17,757][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.5399, 0.0311, 0.0077, 0.0121, 0.0616, 0.2157, 0.0704, 0.0615],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:17,758][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ the] are: tensor([1.4254e-04, 1.3775e-01, 1.4950e-01, 2.0434e-02, 3.5021e-01, 2.0733e-01,
        9.2447e-02, 4.2194e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:17,758][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ the] are: tensor([8.5439e-01, 6.8173e-02, 4.4267e-04, 9.6020e-03, 7.1155e-03, 4.4194e-02,
        1.0684e-02, 5.4030e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:17,759][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.2749, 0.1214, 0.0395, 0.0113, 0.1354, 0.3668, 0.0223, 0.0286],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:17,759][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ the] are: tensor([1.6992e-06, 2.5322e-01, 2.8317e-02, 1.2696e-01, 1.8446e-01, 8.3684e-02,
        1.3418e-01, 1.8917e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:17,759][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ the] are: tensor([9.5023e-02, 1.3632e-01, 1.2688e-04, 1.7872e-03, 9.0191e-03, 6.9716e-01,
        2.5679e-02, 3.4889e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:17,760][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ the] are: tensor([1.4757e-04, 2.9657e-01, 1.2929e-02, 8.2589e-02, 4.9460e-02, 9.6498e-02,
        2.0001e-01, 2.6179e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:17,761][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ office] are: tensor([0.0187, 0.1274, 0.0339, 0.0711, 0.0663, 0.2609, 0.1243, 0.1727, 0.1246],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:17,762][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ office] are: tensor([0.0166, 0.7080, 0.0040, 0.0759, 0.0205, 0.0217, 0.0957, 0.0413, 0.0164],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:17,763][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ office] are: tensor([0.6066, 0.0750, 0.0094, 0.0132, 0.0257, 0.1099, 0.0336, 0.0253, 0.1013],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:17,764][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ office] are: tensor([8.6518e-01, 4.1821e-03, 1.1683e-06, 6.6191e-05, 1.2433e-04, 1.6134e-02,
        1.3199e-03, 1.1494e-03, 1.1184e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:17,766][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ office] are: tensor([0.0059, 0.0690, 0.0968, 0.0151, 0.0284, 0.0763, 0.0395, 0.0091, 0.6598],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:17,767][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ office] are: tensor([0.6202, 0.0262, 0.0061, 0.0075, 0.0474, 0.1165, 0.0331, 0.0388, 0.1041],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:17,767][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ office] are: tensor([1.2109e-04, 7.5685e-02, 4.6722e-02, 1.8025e-02, 2.4601e-01, 1.6359e-01,
        8.6476e-02, 5.2856e-02, 3.1051e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:17,769][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ office] are: tensor([0.5009, 0.2502, 0.0006, 0.0114, 0.0031, 0.1024, 0.0409, 0.0418, 0.0486],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:17,770][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ office] are: tensor([0.7642, 0.0638, 0.0030, 0.0024, 0.0128, 0.0501, 0.0071, 0.0093, 0.0873],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:17,771][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ office] are: tensor([5.3775e-06, 2.2724e-01, 1.8520e-02, 1.2325e-01, 1.5703e-01, 9.7165e-02,
        1.1295e-01, 1.6319e-01, 1.0065e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:17,772][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ office] are: tensor([2.6384e-01, 6.7439e-02, 3.3336e-05, 4.8326e-04, 2.6220e-03, 2.1222e-01,
        9.7557e-03, 2.1609e-02, 4.2200e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:17,773][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ office] are: tensor([1.5273e-04, 1.7379e-01, 7.2032e-03, 7.3239e-02, 4.4666e-02, 9.2633e-02,
        1.9748e-01, 2.5951e-01, 1.5133e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:17,774][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.0246, 0.1175, 0.0349, 0.0695, 0.0553, 0.2510, 0.1044, 0.1410, 0.1155,
        0.0863], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:17,775][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [.] are: tensor([2.7471e-04, 4.0989e-01, 1.7379e-03, 6.2443e-02, 2.6347e-02, 9.4630e-03,
        4.8819e-02, 6.3096e-02, 1.8674e-02, 3.5925e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:17,777][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.6515, 0.0557, 0.0119, 0.0105, 0.0277, 0.0813, 0.0316, 0.0230, 0.0750,
        0.0317], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:17,778][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [.] are: tensor([8.1632e-01, 4.6323e-03, 6.7410e-06, 3.0400e-04, 4.8073e-04, 3.1210e-02,
        2.1858e-03, 2.0477e-03, 1.2682e-01, 1.5988e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:17,779][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0071, 0.0487, 0.1622, 0.0378, 0.0273, 0.1514, 0.0187, 0.0042, 0.5209,
        0.0216], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:17,780][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.8299, 0.0073, 0.0023, 0.0033, 0.0163, 0.0527, 0.0188, 0.0128, 0.0516,
        0.0051], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:17,781][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [.] are: tensor([1.5934e-04, 4.9910e-02, 1.4050e-01, 1.2820e-02, 2.7044e-01, 1.0900e-01,
        6.1975e-02, 2.8764e-02, 2.9815e-01, 2.8284e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:17,782][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [.] are: tensor([8.1469e-01, 2.8328e-02, 5.5531e-04, 1.6640e-03, 3.0542e-03, 9.6878e-02,
        6.3292e-03, 4.7300e-03, 1.6495e-02, 2.7273e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:17,784][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.5013, 0.0607, 0.0370, 0.0053, 0.0464, 0.1196, 0.0134, 0.0209, 0.1690,
        0.0265], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:17,785][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [.] are: tensor([3.4478e-06, 1.8009e-01, 3.8125e-02, 1.3004e-01, 1.7156e-01, 4.2887e-02,
        1.1595e-01, 1.4871e-01, 7.7369e-02, 9.5263e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:17,786][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [.] are: tensor([2.9099e-01, 5.9379e-02, 1.0796e-04, 1.0531e-03, 6.1116e-03, 3.0483e-01,
        1.0479e-02, 1.8284e-02, 2.8776e-01, 2.1006e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:17,787][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [.] are: tensor([1.0897e-04, 1.2405e-01, 1.0502e-02, 5.5203e-02, 5.7886e-02, 9.3131e-02,
        1.4701e-01, 1.9257e-01, 1.4996e-01, 1.6958e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:17,788][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Erica] are: tensor([0.0472, 0.0863, 0.0329, 0.0585, 0.0473, 0.2185, 0.0986, 0.1187, 0.1177,
        0.0650, 0.1093], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:17,789][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Erica] are: tensor([0.0009, 0.4198, 0.0016, 0.0699, 0.0096, 0.0244, 0.0858, 0.0216, 0.0140,
        0.3504, 0.0020], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:17,791][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Erica] are: tensor([0.2974, 0.1291, 0.0072, 0.0267, 0.0237, 0.1594, 0.0496, 0.0425, 0.0965,
        0.0634, 0.1044], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:17,792][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Erica] are: tensor([8.1559e-01, 1.2764e-03, 8.7539e-07, 4.0038e-05, 5.9339e-05, 5.7453e-03,
        7.3891e-04, 9.2466e-04, 7.3369e-02, 1.9884e-02, 8.2368e-02],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:17,793][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Erica] are: tensor([0.0047, 0.0330, 0.2173, 0.0030, 0.0479, 0.0236, 0.0060, 0.0010, 0.3751,
        0.0327, 0.2556], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:17,795][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Erica] are: tensor([0.7916, 0.0111, 0.0042, 0.0043, 0.0264, 0.0527, 0.0143, 0.0161, 0.0433,
        0.0046, 0.0314], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:17,795][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Erica] are: tensor([5.6003e-05, 7.4693e-02, 2.9924e-02, 2.5549e-02, 9.9834e-02, 1.3313e-01,
        8.0733e-02, 4.8133e-02, 2.4412e-01, 4.7252e-02, 2.1657e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:17,796][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Erica] are: tensor([1.4072e-01, 4.0261e-01, 2.6198e-04, 9.5564e-03, 5.0421e-03, 6.3923e-02,
        2.4399e-02, 3.7243e-02, 3.6895e-02, 2.7557e-01, 3.7772e-03],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:17,798][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Erica] are: tensor([0.6316, 0.0459, 0.0059, 0.0042, 0.0107, 0.0621, 0.0111, 0.0180, 0.0856,
        0.0145, 0.1106], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:17,799][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Erica] are: tensor([1.7216e-06, 1.4471e-01, 1.3694e-02, 1.0592e-01, 1.2524e-01, 8.9210e-02,
        1.1764e-01, 1.3457e-01, 7.7530e-02, 9.4521e-02, 9.6952e-02],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:17,800][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Erica] are: tensor([7.1395e-02, 1.5011e-02, 2.0358e-05, 1.9607e-04, 7.0890e-04, 6.3248e-02,
        3.8764e-03, 9.1807e-03, 1.8593e-01, 3.5607e-02, 6.1482e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:17,801][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Erica] are: tensor([1.9573e-04, 1.5067e-01, 6.7715e-03, 5.2022e-02, 2.9775e-02, 9.6278e-02,
        1.4294e-01, 1.3598e-01, 1.3065e-01, 2.2368e-01, 3.1037e-02],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:17,802][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.0164, 0.0993, 0.0314, 0.0525, 0.0442, 0.1927, 0.0864, 0.0997, 0.0983,
        0.0566, 0.1115, 0.1109], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:17,804][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0007, 0.3929, 0.0022, 0.0376, 0.0253, 0.0113, 0.0915, 0.0682, 0.0173,
        0.3276, 0.0015, 0.0238], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:17,804][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.3848, 0.0642, 0.0096, 0.0090, 0.0258, 0.0646, 0.0247, 0.0186, 0.0845,
        0.0242, 0.1626, 0.1276], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:17,805][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([8.9294e-01, 6.3540e-04, 8.9602e-07, 1.5229e-05, 2.6807e-05, 1.5128e-03,
        2.2610e-04, 1.5402e-04, 1.4454e-02, 2.6600e-03, 2.9157e-02, 5.8223e-02],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:17,805][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.0009, 0.0171, 0.1146, 0.0131, 0.0195, 0.0879, 0.0188, 0.0052, 0.4995,
        0.0172, 0.1690, 0.0372], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:17,806][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.5385, 0.0225, 0.0044, 0.0066, 0.0366, 0.0874, 0.0296, 0.0245, 0.0937,
        0.0086, 0.0394, 0.1081], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:17,806][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([1.1434e-04, 5.0901e-02, 3.6301e-02, 1.5564e-02, 1.3750e-01, 1.0492e-01,
        5.1119e-02, 2.9738e-02, 1.9465e-01, 3.2591e-02, 2.5213e-01, 9.4469e-02],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:17,806][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.4076, 0.1370, 0.0021, 0.0174, 0.0073, 0.0973, 0.0288, 0.0366, 0.0266,
        0.1647, 0.0243, 0.0502], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:17,807][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.1992, 0.1062, 0.0208, 0.0066, 0.0321, 0.1310, 0.0100, 0.0162, 0.1459,
        0.0222, 0.2339, 0.0759], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:17,807][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([2.2226e-06, 1.5926e-01, 1.1859e-02, 1.1360e-01, 9.0868e-02, 3.5338e-02,
        9.5044e-02, 1.3143e-01, 8.1128e-02, 1.1948e-01, 1.2992e-01, 3.2074e-02],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:17,808][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([1.3354e-01, 1.0224e-02, 8.0282e-06, 1.0940e-04, 4.4356e-04, 2.5517e-02,
        1.8027e-03, 2.4998e-03, 8.3849e-02, 7.9790e-03, 1.8238e-01, 5.5164e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:17,809][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([6.1696e-05, 9.0061e-02, 4.0092e-03, 4.8851e-02, 1.5431e-02, 5.7402e-02,
        7.3145e-02, 1.0607e-01, 9.1397e-02, 1.9526e-01, 2.0235e-02, 2.9807e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:17,810][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0042, 0.1015, 0.0254, 0.0510, 0.0464, 0.1922, 0.0835, 0.1051, 0.0945,
        0.0603, 0.0903, 0.1021, 0.0434], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:17,811][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ a] are: tensor([3.1801e-04, 3.0225e-01, 1.0579e-03, 3.9454e-02, 1.2118e-02, 2.7248e-03,
        4.6390e-02, 1.9369e-02, 8.7246e-03, 5.3529e-01, 7.4206e-04, 7.6884e-03,
        2.3875e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:17,813][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.2339, 0.0716, 0.0089, 0.0119, 0.0322, 0.1084, 0.0322, 0.0228, 0.1098,
        0.0262, 0.1551, 0.1720, 0.0150], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:17,813][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ a] are: tensor([1.8037e-01, 2.1654e-03, 5.4765e-06, 2.0642e-04, 2.8635e-04, 2.1269e-02,
        1.7284e-03, 1.1449e-03, 1.0281e-01, 1.7917e-02, 9.5094e-02, 5.7182e-01,
        5.1850e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:17,814][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ a] are: tensor([6.8703e-04, 1.2529e-02, 2.6240e-02, 3.8052e-03, 6.7536e-03, 3.7860e-02,
        6.2370e-03, 2.2725e-03, 8.1732e-01, 1.4524e-02, 3.7169e-02, 3.4299e-02,
        3.0343e-04], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:17,816][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.4049, 0.0199, 0.0055, 0.0072, 0.0421, 0.1286, 0.0366, 0.0369, 0.1256,
        0.0090, 0.0393, 0.1138, 0.0305], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:17,817][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ a] are: tensor([9.8344e-05, 4.7314e-02, 2.7681e-02, 1.2778e-02, 1.2562e-01, 1.5243e-01,
        5.0952e-02, 2.9377e-02, 1.8783e-01, 2.9829e-02, 2.0511e-01, 9.5311e-02,
        3.5662e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:17,818][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.5163, 0.0607, 0.0029, 0.0164, 0.0108, 0.0410, 0.0157, 0.0147, 0.0492,
        0.1803, 0.0347, 0.0429, 0.0143], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:17,820][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0606, 0.0601, 0.0161, 0.0051, 0.0503, 0.2102, 0.0086, 0.0130, 0.2262,
        0.0173, 0.2408, 0.0896, 0.0021], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:17,820][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ a] are: tensor([1.2673e-06, 1.5790e-01, 9.6018e-03, 9.6123e-02, 9.8266e-02, 5.6693e-02,
        9.1433e-02, 1.2732e-01, 6.6009e-02, 9.5823e-02, 8.2143e-02, 3.8003e-02,
        8.0689e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:17,821][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ a] are: tensor([2.0580e-02, 1.2361e-02, 1.9864e-05, 3.4866e-04, 8.9499e-04, 6.3613e-02,
        3.6647e-03, 4.2382e-03, 1.0085e-01, 1.1607e-02, 1.6680e-01, 6.0779e-01,
        7.2335e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:17,822][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ a] are: tensor([1.1419e-04, 8.5246e-02, 3.4940e-03, 3.9200e-02, 1.4122e-02, 6.2456e-02,
        9.5946e-02, 1.0672e-01, 1.0287e-01, 2.0728e-01, 1.9449e-02, 2.1458e-01,
        4.8524e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:17,824][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ basketball] are: tensor([0.0220, 0.0767, 0.0264, 0.0420, 0.0466, 0.1524, 0.0836, 0.1034, 0.0778,
        0.0441, 0.0870, 0.0871, 0.0394, 0.1114], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:17,825][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ basketball] are: tensor([0.0018, 0.2980, 0.0054, 0.1059, 0.0332, 0.0237, 0.0962, 0.0533, 0.0155,
        0.2698, 0.0052, 0.0354, 0.0320, 0.0245], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:17,827][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ basketball] are: tensor([0.4034, 0.0584, 0.0076, 0.0111, 0.0183, 0.0403, 0.0273, 0.0200, 0.0614,
        0.0255, 0.1347, 0.0986, 0.0158, 0.0777], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:17,828][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ basketball] are: tensor([7.7568e-01, 6.1580e-05, 4.5114e-08, 1.5891e-06, 1.2678e-06, 1.4453e-04,
        2.8330e-05, 1.8762e-05, 1.1756e-03, 4.3833e-04, 2.0868e-03, 1.9072e-02,
        2.8733e-04, 2.0100e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:17,829][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ basketball] are: tensor([0.0011, 0.0047, 0.2617, 0.0007, 0.0491, 0.0105, 0.0019, 0.0004, 0.2234,
        0.0024, 0.3281, 0.0041, 0.0003, 0.1115], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:17,831][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ basketball] are: tensor([0.3939, 0.0137, 0.0029, 0.0052, 0.0279, 0.0720, 0.0187, 0.0218, 0.0538,
        0.0060, 0.0244, 0.0789, 0.0190, 0.2618], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:17,832][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ basketball] are: tensor([1.3137e-04, 3.1407e-02, 3.9895e-02, 1.0397e-02, 1.2200e-01, 6.4181e-02,
        3.8584e-02, 1.7911e-02, 1.5347e-01, 2.4516e-02, 2.7213e-01, 1.2040e-01,
        3.4048e-02, 7.0933e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:17,833][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ basketball] are: tensor([7.1415e-01, 9.3748e-02, 2.3312e-04, 6.3949e-03, 6.9947e-04, 1.6181e-02,
        1.4714e-02, 9.9823e-03, 8.4156e-03, 7.9614e-02, 3.6351e-03, 3.2502e-02,
        1.2311e-02, 7.4198e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:17,834][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ basketball] are: tensor([0.3253, 0.0971, 0.0126, 0.0064, 0.0244, 0.0958, 0.0114, 0.0071, 0.0890,
        0.0177, 0.1616, 0.0442, 0.0025, 0.1048], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:17,835][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ basketball] are: tensor([2.1146e-06, 1.5541e-01, 1.5525e-02, 1.0866e-01, 8.3929e-02, 4.8274e-02,
        8.0653e-02, 1.1160e-01, 6.2236e-02, 8.1746e-02, 8.3951e-02, 5.9770e-02,
        8.8240e-02, 2.0007e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:17,836][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ basketball] are: tensor([9.9086e-02, 2.0810e-03, 3.3228e-06, 3.2325e-05, 5.6065e-05, 4.1138e-03,
        3.6231e-04, 6.6531e-04, 9.7967e-03, 2.1998e-03, 4.0684e-02, 1.1259e-01,
        2.2817e-03, 7.2605e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:17,837][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ basketball] are: tensor([5.2765e-05, 9.8892e-02, 6.5652e-03, 4.3215e-02, 2.3849e-02, 6.6874e-02,
        1.0756e-01, 1.1537e-01, 7.1925e-02, 1.5915e-01, 2.3313e-02, 2.2032e-01,
        4.7797e-02, 1.5117e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:17,839][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0066, 0.0817, 0.0262, 0.0418, 0.0419, 0.1630, 0.0714, 0.0877, 0.0902,
        0.0489, 0.0856, 0.0904, 0.0367, 0.0959, 0.0320], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:17,840][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0003, 0.2413, 0.0028, 0.0281, 0.0440, 0.0334, 0.0567, 0.0874, 0.0216,
        0.2561, 0.0030, 0.0438, 0.0997, 0.0253, 0.0566], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:17,842][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.2373, 0.0688, 0.0076, 0.0099, 0.0235, 0.0815, 0.0234, 0.0199, 0.0675,
        0.0260, 0.1050, 0.1529, 0.0130, 0.1437, 0.0199], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:17,843][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ to] are: tensor([1.8092e-01, 2.9510e-04, 7.0015e-07, 2.2124e-05, 2.4692e-05, 2.1676e-03,
        1.8659e-04, 1.6941e-04, 8.6204e-03, 1.8908e-03, 6.8128e-03, 4.7649e-02,
        9.8773e-04, 7.4642e-01, 3.8371e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:17,844][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0064, 0.0284, 0.0473, 0.0332, 0.0183, 0.0412, 0.0156, 0.0052, 0.5933,
        0.0188, 0.0589, 0.0404, 0.0030, 0.0682, 0.0218], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:17,846][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.4902, 0.0107, 0.0032, 0.0038, 0.0226, 0.0757, 0.0170, 0.0163, 0.0775,
        0.0043, 0.0228, 0.0757, 0.0127, 0.1522, 0.0153], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:17,847][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ to] are: tensor([9.6233e-05, 3.5726e-02, 3.3928e-02, 1.0405e-02, 9.2886e-02, 1.0762e-01,
        4.3742e-02, 2.4433e-02, 1.3572e-01, 1.9387e-02, 2.0582e-01, 8.0717e-02,
        3.8380e-02, 1.0796e-01, 6.3183e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:17,848][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.4656, 0.0557, 0.0015, 0.0080, 0.0062, 0.1335, 0.0119, 0.0158, 0.0294,
        0.0978, 0.0206, 0.1255, 0.0183, 0.0051, 0.0050], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:17,850][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.1201, 0.0611, 0.0125, 0.0048, 0.0380, 0.1534, 0.0109, 0.0161, 0.1662,
        0.0198, 0.2026, 0.0735, 0.0034, 0.1144, 0.0031], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:17,851][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ to] are: tensor([1.1019e-06, 1.2445e-01, 1.3052e-02, 8.6529e-02, 7.2907e-02, 5.3556e-02,
        8.1654e-02, 1.2234e-01, 5.0325e-02, 7.3458e-02, 8.7483e-02, 2.9970e-02,
        8.5743e-02, 2.5021e-02, 9.3507e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:17,852][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ to] are: tensor([4.0884e-02, 2.8229e-03, 5.6623e-06, 6.8097e-05, 1.6666e-04, 1.4604e-02,
        6.3095e-04, 1.1315e-03, 1.5525e-02, 2.8263e-03, 3.2079e-02, 1.1302e-01,
        2.0754e-03, 7.7049e-01, 3.6687e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:17,852][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ to] are: tensor([6.5321e-05, 7.7069e-02, 3.9604e-03, 2.6731e-02, 1.4428e-02, 4.6988e-02,
        9.0596e-02, 1.1002e-01, 7.9412e-02, 1.7932e-01, 1.9489e-02, 2.3461e-01,
        4.8526e-02, 2.4412e-02, 4.4371e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:17,898][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:24:17,900][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:17,901][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:17,902][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:17,903][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:17,904][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:17,904][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:17,905][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:17,905][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:17,905][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:17,906][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:17,906][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:17,906][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:17,907][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.9931, 0.0069], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:17,907][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.1450, 0.8550], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:17,907][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.9477, 0.0523], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:17,908][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.9874, 0.0126], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:17,908][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.3412, 0.6588], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:17,908][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.9961, 0.0039], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:17,909][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0032, 0.9968], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:17,909][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.7653, 0.2347], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:17,909][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.7313, 0.2687], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:17,910][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([1.0979e-05, 9.9999e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:17,910][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.4774, 0.5226], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:17,910][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0194, 0.9806], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:17,911][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Erica] are: tensor([0.9626, 0.0283, 0.0091], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:17,911][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Erica] are: tensor([0.0571, 0.4794, 0.4635], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:17,911][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Erica] are: tensor([0.5701, 0.3985, 0.0314], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:17,912][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Erica] are: tensor([0.5887, 0.4107, 0.0006], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:17,912][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Erica] are: tensor([0.4022, 0.4090, 0.1889], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:17,912][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Erica] are: tensor([0.9769, 0.0149, 0.0083], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:17,913][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Erica] are: tensor([0.0012, 0.7282, 0.2707], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:17,913][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Erica] are: tensor([0.1915, 0.7305, 0.0780], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:17,913][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Erica] are: tensor([0.4415, 0.5114, 0.0472], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:17,914][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Erica] are: tensor([4.0577e-05, 8.8219e-01, 1.1777e-01], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:17,914][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Erica] are: tensor([0.0061, 0.9919, 0.0021], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:17,914][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Erica] are: tensor([0.0093, 0.9163, 0.0744], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:17,915][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.9802, 0.0101, 0.0050, 0.0047], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:17,916][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0719, 0.3108, 0.4743, 0.1430], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:17,917][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.8791, 0.0927, 0.0131, 0.0151], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:17,918][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([8.3060e-01, 1.6344e-01, 4.8260e-04, 5.4826e-03], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:17,920][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.5190, 0.2728, 0.1548, 0.0534], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:17,920][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.9900, 0.0048, 0.0012, 0.0040], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:17,921][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0038, 0.4209, 0.4846, 0.0907], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:17,921][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.3581, 0.5550, 0.0319, 0.0550], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:17,921][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.6545, 0.1887, 0.1109, 0.0459], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:17,922][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([3.3171e-05, 5.4019e-01, 8.6552e-02, 3.7322e-01], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:17,922][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0752, 0.9158, 0.0013, 0.0077], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:17,922][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0130, 0.5784, 0.0772, 0.3315], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:17,923][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Joshua] are: tensor([0.9365, 0.0328, 0.0106, 0.0080, 0.0120], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:17,923][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Joshua] are: tensor([0.0336, 0.2580, 0.2320, 0.0743, 0.4021], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:17,924][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Joshua] are: tensor([0.5925, 0.3045, 0.0225, 0.0292, 0.0513], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:17,925][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Joshua] are: tensor([8.0543e-01, 1.7709e-01, 5.1066e-05, 4.6014e-03, 1.2822e-02],
       device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:17,926][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Joshua] are: tensor([0.3200, 0.3361, 0.1490, 0.0410, 0.1538], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:17,927][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Joshua] are: tensor([0.9541, 0.0119, 0.0036, 0.0064, 0.0240], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:17,929][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Joshua] are: tensor([0.0011, 0.2468, 0.2176, 0.0775, 0.4570], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:17,930][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Joshua] are: tensor([0.2622, 0.3315, 0.0145, 0.0446, 0.3472], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:17,931][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Joshua] are: tensor([0.6506, 0.1812, 0.0319, 0.0366, 0.0998], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:17,932][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Joshua] are: tensor([1.7848e-05, 4.0600e-01, 5.8774e-02, 2.1905e-01, 3.1617e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:17,933][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Joshua] are: tensor([8.3922e-02, 8.3808e-01, 3.7407e-04, 5.5010e-03, 7.2127e-02],
       device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:17,935][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Joshua] are: tensor([0.0065, 0.5958, 0.0490, 0.1917, 0.1569], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:17,936][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([0.9208, 0.0192, 0.0032, 0.0047, 0.0038, 0.0483], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:17,937][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([0.0192, 0.1586, 0.1807, 0.0457, 0.2966, 0.2993], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:17,939][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([0.6539, 0.1295, 0.0074, 0.0211, 0.0276, 0.1605], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:17,939][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([9.4524e-01, 1.3028e-02, 4.6268e-06, 1.4491e-04, 8.6108e-04, 4.0722e-02],
       device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:17,941][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([0.1225, 0.4131, 0.1710, 0.0549, 0.1266, 0.1120], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:17,942][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([0.9386, 0.0098, 0.0016, 0.0054, 0.0070, 0.0376], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:17,944][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([0.0006, 0.2080, 0.1121, 0.0545, 0.4223, 0.2025], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:17,945][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([0.1540, 0.1888, 0.0043, 0.0208, 0.1332, 0.4990], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:17,947][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([0.4817, 0.1569, 0.0332, 0.0305, 0.0683, 0.2295], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:17,947][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([7.5138e-06, 4.5238e-01, 1.6572e-02, 3.3746e-01, 1.3525e-01, 5.8327e-02],
       device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:17,948][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([8.6594e-02, 2.6814e-01, 9.4348e-05, 9.7329e-04, 1.0886e-02, 6.3331e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:17,950][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([0.0033, 0.3458, 0.0524, 0.2010, 0.1512, 0.2462], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:17,951][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.8825, 0.0152, 0.0048, 0.0042, 0.0068, 0.0559, 0.0306],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:17,953][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0131, 0.1045, 0.1439, 0.0388, 0.2562, 0.3053, 0.1382],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:17,954][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.6017, 0.1294, 0.0137, 0.0224, 0.0422, 0.1487, 0.0419],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:17,955][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([8.4597e-01, 2.0538e-02, 2.5795e-05, 7.0335e-04, 2.4850e-03, 1.2457e-01,
        5.7074e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:17,956][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.2269, 0.2297, 0.1568, 0.0447, 0.1157, 0.1044, 0.1217],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:17,958][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.9283, 0.0051, 0.0019, 0.0042, 0.0077, 0.0381, 0.0148],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:17,959][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([2.7293e-04, 1.5082e-01, 1.4889e-01, 3.8916e-02, 3.0260e-01, 2.1929e-01,
        1.3921e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:17,960][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.1356, 0.1381, 0.0064, 0.0185, 0.1317, 0.4633, 0.1063],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:17,962][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.4017, 0.1153, 0.0506, 0.0285, 0.1146, 0.2259, 0.0635],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:17,963][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([2.5523e-06, 3.3156e-01, 3.3249e-02, 1.8673e-01, 1.7214e-01, 1.1126e-01,
        1.6506e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:17,963][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([8.9765e-02, 1.9631e-01, 1.9119e-04, 1.7842e-03, 1.3249e-02, 6.7746e-01,
        2.1243e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:17,965][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0045, 0.2932, 0.0347, 0.1488, 0.1162, 0.1591, 0.2435],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:17,966][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.7766, 0.0263, 0.0061, 0.0060, 0.0088, 0.0945, 0.0531, 0.0287],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:17,968][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0097, 0.0722, 0.1215, 0.0273, 0.2710, 0.2913, 0.0954, 0.1115],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:17,968][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.4175, 0.1482, 0.0201, 0.0252, 0.0750, 0.1912, 0.0658, 0.0570],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:17,969][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([8.2179e-01, 1.7766e-02, 2.5346e-05, 7.7938e-04, 1.9840e-03, 1.4467e-01,
        8.1696e-03, 4.8133e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:17,969][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.1713, 0.2230, 0.1594, 0.0414, 0.1064, 0.1137, 0.1308, 0.0540],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:17,969][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.8649, 0.0075, 0.0024, 0.0063, 0.0123, 0.0561, 0.0260, 0.0245],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:17,970][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([1.9873e-04, 1.5467e-01, 1.8178e-01, 2.3860e-02, 3.3843e-01, 1.6447e-01,
        9.5030e-02, 4.1561e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:17,970][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.1085, 0.1349, 0.0047, 0.0179, 0.1056, 0.4808, 0.0948, 0.0527],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:17,971][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.3429, 0.1238, 0.0468, 0.0262, 0.1282, 0.2192, 0.0572, 0.0556],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:17,971][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([1.6992e-06, 2.5322e-01, 2.8317e-02, 1.2696e-01, 1.8446e-01, 8.3684e-02,
        1.3418e-01, 1.8917e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:17,972][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([9.5023e-02, 1.3632e-01, 1.2688e-04, 1.7872e-03, 9.0191e-03, 6.9716e-01,
        2.5679e-02, 3.4889e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:17,974][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0037, 0.2632, 0.0273, 0.1107, 0.0954, 0.1037, 0.1644, 0.2316],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:17,975][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ office] are: tensor([0.8304, 0.0106, 0.0028, 0.0030, 0.0053, 0.0507, 0.0252, 0.0164, 0.0555],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:17,976][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ office] are: tensor([0.0137, 0.0586, 0.0614, 0.0162, 0.1052, 0.2202, 0.0697, 0.0813, 0.3738],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:17,978][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ office] are: tensor([0.6003, 0.0767, 0.0084, 0.0128, 0.0243, 0.1145, 0.0336, 0.0258, 0.1035],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:17,979][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ office] are: tensor([9.5572e-01, 1.4993e-03, 5.3424e-07, 2.9011e-05, 3.8309e-05, 4.6753e-03,
        5.4813e-04, 4.1636e-04, 3.7075e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:17,980][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ office] are: tensor([0.1341, 0.2265, 0.0916, 0.0310, 0.1090, 0.0839, 0.1178, 0.0512, 0.1548],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:17,981][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ office] are: tensor([0.9165, 0.0049, 0.0016, 0.0029, 0.0062, 0.0249, 0.0107, 0.0100, 0.0223],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:17,982][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ office] are: tensor([2.1367e-04, 9.3587e-02, 6.7514e-02, 2.2875e-02, 2.6452e-01, 1.4174e-01,
        9.5585e-02, 5.5029e-02, 2.5894e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:17,984][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ office] are: tensor([0.1551, 0.0638, 0.0018, 0.0087, 0.0450, 0.3291, 0.0554, 0.0336, 0.3075],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:17,985][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ office] are: tensor([0.6126, 0.0662, 0.0100, 0.0089, 0.0291, 0.0747, 0.0240, 0.0252, 0.1494],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:17,986][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ office] are: tensor([5.3775e-06, 2.2724e-01, 1.8520e-02, 1.2325e-01, 1.5703e-01, 9.7165e-02,
        1.1295e-01, 1.6319e-01, 1.0065e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:17,987][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ office] are: tensor([2.6384e-01, 6.7439e-02, 3.3336e-05, 4.8326e-04, 2.6220e-03, 2.1222e-01,
        9.7557e-03, 2.1609e-02, 4.2200e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:17,988][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ office] are: tensor([0.0046, 0.1786, 0.0163, 0.0955, 0.0843, 0.0954, 0.1587, 0.2254, 0.1412],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:17,990][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.8615, 0.0063, 0.0034, 0.0031, 0.0051, 0.0334, 0.0228, 0.0133, 0.0364,
        0.0146], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:17,991][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.0089, 0.0389, 0.1020, 0.0142, 0.1988, 0.1473, 0.0604, 0.0512, 0.3542,
        0.0240], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:17,993][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.6482, 0.0571, 0.0106, 0.0101, 0.0265, 0.0847, 0.0317, 0.0235, 0.0775,
        0.0300], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:17,994][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([9.2303e-01, 1.8407e-03, 3.5512e-06, 1.2392e-04, 1.7620e-04, 1.0112e-02,
        1.0090e-03, 7.6480e-04, 5.4724e-02, 8.2191e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:17,995][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.2073, 0.1666, 0.1230, 0.0313, 0.0827, 0.0538, 0.0968, 0.0416, 0.1433,
        0.0536], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:17,996][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.9367, 0.0025, 0.0010, 0.0025, 0.0047, 0.0184, 0.0100, 0.0068, 0.0133,
        0.0041], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:17,997][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([2.5450e-04, 6.1438e-02, 1.7910e-01, 1.6009e-02, 2.7784e-01, 9.4234e-02,
        6.7900e-02, 3.0301e-02, 2.4180e-01, 3.1123e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:17,999][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.1524, 0.0626, 0.0045, 0.0101, 0.0635, 0.2106, 0.0532, 0.0290, 0.3344,
        0.0797], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:18,000][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.4327, 0.0662, 0.0364, 0.0146, 0.0605, 0.1006, 0.0354, 0.0366, 0.1498,
        0.0671], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:18,001][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([3.4478e-06, 1.8009e-01, 3.8125e-02, 1.3004e-01, 1.7156e-01, 4.2887e-02,
        1.1595e-01, 1.4871e-01, 7.7369e-02, 9.5263e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:18,002][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([2.9099e-01, 5.9379e-02, 1.0796e-04, 1.0531e-03, 6.1116e-03, 3.0483e-01,
        1.0479e-02, 1.8284e-02, 2.8776e-01, 2.1006e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:18,004][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.0037, 0.1311, 0.0229, 0.0768, 0.1075, 0.0974, 0.1252, 0.1761, 0.1416,
        0.1177], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:18,005][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Erica] are: tensor([0.7348, 0.0118, 0.0046, 0.0053, 0.0044, 0.0683, 0.0277, 0.0147, 0.0573,
        0.0216, 0.0493], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:18,006][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Erica] are: tensor([0.0045, 0.0557, 0.0438, 0.0184, 0.0745, 0.1619, 0.0764, 0.0719, 0.2932,
        0.0358, 0.1640], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:18,008][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Erica] are: tensor([0.2841, 0.1348, 0.0064, 0.0266, 0.0229, 0.1666, 0.0499, 0.0433, 0.1009,
        0.0624, 0.1018], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:18,009][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Erica] are: tensor([9.1176e-01, 5.8456e-04, 5.6951e-07, 2.2532e-05, 3.0507e-05, 2.6870e-03,
        3.6637e-04, 4.2016e-04, 3.3104e-02, 1.0661e-02, 4.0367e-02],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:18,010][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Erica] are: tensor([0.1173, 0.1618, 0.0910, 0.0188, 0.0823, 0.0467, 0.0707, 0.0331, 0.1768,
        0.0556, 0.1459], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:18,012][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Erica] are: tensor([0.9050, 0.0038, 0.0021, 0.0028, 0.0073, 0.0213, 0.0087, 0.0084, 0.0177,
        0.0050, 0.0179], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:18,013][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Erica] are: tensor([9.8822e-05, 9.0241e-02, 4.4246e-02, 3.0817e-02, 1.1561e-01, 1.1768e-01,
        8.8419e-02, 5.0145e-02, 2.1103e-01, 5.1253e-02, 2.0046e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:18,014][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Erica] are: tensor([0.1633, 0.0317, 0.0016, 0.0057, 0.0250, 0.1129, 0.0367, 0.0202, 0.2250,
        0.0870, 0.2910], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:18,015][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Erica] are: tensor([0.3013, 0.0590, 0.0155, 0.0161, 0.0274, 0.1009, 0.0427, 0.0529, 0.1642,
        0.0672, 0.1527], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:18,016][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Erica] are: tensor([1.7216e-06, 1.4471e-01, 1.3694e-02, 1.0592e-01, 1.2524e-01, 8.9210e-02,
        1.1764e-01, 1.3457e-01, 7.7530e-02, 9.4521e-02, 9.6952e-02],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:18,016][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Erica] are: tensor([7.1395e-02, 1.5011e-02, 2.0358e-05, 1.9607e-04, 7.0890e-04, 6.3248e-02,
        3.8764e-03, 9.1807e-03, 1.8593e-01, 3.5607e-02, 6.1482e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:18,016][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Erica] are: tensor([0.0028, 0.1689, 0.0159, 0.0785, 0.0555, 0.0990, 0.1222, 0.1323, 0.1259,
        0.1499, 0.0490], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:18,017][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.7168, 0.0090, 0.0039, 0.0030, 0.0040, 0.0286, 0.0182, 0.0100, 0.0368,
        0.0105, 0.0486, 0.1106], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:18,017][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0039, 0.0419, 0.0546, 0.0205, 0.0752, 0.1126, 0.0562, 0.0498, 0.2026,
        0.0282, 0.1838, 0.1707], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:18,017][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.3792, 0.0655, 0.0088, 0.0087, 0.0250, 0.0668, 0.0247, 0.0188, 0.0862,
        0.0232, 0.1623, 0.1308], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:18,018][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([9.4361e-01, 3.2963e-04, 4.9303e-07, 1.1042e-05, 1.3351e-05, 8.6939e-04,
        1.4521e-04, 9.4614e-05, 7.9161e-03, 1.7126e-03, 1.4058e-02, 3.1244e-02],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:18,018][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.1206, 0.1041, 0.1089, 0.0267, 0.0994, 0.0562, 0.0491, 0.0314, 0.1500,
        0.0415, 0.1600, 0.0521], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:18,018][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.8166, 0.0073, 0.0021, 0.0042, 0.0107, 0.0285, 0.0139, 0.0112, 0.0248,
        0.0064, 0.0215, 0.0531], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:18,019][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([1.5641e-04, 6.2504e-02, 5.3919e-02, 1.9556e-02, 1.5529e-01, 9.4312e-02,
        5.8415e-02, 3.2265e-02, 1.7248e-01, 3.6484e-02, 2.2880e-01, 8.5816e-02],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:18,020][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.1052, 0.0314, 0.0014, 0.0058, 0.0246, 0.1085, 0.0344, 0.0188, 0.1580,
        0.0461, 0.2475, 0.2184], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:18,022][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.2158, 0.0734, 0.0244, 0.0145, 0.0417, 0.0937, 0.0277, 0.0337, 0.1263,
        0.0691, 0.1452, 0.1346], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:18,022][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([2.2226e-06, 1.5926e-01, 1.1859e-02, 1.1360e-01, 9.0868e-02, 3.5338e-02,
        9.5044e-02, 1.3143e-01, 8.1128e-02, 1.1948e-01, 1.2992e-01, 3.2074e-02],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:18,023][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([1.3354e-01, 1.0224e-02, 8.0282e-06, 1.0940e-04, 4.4356e-04, 2.5517e-02,
        1.8027e-03, 2.4998e-03, 8.3849e-02, 7.9790e-03, 1.8238e-01, 5.5164e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:18,025][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.0016, 0.1060, 0.0104, 0.0729, 0.0344, 0.0654, 0.0705, 0.1080, 0.0940,
        0.1321, 0.0354, 0.2693], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:18,026][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.5255, 0.0124, 0.0044, 0.0037, 0.0082, 0.0629, 0.0369, 0.0199, 0.0839,
        0.0183, 0.0577, 0.1444, 0.0218], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:18,027][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0036, 0.0321, 0.0236, 0.0106, 0.0879, 0.1214, 0.0448, 0.0430, 0.2400,
        0.0214, 0.1459, 0.1666, 0.0589], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:18,029][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.2269, 0.0725, 0.0082, 0.0116, 0.0314, 0.1120, 0.0320, 0.0229, 0.1117,
        0.0252, 0.1547, 0.1762, 0.0148], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:18,030][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([3.8136e-01, 2.0658e-03, 5.6236e-06, 2.1504e-04, 2.1664e-04, 1.5998e-02,
        1.7013e-03, 9.9312e-04, 8.3264e-02, 1.7458e-02, 8.1139e-02, 4.1154e-01,
        4.0453e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:18,031][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.1298, 0.1127, 0.0798, 0.0266, 0.0932, 0.0484, 0.0771, 0.0404, 0.1588,
        0.0424, 0.1114, 0.0419, 0.0375], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:18,033][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.7880, 0.0061, 0.0023, 0.0045, 0.0112, 0.0373, 0.0157, 0.0165, 0.0293,
        0.0056, 0.0194, 0.0465, 0.0176], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:18,034][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([1.3793e-04, 6.0295e-02, 4.2632e-02, 1.6632e-02, 1.4533e-01, 1.3386e-01,
        5.9621e-02, 3.2237e-02, 1.6817e-01, 3.4112e-02, 1.9025e-01, 8.5705e-02,
        3.1024e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:18,035][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0215, 0.0355, 0.0018, 0.0064, 0.0402, 0.1667, 0.0307, 0.0173, 0.2087,
        0.0428, 0.2011, 0.2110, 0.0165], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:18,037][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.1774, 0.0663, 0.0213, 0.0123, 0.0497, 0.1168, 0.0234, 0.0248, 0.1546,
        0.0516, 0.1428, 0.1465, 0.0127], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:18,038][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([1.2673e-06, 1.5790e-01, 9.6018e-03, 9.6123e-02, 9.8266e-02, 5.6693e-02,
        9.1433e-02, 1.2732e-01, 6.6009e-02, 9.5823e-02, 8.2143e-02, 3.8003e-02,
        8.0689e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:18,038][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([2.0580e-02, 1.2361e-02, 1.9864e-05, 3.4866e-04, 8.9499e-04, 6.3613e-02,
        3.6647e-03, 4.2382e-03, 1.0085e-01, 1.1607e-02, 1.6680e-01, 6.0779e-01,
        7.2335e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:18,040][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0023, 0.1004, 0.0088, 0.0566, 0.0309, 0.0676, 0.0861, 0.1070, 0.1030,
        0.1352, 0.0339, 0.2019, 0.0664], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:18,041][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ basketball] are: tensor([0.7644, 0.0065, 0.0019, 0.0021, 0.0023, 0.0189, 0.0171, 0.0093, 0.0156,
        0.0083, 0.0232, 0.0607, 0.0064, 0.0632], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:18,043][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ basketball] are: tensor([0.0055, 0.0325, 0.0397, 0.0118, 0.0937, 0.0761, 0.0430, 0.0391, 0.1578,
        0.0174, 0.1302, 0.1237, 0.0492, 0.1805], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:18,044][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ basketball] are: tensor([0.3976, 0.0604, 0.0069, 0.0110, 0.0176, 0.0418, 0.0276, 0.0205, 0.0633,
        0.0244, 0.1338, 0.1016, 0.0157, 0.0780], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:18,045][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ basketball] are: tensor([9.0019e-01, 4.3498e-05, 4.2020e-08, 1.5999e-06, 9.3131e-07, 1.0863e-04,
        2.5905e-05, 1.6970e-05, 9.3855e-04, 4.0345e-04, 1.5576e-03, 1.1832e-02,
        1.9358e-04, 8.4690e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:18,047][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ basketball] are: tensor([0.1046, 0.0970, 0.0959, 0.0166, 0.1000, 0.0346, 0.0478, 0.0257, 0.0777,
        0.0231, 0.1400, 0.0428, 0.0227, 0.1715], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:18,048][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ basketball] are: tensor([0.8345, 0.0040, 0.0011, 0.0028, 0.0060, 0.0202, 0.0085, 0.0086, 0.0136,
        0.0054, 0.0105, 0.0306, 0.0106, 0.0436], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:18,049][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ basketball] are: tensor([1.9446e-04, 3.9593e-02, 5.8851e-02, 1.3437e-02, 1.4065e-01, 6.0297e-02,
        4.5785e-02, 2.0254e-02, 1.4022e-01, 2.8213e-02, 2.5025e-01, 1.0600e-01,
        2.9724e-02, 6.6530e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:18,050][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ basketball] are: tensor([0.1310, 0.0157, 0.0008, 0.0023, 0.0115, 0.0293, 0.0166, 0.0095, 0.0888,
        0.0312, 0.1552, 0.0978, 0.0083, 0.4019], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:18,052][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ basketball] are: tensor([0.3818, 0.0615, 0.0182, 0.0124, 0.0291, 0.0534, 0.0237, 0.0146, 0.0712,
        0.0505, 0.1063, 0.0667, 0.0106, 0.0998], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:18,053][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ basketball] are: tensor([2.1146e-06, 1.5541e-01, 1.5525e-02, 1.0866e-01, 8.3929e-02, 4.8274e-02,
        8.0653e-02, 1.1160e-01, 6.2236e-02, 8.1746e-02, 8.3951e-02, 5.9770e-02,
        8.8240e-02, 2.0007e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:18,054][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ basketball] are: tensor([9.9086e-02, 2.0810e-03, 3.3228e-06, 3.2325e-05, 5.6065e-05, 4.1138e-03,
        3.6231e-04, 6.6531e-04, 9.7967e-03, 2.1998e-03, 4.0684e-02, 1.1259e-01,
        2.2817e-03, 7.2605e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:18,055][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ basketball] are: tensor([0.0014, 0.0957, 0.0143, 0.0603, 0.0444, 0.0700, 0.0924, 0.1104, 0.0736,
        0.1062, 0.0369, 0.2010, 0.0625, 0.0308], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:18,057][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.6153, 0.0068, 0.0031, 0.0021, 0.0048, 0.0303, 0.0171, 0.0091, 0.0435,
        0.0095, 0.0287, 0.0856, 0.0102, 0.1146, 0.0193], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:18,058][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0041, 0.0244, 0.0322, 0.0104, 0.0576, 0.0742, 0.0403, 0.0353, 0.2014,
        0.0164, 0.1253, 0.0937, 0.0528, 0.1972, 0.0347], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:18,059][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.2318, 0.0702, 0.0070, 0.0096, 0.0226, 0.0844, 0.0233, 0.0201, 0.0685,
        0.0248, 0.1031, 0.1572, 0.0128, 0.1451, 0.0194], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:18,060][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([4.8546e-01, 2.9311e-04, 8.0725e-07, 2.3833e-05, 2.1732e-05, 1.9118e-03,
        2.0745e-04, 1.6584e-04, 9.1437e-03, 2.2565e-03, 7.2128e-03, 4.3515e-02,
        8.8671e-04, 4.4558e-01, 3.3249e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:18,062][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.1365, 0.0893, 0.0590, 0.0200, 0.0581, 0.0433, 0.0578, 0.0285, 0.0909,
        0.0318, 0.0780, 0.0481, 0.0267, 0.1738, 0.0583], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:18,063][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.8321, 0.0035, 0.0014, 0.0028, 0.0059, 0.0243, 0.0088, 0.0085, 0.0179,
        0.0033, 0.0112, 0.0371, 0.0087, 0.0254, 0.0092], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:18,063][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([1.4249e-04, 4.6091e-02, 5.2907e-02, 1.3782e-02, 1.1185e-01, 9.6347e-02,
        5.1834e-02, 2.7268e-02, 1.2502e-01, 2.2928e-02, 1.9303e-01, 7.2491e-02,
        3.2478e-02, 9.6768e-02, 5.7055e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:18,064][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0467, 0.0230, 0.0014, 0.0037, 0.0207, 0.0720, 0.0195, 0.0114, 0.1003,
        0.0297, 0.1184, 0.1084, 0.0099, 0.4184, 0.0166], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:18,064][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.2671, 0.0468, 0.0156, 0.0083, 0.0320, 0.0722, 0.0191, 0.0192, 0.0982,
        0.0385, 0.1059, 0.0952, 0.0114, 0.1522, 0.0184], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:18,064][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([1.1019e-06, 1.2445e-01, 1.3052e-02, 8.6529e-02, 7.2907e-02, 5.3556e-02,
        8.1654e-02, 1.2234e-01, 5.0325e-02, 7.3458e-02, 8.7483e-02, 2.9970e-02,
        8.5743e-02, 2.5021e-02, 9.3507e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:18,065][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([4.0884e-02, 2.8229e-03, 5.6623e-06, 6.8097e-05, 1.6666e-04, 1.4604e-02,
        6.3095e-04, 1.1315e-03, 1.5525e-02, 2.8263e-03, 3.2079e-02, 1.1302e-01,
        2.0754e-03, 7.7049e-01, 3.6687e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:18,065][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0016, 0.0859, 0.0096, 0.0412, 0.0311, 0.0534, 0.0770, 0.1028, 0.0784,
        0.1126, 0.0329, 0.2100, 0.0642, 0.0477, 0.0517], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:18,066][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:24:18,067][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[9910],
        [ 258],
        [   8],
        [   3],
        [3717],
        [  17],
        [   7],
        [   5],
        [   2],
        [   1],
        [   2],
        [   1],
        [   2],
        [   2],
        [   1]], device='cuda:0')
[2024-07-24 10:24:18,069][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[10344],
        [ 1075],
        [   62],
        [   40],
        [ 2083],
        [   24],
        [    4],
        [    2],
        [    1],
        [    1],
        [    2],
        [    1],
        [    1],
        [    1],
        [    1]], device='cuda:0')
[2024-07-24 10:24:18,070][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[8234],
        [2197],
        [2791],
        [3343],
        [4654],
        [3268],
        [2994],
        [2684],
        [2648],
        [2655],
        [3097],
        [3575],
        [3401],
        [3400],
        [3361]], device='cuda:0')
[2024-07-24 10:24:18,071][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[24490],
        [10453],
        [10555],
        [10878],
        [10865],
        [12320],
        [14748],
        [13324],
        [12554],
        [17649],
        [17753],
        [17069],
        [19207],
        [16991],
        [15964]], device='cuda:0')
[2024-07-24 10:24:18,073][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 5769],
        [ 7168],
        [19697],
        [ 8796],
        [23473],
        [20693],
        [22493],
        [26535],
        [13348],
        [15013],
        [19764],
        [20794],
        [23595],
        [22667],
        [27779]], device='cuda:0')
[2024-07-24 10:24:18,074][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[36963],
        [38350],
        [42070],
        [41833],
        [41948],
        [37530],
        [36092],
        [36148],
        [38155],
        [38225],
        [38428],
        [38057],
        [37432],
        [41859],
        [42873]], device='cuda:0')
[2024-07-24 10:24:18,075][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[1623],
        [2257],
        [ 349],
        [ 295],
        [ 294],
        [1115],
        [ 558],
        [3374],
        [ 517],
        [ 507],
        [ 297],
        [ 374],
        [ 672],
        [ 270],
        [ 361]], device='cuda:0')
[2024-07-24 10:24:18,076][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[ 6929],
        [ 7100],
        [ 7902],
        [ 7040],
        [ 3576],
        [10531],
        [ 8553],
        [11820],
        [12277],
        [ 8587],
        [ 7289],
        [13997],
        [14961],
        [11531],
        [12107]], device='cuda:0')
[2024-07-24 10:24:18,078][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[18068],
        [22143],
        [26382],
        [30394],
        [49499],
        [47476],
        [42984],
        [45989],
        [41814],
        [45037],
        [36769],
        [42207],
        [39991],
        [40963],
        [35069]], device='cuda:0')
[2024-07-24 10:24:18,079][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[ 1078],
        [ 1100],
        [23489],
        [ 1632],
        [24733],
        [16947],
        [19383],
        [ 7533],
        [22782],
        [12249],
        [31491],
        [28120],
        [27488],
        [15933],
        [23828]], device='cuda:0')
[2024-07-24 10:24:18,081][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[ 3196],
        [ 4587],
        [ 5730],
        [ 4926],
        [ 9646],
        [ 5836],
        [15309],
        [18825],
        [ 4321],
        [ 8068],
        [ 4840],
        [ 7767],
        [ 8990],
        [ 6806],
        [ 8259]], device='cuda:0')
[2024-07-24 10:24:18,082][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[30565],
        [ 9179],
        [10736],
        [ 3064],
        [50189],
        [33576],
        [44885],
        [46669],
        [43285],
        [45379],
        [37195],
        [28575],
        [30906],
        [27580],
        [22202]], device='cuda:0')
[2024-07-24 10:24:18,083][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[ 3050],
        [29204],
        [36932],
        [36219],
        [36535],
        [24707],
        [22873],
        [21532],
        [24965],
        [22158],
        [13607],
        [19669],
        [21807],
        [16237],
        [17065]], device='cuda:0')
[2024-07-24 10:24:18,085][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[25199],
        [21575],
        [22505],
        [20385],
        [29392],
        [21572],
        [21218],
        [22984],
        [21458],
        [23187],
        [21665],
        [20977],
        [21491],
        [22580],
        [22369]], device='cuda:0')
[2024-07-24 10:24:18,086][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[28401],
        [15906],
        [19535],
        [14282],
        [18111],
        [19442],
        [15472],
        [14673],
        [19714],
        [12590],
        [16989],
        [18698],
        [16531],
        [14582],
        [11649]], device='cuda:0')
[2024-07-24 10:24:18,087][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[ 7469],
        [ 6953],
        [ 5915],
        [ 6042],
        [ 5018],
        [ 4346],
        [ 4294],
        [ 9360],
        [ 6734],
        [ 4408],
        [11950],
        [ 8587],
        [16222],
        [ 7071],
        [13957]], device='cuda:0')
[2024-07-24 10:24:18,089][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[32236],
        [47001],
        [41753],
        [39036],
        [20366],
        [11020],
        [ 9046],
        [ 5972],
        [ 4749],
        [ 3884],
        [11194],
        [17731],
        [13905],
        [13092],
        [13691]], device='cuda:0')
[2024-07-24 10:24:18,090][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[23061],
        [23392],
        [26887],
        [24911],
        [28695],
        [22914],
        [24661],
        [25726],
        [18890],
        [18877],
        [23957],
        [23901],
        [22907],
        [21270],
        [19004]], device='cuda:0')
[2024-07-24 10:24:18,092][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[9381],
        [9000],
        [2472],
        [5974],
        [5440],
        [8487],
        [7561],
        [7461],
        [9148],
        [8866],
        [8689],
        [7750],
        [1737],
        [7561],
        [5650]], device='cuda:0')
[2024-07-24 10:24:18,093][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[27189],
        [25154],
        [14781],
        [12976],
        [11372],
        [11357],
        [ 9562],
        [ 9446],
        [ 9288],
        [ 8633],
        [ 7427],
        [ 6763],
        [ 7488],
        [ 6595],
        [ 7546]], device='cuda:0')
[2024-07-24 10:24:18,094][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[22138],
        [21994],
        [21953],
        [22208],
        [19920],
        [20301],
        [20473],
        [16679],
        [19622],
        [20932],
        [19405],
        [11740],
        [11485],
        [13758],
        [13354]], device='cuda:0')
[2024-07-24 10:24:18,096][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[29827],
        [47137],
        [48263],
        [47515],
        [48160],
        [49388],
        [49742],
        [49596],
        [49497],
        [49304],
        [49174],
        [48376],
        [49017],
        [47985],
        [49110]], device='cuda:0')
[2024-07-24 10:24:18,097][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[34648],
        [31082],
        [30772],
        [30579],
        [17957],
        [36081],
        [36396],
        [36821],
        [42610],
        [42112],
        [41401],
        [33384],
        [35341],
        [41980],
        [42088]], device='cuda:0')
[2024-07-24 10:24:18,098][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[19303],
        [26748],
        [29589],
        [23982],
        [31302],
        [15791],
        [16332],
        [15549],
        [17366],
        [17434],
        [15947],
        [11332],
        [10722],
        [10657],
        [ 8425]], device='cuda:0')
[2024-07-24 10:24:18,100][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[31766],
        [26368],
        [20894],
        [25927],
        [48353],
        [42065],
        [44930],
        [43754],
        [41986],
        [40799],
        [34780],
        [27726],
        [30603],
        [28587],
        [27230]], device='cuda:0')
[2024-07-24 10:24:18,101][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[ 3020],
        [ 2154],
        [ 3283],
        [ 3179],
        [ 2781],
        [ 6634],
        [ 7470],
        [ 8008],
        [18745],
        [15457],
        [19372],
        [17881],
        [18210],
        [19933],
        [20105]], device='cuda:0')
[2024-07-24 10:24:18,103][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[28391],
        [23451],
        [24744],
        [17152],
        [16250],
        [14703],
        [13164],
        [10714],
        [11207],
        [11326],
        [12580],
        [14085],
        [12885],
        [12318],
        [11923]], device='cuda:0')
[2024-07-24 10:24:18,104][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[28991],
        [20617],
        [30793],
        [32589],
        [34213],
        [38515],
        [37487],
        [37102],
        [36766],
        [39713],
        [35312],
        [40821],
        [39017],
        [40431],
        [37363]], device='cuda:0')
[2024-07-24 10:24:18,105][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[ 9939],
        [16175],
        [16254],
        [25870],
        [23306],
        [18136],
        [23595],
        [26654],
        [17900],
        [24960],
        [19124],
        [20996],
        [24819],
        [25301],
        [29360]], device='cuda:0')
[2024-07-24 10:24:18,107][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[12039],
        [12039],
        [12039],
        [12039],
        [12039],
        [12039],
        [12039],
        [12039],
        [12039],
        [12039],
        [12039],
        [12039],
        [12039],
        [12039],
        [12039]], device='cuda:0')
[2024-07-24 10:24:18,155][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:24:18,155][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:18,155][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:18,156][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:18,156][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:18,156][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:18,157][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:18,157][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:18,157][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:18,158][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:18,158][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:18,158][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:18,159][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:18,160][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.1121, 0.8879], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:18,161][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0038, 0.9962], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:18,163][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.5953, 0.4047], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:18,164][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.8816, 0.1184], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:18,166][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.9927, 0.0073], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:18,167][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.9847, 0.0153], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:18,169][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.2545, 0.7455], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:18,170][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.9980, 0.0020], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:18,171][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.8904, 0.1096], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:18,173][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.8633, 0.1367], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:18,174][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0055, 0.9945], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:18,175][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.8768, 0.1232], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:18,177][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Erica] are: tensor([0.0396, 0.9326, 0.0278], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:18,178][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Erica] are: tensor([4.6098e-04, 6.5245e-01, 3.4709e-01], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:18,179][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Erica] are: tensor([0.2079, 0.4060, 0.3861], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:18,180][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Erica] are: tensor([0.6099, 0.3500, 0.0401], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:18,180][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Erica] are: tensor([0.9339, 0.0623, 0.0039], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:18,181][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Erica] are: tensor([5.6412e-02, 9.4344e-01, 1.4387e-04], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:18,181][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Erica] are: tensor([0.0630, 0.8859, 0.0511], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:18,181][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Erica] are: tensor([0.9657, 0.0097, 0.0246], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:18,182][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Erica] are: tensor([0.8990, 0.0619, 0.0391], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:18,182][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Erica] are: tensor([3.5527e-03, 9.9638e-01, 6.9035e-05], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:18,182][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Erica] are: tensor([1.2535e-03, 9.9869e-01, 5.9460e-05], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:18,183][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Erica] are: tensor([0.2864, 0.4541, 0.2595], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:18,184][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0782, 0.7115, 0.0747, 0.1356], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:18,185][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0023, 0.3368, 0.4714, 0.1896], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:18,186][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.3865, 0.2300, 0.1705, 0.2130], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:18,188][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.9052, 0.0483, 0.0246, 0.0219], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:18,189][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.9639, 0.0257, 0.0014, 0.0090], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:18,190][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ and] are: tensor([8.8062e-01, 1.1877e-01, 1.7668e-05, 5.9191e-04], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:18,191][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.1321, 0.5786, 0.1797, 0.1096], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:18,192][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.9776, 0.0034, 0.0154, 0.0036], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:18,194][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.8718, 0.0638, 0.0532, 0.0112], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:18,195][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ and] are: tensor([2.4144e-01, 7.5679e-01, 5.5942e-05, 1.7157e-03], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:18,196][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ and] are: tensor([9.6269e-03, 6.9212e-01, 5.0510e-04, 2.9775e-01], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:18,197][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.8890, 0.0639, 0.0321, 0.0149], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:18,198][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Joshua] are: tensor([0.0509, 0.7668, 0.0292, 0.0814, 0.0717], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:18,199][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Joshua] are: tensor([4.0454e-04, 2.6769e-01, 1.5249e-01, 1.0237e-01, 4.7706e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:18,200][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Joshua] are: tensor([0.1394, 0.2432, 0.1772, 0.2335, 0.2068], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:18,202][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Joshua] are: tensor([0.6880, 0.1206, 0.0321, 0.0449, 0.1144], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:18,203][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Joshua] are: tensor([0.9448, 0.0386, 0.0015, 0.0115, 0.0036], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:18,204][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Joshua] are: tensor([7.8256e-01, 2.0202e-01, 5.7955e-06, 4.8416e-04, 1.4928e-02],
       device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:18,205][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Joshua] are: tensor([0.0755, 0.4699, 0.0850, 0.1146, 0.2550], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:18,207][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Joshua] are: tensor([0.9557, 0.0057, 0.0184, 0.0051, 0.0151], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:18,208][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Joshua] are: tensor([0.6720, 0.0590, 0.0418, 0.0055, 0.2217], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:18,209][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Joshua] are: tensor([1.2931e-01, 8.3156e-01, 1.5386e-05, 1.1161e-03, 3.8004e-02],
       device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:18,210][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Joshua] are: tensor([1.2791e-04, 6.8072e-01, 9.0852e-06, 3.1913e-01, 9.6178e-06],
       device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:18,211][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Joshua] are: tensor([0.2141, 0.2296, 0.2091, 0.0625, 0.2847], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:18,213][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ went] are: tensor([0.0222, 0.4373, 0.0188, 0.0612, 0.0392, 0.4213], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:18,214][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ went] are: tensor([9.3860e-05, 9.8265e-02, 2.8247e-02, 1.0759e-01, 6.6249e-01, 1.0331e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:18,215][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ went] are: tensor([0.0696, 0.1783, 0.1120, 0.1980, 0.1940, 0.2480], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:18,216][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ went] are: tensor([0.4077, 0.1465, 0.0448, 0.0577, 0.2146, 0.1288], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:18,217][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ went] are: tensor([9.4236e-01, 4.0050e-02, 4.4900e-04, 9.5213e-03, 9.5965e-04, 6.6580e-03],
       device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:18,218][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ went] are: tensor([8.0228e-01, 5.0174e-02, 7.3176e-07, 1.0207e-04, 7.2697e-04, 1.4672e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:18,220][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ went] are: tensor([0.0341, 0.4962, 0.0576, 0.0649, 0.1259, 0.2214], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:18,221][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ went] are: tensor([0.9726, 0.0049, 0.0098, 0.0049, 0.0057, 0.0021], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:18,223][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.4895, 0.1385, 0.0450, 0.0205, 0.2189, 0.0877], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:18,223][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ went] are: tensor([3.2209e-01, 1.0931e-01, 6.1074e-07, 5.8748e-05, 9.3641e-04, 5.6761e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:18,224][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ went] are: tensor([1.9949e-04, 7.5674e-01, 4.4564e-06, 2.4272e-01, 5.1682e-06, 3.3542e-04],
       device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:18,226][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ went] are: tensor([0.5144, 0.1276, 0.0624, 0.0205, 0.1156, 0.1596], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:18,227][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0142, 0.3671, 0.0222, 0.0465, 0.0362, 0.3983, 0.1154],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:18,228][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ to] are: tensor([3.0057e-05, 7.8972e-02, 6.5899e-02, 4.1051e-02, 4.1313e-01, 1.4763e-01,
        2.5328e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:18,228][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0556, 0.1270, 0.1089, 0.1695, 0.1520, 0.2512, 0.1358],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:18,228][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.6305, 0.0924, 0.0202, 0.0323, 0.0827, 0.0833, 0.0587],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:18,229][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ to] are: tensor([9.4650e-01, 3.0259e-02, 6.4889e-04, 8.9997e-03, 1.0445e-03, 5.7543e-03,
        6.7935e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:18,229][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ to] are: tensor([9.3226e-01, 1.0313e-02, 8.5647e-07, 5.5164e-05, 1.0862e-03, 5.5123e-02,
        1.1594e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:18,229][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0199, 0.3546, 0.0661, 0.0506, 0.1468, 0.2365, 0.1254],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:18,230][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.9636, 0.0039, 0.0107, 0.0035, 0.0046, 0.0011, 0.0126],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:18,230][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.4755, 0.0666, 0.0527, 0.0126, 0.3095, 0.0531, 0.0300],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:18,230][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ to] are: tensor([2.2254e-01, 8.5658e-02, 4.7582e-06, 1.8209e-04, 2.8862e-03, 6.8578e-01,
        2.9492e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:18,230][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ to] are: tensor([3.1452e-03, 6.3567e-01, 5.6659e-04, 2.4645e-01, 8.7159e-04, 7.7563e-03,
        1.0554e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:18,231][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.3570, 0.1702, 0.0676, 0.0334, 0.1326, 0.1743, 0.0649],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:18,232][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0063, 0.3798, 0.0177, 0.0316, 0.0387, 0.3562, 0.0902, 0.0796],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:18,233][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ the] are: tensor([6.1586e-06, 4.9557e-02, 6.6051e-02, 1.9338e-02, 5.1539e-01, 8.9717e-02,
        1.4558e-01, 1.1436e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:18,234][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0236, 0.1249, 0.0905, 0.1273, 0.1640, 0.2180, 0.1214, 0.1303],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:18,236][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.3586, 0.1146, 0.0330, 0.0383, 0.1598, 0.1286, 0.0740, 0.0932],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:18,237][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.8614, 0.0644, 0.0016, 0.0161, 0.0040, 0.0148, 0.0184, 0.0193],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:18,238][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ the] are: tensor([9.4091e-01, 7.0072e-03, 5.9065e-07, 4.4781e-05, 6.7956e-04, 4.9730e-02,
        9.8408e-04, 6.4284e-04], device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:18,239][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0096, 0.2930, 0.0933, 0.0359, 0.1712, 0.2195, 0.1047, 0.0727],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:18,240][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.8893, 0.0094, 0.0290, 0.0066, 0.0152, 0.0028, 0.0288, 0.0189],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:18,242][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.2949, 0.0909, 0.0809, 0.0139, 0.3719, 0.0741, 0.0422, 0.0312],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:18,243][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ the] are: tensor([1.7285e-01, 5.4441e-02, 3.7524e-06, 1.7751e-04, 3.3046e-03, 7.6277e-01,
        3.2196e-03, 3.2402e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:18,244][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.1300, 0.4470, 0.0049, 0.2832, 0.0041, 0.0115, 0.0735, 0.0459],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:18,245][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.1323, 0.1732, 0.0778, 0.0360, 0.2017, 0.2108, 0.0896, 0.0785],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:18,247][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ office] are: tensor([0.0191, 0.3238, 0.0101, 0.0324, 0.0282, 0.2591, 0.0914, 0.0938, 0.1421],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:18,248][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ office] are: tensor([2.3918e-05, 4.4228e-02, 2.6911e-02, 1.9078e-02, 3.5056e-01, 5.3848e-02,
        1.2713e-01, 1.0229e-01, 2.7593e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:18,249][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ office] are: tensor([0.0276, 0.0886, 0.0589, 0.1090, 0.1307, 0.2119, 0.0954, 0.1035, 0.1744],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:18,251][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ office] are: tensor([0.5525, 0.0762, 0.0195, 0.0163, 0.0913, 0.0636, 0.0424, 0.0432, 0.0951],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:18,252][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ office] are: tensor([9.6806e-01, 1.3048e-02, 3.4861e-04, 3.1643e-03, 6.2588e-04, 3.7087e-03,
        3.9990e-03, 4.4338e-03, 2.6080e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:18,252][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ office] are: tensor([9.1929e-01, 5.4835e-03, 1.5324e-07, 1.6727e-05, 1.1044e-04, 1.9610e-02,
        5.7253e-04, 4.4717e-04, 5.4467e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:18,254][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ office] are: tensor([0.0419, 0.2802, 0.0486, 0.0273, 0.1080, 0.1675, 0.0835, 0.0736, 0.1694],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:18,255][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ office] are: tensor([0.9135, 0.0062, 0.0260, 0.0051, 0.0131, 0.0018, 0.0173, 0.0098, 0.0071],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:18,256][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ office] are: tensor([0.5983, 0.0416, 0.0249, 0.0073, 0.1977, 0.0411, 0.0157, 0.0181, 0.0554],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:18,257][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ office] are: tensor([3.0770e-01, 2.0234e-02, 2.6219e-07, 3.1067e-05, 1.9490e-04, 1.7125e-01,
        1.0531e-03, 9.5374e-04, 4.9858e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:18,258][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ office] are: tensor([7.6150e-03, 8.2682e-01, 7.3625e-05, 1.1692e-01, 4.2198e-05, 7.4325e-04,
        2.5752e-02, 2.2013e-02, 1.9788e-05], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:18,260][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ office] are: tensor([0.2489, 0.0785, 0.0495, 0.0278, 0.1280, 0.1691, 0.0579, 0.0436, 0.1967],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:18,261][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.0233, 0.2528, 0.0313, 0.0340, 0.0414, 0.2290, 0.0866, 0.0694, 0.1660,
        0.0662], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:18,262][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [.] are: tensor([3.9182e-05, 2.8699e-02, 8.1287e-02, 1.6744e-02, 3.0574e-01, 6.2396e-02,
        1.4455e-01, 6.1141e-02, 2.7055e-01, 2.8854e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:18,264][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.0456, 0.0873, 0.1323, 0.0907, 0.1184, 0.1083, 0.0748, 0.0830, 0.1484,
        0.1112], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:18,265][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.6411, 0.0266, 0.0312, 0.0108, 0.0861, 0.0518, 0.0282, 0.0271, 0.0767,
        0.0204], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:18,266][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [.] are: tensor([9.7443e-01, 1.0545e-02, 2.5017e-04, 2.3073e-03, 5.0520e-04, 2.7930e-03,
        2.3184e-03, 2.3720e-03, 1.4680e-03, 3.0068e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:18,267][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [.] are: tensor([9.0741e-01, 7.4186e-03, 9.4547e-07, 6.1727e-05, 4.6135e-04, 2.7683e-02,
        9.7210e-04, 6.3864e-04, 5.4188e-02, 1.1696e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:18,268][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0268, 0.1907, 0.0845, 0.0292, 0.1108, 0.1452, 0.0864, 0.0611, 0.1612,
        0.1041], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:18,269][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [.] are: tensor([9.3215e-01, 3.5570e-03, 2.1697e-02, 3.2446e-03, 9.3787e-03, 9.2429e-04,
        1.3219e-02, 6.5348e-03, 3.9455e-03, 5.3485e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:18,271][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.5421, 0.0214, 0.0267, 0.0062, 0.3251, 0.0223, 0.0135, 0.0093, 0.0258,
        0.0075], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:18,271][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [.] are: tensor([2.7067e-01, 3.2294e-02, 3.9927e-06, 1.3663e-04, 9.7157e-04, 2.5839e-01,
        1.4836e-03, 1.5726e-03, 4.2159e-01, 1.2885e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:18,273][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.0857, 0.4367, 0.0063, 0.1892, 0.0049, 0.0186, 0.1599, 0.0853, 0.0014,
        0.0119], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:18,274][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.1616, 0.0869, 0.0773, 0.0218, 0.1461, 0.1458, 0.0513, 0.0420, 0.2291,
        0.0383], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:18,275][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Erica] are: tensor([0.0109, 0.2965, 0.0080, 0.0375, 0.0162, 0.2263, 0.0808, 0.0736, 0.0935,
        0.0800, 0.0768], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:18,276][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Erica] are: tensor([1.3742e-05, 4.6503e-02, 1.2561e-02, 2.7006e-02, 1.4333e-01, 9.5283e-02,
        1.8858e-01, 1.3813e-01, 2.0710e-01, 7.1931e-02, 6.9569e-02],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:18,276][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Erica] are: tensor([0.0209, 0.0716, 0.0465, 0.1034, 0.0745, 0.1511, 0.0790, 0.0864, 0.1485,
        0.1322, 0.0860], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:18,276][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Erica] are: tensor([0.3149, 0.1188, 0.0118, 0.0420, 0.0510, 0.1186, 0.0618, 0.0663, 0.0782,
        0.0879, 0.0486], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:18,277][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Erica] are: tensor([9.0486e-01, 2.4743e-02, 7.9053e-04, 7.6126e-03, 1.6856e-03, 9.8588e-03,
        8.2671e-03, 9.2504e-03, 8.4565e-03, 1.7781e-02, 6.6956e-03],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:18,277][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Erica] are: tensor([6.7966e-01, 4.1742e-03, 7.0731e-07, 3.4600e-05, 3.1558e-04, 4.3139e-02,
        1.3910e-03, 1.1177e-03, 1.8081e-01, 6.1246e-03, 8.3235e-02],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:18,277][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Erica] are: tensor([0.0092, 0.2566, 0.0151, 0.0344, 0.0513, 0.1308, 0.0785, 0.0661, 0.0928,
        0.1186, 0.1467], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:18,278][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Erica] are: tensor([0.8956, 0.0048, 0.0119, 0.0061, 0.0168, 0.0023, 0.0188, 0.0078, 0.0050,
        0.0088, 0.0221], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:18,278][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Erica] are: tensor([0.6180, 0.0279, 0.0251, 0.0064, 0.1414, 0.0340, 0.0151, 0.0126, 0.0380,
        0.0144, 0.0672], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:18,279][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Erica] are: tensor([4.1086e-02, 5.4835e-03, 3.8331e-07, 1.9106e-05, 1.0146e-04, 8.7162e-02,
        6.3453e-04, 1.0863e-03, 7.1486e-01, 2.4071e-02, 1.2550e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:18,280][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Erica] are: tensor([4.7663e-02, 4.8570e-01, 1.0336e-03, 2.8183e-01, 3.7088e-04, 9.1290e-03,
        6.1611e-02, 1.0562e-01, 3.4410e-04, 6.5746e-03, 1.1904e-04],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:18,281][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Erica] are: tensor([0.0299, 0.1315, 0.0530, 0.0443, 0.0904, 0.2276, 0.0741, 0.0681, 0.1721,
        0.0408, 0.0681], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:18,283][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.0046, 0.2109, 0.0137, 0.0281, 0.0336, 0.1336, 0.0618, 0.0541, 0.0896,
        0.0543, 0.1728, 0.1429], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:18,284][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([1.3527e-05, 3.4512e-02, 1.4201e-02, 1.1149e-02, 1.4723e-01, 4.9821e-02,
        6.3202e-02, 4.7491e-02, 3.6191e-01, 2.6030e-02, 1.4047e-01, 1.0398e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:18,285][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0192, 0.0438, 0.0428, 0.0562, 0.0952, 0.1015, 0.0555, 0.0519, 0.1505,
        0.0655, 0.1024, 0.2155], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:18,286][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.2048, 0.0762, 0.0287, 0.0244, 0.1010, 0.0624, 0.0499, 0.0527, 0.0953,
        0.0340, 0.1125, 0.1580], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:18,287][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([9.1644e-01, 2.3171e-02, 6.8175e-04, 6.5522e-03, 1.6696e-03, 4.9915e-03,
        8.3223e-03, 6.4549e-03, 5.3794e-03, 1.0208e-02, 5.5578e-03, 1.0574e-02],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:18,288][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([9.0258e-01, 1.0054e-03, 1.1291e-07, 8.0421e-06, 2.3047e-05, 4.4421e-03,
        2.2673e-04, 1.8368e-04, 1.2976e-02, 5.3784e-04, 5.8452e-03, 7.2174e-02],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:18,289][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0083, 0.1467, 0.0286, 0.0148, 0.0739, 0.0856, 0.0407, 0.0257, 0.1120,
        0.0464, 0.2761, 0.1412], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:18,291][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.7882, 0.0041, 0.0312, 0.0048, 0.0213, 0.0028, 0.0221, 0.0100, 0.0107,
        0.0070, 0.0657, 0.0320], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:18,292][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.2385, 0.0724, 0.0467, 0.0142, 0.2484, 0.0548, 0.0257, 0.0258, 0.0603,
        0.0240, 0.1083, 0.0808], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:18,293][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([3.9969e-01, 2.4259e-03, 2.1726e-07, 6.7080e-06, 4.6637e-05, 1.8606e-02,
        1.6341e-04, 1.7296e-04, 6.0980e-02, 2.0612e-03, 2.3175e-02, 4.9267e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:18,294][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([1.3478e-01, 4.7906e-01, 9.3971e-04, 2.3775e-01, 3.1746e-04, 7.3969e-03,
        5.6975e-02, 6.9696e-02, 2.3587e-04, 2.3702e-03, 4.3005e-05, 1.0433e-02],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:18,295][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.1907, 0.0995, 0.0305, 0.0228, 0.0661, 0.0747, 0.0462, 0.0351, 0.1797,
        0.0350, 0.0643, 0.1553], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:18,297][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0048, 0.1862, 0.0061, 0.0189, 0.0189, 0.2093, 0.0578, 0.0603, 0.1045,
        0.0591, 0.0675, 0.1481, 0.0585], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:18,298][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ a] are: tensor([7.4836e-06, 2.0808e-02, 1.7075e-02, 1.2641e-02, 2.1459e-01, 9.0565e-02,
        5.7063e-02, 4.7907e-02, 2.1138e-01, 1.7312e-02, 1.1137e-01, 1.1072e-01,
        8.8571e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:18,299][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0177, 0.0602, 0.0428, 0.0619, 0.0781, 0.1255, 0.0503, 0.0676, 0.1099,
        0.0747, 0.0698, 0.1922, 0.0494], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:18,300][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.2641, 0.0570, 0.0143, 0.0208, 0.0686, 0.1110, 0.0464, 0.0449, 0.0880,
        0.0355, 0.0671, 0.1285, 0.0539], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:18,302][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.8535, 0.0401, 0.0009, 0.0106, 0.0026, 0.0142, 0.0099, 0.0112, 0.0059,
        0.0135, 0.0059, 0.0275, 0.0043], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:18,303][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ a] are: tensor([6.4645e-01, 5.1827e-03, 1.2414e-06, 6.0765e-05, 3.6716e-04, 2.6888e-02,
        8.7246e-04, 5.8230e-04, 6.2147e-02, 1.7472e-03, 1.8636e-02, 2.3651e-01,
        5.5147e-04], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:18,304][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0137, 0.1185, 0.0208, 0.0156, 0.0475, 0.1179, 0.0461, 0.0374, 0.1145,
        0.0526, 0.1958, 0.1698, 0.0498], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:18,306][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.7409, 0.0071, 0.0388, 0.0059, 0.0226, 0.0027, 0.0259, 0.0156, 0.0091,
        0.0111, 0.0923, 0.0141, 0.0139], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:18,307][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.2382, 0.0652, 0.0349, 0.0149, 0.2715, 0.0517, 0.0377, 0.0265, 0.0753,
        0.0268, 0.0877, 0.0520, 0.0175], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:18,308][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ a] are: tensor([4.0425e-02, 3.7171e-03, 7.6617e-07, 4.0393e-05, 3.0304e-04, 5.2276e-02,
        4.3544e-04, 2.9556e-04, 1.4742e-01, 4.2341e-03, 2.5049e-02, 7.2514e-01,
        6.6447e-04], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:18,310][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.6483, 0.1283, 0.0097, 0.0860, 0.0076, 0.0093, 0.0315, 0.0284, 0.0021,
        0.0075, 0.0014, 0.0107, 0.0291], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:18,311][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.2053, 0.0446, 0.0270, 0.0089, 0.0912, 0.0707, 0.0220, 0.0155, 0.1690,
        0.0160, 0.0568, 0.2410, 0.0318], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:18,312][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ basketball] are: tensor([0.0256, 0.1747, 0.0111, 0.0165, 0.0164, 0.1225, 0.0491, 0.0453, 0.0908,
        0.0498, 0.1013, 0.1485, 0.0460, 0.1024], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:18,313][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ basketball] are: tensor([6.4276e-05, 7.4345e-03, 1.4019e-02, 8.0400e-03, 1.2854e-01, 2.1480e-02,
        4.4927e-02, 3.9969e-02, 2.8244e-01, 1.3170e-02, 9.0926e-02, 1.6166e-01,
        8.5301e-02, 1.0203e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:18,315][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ basketball] are: tensor([0.0410, 0.0367, 0.0395, 0.0490, 0.0908, 0.0788, 0.0417, 0.0413, 0.1247,
        0.0517, 0.0632, 0.2205, 0.0389, 0.0822], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:18,316][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ basketball] are: tensor([0.4339, 0.0425, 0.0222, 0.0152, 0.0654, 0.0501, 0.0259, 0.0238, 0.0358,
        0.0286, 0.0603, 0.1093, 0.0298, 0.0572], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:18,317][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ basketball] are: tensor([9.4302e-01, 1.1721e-02, 5.5809e-04, 4.9016e-03, 8.9706e-04, 2.8535e-03,
        3.8787e-03, 4.6388e-03, 3.1055e-03, 8.0967e-03, 3.0804e-03, 9.0814e-03,
        1.9235e-03, 2.2478e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:18,318][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ basketball] are: tensor([8.2425e-01, 5.1603e-04, 8.2817e-08, 4.1608e-06, 1.0576e-05, 1.4970e-03,
        1.0203e-04, 8.5154e-05, 5.5090e-03, 3.9269e-04, 2.2362e-03, 6.0081e-02,
        2.0541e-04, 1.0511e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:18,320][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ basketball] are: tensor([0.0220, 0.1190, 0.0218, 0.0214, 0.0401, 0.0683, 0.0463, 0.0380, 0.0680,
        0.0531, 0.1624, 0.1356, 0.0368, 0.1672], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:18,321][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ basketball] are: tensor([9.1876e-01, 1.3701e-03, 1.2706e-02, 1.3198e-03, 9.5357e-03, 5.6257e-04,
        5.6406e-03, 2.6072e-03, 2.9144e-03, 2.1019e-03, 2.4062e-02, 6.5936e-03,
        2.1635e-03, 9.6597e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:18,322][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ basketball] are: tensor([0.3992, 0.0372, 0.0332, 0.0090, 0.1312, 0.0356, 0.0180, 0.0180, 0.0408,
        0.0215, 0.0803, 0.0782, 0.0179, 0.0799], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:18,322][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ basketball] are: tensor([1.9073e-01, 6.5766e-04, 4.8795e-08, 2.7036e-06, 6.2405e-06, 3.8311e-03,
        6.3257e-05, 6.4739e-05, 1.4296e-02, 1.5398e-03, 3.8622e-03, 1.5348e-01,
        5.2421e-04, 6.3094e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:18,323][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ basketball] are: tensor([0.1704, 0.2599, 0.0044, 0.2579, 0.0014, 0.0064, 0.0740, 0.0991, 0.0004,
        0.0080, 0.0003, 0.0153, 0.1007, 0.0016], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:18,323][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ basketball] are: tensor([0.1238, 0.0424, 0.0542, 0.0162, 0.0838, 0.0605, 0.0276, 0.0207, 0.0851,
        0.0149, 0.0774, 0.1997, 0.0328, 0.1608], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:18,324][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0061, 0.1406, 0.0085, 0.0161, 0.0129, 0.1848, 0.0459, 0.0459, 0.0924,
        0.0418, 0.0787, 0.1066, 0.0520, 0.1263, 0.0415], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:18,324][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ to] are: tensor([1.4240e-05, 1.7981e-02, 2.4388e-02, 1.0341e-02, 1.4274e-01, 6.7760e-02,
        6.0602e-02, 3.7277e-02, 1.8542e-01, 1.4178e-02, 1.2922e-01, 6.9452e-02,
        6.4786e-02, 1.2953e-01, 4.6313e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:18,324][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0257, 0.0502, 0.0429, 0.0531, 0.0613, 0.1003, 0.0450, 0.0569, 0.0874,
        0.0640, 0.0712, 0.1486, 0.0402, 0.1096, 0.0435], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:18,325][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.3898, 0.0406, 0.0126, 0.0146, 0.0380, 0.0616, 0.0286, 0.0298, 0.0599,
        0.0229, 0.0498, 0.0900, 0.0369, 0.0917, 0.0330], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:18,325][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ to] are: tensor([9.1522e-01, 2.3752e-02, 6.6231e-04, 6.0810e-03, 1.1544e-03, 6.4798e-03,
        5.4949e-03, 6.7712e-03, 3.3487e-03, 7.9621e-03, 3.3078e-03, 1.1908e-02,
        2.3543e-03, 2.3609e-03, 3.1453e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:18,326][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ to] are: tensor([7.5826e-01, 9.8812e-04, 2.9632e-07, 1.3968e-05, 7.7033e-05, 6.7970e-03,
        2.1706e-04, 1.6556e-04, 1.0488e-02, 3.4571e-04, 2.7423e-03, 6.2944e-02,
        1.9817e-04, 1.5604e-01, 7.2264e-04], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:18,327][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0110, 0.1137, 0.0214, 0.0135, 0.0376, 0.0935, 0.0383, 0.0318, 0.0822,
        0.0517, 0.1578, 0.1295, 0.0412, 0.1398, 0.0371], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:18,328][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.8448, 0.0040, 0.0219, 0.0039, 0.0106, 0.0013, 0.0141, 0.0068, 0.0055,
        0.0047, 0.0395, 0.0087, 0.0058, 0.0126, 0.0158], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:18,330][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.3474, 0.0427, 0.0328, 0.0085, 0.2051, 0.0347, 0.0232, 0.0189, 0.0456,
        0.0168, 0.0801, 0.0370, 0.0131, 0.0764, 0.0176], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:18,331][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ to] are: tensor([8.7185e-02, 1.6771e-03, 3.5413e-07, 1.3688e-05, 5.8645e-05, 2.0045e-02,
        1.6465e-04, 1.9127e-04, 3.6151e-02, 2.4668e-03, 9.0266e-03, 2.1067e-01,
        4.8922e-04, 6.3063e-01, 1.2323e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:18,332][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.1199, 0.3387, 0.0101, 0.1383, 0.0090, 0.0243, 0.0911, 0.0908, 0.0043,
        0.0187, 0.0022, 0.0270, 0.0944, 0.0034, 0.0278], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:18,333][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.1861, 0.0526, 0.0276, 0.0106, 0.0617, 0.0630, 0.0226, 0.0172, 0.1069,
        0.0153, 0.0435, 0.1500, 0.0243, 0.1860, 0.0328], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:18,369][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:24:18,370][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:18,371][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:18,371][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:18,372][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:18,373][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:18,373][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:18,374][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:18,375][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:18,376][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:18,377][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:18,377][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:18,378][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:18,379][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.1121, 0.8879], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:18,380][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0038, 0.9962], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:18,381][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.5980, 0.4020], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:18,383][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.8816, 0.1184], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:18,384][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.9927, 0.0073], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:18,385][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.9847, 0.0153], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:18,387][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.2545, 0.7455], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:18,389][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.9980, 0.0020], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:18,390][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.8904, 0.1096], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:18,391][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.8633, 0.1367], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:18,392][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.6969, 0.3031], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:18,392][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.8768, 0.1232], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:18,393][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Erica] are: tensor([0.0396, 0.9326, 0.0278], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:18,395][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Erica] are: tensor([0.0009, 0.6636, 0.3355], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:18,396][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Erica] are: tensor([0.2053, 0.4052, 0.3895], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:18,398][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Erica] are: tensor([0.6099, 0.3500, 0.0401], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:18,399][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Erica] are: tensor([0.9339, 0.0623, 0.0039], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:18,401][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Erica] are: tensor([5.6412e-02, 9.4344e-01, 1.4387e-04], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:18,402][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Erica] are: tensor([0.0630, 0.8859, 0.0511], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:18,404][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Erica] are: tensor([0.9657, 0.0097, 0.0246], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:18,406][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Erica] are: tensor([0.8990, 0.0619, 0.0391], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:18,407][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Erica] are: tensor([3.5527e-03, 9.9638e-01, 6.9035e-05], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:18,408][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Erica] are: tensor([0.1275, 0.1366, 0.7359], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:18,410][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Erica] are: tensor([0.2864, 0.4541, 0.2595], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:18,412][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0782, 0.7115, 0.0747, 0.1356], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:18,413][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0035, 0.3829, 0.4732, 0.1404], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:18,415][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.3889, 0.2276, 0.1700, 0.2135], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:18,416][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.9052, 0.0483, 0.0246, 0.0219], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:18,418][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.9639, 0.0257, 0.0014, 0.0090], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:18,419][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([8.8062e-01, 1.1877e-01, 1.7668e-05, 5.9191e-04], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:18,421][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.1321, 0.5786, 0.1797, 0.1096], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:18,422][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.9776, 0.0034, 0.0154, 0.0036], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:18,424][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.8718, 0.0638, 0.0532, 0.0112], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:18,425][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([2.4144e-01, 7.5679e-01, 5.5942e-05, 1.7157e-03], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:18,427][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.1932, 0.0500, 0.7545, 0.0023], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:18,428][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.8890, 0.0639, 0.0321, 0.0149], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:18,430][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Joshua] are: tensor([0.0509, 0.7668, 0.0292, 0.0814, 0.0717], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:18,432][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Joshua] are: tensor([0.0008, 0.2955, 0.1585, 0.0784, 0.4669], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:18,433][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Joshua] are: tensor([0.1388, 0.2419, 0.1780, 0.2357, 0.2056], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:18,435][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Joshua] are: tensor([0.6880, 0.1206, 0.0321, 0.0449, 0.1144], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:18,437][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Joshua] are: tensor([0.9448, 0.0386, 0.0015, 0.0115, 0.0036], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:18,438][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Joshua] are: tensor([7.8256e-01, 2.0202e-01, 5.7955e-06, 4.8416e-04, 1.4928e-02],
       device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:18,439][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Joshua] are: tensor([0.0755, 0.4699, 0.0850, 0.1146, 0.2550], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:18,441][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Joshua] are: tensor([0.9557, 0.0057, 0.0184, 0.0051, 0.0151], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:18,441][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Joshua] are: tensor([0.6720, 0.0590, 0.0418, 0.0055, 0.2217], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:18,442][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Joshua] are: tensor([1.2931e-01, 8.3156e-01, 1.5386e-05, 1.1161e-03, 3.8004e-02],
       device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:18,443][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Joshua] are: tensor([0.1276, 0.0772, 0.5150, 0.0025, 0.2778], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:18,444][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Joshua] are: tensor([0.2141, 0.2296, 0.2091, 0.0625, 0.2847], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:18,445][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([0.0222, 0.4373, 0.0188, 0.0612, 0.0392, 0.4213], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:18,446][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([3.2651e-04, 1.5817e-01, 5.8424e-02, 8.7519e-02, 6.3538e-01, 6.0183e-02],
       device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:18,448][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([0.0691, 0.1779, 0.1130, 0.2008, 0.1937, 0.2454], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:18,449][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([0.4077, 0.1465, 0.0448, 0.0577, 0.2146, 0.1288], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:18,451][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([9.4236e-01, 4.0050e-02, 4.4900e-04, 9.5213e-03, 9.5965e-04, 6.6580e-03],
       device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:18,452][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([8.0228e-01, 5.0174e-02, 7.3176e-07, 1.0207e-04, 7.2697e-04, 1.4672e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:18,453][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([0.0341, 0.4962, 0.0576, 0.0649, 0.1259, 0.2214], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:18,455][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([0.9726, 0.0049, 0.0098, 0.0049, 0.0057, 0.0021], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:18,457][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([0.4895, 0.1385, 0.0450, 0.0205, 0.2189, 0.0877], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:18,458][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([3.2209e-01, 1.0931e-01, 6.1074e-07, 5.8748e-05, 9.3641e-04, 5.6761e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:18,459][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([0.0422, 0.0510, 0.4125, 0.0028, 0.2669, 0.2246], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:18,461][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([0.5144, 0.1276, 0.0624, 0.0205, 0.1156, 0.1596], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:18,463][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0142, 0.3671, 0.0222, 0.0465, 0.0362, 0.3983, 0.1154],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:18,464][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([1.6085e-04, 1.3386e-01, 1.1041e-01, 4.1679e-02, 4.5277e-01, 8.3927e-02,
        1.7720e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:18,465][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0558, 0.1268, 0.1098, 0.1717, 0.1515, 0.2478, 0.1366],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:18,467][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.6305, 0.0924, 0.0202, 0.0323, 0.0827, 0.0833, 0.0587],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:18,468][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([9.4650e-01, 3.0259e-02, 6.4889e-04, 8.9997e-03, 1.0445e-03, 5.7543e-03,
        6.7935e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:18,469][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([9.3226e-01, 1.0313e-02, 8.5647e-07, 5.5164e-05, 1.0862e-03, 5.5123e-02,
        1.1594e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:18,471][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0199, 0.3546, 0.0661, 0.0506, 0.1468, 0.2365, 0.1254],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:18,473][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.9636, 0.0039, 0.0107, 0.0035, 0.0046, 0.0011, 0.0126],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:18,474][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.4755, 0.0666, 0.0527, 0.0126, 0.3095, 0.0531, 0.0300],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:18,475][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([2.2254e-01, 8.5658e-02, 4.7582e-06, 1.8209e-04, 2.8862e-03, 6.8578e-01,
        2.9492e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:18,477][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0381, 0.0207, 0.4816, 0.0007, 0.2263, 0.2301, 0.0026],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:18,479][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.3570, 0.1702, 0.0676, 0.0334, 0.1326, 0.1743, 0.0649],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:18,480][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0063, 0.3798, 0.0177, 0.0316, 0.0387, 0.3562, 0.0902, 0.0796],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:18,481][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([5.3244e-05, 9.2930e-02, 1.1243e-01, 2.3781e-02, 5.3028e-01, 5.4826e-02,
        1.1072e-01, 7.4979e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:18,483][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0241, 0.1248, 0.0913, 0.1290, 0.1634, 0.2147, 0.1219, 0.1307],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:18,485][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.3586, 0.1146, 0.0330, 0.0383, 0.1598, 0.1286, 0.0740, 0.0932],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:18,487][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.8614, 0.0644, 0.0016, 0.0161, 0.0040, 0.0148, 0.0184, 0.0193],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:18,488][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([9.4091e-01, 7.0072e-03, 5.9065e-07, 4.4781e-05, 6.7956e-04, 4.9730e-02,
        9.8408e-04, 6.4284e-04], device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:18,489][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0096, 0.2930, 0.0933, 0.0359, 0.1712, 0.2195, 0.1047, 0.0727],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:18,491][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.8893, 0.0094, 0.0290, 0.0066, 0.0152, 0.0028, 0.0288, 0.0189],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:18,492][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.2949, 0.0909, 0.0809, 0.0139, 0.3719, 0.0741, 0.0422, 0.0312],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:18,493][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([1.7285e-01, 5.4441e-02, 3.7524e-06, 1.7751e-04, 3.3046e-03, 7.6277e-01,
        3.2196e-03, 3.2402e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:18,493][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0133, 0.0195, 0.5261, 0.0006, 0.2401, 0.1969, 0.0023, 0.0012],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:18,494][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.1323, 0.1732, 0.0778, 0.0360, 0.2017, 0.2108, 0.0896, 0.0785],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:18,496][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ office] are: tensor([0.0191, 0.3238, 0.0101, 0.0324, 0.0282, 0.2591, 0.0914, 0.0938, 0.1421],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:18,497][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ office] are: tensor([1.4572e-04, 8.2659e-02, 5.2324e-02, 2.4252e-02, 4.1094e-01, 4.1510e-02,
        1.1294e-01, 7.8001e-02, 1.9723e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:18,499][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ office] are: tensor([0.0273, 0.0886, 0.0595, 0.1104, 0.1303, 0.2094, 0.0960, 0.1041, 0.1744],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:18,500][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ office] are: tensor([0.5525, 0.0762, 0.0195, 0.0163, 0.0913, 0.0636, 0.0424, 0.0432, 0.0951],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:18,501][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ office] are: tensor([9.6806e-01, 1.3048e-02, 3.4861e-04, 3.1643e-03, 6.2588e-04, 3.7087e-03,
        3.9990e-03, 4.4338e-03, 2.6080e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:18,503][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ office] are: tensor([9.1929e-01, 5.4835e-03, 1.5324e-07, 1.6727e-05, 1.1044e-04, 1.9610e-02,
        5.7253e-04, 4.4717e-04, 5.4467e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:18,504][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ office] are: tensor([0.0419, 0.2802, 0.0486, 0.0273, 0.1080, 0.1675, 0.0835, 0.0736, 0.1694],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:18,506][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ office] are: tensor([0.9135, 0.0062, 0.0260, 0.0051, 0.0131, 0.0018, 0.0173, 0.0098, 0.0071],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:18,508][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ office] are: tensor([0.5983, 0.0416, 0.0249, 0.0073, 0.1977, 0.0411, 0.0157, 0.0181, 0.0554],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:18,509][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ office] are: tensor([3.0770e-01, 2.0234e-02, 2.6219e-07, 3.1067e-05, 1.9490e-04, 1.7125e-01,
        1.0531e-03, 9.5374e-04, 4.9858e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:18,510][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ office] are: tensor([0.0593, 0.0285, 0.2783, 0.0009, 0.2003, 0.1636, 0.0028, 0.0015, 0.2647],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:18,512][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ office] are: tensor([0.2489, 0.0785, 0.0495, 0.0278, 0.1280, 0.1691, 0.0579, 0.0436, 0.1967],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:18,514][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.0233, 0.2528, 0.0313, 0.0340, 0.0414, 0.2290, 0.0866, 0.0694, 0.1660,
        0.0662], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:18,515][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([2.2794e-04, 5.9896e-02, 1.3860e-01, 2.2406e-02, 3.5560e-01, 4.4544e-02,
        1.1550e-01, 4.9454e-02, 1.8749e-01, 2.6286e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:18,517][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.0450, 0.0869, 0.1332, 0.0916, 0.1178, 0.1069, 0.0752, 0.0834, 0.1484,
        0.1117], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:18,519][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.6411, 0.0266, 0.0312, 0.0108, 0.0861, 0.0518, 0.0282, 0.0271, 0.0767,
        0.0204], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:18,520][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([9.7443e-01, 1.0545e-02, 2.5017e-04, 2.3073e-03, 5.0520e-04, 2.7930e-03,
        2.3184e-03, 2.3720e-03, 1.4680e-03, 3.0068e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:18,521][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([9.0741e-01, 7.4186e-03, 9.4547e-07, 6.1727e-05, 4.6135e-04, 2.7683e-02,
        9.7210e-04, 6.3864e-04, 5.4188e-02, 1.1696e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:18,523][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.0268, 0.1907, 0.0845, 0.0292, 0.1108, 0.1452, 0.0864, 0.0611, 0.1612,
        0.1041], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:18,524][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([9.3215e-01, 3.5570e-03, 2.1697e-02, 3.2446e-03, 9.3787e-03, 9.2429e-04,
        1.3219e-02, 6.5348e-03, 3.9455e-03, 5.3485e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:18,525][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.5421, 0.0214, 0.0267, 0.0062, 0.3251, 0.0223, 0.0135, 0.0093, 0.0258,
        0.0075], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:18,527][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([2.7067e-01, 3.2294e-02, 3.9927e-06, 1.3663e-04, 9.7157e-04, 2.5839e-01,
        1.4836e-03, 1.5726e-03, 4.2159e-01, 1.2885e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:18,528][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([3.7018e-02, 1.0557e-02, 5.0617e-01, 4.0910e-04, 1.5995e-01, 1.1963e-01,
        1.6125e-03, 7.0933e-04, 1.6259e-01, 1.3526e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:18,530][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.1616, 0.0869, 0.0773, 0.0218, 0.1461, 0.1458, 0.0513, 0.0420, 0.2291,
        0.0383], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:18,531][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Erica] are: tensor([0.0109, 0.2965, 0.0080, 0.0375, 0.0162, 0.2263, 0.0808, 0.0736, 0.0935,
        0.0800, 0.0768], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:18,532][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Erica] are: tensor([7.3039e-05, 8.2011e-02, 2.8696e-02, 3.0505e-02, 2.0952e-01, 6.3586e-02,
        1.5396e-01, 1.0045e-01, 1.6284e-01, 6.0330e-02, 1.0803e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:18,534][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Erica] are: tensor([0.0205, 0.0712, 0.0468, 0.1045, 0.0741, 0.1493, 0.0794, 0.0868, 0.1484,
        0.1327, 0.0863], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:18,536][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Erica] are: tensor([0.3149, 0.1188, 0.0118, 0.0420, 0.0510, 0.1186, 0.0618, 0.0663, 0.0782,
        0.0879, 0.0486], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:18,537][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Erica] are: tensor([9.0486e-01, 2.4743e-02, 7.9053e-04, 7.6126e-03, 1.6856e-03, 9.8588e-03,
        8.2671e-03, 9.2504e-03, 8.4565e-03, 1.7781e-02, 6.6956e-03],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:18,539][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Erica] are: tensor([6.7966e-01, 4.1742e-03, 7.0731e-07, 3.4600e-05, 3.1558e-04, 4.3139e-02,
        1.3910e-03, 1.1177e-03, 1.8081e-01, 6.1246e-03, 8.3235e-02],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:18,540][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Erica] are: tensor([0.0092, 0.2566, 0.0151, 0.0344, 0.0513, 0.1308, 0.0785, 0.0661, 0.0928,
        0.1186, 0.1467], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:18,542][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Erica] are: tensor([0.8956, 0.0048, 0.0119, 0.0061, 0.0168, 0.0023, 0.0188, 0.0078, 0.0050,
        0.0088, 0.0221], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:18,542][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Erica] are: tensor([0.6180, 0.0279, 0.0251, 0.0064, 0.1414, 0.0340, 0.0151, 0.0126, 0.0380,
        0.0144, 0.0672], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:18,543][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Erica] are: tensor([4.1086e-02, 5.4835e-03, 3.8331e-07, 1.9106e-05, 1.0146e-04, 8.7162e-02,
        6.3453e-04, 1.0863e-03, 7.1486e-01, 2.4071e-02, 1.2550e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:18,544][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Erica] are: tensor([0.0348, 0.0283, 0.2733, 0.0012, 0.1249, 0.1972, 0.0044, 0.0024, 0.3033,
        0.0042, 0.0260], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:18,545][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Erica] are: tensor([0.0299, 0.1315, 0.0530, 0.0443, 0.0904, 0.2276, 0.0741, 0.0681, 0.1721,
        0.0408, 0.0681], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:18,547][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.0046, 0.2109, 0.0137, 0.0281, 0.0336, 0.1336, 0.0618, 0.0541, 0.0896,
        0.0543, 0.1728, 0.1429], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:18,548][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([7.6645e-05, 6.5169e-02, 3.4722e-02, 1.5998e-02, 2.1167e-01, 3.8430e-02,
        6.8710e-02, 4.3879e-02, 2.3838e-01, 2.7731e-02, 1.7998e-01, 7.5251e-02],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:18,550][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.0192, 0.0438, 0.0432, 0.0570, 0.0951, 0.1005, 0.0559, 0.0523, 0.1508,
        0.0659, 0.1031, 0.2131], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:18,551][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.2048, 0.0762, 0.0287, 0.0244, 0.1010, 0.0624, 0.0499, 0.0527, 0.0953,
        0.0340, 0.1125, 0.1580], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:18,553][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([9.1644e-01, 2.3171e-02, 6.8175e-04, 6.5522e-03, 1.6696e-03, 4.9915e-03,
        8.3223e-03, 6.4549e-03, 5.3794e-03, 1.0208e-02, 5.5578e-03, 1.0574e-02],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:18,554][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([9.0258e-01, 1.0054e-03, 1.1291e-07, 8.0421e-06, 2.3047e-05, 4.4421e-03,
        2.2673e-04, 1.8368e-04, 1.2976e-02, 5.3784e-04, 5.8452e-03, 7.2174e-02],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:18,556][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.0083, 0.1467, 0.0286, 0.0148, 0.0739, 0.0856, 0.0407, 0.0257, 0.1120,
        0.0464, 0.2761, 0.1412], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:18,557][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.7882, 0.0041, 0.0312, 0.0048, 0.0213, 0.0028, 0.0221, 0.0100, 0.0107,
        0.0070, 0.0657, 0.0320], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:18,559][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.2385, 0.0724, 0.0467, 0.0142, 0.2484, 0.0548, 0.0257, 0.0258, 0.0603,
        0.0240, 0.1083, 0.0808], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:18,560][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([3.9969e-01, 2.4259e-03, 2.1726e-07, 6.7080e-06, 4.6637e-05, 1.8606e-02,
        1.6341e-04, 1.7296e-04, 6.0980e-02, 2.0612e-03, 2.3175e-02, 4.9267e-01],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:18,562][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0197, 0.0173, 0.2621, 0.0012, 0.1983, 0.1235, 0.0029, 0.0015, 0.2431,
        0.0032, 0.0385, 0.0887], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:18,564][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.1907, 0.0995, 0.0305, 0.0228, 0.0661, 0.0747, 0.0462, 0.0351, 0.1797,
        0.0350, 0.0643, 0.1553], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:18,566][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0048, 0.1862, 0.0061, 0.0189, 0.0189, 0.2093, 0.0578, 0.0603, 0.1045,
        0.0591, 0.0675, 0.1481, 0.0585], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:18,567][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([6.9209e-05, 4.2437e-02, 3.7847e-02, 1.6656e-02, 2.7320e-01, 5.5381e-02,
        5.9038e-02, 4.1740e-02, 1.5569e-01, 1.9203e-02, 1.5017e-01, 8.1612e-02,
        6.6962e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:18,569][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0177, 0.0604, 0.0433, 0.0628, 0.0780, 0.1241, 0.0506, 0.0680, 0.1100,
        0.0751, 0.0702, 0.1898, 0.0497], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:18,570][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.2641, 0.0570, 0.0143, 0.0208, 0.0686, 0.1110, 0.0464, 0.0449, 0.0880,
        0.0355, 0.0671, 0.1285, 0.0539], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:18,572][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.8535, 0.0401, 0.0009, 0.0106, 0.0026, 0.0142, 0.0099, 0.0112, 0.0059,
        0.0135, 0.0059, 0.0275, 0.0043], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:18,573][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([6.4645e-01, 5.1827e-03, 1.2414e-06, 6.0765e-05, 3.6716e-04, 2.6888e-02,
        8.7246e-04, 5.8230e-04, 6.2147e-02, 1.7472e-03, 1.8636e-02, 2.3651e-01,
        5.5147e-04], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:18,575][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0137, 0.1185, 0.0208, 0.0156, 0.0475, 0.1179, 0.0461, 0.0374, 0.1145,
        0.0526, 0.1958, 0.1698, 0.0498], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:18,577][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.7409, 0.0071, 0.0388, 0.0059, 0.0226, 0.0027, 0.0259, 0.0156, 0.0091,
        0.0111, 0.0923, 0.0141, 0.0139], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:18,579][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.2382, 0.0652, 0.0349, 0.0149, 0.2715, 0.0517, 0.0377, 0.0265, 0.0753,
        0.0268, 0.0877, 0.0520, 0.0175], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:18,580][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([4.0425e-02, 3.7171e-03, 7.6617e-07, 4.0393e-05, 3.0304e-04, 5.2276e-02,
        4.3544e-04, 2.9556e-04, 1.4742e-01, 4.2341e-03, 2.5049e-02, 7.2514e-01,
        6.6447e-04], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:18,582][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0181, 0.0137, 0.2363, 0.0006, 0.1806, 0.1541, 0.0018, 0.0010, 0.2480,
        0.0019, 0.0231, 0.1046, 0.0162], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:18,583][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.2053, 0.0446, 0.0270, 0.0089, 0.0912, 0.0707, 0.0220, 0.0155, 0.1690,
        0.0160, 0.0568, 0.2410, 0.0318], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:18,585][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ basketball] are: tensor([0.0256, 0.1747, 0.0111, 0.0165, 0.0164, 0.1225, 0.0491, 0.0453, 0.0908,
        0.0498, 0.1013, 0.1485, 0.0460, 0.1024], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:18,587][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ basketball] are: tensor([0.0003, 0.0212, 0.0357, 0.0127, 0.2036, 0.0193, 0.0519, 0.0383, 0.2064,
        0.0156, 0.1321, 0.1067, 0.0652, 0.0911], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:18,589][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ basketball] are: tensor([0.0412, 0.0369, 0.0400, 0.0498, 0.0908, 0.0781, 0.0420, 0.0417, 0.1250,
        0.0520, 0.0636, 0.2180, 0.0391, 0.0816], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:18,591][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ basketball] are: tensor([0.4339, 0.0425, 0.0222, 0.0152, 0.0654, 0.0501, 0.0259, 0.0238, 0.0358,
        0.0286, 0.0603, 0.1093, 0.0298, 0.0572], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:18,592][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ basketball] are: tensor([9.4302e-01, 1.1721e-02, 5.5809e-04, 4.9016e-03, 8.9706e-04, 2.8535e-03,
        3.8787e-03, 4.6388e-03, 3.1055e-03, 8.0967e-03, 3.0804e-03, 9.0814e-03,
        1.9235e-03, 2.2478e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:18,593][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ basketball] are: tensor([8.2425e-01, 5.1603e-04, 8.2817e-08, 4.1608e-06, 1.0576e-05, 1.4970e-03,
        1.0203e-04, 8.5154e-05, 5.5090e-03, 3.9269e-04, 2.2362e-03, 6.0081e-02,
        2.0541e-04, 1.0511e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:18,594][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ basketball] are: tensor([0.0220, 0.1190, 0.0218, 0.0214, 0.0401, 0.0683, 0.0463, 0.0380, 0.0680,
        0.0531, 0.1624, 0.1356, 0.0368, 0.1672], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:18,595][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ basketball] are: tensor([9.1876e-01, 1.3701e-03, 1.2706e-02, 1.3198e-03, 9.5357e-03, 5.6257e-04,
        5.6406e-03, 2.6072e-03, 2.9144e-03, 2.1019e-03, 2.4062e-02, 6.5936e-03,
        2.1635e-03, 9.6597e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:18,596][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ basketball] are: tensor([0.3992, 0.0372, 0.0332, 0.0090, 0.1312, 0.0356, 0.0180, 0.0180, 0.0408,
        0.0215, 0.0803, 0.0782, 0.0179, 0.0799], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:18,598][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ basketball] are: tensor([1.9073e-01, 6.5766e-04, 4.8795e-08, 2.7036e-06, 6.2405e-06, 3.8311e-03,
        6.3257e-05, 6.4739e-05, 1.4296e-02, 1.5398e-03, 3.8622e-03, 1.5348e-01,
        5.2421e-04, 6.3094e-01], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:18,599][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ basketball] are: tensor([0.0217, 0.0113, 0.1735, 0.0006, 0.0798, 0.0778, 0.0021, 0.0013, 0.1189,
        0.0028, 0.0200, 0.1362, 0.0164, 0.3376], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:18,601][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ basketball] are: tensor([0.1238, 0.0424, 0.0542, 0.0162, 0.0838, 0.0605, 0.0276, 0.0207, 0.0851,
        0.0149, 0.0774, 0.1997, 0.0328, 0.1608], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:18,603][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0061, 0.1406, 0.0085, 0.0161, 0.0129, 0.1848, 0.0459, 0.0459, 0.0924,
        0.0418, 0.0787, 0.1066, 0.0520, 0.1263, 0.0415], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:18,604][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([8.7119e-05, 3.6053e-02, 5.0408e-02, 1.3937e-02, 2.0038e-01, 4.3371e-02,
        6.1893e-02, 3.4350e-02, 1.3816e-01, 1.5043e-02, 1.5909e-01, 5.3635e-02,
        4.9939e-02, 1.0136e-01, 4.2295e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:18,606][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0257, 0.0503, 0.0434, 0.0539, 0.0612, 0.0993, 0.0453, 0.0573, 0.0875,
        0.0644, 0.0717, 0.1468, 0.0405, 0.1089, 0.0437], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:18,608][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.3898, 0.0406, 0.0126, 0.0146, 0.0380, 0.0616, 0.0286, 0.0298, 0.0599,
        0.0229, 0.0498, 0.0900, 0.0369, 0.0917, 0.0330], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:18,609][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([9.1522e-01, 2.3752e-02, 6.6231e-04, 6.0810e-03, 1.1544e-03, 6.4798e-03,
        5.4949e-03, 6.7712e-03, 3.3487e-03, 7.9621e-03, 3.3078e-03, 1.1908e-02,
        2.3543e-03, 2.3609e-03, 3.1453e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:18,610][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([7.5826e-01, 9.8812e-04, 2.9632e-07, 1.3968e-05, 7.7033e-05, 6.7970e-03,
        2.1706e-04, 1.6556e-04, 1.0488e-02, 3.4571e-04, 2.7423e-03, 6.2944e-02,
        1.9817e-04, 1.5604e-01, 7.2264e-04], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:18,612][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0110, 0.1137, 0.0214, 0.0135, 0.0376, 0.0935, 0.0383, 0.0318, 0.0822,
        0.0517, 0.1578, 0.1295, 0.0412, 0.1398, 0.0371], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:18,614][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.8448, 0.0040, 0.0219, 0.0039, 0.0106, 0.0013, 0.0141, 0.0068, 0.0055,
        0.0047, 0.0395, 0.0087, 0.0058, 0.0126, 0.0158], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:18,615][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.3474, 0.0427, 0.0328, 0.0085, 0.2051, 0.0347, 0.0232, 0.0189, 0.0456,
        0.0168, 0.0801, 0.0370, 0.0131, 0.0764, 0.0176], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:18,617][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([8.7185e-02, 1.6771e-03, 3.5413e-07, 1.3688e-05, 5.8645e-05, 2.0045e-02,
        1.6465e-04, 1.9127e-04, 3.6151e-02, 2.4668e-03, 9.0266e-03, 2.1067e-01,
        4.8922e-04, 6.3063e-01, 1.2323e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:18,618][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([1.9106e-02, 6.6705e-03, 1.8279e-01, 2.5333e-04, 8.6193e-02, 1.0302e-01,
        1.0163e-03, 4.8702e-04, 1.1094e-01, 7.8441e-04, 1.1654e-02, 5.9881e-02,
        9.6511e-03, 4.0419e-01, 3.3602e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:18,620][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.1861, 0.0526, 0.0276, 0.0106, 0.0617, 0.0630, 0.0226, 0.0172, 0.1069,
        0.0153, 0.0435, 0.1500, 0.0243, 0.1860, 0.0328], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:18,624][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:24:18,625][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[384],
        [683],
        [167],
        [151],
        [659],
        [ 11],
        [  6],
        [ 12],
        [  8],
        [  2],
        [ 16],
        [  4],
        [  7],
        [  3],
        [  1]], device='cuda:0')
[2024-07-24 10:24:18,627][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[425],
        [537],
        [ 96],
        [ 94],
        [201],
        [  4],
        [  2],
        [  3],
        [  2],
        [  1],
        [  5],
        [  1],
        [  1],
        [  1],
        [  1]], device='cuda:0')
[2024-07-24 10:24:18,629][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[39676],
        [48791],
        [48875],
        [49241],
        [49801],
        [49883],
        [49872],
        [49896],
        [49970],
        [50049],
        [49955],
        [50097],
        [50082],
        [50074],
        [50004]], device='cuda:0')
[2024-07-24 10:24:18,631][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[38793],
        [11476],
        [17222],
        [23085],
        [42273],
        [45869],
        [42222],
        [44426],
        [41837],
        [40847],
        [34244],
        [36820],
        [38512],
        [37208],
        [36940]], device='cuda:0')
[2024-07-24 10:24:18,632][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[11366],
        [18634],
        [28876],
        [12158],
        [48065],
        [41777],
        [34584],
        [38715],
        [24325],
        [29134],
        [13991],
        [17922],
        [15802],
        [19753],
        [16427]], device='cuda:0')
[2024-07-24 10:24:18,634][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[ 9948],
        [ 9067],
        [11016],
        [ 9544],
        [18023],
        [19433],
        [12291],
        [12636],
        [10652],
        [11570],
        [ 6981],
        [14849],
        [11510],
        [14725],
        [12193]], device='cuda:0')
[2024-07-24 10:24:18,635][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[20388],
        [20305],
        [19688],
        [20027],
        [19968],
        [19990],
        [19998],
        [19448],
        [19939],
        [20155],
        [19803],
        [19547],
        [19247],
        [19919],
        [19636]], device='cuda:0')
[2024-07-24 10:24:18,637][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[41407],
        [42036],
        [33127],
        [43373],
        [42098],
        [40208],
        [41991],
        [41985],
        [42850],
        [42763],
        [42016],
        [40818],
        [33543],
        [37923],
        [35613]], device='cuda:0')
[2024-07-24 10:24:18,639][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[15208],
        [39398],
        [40324],
        [41418],
        [48934],
        [46259],
        [46486],
        [47074],
        [45523],
        [45409],
        [42595],
        [45683],
        [43338],
        [40276],
        [40023]], device='cuda:0')
[2024-07-24 10:24:18,640][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[13543],
        [13732],
        [17449],
        [16374],
        [10126],
        [13259],
        [14513],
        [16176],
        [14710],
        [14892],
        [13879],
        [17986],
        [21704],
        [13975],
        [19454]], device='cuda:0')
[2024-07-24 10:24:18,642][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[33443],
        [33491],
        [32299],
        [30956],
        [19311],
        [18305],
        [15857],
        [14483],
        [16449],
        [14721],
        [18126],
        [14268],
        [13910],
        [14877],
        [14288]], device='cuda:0')
[2024-07-24 10:24:18,644][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[23952],
        [33201],
        [47550],
        [47127],
        [47208],
        [36237],
        [35507],
        [34667],
        [45733],
        [44875],
        [46711],
        [43125],
        [44830],
        [44168],
        [44671]], device='cuda:0')
[2024-07-24 10:24:18,645][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[2167],
        [2603],
        [2603],
        [2638],
        [2656],
        [2606],
        [2444],
        [2392],
        [2533],
        [2232],
        [2487],
        [2436],
        [1853],
        [2747],
        [2424]], device='cuda:0')
[2024-07-24 10:24:18,646][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[14750],
        [17765],
        [38089],
        [18794],
        [41850],
        [28825],
        [29899],
        [31209],
        [29186],
        [31096],
        [29386],
        [29109],
        [29181],
        [36778],
        [35571]], device='cuda:0')
[2024-07-24 10:24:18,648][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[14047],
        [35929],
        [32861],
        [33397],
        [23563],
        [31608],
        [25842],
        [21927],
        [19710],
        [19956],
        [11654],
        [ 9123],
        [12310],
        [ 4747],
        [ 7286]], device='cuda:0')
[2024-07-24 10:24:18,649][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[16892],
        [19139],
        [18942],
        [19336],
        [18627],
        [23306],
        [25403],
        [25385],
        [26411],
        [26924],
        [26848],
        [27567],
        [28781],
        [27767],
        [28603]], device='cuda:0')
[2024-07-24 10:24:18,651][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[39639],
        [27444],
        [29691],
        [32310],
        [35234],
        [37387],
        [42211],
        [40416],
        [42922],
        [42822],
        [43916],
        [42733],
        [42368],
        [42211],
        [41827]], device='cuda:0')
[2024-07-24 10:24:18,653][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[39139],
        [34922],
        [28016],
        [35634],
        [33900],
        [33362],
        [34657],
        [34736],
        [34366],
        [33181],
        [35655],
        [30833],
        [31847],
        [31455],
        [34237]], device='cuda:0')
[2024-07-24 10:24:18,654][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[24746],
        [27361],
        [26604],
        [29817],
        [27654],
        [26039],
        [26455],
        [25998],
        [27806],
        [28019],
        [28317],
        [26544],
        [26416],
        [26825],
        [27395]], device='cuda:0')
[2024-07-24 10:24:18,656][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[22042],
        [22128],
        [22282],
        [22172],
        [22203],
        [22184],
        [22273],
        [22082],
        [22505],
        [22331],
        [22498],
        [22596],
        [22158],
        [22546],
        [22504]], device='cuda:0')
[2024-07-24 10:24:18,658][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[26494],
        [27132],
        [31432],
        [27736],
        [28013],
        [29566],
        [31346],
        [31147],
        [33683],
        [34014],
        [34688],
        [32799],
        [29619],
        [30672],
        [30075]], device='cuda:0')
[2024-07-24 10:24:18,660][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[12157],
        [  903],
        [  905],
        [ 1372],
        [ 2714],
        [ 2292],
        [ 2967],
        [ 3644],
        [ 4211],
        [ 4715],
        [ 3376],
        [ 7181],
        [ 7967],
        [ 4745],
        [ 5228]], device='cuda:0')
[2024-07-24 10:24:18,661][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[25999],
        [26061],
        [27844],
        [27174],
        [28549],
        [27331],
        [27575],
        [30224],
        [29592],
        [28940],
        [30161],
        [32167],
        [33791],
        [29313],
        [31490]], device='cuda:0')
[2024-07-24 10:24:18,663][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[25814],
        [23365],
        [23495],
        [22967],
        [20254],
        [19503],
        [19564],
        [18587],
        [19911],
        [19663],
        [19387],
        [17295],
        [17261],
        [17547],
        [17644]], device='cuda:0')
[2024-07-24 10:24:18,664][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[36623],
        [27913],
        [16096],
        [15820],
        [16208],
        [20046],
        [19408],
        [19286],
        [12848],
        [13232],
        [12271],
        [16408],
        [13867],
        [ 8420],
        [ 8284]], device='cuda:0')
[2024-07-24 10:24:18,666][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[34753],
        [21915],
        [27123],
        [29515],
        [31910],
        [27989],
        [29156],
        [29977],
        [20575],
        [26373],
        [18115],
        [19691],
        [18678],
        [13840],
        [13651]], device='cuda:0')
[2024-07-24 10:24:18,668][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[19111],
        [17139],
        [11455],
        [18121],
        [ 6608],
        [10299],
        [ 9072],
        [ 7689],
        [ 9103],
        [ 8086],
        [ 7714],
        [ 8320],
        [ 7737],
        [ 7630],
        [ 8380]], device='cuda:0')
[2024-07-24 10:24:18,669][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[ 6761],
        [12068],
        [15191],
        [11505],
        [12883],
        [12274],
        [10793],
        [11627],
        [11152],
        [10586],
        [11867],
        [11673],
        [13151],
        [16504],
        [15003]], device='cuda:0')
[2024-07-24 10:24:18,671][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[ 5783],
        [43982],
        [38044],
        [37905],
        [37591],
        [27392],
        [23351],
        [21407],
        [17697],
        [16978],
        [16286],
        [12262],
        [ 9898],
        [19752],
        [14577]], device='cuda:0')
[2024-07-24 10:24:18,673][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[15582],
        [15582],
        [15582],
        [15582],
        [15582],
        [15582],
        [15582],
        [15582],
        [15582],
        [15582],
        [15582],
        [15582],
        [15582],
        [15582],
        [15582]], device='cuda:0')
[2024-07-24 10:24:18,793][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:24:18,794][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:18,795][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:18,795][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:18,797][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:18,797][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:18,798][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:18,799][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:18,799][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:18,800][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:18,801][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:18,801][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:18,802][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:18,803][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [,] are: tensor([9.9921e-01, 7.8822e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:18,803][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [,] are: tensor([1.0000e+00, 4.3128e-06], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:18,804][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.9936, 0.0064], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:18,805][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.9965, 0.0035], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:18,806][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.9196, 0.0804], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:18,806][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [,] are: tensor([9.9995e-01, 4.5924e-05], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:18,807][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [,] are: tensor([9.9911e-01, 8.8912e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:18,808][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [,] are: tensor([9.9996e-01, 3.5344e-05], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:18,811][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.9979, 0.0021], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:18,813][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [,] are: tensor([1.0000e+00, 3.4678e-06], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:18,815][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [,] are: tensor([1.0000e+00, 5.2972e-09], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:18,815][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [,] are: tensor([9.9998e-01, 1.5608e-05], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:18,816][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Erica] are: tensor([9.9910e-01, 7.1744e-04, 1.8335e-04], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:18,817][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Erica] are: tensor([9.9984e-01, 1.1602e-04, 4.0751e-05], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:18,817][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Erica] are: tensor([8.4983e-01, 1.4960e-01, 5.6475e-04], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:18,819][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Erica] are: tensor([2.9287e-01, 7.0712e-01, 3.1179e-06], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:18,821][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Erica] are: tensor([0.1246, 0.6972, 0.1782], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:18,823][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Erica] are: tensor([9.9786e-01, 1.8408e-03, 3.0329e-04], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:18,827][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Erica] are: tensor([0.9641, 0.0321, 0.0038], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:18,829][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Erica] are: tensor([9.9957e-01, 3.5507e-04, 7.6076e-05], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:18,831][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Erica] are: tensor([3.3131e-04, 9.9763e-01, 2.0392e-03], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:18,833][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Erica] are: tensor([9.9972e-01, 2.7082e-04, 7.0405e-06], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:18,836][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Erica] are: tensor([9.9999e-01, 5.9365e-06, 3.4277e-07], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:18,838][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Erica] are: tensor([9.8979e-01, 9.3231e-03, 8.8783e-04], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:18,838][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ and] are: tensor([9.8822e-01, 9.2799e-03, 5.3169e-04, 1.9657e-03], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:18,839][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ and] are: tensor([9.9996e-01, 1.2322e-05, 2.8883e-05, 1.2967e-06], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:18,840][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.9665, 0.0218, 0.0019, 0.0097], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:18,840][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ and] are: tensor([9.3449e-01, 6.5439e-02, 2.2335e-06, 6.7562e-05], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:18,842][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.4037, 0.2630, 0.0705, 0.2627], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:18,844][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ and] are: tensor([9.9991e-01, 4.4864e-05, 4.2850e-05, 5.8335e-06], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:18,847][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ and] are: tensor([9.9716e-01, 2.1406e-03, 6.3328e-04, 6.1212e-05], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:18,849][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ and] are: tensor([9.9989e-01, 3.8736e-05, 5.8495e-05, 1.2162e-05], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:18,853][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.2442, 0.6352, 0.0689, 0.0517], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:18,855][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ and] are: tensor([9.9999e-01, 9.0105e-06, 3.1890e-06, 2.5214e-07], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:18,858][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ and] are: tensor([1.0000e+00, 1.1433e-07, 1.9757e-08, 1.5494e-07], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:18,860][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ and] are: tensor([9.9990e-01, 7.4926e-05, 5.9449e-06, 1.6154e-05], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:18,861][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Joshua] are: tensor([9.9806e-01, 3.0770e-04, 5.2162e-05, 8.9976e-05, 1.4916e-03],
       device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:18,862][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Joshua] are: tensor([9.9990e-01, 8.0996e-05, 1.3217e-05, 3.1406e-06, 4.8103e-06],
       device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:18,863][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Joshua] are: tensor([9.0841e-01, 6.6093e-02, 5.9872e-04, 1.3857e-02, 1.1038e-02],
       device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:18,863][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Joshua] are: tensor([7.5715e-01, 2.4250e-01, 3.7828e-07, 2.2869e-04, 1.2714e-04],
       device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:18,865][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Joshua] are: tensor([0.2436, 0.1761, 0.0246, 0.1242, 0.4316], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:18,867][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Joshua] are: tensor([9.9808e-01, 7.6731e-04, 1.3646e-04, 4.8581e-05, 9.6442e-04],
       device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:18,869][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Joshua] are: tensor([9.8968e-01, 7.9294e-03, 8.6306e-04, 1.6213e-04, 1.3669e-03],
       device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:18,872][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Joshua] are: tensor([9.9979e-01, 1.5957e-04, 2.3446e-05, 9.4547e-06, 1.2803e-05],
       device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:18,876][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Joshua] are: tensor([0.2254, 0.2271, 0.0926, 0.0376, 0.4173], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:18,878][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Joshua] are: tensor([9.9990e-01, 6.9681e-05, 2.8574e-06, 8.2704e-07, 2.1841e-05],
       device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:18,881][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Joshua] are: tensor([1.0000e+00, 8.3355e-07, 5.8765e-08, 3.4679e-07, 6.3716e-07],
       device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:18,883][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Joshua] are: tensor([9.9637e-01, 2.3601e-03, 5.5891e-05, 2.7144e-04, 9.4041e-04],
       device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:18,884][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ went] are: tensor([9.3859e-01, 5.4879e-03, 3.3512e-04, 8.9376e-04, 3.1688e-03, 5.1521e-02],
       device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:18,885][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ went] are: tensor([9.9974e-01, 1.1645e-04, 5.7511e-05, 7.0394e-06, 1.4195e-05, 6.2844e-05],
       device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:18,885][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ went] are: tensor([0.7281, 0.1727, 0.0015, 0.0224, 0.0257, 0.0496], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:18,886][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ went] are: tensor([9.8799e-01, 1.0759e-02, 1.4907e-08, 1.7797e-05, 6.7497e-06, 1.2295e-03],
       device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:18,888][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ went] are: tensor([0.1063, 0.1752, 0.0552, 0.1036, 0.3205, 0.2392], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:18,890][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ went] are: tensor([9.9454e-01, 8.9398e-04, 2.2745e-04, 6.1534e-05, 2.5673e-03, 1.7116e-03],
       device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:18,893][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ went] are: tensor([9.8359e-01, 9.4071e-03, 8.4976e-04, 3.3278e-04, 2.5643e-03, 3.2577e-03],
       device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:18,895][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ went] are: tensor([9.9839e-01, 5.6679e-04, 2.4015e-04, 7.8798e-05, 1.1913e-04, 6.0928e-04],
       device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:18,899][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.7166, 0.0119, 0.0509, 0.0077, 0.0682, 0.1447], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:18,902][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ went] are: tensor([9.9981e-01, 1.2448e-04, 6.0383e-06, 2.0683e-06, 3.6123e-05, 2.4979e-05],
       device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:18,904][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ went] are: tensor([1.0000e+00, 2.3266e-07, 1.6502e-08, 1.7126e-07, 5.0141e-08, 1.9372e-07],
       device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:18,906][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ went] are: tensor([9.9595e-01, 4.7248e-04, 1.8081e-05, 8.4504e-05, 2.9288e-04, 3.1853e-03],
       device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:18,907][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.8091, 0.0510, 0.0013, 0.0055, 0.0098, 0.0830, 0.0402],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:18,907][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ to] are: tensor([9.9992e-01, 2.1405e-05, 2.8085e-05, 1.5283e-06, 5.0604e-06, 1.8273e-05,
        3.9122e-06], device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:18,908][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.7686, 0.0371, 0.0011, 0.0118, 0.0163, 0.1233, 0.0418],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:18,909][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ to] are: tensor([9.8374e-01, 1.4437e-02, 1.6669e-07, 1.7915e-05, 7.6307e-06, 1.6573e-03,
        1.3934e-04], device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:18,912][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.1462, 0.1823, 0.0427, 0.0909, 0.2292, 0.1563, 0.1524],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:18,915][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ to] are: tensor([9.9961e-01, 8.9907e-05, 2.6705e-05, 4.8873e-06, 1.7321e-04, 8.2977e-05,
        1.3474e-05], device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:18,917][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ to] are: tensor([9.8667e-01, 7.1763e-03, 1.8537e-03, 1.5417e-04, 2.2619e-03, 1.6059e-03,
        2.7644e-04], device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:18,919][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ to] are: tensor([9.9991e-01, 3.0029e-05, 3.0791e-05, 3.9319e-06, 4.9439e-06, 1.6431e-05,
        3.8825e-06], device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:18,923][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.6321, 0.0418, 0.0291, 0.0121, 0.0696, 0.1357, 0.0794],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:18,926][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ to] are: tensor([9.9991e-01, 3.4871e-05, 7.0165e-06, 6.1659e-07, 2.2015e-05, 2.2712e-05,
        1.2058e-06], device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:18,928][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ to] are: tensor([1.0000e+00, 5.3202e-08, 1.1028e-08, 6.0504e-08, 2.4553e-08, 4.1012e-08,
        2.2495e-08], device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:18,929][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ to] are: tensor([9.9946e-01, 5.3154e-05, 4.6041e-06, 1.0508e-05, 4.2263e-05, 3.9561e-04,
        3.1028e-05], device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:18,930][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.5992, 0.0648, 0.0025, 0.0112, 0.0263, 0.1209, 0.0654, 0.1098],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:18,931][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ the] are: tensor([9.9903e-01, 2.2606e-04, 2.9547e-04, 1.8772e-05, 1.0672e-04, 2.2304e-04,
        4.9328e-05, 5.4006e-05], device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:18,932][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.5785, 0.0867, 0.0021, 0.0206, 0.0409, 0.1525, 0.0664, 0.0522],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:18,934][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ the] are: tensor([8.6013e-01, 1.2162e-01, 1.5654e-06, 1.2811e-04, 1.1016e-04, 1.3465e-02,
        1.9769e-03, 2.5712e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:18,937][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0657, 0.2166, 0.0419, 0.0755, 0.2311, 0.1746, 0.1230, 0.0716],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:18,939][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ the] are: tensor([9.9615e-01, 6.5176e-04, 1.5570e-04, 1.7769e-05, 2.1457e-03, 7.2991e-04,
        6.6688e-05, 8.2610e-05], device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:18,941][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ the] are: tensor([9.3825e-01, 3.2184e-02, 9.0868e-03, 4.4026e-04, 1.2433e-02, 6.0025e-03,
        8.7662e-04, 7.2888e-04], device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:18,944][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ the] are: tensor([9.9916e-01, 3.0107e-04, 2.5703e-04, 2.3699e-05, 5.1519e-05, 1.4589e-04,
        2.5099e-05, 3.4595e-05], device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:18,947][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.9492, 0.0016, 0.0083, 0.0021, 0.0094, 0.0127, 0.0068, 0.0098],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:18,949][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ the] are: tensor([9.9973e-01, 1.1468e-04, 1.4596e-05, 6.2908e-07, 7.6360e-05, 6.2601e-05,
        1.7782e-06, 1.4784e-06], device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:18,951][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ the] are: tensor([1.0000e+00, 1.3036e-06, 1.8559e-07, 1.2559e-06, 5.2183e-07, 5.6989e-07,
        6.4623e-07, 3.1231e-07], device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:18,952][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ the] are: tensor([9.9352e-01, 7.3991e-04, 2.3220e-05, 7.1532e-05, 3.8703e-04, 3.5869e-03,
        4.0435e-04, 1.2662e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:18,953][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ office] are: tensor([9.7752e-01, 8.2307e-04, 4.7842e-05, 1.5917e-04, 8.9450e-04, 1.1529e-02,
        2.1918e-03, 1.8359e-03, 5.0004e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:18,953][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ office] are: tensor([9.9982e-01, 6.5745e-05, 2.8933e-05, 3.3300e-06, 6.2663e-06, 3.6122e-05,
        7.1135e-06, 8.7610e-06, 2.8113e-05], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:18,955][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ office] are: tensor([7.7842e-01, 6.2964e-02, 3.1992e-04, 7.5626e-03, 1.0009e-02, 8.6189e-02,
        2.1006e-02, 1.7351e-02, 1.6178e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:18,957][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ office] are: tensor([9.9113e-01, 8.1749e-03, 1.0733e-08, 4.9443e-06, 1.1890e-06, 3.3745e-04,
        6.4181e-05, 9.9522e-05, 1.8596e-04], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:18,960][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ office] are: tensor([0.0922, 0.0743, 0.0216, 0.0413, 0.1381, 0.1144, 0.0805, 0.0435, 0.3942],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:18,963][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ office] are: tensor([9.9882e-01, 1.7106e-04, 4.5381e-05, 9.9859e-06, 2.5757e-04, 3.2817e-04,
        2.8536e-05, 2.7636e-05, 3.1570e-04], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:18,965][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ office] are: tensor([9.8120e-01, 6.7604e-03, 1.0852e-03, 2.1536e-04, 2.8163e-03, 2.7938e-03,
        3.6236e-04, 4.3234e-04, 4.3350e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:18,967][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ office] are: tensor([9.9957e-01, 2.3350e-04, 3.1565e-05, 9.6095e-06, 8.3747e-06, 5.1863e-05,
        7.8093e-06, 1.1586e-05, 7.8581e-05], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:18,971][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ office] are: tensor([0.9307, 0.0012, 0.0110, 0.0013, 0.0098, 0.0131, 0.0056, 0.0114, 0.0160],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:18,973][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ office] are: tensor([9.9966e-01, 9.9140e-05, 6.6825e-06, 9.8828e-07, 3.7532e-05, 5.2798e-05,
        2.0928e-06, 2.2109e-06, 1.3705e-04], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:18,974][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ office] are: tensor([1.0000e+00, 8.2963e-07, 2.9955e-08, 5.7308e-07, 6.6825e-08, 2.2152e-07,
        2.2681e-07, 1.5429e-07, 1.2714e-07], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:18,975][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ office] are: tensor([9.9925e-01, 8.4876e-05, 1.6830e-06, 6.9822e-06, 1.8517e-05, 3.3309e-04,
        2.7254e-05, 1.1252e-04, 1.6788e-04], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:18,976][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.7139, 0.0211, 0.0008, 0.0034, 0.0074, 0.0587, 0.0275, 0.0465, 0.0311,
        0.0895], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:18,977][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [.] are: tensor([9.9975e-01, 1.5857e-05, 8.3606e-05, 4.6360e-06, 2.8520e-05, 2.9908e-05,
        1.1780e-05, 1.0877e-05, 4.9846e-05, 1.0685e-05], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:18,980][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.9147, 0.0132, 0.0011, 0.0032, 0.0078, 0.0173, 0.0118, 0.0081, 0.0083,
        0.0145], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:18,982][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [.] are: tensor([9.8748e-01, 8.1427e-03, 6.4564e-07, 3.3568e-05, 2.1850e-05, 1.3476e-03,
        2.9018e-04, 4.2470e-04, 9.2944e-04, 1.3310e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:18,987][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.1429, 0.0452, 0.0437, 0.0440, 0.2202, 0.0661, 0.0621, 0.0460, 0.2269,
        0.1029], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:18,989][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [.] are: tensor([9.9930e-01, 6.1625e-05, 3.7594e-05, 5.2739e-06, 2.4054e-04, 1.0716e-04,
        1.4347e-05, 1.3312e-05, 2.0849e-04, 1.2120e-05], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:18,992][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [.] are: tensor([9.9328e-01, 2.4644e-03, 9.9252e-04, 4.8872e-05, 9.5725e-04, 3.8586e-04,
        1.1758e-04, 6.7492e-05, 1.6128e-03, 7.0766e-05], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:18,994][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [.] are: tensor([9.9980e-01, 3.8459e-05, 4.5093e-05, 6.8070e-06, 9.5812e-06, 2.1206e-05,
        5.3996e-06, 5.1667e-06, 6.2541e-05, 3.3369e-06], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:18,996][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [.] are: tensor([9.7362e-01, 2.6435e-04, 4.6343e-03, 5.6936e-04, 3.3879e-03, 2.7193e-03,
        1.3963e-03, 2.3185e-03, 2.8437e-03, 8.2416e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:18,997][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [.] are: tensor([9.9996e-01, 4.5104e-06, 2.1514e-06, 8.4827e-08, 6.8459e-06, 2.9786e-06,
        1.5770e-07, 1.1461e-07, 2.4171e-05, 2.9583e-07], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:18,997][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [.] are: tensor([1.0000e+00, 7.1261e-08, 2.0160e-08, 1.4695e-07, 6.2823e-08, 3.6935e-08,
        5.7201e-08, 1.5873e-08, 4.9511e-08, 1.5271e-06], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:18,998][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [.] are: tensor([9.9909e-01, 3.0698e-05, 5.9564e-06, 7.5604e-06, 3.8888e-05, 3.1853e-04,
        3.2369e-05, 6.8692e-05, 3.6785e-04, 4.2717e-05], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:19,000][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Erica] are: tensor([9.8605e-01, 1.9721e-04, 2.4518e-05, 5.5024e-05, 6.5403e-04, 5.5866e-03,
        6.6148e-04, 6.7308e-04, 4.1291e-03, 1.6761e-03, 2.9702e-04],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:19,002][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Erica] are: tensor([9.9983e-01, 5.4521e-05, 1.3392e-05, 4.1379e-06, 4.7560e-06, 2.0953e-05,
        1.0855e-05, 1.1761e-05, 2.3418e-05, 1.8575e-05, 4.6347e-06],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:19,004][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Erica] are: tensor([7.3141e-01, 7.0966e-02, 2.7764e-04, 1.6845e-02, 7.2906e-03, 3.4734e-02,
        2.4988e-02, 1.7567e-02, 1.0742e-02, 8.4199e-02, 9.7723e-04],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:19,007][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Erica] are: tensor([9.7610e-01, 1.5949e-02, 4.3898e-08, 3.9372e-05, 6.0236e-06, 2.7424e-03,
        3.0882e-04, 5.7293e-04, 1.2229e-03, 2.4818e-03, 5.8019e-04],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:19,010][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Erica] are: tensor([0.0602, 0.0383, 0.0091, 0.0328, 0.0922, 0.0727, 0.0595, 0.0347, 0.3011,
        0.0572, 0.2422], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:19,012][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Erica] are: tensor([9.9713e-01, 5.2183e-04, 5.6567e-05, 3.3435e-05, 1.9917e-04, 8.5081e-04,
        1.0074e-04, 1.2117e-04, 7.1004e-04, 1.3040e-04, 1.4189e-04],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:19,014][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Erica] are: tensor([9.7563e-01, 9.5045e-03, 6.5241e-04, 1.9573e-04, 1.4551e-03, 3.8751e-03,
        9.1588e-04, 6.2108e-04, 5.9828e-03, 8.9416e-04, 2.7269e-04],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:19,017][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Erica] are: tensor([9.9977e-01, 8.7047e-05, 2.3652e-05, 5.0967e-06, 3.4848e-06, 2.5741e-05,
        4.9623e-06, 4.9048e-06, 4.9330e-05, 8.5355e-06, 1.9649e-05],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:19,019][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Erica] are: tensor([0.0672, 0.0313, 0.0069, 0.0042, 0.0310, 0.0789, 0.0334, 0.0929, 0.1044,
        0.2774, 0.2724], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:19,019][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Erica] are: tensor([9.9950e-01, 2.2658e-04, 2.3724e-06, 2.7347e-06, 1.7854e-05, 4.7061e-05,
        6.2894e-06, 7.9299e-06, 1.6222e-04, 2.3429e-05, 1.7781e-06],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:19,020][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Erica] are: tensor([9.9999e-01, 1.9946e-07, 1.9796e-08, 1.6572e-07, 6.4523e-08, 3.6577e-07,
        8.8642e-08, 5.1077e-08, 3.6076e-07, 4.7212e-06, 9.8228e-07],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:19,021][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Erica] are: tensor([9.9639e-01, 1.6517e-04, 1.2548e-05, 2.2547e-05, 1.3278e-04, 1.7524e-03,
        5.8298e-05, 2.6419e-04, 8.9850e-04, 2.1391e-04, 8.8131e-05],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:19,022][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([9.0528e-01, 2.5013e-03, 1.5820e-04, 5.9479e-04, 1.5220e-03, 2.7520e-02,
        5.7258e-03, 7.3382e-03, 9.6491e-03, 1.3523e-02, 9.4954e-04, 2.5234e-02],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:19,025][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([9.9937e-01, 9.3681e-05, 6.0619e-05, 6.1710e-06, 2.2150e-05, 6.4217e-05,
        1.6846e-05, 1.9694e-05, 9.7011e-05, 2.1769e-05, 4.0303e-05, 1.8386e-04],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:19,028][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.5547, 0.0880, 0.0040, 0.0144, 0.0241, 0.0545, 0.0297, 0.0302, 0.0389,
        0.1034, 0.0157, 0.0423], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:19,030][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([9.9438e-01, 2.5901e-03, 1.1522e-08, 2.8417e-06, 1.0376e-06, 2.2021e-04,
        3.8765e-05, 5.5816e-05, 1.4383e-04, 3.9824e-04, 2.0875e-04, 1.9575e-03],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:19,034][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.0084, 0.0442, 0.0137, 0.0252, 0.0773, 0.0663, 0.0453, 0.0229, 0.2082,
        0.0352, 0.2831, 0.1703], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:19,037][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([9.8815e-01, 1.3562e-03, 3.4733e-04, 6.6973e-05, 1.7090e-03, 2.0789e-03,
        2.6513e-04, 2.4642e-04, 3.5614e-03, 1.2176e-04, 9.0271e-04, 1.1982e-03],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:19,039][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([9.5422e-01, 1.5306e-02, 2.9167e-03, 2.5004e-04, 4.8201e-03, 2.7496e-03,
        6.9659e-04, 4.8958e-04, 1.2708e-02, 5.4497e-04, 1.2838e-03, 4.0138e-03],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:19,041][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([9.9808e-01, 4.3240e-04, 2.0375e-04, 5.4913e-05, 3.7900e-05, 1.3801e-04,
        5.8075e-05, 9.8506e-05, 4.7889e-04, 3.0023e-05, 9.6438e-05, 2.8742e-04],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:19,042][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.4707, 0.0070, 0.0173, 0.0025, 0.0229, 0.0294, 0.0162, 0.0332, 0.0384,
        0.0663, 0.2045, 0.0916], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:19,043][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([9.9904e-01, 1.9756e-04, 1.5612e-05, 2.6431e-06, 6.4640e-05, 9.8742e-05,
        6.8290e-06, 6.3679e-06, 4.2230e-04, 1.5430e-05, 1.0967e-05, 1.1631e-04],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:19,044][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([1.0000e+00, 2.1933e-07, 4.1923e-08, 1.1987e-07, 7.0635e-08, 1.4864e-07,
        7.9234e-08, 5.7507e-08, 1.9552e-07, 1.2766e-06, 9.8577e-07, 8.9509e-07],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:19,045][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([9.9876e-01, 3.5632e-05, 2.3757e-06, 1.1679e-05, 1.7441e-05, 1.2513e-04,
        2.1311e-05, 7.1686e-05, 2.2543e-04, 4.3680e-05, 3.0115e-05, 6.5957e-04],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:19,048][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.3371, 0.0380, 0.0019, 0.0105, 0.0173, 0.1239, 0.0404, 0.0766, 0.0665,
        0.1213, 0.0075, 0.1040, 0.0550], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:19,050][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ a] are: tensor([9.9919e-01, 5.6425e-05, 9.7824e-05, 8.2184e-06, 4.4009e-05, 1.0545e-04,
        1.5945e-05, 2.2410e-05, 1.1549e-04, 2.0247e-05, 5.6683e-05, 2.6184e-04,
        5.3786e-06], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:19,054][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.6258, 0.0377, 0.0022, 0.0095, 0.0192, 0.1031, 0.0279, 0.0241, 0.0348,
        0.0623, 0.0100, 0.0371, 0.0062], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:19,057][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ a] are: tensor([9.7300e-01, 1.0507e-02, 3.2357e-07, 3.1861e-05, 1.3869e-05, 1.1303e-03,
        2.7822e-04, 3.2192e-04, 7.4490e-04, 8.7375e-04, 1.4425e-03, 1.1636e-02,
        1.9560e-05], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:19,061][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0148, 0.0317, 0.0151, 0.0229, 0.0945, 0.0614, 0.0379, 0.0295, 0.1266,
        0.0365, 0.3857, 0.1062, 0.0371], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:19,063][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ a] are: tensor([9.9755e-01, 2.2165e-04, 3.8827e-05, 8.2909e-06, 4.3450e-04, 6.4533e-04,
        2.3789e-05, 3.3468e-05, 5.9239e-04, 1.8581e-05, 1.1608e-04, 2.8611e-04,
        3.3902e-05], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:19,064][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ a] are: tensor([9.7338e-01, 5.0252e-03, 1.8227e-03, 1.6493e-04, 4.4096e-03, 2.6031e-03,
        2.6824e-04, 4.0843e-04, 7.0207e-03, 2.2900e-04, 6.4005e-04, 3.5765e-03,
        4.5525e-04], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:19,065][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ a] are: tensor([9.9948e-01, 9.4293e-05, 5.7631e-05, 8.7247e-06, 1.6010e-05, 4.7912e-05,
        7.2016e-06, 1.1021e-05, 1.3083e-04, 4.4359e-06, 3.9505e-05, 9.7071e-05,
        7.2107e-06], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:19,066][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.3916, 0.0220, 0.0150, 0.0053, 0.0255, 0.0505, 0.0275, 0.0448, 0.0592,
        0.0811, 0.1604, 0.0830, 0.0342], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:19,067][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ a] are: tensor([9.9985e-01, 1.2871e-05, 2.4742e-06, 1.9523e-07, 1.1458e-05, 2.3595e-05,
        4.1377e-07, 5.1794e-07, 6.9363e-05, 1.0555e-06, 1.1258e-06, 2.1948e-05,
        5.7056e-07], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:19,069][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ a] are: tensor([9.9999e-01, 9.4887e-07, 1.9474e-07, 8.9602e-07, 1.4670e-07, 3.0839e-07,
        2.2920e-07, 1.5117e-07, 5.2222e-07, 4.5269e-06, 1.9475e-06, 9.4421e-07,
        7.0152e-08], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:19,072][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ a] are: tensor([9.9391e-01, 1.6092e-04, 1.5748e-05, 3.4956e-05, 1.4320e-04, 1.0713e-03,
        9.9929e-05, 3.0369e-04, 8.5921e-04, 1.7075e-04, 1.4438e-04, 2.7982e-03,
        2.8999e-04], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:19,074][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ basketball] are: tensor([9.2460e-01, 1.6488e-03, 1.2207e-04, 3.8216e-04, 1.8713e-03, 2.9032e-02,
        3.5740e-03, 5.0470e-03, 7.5624e-03, 8.6886e-03, 9.6093e-04, 1.2773e-02,
        3.2568e-03, 4.8497e-04], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:19,077][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ basketball] are: tensor([9.9902e-01, 5.6667e-05, 8.3198e-05, 1.0384e-05, 1.7417e-05, 8.7760e-05,
        1.5383e-05, 2.8399e-05, 7.5868e-05, 3.3576e-05, 3.7876e-05, 4.0462e-04,
        1.1287e-05, 1.1996e-04], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:19,079][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ basketball] are: tensor([7.1342e-01, 3.0432e-02, 7.1201e-04, 5.8740e-03, 6.1037e-03, 3.5360e-02,
        1.2625e-02, 1.4304e-02, 1.4187e-02, 3.8859e-02, 1.5930e-03, 3.0913e-02,
        7.2375e-03, 8.8383e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:19,081][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ basketball] are: tensor([9.9473e-01, 3.7755e-04, 1.6177e-08, 1.5512e-06, 5.4006e-07, 6.0391e-05,
        1.4707e-05, 1.3648e-05, 4.3828e-05, 1.4533e-04, 6.9473e-05, 9.9050e-04,
        5.3932e-06, 3.5492e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:19,085][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ basketball] are: tensor([0.0261, 0.0103, 0.0077, 0.0108, 0.0385, 0.0529, 0.0256, 0.0184, 0.1523,
        0.0148, 0.0593, 0.1614, 0.0263, 0.3956], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:19,087][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ basketball] are: tensor([9.9827e-01, 3.4475e-05, 3.3597e-05, 6.0720e-06, 1.3217e-04, 2.6123e-04,
        2.3348e-05, 3.7491e-05, 3.2362e-04, 1.1857e-05, 4.9046e-05, 3.9198e-04,
        3.5106e-05, 3.8950e-04], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:19,087][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ basketball] are: tensor([9.7324e-01, 2.3639e-03, 8.7653e-04, 1.1993e-04, 2.0932e-03, 1.5985e-03,
        2.4879e-04, 3.3582e-04, 2.3746e-03, 2.2220e-04, 2.1814e-04, 4.4611e-03,
        5.4680e-04, 1.1305e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:19,088][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ basketball] are: tensor([9.9886e-01, 8.2492e-05, 2.5898e-05, 8.1695e-06, 7.7724e-06, 2.9700e-05,
        7.5905e-06, 8.6189e-06, 6.5276e-05, 3.7194e-06, 1.2649e-05, 7.6117e-05,
        7.8141e-06, 8.0274e-04], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:19,089][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ basketball] are: tensor([7.6980e-01, 6.3231e-04, 1.2072e-02, 8.0415e-04, 7.6056e-03, 6.8867e-03,
        3.5348e-03, 6.8956e-03, 9.0680e-03, 1.0882e-02, 8.9235e-02, 2.5337e-02,
        2.3551e-02, 3.3699e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:19,090][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ basketball] are: tensor([9.9918e-01, 5.2124e-05, 4.6371e-06, 8.4369e-07, 2.8046e-05, 3.8054e-05,
        1.7576e-06, 2.4541e-06, 1.3218e-04, 4.0433e-06, 1.8831e-06, 2.5856e-04,
        2.4483e-06, 2.9521e-04], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:19,093][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ basketball] are: tensor([9.9999e-01, 9.1478e-08, 5.2927e-08, 1.3331e-07, 2.7264e-08, 1.4080e-07,
        1.1602e-07, 5.1335e-08, 9.1158e-08, 1.4572e-06, 9.3471e-07, 5.8319e-07,
        3.5311e-08, 4.9014e-06], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:19,095][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ basketball] are: tensor([9.9760e-01, 3.5861e-05, 5.3657e-06, 1.2557e-05, 1.6434e-05, 2.1501e-04,
        4.2239e-05, 7.8376e-05, 1.4880e-04, 7.4746e-05, 2.0240e-05, 7.5296e-04,
        1.8674e-04, 8.1443e-04], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:19,098][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.4901, 0.0326, 0.0012, 0.0058, 0.0103, 0.0834, 0.0427, 0.0551, 0.0410,
        0.0912, 0.0044, 0.0702, 0.0403, 0.0021, 0.0297], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:19,101][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ to] are: tensor([9.9975e-01, 2.1780e-05, 3.9165e-05, 2.2651e-06, 5.8030e-06, 2.5033e-05,
        5.0294e-06, 6.1122e-06, 2.1861e-05, 5.5802e-06, 1.1387e-05, 5.1356e-05,
        1.5743e-06, 5.2671e-05, 1.6014e-06], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:19,105][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.6837, 0.0265, 0.0017, 0.0052, 0.0070, 0.0575, 0.0168, 0.0137, 0.0140,
        0.0275, 0.0026, 0.0247, 0.0054, 0.1077, 0.0060], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:19,107][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ to] are: tensor([9.7607e-01, 3.0580e-03, 1.6706e-07, 9.7013e-06, 3.4415e-06, 4.1635e-04,
        5.0940e-05, 8.3651e-05, 1.6734e-04, 2.4929e-04, 4.2110e-04, 4.0293e-03,
        8.0306e-06, 1.5402e-02, 2.8419e-05], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:19,109][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0196, 0.0255, 0.0095, 0.0142, 0.0441, 0.0296, 0.0248, 0.0172, 0.0774,
        0.0290, 0.2002, 0.0728, 0.0270, 0.3396, 0.0696], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:19,110][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ to] are: tensor([9.9919e-01, 7.9175e-05, 2.2486e-05, 3.6870e-06, 9.1070e-05, 9.2199e-05,
        9.6848e-06, 1.1851e-05, 1.1693e-04, 6.2168e-06, 3.9455e-05, 5.7618e-05,
        8.9892e-06, 2.5968e-04, 9.5120e-06], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:19,111][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ to] are: tensor([9.7631e-01, 7.5918e-03, 1.3183e-03, 1.3298e-04, 1.2786e-03, 1.2671e-03,
        2.1990e-04, 2.6243e-04, 2.4855e-03, 1.6670e-04, 2.5465e-04, 1.2163e-03,
        2.6052e-04, 7.0733e-03, 1.5861e-04], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:19,112][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ to] are: tensor([9.9945e-01, 3.1013e-05, 2.5453e-05, 3.0781e-06, 3.3237e-06, 1.0799e-05,
        2.7410e-06, 3.3183e-06, 2.6761e-05, 1.3885e-06, 7.1839e-06, 1.4144e-05,
        2.7383e-06, 4.2024e-04, 1.8078e-06], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:19,114][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.1068, 0.0605, 0.0098, 0.0047, 0.0281, 0.0633, 0.0342, 0.0819, 0.0676,
        0.1109, 0.1033, 0.1153, 0.0464, 0.1501, 0.0170], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:19,116][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ to] are: tensor([9.9986e-01, 1.4780e-05, 3.7300e-06, 1.9701e-07, 8.6759e-06, 1.0246e-05,
        3.4702e-07, 3.0189e-07, 2.9762e-05, 6.5402e-07, 9.4882e-07, 1.4082e-05,
        3.7712e-07, 5.4053e-05, 2.4657e-07], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:19,119][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ to] are: tensor([1.0000e+00, 5.7994e-08, 2.2991e-08, 6.5224e-08, 3.1540e-08, 3.8683e-08,
        1.7815e-08, 6.6596e-09, 3.4081e-08, 3.1486e-07, 2.1662e-07, 1.0073e-07,
        3.9504e-09, 3.5878e-07, 3.9861e-08], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:19,121][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ to] are: tensor([9.9749e-01, 5.3094e-05, 9.0669e-06, 1.0826e-05, 4.7024e-05, 2.7953e-04,
        2.4584e-05, 7.0468e-05, 2.1016e-04, 4.1808e-05, 5.3525e-05, 6.2634e-04,
        6.3562e-05, 9.7230e-04, 4.6593e-05], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:19,234][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:24:19,235][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:19,235][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:19,236][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:19,237][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:19,237][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:19,238][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:19,239][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:19,239][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:19,240][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:19,241][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:19,241][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:19,242][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:19,243][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.9978, 0.0022], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:19,243][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([1.0000e+00, 4.3128e-06], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:19,246][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.9936, 0.0064], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:19,247][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.9965, 0.0035], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:19,248][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.9196, 0.0804], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:19,248][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([9.9995e-01, 4.5924e-05], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:19,249][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([9.9911e-01, 8.8912e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:19,250][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([9.9996e-01, 3.5344e-05], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:19,253][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.4738, 0.5262], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:19,255][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([1.0000e+00, 3.4678e-06], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:19,257][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([1.0000e+00, 5.2972e-09], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:19,260][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([9.9998e-01, 1.5608e-05], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:19,264][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Erica] are: tensor([0.9774, 0.0178, 0.0048], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:19,266][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Erica] are: tensor([9.9984e-01, 1.1602e-04, 4.0751e-05], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:19,269][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Erica] are: tensor([8.4983e-01, 1.4960e-01, 5.6475e-04], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:19,269][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Erica] are: tensor([2.9287e-01, 7.0712e-01, 3.1179e-06], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:19,270][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Erica] are: tensor([0.1246, 0.6972, 0.1782], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:19,271][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Erica] are: tensor([9.9786e-01, 1.8408e-03, 3.0329e-04], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:19,271][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Erica] are: tensor([0.9641, 0.0321, 0.0038], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:19,273][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Erica] are: tensor([9.9957e-01, 3.5507e-04, 7.6076e-05], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:19,275][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Erica] are: tensor([0.1465, 0.7586, 0.0949], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:19,277][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Erica] are: tensor([9.9972e-01, 2.7082e-04, 7.0405e-06], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:19,280][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Erica] are: tensor([9.9999e-01, 5.9365e-06, 3.4277e-07], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:19,282][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Erica] are: tensor([9.8979e-01, 9.3231e-03, 8.8783e-04], device='cuda:0') for source tokens [Then, Erica]
[2024-07-24 10:24:19,284][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([9.8995e-01, 4.4600e-03, 8.5956e-04, 4.7332e-03], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:19,286][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([9.9996e-01, 1.2322e-05, 2.8883e-05, 1.2967e-06], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:19,290][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.9665, 0.0218, 0.0019, 0.0097], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:19,291][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([9.3449e-01, 6.5439e-02, 2.2335e-06, 6.7562e-05], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:19,292][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.4037, 0.2630, 0.0705, 0.2627], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:19,293][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([9.9991e-01, 4.4864e-05, 4.2850e-05, 5.8335e-06], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:19,294][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([9.9716e-01, 2.1406e-03, 6.3328e-04, 6.1212e-05], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:19,294][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([9.9989e-01, 3.8736e-05, 5.8495e-05, 1.2162e-05], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:19,296][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.9056, 0.0789, 0.0109, 0.0046], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:19,298][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([9.9999e-01, 9.0105e-06, 3.1890e-06, 2.5214e-07], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:19,300][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([1.0000e+00, 1.1433e-07, 1.9757e-08, 1.5494e-07], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:19,302][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([9.9990e-01, 7.4926e-05, 5.9449e-06, 1.6154e-05], device='cuda:0') for source tokens [Then, Erica and]
[2024-07-24 10:24:19,305][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Joshua] are: tensor([9.8037e-01, 6.4822e-03, 7.6626e-04, 8.5775e-03, 3.7996e-03],
       device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:19,307][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Joshua] are: tensor([9.9990e-01, 8.0996e-05, 1.3217e-05, 3.1406e-06, 4.8103e-06],
       device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:19,309][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Joshua] are: tensor([9.0841e-01, 6.6093e-02, 5.9872e-04, 1.3857e-02, 1.1038e-02],
       device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:19,311][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Joshua] are: tensor([7.5715e-01, 2.4250e-01, 3.7828e-07, 2.2869e-04, 1.2714e-04],
       device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:19,314][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Joshua] are: tensor([0.2436, 0.1761, 0.0246, 0.1242, 0.4316], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:19,315][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Joshua] are: tensor([9.9808e-01, 7.6731e-04, 1.3646e-04, 4.8581e-05, 9.6442e-04],
       device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:19,315][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Joshua] are: tensor([9.8968e-01, 7.9294e-03, 8.6306e-04, 1.6213e-04, 1.3669e-03],
       device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:19,316][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Joshua] are: tensor([9.9979e-01, 1.5957e-04, 2.3446e-05, 9.4547e-06, 1.2803e-05],
       device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:19,317][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Joshua] are: tensor([0.7473, 0.1523, 0.0243, 0.0168, 0.0593], device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:19,318][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Joshua] are: tensor([9.9990e-01, 6.9681e-05, 2.8574e-06, 8.2704e-07, 2.1841e-05],
       device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:19,320][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Joshua] are: tensor([1.0000e+00, 8.3355e-07, 5.8765e-08, 3.4679e-07, 6.3716e-07],
       device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:19,322][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Joshua] are: tensor([9.9637e-01, 2.3601e-03, 5.5891e-05, 2.7144e-04, 9.4041e-04],
       device='cuda:0') for source tokens [Then, Erica and Joshua]
[2024-07-24 10:24:19,325][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([9.7244e-01, 4.8892e-03, 5.5422e-04, 3.4068e-03, 8.9213e-04, 1.7814e-02],
       device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:19,327][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([9.9974e-01, 1.1645e-04, 5.7511e-05, 7.0394e-06, 1.4195e-05, 6.2844e-05],
       device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:19,330][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([0.7281, 0.1727, 0.0015, 0.0224, 0.0257, 0.0496], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:19,333][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([9.8799e-01, 1.0759e-02, 1.4907e-08, 1.7797e-05, 6.7497e-06, 1.2295e-03],
       device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:19,337][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([0.1063, 0.1752, 0.0552, 0.1036, 0.3205, 0.2392], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:19,337][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([9.9454e-01, 8.9398e-04, 2.2745e-04, 6.1534e-05, 2.5673e-03, 1.7116e-03],
       device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:19,338][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([9.8359e-01, 9.4071e-03, 8.4976e-04, 3.3278e-04, 2.5643e-03, 3.2577e-03],
       device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:19,339][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([9.9839e-01, 5.6679e-04, 2.4015e-04, 7.8798e-05, 1.1913e-04, 6.0928e-04],
       device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:19,339][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([0.6796, 0.1212, 0.0093, 0.0050, 0.0183, 0.1667], device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:19,341][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([9.9981e-01, 1.2448e-04, 6.0383e-06, 2.0683e-06, 3.6123e-05, 2.4979e-05],
       device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:19,343][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([1.0000e+00, 2.3266e-07, 1.6502e-08, 1.7126e-07, 5.0141e-08, 1.9372e-07],
       device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:19,345][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([9.9595e-01, 4.7248e-04, 1.8081e-05, 8.4504e-05, 2.9288e-04, 3.1853e-03],
       device='cuda:0') for source tokens [Then, Erica and Joshua went]
[2024-07-24 10:24:19,348][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.9055, 0.0098, 0.0015, 0.0073, 0.0016, 0.0388, 0.0356],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:19,350][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([9.9992e-01, 2.1405e-05, 2.8085e-05, 1.5283e-06, 5.0604e-06, 1.8273e-05,
        3.9122e-06], device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:19,354][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.7686, 0.0371, 0.0011, 0.0118, 0.0163, 0.1233, 0.0418],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:19,357][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([9.8374e-01, 1.4437e-02, 1.6669e-07, 1.7915e-05, 7.6307e-06, 1.6573e-03,
        1.3934e-04], device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:19,359][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.1462, 0.1823, 0.0427, 0.0909, 0.2292, 0.1563, 0.1524],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:19,360][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([9.9961e-01, 8.9907e-05, 2.6705e-05, 4.8873e-06, 1.7321e-04, 8.2977e-05,
        1.3474e-05], device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:19,360][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([9.8667e-01, 7.1763e-03, 1.8537e-03, 1.5417e-04, 2.2619e-03, 1.6059e-03,
        2.7644e-04], device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:19,361][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([9.9991e-01, 3.0029e-05, 3.0791e-05, 3.9319e-06, 4.9439e-06, 1.6431e-05,
        3.8825e-06], device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:19,362][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.1590, 0.4506, 0.0264, 0.0186, 0.0528, 0.2481, 0.0443],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:19,363][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([9.9991e-01, 3.4871e-05, 7.0165e-06, 6.1659e-07, 2.2015e-05, 2.2712e-05,
        1.2058e-06], device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:19,365][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([1.0000e+00, 5.3202e-08, 1.1028e-08, 6.0504e-08, 2.4553e-08, 4.1012e-08,
        2.2495e-08], device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:19,367][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([9.9946e-01, 5.3154e-05, 4.6041e-06, 1.0508e-05, 4.2263e-05, 3.9561e-04,
        3.1028e-05], device='cuda:0') for source tokens [Then, Erica and Joshua went to]
[2024-07-24 10:24:19,371][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.7999, 0.0072, 0.0019, 0.0102, 0.0024, 0.0438, 0.0567, 0.0779],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:19,373][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([9.9903e-01, 2.2606e-04, 2.9547e-04, 1.8772e-05, 1.0672e-04, 2.2304e-04,
        4.9328e-05, 5.4006e-05], device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:19,377][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.5785, 0.0867, 0.0021, 0.0206, 0.0409, 0.1525, 0.0664, 0.0522],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:19,379][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([8.6013e-01, 1.2162e-01, 1.5654e-06, 1.2811e-04, 1.1016e-04, 1.3465e-02,
        1.9769e-03, 2.5712e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:19,381][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0657, 0.2166, 0.0419, 0.0755, 0.2311, 0.1746, 0.1230, 0.0716],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:19,382][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([9.9615e-01, 6.5176e-04, 1.5570e-04, 1.7769e-05, 2.1457e-03, 7.2991e-04,
        6.6688e-05, 8.2610e-05], device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:19,383][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([9.3825e-01, 3.2184e-02, 9.0868e-03, 4.4026e-04, 1.2433e-02, 6.0025e-03,
        8.7662e-04, 7.2888e-04], device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:19,384][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([9.9916e-01, 3.0107e-04, 2.5703e-04, 2.3699e-05, 5.1519e-05, 1.4589e-04,
        2.5099e-05, 3.4595e-05], device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:19,385][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.7487, 0.0791, 0.0097, 0.0059, 0.0181, 0.0950, 0.0150, 0.0286],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:19,387][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([9.9973e-01, 1.1468e-04, 1.4596e-05, 6.2908e-07, 7.6360e-05, 6.2601e-05,
        1.7782e-06, 1.4784e-06], device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:19,390][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([1.0000e+00, 1.3036e-06, 1.8559e-07, 1.2559e-06, 5.2183e-07, 5.6989e-07,
        6.4623e-07, 3.1231e-07], device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:19,392][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([9.9352e-01, 7.3991e-04, 2.3220e-05, 7.1532e-05, 3.8703e-04, 3.5869e-03,
        4.0435e-04, 1.2662e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to the]
[2024-07-24 10:24:19,394][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ office] are: tensor([9.2838e-01, 3.6680e-03, 7.3859e-04, 3.3196e-03, 1.4046e-03, 2.1771e-02,
        1.5575e-02, 1.4865e-02, 1.0282e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:19,397][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ office] are: tensor([9.9982e-01, 6.5745e-05, 2.8933e-05, 3.3300e-06, 6.2663e-06, 3.6122e-05,
        7.1135e-06, 8.7610e-06, 2.8113e-05], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:19,399][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ office] are: tensor([7.7842e-01, 6.2964e-02, 3.1992e-04, 7.5626e-03, 1.0009e-02, 8.6189e-02,
        2.1006e-02, 1.7351e-02, 1.6178e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:19,402][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ office] are: tensor([9.9113e-01, 8.1749e-03, 1.0733e-08, 4.9443e-06, 1.1890e-06, 3.3745e-04,
        6.4181e-05, 9.9522e-05, 1.8596e-04], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:19,404][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ office] are: tensor([0.0922, 0.0743, 0.0216, 0.0413, 0.1381, 0.1144, 0.0805, 0.0435, 0.3942],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:19,405][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ office] are: tensor([9.9882e-01, 1.7106e-04, 4.5381e-05, 9.9859e-06, 2.5757e-04, 3.2817e-04,
        2.8536e-05, 2.7636e-05, 3.1570e-04], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:19,405][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ office] are: tensor([9.8120e-01, 6.7604e-03, 1.0852e-03, 2.1536e-04, 2.8163e-03, 2.7938e-03,
        3.6236e-04, 4.3234e-04, 4.3350e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:19,406][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ office] are: tensor([9.9957e-01, 2.3350e-04, 3.1565e-05, 9.6095e-06, 8.3747e-06, 5.1863e-05,
        7.8093e-06, 1.1586e-05, 7.8581e-05], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:19,408][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ office] are: tensor([0.7508, 0.0783, 0.0101, 0.0032, 0.0129, 0.0780, 0.0082, 0.0277, 0.0309],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:19,410][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ office] are: tensor([9.9966e-01, 9.9140e-05, 6.6825e-06, 9.8828e-07, 3.7532e-05, 5.2798e-05,
        2.0928e-06, 2.2109e-06, 1.3705e-04], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:19,412][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ office] are: tensor([1.0000e+00, 8.2963e-07, 2.9955e-08, 5.7308e-07, 6.6825e-08, 2.2152e-07,
        2.2681e-07, 1.5429e-07, 1.2714e-07], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:19,414][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ office] are: tensor([9.9925e-01, 8.4876e-05, 1.6830e-06, 6.9822e-06, 1.8517e-05, 3.3309e-04,
        2.7254e-05, 1.1252e-04, 1.6788e-04], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office]
[2024-07-24 10:24:19,417][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([8.5340e-01, 2.8661e-03, 6.1943e-04, 4.3684e-03, 9.3586e-04, 1.3241e-02,
        2.1096e-02, 2.4439e-02, 8.0530e-03, 7.0983e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:19,419][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([9.9975e-01, 1.5857e-05, 8.3606e-05, 4.6360e-06, 2.8520e-05, 2.9908e-05,
        1.1780e-05, 1.0877e-05, 4.9846e-05, 1.0685e-05], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:19,422][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.9147, 0.0132, 0.0011, 0.0032, 0.0078, 0.0173, 0.0118, 0.0081, 0.0083,
        0.0145], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:19,425][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([9.8748e-01, 8.1427e-03, 6.4564e-07, 3.3568e-05, 2.1850e-05, 1.3476e-03,
        2.9018e-04, 4.2470e-04, 9.2944e-04, 1.3310e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:19,426][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.1429, 0.0452, 0.0437, 0.0440, 0.2202, 0.0661, 0.0621, 0.0460, 0.2269,
        0.1029], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:19,427][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([9.9930e-01, 6.1625e-05, 3.7594e-05, 5.2739e-06, 2.4054e-04, 1.0716e-04,
        1.4347e-05, 1.3312e-05, 2.0849e-04, 1.2120e-05], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:19,428][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([9.9328e-01, 2.4644e-03, 9.9252e-04, 4.8872e-05, 9.5725e-04, 3.8586e-04,
        1.1758e-04, 6.7492e-05, 1.6128e-03, 7.0766e-05], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:19,429][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([9.9980e-01, 3.8459e-05, 4.5093e-05, 6.8070e-06, 9.5812e-06, 2.1206e-05,
        5.3996e-06, 5.1667e-06, 6.2541e-05, 3.3369e-06], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:19,431][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.8819, 0.0208, 0.0099, 0.0025, 0.0113, 0.0303, 0.0034, 0.0089, 0.0072,
        0.0237], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:19,433][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([9.9996e-01, 4.5104e-06, 2.1514e-06, 8.4827e-08, 6.8459e-06, 2.9786e-06,
        1.5770e-07, 1.1461e-07, 2.4171e-05, 2.9583e-07], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:19,435][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([1.0000e+00, 7.1261e-08, 2.0160e-08, 1.4695e-07, 6.2823e-08, 3.6935e-08,
        5.7201e-08, 1.5873e-08, 4.9511e-08, 1.5271e-06], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:19,438][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([9.9909e-01, 3.0698e-05, 5.9564e-06, 7.5604e-06, 3.8888e-05, 3.1853e-04,
        3.2369e-05, 6.8692e-05, 3.6785e-04, 4.2717e-05], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office.]
[2024-07-24 10:24:19,440][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Erica] are: tensor([8.2129e-01, 1.3933e-03, 2.5509e-04, 3.6513e-03, 1.0936e-03, 2.0127e-02,
        3.5569e-02, 3.1406e-02, 5.8616e-03, 7.0780e-02, 8.5685e-03],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:19,442][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Erica] are: tensor([9.9983e-01, 5.4521e-05, 1.3392e-05, 4.1379e-06, 4.7560e-06, 2.0953e-05,
        1.0855e-05, 1.1761e-05, 2.3418e-05, 1.8575e-05, 4.6347e-06],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:19,445][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Erica] are: tensor([7.3141e-01, 7.0966e-02, 2.7764e-04, 1.6845e-02, 7.2906e-03, 3.4734e-02,
        2.4988e-02, 1.7567e-02, 1.0742e-02, 8.4199e-02, 9.7723e-04],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:19,447][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Erica] are: tensor([9.7610e-01, 1.5949e-02, 4.3898e-08, 3.9372e-05, 6.0236e-06, 2.7424e-03,
        3.0882e-04, 5.7293e-04, 1.2229e-03, 2.4818e-03, 5.8019e-04],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:19,449][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Erica] are: tensor([0.0602, 0.0383, 0.0091, 0.0328, 0.0922, 0.0727, 0.0595, 0.0347, 0.3011,
        0.0572, 0.2422], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:19,450][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Erica] are: tensor([9.9713e-01, 5.2183e-04, 5.6567e-05, 3.3435e-05, 1.9917e-04, 8.5081e-04,
        1.0074e-04, 1.2117e-04, 7.1004e-04, 1.3040e-04, 1.4189e-04],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:19,451][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Erica] are: tensor([9.7563e-01, 9.5045e-03, 6.5241e-04, 1.9573e-04, 1.4551e-03, 3.8751e-03,
        9.1588e-04, 6.2108e-04, 5.9828e-03, 8.9416e-04, 2.7269e-04],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:19,451][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Erica] are: tensor([9.9977e-01, 8.7047e-05, 2.3652e-05, 5.0967e-06, 3.4848e-06, 2.5741e-05,
        4.9623e-06, 4.9048e-06, 4.9330e-05, 8.5355e-06, 1.9649e-05],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:19,453][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Erica] are: tensor([0.2643, 0.1014, 0.0157, 0.0123, 0.0364, 0.1258, 0.0148, 0.0478, 0.0503,
        0.1480, 0.1833], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:19,455][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Erica] are: tensor([9.9950e-01, 2.2658e-04, 2.3724e-06, 2.7347e-06, 1.7854e-05, 4.7061e-05,
        6.2894e-06, 7.9299e-06, 1.6222e-04, 2.3429e-05, 1.7781e-06],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:19,458][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Erica] are: tensor([9.9999e-01, 1.9946e-07, 1.9796e-08, 1.6572e-07, 6.4523e-08, 3.6577e-07,
        8.8642e-08, 5.1077e-08, 3.6076e-07, 4.7212e-06, 9.8228e-07],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:19,460][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Erica] are: tensor([9.9639e-01, 1.6517e-04, 1.2548e-05, 2.2547e-05, 1.3278e-04, 1.7524e-03,
        5.8298e-05, 2.6419e-04, 8.9850e-04, 2.1391e-04, 8.8131e-05],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica]
[2024-07-24 10:24:19,463][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([8.9332e-01, 1.9776e-03, 6.5293e-04, 1.3148e-03, 9.2004e-04, 7.8811e-03,
        4.9313e-03, 5.5368e-03, 2.3963e-03, 3.1694e-02, 7.3662e-03, 4.2009e-02],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:19,465][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([9.9937e-01, 9.3681e-05, 6.0619e-05, 6.1710e-06, 2.2150e-05, 6.4217e-05,
        1.6846e-05, 1.9694e-05, 9.7011e-05, 2.1769e-05, 4.0303e-05, 1.8386e-04],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:19,469][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.5547, 0.0880, 0.0040, 0.0144, 0.0241, 0.0545, 0.0297, 0.0302, 0.0389,
        0.1034, 0.0157, 0.0423], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:19,472][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([9.9438e-01, 2.5901e-03, 1.1522e-08, 2.8417e-06, 1.0376e-06, 2.2021e-04,
        3.8765e-05, 5.5816e-05, 1.4383e-04, 3.9824e-04, 2.0875e-04, 1.9575e-03],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:19,473][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.0084, 0.0442, 0.0137, 0.0252, 0.0773, 0.0663, 0.0453, 0.0229, 0.2082,
        0.0352, 0.2831, 0.1703], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:19,474][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([9.8815e-01, 1.3562e-03, 3.4733e-04, 6.6973e-05, 1.7090e-03, 2.0789e-03,
        2.6513e-04, 2.4642e-04, 3.5614e-03, 1.2176e-04, 9.0271e-04, 1.1982e-03],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:19,475][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([9.5422e-01, 1.5306e-02, 2.9167e-03, 2.5004e-04, 4.8201e-03, 2.7496e-03,
        6.9659e-04, 4.8958e-04, 1.2708e-02, 5.4497e-04, 1.2838e-03, 4.0138e-03],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:19,476][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([9.9808e-01, 4.3240e-04, 2.0375e-04, 5.4913e-05, 3.7900e-05, 1.3801e-04,
        5.8075e-05, 9.8506e-05, 4.7889e-04, 3.0023e-05, 9.6438e-05, 2.8742e-04],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:19,478][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.4848, 0.1082, 0.0126, 0.0041, 0.0188, 0.0555, 0.0107, 0.0239, 0.0266,
        0.0433, 0.0710, 0.1404], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:19,480][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([9.9904e-01, 1.9756e-04, 1.5612e-05, 2.6431e-06, 6.4640e-05, 9.8742e-05,
        6.8290e-06, 6.3679e-06, 4.2230e-04, 1.5430e-05, 1.0967e-05, 1.1631e-04],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:19,482][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([1.0000e+00, 2.1933e-07, 4.1923e-08, 1.1987e-07, 7.0635e-08, 1.4864e-07,
        7.9234e-08, 5.7507e-08, 1.9552e-07, 1.2766e-06, 9.8577e-07, 8.9509e-07],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:19,485][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([9.9876e-01, 3.5632e-05, 2.3757e-06, 1.1679e-05, 1.7441e-05, 1.2513e-04,
        2.1311e-05, 7.1686e-05, 2.2543e-04, 4.3680e-05, 3.0115e-05, 6.5957e-04],
       device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave]
[2024-07-24 10:24:19,489][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.6616, 0.0026, 0.0024, 0.0059, 0.0033, 0.0299, 0.0423, 0.0341, 0.0163,
        0.0624, 0.0198, 0.0884, 0.0310], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:19,491][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([9.9919e-01, 5.6425e-05, 9.7824e-05, 8.2184e-06, 4.4009e-05, 1.0545e-04,
        1.5945e-05, 2.2410e-05, 1.1549e-04, 2.0247e-05, 5.6683e-05, 2.6184e-04,
        5.3786e-06], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:19,495][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.6258, 0.0377, 0.0022, 0.0095, 0.0192, 0.1031, 0.0279, 0.0241, 0.0348,
        0.0623, 0.0100, 0.0371, 0.0062], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:19,496][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([9.7300e-01, 1.0507e-02, 3.2357e-07, 3.1861e-05, 1.3869e-05, 1.1303e-03,
        2.7822e-04, 3.2192e-04, 7.4490e-04, 8.7375e-04, 1.4425e-03, 1.1636e-02,
        1.9560e-05], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:19,497][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0148, 0.0317, 0.0151, 0.0229, 0.0945, 0.0614, 0.0379, 0.0295, 0.1266,
        0.0365, 0.3857, 0.1062, 0.0371], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:19,498][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([9.9755e-01, 2.2165e-04, 3.8827e-05, 8.2909e-06, 4.3450e-04, 6.4533e-04,
        2.3789e-05, 3.3468e-05, 5.9239e-04, 1.8581e-05, 1.1608e-04, 2.8611e-04,
        3.3902e-05], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:19,499][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([9.7338e-01, 5.0252e-03, 1.8227e-03, 1.6493e-04, 4.4096e-03, 2.6031e-03,
        2.6824e-04, 4.0843e-04, 7.0207e-03, 2.2900e-04, 6.4005e-04, 3.5765e-03,
        4.5525e-04], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:19,501][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([9.9948e-01, 9.4293e-05, 5.7631e-05, 8.7247e-06, 1.6010e-05, 4.7912e-05,
        7.2016e-06, 1.1021e-05, 1.3083e-04, 4.4359e-06, 3.9505e-05, 9.7071e-05,
        7.2107e-06], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:19,505][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.4632, 0.0465, 0.0271, 0.0073, 0.0209, 0.0682, 0.0161, 0.0239, 0.0333,
        0.0346, 0.1405, 0.0978, 0.0208], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:19,507][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([9.9985e-01, 1.2871e-05, 2.4742e-06, 1.9523e-07, 1.1458e-05, 2.3595e-05,
        4.1377e-07, 5.1794e-07, 6.9363e-05, 1.0555e-06, 1.1258e-06, 2.1948e-05,
        5.7056e-07], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:19,509][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([9.9999e-01, 9.4887e-07, 1.9474e-07, 8.9602e-07, 1.4670e-07, 3.0839e-07,
        2.2920e-07, 1.5117e-07, 5.2222e-07, 4.5269e-06, 1.9475e-06, 9.4421e-07,
        7.0152e-08], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:19,512][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([9.9391e-01, 1.6092e-04, 1.5748e-05, 3.4956e-05, 1.4320e-04, 1.0713e-03,
        9.9929e-05, 3.0369e-04, 8.5921e-04, 1.7075e-04, 1.4438e-04, 2.7982e-03,
        2.8999e-04], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a]
[2024-07-24 10:24:19,514][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ basketball] are: tensor([8.9386e-01, 1.4803e-03, 5.5854e-04, 2.0954e-03, 7.3564e-04, 6.2140e-03,
        1.1175e-02, 7.1674e-03, 4.4050e-03, 2.0218e-02, 5.8220e-03, 2.6116e-02,
        9.1448e-03, 1.1005e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:19,516][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ basketball] are: tensor([9.9902e-01, 5.6667e-05, 8.3198e-05, 1.0384e-05, 1.7417e-05, 8.7760e-05,
        1.5383e-05, 2.8399e-05, 7.5868e-05, 3.3576e-05, 3.7876e-05, 4.0462e-04,
        1.1287e-05, 1.1996e-04], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:19,518][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ basketball] are: tensor([7.1342e-01, 3.0432e-02, 7.1201e-04, 5.8740e-03, 6.1037e-03, 3.5360e-02,
        1.2625e-02, 1.4304e-02, 1.4187e-02, 3.8859e-02, 1.5930e-03, 3.0913e-02,
        7.2375e-03, 8.8383e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:19,519][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ basketball] are: tensor([9.9473e-01, 3.7755e-04, 1.6177e-08, 1.5512e-06, 5.4006e-07, 6.0391e-05,
        1.4707e-05, 1.3648e-05, 4.3828e-05, 1.4533e-04, 6.9473e-05, 9.9050e-04,
        5.3932e-06, 3.5492e-03], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:19,520][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ basketball] are: tensor([0.0261, 0.0103, 0.0077, 0.0108, 0.0385, 0.0529, 0.0256, 0.0184, 0.1523,
        0.0148, 0.0593, 0.1614, 0.0263, 0.3956], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:19,521][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ basketball] are: tensor([9.9827e-01, 3.4475e-05, 3.3597e-05, 6.0720e-06, 1.3217e-04, 2.6123e-04,
        2.3348e-05, 3.7491e-05, 3.2362e-04, 1.1857e-05, 4.9046e-05, 3.9198e-04,
        3.5106e-05, 3.8950e-04], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:19,522][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ basketball] are: tensor([9.7324e-01, 2.3639e-03, 8.7653e-04, 1.1993e-04, 2.0932e-03, 1.5985e-03,
        2.4879e-04, 3.3582e-04, 2.3746e-03, 2.2220e-04, 2.1814e-04, 4.4611e-03,
        5.4680e-04, 1.1305e-02], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:19,524][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ basketball] are: tensor([9.9886e-01, 8.2492e-05, 2.5898e-05, 8.1695e-06, 7.7724e-06, 2.9700e-05,
        7.5905e-06, 8.6189e-06, 6.5276e-05, 3.7194e-06, 1.2649e-05, 7.6117e-05,
        7.8141e-06, 8.0274e-04], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:19,525][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ basketball] are: tensor([0.3932, 0.0394, 0.0169, 0.0032, 0.0168, 0.0571, 0.0087, 0.0225, 0.0251,
        0.0226, 0.0818, 0.1741, 0.0277, 0.1109], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:19,528][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ basketball] are: tensor([9.9918e-01, 5.2124e-05, 4.6371e-06, 8.4369e-07, 2.8046e-05, 3.8054e-05,
        1.7576e-06, 2.4541e-06, 1.3218e-04, 4.0433e-06, 1.8831e-06, 2.5856e-04,
        2.4483e-06, 2.9521e-04], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:19,530][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ basketball] are: tensor([9.9999e-01, 9.1478e-08, 5.2927e-08, 1.3331e-07, 2.7264e-08, 1.4080e-07,
        1.1602e-07, 5.1335e-08, 9.1158e-08, 1.4572e-06, 9.3471e-07, 5.8319e-07,
        3.5311e-08, 4.9014e-06], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:19,532][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ basketball] are: tensor([9.9760e-01, 3.5861e-05, 5.3657e-06, 1.2557e-05, 1.6434e-05, 2.1501e-04,
        4.2239e-05, 7.8376e-05, 1.4880e-04, 7.4746e-05, 2.0240e-05, 7.5296e-04,
        1.8674e-04, 8.1443e-04], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball]
[2024-07-24 10:24:19,536][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.5854, 0.0044, 0.0017, 0.0072, 0.0024, 0.0298, 0.0409, 0.0453, 0.0160,
        0.0921, 0.0116, 0.0739, 0.0396, 0.0179, 0.0319], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:19,538][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([9.9975e-01, 2.1780e-05, 3.9165e-05, 2.2651e-06, 5.8030e-06, 2.5033e-05,
        5.0294e-06, 6.1122e-06, 2.1861e-05, 5.5802e-06, 1.1387e-05, 5.1356e-05,
        1.5743e-06, 5.2671e-05, 1.6014e-06], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:19,542][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.6837, 0.0265, 0.0017, 0.0052, 0.0070, 0.0575, 0.0168, 0.0137, 0.0140,
        0.0275, 0.0026, 0.0247, 0.0054, 0.1077, 0.0060], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:19,543][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([9.7607e-01, 3.0580e-03, 1.6706e-07, 9.7013e-06, 3.4415e-06, 4.1635e-04,
        5.0940e-05, 8.3651e-05, 1.6734e-04, 2.4929e-04, 4.2110e-04, 4.0293e-03,
        8.0306e-06, 1.5402e-02, 2.8419e-05], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:19,544][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0196, 0.0255, 0.0095, 0.0142, 0.0441, 0.0296, 0.0248, 0.0172, 0.0774,
        0.0290, 0.2002, 0.0728, 0.0270, 0.3396, 0.0696], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:19,545][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([9.9919e-01, 7.9175e-05, 2.2486e-05, 3.6870e-06, 9.1070e-05, 9.2199e-05,
        9.6848e-06, 1.1851e-05, 1.1693e-04, 6.2168e-06, 3.9455e-05, 5.7618e-05,
        8.9892e-06, 2.5968e-04, 9.5120e-06], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:19,546][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([9.7631e-01, 7.5918e-03, 1.3183e-03, 1.3298e-04, 1.2786e-03, 1.2671e-03,
        2.1990e-04, 2.6243e-04, 2.4855e-03, 1.6670e-04, 2.5465e-04, 1.2163e-03,
        2.6052e-04, 7.0733e-03, 1.5861e-04], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:19,548][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([9.9945e-01, 3.1013e-05, 2.5453e-05, 3.0781e-06, 3.3237e-06, 1.0799e-05,
        2.7410e-06, 3.3183e-06, 2.6761e-05, 1.3885e-06, 7.1839e-06, 1.4144e-05,
        2.7383e-06, 4.2024e-04, 1.8078e-06], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:19,552][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.2767, 0.0902, 0.0445, 0.0080, 0.0285, 0.0779, 0.0152, 0.0365, 0.0234,
        0.0349, 0.1018, 0.1337, 0.0414, 0.0729, 0.0141], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:19,554][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([9.9986e-01, 1.4780e-05, 3.7300e-06, 1.9701e-07, 8.6759e-06, 1.0246e-05,
        3.4702e-07, 3.0189e-07, 2.9762e-05, 6.5402e-07, 9.4882e-07, 1.4082e-05,
        3.7712e-07, 5.4053e-05, 2.4657e-07], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:19,556][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([1.0000e+00, 5.7994e-08, 2.2991e-08, 6.5224e-08, 3.1540e-08, 3.8683e-08,
        1.7815e-08, 6.6596e-09, 3.4081e-08, 3.1486e-07, 2.1662e-07, 1.0073e-07,
        3.9504e-09, 3.5878e-07, 3.9861e-08], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:19,558][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([9.9749e-01, 5.3094e-05, 9.0669e-06, 1.0826e-05, 4.7024e-05, 2.7953e-04,
        2.4584e-05, 7.0468e-05, 2.1016e-04, 4.1808e-05, 5.3525e-05, 6.2634e-04,
        6.3562e-05, 9.7230e-04, 4.6593e-05], device='cuda:0') for source tokens [Then, Erica and Joshua went to the office. Erica gave a basketball to]
[2024-07-24 10:24:19,562][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:24:19,565][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[3481],
        [1026],
        [ 405],
        [ 332],
        [ 820],
        [  80],
        [  17],
        [ 130],
        [ 134],
        [  22],
        [  44],
        [   7],
        [   3],
        [  20],
        [   1]], device='cuda:0')
[2024-07-24 10:24:19,567][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[3659],
        [ 753],
        [ 286],
        [ 271],
        [ 756],
        [  33],
        [  10],
        [  34],
        [  27],
        [   3],
        [  24],
        [   8],
        [   5],
        [   2],
        [   1]], device='cuda:0')
[2024-07-24 10:24:19,568][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[7858],
        [7827],
        [7814],
        [7244],
        [7750],
        [5659],
        [4331],
        [7236],
        [7001],
        [4563],
        [7258],
        [4636],
        [6622],
        [5212],
        [6082]], device='cuda:0')
[2024-07-24 10:24:19,570][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[2066],
        [2066],
        [2065],
        [2066],
        [2065],
        [2066],
        [2066],
        [2078],
        [2067],
        [2072],
        [2067],
        [2069],
        [2069],
        [2070],
        [2068]], device='cuda:0')
[2024-07-24 10:24:19,573][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 6738],
        [ 7061],
        [18963],
        [ 8730],
        [22034],
        [35642],
        [21270],
        [36454],
        [20248],
        [14929],
        [21445],
        [31983],
        [26797],
        [29217],
        [30007]], device='cuda:0')
[2024-07-24 10:24:19,575][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[15522],
        [15764],
        [26322],
        [20302],
        [24699],
        [16431],
        [16722],
        [22889],
        [16197],
        [16706],
        [17916],
        [16159],
        [18790],
        [16221],
        [18867]], device='cuda:0')
[2024-07-24 10:24:19,578][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[26521],
        [25720],
        [12702],
        [25450],
        [ 4483],
        [ 8423],
        [ 9905],
        [10446],
        [ 9250],
        [ 7517],
        [ 8753],
        [ 9034],
        [ 8527],
        [ 8455],
        [ 7375]], device='cuda:0')
[2024-07-24 10:24:19,581][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[38619],
        [38619],
        [38633],
        [38617],
        [38574],
        [38518],
        [38621],
        [38521],
        [38613],
        [38611],
        [38615],
        [38355],
        [38599],
        [38623],
        [38629]], device='cuda:0')
[2024-07-24 10:24:19,583][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[15547],
        [15704],
        [22325],
        [16126],
        [18029],
        [19352],
        [18819],
        [32336],
        [19172],
        [16916],
        [19031],
        [23667],
        [20972],
        [17081],
        [17519]], device='cuda:0')
[2024-07-24 10:24:19,586][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[48124],
        [48124],
        [48131],
        [48124],
        [48128],
        [48156],
        [48124],
        [48137],
        [48133],
        [48128],
        [48131],
        [48182],
        [48136],
        [48176],
        [48147]], device='cuda:0')
[2024-07-24 10:24:19,589][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[12147],
        [12147],
        [ 8664],
        [ 9870],
        [10985],
        [12533],
        [12935],
        [12194],
        [12219],
        [12170],
        [ 9142],
        [15654],
        [33790],
        [12481],
        [ 9330]], device='cuda:0')
[2024-07-24 10:24:19,591][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[23345],
        [23343],
        [23330],
        [23344],
        [23343],
        [23347],
        [23344],
        [23351],
        [23378],
        [23349],
        [23373],
        [23452],
        [23357],
        [23390],
        [23348]], device='cuda:0')
[2024-07-24 10:24:19,593][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[39843],
        [39843],
        [39843],
        [39843],
        [39843],
        [39843],
        [39843],
        [39843],
        [39843],
        [39843],
        [39843],
        [39843],
        [39843],
        [39843],
        [39843]], device='cuda:0')
[2024-07-24 10:24:19,594][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[40164],
        [40166],
        [41190],
        [40176],
        [40660],
        [40526],
        [40215],
        [40737],
        [40242],
        [40262],
        [40523],
        [40338],
        [41056],
        [40563],
        [40599]], device='cuda:0')
[2024-07-24 10:24:19,596][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[14305],
        [17726],
        [ 1482],
        [29266],
        [10087],
        [ 7954],
        [15543],
        [31448],
        [14647],
        [15356],
        [  471],
        [13763],
        [33320],
        [26155],
        [27072]], device='cuda:0')
[2024-07-24 10:24:19,598][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[17024],
        [16938],
        [16356],
        [16725],
        [16480],
        [16288],
        [15115],
        [14446],
        [15428],
        [15485],
        [15196],
        [15586],
        [14334],
        [15473],
        [14292]], device='cuda:0')
[2024-07-24 10:24:19,601][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[17335],
        [17335],
        [17345],
        [17336],
        [17342],
        [17348],
        [17337],
        [17366],
        [17345],
        [17343],
        [17344],
        [17361],
        [17370],
        [17373],
        [17347]], device='cuda:0')
[2024-07-24 10:24:19,604][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[36625],
        [36985],
        [40706],
        [38359],
        [39346],
        [39241],
        [41042],
        [40206],
        [40799],
        [38957],
        [38158],
        [38700],
        [40385],
        [39717],
        [40107]], device='cuda:0')
[2024-07-24 10:24:19,606][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[13034],
        [13344],
        [17299],
        [13768],
        [16314],
        [13554],
        [13530],
        [14648],
        [13564],
        [13529],
        [13380],
        [13461],
        [13673],
        [12995],
        [12234]], device='cuda:0')
[2024-07-24 10:24:19,609][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[15883],
        [ 9991],
        [20558],
        [12158],
        [11823],
        [15256],
        [17518],
        [18867],
        [19801],
        [21970],
        [28490],
        [26759],
        [31534],
        [23915],
        [27970]], device='cuda:0')
[2024-07-24 10:24:19,612][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[15026],
        [15020],
        [14792],
        [15011],
        [14883],
        [14475],
        [14982],
        [14688],
        [14892],
        [14949],
        [14637],
        [13677],
        [14722],
        [14825],
        [14921]], device='cuda:0')
[2024-07-24 10:24:19,614][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[7969],
        [7999],
        [7889],
        [7975],
        [7937],
        [7795],
        [7740],
        [6655],
        [7752],
        [7838],
        [7979],
        [7565],
        [7430],
        [7747],
        [7952]], device='cuda:0')
[2024-07-24 10:24:19,617][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[17453],
        [17452],
        [17440],
        [17456],
        [17445],
        [17470],
        [17453],
        [17474],
        [17450],
        [17464],
        [17458],
        [17532],
        [17475],
        [17475],
        [17464]], device='cuda:0')
[2024-07-24 10:24:19,618][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[19948],
        [19500],
        [15036],
        [19911],
        [19819],
        [19663],
        [14503],
        [19809],
        [19829],
        [19906],
        [11873],
        [19151],
        [18799],
        [17646],
        [13689]], device='cuda:0')
[2024-07-24 10:24:19,620][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[8183],
        [8184],
        [8205],
        [8185],
        [8192],
        [8196],
        [8187],
        [8195],
        [8198],
        [8184],
        [8212],
        [8231],
        [8191],
        [8223],
        [8193]], device='cuda:0')
[2024-07-24 10:24:19,621][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[12150],
        [12150],
        [12153],
        [12150],
        [12151],
        [12150],
        [12150],
        [12150],
        [12151],
        [12151],
        [12150],
        [12150],
        [12150],
        [12150],
        [12150]], device='cuda:0')
[2024-07-24 10:24:19,624][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[9342],
        [9343],
        [9248],
        [9342],
        [9337],
        [9311],
        [9343],
        [9488],
        [9354],
        [9362],
        [9399],
        [9390],
        [9548],
        [9433],
        [9427]], device='cuda:0')
[2024-07-24 10:24:19,626][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[29966],
        [30062],
        [28465],
        [29614],
        [28694],
        [30193],
        [29278],
        [29831],
        [29183],
        [29050],
        [29827],
        [29872],
        [28973],
        [29497],
        [29372]], device='cuda:0')
[2024-07-24 10:24:19,629][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[32907],
        [26162],
        [48603],
        [19727],
        [36572],
        [38164],
        [31205],
        [11683],
        [34032],
        [29432],
        [50055],
        [33563],
        [ 9431],
        [20155],
        [17738]], device='cuda:0')
[2024-07-24 10:24:19,631][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[16169],
        [16169],
        [16169],
        [16169],
        [16169],
        [16169],
        [16169],
        [16169],
        [16169],
        [16169],
        [16169],
        [16169],
        [16169],
        [16169],
        [16169]], device='cuda:0')
