[2024-07-24 10:21:36,328][explain_satisfiability.py][line:287][INFO] ############ CASE TEXT isThen, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to
[2024-07-24 10:21:36,328][explain_satisfiability.py][line:288][INFO] ############ CASE Prediction is  Travis
[2024-07-24 10:21:36,328][explain_satisfiability.py][line:289][INFO] ############ Refined Forward Graph
[2024-07-24 10:21:36,328][explain_satisfiability.py][line:290][INFO] ****** Layer 1
[2024-07-24 10:21:36,328][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 0
[2024-07-24 10:21:36,328][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,328][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 1
[2024-07-24 10:21:36,328][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit7', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:36,328][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 2
[2024-07-24 10:21:36,328][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,329][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 3
[2024-07-24 10:21:36,329][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,329][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 4
[2024-07-24 10:21:36,329][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:36,329][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 5
[2024-07-24 10:21:36,329][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:36,329][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 6
[2024-07-24 10:21:36,329][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:36,329][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 7
[2024-07-24 10:21:36,329][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:21:36,329][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 8
[2024-07-24 10:21:36,329][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,329][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 9
[2024-07-24 10:21:36,329][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit5', 'circuit6', 'circuit13', 'circuit17', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:36,329][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 10
[2024-07-24 10:21:36,329][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:21:36,330][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 11
[2024-07-24 10:21:36,330][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:36,330][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 12
[2024-07-24 10:21:36,330][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,330][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 13
[2024-07-24 10:21:36,330][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit3', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,330][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 14
[2024-07-24 10:21:36,330][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit23']
[2024-07-24 10:21:36,330][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 15
[2024-07-24 10:21:36,330][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:36,330][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 16
[2024-07-24 10:21:36,330][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:36,330][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 17
[2024-07-24 10:21:36,330][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit22', 'circuit24', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,330][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 18
[2024-07-24 10:21:36,331][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,331][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 19
[2024-07-24 10:21:36,331][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,331][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 20
[2024-07-24 10:21:36,331][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit26', 'circuit27']
[2024-07-24 10:21:36,331][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 21
[2024-07-24 10:21:36,331][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:36,331][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 22
[2024-07-24 10:21:36,331][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:21:36,331][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 23
[2024-07-24 10:21:36,331][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit27']
[2024-07-24 10:21:36,331][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 24
[2024-07-24 10:21:36,331][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:21:36,331][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 25
[2024-07-24 10:21:36,331][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:21:36,331][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 26
[2024-07-24 10:21:36,332][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,335][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 27
[2024-07-24 10:21:36,335][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,335][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 28
[2024-07-24 10:21:36,336][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,336][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 0
[2024-07-24 10:21:36,336][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit7', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,336][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,336][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 1
[2024-07-24 10:21:36,336][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:36,336][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit6', 'circuit19', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:36,336][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 2
[2024-07-24 10:21:36,336][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:21:36,336][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit20']
[2024-07-24 10:21:36,336][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 3
[2024-07-24 10:21:36,336][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:21:36,336][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,336][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 4
[2024-07-24 10:21:36,336][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit18', 'circuit23']
[2024-07-24 10:21:36,337][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,337][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 5
[2024-07-24 10:21:36,337][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:21:36,337][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,337][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 6
[2024-07-24 10:21:36,337][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit19', 'circuit21']
[2024-07-24 10:21:36,337][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,337][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 7
[2024-07-24 10:21:36,337][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,337][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit2', 'circuit10', 'circuit12', 'circuit16']
[2024-07-24 10:21:36,337][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 8
[2024-07-24 10:21:36,337][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:36,337][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:21:36,337][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 9
[2024-07-24 10:21:36,337][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit17', 'circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:21:36,337][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:21:36,338][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 10
[2024-07-24 10:21:36,338][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,338][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,338][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 11
[2024-07-24 10:21:36,338][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,338][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit8', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,338][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 12
[2024-07-24 10:21:36,338][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit11', 'circuit12', 'circuit13', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:36,338][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit23']
[2024-07-24 10:21:36,338][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 13
[2024-07-24 10:21:36,338][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,338][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,338][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 14
[2024-07-24 10:21:36,338][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:21:36,338][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:21:36,338][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 15
[2024-07-24 10:21:36,339][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit6', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,339][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit13', 'circuit15', 'circuit16', 'circuit20', 'circuit21', 'circuit26']
[2024-07-24 10:21:36,339][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 16
[2024-07-24 10:21:36,339][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:36,339][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13']
[2024-07-24 10:21:36,339][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 17
[2024-07-24 10:21:36,339][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,339][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit4', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:21:36,339][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 18
[2024-07-24 10:21:36,339][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:21:36,339][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,339][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 19
[2024-07-24 10:21:36,339][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:21:36,339][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:21:36,339][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 20
[2024-07-24 10:21:36,340][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit26', 'circuit27']
[2024-07-24 10:21:36,340][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,340][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 21
[2024-07-24 10:21:36,340][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:21:36,340][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,340][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 22
[2024-07-24 10:21:36,340][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:21:36,340][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:21:36,340][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 23
[2024-07-24 10:21:36,340][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:21:36,340][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit8', 'circuit12', 'circuit13', 'circuit14', 'circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:21:36,340][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 24
[2024-07-24 10:21:36,340][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:21:36,340][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit25']
[2024-07-24 10:21:36,340][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 25
[2024-07-24 10:21:36,340][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:21:36,341][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit17']
[2024-07-24 10:21:36,341][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 26
[2024-07-24 10:21:36,341][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,341][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,341][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 27
[2024-07-24 10:21:36,341][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,341][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,341][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 28
[2024-07-24 10:21:36,341][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,341][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,341][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 0
[2024-07-24 10:21:36,341][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit2', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,341][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,341][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit7', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:36,341][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 1
[2024-07-24 10:21:36,341][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,342][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit2', 'circuit7', 'circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:21:36,342][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:36,342][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 2
[2024-07-24 10:21:36,342][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:21:36,342][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,342][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:21:36,342][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 3
[2024-07-24 10:21:36,342][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:21:36,342][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit5', 'circuit8', 'circuit13', 'circuit14', 'circuit19']
[2024-07-24 10:21:36,342][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:21:36,342][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 4
[2024-07-24 10:21:36,342][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit20', 'circuit22', 'circuit23', 'circuit26', 'circuit27']
[2024-07-24 10:21:36,342][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit27']
[2024-07-24 10:21:36,342][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:36,342][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 5
[2024-07-24 10:21:36,342][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit10', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:21:36,343][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit8']
[2024-07-24 10:21:36,343][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:36,343][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 6
[2024-07-24 10:21:36,343][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit22', 'circuit23']
[2024-07-24 10:21:36,343][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23']
[2024-07-24 10:21:36,343][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15']
[2024-07-24 10:21:36,343][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 7
[2024-07-24 10:21:36,343][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:21:36,343][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14']
[2024-07-24 10:21:36,343][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,343][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 8
[2024-07-24 10:21:36,343][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:21:36,343][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit11', 'circuit14']
[2024-07-24 10:21:36,343][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15']
[2024-07-24 10:21:36,343][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 9
[2024-07-24 10:21:36,344][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit26']
[2024-07-24 10:21:36,344][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,344][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit18', 'circuit20', 'circuit22']
[2024-07-24 10:21:36,344][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 10
[2024-07-24 10:21:36,344][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,344][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit2']
[2024-07-24 10:21:36,344][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,344][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 11
[2024-07-24 10:21:36,344][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:21:36,344][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:36,344][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit4', 'circuit7', 'circuit8', 'circuit10', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:36,344][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 12
[2024-07-24 10:21:36,344][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,344][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,344][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,344][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 13
[2024-07-24 10:21:36,345][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,345][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:36,345][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,345][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 14
[2024-07-24 10:21:36,345][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:21:36,345][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,345][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:21:36,345][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 15
[2024-07-24 10:21:36,345][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,345][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,345][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,345][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 16
[2024-07-24 10:21:36,345][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,345][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,345][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit4', 'circuit5', 'circuit6', 'circuit9', 'circuit14']
[2024-07-24 10:21:36,345][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 17
[2024-07-24 10:21:36,346][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,346][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,346][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit11']
[2024-07-24 10:21:36,346][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 18
[2024-07-24 10:21:36,346][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit13', 'circuit17', 'circuit20', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:36,346][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit22']
[2024-07-24 10:21:36,346][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13']
[2024-07-24 10:21:36,346][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 19
[2024-07-24 10:21:36,346][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:21:36,346][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,346][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,346][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 20
[2024-07-24 10:21:36,346][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,346][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,346][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,346][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 21
[2024-07-24 10:21:36,347][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,347][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,347][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,347][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 22
[2024-07-24 10:21:36,347][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,347][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,347][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,347][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 23
[2024-07-24 10:21:36,347][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,347][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,347][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,347][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 24
[2024-07-24 10:21:36,347][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit27']
[2024-07-24 10:21:36,347][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,347][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,347][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 25
[2024-07-24 10:21:36,348][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,348][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,348][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,348][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 26
[2024-07-24 10:21:36,348][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,348][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,348][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,348][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 27
[2024-07-24 10:21:36,348][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,348][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,348][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,348][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 28
[2024-07-24 10:21:36,348][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,348][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,348][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,348][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 0
[2024-07-24 10:21:36,349][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit2', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,349][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:36,349][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit8', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,349][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit5', 'circuit6', 'circuit7', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,349][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 1
[2024-07-24 10:21:36,349][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit20', 'circuit26']
[2024-07-24 10:21:36,349][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,349][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,349][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,349][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 2
[2024-07-24 10:21:36,349][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:36,349][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:36,349][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit2', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:36,349][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit5', 'circuit6', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:36,349][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 3
[2024-07-24 10:21:36,350][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:36,350][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit5', 'circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:36,350][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit5', 'circuit7', 'circuit8', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:21:36,350][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit5', 'circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:36,350][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 4
[2024-07-24 10:21:36,350][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit20', 'circuit24']
[2024-07-24 10:21:36,350][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,350][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15']
[2024-07-24 10:21:36,350][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,350][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 5
[2024-07-24 10:21:36,350][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,350][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:21:36,350][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit17', 'circuit22']
[2024-07-24 10:21:36,350][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit16', 'circuit17', 'circuit21', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:21:36,350][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 6
[2024-07-24 10:21:36,350][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:36,351][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit1', 'circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit14', 'circuit15', 'circuit16', 'circuit22', 'circuit24']
[2024-07-24 10:21:36,351][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,351][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit21', 'circuit23', 'circuit25']
[2024-07-24 10:21:36,351][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 7
[2024-07-24 10:21:36,351][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,351][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit12', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:21:36,351][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit7', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:21:36,351][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:21:36,351][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 8
[2024-07-24 10:21:36,351][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:21:36,351][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:21:36,351][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:36,351][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:21:36,351][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 9
[2024-07-24 10:21:36,351][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,352][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit7', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,352][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:36,352][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit5', 'circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:36,352][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 10
[2024-07-24 10:21:36,352][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:21:36,352][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit19', 'circuit20', 'circuit22']
[2024-07-24 10:21:36,352][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit18', 'circuit23']
[2024-07-24 10:21:36,352][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:21:36,352][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 11
[2024-07-24 10:21:36,352][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit16', 'circuit17', 'circuit19', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:21:36,352][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:21:36,352][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit22']
[2024-07-24 10:21:36,352][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit25']
[2024-07-24 10:21:36,352][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 12
[2024-07-24 10:21:36,352][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit28']
[2024-07-24 10:21:36,352][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2']
[2024-07-24 10:21:36,353][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,353][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,353][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 13
[2024-07-24 10:21:36,353][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,353][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,353][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:36,353][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,353][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 14
[2024-07-24 10:21:36,353][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,353][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,353][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,353][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,353][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 15
[2024-07-24 10:21:36,353][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:36,353][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,353][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,354][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:21:36,354][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 16
[2024-07-24 10:21:36,354][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:36,354][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit5', 'circuit6', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:21:36,354][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:21:36,354][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,354][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 17
[2024-07-24 10:21:36,354][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:21:36,354][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,354][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,354][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,354][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 18
[2024-07-24 10:21:36,354][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:36,354][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit1', 'circuit10', 'circuit11', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:21:36,354][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit26']
[2024-07-24 10:21:36,354][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit13', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:36,355][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 19
[2024-07-24 10:21:36,355][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:21:36,355][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,355][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,355][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit23']
[2024-07-24 10:21:36,355][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 20
[2024-07-24 10:21:36,355][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:21:36,355][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,355][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:21:36,355][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,355][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 21
[2024-07-24 10:21:36,355][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit19', 'circuit20']
[2024-07-24 10:21:36,355][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit10', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit22']
[2024-07-24 10:21:36,355][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,355][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,356][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 22
[2024-07-24 10:21:36,356][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:21:36,356][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit15', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:21:36,356][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:21:36,356][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,356][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 23
[2024-07-24 10:21:36,356][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,356][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,356][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,356][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,356][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 24
[2024-07-24 10:21:36,356][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:21:36,356][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,356][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20']
[2024-07-24 10:21:36,356][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit25']
[2024-07-24 10:21:36,356][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 25
[2024-07-24 10:21:36,357][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,357][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,357][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,357][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,357][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 26
[2024-07-24 10:21:36,357][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,357][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,357][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,357][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,357][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 27
[2024-07-24 10:21:36,357][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,357][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,357][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,357][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,357][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 28
[2024-07-24 10:21:36,357][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,358][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,358][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,358][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,358][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 0
[2024-07-24 10:21:36,358][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit2', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,358][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,358][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,358][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit5', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:36,358][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit3', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:36,358][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 1
[2024-07-24 10:21:36,358][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:36,358][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,358][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,358][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit6', 'circuit7', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:36,358][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,359][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 2
[2024-07-24 10:21:36,359][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,359][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit7', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:21:36,359][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23']
[2024-07-24 10:21:36,359][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:21:36,359][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit24']
[2024-07-24 10:21:36,359][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 3
[2024-07-24 10:21:36,359][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,359][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:21:36,359][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit20', 'circuit22', 'circuit23']
[2024-07-24 10:21:36,359][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:36,359][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:21:36,359][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 4
[2024-07-24 10:21:36,359][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit2', 'circuit10', 'circuit12', 'circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:36,359][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit2', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19']
[2024-07-24 10:21:36,360][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit26']
[2024-07-24 10:21:36,360][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit21', 'circuit23', 'circuit24']
[2024-07-24 10:21:36,360][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,360][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 5
[2024-07-24 10:21:36,360][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:21:36,360][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,360][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,360][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,360][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,360][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 6
[2024-07-24 10:21:36,360][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit6', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:21:36,360][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit21']
[2024-07-24 10:21:36,360][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:21:36,360][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,360][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit15', 'circuit21']
[2024-07-24 10:21:36,360][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 7
[2024-07-24 10:21:36,361][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22']
[2024-07-24 10:21:36,361][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,361][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit22']
[2024-07-24 10:21:36,361][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:21:36,361][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,361][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 8
[2024-07-24 10:21:36,361][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,361][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,361][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,361][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,361][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,361][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 9
[2024-07-24 10:21:36,361][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit28']
[2024-07-24 10:21:36,361][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit24']
[2024-07-24 10:21:36,361][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit20']
[2024-07-24 10:21:36,361][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit23', 'circuit25']
[2024-07-24 10:21:36,362][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:21:36,362][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 10
[2024-07-24 10:21:36,362][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:21:36,362][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit5', 'circuit8', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:36,362][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:21:36,362][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:21:36,362][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit15']
[2024-07-24 10:21:36,362][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 11
[2024-07-24 10:21:36,362][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit13', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit24']
[2024-07-24 10:21:36,362][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,362][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit19', 'circuit22']
[2024-07-24 10:21:36,362][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit15', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:21:36,362][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:21:36,362][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 12
[2024-07-24 10:21:36,362][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:21:36,362][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit3', 'circuit5', 'circuit7', 'circuit11', 'circuit12', 'circuit20']
[2024-07-24 10:21:36,363][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:21:36,363][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:21:36,363][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,363][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 13
[2024-07-24 10:21:36,363][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,363][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit7', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:36,363][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit5', 'circuit7', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:36,363][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit5', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:36,363][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,363][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 14
[2024-07-24 10:21:36,363][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit15', 'circuit17', 'circuit18', 'circuit21', 'circuit27']
[2024-07-24 10:21:36,363][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,363][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit22']
[2024-07-24 10:21:36,363][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit15', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:21:36,363][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit21', 'circuit25']
[2024-07-24 10:21:36,364][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 15
[2024-07-24 10:21:36,364][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:21:36,364][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,364][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,364][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,364][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,364][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 16
[2024-07-24 10:21:36,364][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,364][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,364][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,364][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,364][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,364][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 17
[2024-07-24 10:21:36,364][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit16', 'circuit18', 'circuit20', 'circuit22', 'circuit24', 'circuit27']
[2024-07-24 10:21:36,364][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,364][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,365][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,365][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit15']
[2024-07-24 10:21:36,365][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 18
[2024-07-24 10:21:36,365][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,365][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0']
[2024-07-24 10:21:36,365][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,365][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,365][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,365][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 19
[2024-07-24 10:21:36,365][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:21:36,365][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,365][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:21:36,365][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,365][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,365][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 20
[2024-07-24 10:21:36,365][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,366][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,366][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,366][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,366][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,366][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 21
[2024-07-24 10:21:36,366][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,366][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,366][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,366][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,366][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,366][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 22
[2024-07-24 10:21:36,366][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,366][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit16']
[2024-07-24 10:21:36,366][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,366][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit8']
[2024-07-24 10:21:36,366][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit10', 'circuit13', 'circuit14', 'circuit20', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:21:36,367][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 23
[2024-07-24 10:21:36,367][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:21:36,367][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:21:36,367][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:36,367][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:36,367][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:21:36,367][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 24
[2024-07-24 10:21:36,367][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit19', 'circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:21:36,367][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,367][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit23']
[2024-07-24 10:21:36,367][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit25']
[2024-07-24 10:21:36,367][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,367][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 25
[2024-07-24 10:21:36,367][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,367][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit20', 'circuit21', 'circuit24', 'circuit25']
[2024-07-24 10:21:36,367][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit8', 'circuit13', 'circuit26']
[2024-07-24 10:21:36,368][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,368][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,368][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 26
[2024-07-24 10:21:36,368][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,368][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,368][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,368][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,368][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,368][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 27
[2024-07-24 10:21:36,368][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,368][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,368][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,368][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,368][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,368][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 28
[2024-07-24 10:21:36,369][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,369][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,369][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,369][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,369][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,369][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 0
[2024-07-24 10:21:36,369][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,369][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit5', 'circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:36,369][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit4', 'circuit7', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,369][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit5', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:36,369][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit6', 'circuit8', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:36,369][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:36,369][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 1
[2024-07-24 10:21:36,369][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit26']
[2024-07-24 10:21:36,369][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,369][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,370][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,370][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,370][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,370][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 2
[2024-07-24 10:21:36,370][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit24']
[2024-07-24 10:21:36,370][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,370][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,370][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit25']
[2024-07-24 10:21:36,370][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,370][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,370][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 3
[2024-07-24 10:21:36,370][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:36,370][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit14', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:36,370][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:21:36,370][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:36,371][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:36,371][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:21:36,371][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 4
[2024-07-24 10:21:36,371][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:21:36,371][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,371][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit17']
[2024-07-24 10:21:36,371][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,371][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,371][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,371][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 5
[2024-07-24 10:21:36,371][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:36,371][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16']
[2024-07-24 10:21:36,371][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit22', 'circuit24']
[2024-07-24 10:21:36,371][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:21:36,371][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:36,371][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:21:36,372][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 6
[2024-07-24 10:21:36,372][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:21:36,372][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:21:36,372][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15']
[2024-07-24 10:21:36,372][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:21:36,372][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:21:36,372][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:21:36,372][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 7
[2024-07-24 10:21:36,372][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit2', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:21:36,372][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:21:36,372][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,372][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,372][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit18']
[2024-07-24 10:21:36,372][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit16', 'circuit19', 'circuit20']
[2024-07-24 10:21:36,372][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 8
[2024-07-24 10:21:36,372][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,373][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,373][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,373][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,373][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,373][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,373][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 9
[2024-07-24 10:21:36,373][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,373][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,373][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,373][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,373][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,373][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,373][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 10
[2024-07-24 10:21:36,373][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,373][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,373][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,374][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,374][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,374][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,374][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 11
[2024-07-24 10:21:36,374][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:36,374][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit2', 'circuit10', 'circuit13', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit26']
[2024-07-24 10:21:36,374][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:36,374][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit5', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:21:36,374][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit20', 'circuit23', 'circuit24']
[2024-07-24 10:21:36,374][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit24']
[2024-07-24 10:21:36,374][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 12
[2024-07-24 10:21:36,374][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,374][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,374][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,374][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,374][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,375][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,375][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 13
[2024-07-24 10:21:36,375][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:36,375][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,375][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:36,375][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit5', 'circuit6', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,375][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,375][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit5', 'circuit6', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:36,375][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 14
[2024-07-24 10:21:36,375][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,375][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,375][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,375][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,375][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,375][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,375][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 15
[2024-07-24 10:21:36,376][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,376][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,376][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,376][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,376][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,376][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,376][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 16
[2024-07-24 10:21:36,376][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit20', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:21:36,376][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit21', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:21:36,376][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:36,376][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit15', 'circuit17']
[2024-07-24 10:21:36,376][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,376][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit17', 'circuit23']
[2024-07-24 10:21:36,376][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 17
[2024-07-24 10:21:36,376][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,377][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit2', 'circuit12']
[2024-07-24 10:21:36,377][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,377][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit5']
[2024-07-24 10:21:36,377][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit16']
[2024-07-24 10:21:36,377][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit14']
[2024-07-24 10:21:36,377][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 18
[2024-07-24 10:21:36,377][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:21:36,377][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,377][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,377][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,377][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,377][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,377][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 19
[2024-07-24 10:21:36,377][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit27']
[2024-07-24 10:21:36,377][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,377][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,378][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,378][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit24']
[2024-07-24 10:21:36,378][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,378][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 20
[2024-07-24 10:21:36,378][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:21:36,378][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,378][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,378][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,378][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit24']
[2024-07-24 10:21:36,378][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0']
[2024-07-24 10:21:36,378][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 21
[2024-07-24 10:21:36,378][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:21:36,378][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,378][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit18']
[2024-07-24 10:21:36,378][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,378][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,379][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,379][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 22
[2024-07-24 10:21:36,379][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,379][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,379][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,379][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,379][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit17']
[2024-07-24 10:21:36,379][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,379][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 23
[2024-07-24 10:21:36,379][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,379][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,379][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,379][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,379][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,379][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,379][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 24
[2024-07-24 10:21:36,380][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:21:36,380][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,380][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit23']
[2024-07-24 10:21:36,380][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,380][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit19', 'circuit23', 'circuit25']
[2024-07-24 10:21:36,380][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,380][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 25
[2024-07-24 10:21:36,380][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,380][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,380][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,380][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,380][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,380][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,380][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 26
[2024-07-24 10:21:36,380][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,380][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,381][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,381][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,381][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,381][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,381][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 27
[2024-07-24 10:21:36,381][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,381][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,381][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,381][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,381][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,381][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,381][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 28
[2024-07-24 10:21:36,381][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,381][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,381][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,382][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,382][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,382][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,382][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 0
[2024-07-24 10:21:36,382][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit6', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,382][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit5', 'circuit7', 'circuit8', 'circuit11', 'circuit12', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,382][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:36,382][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:36,382][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:36,382][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit6', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:36,382][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit5', 'circuit7', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:36,382][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 1
[2024-07-24 10:21:36,382][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,382][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,382][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,382][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,383][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,383][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,383][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,383][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 2
[2024-07-24 10:21:36,383][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit21', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:21:36,383][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,383][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:36,383][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit15']
[2024-07-24 10:21:36,383][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit19']
[2024-07-24 10:21:36,383][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit14']
[2024-07-24 10:21:36,383][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0']
[2024-07-24 10:21:36,383][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 3
[2024-07-24 10:21:36,383][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit2', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,383][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit5', 'circuit19', 'circuit23']
[2024-07-24 10:21:36,383][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit3', 'circuit14', 'circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:21:36,384][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,384][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,384][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit24']
[2024-07-24 10:21:36,384][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit23', 'circuit25', 'circuit27']
[2024-07-24 10:21:36,384][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 4
[2024-07-24 10:21:36,384][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit8', 'circuit9', 'circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:21:36,384][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit11', 'circuit12', 'circuit14', 'circuit25']
[2024-07-24 10:21:36,384][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,384][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit25']
[2024-07-24 10:21:36,384][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:21:36,384][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit5', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:21:36,384][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit24', 'circuit25']
[2024-07-24 10:21:36,384][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 5
[2024-07-24 10:21:36,384][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit18', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:21:36,384][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,384][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,385][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,385][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,385][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,385][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,385][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 6
[2024-07-24 10:21:36,385][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:36,385][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit5', 'circuit7', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit27']
[2024-07-24 10:21:36,385][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:36,385][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:36,385][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit21', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:21:36,385][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit10', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:21:36,385][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:21:36,385][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 7
[2024-07-24 10:21:36,385][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:21:36,385][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit7', 'circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit27']
[2024-07-24 10:21:36,385][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:36,386][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit5', 'circuit11', 'circuit13', 'circuit15', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:21:36,386][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:21:36,386][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:21:36,386][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,386][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 8
[2024-07-24 10:21:36,386][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:21:36,386][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:21:36,386][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit26']
[2024-07-24 10:21:36,386][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit3', 'circuit5', 'circuit14']
[2024-07-24 10:21:36,386][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit20', 'circuit21']
[2024-07-24 10:21:36,386][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,386][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,386][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 9
[2024-07-24 10:21:36,386][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:21:36,386][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:21:36,387][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit23']
[2024-07-24 10:21:36,387][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,387][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,387][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,387][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,387][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 10
[2024-07-24 10:21:36,387][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit18', 'circuit27']
[2024-07-24 10:21:36,387][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit2', 'circuit13', 'circuit19']
[2024-07-24 10:21:36,387][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17']
[2024-07-24 10:21:36,387][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit23']
[2024-07-24 10:21:36,387][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:21:36,387][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,387][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit23', 'circuit25']
[2024-07-24 10:21:36,387][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 11
[2024-07-24 10:21:36,387][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,387][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,388][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,388][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,388][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,388][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,388][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,388][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 12
[2024-07-24 10:21:36,388][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14']
[2024-07-24 10:21:36,388][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,388][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,388][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,388][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,388][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,388][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,388][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 13
[2024-07-24 10:21:36,388][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,388][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit16', 'circuit24']
[2024-07-24 10:21:36,389][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit27']
[2024-07-24 10:21:36,389][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit5', 'circuit6', 'circuit14', 'circuit19', 'circuit20']
[2024-07-24 10:21:36,389][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:21:36,389][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:21:36,389][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit20', 'circuit23', 'circuit24']
[2024-07-24 10:21:36,389][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 14
[2024-07-24 10:21:36,389][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,389][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,389][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,389][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,389][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,389][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,389][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,389][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 15
[2024-07-24 10:21:36,389][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,389][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,390][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,390][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,390][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,390][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,390][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,390][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 16
[2024-07-24 10:21:36,390][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,390][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,390][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,390][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,390][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,390][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,390][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,390][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 17
[2024-07-24 10:21:36,390][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,390][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,391][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,391][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,391][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,391][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,391][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,391][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 18
[2024-07-24 10:21:36,391][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,391][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,391][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,391][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,391][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,391][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,391][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,391][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 19
[2024-07-24 10:21:36,391][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,391][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,392][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,392][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,392][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,392][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,392][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,392][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 20
[2024-07-24 10:21:36,392][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,392][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,392][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,392][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,392][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,392][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,392][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,392][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 21
[2024-07-24 10:21:36,392][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,392][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,393][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,393][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,393][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,393][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,393][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,393][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 22
[2024-07-24 10:21:36,393][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,393][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,393][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,393][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,393][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,393][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,393][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,393][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 23
[2024-07-24 10:21:36,393][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,393][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,394][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,394][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,394][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,394][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,394][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,394][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 24
[2024-07-24 10:21:36,394][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,394][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,394][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,394][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,394][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,394][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,394][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,394][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 25
[2024-07-24 10:21:36,394][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,394][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,395][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,395][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,395][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,395][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,395][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,395][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 26
[2024-07-24 10:21:36,395][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,395][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,395][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,395][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,395][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,395][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,395][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,395][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 27
[2024-07-24 10:21:36,395][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,396][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,396][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,396][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,396][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,396][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,396][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,396][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 28
[2024-07-24 10:21:36,396][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,396][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,396][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,396][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,396][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,396][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,396][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,396][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 0
[2024-07-24 10:21:36,396][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,397][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit7', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:21:36,397][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit7', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:36,397][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:36,397][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,397][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit5', 'circuit7', 'circuit8', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:36,397][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit7', 'circuit8', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:36,397][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:36,397][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 1
[2024-07-24 10:21:36,397][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,397][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit20']
[2024-07-24 10:21:36,397][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,397][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit21']
[2024-07-24 10:21:36,397][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,397][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,397][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,398][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit16', 'circuit17', 'circuit19', 'circuit25']
[2024-07-24 10:21:36,398][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 2
[2024-07-24 10:21:36,398][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,398][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit17', 'circuit20']
[2024-07-24 10:21:36,398][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:21:36,398][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,398][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit21']
[2024-07-24 10:21:36,398][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,398][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,398][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,398][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 3
[2024-07-24 10:21:36,398][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,398][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,398][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,398][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,398][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:21:36,399][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,399][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit19', 'circuit21', 'circuit24']
[2024-07-24 10:21:36,399][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,399][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 4
[2024-07-24 10:21:36,399][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,399][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:21:36,399][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,399][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,399][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0']
[2024-07-24 10:21:36,399][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit23']
[2024-07-24 10:21:36,399][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit14', 'circuit16', 'circuit18', 'circuit19', 'circuit20']
[2024-07-24 10:21:36,399][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit21', 'circuit25']
[2024-07-24 10:21:36,399][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 5
[2024-07-24 10:21:36,399][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,399][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit25']
[2024-07-24 10:21:36,399][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:36,400][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:21:36,400][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,400][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,400][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:21:36,400][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0']
[2024-07-24 10:21:36,400][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 6
[2024-07-24 10:21:36,400][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit27']
[2024-07-24 10:21:36,400][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit25']
[2024-07-24 10:21:36,400][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,400][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit23']
[2024-07-24 10:21:36,400][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit21', 'circuit24']
[2024-07-24 10:21:36,400][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,400][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit25']
[2024-07-24 10:21:36,400][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit22']
[2024-07-24 10:21:36,400][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 7
[2024-07-24 10:21:36,400][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit27']
[2024-07-24 10:21:36,401][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,401][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit17']
[2024-07-24 10:21:36,401][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,401][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20']
[2024-07-24 10:21:36,401][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,401][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit19']
[2024-07-24 10:21:36,401][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit21', 'circuit25']
[2024-07-24 10:21:36,401][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 8
[2024-07-24 10:21:36,401][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit20', 'circuit21', 'circuit24']
[2024-07-24 10:21:36,401][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,401][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,401][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,401][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,401][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,401][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit27']
[2024-07-24 10:21:36,401][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit6', 'circuit7', 'circuit8', 'circuit12', 'circuit17', 'circuit18', 'circuit21', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:21:36,402][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 9
[2024-07-24 10:21:36,402][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit5', 'circuit6', 'circuit8', 'circuit10', 'circuit13', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:36,402][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit24']
[2024-07-24 10:21:36,402][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:21:36,402][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,402][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:21:36,402][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit24']
[2024-07-24 10:21:36,402][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,402][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit19', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:21:36,402][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 10
[2024-07-24 10:21:36,402][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit27']
[2024-07-24 10:21:36,402][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit16', 'circuit18']
[2024-07-24 10:21:36,402][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,402][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,402][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,403][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit19', 'circuit20', 'circuit21']
[2024-07-24 10:21:36,403][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit24']
[2024-07-24 10:21:36,403][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit14', 'circuit16']
[2024-07-24 10:21:36,403][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 11
[2024-07-24 10:21:36,403][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,403][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,403][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,403][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,403][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,403][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,403][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,403][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,403][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 12
[2024-07-24 10:21:36,403][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,403][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,403][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,404][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,404][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,404][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,404][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,404][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,404][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 13
[2024-07-24 10:21:36,404][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit16', 'circuit27']
[2024-07-24 10:21:36,404][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,404][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,404][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,404][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,404][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,404][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:21:36,404][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit23']
[2024-07-24 10:21:36,404][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 14
[2024-07-24 10:21:36,404][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,405][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,405][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,405][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,405][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,405][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,405][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,405][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,405][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 15
[2024-07-24 10:21:36,405][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,405][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,405][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,405][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,405][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,405][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,405][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,405][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,406][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 16
[2024-07-24 10:21:36,406][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,406][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,406][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,406][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,406][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,406][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,406][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,406][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,406][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 17
[2024-07-24 10:21:36,406][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,406][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,406][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,406][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,406][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,406][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,407][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,407][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,407][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 18
[2024-07-24 10:21:36,407][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,407][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,407][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,407][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,407][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,407][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,407][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,407][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,407][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 19
[2024-07-24 10:21:36,407][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,407][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,407][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,407][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,408][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,408][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,408][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,408][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,408][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 20
[2024-07-24 10:21:36,408][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,408][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,408][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,408][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,408][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,408][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,408][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,408][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,408][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 21
[2024-07-24 10:21:36,408][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,408][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,409][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,409][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,409][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,409][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,409][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,409][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,409][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 22
[2024-07-24 10:21:36,409][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,409][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,409][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,409][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,409][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,409][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,409][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,409][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,409][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 23
[2024-07-24 10:21:36,410][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,410][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,410][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,410][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,410][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,410][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,410][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,410][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,410][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 24
[2024-07-24 10:21:36,410][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,410][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,410][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,410][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,410][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,410][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,410][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,411][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,411][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 25
[2024-07-24 10:21:36,411][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,411][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,411][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,411][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,411][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,411][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,411][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,411][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,411][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 26
[2024-07-24 10:21:36,411][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,411][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,411][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,411][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,412][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,412][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,412][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,412][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,412][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 27
[2024-07-24 10:21:36,412][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,412][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,412][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,412][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,412][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,412][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,412][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,412][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,412][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 28
[2024-07-24 10:21:36,412][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,412][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,413][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,413][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,413][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,413][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,413][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,413][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,413][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 0
[2024-07-24 10:21:36,413][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:36,413][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:36,413][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,413][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:36,413][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit3', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:36,413][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:36,413][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit4', 'circuit5', 'circuit7', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:36,413][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit4', 'circuit5', 'circuit7', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:36,414][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,414][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 1
[2024-07-24 10:21:36,414][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:21:36,414][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,414][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,414][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,414][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,414][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,414][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,414][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,414][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:36,414][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 2
[2024-07-24 10:21:36,414][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:21:36,414][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit24']
[2024-07-24 10:21:36,414][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,414][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit20', 'circuit23']
[2024-07-24 10:21:36,415][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit21', 'circuit23', 'circuit24']
[2024-07-24 10:21:36,415][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,415][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,415][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,415][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:36,415][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 3
[2024-07-24 10:21:36,415][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,415][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,415][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,415][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,415][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,415][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,415][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,415][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,415][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0']
[2024-07-24 10:21:36,415][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 4
[2024-07-24 10:21:36,416][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,416][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16']
[2024-07-24 10:21:36,416][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0']
[2024-07-24 10:21:36,416][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit5']
[2024-07-24 10:21:36,416][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit5', 'circuit18']
[2024-07-24 10:21:36,416][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,416][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,416][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,416][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0']
[2024-07-24 10:21:36,416][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 5
[2024-07-24 10:21:36,416][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,416][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,416][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit4', 'circuit7']
[2024-07-24 10:21:36,416][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit8']
[2024-07-24 10:21:36,416][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,417][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,417][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0']
[2024-07-24 10:21:36,417][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit13']
[2024-07-24 10:21:36,417][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:36,417][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 6
[2024-07-24 10:21:36,417][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit20', 'circuit24']
[2024-07-24 10:21:36,417][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16']
[2024-07-24 10:21:36,417][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,417][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,417][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,417][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit6', 'circuit7', 'circuit9']
[2024-07-24 10:21:36,417][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit24']
[2024-07-24 10:21:36,417][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,417][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit11', 'circuit12']
[2024-07-24 10:21:36,417][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 7
[2024-07-24 10:21:36,417][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit25']
[2024-07-24 10:21:36,418][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,418][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit22']
[2024-07-24 10:21:36,418][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,418][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit23', 'circuit24']
[2024-07-24 10:21:36,418][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,418][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit18', 'circuit23']
[2024-07-24 10:21:36,418][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit14']
[2024-07-24 10:21:36,418][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit19', 'circuit20', 'circuit25']
[2024-07-24 10:21:36,418][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 8
[2024-07-24 10:21:36,418][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,418][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,418][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit21', 'circuit24']
[2024-07-24 10:21:36,418][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit20']
[2024-07-24 10:21:36,418][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit13', 'circuit14', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:21:36,418][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,418][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,419][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,419][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:36,419][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 9
[2024-07-24 10:21:36,419][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:21:36,419][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,419][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,419][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,419][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,419][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,419][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,419][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,419][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit24']
[2024-07-24 10:21:36,419][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 10
[2024-07-24 10:21:36,419][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,419][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13']
[2024-07-24 10:21:36,419][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14']
[2024-07-24 10:21:36,420][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,420][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,420][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,420][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,420][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,420][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:36,420][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 11
[2024-07-24 10:21:36,420][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,420][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,420][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,420][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,420][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,420][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,420][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,420][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,420][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:36,421][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 12
[2024-07-24 10:21:36,421][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,421][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,421][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,421][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,421][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,421][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,421][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,421][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,421][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:36,421][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 13
[2024-07-24 10:21:36,421][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,421][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit19']
[2024-07-24 10:21:36,421][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit19']
[2024-07-24 10:21:36,421][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:21:36,421][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit23', 'circuit25']
[2024-07-24 10:21:36,422][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,422][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,422][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,422][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:36,422][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 14
[2024-07-24 10:21:36,422][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,422][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,422][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,422][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,422][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,422][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,422][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,422][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,422][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:36,422][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 15
[2024-07-24 10:21:36,422][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,423][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,423][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,423][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,423][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,423][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,423][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,423][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,423][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:36,423][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 16
[2024-07-24 10:21:36,423][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,423][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,423][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,423][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,423][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,423][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,423][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,424][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,424][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:36,424][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 17
[2024-07-24 10:21:36,424][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,424][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,424][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,424][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,424][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,424][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,424][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,424][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,424][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:36,424][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 18
[2024-07-24 10:21:36,424][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,424][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,424][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,425][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,425][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,425][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,425][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,425][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,425][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:36,425][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 19
[2024-07-24 10:21:36,425][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,425][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,425][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,425][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,425][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,425][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,425][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,425][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,425][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:36,426][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 20
[2024-07-24 10:21:36,426][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,426][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,426][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,426][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,426][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,426][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,426][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,426][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,426][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:36,426][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 21
[2024-07-24 10:21:36,426][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,426][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,426][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,426][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,426][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,427][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,427][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,427][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,427][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:36,427][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 22
[2024-07-24 10:21:36,427][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,427][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,427][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,427][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,427][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,427][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,427][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,427][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,427][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:36,427][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 23
[2024-07-24 10:21:36,427][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,428][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,428][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,428][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,428][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,428][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,428][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,428][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,428][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:36,428][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 24
[2024-07-24 10:21:36,428][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,428][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,428][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,428][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,428][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,428][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,428][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,429][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,429][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:36,429][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 25
[2024-07-24 10:21:36,429][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,429][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,429][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,429][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,429][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,429][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,429][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,429][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,429][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:36,429][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 26
[2024-07-24 10:21:36,429][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,429][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,430][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,430][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,430][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,430][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,430][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,430][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,430][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,430][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 27
[2024-07-24 10:21:36,430][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,430][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,430][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,430][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,430][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,430][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,430][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,431][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,431][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,431][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 28
[2024-07-24 10:21:36,431][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,431][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,431][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,431][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,431][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,431][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,431][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,431][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,431][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,431][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 0
[2024-07-24 10:21:36,431][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:36,431][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit7', 'circuit8', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,431][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:36,432][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit5', 'circuit15', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:21:36,432][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:36,432][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit7', 'circuit9', 'circuit10', 'circuit12', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:36,432][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit11', 'circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:36,432][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit13', 'circuit15', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:21:36,432][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit13', 'circuit17', 'circuit20', 'circuit23', 'circuit27']
[2024-07-24 10:21:36,432][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit6', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit17', 'circuit20', 'circuit22']
[2024-07-24 10:21:36,432][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 1
[2024-07-24 10:21:36,432][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,432][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,432][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,432][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,432][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,432][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,432][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,433][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,433][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit26']
[2024-07-24 10:21:36,433][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:36,433][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 2
[2024-07-24 10:21:36,433][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,433][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,433][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,433][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,433][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,433][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,433][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,433][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,433][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:36,433][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:36,433][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 3
[2024-07-24 10:21:36,433][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,434][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,434][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,434][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit6', 'circuit7', 'circuit8', 'circuit27']
[2024-07-24 10:21:36,434][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,434][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,434][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,434][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,434][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:36,434][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:36,434][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 4
[2024-07-24 10:21:36,434][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,434][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,434][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,434][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,434][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,434][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,435][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,435][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,435][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:36,435][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:36,435][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 5
[2024-07-24 10:21:36,435][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,435][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,435][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,435][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,435][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,435][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,435][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,435][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,435][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0']
[2024-07-24 10:21:36,435][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:36,435][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 6
[2024-07-24 10:21:36,436][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit19', 'circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:21:36,436][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,436][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,436][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,436][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,436][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,436][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,436][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,436][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit24']
[2024-07-24 10:21:36,436][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit19', 'circuit22', 'circuit24']
[2024-07-24 10:21:36,436][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 7
[2024-07-24 10:21:36,436][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit17']
[2024-07-24 10:21:36,436][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit18', 'circuit20']
[2024-07-24 10:21:36,436][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,436][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit16', 'circuit20', 'circuit21']
[2024-07-24 10:21:36,437][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit18', 'circuit23']
[2024-07-24 10:21:36,437][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,437][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,437][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,437][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:36,437][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:36,437][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 8
[2024-07-24 10:21:36,437][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,437][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,437][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,437][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,437][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,437][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,437][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,437][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,437][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:36,438][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:36,438][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 9
[2024-07-24 10:21:36,438][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,438][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,438][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,438][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,438][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,438][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,438][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,438][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,438][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:36,438][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:36,438][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 10
[2024-07-24 10:21:36,438][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,438][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,438][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,439][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,439][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,439][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,439][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,439][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,439][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:36,439][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:36,439][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 11
[2024-07-24 10:21:36,439][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,439][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,439][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,439][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,439][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,439][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,439][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,439][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,440][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:36,440][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:36,440][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 12
[2024-07-24 10:21:36,440][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,440][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,440][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,440][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,440][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,440][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,440][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,440][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,440][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:36,440][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:36,440][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 13
[2024-07-24 10:21:36,440][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit18', 'circuit21']
[2024-07-24 10:21:36,440][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:21:36,441][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit20']
[2024-07-24 10:21:36,441][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,441][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,441][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,441][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit25']
[2024-07-24 10:21:36,441][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit16', 'circuit18', 'circuit20']
[2024-07-24 10:21:36,441][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:21:36,441][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:21:36,441][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 14
[2024-07-24 10:21:36,441][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,441][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,441][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,441][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,441][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,441][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,441][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,442][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,442][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:36,442][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:36,442][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 15
[2024-07-24 10:21:36,442][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,442][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,442][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,442][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,442][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,442][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,442][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,442][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,442][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:36,442][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:36,442][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 16
[2024-07-24 10:21:36,442][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,443][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,443][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,443][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,443][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,443][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,443][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,443][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,443][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:36,443][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:36,443][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 17
[2024-07-24 10:21:36,443][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,443][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,443][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,443][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,443][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,443][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,444][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,444][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,444][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:36,444][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:36,444][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 18
[2024-07-24 10:21:36,444][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,444][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,444][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,444][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,444][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,444][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,444][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,444][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,444][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:36,444][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:36,444][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 19
[2024-07-24 10:21:36,445][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,445][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,445][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,445][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,445][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,445][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,445][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,445][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,445][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:36,445][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:36,445][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 20
[2024-07-24 10:21:36,445][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,445][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,445][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,445][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,445][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,446][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,446][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,446][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,446][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:36,446][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:36,446][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 21
[2024-07-24 10:21:36,446][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,446][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,446][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,446][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,446][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,446][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,446][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,446][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,446][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:36,446][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:36,447][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 22
[2024-07-24 10:21:36,447][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,447][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,447][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,447][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,447][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,447][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,447][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,447][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,447][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:36,447][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:36,447][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 23
[2024-07-24 10:21:36,447][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,447][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,447][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,448][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,448][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,448][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,448][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,448][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,448][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:36,448][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:36,448][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 24
[2024-07-24 10:21:36,448][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,448][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,448][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,448][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,448][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,448][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,448][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,448][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,449][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:36,449][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:36,449][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 25
[2024-07-24 10:21:36,449][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,449][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,449][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,449][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,449][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,449][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,449][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,449][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,449][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:36,449][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:36,449][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 26
[2024-07-24 10:21:36,449][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,449][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,450][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,450][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,450][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,450][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,450][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,450][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,450][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,450][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,450][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 27
[2024-07-24 10:21:36,450][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,450][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,450][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,450][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,450][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,450][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,451][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,451][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,451][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,451][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,451][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 28
[2024-07-24 10:21:36,451][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,451][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,451][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,451][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,451][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,451][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,451][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,451][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,451][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,451][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,452][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 0
[2024-07-24 10:21:36,452][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:21:36,452][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit23']
[2024-07-24 10:21:36,452][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit9', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:21:36,452][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:21:36,452][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit8', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:21:36,452][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:21:36,452][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit3', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit10', 'circuit11', 'circuit13', 'circuit25']
[2024-07-24 10:21:36,452][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit4', 'circuit7', 'circuit12', 'circuit13']
[2024-07-24 10:21:36,452][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit10', 'circuit12']
[2024-07-24 10:21:36,452][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit6', 'circuit10', 'circuit17', 'circuit24']
[2024-07-24 10:21:36,452][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit8', 'circuit9']
[2024-07-24 10:21:36,452][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 1
[2024-07-24 10:21:36,452][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit24']
[2024-07-24 10:21:36,452][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,453][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,453][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,453][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,453][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,453][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,453][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,453][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:36,453][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:36,453][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:21:36,453][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 2
[2024-07-24 10:21:36,453][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,453][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,453][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,453][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,453][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,453][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,454][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,454][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,454][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:36,454][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:36,454][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:21:36,454][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 3
[2024-07-24 10:21:36,454][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit18', 'circuit22', 'circuit23', 'circuit27']
[2024-07-24 10:21:36,454][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit19', 'circuit23']
[2024-07-24 10:21:36,454][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit19', 'circuit22', 'circuit24']
[2024-07-24 10:21:36,454][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,454][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit18', 'circuit19', 'circuit20']
[2024-07-24 10:21:36,454][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,454][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit25']
[2024-07-24 10:21:36,454][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit21']
[2024-07-24 10:21:36,454][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit7', 'circuit8', 'circuit10', 'circuit11', 'circuit13', 'circuit22', 'circuit26']
[2024-07-24 10:21:36,454][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit10', 'circuit13']
[2024-07-24 10:21:36,455][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0']
[2024-07-24 10:21:36,455][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 4
[2024-07-24 10:21:36,455][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14']
[2024-07-24 10:21:36,455][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:21:36,455][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:21:36,455][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,455][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit21']
[2024-07-24 10:21:36,455][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,455][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,455][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,455][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:36,455][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:36,455][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit8']
[2024-07-24 10:21:36,455][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 5
[2024-07-24 10:21:36,455][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit27']
[2024-07-24 10:21:36,455][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:21:36,456][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit24']
[2024-07-24 10:21:36,456][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,456][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,456][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,456][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,456][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,456][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:36,456][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:36,456][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:21:36,456][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 6
[2024-07-24 10:21:36,456][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,456][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,456][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,456][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,456][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,456][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,457][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,457][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,457][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:36,457][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:36,457][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:21:36,457][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 7
[2024-07-24 10:21:36,457][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,457][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,457][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,457][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,457][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,457][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,457][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,457][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,457][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:36,457][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:36,458][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:21:36,458][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 8
[2024-07-24 10:21:36,458][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,458][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,458][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,458][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,458][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,458][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,458][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,458][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,458][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:36,458][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:36,458][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:21:36,458][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 9
[2024-07-24 10:21:36,458][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,458][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,459][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit19', 'circuit26']
[2024-07-24 10:21:36,459][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,459][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,459][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,459][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,459][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,459][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:36,459][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:36,459][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:21:36,459][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 10
[2024-07-24 10:21:36,459][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,459][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,459][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,459][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,459][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,460][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,460][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,460][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,460][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:36,460][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:36,460][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:21:36,460][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 11
[2024-07-24 10:21:36,460][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,460][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,460][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,460][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,460][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,460][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,460][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,460][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,460][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:36,461][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:36,461][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:21:36,461][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 12
[2024-07-24 10:21:36,461][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,461][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,461][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,461][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,461][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,461][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,461][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,461][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,461][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:36,461][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:36,461][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:21:36,461][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 13
[2024-07-24 10:21:36,461][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:21:36,462][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit16', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:21:36,462][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit24']
[2024-07-24 10:21:36,462][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,462][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,462][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,462][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:21:36,462][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,462][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24']
[2024-07-24 10:21:36,462][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit20', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:21:36,462][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:21:36,462][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 14
[2024-07-24 10:21:36,462][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,462][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,462][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,462][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,462][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,463][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,463][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,463][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,463][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:36,463][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:36,463][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:21:36,463][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 15
[2024-07-24 10:21:36,463][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,463][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,463][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,463][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,463][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,463][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,463][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,463][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,463][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:36,464][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:36,464][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:21:36,464][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 16
[2024-07-24 10:21:36,464][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,464][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,464][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,464][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,464][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,464][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,464][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,464][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,464][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:36,464][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:36,464][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:21:36,464][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 17
[2024-07-24 10:21:36,464][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,465][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,465][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,465][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,465][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,465][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,465][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,465][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,465][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:36,465][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:36,465][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:21:36,465][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 18
[2024-07-24 10:21:36,465][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,465][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,465][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,465][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,466][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,466][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,466][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,466][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,466][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:36,466][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:36,466][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:21:36,466][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 19
[2024-07-24 10:21:36,466][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,466][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,466][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,466][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,466][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,466][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,466][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,466][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,467][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:36,467][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:36,467][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:21:36,467][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 20
[2024-07-24 10:21:36,467][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,467][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,467][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,467][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,467][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,467][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,467][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,467][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,467][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:36,467][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:36,467][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:21:36,467][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 21
[2024-07-24 10:21:36,468][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,468][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,468][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,468][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,468][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,468][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,468][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,468][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,468][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:36,468][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:36,468][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:21:36,468][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 22
[2024-07-24 10:21:36,468][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,468][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,468][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,468][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,469][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,469][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,469][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,469][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,469][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:36,469][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:36,469][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:21:36,469][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 23
[2024-07-24 10:21:36,469][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,469][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,469][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,469][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,469][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,469][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,469][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,469][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,470][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:36,470][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:36,470][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:21:36,470][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 24
[2024-07-24 10:21:36,470][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,470][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,470][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,470][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,470][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,470][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,470][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,470][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,470][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:36,470][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:36,470][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:21:36,470][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 25
[2024-07-24 10:21:36,471][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:21:36,471][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:21:36,471][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:21:36,471][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:21:36,471][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:21:36,471][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:21:36,471][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:21:36,471][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:21:36,471][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:21:36,471][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:21:36,471][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:21:36,471][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 26
[2024-07-24 10:21:36,471][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,471][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,471][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,472][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,472][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,472][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,472][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,472][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,472][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,472][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,472][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,472][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 27
[2024-07-24 10:21:36,472][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,472][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,472][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,472][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,472][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,472][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,473][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,473][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,473][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,473][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,473][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,473][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 28
[2024-07-24 10:21:36,473][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,473][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,473][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,473][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,473][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,473][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,473][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,473][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,473][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,473][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:36,474][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:21:37,460][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:21:37,460][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:37,461][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:37,461][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:37,461][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:37,462][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:37,462][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:37,462][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:37,463][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:37,463][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:37,463][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:37,463][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:37,464][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:37,465][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.9675, 0.0325], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:37,467][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0065, 0.9935], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:37,468][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.6358, 0.3642], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:37,468][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.6853, 0.3147], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:37,470][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.9772, 0.0228], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:37,471][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.2539, 0.7461], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:37,472][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.9881, 0.0119], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:37,474][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.9119, 0.0881], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:37,475][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.3215, 0.6785], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:37,477][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.7118, 0.2882], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:37,478][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.7102, 0.2898], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:37,479][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.6916, 0.3084], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:37,481][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Anthony] are: tensor([0.3488, 0.3704, 0.2808], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:37,481][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Anthony] are: tensor([1.8365e-04, 6.9409e-05, 9.9975e-01], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:37,483][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Anthony] are: tensor([0.6160, 0.2863, 0.0977], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:37,484][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Anthony] are: tensor([0.0277, 0.0011, 0.9712], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:37,486][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Anthony] are: tensor([0.1183, 0.0257, 0.8560], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:37,487][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Anthony] are: tensor([3.7720e-02, 8.1616e-06, 9.6227e-01], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:37,488][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Anthony] are: tensor([0.4225, 0.2850, 0.2924], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:37,489][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Anthony] are: tensor([0.3921, 0.4624, 0.1455], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:37,491][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Anthony] are: tensor([0.5344, 0.2306, 0.2350], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:37,492][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Anthony] are: tensor([0.6557, 0.3048, 0.0395], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:37,492][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Anthony] are: tensor([0.4534, 0.2519, 0.2948], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:37,492][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Anthony] are: tensor([0.4859, 0.3234, 0.1908], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:37,493][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.7093, 0.0804, 0.1477, 0.0627], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:37,493][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ and] are: tensor([2.3034e-03, 3.9262e-02, 1.0576e-04, 9.5833e-01], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:37,493][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.2325, 0.1740, 0.0580, 0.5355], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:37,493][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.1105, 0.3776, 0.0499, 0.4620], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:37,494][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.3285, 0.1488, 0.2532, 0.2695], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:37,494][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1226, 0.1962, 0.0110, 0.6702], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:37,494][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.6403, 0.0306, 0.3058, 0.0232], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:37,495][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.2540, 0.1931, 0.2621, 0.2908], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:37,495][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0669, 0.4682, 0.0259, 0.4390], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:37,496][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.4259, 0.2378, 0.1152, 0.2210], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:37,497][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.4149, 0.3091, 0.0721, 0.2039], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:37,498][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.4563, 0.1993, 0.0840, 0.2604], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:37,499][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Travis] are: tensor([0.2129, 0.2701, 0.0681, 0.2627, 0.1862], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:37,500][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Travis] are: tensor([1.5118e-05, 2.2406e-05, 9.3010e-05, 4.0194e-05, 9.9983e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:37,502][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Travis] are: tensor([0.2886, 0.1602, 0.0179, 0.0992, 0.4341], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:37,503][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Travis] are: tensor([2.9967e-04, 1.0561e-05, 1.9052e-04, 2.7832e-05, 9.9947e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:37,504][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Travis] are: tensor([0.0129, 0.0018, 0.0068, 0.0020, 0.9765], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:37,505][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Travis] are: tensor([4.7706e-03, 6.1325e-07, 1.0074e-05, 1.5966e-07, 9.9522e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:37,506][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Travis] are: tensor([0.1951, 0.2582, 0.2602, 0.1483, 0.1383], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:37,507][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Travis] are: tensor([0.2073, 0.1557, 0.1487, 0.3301, 0.1582], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:37,509][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Travis] are: tensor([0.2549, 0.1890, 0.2497, 0.1400, 0.1664], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:37,510][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Travis] are: tensor([0.3608, 0.2612, 0.1480, 0.2215, 0.0085], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:37,511][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Travis] are: tensor([0.2696, 0.2266, 0.0937, 0.1486, 0.2615], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:37,513][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Travis] are: tensor([0.3541, 0.2175, 0.0972, 0.2051, 0.1261], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:37,514][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.4021, 0.0354, 0.1213, 0.0352, 0.0963, 0.3098], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:37,515][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ had] are: tensor([3.2203e-04, 1.6747e-03, 7.4178e-04, 2.8605e-03, 1.2639e-04, 9.9427e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:37,516][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.4600, 0.1173, 0.0751, 0.1388, 0.0715, 0.1374], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:37,517][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ had] are: tensor([4.9366e-03, 5.4257e-03, 8.8014e-04, 1.1481e-02, 2.0548e-03, 9.7522e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:37,519][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.2003, 0.0569, 0.0750, 0.1031, 0.1395, 0.4252], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:37,519][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ had] are: tensor([3.9796e-02, 1.8571e-03, 7.2338e-04, 1.2911e-03, 2.7444e-04, 9.5606e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:37,521][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.2850, 0.0213, 0.4079, 0.0200, 0.2373, 0.0286], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:37,522][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.1324, 0.1031, 0.0902, 0.2393, 0.1373, 0.2977], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:37,524][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.0968, 0.2720, 0.0293, 0.3572, 0.0237, 0.2210], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:37,525][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.2969, 0.1790, 0.1058, 0.1844, 0.1092, 0.1247], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:37,526][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.2517, 0.1941, 0.0676, 0.1422, 0.0357, 0.3087], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:37,528][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.4323, 0.1444, 0.0601, 0.1801, 0.0920, 0.0910], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:37,529][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.5293, 0.0610, 0.1461, 0.0461, 0.1007, 0.0760, 0.0408],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:37,530][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ a] are: tensor([8.5558e-04, 4.2998e-03, 1.5739e-03, 4.2977e-03, 4.1390e-04, 4.6828e-04,
        9.8809e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:37,531][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.2896, 0.1796, 0.0862, 0.2118, 0.0683, 0.1199, 0.0448],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:37,533][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0290, 0.0177, 0.0167, 0.0327, 0.0195, 0.1766, 0.7078],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:37,534][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.1377, 0.0303, 0.0718, 0.0426, 0.0789, 0.4304, 0.2082],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:37,535][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0557, 0.1292, 0.0052, 0.0967, 0.0044, 0.0446, 0.6641],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:37,537][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.3606, 0.0120, 0.2786, 0.0102, 0.2739, 0.0530, 0.0117],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:37,538][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0954, 0.0573, 0.0662, 0.1282, 0.1418, 0.2150, 0.2960],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:37,539][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0241, 0.1310, 0.0099, 0.1946, 0.0067, 0.1422, 0.4915],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:37,541][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.2594, 0.1661, 0.0924, 0.1685, 0.0761, 0.1045, 0.1329],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:37,542][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.2260, 0.1927, 0.0716, 0.1634, 0.0369, 0.0836, 0.2259],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:37,544][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.3329, 0.1334, 0.0732, 0.1433, 0.1207, 0.0860, 0.1104],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:37,545][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ lot] are: tensor([0.3396, 0.0751, 0.1939, 0.0793, 0.0655, 0.0708, 0.0840, 0.0917],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:37,546][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ lot] are: tensor([2.6497e-04, 1.0295e-03, 6.3491e-05, 1.2102e-03, 6.9342e-04, 1.3688e-03,
        5.0380e-04, 9.9487e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:37,547][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ lot] are: tensor([0.2853, 0.1103, 0.0844, 0.1972, 0.0637, 0.1465, 0.0761, 0.0365],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:37,548][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ lot] are: tensor([1.0759e-03, 1.2846e-04, 7.4875e-05, 2.5190e-04, 1.4961e-03, 2.0019e-03,
        1.6721e-03, 9.9330e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:37,549][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ lot] are: tensor([0.0450, 0.0140, 0.0029, 0.0155, 0.0532, 0.0595, 0.0700, 0.7399],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:37,550][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ lot] are: tensor([3.2514e-03, 1.1954e-04, 2.0727e-05, 1.7788e-05, 1.6411e-04, 9.6455e-06,
        5.2869e-06, 9.9641e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:37,551][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ lot] are: tensor([0.3054, 0.0660, 0.1429, 0.0385, 0.1280, 0.0436, 0.0570, 0.2186],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:37,551][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ lot] are: tensor([0.0915, 0.0493, 0.0137, 0.0971, 0.0904, 0.1575, 0.2911, 0.2094],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:37,551][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ lot] are: tensor([0.1256, 0.1526, 0.0333, 0.1410, 0.0351, 0.1151, 0.3417, 0.0557],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:37,552][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ lot] are: tensor([0.2477, 0.1572, 0.0690, 0.1521, 0.0774, 0.1021, 0.1310, 0.0634],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:37,552][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ lot] are: tensor([0.2107, 0.1513, 0.0427, 0.1251, 0.0411, 0.0844, 0.0842, 0.2605],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:37,552][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ lot] are: tensor([0.4514, 0.0865, 0.0534, 0.0896, 0.1092, 0.0611, 0.0451, 0.1038],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:37,553][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ of] are: tensor([0.3642, 0.0573, 0.1190, 0.0412, 0.1193, 0.0751, 0.0500, 0.1421, 0.0319],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:37,553][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ of] are: tensor([8.9873e-04, 1.5861e-02, 6.2899e-05, 2.1565e-02, 2.1261e-05, 6.7603e-04,
        3.8738e-04, 9.5701e-05, 9.6043e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:37,554][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ of] are: tensor([0.2982, 0.1413, 0.0601, 0.1313, 0.0504, 0.0760, 0.0602, 0.0836, 0.0989],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:37,555][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ of] are: tensor([0.0052, 0.0030, 0.0005, 0.0069, 0.0141, 0.0450, 0.0605, 0.3698, 0.4951],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:37,556][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ of] are: tensor([0.1428, 0.0195, 0.0440, 0.0232, 0.1322, 0.1027, 0.0665, 0.3082, 0.1609],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:37,558][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ of] are: tensor([0.0227, 0.0913, 0.0011, 0.1072, 0.0009, 0.0657, 0.2358, 0.0072, 0.4681],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:37,559][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ of] are: tensor([0.2227, 0.0190, 0.1833, 0.0167, 0.2633, 0.0434, 0.0175, 0.2221, 0.0119],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:37,560][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ of] are: tensor([0.0543, 0.0263, 0.0339, 0.0550, 0.0430, 0.1087, 0.1840, 0.2731, 0.2216],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:37,562][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ of] are: tensor([0.0229, 0.1177, 0.0119, 0.1840, 0.0072, 0.1239, 0.3541, 0.0216, 0.1567],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:37,563][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ of] are: tensor([0.2020, 0.1319, 0.0734, 0.1351, 0.0625, 0.0847, 0.1102, 0.0788, 0.1213],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:37,564][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ of] are: tensor([0.1688, 0.1565, 0.0528, 0.1480, 0.0250, 0.0764, 0.0909, 0.0590, 0.2225],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:37,566][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ of] are: tensor([0.2577, 0.1121, 0.0658, 0.1321, 0.1238, 0.0770, 0.0832, 0.0989, 0.0494],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:37,567][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ fun] are: tensor([0.2514, 0.1014, 0.1127, 0.0930, 0.0686, 0.0354, 0.0889, 0.0987, 0.0548,
        0.0951], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:37,568][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ fun] are: tensor([1.4098e-04, 4.5754e-05, 5.1837e-04, 3.7539e-05, 1.5562e-04, 2.0438e-05,
        1.1354e-03, 8.8541e-04, 1.7991e-05, 9.9704e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:37,569][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ fun] are: tensor([0.1925, 0.0668, 0.1183, 0.1067, 0.0632, 0.0970, 0.0889, 0.0717, 0.0984,
        0.0965], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:37,570][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ fun] are: tensor([4.4577e-04, 8.2966e-06, 7.8065e-05, 8.7108e-06, 2.4110e-05, 2.8329e-04,
        2.2893e-04, 1.8482e-03, 2.9447e-04, 9.9678e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:37,572][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ fun] are: tensor([0.0123, 0.0021, 0.0019, 0.0024, 0.0023, 0.0103, 0.0108, 0.0139, 0.0096,
        0.9343], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:37,573][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ fun] are: tensor([4.2282e-03, 2.8176e-05, 1.2069e-04, 3.7844e-06, 7.8665e-06, 4.2782e-07,
        1.7979e-06, 1.4491e-04, 2.7547e-07, 9.9546e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:37,574][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ fun] are: tensor([0.1909, 0.0405, 0.1921, 0.0315, 0.1862, 0.0265, 0.0288, 0.1259, 0.0344,
        0.1432], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:37,575][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ fun] are: tensor([0.0940, 0.0235, 0.0071, 0.0505, 0.0265, 0.0698, 0.1393, 0.1961, 0.2635,
        0.1297], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:37,577][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ fun] are: tensor([0.1290, 0.1192, 0.0493, 0.1769, 0.0226, 0.1043, 0.1951, 0.0640, 0.1028,
        0.0371], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:37,578][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ fun] are: tensor([0.1939, 0.1184, 0.0888, 0.1131, 0.0606, 0.0851, 0.0976, 0.0790, 0.1045,
        0.0589], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:37,580][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ fun] are: tensor([0.1315, 0.1025, 0.0636, 0.0995, 0.0394, 0.0563, 0.0827, 0.0863, 0.0715,
        0.2667], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:37,581][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ fun] are: tensor([0.3057, 0.1522, 0.0527, 0.1135, 0.0790, 0.0692, 0.0640, 0.0451, 0.0533,
        0.0655], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:37,583][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.2621, 0.0371, 0.0809, 0.0342, 0.0739, 0.0481, 0.0536, 0.1416, 0.0334,
        0.2097, 0.0253], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:37,583][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ at] are: tensor([7.4886e-04, 1.5250e-03, 2.2404e-04, 3.7652e-03, 4.3963e-04, 1.5075e-04,
        1.4843e-03, 3.0382e-05, 4.3030e-03, 3.3100e-05, 9.8730e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:37,585][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.1942, 0.1002, 0.0424, 0.1185, 0.0564, 0.0784, 0.0439, 0.0620, 0.1147,
        0.0782, 0.1110], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:37,586][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ at] are: tensor([1.0224e-03, 3.5278e-04, 7.9464e-05, 6.9248e-04, 8.4767e-05, 4.8618e-03,
        7.4774e-03, 3.9671e-03, 3.0006e-02, 1.3053e-01, 8.2093e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:37,587][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.0620, 0.0063, 0.0051, 0.0095, 0.0118, 0.0582, 0.0343, 0.0469, 0.0709,
        0.3789, 0.3161], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:37,589][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.0545, 0.0231, 0.0016, 0.0096, 0.0048, 0.0363, 0.0160, 0.0012, 0.0039,
        0.0009, 0.8481], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:37,590][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.1623, 0.0124, 0.2095, 0.0121, 0.1871, 0.0397, 0.0156, 0.1723, 0.0119,
        0.1580, 0.0193], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:37,592][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0365, 0.0124, 0.0076, 0.0280, 0.0230, 0.0467, 0.0819, 0.1097, 0.1263,
        0.1928, 0.3350], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:37,593][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.0240, 0.1162, 0.0094, 0.2107, 0.0067, 0.1120, 0.1973, 0.0245, 0.1664,
        0.0261, 0.1067], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:37,594][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.1488, 0.1038, 0.0606, 0.1124, 0.0550, 0.0778, 0.0898, 0.0691, 0.1083,
        0.0722, 0.1021], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:37,596][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.1427, 0.1104, 0.0459, 0.1136, 0.0394, 0.0828, 0.0957, 0.0344, 0.0917,
        0.0301, 0.2133], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:37,597][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.2567, 0.0880, 0.0497, 0.0913, 0.0779, 0.0545, 0.0476, 0.0859, 0.0478,
        0.0833, 0.1172], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:37,599][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.4023, 0.0341, 0.0975, 0.0220, 0.0866, 0.0445, 0.0195, 0.0867, 0.0196,
        0.1424, 0.0209, 0.0238], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:37,599][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ the] are: tensor([2.9751e-03, 1.8210e-02, 4.3203e-04, 3.9242e-02, 1.0791e-04, 2.7151e-04,
        3.3099e-02, 8.6438e-05, 6.8753e-02, 7.4390e-05, 4.1115e-02, 7.9563e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:37,601][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.1800, 0.0881, 0.0391, 0.0983, 0.0416, 0.0915, 0.0285, 0.0676, 0.1096,
        0.0609, 0.1658, 0.0290], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:37,602][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ the] are: tensor([1.0766e-02, 1.6524e-03, 6.2340e-04, 1.8818e-03, 1.6579e-03, 7.3199e-03,
        1.8886e-02, 1.2110e-02, 6.1516e-02, 5.5835e-02, 1.8249e-01, 6.4526e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:37,603][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.1106, 0.0123, 0.0195, 0.0163, 0.0197, 0.0773, 0.0331, 0.0499, 0.0974,
        0.1402, 0.2299, 0.1939], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:37,605][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0654, 0.1024, 0.0091, 0.0838, 0.0204, 0.0627, 0.2055, 0.0499, 0.0538,
        0.0112, 0.0574, 0.2784], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:37,606][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.1802, 0.0030, 0.2119, 0.0029, 0.2283, 0.0173, 0.0033, 0.1519, 0.0025,
        0.1903, 0.0065, 0.0020], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:37,607][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0378, 0.0088, 0.0061, 0.0175, 0.0292, 0.0228, 0.0364, 0.0571, 0.0939,
        0.0964, 0.2914, 0.3026], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:37,608][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0084, 0.0713, 0.0068, 0.1147, 0.0027, 0.0747, 0.2406, 0.0078, 0.0764,
        0.0135, 0.0510, 0.3320], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:37,608][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.1668, 0.0942, 0.0591, 0.0977, 0.0491, 0.0685, 0.0781, 0.0638, 0.0908,
        0.0492, 0.0920, 0.0906], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:37,609][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.1748, 0.1070, 0.0509, 0.1067, 0.0360, 0.0545, 0.1119, 0.0416, 0.0642,
        0.0301, 0.0737, 0.1486], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:37,609][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.1963, 0.0790, 0.0621, 0.0828, 0.0862, 0.0512, 0.0857, 0.0754, 0.0313,
        0.0785, 0.0781, 0.0932], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:37,609][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ hospital] are: tensor([0.1451, 0.0691, 0.1034, 0.0697, 0.0728, 0.0668, 0.0695, 0.0355, 0.0679,
        0.0673, 0.0464, 0.0742, 0.1123], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:37,610][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ hospital] are: tensor([2.5590e-05, 1.6636e-04, 1.1465e-04, 8.7247e-05, 8.4772e-04, 4.2452e-04,
        2.7491e-05, 6.6746e-05, 7.7516e-06, 1.6970e-05, 2.7122e-04, 2.4056e-05,
        9.9792e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:37,610][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ hospital] are: tensor([0.2102, 0.0594, 0.0931, 0.0455, 0.0198, 0.0531, 0.0603, 0.0548, 0.0590,
        0.0635, 0.0525, 0.0595, 0.1691], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:37,610][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ hospital] are: tensor([2.4805e-04, 4.7510e-07, 5.8079e-05, 8.7695e-07, 1.3377e-05, 1.3054e-05,
        6.1770e-06, 1.0982e-04, 2.8450e-05, 7.7763e-04, 2.0312e-04, 1.2121e-04,
        9.9842e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:37,611][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ hospital] are: tensor([3.8999e-03, 1.7760e-04, 1.4515e-03, 1.3758e-04, 5.0344e-04, 2.3748e-04,
        3.0095e-04, 2.6881e-04, 4.0237e-04, 9.1878e-04, 1.6768e-03, 1.4152e-03,
        9.8861e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:37,611][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ hospital] are: tensor([2.1877e-03, 4.3898e-06, 4.6751e-05, 7.4061e-07, 4.3969e-05, 1.4956e-05,
        4.0290e-07, 1.4905e-05, 7.3216e-08, 1.4067e-06, 4.0707e-07, 1.5992e-07,
        9.9768e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:37,613][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ hospital] are: tensor([0.1984, 0.0601, 0.1217, 0.0417, 0.1344, 0.0220, 0.0294, 0.0339, 0.0280,
        0.0773, 0.0176, 0.0257, 0.2099], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:37,614][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ hospital] are: tensor([0.0427, 0.0124, 0.0040, 0.0204, 0.0082, 0.0298, 0.0361, 0.0307, 0.0760,
        0.1222, 0.1895, 0.3138, 0.1142], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:37,615][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ hospital] are: tensor([0.1515, 0.0762, 0.0595, 0.0849, 0.0388, 0.0574, 0.0907, 0.0489, 0.0794,
        0.0647, 0.0693, 0.0980, 0.0808], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:37,617][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ hospital] are: tensor([0.1917, 0.1021, 0.0736, 0.0892, 0.0568, 0.0648, 0.0801, 0.0595, 0.0698,
        0.0465, 0.0738, 0.0808, 0.0115], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:37,618][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ hospital] are: tensor([0.1252, 0.0935, 0.0433, 0.0819, 0.0349, 0.0702, 0.0749, 0.0289, 0.0439,
        0.0140, 0.0586, 0.0546, 0.2759], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:37,619][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ hospital] are: tensor([0.1423, 0.0904, 0.0457, 0.0773, 0.0740, 0.0458, 0.0444, 0.0793, 0.0843,
        0.0974, 0.0965, 0.0502, 0.0723], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:37,621][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.4449, 0.0139, 0.0831, 0.0116, 0.0850, 0.0484, 0.0218, 0.0786, 0.0089,
        0.1083, 0.0169, 0.0370, 0.0317, 0.0101], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:37,621][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [.] are: tensor([2.9670e-03, 2.9773e-02, 2.7755e-05, 5.5119e-03, 4.5691e-04, 1.1794e-04,
        2.6022e-04, 2.2072e-04, 2.5132e-03, 7.6660e-05, 1.1373e-03, 2.5236e-04,
        2.2062e-04, 9.5646e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:37,623][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.3431, 0.0438, 0.0325, 0.0375, 0.0324, 0.1920, 0.0173, 0.0463, 0.0826,
        0.0366, 0.0510, 0.0213, 0.0191, 0.0444], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:37,624][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [.] are: tensor([1.1994e-02, 1.4260e-03, 4.2386e-04, 1.3817e-03, 7.9925e-04, 4.3083e-03,
        4.6444e-03, 1.8872e-02, 1.8070e-02, 1.9196e-02, 6.2098e-02, 1.6867e-01,
        2.2868e-01, 4.5944e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:37,625][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0311, 0.0105, 0.0096, 0.0200, 0.0059, 0.0217, 0.0185, 0.0459, 0.0612,
        0.0694, 0.1416, 0.1212, 0.1058, 0.3377], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:37,627][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.1018, 0.1619, 0.0307, 0.1037, 0.0144, 0.0717, 0.0779, 0.0326, 0.0512,
        0.0108, 0.0540, 0.0627, 0.0182, 0.2084], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:37,628][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.2171, 0.0056, 0.1869, 0.0041, 0.1250, 0.0114, 0.0056, 0.0843, 0.0034,
        0.1781, 0.0073, 0.0036, 0.1649, 0.0027], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:37,630][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0181, 0.0044, 0.0041, 0.0081, 0.0122, 0.0121, 0.0185, 0.0302, 0.0315,
        0.0668, 0.0939, 0.1451, 0.1519, 0.4032], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:37,631][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.0143, 0.1268, 0.0072, 0.1011, 0.0049, 0.0225, 0.0845, 0.0064, 0.0606,
        0.0048, 0.0400, 0.1368, 0.0051, 0.3848], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:37,633][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.1422, 0.0795, 0.0537, 0.0826, 0.0480, 0.0630, 0.0636, 0.0599, 0.0665,
        0.0594, 0.0697, 0.0717, 0.0527, 0.0875], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:37,634][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.1060, 0.0894, 0.0322, 0.0962, 0.0460, 0.0728, 0.0596, 0.0626, 0.0747,
        0.0524, 0.0737, 0.0599, 0.0485, 0.1259], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:37,635][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.2171, 0.0757, 0.0514, 0.0719, 0.0774, 0.0507, 0.0439, 0.0700, 0.0357,
        0.0638, 0.0756, 0.0340, 0.0389, 0.0941], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:37,637][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Anthony] are: tensor([0.1072, 0.1011, 0.1438, 0.0794, 0.0316, 0.0128, 0.0349, 0.0127, 0.0605,
        0.0451, 0.0460, 0.0543, 0.0549, 0.0679, 0.1477], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:37,638][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Anthony] are: tensor([5.8848e-05, 7.9151e-06, 4.8324e-01, 1.6936e-05, 7.8669e-06, 1.8123e-05,
        2.0471e-05, 3.9493e-06, 2.1139e-05, 4.5853e-05, 2.0582e-05, 1.3348e-05,
        5.4856e-06, 1.1357e-06, 5.1652e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:37,639][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Anthony] are: tensor([0.2029, 0.0912, 0.0663, 0.0432, 0.0355, 0.0789, 0.0735, 0.0230, 0.0722,
        0.0241, 0.0399, 0.0846, 0.0833, 0.0386, 0.0429], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:37,640][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Anthony] are: tensor([6.8918e-04, 1.3910e-06, 1.0527e-03, 2.2746e-06, 8.2793e-05, 1.0053e-05,
        2.4149e-05, 5.0940e-05, 4.8046e-05, 4.4779e-04, 2.0896e-04, 4.5625e-04,
        6.8756e-04, 1.8024e-04, 9.9606e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:37,641][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Anthony] are: tensor([8.6298e-03, 1.5131e-03, 3.7211e-02, 1.1290e-03, 2.3157e-03, 8.8557e-04,
        8.0976e-04, 2.1087e-03, 4.0235e-03, 7.5166e-03, 8.8826e-03, 4.8645e-03,
        2.5814e-03, 1.8717e-02, 8.9881e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:37,642][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Anthony] are: tensor([2.8199e-03, 3.3454e-07, 5.5974e-01, 1.4213e-07, 2.6441e-06, 2.9749e-07,
        6.1303e-08, 2.0650e-07, 7.6691e-09, 2.0312e-06, 2.4269e-08, 3.9131e-08,
        1.5266e-06, 1.5813e-08, 4.3743e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:37,643][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Anthony] are: tensor([0.1038, 0.0882, 0.1859, 0.0516, 0.0852, 0.0099, 0.0278, 0.0156, 0.0227,
        0.0208, 0.0127, 0.0459, 0.1245, 0.0493, 0.1561], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:37,645][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Anthony] are: tensor([0.0293, 0.0104, 0.0038, 0.0149, 0.0039, 0.0115, 0.0241, 0.0194, 0.0446,
        0.0096, 0.1320, 0.1082, 0.0919, 0.3746, 0.1218], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:37,646][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Anthony] are: tensor([0.1353, 0.0589, 0.1043, 0.0531, 0.1196, 0.0226, 0.0471, 0.0223, 0.0428,
        0.0216, 0.0402, 0.0584, 0.1082, 0.0516, 0.1140], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:37,648][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Anthony] are: tensor([0.1737, 0.0908, 0.0137, 0.0852, 0.0596, 0.0530, 0.0537, 0.0327, 0.0744,
        0.0501, 0.0651, 0.0686, 0.0869, 0.0815, 0.0111], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:37,649][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Anthony] are: tensor([0.0887, 0.0662, 0.2141, 0.0676, 0.0262, 0.0381, 0.0494, 0.0159, 0.0568,
        0.0260, 0.0475, 0.0473, 0.0258, 0.0429, 0.1876], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:37,651][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Anthony] are: tensor([0.1018, 0.0610, 0.0621, 0.0677, 0.0539, 0.0598, 0.0355, 0.0762, 0.0354,
        0.1063, 0.0719, 0.0339, 0.0561, 0.0976, 0.0807], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:37,652][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.2006, 0.0197, 0.0637, 0.0238, 0.0640, 0.0984, 0.0188, 0.0478, 0.0231,
        0.0383, 0.0189, 0.0175, 0.0502, 0.0157, 0.0830, 0.2164],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:37,653][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([3.7533e-04, 5.8270e-04, 1.5728e-04, 1.2671e-03, 1.0612e-04, 6.5425e-03,
        1.4130e-04, 3.2865e-04, 7.6630e-04, 1.2339e-04, 3.5817e-04, 1.7588e-04,
        4.1545e-05, 5.0912e-05, 8.0016e-05, 9.8890e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:37,654][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.1652, 0.0414, 0.0498, 0.0499, 0.0185, 0.0743, 0.0429, 0.0559, 0.0713,
        0.0626, 0.0703, 0.0528, 0.0520, 0.0701, 0.0490, 0.0740],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:37,655][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([8.5901e-04, 4.6022e-06, 1.0223e-06, 3.9982e-06, 1.8811e-06, 4.5586e-05,
        1.1803e-05, 3.8647e-05, 4.7166e-05, 2.9236e-04, 1.4119e-04, 2.0658e-04,
        5.5073e-04, 6.5230e-04, 7.2379e-04, 9.9642e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:37,657][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.0830, 0.0065, 0.0041, 0.0065, 0.0030, 0.0107, 0.0075, 0.0101, 0.0189,
        0.0227, 0.0394, 0.0214, 0.0630, 0.0429, 0.0497, 0.6108],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:37,658][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([3.9537e-02, 2.1612e-05, 9.1917e-05, 2.1874e-05, 2.0068e-05, 1.8039e-03,
        1.2768e-05, 7.0414e-06, 5.9637e-06, 5.3260e-05, 1.5034e-05, 7.0799e-06,
        1.6377e-05, 1.0706e-06, 1.5326e-05, 9.5837e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:37,659][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0758, 0.0095, 0.1253, 0.0093, 0.0871, 0.0113, 0.0135, 0.0611, 0.0070,
        0.1171, 0.0082, 0.0105, 0.2216, 0.0097, 0.2098, 0.0233],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:37,661][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0188, 0.0042, 0.0038, 0.0062, 0.0050, 0.0062, 0.0119, 0.0139, 0.0153,
        0.0242, 0.0560, 0.0771, 0.0375, 0.3085, 0.1874, 0.2244],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:37,662][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.0743, 0.0733, 0.0132, 0.0929, 0.0079, 0.0402, 0.1057, 0.0363, 0.0818,
        0.0658, 0.0762, 0.1282, 0.0506, 0.0995, 0.0179, 0.0362],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:37,664][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.1110, 0.0609, 0.0420, 0.0646, 0.0498, 0.0601, 0.0540, 0.0539, 0.0596,
        0.0733, 0.0540, 0.0581, 0.0631, 0.0875, 0.0487, 0.0593],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:37,665][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0794, 0.0560, 0.0356, 0.0631, 0.0319, 0.1052, 0.0514, 0.0307, 0.0542,
        0.0339, 0.0560, 0.0494, 0.0321, 0.0665, 0.0353, 0.2192],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:37,666][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.2205, 0.0778, 0.0398, 0.0930, 0.0432, 0.0409, 0.0373, 0.0471, 0.0394,
        0.0456, 0.0691, 0.0335, 0.0410, 0.0838, 0.0331, 0.0550],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:37,666][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.2520, 0.0199, 0.0632, 0.0154, 0.0443, 0.0321, 0.0138, 0.0613, 0.0130,
        0.1060, 0.0129, 0.0244, 0.0782, 0.0182, 0.0931, 0.1311, 0.0212],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:37,667][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ a] are: tensor([4.3910e-04, 1.1430e-03, 4.7682e-04, 1.2515e-03, 1.5823e-04, 1.3490e-04,
        4.3309e-01, 1.8437e-04, 1.1685e-03, 9.9681e-04, 3.4107e-03, 1.4669e-02,
        9.5686e-05, 2.8399e-04, 2.5792e-04, 1.1745e-04, 5.4212e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:37,667][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0959, 0.0490, 0.0353, 0.0747, 0.0313, 0.0449, 0.0152, 0.0568, 0.0753,
        0.0424, 0.1142, 0.0177, 0.0456, 0.1589, 0.0409, 0.0850, 0.0171],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:37,668][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ a] are: tensor([3.4449e-03, 2.6178e-04, 1.3788e-04, 1.6759e-04, 7.8326e-05, 3.6047e-04,
        1.2553e-03, 5.3146e-04, 1.6742e-03, 1.6822e-03, 4.5729e-03, 1.8691e-02,
        7.6468e-03, 2.7744e-02, 5.4426e-02, 1.2674e-01, 7.5058e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:37,668][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0220, 0.0026, 0.0039, 0.0028, 0.0027, 0.0183, 0.0073, 0.0068, 0.0110,
        0.0254, 0.0240, 0.0183, 0.0425, 0.0213, 0.0703, 0.5332, 0.1876],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:37,668][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0166, 0.0528, 0.0028, 0.0463, 0.0024, 0.0248, 0.4154, 0.0038, 0.0249,
        0.0043, 0.0314, 0.1011, 0.0025, 0.0132, 0.0006, 0.0039, 0.2533],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:37,669][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.1057, 0.0024, 0.0949, 0.0024, 0.1027, 0.0155, 0.0027, 0.1009, 0.0026,
        0.1278, 0.0053, 0.0021, 0.1654, 0.0022, 0.1932, 0.0701, 0.0040],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:37,670][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0139, 0.0025, 0.0023, 0.0040, 0.0037, 0.0036, 0.0040, 0.0073, 0.0095,
        0.0120, 0.0300, 0.0352, 0.0213, 0.1997, 0.1181, 0.2743, 0.2586],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:37,671][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0069, 0.0337, 0.0029, 0.0591, 0.0020, 0.0459, 0.1360, 0.0064, 0.0435,
        0.0111, 0.0353, 0.1946, 0.0150, 0.0996, 0.0058, 0.0233, 0.2787],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:37,673][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.1041, 0.0637, 0.0442, 0.0701, 0.0349, 0.0471, 0.0548, 0.0462, 0.0647,
        0.0407, 0.0640, 0.0659, 0.0538, 0.0692, 0.0477, 0.0592, 0.0697],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:37,674][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0731, 0.0568, 0.0327, 0.0670, 0.0232, 0.0444, 0.1242, 0.0333, 0.0532,
        0.0381, 0.0686, 0.0802, 0.0491, 0.0541, 0.0302, 0.0354, 0.1364],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:37,675][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.1776, 0.0666, 0.0448, 0.0636, 0.0658, 0.0432, 0.0488, 0.0564, 0.0279,
        0.0547, 0.0555, 0.0360, 0.0319, 0.0719, 0.0400, 0.0675, 0.0478],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:37,677][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ drink] are: tensor([0.1443, 0.0427, 0.0296, 0.0371, 0.0362, 0.0270, 0.0328, 0.0347, 0.0276,
        0.0643, 0.0293, 0.0320, 0.1467, 0.0334, 0.0245, 0.0368, 0.0362, 0.1849],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:37,678][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ drink] are: tensor([2.5846e-04, 7.7059e-05, 5.8600e-04, 9.0857e-05, 3.7402e-04, 5.5531e-05,
        1.2057e-05, 4.7693e-05, 2.8550e-05, 8.0274e-04, 1.8103e-04, 7.6665e-06,
        3.6405e-04, 1.0020e-05, 3.0619e-04, 8.4900e-05, 7.3691e-06, 9.9671e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:37,679][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ drink] are: tensor([0.1413, 0.0457, 0.0417, 0.0406, 0.0282, 0.0410, 0.0645, 0.0804, 0.0491,
        0.0728, 0.0544, 0.0593, 0.0230, 0.0616, 0.0325, 0.0253, 0.0647, 0.0738],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:37,680][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ drink] are: tensor([1.2571e-03, 1.6932e-06, 8.7059e-06, 8.5761e-07, 4.1673e-06, 5.5198e-06,
        1.2646e-06, 6.0041e-05, 4.4593e-06, 2.8735e-04, 1.5978e-05, 1.4221e-05,
        1.8269e-03, 8.8903e-05, 2.0409e-03, 1.2341e-02, 4.0001e-04, 9.8164e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:37,682][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ drink] are: tensor([0.0506, 0.0023, 0.0064, 0.0018, 0.0075, 0.0016, 0.0017, 0.0044, 0.0033,
        0.0106, 0.0041, 0.0062, 0.0059, 0.0056, 0.0358, 0.0217, 0.0152, 0.8152],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:37,683][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ drink] are: tensor([4.0919e-03, 7.5859e-06, 4.4396e-05, 1.4039e-06, 2.8617e-06, 1.5257e-06,
        1.4009e-06, 4.5550e-06, 4.7765e-07, 4.1686e-05, 1.0413e-06, 2.3705e-07,
        5.7741e-06, 1.7014e-07, 8.0350e-06, 4.8792e-06, 4.6025e-07, 9.9578e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:37,684][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ drink] are: tensor([0.0859, 0.0298, 0.1104, 0.0220, 0.0469, 0.0085, 0.0148, 0.0424, 0.0137,
        0.0963, 0.0115, 0.0141, 0.2088, 0.0166, 0.1076, 0.0125, 0.0166, 0.1417],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:37,686][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ drink] are: tensor([0.0309, 0.0041, 0.0007, 0.0047, 0.0018, 0.0068, 0.0097, 0.0068, 0.0136,
        0.0184, 0.0357, 0.0417, 0.0371, 0.1589, 0.0109, 0.2517, 0.3168, 0.0497],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:37,687][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ drink] are: tensor([0.1693, 0.0618, 0.0265, 0.0607, 0.0289, 0.0353, 0.0520, 0.0589, 0.0501,
        0.1070, 0.0429, 0.0498, 0.0357, 0.0335, 0.0217, 0.0492, 0.0565, 0.0602],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:37,688][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ drink] are: tensor([0.1238, 0.0650, 0.0573, 0.0613, 0.0342, 0.0500, 0.0476, 0.0440, 0.0505,
        0.0498, 0.0421, 0.0492, 0.0650, 0.0689, 0.0569, 0.0574, 0.0555, 0.0214],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:37,690][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ drink] are: tensor([0.0814, 0.0518, 0.0365, 0.0615, 0.0282, 0.0473, 0.0430, 0.0346, 0.0549,
        0.0446, 0.0408, 0.0446, 0.0355, 0.0543, 0.0300, 0.0325, 0.0381, 0.2405],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:37,691][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ drink] are: tensor([0.1146, 0.0540, 0.0567, 0.0459, 0.0745, 0.0421, 0.0328, 0.0585, 0.0311,
        0.0654, 0.0581, 0.0297, 0.0380, 0.0762, 0.0557, 0.0677, 0.0326, 0.0663],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:37,693][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.2056, 0.0180, 0.0619, 0.0151, 0.0438, 0.0502, 0.0160, 0.0516, 0.0166,
        0.0570, 0.0154, 0.0240, 0.0291, 0.0166, 0.1006, 0.1344, 0.0260, 0.1037,
        0.0145], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:37,694][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ to] are: tensor([4.0645e-03, 8.9857e-03, 2.1719e-05, 2.6126e-02, 8.6956e-05, 2.3098e-04,
        1.0628e-03, 3.7219e-05, 2.5763e-02, 1.8243e-04, 1.4922e-02, 1.4075e-03,
        1.7330e-05, 6.9827e-03, 9.2497e-06, 6.6518e-04, 9.9174e-04, 5.0125e-05,
        9.0839e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:37,695][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1041, 0.0424, 0.0214, 0.0618, 0.0233, 0.0380, 0.0157, 0.0454, 0.0667,
        0.0352, 0.0910, 0.0187, 0.0192, 0.1871, 0.0218, 0.0534, 0.0175, 0.0120,
        0.1251], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:37,696][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ to] are: tensor([1.1973e-03, 6.3143e-05, 6.8123e-06, 3.0277e-05, 8.7319e-07, 7.2251e-05,
        1.0073e-04, 3.0045e-05, 3.9245e-04, 2.6352e-04, 5.9617e-04, 2.4224e-03,
        4.8173e-04, 4.3876e-03, 1.4507e-03, 2.5066e-01, 7.1239e-02, 2.1033e-02,
        6.4557e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:37,698][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0205, 0.0011, 0.0008, 0.0016, 0.0004, 0.0109, 0.0029, 0.0046, 0.0040,
        0.0262, 0.0103, 0.0077, 0.0125, 0.0125, 0.0111, 0.3677, 0.0825, 0.1498,
        0.2729], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:37,699][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0298, 0.0437, 0.0016, 0.0588, 0.0013, 0.0251, 0.1861, 0.0075, 0.0396,
        0.0096, 0.0168, 0.1359, 0.0005, 0.0165, 0.0003, 0.0049, 0.1150, 0.0003,
        0.3067], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:37,701][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0884, 0.0039, 0.0310, 0.0034, 0.0462, 0.0119, 0.0032, 0.0379, 0.0047,
        0.1080, 0.0172, 0.0027, 0.1072, 0.0047, 0.0609, 0.0573, 0.0052, 0.0948,
        0.3113], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:37,702][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0146, 0.0021, 0.0025, 0.0029, 0.0025, 0.0026, 0.0031, 0.0043, 0.0038,
        0.0111, 0.0110, 0.0183, 0.0162, 0.0912, 0.0758, 0.1206, 0.1588, 0.1831,
        0.2757], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:37,703][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0053, 0.0387, 0.0026, 0.0694, 0.0010, 0.0314, 0.0850, 0.0057, 0.0494,
        0.0058, 0.0337, 0.1518, 0.0087, 0.1172, 0.0046, 0.0174, 0.1673, 0.0131,
        0.1916], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:37,705][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0889, 0.0529, 0.0389, 0.0598, 0.0304, 0.0406, 0.0507, 0.0403, 0.0541,
        0.0430, 0.0542, 0.0582, 0.0464, 0.0610, 0.0429, 0.0534, 0.0651, 0.0381,
        0.0813], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:37,707][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0718, 0.0549, 0.0231, 0.0706, 0.0268, 0.0553, 0.0637, 0.0348, 0.0629,
        0.0402, 0.0635, 0.0635, 0.0264, 0.0679, 0.0223, 0.0555, 0.0707, 0.0271,
        0.0989], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:37,708][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.1594, 0.0614, 0.0406, 0.0621, 0.0592, 0.0457, 0.0402, 0.0489, 0.0289,
        0.0478, 0.0578, 0.0288, 0.0257, 0.0617, 0.0343, 0.0638, 0.0374, 0.0385,
        0.0579], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:37,720][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:21:37,721][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:37,721][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:37,722][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:37,723][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:37,723][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:37,724][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:37,725][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:37,726][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:37,727][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:37,727][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:37,728][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:37,729][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:37,729][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.9675, 0.0325], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:37,730][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0065, 0.9935], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:37,732][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.6358, 0.3642], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:37,733][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.6853, 0.3147], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:37,735][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.9772, 0.0228], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:37,737][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.2539, 0.7461], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:37,738][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.9881, 0.0119], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:37,740][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.9119, 0.0881], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:37,741][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.3215, 0.6785], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:37,742][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.7118, 0.2882], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:37,742][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.7102, 0.2898], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:37,743][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.6916, 0.3084], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:37,744][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Anthony] are: tensor([0.3488, 0.3704, 0.2808], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:37,745][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Anthony] are: tensor([1.8365e-04, 6.9409e-05, 9.9975e-01], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:37,746][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Anthony] are: tensor([0.6160, 0.2863, 0.0977], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:37,748][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Anthony] are: tensor([0.0277, 0.0011, 0.9712], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:37,749][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Anthony] are: tensor([0.1183, 0.0257, 0.8560], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:37,750][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Anthony] are: tensor([3.7720e-02, 8.1616e-06, 9.6227e-01], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:37,752][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Anthony] are: tensor([0.4225, 0.2850, 0.2924], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:37,753][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Anthony] are: tensor([0.3921, 0.4624, 0.1455], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:37,755][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Anthony] are: tensor([0.5344, 0.2306, 0.2350], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:37,757][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Anthony] are: tensor([0.6557, 0.3048, 0.0395], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:37,758][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Anthony] are: tensor([0.4534, 0.2519, 0.2948], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:37,760][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Anthony] are: tensor([0.4859, 0.3234, 0.1908], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:37,761][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.7093, 0.0804, 0.1477, 0.0627], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:37,762][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([2.3034e-03, 3.9262e-02, 1.0576e-04, 9.5833e-01], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:37,764][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.2325, 0.1740, 0.0580, 0.5355], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:37,766][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.1105, 0.3776, 0.0499, 0.4620], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:37,767][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.3285, 0.1488, 0.2532, 0.2695], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:37,769][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.1226, 0.1962, 0.0110, 0.6702], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:37,771][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.6403, 0.0306, 0.3058, 0.0232], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:37,772][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2540, 0.1931, 0.2621, 0.2908], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:37,774][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0669, 0.4682, 0.0259, 0.4390], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:37,775][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.4259, 0.2378, 0.1152, 0.2210], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:37,777][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.4149, 0.3091, 0.0721, 0.2039], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:37,779][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.4563, 0.1993, 0.0840, 0.2604], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:37,780][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Travis] are: tensor([0.2129, 0.2701, 0.0681, 0.2627, 0.1862], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:37,781][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Travis] are: tensor([1.5118e-05, 2.2406e-05, 9.3010e-05, 4.0194e-05, 9.9983e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:37,783][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Travis] are: tensor([0.2886, 0.1602, 0.0179, 0.0992, 0.4341], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:37,784][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Travis] are: tensor([2.9967e-04, 1.0561e-05, 1.9052e-04, 2.7832e-05, 9.9947e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:37,786][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Travis] are: tensor([0.0129, 0.0018, 0.0068, 0.0020, 0.9765], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:37,787][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Travis] are: tensor([4.7706e-03, 6.1325e-07, 1.0074e-05, 1.5966e-07, 9.9522e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:37,789][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Travis] are: tensor([0.1951, 0.2582, 0.2602, 0.1483, 0.1383], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:37,790][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Travis] are: tensor([0.2073, 0.1557, 0.1487, 0.3301, 0.1582], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:37,792][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Travis] are: tensor([0.2549, 0.1890, 0.2497, 0.1400, 0.1664], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:37,794][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Travis] are: tensor([0.3608, 0.2612, 0.1480, 0.2215, 0.0085], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:37,795][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Travis] are: tensor([0.2696, 0.2266, 0.0937, 0.1486, 0.2615], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:37,797][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Travis] are: tensor([0.3541, 0.2175, 0.0972, 0.2051, 0.1261], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:37,798][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.4021, 0.0354, 0.1213, 0.0352, 0.0963, 0.3098], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:37,800][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([3.2203e-04, 1.6747e-03, 7.4178e-04, 2.8605e-03, 1.2639e-04, 9.9427e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:37,802][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.4600, 0.1173, 0.0751, 0.1388, 0.0715, 0.1374], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:37,803][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([4.9366e-03, 5.4257e-03, 8.8014e-04, 1.1481e-02, 2.0548e-03, 9.7522e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:37,804][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.2003, 0.0569, 0.0750, 0.1031, 0.1395, 0.4252], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:37,805][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([3.9796e-02, 1.8571e-03, 7.2338e-04, 1.2911e-03, 2.7444e-04, 9.5606e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:37,805][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.2850, 0.0213, 0.4079, 0.0200, 0.2373, 0.0286], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:37,807][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.1324, 0.1031, 0.0902, 0.2393, 0.1373, 0.2977], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:37,808][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.0968, 0.2720, 0.0293, 0.3572, 0.0237, 0.2210], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:37,810][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.2969, 0.1790, 0.1058, 0.1844, 0.1092, 0.1247], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:37,812][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.2517, 0.1941, 0.0676, 0.1422, 0.0357, 0.3087], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:37,813][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.4323, 0.1444, 0.0601, 0.1801, 0.0920, 0.0910], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:37,815][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.5293, 0.0610, 0.1461, 0.0461, 0.1007, 0.0760, 0.0408],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:37,816][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([8.5558e-04, 4.2998e-03, 1.5739e-03, 4.2977e-03, 4.1390e-04, 4.6828e-04,
        9.8809e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:37,817][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.2896, 0.1796, 0.0862, 0.2118, 0.0683, 0.1199, 0.0448],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:37,819][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0290, 0.0177, 0.0167, 0.0327, 0.0195, 0.1766, 0.7078],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:37,821][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.1377, 0.0303, 0.0718, 0.0426, 0.0789, 0.4304, 0.2082],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:37,822][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0557, 0.1292, 0.0052, 0.0967, 0.0044, 0.0446, 0.6641],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:37,824][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.3606, 0.0120, 0.2786, 0.0102, 0.2739, 0.0530, 0.0117],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:37,826][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0954, 0.0573, 0.0662, 0.1282, 0.1418, 0.2150, 0.2960],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:37,827][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0241, 0.1310, 0.0099, 0.1946, 0.0067, 0.1422, 0.4915],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:37,829][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.2594, 0.1661, 0.0924, 0.1685, 0.0761, 0.1045, 0.1329],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:37,831][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.2260, 0.1927, 0.0716, 0.1634, 0.0369, 0.0836, 0.2259],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:37,832][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.3329, 0.1334, 0.0732, 0.1433, 0.1207, 0.0860, 0.1104],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:37,834][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ lot] are: tensor([0.3396, 0.0751, 0.1939, 0.0793, 0.0655, 0.0708, 0.0840, 0.0917],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:37,835][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ lot] are: tensor([2.6497e-04, 1.0295e-03, 6.3491e-05, 1.2102e-03, 6.9342e-04, 1.3688e-03,
        5.0380e-04, 9.9487e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:37,837][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ lot] are: tensor([0.2853, 0.1103, 0.0844, 0.1972, 0.0637, 0.1465, 0.0761, 0.0365],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:37,838][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ lot] are: tensor([1.0759e-03, 1.2846e-04, 7.4875e-05, 2.5190e-04, 1.4961e-03, 2.0019e-03,
        1.6721e-03, 9.9330e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:37,840][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ lot] are: tensor([0.0450, 0.0140, 0.0029, 0.0155, 0.0532, 0.0595, 0.0700, 0.7399],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:37,841][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ lot] are: tensor([3.2514e-03, 1.1954e-04, 2.0727e-05, 1.7788e-05, 1.6411e-04, 9.6455e-06,
        5.2869e-06, 9.9641e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:37,843][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ lot] are: tensor([0.3054, 0.0660, 0.1429, 0.0385, 0.1280, 0.0436, 0.0570, 0.2186],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:37,844][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ lot] are: tensor([0.0915, 0.0493, 0.0137, 0.0971, 0.0904, 0.1575, 0.2911, 0.2094],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:37,846][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ lot] are: tensor([0.1256, 0.1526, 0.0333, 0.1410, 0.0351, 0.1151, 0.3417, 0.0557],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:37,847][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ lot] are: tensor([0.2477, 0.1572, 0.0690, 0.1521, 0.0774, 0.1021, 0.1310, 0.0634],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:37,849][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ lot] are: tensor([0.2107, 0.1513, 0.0427, 0.1251, 0.0411, 0.0844, 0.0842, 0.2605],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:37,851][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ lot] are: tensor([0.4514, 0.0865, 0.0534, 0.0896, 0.1092, 0.0611, 0.0451, 0.1038],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:37,853][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([0.3642, 0.0573, 0.1190, 0.0412, 0.1193, 0.0751, 0.0500, 0.1421, 0.0319],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:37,854][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([8.9873e-04, 1.5861e-02, 6.2899e-05, 2.1565e-02, 2.1261e-05, 6.7603e-04,
        3.8738e-04, 9.5701e-05, 9.6043e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:37,855][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([0.2982, 0.1413, 0.0601, 0.1313, 0.0504, 0.0760, 0.0602, 0.0836, 0.0989],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:37,857][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([0.0052, 0.0030, 0.0005, 0.0069, 0.0141, 0.0450, 0.0605, 0.3698, 0.4951],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:37,859][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([0.1428, 0.0195, 0.0440, 0.0232, 0.1322, 0.1027, 0.0665, 0.3082, 0.1609],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:37,860][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([0.0227, 0.0913, 0.0011, 0.1072, 0.0009, 0.0657, 0.2358, 0.0072, 0.4681],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:37,862][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([0.2227, 0.0190, 0.1833, 0.0167, 0.2633, 0.0434, 0.0175, 0.2221, 0.0119],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:37,864][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([0.0543, 0.0263, 0.0339, 0.0550, 0.0430, 0.1087, 0.1840, 0.2731, 0.2216],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:37,865][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([0.0229, 0.1177, 0.0119, 0.1840, 0.0072, 0.1239, 0.3541, 0.0216, 0.1567],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:37,865][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([0.2020, 0.1319, 0.0734, 0.1351, 0.0625, 0.0847, 0.1102, 0.0788, 0.1213],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:37,866][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([0.1688, 0.1565, 0.0528, 0.1480, 0.0250, 0.0764, 0.0909, 0.0590, 0.2225],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:37,867][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([0.2577, 0.1121, 0.0658, 0.1321, 0.1238, 0.0770, 0.0832, 0.0989, 0.0494],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:37,868][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ fun] are: tensor([0.2514, 0.1014, 0.1127, 0.0930, 0.0686, 0.0354, 0.0889, 0.0987, 0.0548,
        0.0951], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:37,869][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ fun] are: tensor([1.4098e-04, 4.5754e-05, 5.1837e-04, 3.7539e-05, 1.5562e-04, 2.0438e-05,
        1.1354e-03, 8.8541e-04, 1.7991e-05, 9.9704e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:37,871][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ fun] are: tensor([0.1925, 0.0668, 0.1183, 0.1067, 0.0632, 0.0970, 0.0889, 0.0717, 0.0984,
        0.0965], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:37,872][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ fun] are: tensor([4.4577e-04, 8.2966e-06, 7.8065e-05, 8.7108e-06, 2.4110e-05, 2.8329e-04,
        2.2893e-04, 1.8482e-03, 2.9447e-04, 9.9678e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:37,874][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ fun] are: tensor([0.0123, 0.0021, 0.0019, 0.0024, 0.0023, 0.0103, 0.0108, 0.0139, 0.0096,
        0.9343], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:37,875][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ fun] are: tensor([4.2282e-03, 2.8176e-05, 1.2069e-04, 3.7844e-06, 7.8665e-06, 4.2782e-07,
        1.7979e-06, 1.4491e-04, 2.7547e-07, 9.9546e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:37,876][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ fun] are: tensor([0.1909, 0.0405, 0.1921, 0.0315, 0.1862, 0.0265, 0.0288, 0.1259, 0.0344,
        0.1432], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:37,878][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ fun] are: tensor([0.0940, 0.0235, 0.0071, 0.0505, 0.0265, 0.0698, 0.1393, 0.1961, 0.2635,
        0.1297], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:37,880][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ fun] are: tensor([0.1290, 0.1192, 0.0493, 0.1769, 0.0226, 0.1043, 0.1951, 0.0640, 0.1028,
        0.0371], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:37,882][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ fun] are: tensor([0.1939, 0.1184, 0.0888, 0.1131, 0.0606, 0.0851, 0.0976, 0.0790, 0.1045,
        0.0589], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:37,883][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ fun] are: tensor([0.1315, 0.1025, 0.0636, 0.0995, 0.0394, 0.0563, 0.0827, 0.0863, 0.0715,
        0.2667], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:37,885][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ fun] are: tensor([0.3057, 0.1522, 0.0527, 0.1135, 0.0790, 0.0692, 0.0640, 0.0451, 0.0533,
        0.0655], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:37,887][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.2621, 0.0371, 0.0809, 0.0342, 0.0739, 0.0481, 0.0536, 0.1416, 0.0334,
        0.2097, 0.0253], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:37,888][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([7.4886e-04, 1.5250e-03, 2.2404e-04, 3.7652e-03, 4.3963e-04, 1.5075e-04,
        1.4843e-03, 3.0382e-05, 4.3030e-03, 3.3100e-05, 9.8730e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:37,889][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.1942, 0.1002, 0.0424, 0.1185, 0.0564, 0.0784, 0.0439, 0.0620, 0.1147,
        0.0782, 0.1110], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:37,891][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([1.0224e-03, 3.5278e-04, 7.9464e-05, 6.9248e-04, 8.4767e-05, 4.8618e-03,
        7.4774e-03, 3.9671e-03, 3.0006e-02, 1.3053e-01, 8.2093e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:37,892][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.0620, 0.0063, 0.0051, 0.0095, 0.0118, 0.0582, 0.0343, 0.0469, 0.0709,
        0.3789, 0.3161], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:37,894][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.0545, 0.0231, 0.0016, 0.0096, 0.0048, 0.0363, 0.0160, 0.0012, 0.0039,
        0.0009, 0.8481], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:37,896][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.1623, 0.0124, 0.2095, 0.0121, 0.1871, 0.0397, 0.0156, 0.1723, 0.0119,
        0.1580, 0.0193], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:37,897][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.0365, 0.0124, 0.0076, 0.0280, 0.0230, 0.0467, 0.0819, 0.1097, 0.1263,
        0.1928, 0.3350], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:37,899][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.0240, 0.1162, 0.0094, 0.2107, 0.0067, 0.1120, 0.1973, 0.0245, 0.1664,
        0.0261, 0.1067], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:37,901][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.1488, 0.1038, 0.0606, 0.1124, 0.0550, 0.0778, 0.0898, 0.0691, 0.1083,
        0.0722, 0.1021], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:37,903][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.1427, 0.1104, 0.0459, 0.1136, 0.0394, 0.0828, 0.0957, 0.0344, 0.0917,
        0.0301, 0.2133], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:37,904][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.2567, 0.0880, 0.0497, 0.0913, 0.0779, 0.0545, 0.0476, 0.0859, 0.0478,
        0.0833, 0.1172], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:37,906][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.4023, 0.0341, 0.0975, 0.0220, 0.0866, 0.0445, 0.0195, 0.0867, 0.0196,
        0.1424, 0.0209, 0.0238], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:37,907][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([2.9751e-03, 1.8210e-02, 4.3203e-04, 3.9242e-02, 1.0791e-04, 2.7151e-04,
        3.3099e-02, 8.6438e-05, 6.8753e-02, 7.4390e-05, 4.1115e-02, 7.9563e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:37,909][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.1800, 0.0881, 0.0391, 0.0983, 0.0416, 0.0915, 0.0285, 0.0676, 0.1096,
        0.0609, 0.1658, 0.0290], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:37,910][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([1.0766e-02, 1.6524e-03, 6.2340e-04, 1.8818e-03, 1.6579e-03, 7.3199e-03,
        1.8886e-02, 1.2110e-02, 6.1516e-02, 5.5835e-02, 1.8249e-01, 6.4526e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:37,912][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.1106, 0.0123, 0.0195, 0.0163, 0.0197, 0.0773, 0.0331, 0.0499, 0.0974,
        0.1402, 0.2299, 0.1939], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:37,914][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.0654, 0.1024, 0.0091, 0.0838, 0.0204, 0.0627, 0.2055, 0.0499, 0.0538,
        0.0112, 0.0574, 0.2784], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:37,915][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.1802, 0.0030, 0.2119, 0.0029, 0.2283, 0.0173, 0.0033, 0.1519, 0.0025,
        0.1903, 0.0065, 0.0020], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:37,917][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0378, 0.0088, 0.0061, 0.0175, 0.0292, 0.0228, 0.0364, 0.0571, 0.0939,
        0.0964, 0.2914, 0.3026], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:37,919][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0084, 0.0713, 0.0068, 0.1147, 0.0027, 0.0747, 0.2406, 0.0078, 0.0764,
        0.0135, 0.0510, 0.3320], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:37,921][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.1668, 0.0942, 0.0591, 0.0977, 0.0491, 0.0685, 0.0781, 0.0638, 0.0908,
        0.0492, 0.0920, 0.0906], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:37,922][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.1748, 0.1070, 0.0509, 0.1067, 0.0360, 0.0545, 0.1119, 0.0416, 0.0642,
        0.0301, 0.0737, 0.1486], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:37,924][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.1963, 0.0790, 0.0621, 0.0828, 0.0862, 0.0512, 0.0857, 0.0754, 0.0313,
        0.0785, 0.0781, 0.0932], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:37,926][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ hospital] are: tensor([0.1451, 0.0691, 0.1034, 0.0697, 0.0728, 0.0668, 0.0695, 0.0355, 0.0679,
        0.0673, 0.0464, 0.0742, 0.1123], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:37,927][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ hospital] are: tensor([2.5590e-05, 1.6636e-04, 1.1465e-04, 8.7247e-05, 8.4772e-04, 4.2452e-04,
        2.7491e-05, 6.6746e-05, 7.7516e-06, 1.6970e-05, 2.7122e-04, 2.4056e-05,
        9.9792e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:37,928][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ hospital] are: tensor([0.2102, 0.0594, 0.0931, 0.0455, 0.0198, 0.0531, 0.0603, 0.0548, 0.0590,
        0.0635, 0.0525, 0.0595, 0.1691], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:37,929][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ hospital] are: tensor([2.4805e-04, 4.7510e-07, 5.8079e-05, 8.7695e-07, 1.3377e-05, 1.3054e-05,
        6.1770e-06, 1.0982e-04, 2.8450e-05, 7.7763e-04, 2.0312e-04, 1.2121e-04,
        9.9842e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:37,930][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ hospital] are: tensor([3.8999e-03, 1.7760e-04, 1.4515e-03, 1.3758e-04, 5.0344e-04, 2.3748e-04,
        3.0095e-04, 2.6881e-04, 4.0237e-04, 9.1878e-04, 1.6768e-03, 1.4152e-03,
        9.8861e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:37,931][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ hospital] are: tensor([2.1877e-03, 4.3898e-06, 4.6751e-05, 7.4061e-07, 4.3969e-05, 1.4956e-05,
        4.0290e-07, 1.4905e-05, 7.3216e-08, 1.4067e-06, 4.0707e-07, 1.5992e-07,
        9.9768e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:37,933][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ hospital] are: tensor([0.1984, 0.0601, 0.1217, 0.0417, 0.1344, 0.0220, 0.0294, 0.0339, 0.0280,
        0.0773, 0.0176, 0.0257, 0.2099], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:37,934][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ hospital] are: tensor([0.0427, 0.0124, 0.0040, 0.0204, 0.0082, 0.0298, 0.0361, 0.0307, 0.0760,
        0.1222, 0.1895, 0.3138, 0.1142], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:37,936][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ hospital] are: tensor([0.1515, 0.0762, 0.0595, 0.0849, 0.0388, 0.0574, 0.0907, 0.0489, 0.0794,
        0.0647, 0.0693, 0.0980, 0.0808], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:37,937][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ hospital] are: tensor([0.1917, 0.1021, 0.0736, 0.0892, 0.0568, 0.0648, 0.0801, 0.0595, 0.0698,
        0.0465, 0.0738, 0.0808, 0.0115], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:37,939][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ hospital] are: tensor([0.1252, 0.0935, 0.0433, 0.0819, 0.0349, 0.0702, 0.0749, 0.0289, 0.0439,
        0.0140, 0.0586, 0.0546, 0.2759], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:37,941][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ hospital] are: tensor([0.1423, 0.0904, 0.0457, 0.0773, 0.0740, 0.0458, 0.0444, 0.0793, 0.0843,
        0.0974, 0.0965, 0.0502, 0.0723], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:37,943][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.4449, 0.0139, 0.0831, 0.0116, 0.0850, 0.0484, 0.0218, 0.0786, 0.0089,
        0.1083, 0.0169, 0.0370, 0.0317, 0.0101], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:37,944][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([2.9670e-03, 2.9773e-02, 2.7755e-05, 5.5119e-03, 4.5691e-04, 1.1794e-04,
        2.6022e-04, 2.2072e-04, 2.5132e-03, 7.6660e-05, 1.1373e-03, 2.5236e-04,
        2.2062e-04, 9.5646e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:37,946][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.3431, 0.0438, 0.0325, 0.0375, 0.0324, 0.1920, 0.0173, 0.0463, 0.0826,
        0.0366, 0.0510, 0.0213, 0.0191, 0.0444], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:37,947][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([1.1994e-02, 1.4260e-03, 4.2386e-04, 1.3817e-03, 7.9925e-04, 4.3083e-03,
        4.6444e-03, 1.8872e-02, 1.8070e-02, 1.9196e-02, 6.2098e-02, 1.6867e-01,
        2.2868e-01, 4.5944e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:37,949][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.0311, 0.0105, 0.0096, 0.0200, 0.0059, 0.0217, 0.0185, 0.0459, 0.0612,
        0.0694, 0.1416, 0.1212, 0.1058, 0.3377], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:37,950][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.1018, 0.1619, 0.0307, 0.1037, 0.0144, 0.0717, 0.0779, 0.0326, 0.0512,
        0.0108, 0.0540, 0.0627, 0.0182, 0.2084], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:37,952][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.2171, 0.0056, 0.1869, 0.0041, 0.1250, 0.0114, 0.0056, 0.0843, 0.0034,
        0.1781, 0.0073, 0.0036, 0.1649, 0.0027], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:37,954][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0181, 0.0044, 0.0041, 0.0081, 0.0122, 0.0121, 0.0185, 0.0302, 0.0315,
        0.0668, 0.0939, 0.1451, 0.1519, 0.4032], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:37,956][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.0143, 0.1268, 0.0072, 0.1011, 0.0049, 0.0225, 0.0845, 0.0064, 0.0606,
        0.0048, 0.0400, 0.1368, 0.0051, 0.3848], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:37,958][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.1422, 0.0795, 0.0537, 0.0826, 0.0480, 0.0630, 0.0636, 0.0599, 0.0665,
        0.0594, 0.0697, 0.0717, 0.0527, 0.0875], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:37,959][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.1060, 0.0894, 0.0322, 0.0962, 0.0460, 0.0728, 0.0596, 0.0626, 0.0747,
        0.0524, 0.0737, 0.0599, 0.0485, 0.1259], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:37,961][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.2171, 0.0757, 0.0514, 0.0719, 0.0774, 0.0507, 0.0439, 0.0700, 0.0357,
        0.0638, 0.0756, 0.0340, 0.0389, 0.0941], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:37,963][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Anthony] are: tensor([0.1072, 0.1011, 0.1438, 0.0794, 0.0316, 0.0128, 0.0349, 0.0127, 0.0605,
        0.0451, 0.0460, 0.0543, 0.0549, 0.0679, 0.1477], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:37,964][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Anthony] are: tensor([5.8848e-05, 7.9151e-06, 4.8324e-01, 1.6936e-05, 7.8669e-06, 1.8123e-05,
        2.0471e-05, 3.9493e-06, 2.1139e-05, 4.5853e-05, 2.0582e-05, 1.3348e-05,
        5.4856e-06, 1.1357e-06, 5.1652e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:37,966][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Anthony] are: tensor([0.2029, 0.0912, 0.0663, 0.0432, 0.0355, 0.0789, 0.0735, 0.0230, 0.0722,
        0.0241, 0.0399, 0.0846, 0.0833, 0.0386, 0.0429], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:37,967][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Anthony] are: tensor([6.8918e-04, 1.3910e-06, 1.0527e-03, 2.2746e-06, 8.2793e-05, 1.0053e-05,
        2.4149e-05, 5.0940e-05, 4.8046e-05, 4.4779e-04, 2.0896e-04, 4.5625e-04,
        6.8756e-04, 1.8024e-04, 9.9606e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:37,968][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Anthony] are: tensor([8.6298e-03, 1.5131e-03, 3.7211e-02, 1.1290e-03, 2.3157e-03, 8.8557e-04,
        8.0976e-04, 2.1087e-03, 4.0235e-03, 7.5166e-03, 8.8826e-03, 4.8645e-03,
        2.5814e-03, 1.8717e-02, 8.9881e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:37,970][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Anthony] are: tensor([2.8199e-03, 3.3454e-07, 5.5974e-01, 1.4213e-07, 2.6441e-06, 2.9749e-07,
        6.1303e-08, 2.0650e-07, 7.6691e-09, 2.0312e-06, 2.4269e-08, 3.9131e-08,
        1.5266e-06, 1.5813e-08, 4.3743e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:37,971][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Anthony] are: tensor([0.1038, 0.0882, 0.1859, 0.0516, 0.0852, 0.0099, 0.0278, 0.0156, 0.0227,
        0.0208, 0.0127, 0.0459, 0.1245, 0.0493, 0.1561], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:37,973][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Anthony] are: tensor([0.0293, 0.0104, 0.0038, 0.0149, 0.0039, 0.0115, 0.0241, 0.0194, 0.0446,
        0.0096, 0.1320, 0.1082, 0.0919, 0.3746, 0.1218], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:37,975][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Anthony] are: tensor([0.1353, 0.0589, 0.1043, 0.0531, 0.1196, 0.0226, 0.0471, 0.0223, 0.0428,
        0.0216, 0.0402, 0.0584, 0.1082, 0.0516, 0.1140], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:37,977][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Anthony] are: tensor([0.1737, 0.0908, 0.0137, 0.0852, 0.0596, 0.0530, 0.0537, 0.0327, 0.0744,
        0.0501, 0.0651, 0.0686, 0.0869, 0.0815, 0.0111], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:37,978][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Anthony] are: tensor([0.0887, 0.0662, 0.2141, 0.0676, 0.0262, 0.0381, 0.0494, 0.0159, 0.0568,
        0.0260, 0.0475, 0.0473, 0.0258, 0.0429, 0.1876], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:37,980][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Anthony] are: tensor([0.1018, 0.0610, 0.0621, 0.0677, 0.0539, 0.0598, 0.0355, 0.0762, 0.0354,
        0.1063, 0.0719, 0.0339, 0.0561, 0.0976, 0.0807], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:37,982][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.2006, 0.0197, 0.0637, 0.0238, 0.0640, 0.0984, 0.0188, 0.0478, 0.0231,
        0.0383, 0.0189, 0.0175, 0.0502, 0.0157, 0.0830, 0.2164],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:37,983][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([3.7533e-04, 5.8270e-04, 1.5728e-04, 1.2671e-03, 1.0612e-04, 6.5425e-03,
        1.4130e-04, 3.2865e-04, 7.6630e-04, 1.2339e-04, 3.5817e-04, 1.7588e-04,
        4.1545e-05, 5.0912e-05, 8.0016e-05, 9.8890e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:37,985][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.1652, 0.0414, 0.0498, 0.0499, 0.0185, 0.0743, 0.0429, 0.0559, 0.0713,
        0.0626, 0.0703, 0.0528, 0.0520, 0.0701, 0.0490, 0.0740],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:37,986][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([8.5901e-04, 4.6022e-06, 1.0223e-06, 3.9982e-06, 1.8811e-06, 4.5586e-05,
        1.1803e-05, 3.8647e-05, 4.7166e-05, 2.9236e-04, 1.4119e-04, 2.0658e-04,
        5.5073e-04, 6.5230e-04, 7.2379e-04, 9.9642e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:37,988][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.0830, 0.0065, 0.0041, 0.0065, 0.0030, 0.0107, 0.0075, 0.0101, 0.0189,
        0.0227, 0.0394, 0.0214, 0.0630, 0.0429, 0.0497, 0.6108],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:37,989][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([3.9537e-02, 2.1612e-05, 9.1917e-05, 2.1874e-05, 2.0068e-05, 1.8039e-03,
        1.2768e-05, 7.0414e-06, 5.9637e-06, 5.3260e-05, 1.5034e-05, 7.0799e-06,
        1.6377e-05, 1.0706e-06, 1.5326e-05, 9.5837e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:37,990][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.0758, 0.0095, 0.1253, 0.0093, 0.0871, 0.0113, 0.0135, 0.0611, 0.0070,
        0.1171, 0.0082, 0.0105, 0.2216, 0.0097, 0.2098, 0.0233],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:37,991][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0188, 0.0042, 0.0038, 0.0062, 0.0050, 0.0062, 0.0119, 0.0139, 0.0153,
        0.0242, 0.0560, 0.0771, 0.0375, 0.3085, 0.1874, 0.2244],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:37,992][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.0743, 0.0733, 0.0132, 0.0929, 0.0079, 0.0402, 0.1057, 0.0363, 0.0818,
        0.0658, 0.0762, 0.1282, 0.0506, 0.0995, 0.0179, 0.0362],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:37,994][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.1110, 0.0609, 0.0420, 0.0646, 0.0498, 0.0601, 0.0540, 0.0539, 0.0596,
        0.0733, 0.0540, 0.0581, 0.0631, 0.0875, 0.0487, 0.0593],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:37,996][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0794, 0.0560, 0.0356, 0.0631, 0.0319, 0.1052, 0.0514, 0.0307, 0.0542,
        0.0339, 0.0560, 0.0494, 0.0321, 0.0665, 0.0353, 0.2192],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:37,998][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.2205, 0.0778, 0.0398, 0.0930, 0.0432, 0.0409, 0.0373, 0.0471, 0.0394,
        0.0456, 0.0691, 0.0335, 0.0410, 0.0838, 0.0331, 0.0550],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:37,999][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.2520, 0.0199, 0.0632, 0.0154, 0.0443, 0.0321, 0.0138, 0.0613, 0.0130,
        0.1060, 0.0129, 0.0244, 0.0782, 0.0182, 0.0931, 0.1311, 0.0212],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:38,001][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([4.3910e-04, 1.1430e-03, 4.7682e-04, 1.2515e-03, 1.5823e-04, 1.3490e-04,
        4.3309e-01, 1.8437e-04, 1.1685e-03, 9.9681e-04, 3.4107e-03, 1.4669e-02,
        9.5686e-05, 2.8399e-04, 2.5792e-04, 1.1745e-04, 5.4212e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:38,003][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0959, 0.0490, 0.0353, 0.0747, 0.0313, 0.0449, 0.0152, 0.0568, 0.0753,
        0.0424, 0.1142, 0.0177, 0.0456, 0.1589, 0.0409, 0.0850, 0.0171],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:38,004][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([3.4449e-03, 2.6178e-04, 1.3788e-04, 1.6759e-04, 7.8326e-05, 3.6047e-04,
        1.2553e-03, 5.3146e-04, 1.6742e-03, 1.6822e-03, 4.5729e-03, 1.8691e-02,
        7.6468e-03, 2.7744e-02, 5.4426e-02, 1.2674e-01, 7.5058e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:38,006][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0220, 0.0026, 0.0039, 0.0028, 0.0027, 0.0183, 0.0073, 0.0068, 0.0110,
        0.0254, 0.0240, 0.0183, 0.0425, 0.0213, 0.0703, 0.5332, 0.1876],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:38,007][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0166, 0.0528, 0.0028, 0.0463, 0.0024, 0.0248, 0.4154, 0.0038, 0.0249,
        0.0043, 0.0314, 0.1011, 0.0025, 0.0132, 0.0006, 0.0039, 0.2533],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:38,009][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.1057, 0.0024, 0.0949, 0.0024, 0.1027, 0.0155, 0.0027, 0.1009, 0.0026,
        0.1278, 0.0053, 0.0021, 0.1654, 0.0022, 0.1932, 0.0701, 0.0040],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:38,011][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0139, 0.0025, 0.0023, 0.0040, 0.0037, 0.0036, 0.0040, 0.0073, 0.0095,
        0.0120, 0.0300, 0.0352, 0.0213, 0.1997, 0.1181, 0.2743, 0.2586],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:38,013][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0069, 0.0337, 0.0029, 0.0591, 0.0020, 0.0459, 0.1360, 0.0064, 0.0435,
        0.0111, 0.0353, 0.1946, 0.0150, 0.0996, 0.0058, 0.0233, 0.2787],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:38,015][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.1041, 0.0637, 0.0442, 0.0701, 0.0349, 0.0471, 0.0548, 0.0462, 0.0647,
        0.0407, 0.0640, 0.0659, 0.0538, 0.0692, 0.0477, 0.0592, 0.0697],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:38,017][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0731, 0.0568, 0.0327, 0.0670, 0.0232, 0.0444, 0.1242, 0.0333, 0.0532,
        0.0381, 0.0686, 0.0802, 0.0491, 0.0541, 0.0302, 0.0354, 0.1364],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:38,019][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.1776, 0.0666, 0.0448, 0.0636, 0.0658, 0.0432, 0.0488, 0.0564, 0.0279,
        0.0547, 0.0555, 0.0360, 0.0319, 0.0719, 0.0400, 0.0675, 0.0478],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:38,020][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ drink] are: tensor([0.1443, 0.0427, 0.0296, 0.0371, 0.0362, 0.0270, 0.0328, 0.0347, 0.0276,
        0.0643, 0.0293, 0.0320, 0.1467, 0.0334, 0.0245, 0.0368, 0.0362, 0.1849],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:38,022][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ drink] are: tensor([2.5846e-04, 7.7059e-05, 5.8600e-04, 9.0857e-05, 3.7402e-04, 5.5531e-05,
        1.2057e-05, 4.7693e-05, 2.8550e-05, 8.0274e-04, 1.8103e-04, 7.6665e-06,
        3.6405e-04, 1.0020e-05, 3.0619e-04, 8.4900e-05, 7.3691e-06, 9.9671e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:38,023][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ drink] are: tensor([0.1413, 0.0457, 0.0417, 0.0406, 0.0282, 0.0410, 0.0645, 0.0804, 0.0491,
        0.0728, 0.0544, 0.0593, 0.0230, 0.0616, 0.0325, 0.0253, 0.0647, 0.0738],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:38,025][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ drink] are: tensor([1.2571e-03, 1.6932e-06, 8.7059e-06, 8.5761e-07, 4.1673e-06, 5.5198e-06,
        1.2646e-06, 6.0041e-05, 4.4593e-06, 2.8735e-04, 1.5978e-05, 1.4221e-05,
        1.8269e-03, 8.8903e-05, 2.0409e-03, 1.2341e-02, 4.0001e-04, 9.8164e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:38,027][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ drink] are: tensor([0.0506, 0.0023, 0.0064, 0.0018, 0.0075, 0.0016, 0.0017, 0.0044, 0.0033,
        0.0106, 0.0041, 0.0062, 0.0059, 0.0056, 0.0358, 0.0217, 0.0152, 0.8152],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:38,028][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ drink] are: tensor([4.0919e-03, 7.5859e-06, 4.4396e-05, 1.4039e-06, 2.8617e-06, 1.5257e-06,
        1.4009e-06, 4.5550e-06, 4.7765e-07, 4.1686e-05, 1.0413e-06, 2.3705e-07,
        5.7741e-06, 1.7014e-07, 8.0350e-06, 4.8792e-06, 4.6025e-07, 9.9578e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:38,030][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ drink] are: tensor([0.0859, 0.0298, 0.1104, 0.0220, 0.0469, 0.0085, 0.0148, 0.0424, 0.0137,
        0.0963, 0.0115, 0.0141, 0.2088, 0.0166, 0.1076, 0.0125, 0.0166, 0.1417],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:38,031][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ drink] are: tensor([0.0309, 0.0041, 0.0007, 0.0047, 0.0018, 0.0068, 0.0097, 0.0068, 0.0136,
        0.0184, 0.0357, 0.0417, 0.0371, 0.1589, 0.0109, 0.2517, 0.3168, 0.0497],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:38,033][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ drink] are: tensor([0.1693, 0.0618, 0.0265, 0.0607, 0.0289, 0.0353, 0.0520, 0.0589, 0.0501,
        0.1070, 0.0429, 0.0498, 0.0357, 0.0335, 0.0217, 0.0492, 0.0565, 0.0602],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:38,035][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ drink] are: tensor([0.1238, 0.0650, 0.0573, 0.0613, 0.0342, 0.0500, 0.0476, 0.0440, 0.0505,
        0.0498, 0.0421, 0.0492, 0.0650, 0.0689, 0.0569, 0.0574, 0.0555, 0.0214],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:38,037][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ drink] are: tensor([0.0814, 0.0518, 0.0365, 0.0615, 0.0282, 0.0473, 0.0430, 0.0346, 0.0549,
        0.0446, 0.0408, 0.0446, 0.0355, 0.0543, 0.0300, 0.0325, 0.0381, 0.2405],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:38,039][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ drink] are: tensor([0.1146, 0.0540, 0.0567, 0.0459, 0.0745, 0.0421, 0.0328, 0.0585, 0.0311,
        0.0654, 0.0581, 0.0297, 0.0380, 0.0762, 0.0557, 0.0677, 0.0326, 0.0663],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:38,040][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.2056, 0.0180, 0.0619, 0.0151, 0.0438, 0.0502, 0.0160, 0.0516, 0.0166,
        0.0570, 0.0154, 0.0240, 0.0291, 0.0166, 0.1006, 0.1344, 0.0260, 0.1037,
        0.0145], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:38,042][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([4.0645e-03, 8.9857e-03, 2.1719e-05, 2.6126e-02, 8.6956e-05, 2.3098e-04,
        1.0628e-03, 3.7219e-05, 2.5763e-02, 1.8243e-04, 1.4922e-02, 1.4075e-03,
        1.7330e-05, 6.9827e-03, 9.2497e-06, 6.6518e-04, 9.9174e-04, 5.0125e-05,
        9.0839e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:38,044][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1041, 0.0424, 0.0214, 0.0618, 0.0233, 0.0380, 0.0157, 0.0454, 0.0667,
        0.0352, 0.0910, 0.0187, 0.0192, 0.1871, 0.0218, 0.0534, 0.0175, 0.0120,
        0.1251], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:38,045][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([1.1973e-03, 6.3143e-05, 6.8123e-06, 3.0277e-05, 8.7319e-07, 7.2251e-05,
        1.0073e-04, 3.0045e-05, 3.9245e-04, 2.6352e-04, 5.9617e-04, 2.4224e-03,
        4.8173e-04, 4.3876e-03, 1.4507e-03, 2.5066e-01, 7.1239e-02, 2.1033e-02,
        6.4557e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:38,047][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0205, 0.0011, 0.0008, 0.0016, 0.0004, 0.0109, 0.0029, 0.0046, 0.0040,
        0.0262, 0.0103, 0.0077, 0.0125, 0.0125, 0.0111, 0.3677, 0.0825, 0.1498,
        0.2729], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:38,049][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0298, 0.0437, 0.0016, 0.0588, 0.0013, 0.0251, 0.1861, 0.0075, 0.0396,
        0.0096, 0.0168, 0.1359, 0.0005, 0.0165, 0.0003, 0.0049, 0.1150, 0.0003,
        0.3067], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:38,050][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0884, 0.0039, 0.0310, 0.0034, 0.0462, 0.0119, 0.0032, 0.0379, 0.0047,
        0.1080, 0.0172, 0.0027, 0.1072, 0.0047, 0.0609, 0.0573, 0.0052, 0.0948,
        0.3113], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:38,051][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0146, 0.0021, 0.0025, 0.0029, 0.0025, 0.0026, 0.0031, 0.0043, 0.0038,
        0.0111, 0.0110, 0.0183, 0.0162, 0.0912, 0.0758, 0.1206, 0.1588, 0.1831,
        0.2757], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:38,052][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0053, 0.0387, 0.0026, 0.0694, 0.0010, 0.0314, 0.0850, 0.0057, 0.0494,
        0.0058, 0.0337, 0.1518, 0.0087, 0.1172, 0.0046, 0.0174, 0.1673, 0.0131,
        0.1916], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:38,053][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0889, 0.0529, 0.0389, 0.0598, 0.0304, 0.0406, 0.0507, 0.0403, 0.0541,
        0.0430, 0.0542, 0.0582, 0.0464, 0.0610, 0.0429, 0.0534, 0.0651, 0.0381,
        0.0813], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:38,055][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0718, 0.0549, 0.0231, 0.0706, 0.0268, 0.0553, 0.0637, 0.0348, 0.0629,
        0.0402, 0.0635, 0.0635, 0.0264, 0.0679, 0.0223, 0.0555, 0.0707, 0.0271,
        0.0989], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:38,057][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.1594, 0.0614, 0.0406, 0.0621, 0.0592, 0.0457, 0.0402, 0.0489, 0.0289,
        0.0478, 0.0578, 0.0288, 0.0257, 0.0617, 0.0343, 0.0638, 0.0374, 0.0385,
        0.0579], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:38,061][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:21:38,063][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[29705],
        [10579],
        [11608],
        [19270],
        [    1],
        [15554],
        [13290],
        [ 6760],
        [12050],
        [16453],
        [20618],
        [12819],
        [22381],
        [11823],
        [10548],
        [17379],
        [16450],
        [17020],
        [14612]], device='cuda:0')
[2024-07-24 10:21:38,065][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[34185],
        [43510],
        [12546],
        [43744],
        [    1],
        [43110],
        [34513],
        [31911],
        [37735],
        [39026],
        [36171],
        [24872],
        [37363],
        [36519],
        [ 3007],
        [40579],
        [23720],
        [37218],
        [30826]], device='cuda:0')
[2024-07-24 10:21:38,067][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[ 1155],
        [ 1094],
        [ 2394],
        [ 1070],
        [ 2801],
        [ 2242],
        [  940],
        [ 1843],
        [ 1340],
        [ 3317],
        [ 4393],
        [ 2064],
        [ 5478],
        [ 1659],
        [ 6828],
        [ 5615],
        [ 4970],
        [13386],
        [ 6044]], device='cuda:0')
[2024-07-24 10:21:38,068][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[ 8962],
        [36730],
        [49758],
        [46320],
        [12954],
        [44054],
        [45787],
        [12661],
        [40309],
        [18475],
        [39544],
        [46562],
        [30519],
        [25664],
        [49486],
        [10997],
        [44130],
        [ 5287],
        [35192]], device='cuda:0')
[2024-07-24 10:21:38,071][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[14864],
        [14539],
        [13961],
        [19365],
        [ 6389],
        [19148],
        [19106],
        [19934],
        [19698],
        [18285],
        [20101],
        [21125],
        [15305],
        [23832],
        [18202],
        [21516],
        [24234],
        [17844],
        [26372]], device='cuda:0')
[2024-07-24 10:21:38,072][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[50204],
        [49407],
        [13741],
        [11312],
        [  147],
        [ 1567],
        [ 3364],
        [15099],
        [11443],
        [ 2540],
        [ 8049],
        [12800],
        [22924],
        [11814],
        [ 6257],
        [ 5567],
        [ 3930],
        [ 9259],
        [ 6345]], device='cuda:0')
[2024-07-24 10:21:38,074][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[32632],
        [32688],
        [ 9212],
        [23302],
        [  107],
        [12825],
        [14840],
        [ 2332],
        [ 3478],
        [ 7534],
        [ 8989],
        [13671],
        [50111],
        [19942],
        [ 5766],
        [30184],
        [24114],
        [31083],
        [28965]], device='cuda:0')
[2024-07-24 10:21:38,076][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[23280],
        [17534],
        [27794],
        [18775],
        [ 1758],
        [15811],
        [19102],
        [ 1647],
        [21401],
        [19773],
        [23682],
        [17078],
        [38024],
        [22826],
        [30782],
        [31784],
        [20772],
        [ 3293],
        [20405]], device='cuda:0')
[2024-07-24 10:21:38,078][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[27993],
        [27723],
        [19249],
        [24170],
        [ 5936],
        [ 1842],
        [  894],
        [ 5414],
        [ 1149],
        [ 1205],
        [ 1543],
        [  979],
        [10002],
        [11039],
        [11322],
        [20374],
        [14163],
        [31632],
        [14834]], device='cuda:0')
[2024-07-24 10:21:38,080][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[ 9289],
        [ 7403],
        [ 1503],
        [ 3453],
        [ 1113],
        [ 2824],
        [ 9566],
        [18920],
        [16665],
        [14662],
        [ 3083],
        [ 5097],
        [ 8434],
        [ 6682],
        [ 3723],
        [11245],
        [23869],
        [24673],
        [15079]], device='cuda:0')
[2024-07-24 10:21:38,082][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[ 4232],
        [ 6729],
        [ 1695],
        [13499],
        [  170],
        [ 9570],
        [15739],
        [ 7453],
        [13734],
        [ 5703],
        [ 9912],
        [10819],
        [ 2616],
        [11883],
        [  446],
        [ 5120],
        [12556],
        [ 3666],
        [13582]], device='cuda:0')
[2024-07-24 10:21:38,084][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[43405],
        [46907],
        [46504],
        [47334],
        [46928],
        [44953],
        [46074],
        [45667],
        [46459],
        [44049],
        [45519],
        [46028],
        [44873],
        [43908],
        [43645],
        [40369],
        [43750],
        [39347],
        [43164]], device='cuda:0')
[2024-07-24 10:21:38,086][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[11650],
        [ 5575],
        [22652],
        [ 4321],
        [17026],
        [ 2142],
        [ 4504],
        [11776],
        [ 2800],
        [20456],
        [ 1975],
        [ 5465],
        [28792],
        [ 2583],
        [33656],
        [ 2651],
        [ 6692],
        [22383],
        [ 2656]], device='cuda:0')
[2024-07-24 10:21:38,088][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[18290],
        [14023],
        [13110],
        [14878],
        [11496],
        [10269],
        [ 9676],
        [ 9783],
        [ 9161],
        [ 8878],
        [ 7838],
        [ 9801],
        [ 6925],
        [ 7591],
        [ 6961],
        [ 8460],
        [ 7906],
        [ 5688],
        [ 6459]], device='cuda:0')
[2024-07-24 10:21:38,090][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[39328],
        [ 8342],
        [20606],
        [31922],
        [    1],
        [38677],
        [37842],
        [28523],
        [25447],
        [42438],
        [20116],
        [32337],
        [39510],
        [ 9721],
        [18647],
        [38282],
        [37787],
        [25267],
        [19269]], device='cuda:0')
[2024-07-24 10:21:38,092][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[13149],
        [14219],
        [22903],
        [18801],
        [20051],
        [11851],
        [17098],
        [22520],
        [19905],
        [25358],
        [25819],
        [22777],
        [20657],
        [20499],
        [24557],
        [18959],
        [21124],
        [20509],
        [22423]], device='cuda:0')
[2024-07-24 10:21:38,094][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[11211],
        [ 6312],
        [ 6761],
        [ 4714],
        [21100],
        [12923],
        [ 3433],
        [13650],
        [ 3490],
        [16667],
        [11180],
        [ 2117],
        [15227],
        [ 8143],
        [ 7659],
        [28261],
        [ 4482],
        [27766],
        [ 7431]], device='cuda:0')
[2024-07-24 10:21:38,096][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[42288],
        [41480],
        [42287],
        [46695],
        [32512],
        [42072],
        [43680],
        [43595],
        [42898],
        [42842],
        [39854],
        [38251],
        [41567],
        [39795],
        [40530],
        [40203],
        [37216],
        [40545],
        [32814]], device='cuda:0')
[2024-07-24 10:21:38,098][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[ 9825],
        [12479],
        [14296],
        [18749],
        [14366],
        [13964],
        [10500],
        [18655],
        [11733],
        [29655],
        [ 8528],
        [ 7692],
        [ 7234],
        [10027],
        [14428],
        [10456],
        [10070],
        [18369],
        [10548]], device='cuda:0')
[2024-07-24 10:21:38,100][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[ 5949],
        [ 6066],
        [18436],
        [ 5821],
        [ 3906],
        [ 4748],
        [ 4991],
        [14477],
        [ 8096],
        [14461],
        [ 5319],
        [ 5690],
        [ 2760],
        [ 9434],
        [14687],
        [ 5669],
        [ 4419],
        [15039],
        [ 3690]], device='cuda:0')
[2024-07-24 10:21:38,102][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[27124],
        [23693],
        [16946],
        [17032],
        [ 6019],
        [11951],
        [10167],
        [16912],
        [12862],
        [ 5997],
        [11713],
        [10756],
        [18996],
        [14720],
        [17933],
        [ 7658],
        [ 8688],
        [30964],
        [11945]], device='cuda:0')
[2024-07-24 10:21:38,103][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[42737],
        [42673],
        [10993],
        [22388],
        [ 5259],
        [ 7249],
        [ 7558],
        [ 8602],
        [ 5257],
        [ 6547],
        [ 6181],
        [ 6303],
        [ 8057],
        [11963],
        [ 3652],
        [ 7471],
        [ 5856],
        [ 9685],
        [32691]], device='cuda:0')
[2024-07-24 10:21:38,105][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[41768],
        [41388],
        [39518],
        [44754],
        [45151],
        [39970],
        [29450],
        [30551],
        [33714],
        [38097],
        [40620],
        [27489],
        [31634],
        [34591],
        [30038],
        [34451],
        [22728],
        [21401],
        [32562]], device='cuda:0')
[2024-07-24 10:21:38,107][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[34926],
        [26729],
        [31862],
        [25577],
        [29191],
        [28852],
        [28924],
        [30817],
        [27867],
        [31047],
        [28146],
        [30537],
        [34663],
        [23603],
        [36367],
        [32781],
        [31155],
        [37578],
        [30818]], device='cuda:0')
[2024-07-24 10:21:38,109][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[38352],
        [37235],
        [37430],
        [36823],
        [37025],
        [38610],
        [35713],
        [35769],
        [35811],
        [35949],
        [35928],
        [34912],
        [35253],
        [33840],
        [34255],
        [35114],
        [34093],
        [34499],
        [33300]], device='cuda:0')
[2024-07-24 10:21:38,111][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[45158],
        [45654],
        [36431],
        [43464],
        [36246],
        [38050],
        [38468],
        [40486],
        [40543],
        [30350],
        [40399],
        [38404],
        [31592],
        [39471],
        [29601],
        [36452],
        [35619],
        [28942],
        [37532]], device='cuda:0')
[2024-07-24 10:21:38,113][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[10237],
        [ 7611],
        [20574],
        [10039],
        [21906],
        [13088],
        [23518],
        [10016],
        [21306],
        [18183],
        [16525],
        [25682],
        [21510],
        [20657],
        [26611],
        [18562],
        [22247],
        [23656],
        [19886]], device='cuda:0')
[2024-07-24 10:21:38,115][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[ 5358],
        [ 5770],
        [11516],
        [ 9713],
        [12655],
        [15243],
        [17758],
        [11264],
        [15537],
        [14328],
        [15301],
        [18532],
        [15315],
        [15081],
        [15696],
        [14616],
        [20522],
        [14679],
        [14776]], device='cuda:0')
[2024-07-24 10:21:38,116][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[ 7652],
        [34777],
        [22835],
        [12391],
        [50256],
        [ 8235],
        [ 7748],
        [15936],
        [17681],
        [ 5488],
        [24254],
        [11533],
        [ 7707],
        [35330],
        [25077],
        [ 8674],
        [ 7840],
        [19054],
        [24339]], device='cuda:0')
[2024-07-24 10:21:38,118][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[5267],
        [5267],
        [5267],
        [5267],
        [5267],
        [5267],
        [5267],
        [5267],
        [5267],
        [5267],
        [5267],
        [5267],
        [5267],
        [5267],
        [5267],
        [5267],
        [5267],
        [5267],
        [5267]], device='cuda:0')
[2024-07-24 10:21:38,138][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:21:38,139][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:38,141][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:38,142][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:38,143][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:38,145][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:38,145][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:38,146][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:38,147][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:38,147][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:38,148][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:38,149][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:38,149][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:38,150][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.6236, 0.3764], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:38,151][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.8666, 0.1334], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:38,152][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.9944, 0.0056], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:38,152][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.3845, 0.6155], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:38,153][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.8884, 0.1116], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:38,154][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.2776, 0.7224], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:38,154][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.9974, 0.0026], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:38,156][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.9350, 0.0650], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:38,157][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.5910, 0.4090], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:38,159][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.1116, 0.8884], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:38,160][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0227, 0.9773], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:38,162][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.9691, 0.0309], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:38,164][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Anthony] are: tensor([0.5396, 0.2004, 0.2600], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:38,165][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Anthony] are: tensor([0.5548, 0.3352, 0.1100], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:38,167][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Anthony] are: tensor([0.8838, 0.0413, 0.0749], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:38,168][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Anthony] are: tensor([0.4817, 0.4010, 0.1172], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:38,170][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Anthony] are: tensor([0.5713, 0.2231, 0.2056], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:38,172][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Anthony] are: tensor([0.2125, 0.5966, 0.1909], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:38,173][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Anthony] are: tensor([0.9843, 0.0011, 0.0146], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:38,175][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Anthony] are: tensor([0.5528, 0.2583, 0.1889], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:38,176][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Anthony] are: tensor([0.4244, 0.2958, 0.2798], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:38,178][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Anthony] are: tensor([0.0971, 0.7644, 0.1385], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:38,180][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Anthony] are: tensor([0.0236, 0.4913, 0.4851], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:38,181][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Anthony] are: tensor([0.7817, 0.2160, 0.0023], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:38,183][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0567, 0.3458, 0.3068, 0.2907], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:38,184][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.4752, 0.2299, 0.1295, 0.1653], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:38,186][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.5094, 0.0330, 0.0681, 0.3895], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:38,188][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.3410, 0.2857, 0.1147, 0.2586], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:38,189][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.3019, 0.1113, 0.2163, 0.3705], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:38,191][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0686, 0.7361, 0.0178, 0.1774], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:38,193][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.9525, 0.0035, 0.0334, 0.0106], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:38,193][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.5129, 0.1385, 0.1232, 0.2254], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:38,194][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.3724, 0.2522, 0.2567, 0.1187], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:38,195][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0366, 0.3290, 0.0617, 0.5728], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:38,196][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0189, 0.3235, 0.4095, 0.2481], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:38,197][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0110, 0.0649, 0.0040, 0.9201], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:38,199][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Travis] are: tensor([0.4035, 0.0383, 0.3581, 0.0734, 0.1267], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:38,200][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Travis] are: tensor([0.4477, 0.1641, 0.1084, 0.2435, 0.0363], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:38,202][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Travis] are: tensor([0.4722, 0.0369, 0.0564, 0.3619, 0.0726], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:38,204][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Travis] are: tensor([0.3983, 0.2429, 0.0887, 0.1983, 0.0717], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:38,205][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Travis] are: tensor([0.2724, 0.2080, 0.1083, 0.3159, 0.0953], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:38,207][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Travis] are: tensor([0.0463, 0.1424, 0.7045, 0.0988, 0.0080], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:38,208][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Travis] are: tensor([0.9179, 0.0052, 0.0397, 0.0128, 0.0244], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:38,210][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Travis] are: tensor([0.6578, 0.0636, 0.1551, 0.0630, 0.0605], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:38,212][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Travis] are: tensor([0.3438, 0.2441, 0.2216, 0.0974, 0.0931], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:38,213][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Travis] are: tensor([0.0302, 0.2283, 0.0444, 0.4703, 0.2268], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:38,215][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Travis] are: tensor([0.0197, 0.2649, 0.2987, 0.2093, 0.2074], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:38,216][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Travis] are: tensor([2.4776e-01, 4.9281e-02, 1.3248e-04, 2.0966e-03, 7.0073e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:38,218][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.0698, 0.3927, 0.0736, 0.2403, 0.0540, 0.1697], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:38,220][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.5061, 0.1162, 0.0775, 0.1755, 0.0346, 0.0902], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:38,221][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.3278, 0.0337, 0.0605, 0.2525, 0.0813, 0.2443], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:38,223][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.2599, 0.2027, 0.0855, 0.1719, 0.0767, 0.2032], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:38,224][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.1726, 0.1148, 0.1196, 0.2285, 0.1061, 0.2584], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:38,226][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.0698, 0.7282, 0.0758, 0.0304, 0.0337, 0.0620], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:38,227][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.9024, 0.0063, 0.0531, 0.0143, 0.0223, 0.0016], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:38,229][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.1840, 0.1182, 0.0733, 0.1470, 0.2461, 0.2314], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:38,231][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.3291, 0.2155, 0.2013, 0.0924, 0.0815, 0.0803], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:38,232][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.0218, 0.1917, 0.0397, 0.3860, 0.1983, 0.1625], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:38,234][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.0090, 0.2125, 0.2663, 0.1409, 0.1770, 0.1943], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:38,235][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ had] are: tensor([1.0498e-01, 3.5305e-01, 6.0833e-05, 1.4878e-01, 3.5160e-03, 3.8962e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:38,237][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0095, 0.0757, 0.0946, 0.0886, 0.0379, 0.5749, 0.1188],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:38,238][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.3586, 0.1325, 0.0719, 0.1270, 0.0370, 0.0594, 0.2136],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:38,240][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.2532, 0.0276, 0.0472, 0.1869, 0.0621, 0.1704, 0.2526],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:38,242][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.2433, 0.1654, 0.0709, 0.1409, 0.0647, 0.1619, 0.1529],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:38,243][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.1228, 0.0872, 0.0794, 0.1984, 0.0790, 0.1987, 0.2345],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:38,245][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0939, 0.7038, 0.0350, 0.0613, 0.0176, 0.0317, 0.0567],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:38,247][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.6466, 0.0213, 0.1792, 0.0534, 0.0870, 0.0056, 0.0069],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:38,248][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.1835, 0.0847, 0.0769, 0.0862, 0.2429, 0.2047, 0.1213],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:38,250][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.2935, 0.1869, 0.1733, 0.0802, 0.0678, 0.0665, 0.1318],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:38,252][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0138, 0.1401, 0.0253, 0.2735, 0.1303, 0.1159, 0.3010],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:38,253][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0115, 0.1701, 0.2261, 0.1287, 0.1776, 0.1602, 0.1258],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:38,254][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ a] are: tensor([1.0032e-02, 7.1887e-02, 4.5456e-04, 1.2646e-01, 8.4538e-03, 6.6707e-02,
        7.1601e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:38,255][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ lot] are: tensor([0.0179, 0.0833, 0.0411, 0.0912, 0.0235, 0.1382, 0.5672, 0.0377],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:38,256][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ lot] are: tensor([0.1628, 0.0790, 0.0244, 0.1360, 0.0134, 0.0363, 0.1302, 0.4178],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:38,257][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ lot] are: tensor([0.2264, 0.0251, 0.0382, 0.1681, 0.0551, 0.1487, 0.2227, 0.1158],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:38,258][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ lot] are: tensor([0.2312, 0.1602, 0.0566, 0.1482, 0.0558, 0.1560, 0.1427, 0.0493],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:38,259][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ lot] are: tensor([0.1276, 0.0795, 0.0615, 0.1798, 0.0745, 0.1614, 0.2093, 0.1063],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:38,260][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ lot] are: tensor([0.0623, 0.6672, 0.0132, 0.0553, 0.0123, 0.0265, 0.0754, 0.0879],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:38,262][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ lot] are: tensor([0.6343, 0.0176, 0.1943, 0.0598, 0.0683, 0.0052, 0.0079, 0.0127],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:38,263][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ lot] are: tensor([0.7064, 0.0905, 0.0179, 0.0434, 0.0278, 0.0320, 0.0638, 0.0183],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:38,265][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ lot] are: tensor([0.2531, 0.1638, 0.1599, 0.0701, 0.0643, 0.0648, 0.1264, 0.0976],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:38,266][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ lot] are: tensor([0.0131, 0.1329, 0.0253, 0.2458, 0.1252, 0.1005, 0.2613, 0.0960],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:38,268][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ lot] are: tensor([0.0108, 0.1440, 0.2207, 0.1058, 0.1535, 0.1267, 0.1011, 0.1374],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:38,269][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ lot] are: tensor([3.4927e-01, 4.4309e-01, 4.0090e-05, 1.2673e-01, 8.7140e-04, 7.0354e-03,
        1.5142e-02, 5.7824e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:38,271][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ of] are: tensor([0.0012, 0.0191, 0.0194, 0.0139, 0.0061, 0.0407, 0.1411, 0.7468, 0.0117],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:38,272][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ of] are: tensor([0.1635, 0.0663, 0.0428, 0.0647, 0.0169, 0.0346, 0.1540, 0.3567, 0.1005],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:38,274][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ of] are: tensor([0.1727, 0.0221, 0.0360, 0.1339, 0.0486, 0.1301, 0.1743, 0.0828, 0.1995],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:38,276][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ of] are: tensor([0.2256, 0.1399, 0.0541, 0.1326, 0.0478, 0.1511, 0.1372, 0.0483, 0.0633],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:38,278][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ of] are: tensor([0.0775, 0.0767, 0.0627, 0.1642, 0.0730, 0.1555, 0.1740, 0.0505, 0.1660],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:38,279][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ of] are: tensor([3.1516e-03, 1.1150e-02, 7.0672e-04, 4.8158e-03, 2.6071e-04, 3.2198e-04,
        9.3063e-03, 4.2356e-04, 9.6986e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:38,280][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ of] are: tensor([0.6152, 0.0233, 0.1879, 0.0547, 0.0824, 0.0058, 0.0077, 0.0129, 0.0100],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:38,282][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ of] are: tensor([0.2790, 0.0701, 0.0257, 0.0469, 0.0656, 0.0875, 0.0656, 0.3058, 0.0537],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:38,284][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ of] are: tensor([0.2468, 0.1582, 0.1535, 0.0678, 0.0610, 0.0603, 0.1161, 0.0890, 0.0474],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:38,285][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ of] are: tensor([0.0104, 0.1076, 0.0197, 0.1967, 0.0980, 0.0814, 0.2118, 0.0767, 0.1978],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:38,287][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ of] are: tensor([0.0094, 0.1378, 0.1852, 0.1028, 0.1371, 0.1364, 0.0882, 0.1382, 0.0649],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:38,289][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ of] are: tensor([0.0637, 0.2042, 0.0006, 0.2178, 0.0103, 0.1380, 0.2810, 0.0331, 0.0513],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:38,291][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ fun] are: tensor([0.0024, 0.0074, 0.0094, 0.0071, 0.0099, 0.0852, 0.0477, 0.7478, 0.0337,
        0.0495], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:38,292][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ fun] are: tensor([0.1002, 0.0488, 0.0167, 0.0821, 0.0102, 0.0251, 0.0666, 0.3521, 0.0807,
        0.2176], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:38,294][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ fun] are: tensor([0.1439, 0.0215, 0.0304, 0.1332, 0.0411, 0.1175, 0.1564, 0.0776, 0.1952,
        0.0831], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:38,296][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ fun] are: tensor([0.1967, 0.1238, 0.0517, 0.1188, 0.0552, 0.1260, 0.1143, 0.0529, 0.0646,
        0.0959], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:38,297][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ fun] are: tensor([0.1048, 0.0719, 0.0436, 0.1530, 0.0479, 0.1218, 0.1402, 0.0737, 0.1646,
        0.0785], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:38,299][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ fun] are: tensor([0.0836, 0.4033, 0.0959, 0.0539, 0.0175, 0.0321, 0.1242, 0.0589, 0.0807,
        0.0499], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:38,301][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ fun] are: tensor([0.7386, 0.0216, 0.0990, 0.0380, 0.0555, 0.0047, 0.0062, 0.0108, 0.0082,
        0.0174], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:38,303][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ fun] are: tensor([0.0363, 0.0185, 0.0336, 0.0216, 0.0732, 0.1059, 0.0271, 0.5900, 0.0613,
        0.0325], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:38,304][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ fun] are: tensor([0.2222, 0.1474, 0.1510, 0.0644, 0.0613, 0.0605, 0.1152, 0.0904, 0.0486,
        0.0389], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:38,306][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ fun] are: tensor([0.0112, 0.1013, 0.0216, 0.1972, 0.1024, 0.0782, 0.1869, 0.0735, 0.1837,
        0.0441], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:38,308][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ fun] are: tensor([0.0091, 0.1278, 0.1546, 0.0927, 0.1135, 0.1103, 0.0820, 0.1111, 0.0514,
        0.1476], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:38,309][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ fun] are: tensor([1.0598e-01, 6.9003e-01, 5.8407e-04, 7.0034e-02, 1.0777e-02, 1.1142e-02,
        1.3696e-02, 5.5889e-03, 3.9057e-03, 8.8266e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:38,311][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.0019, 0.0120, 0.0357, 0.0205, 0.0243, 0.0815, 0.1518, 0.5314, 0.0880,
        0.0470, 0.0058], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:38,312][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.0630, 0.0313, 0.0211, 0.0395, 0.0086, 0.0253, 0.0792, 0.3348, 0.0851,
        0.2694, 0.0427], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:38,314][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.1211, 0.0174, 0.0286, 0.0923, 0.0382, 0.0930, 0.1211, 0.0630, 0.1345,
        0.0645, 0.2264], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:38,316][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.1728, 0.1118, 0.0514, 0.1042, 0.0482, 0.1100, 0.0974, 0.0493, 0.0585,
        0.0855, 0.1109], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:38,317][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.0633, 0.0538, 0.0435, 0.1153, 0.0487, 0.1192, 0.1259, 0.0578, 0.1300,
        0.0658, 0.1766], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:38,318][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.0100, 0.0419, 0.0013, 0.0088, 0.0036, 0.0010, 0.0237, 0.0033, 0.0442,
        0.0015, 0.8606], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:38,318][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.6176, 0.0313, 0.1279, 0.0556, 0.0757, 0.0066, 0.0079, 0.0125, 0.0106,
        0.0225, 0.0319], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:38,320][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0253, 0.0075, 0.0214, 0.0131, 0.1714, 0.0757, 0.0122, 0.5847, 0.0376,
        0.0408, 0.0104], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:38,321][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.2231, 0.1432, 0.1379, 0.0617, 0.0559, 0.0553, 0.1047, 0.0808, 0.0435,
        0.0347, 0.0591], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:38,323][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.0095, 0.0916, 0.0178, 0.1759, 0.0898, 0.0716, 0.1746, 0.0657, 0.1668,
        0.0393, 0.0974], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:38,325][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.0091, 0.1071, 0.1416, 0.0820, 0.1034, 0.0980, 0.0696, 0.1132, 0.0442,
        0.1387, 0.0932], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:38,326][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.0007, 0.0332, 0.0007, 0.0735, 0.0124, 0.2138, 0.2562, 0.0432, 0.0238,
        0.0070, 0.3353], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:38,328][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0017, 0.0113, 0.0482, 0.0191, 0.0502, 0.0461, 0.1241, 0.5199, 0.0852,
        0.0438, 0.0240, 0.0264], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:38,329][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.1357, 0.0393, 0.0203, 0.0365, 0.0085, 0.0153, 0.0860, 0.2487, 0.0821,
        0.1697, 0.0478, 0.1100], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:38,331][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0991, 0.0160, 0.0256, 0.0763, 0.0329, 0.0784, 0.1043, 0.0584, 0.1085,
        0.0601, 0.1806, 0.1599], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:38,333][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.1733, 0.0988, 0.0427, 0.0915, 0.0380, 0.1013, 0.0934, 0.0410, 0.0496,
        0.0720, 0.1029, 0.0956], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:38,335][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0510, 0.0449, 0.0388, 0.0962, 0.0420, 0.0909, 0.1151, 0.0550, 0.1008,
        0.0598, 0.1386, 0.1669], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:38,336][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0296, 0.4128, 0.0418, 0.0261, 0.0214, 0.0083, 0.0369, 0.0133, 0.2381,
        0.0046, 0.1317, 0.0353], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:38,338][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.4386, 0.0274, 0.1826, 0.0833, 0.1302, 0.0105, 0.0085, 0.0174, 0.0122,
        0.0263, 0.0355, 0.0275], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:38,340][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0369, 0.0106, 0.0224, 0.0143, 0.1282, 0.0933, 0.0261, 0.5577, 0.0294,
        0.0456, 0.0139, 0.0216], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:38,341][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.1908, 0.1258, 0.1213, 0.0538, 0.0477, 0.0486, 0.0919, 0.0704, 0.0373,
        0.0297, 0.0518, 0.1308], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:38,343][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0070, 0.0742, 0.0128, 0.1406, 0.0678, 0.0564, 0.1444, 0.0522, 0.1361,
        0.0303, 0.0788, 0.1994], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:38,345][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0083, 0.0947, 0.1284, 0.0728, 0.1030, 0.0941, 0.0722, 0.1033, 0.0392,
        0.1316, 0.0776, 0.0748], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:38,347][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0014, 0.0458, 0.0004, 0.0631, 0.0101, 0.2331, 0.3112, 0.0270, 0.0175,
        0.0054, 0.0807, 0.2042], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:38,348][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ hospital] are: tensor([0.0023, 0.0054, 0.0108, 0.0073, 0.2373, 0.0215, 0.0228, 0.5276, 0.0531,
        0.0263, 0.0372, 0.0383, 0.0100], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:38,350][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ hospital] are: tensor([0.0571, 0.0270, 0.0160, 0.0444, 0.0086, 0.0164, 0.0449, 0.2725, 0.0637,
        0.2088, 0.0522, 0.1230, 0.0654], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:38,352][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ hospital] are: tensor([0.0903, 0.0174, 0.0243, 0.0806, 0.0294, 0.0808, 0.0958, 0.0520, 0.1069,
        0.0565, 0.1666, 0.1320, 0.0674], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:38,354][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ hospital] are: tensor([0.1732, 0.1082, 0.0436, 0.0885, 0.0394, 0.0944, 0.0779, 0.0318, 0.0410,
        0.0681, 0.1024, 0.0746, 0.0569], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:38,355][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ hospital] are: tensor([0.0722, 0.0558, 0.0559, 0.0973, 0.0513, 0.0951, 0.0895, 0.0431, 0.0940,
        0.0516, 0.1074, 0.1149, 0.0718], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:38,357][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ hospital] are: tensor([0.0320, 0.1940, 0.0179, 0.0163, 0.0245, 0.0153, 0.1105, 0.0183, 0.0503,
        0.0058, 0.1716, 0.1250, 0.2187], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:38,359][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ hospital] are: tensor([0.3271, 0.0278, 0.1707, 0.0864, 0.1244, 0.0116, 0.0083, 0.0173, 0.0117,
        0.0233, 0.0325, 0.0242, 0.1347], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:38,361][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ hospital] are: tensor([0.0443, 0.0129, 0.0380, 0.0161, 0.0701, 0.0435, 0.0297, 0.5595, 0.0556,
        0.0894, 0.0076, 0.0269, 0.0064], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:38,362][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ hospital] are: tensor([0.1853, 0.1194, 0.1097, 0.0516, 0.0466, 0.0470, 0.0912, 0.0700, 0.0337,
        0.0290, 0.0477, 0.1233, 0.0454], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:38,364][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ hospital] are: tensor([0.0080, 0.0682, 0.0140, 0.1421, 0.0712, 0.0531, 0.1279, 0.0527, 0.1283,
        0.0296, 0.0737, 0.1692, 0.0619], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:38,366][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ hospital] are: tensor([0.0074, 0.0964, 0.1113, 0.0771, 0.0820, 0.0900, 0.0647, 0.0886, 0.0432,
        0.1176, 0.0830, 0.0576, 0.0811], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:38,367][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ hospital] are: tensor([1.9196e-02, 3.0700e-02, 7.2434e-04, 3.4158e-02, 2.1675e-02, 1.6198e-02,
        8.9089e-03, 7.1218e-04, 4.4432e-03, 1.5495e-04, 1.3029e-02, 3.3680e-03,
        8.4673e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:38,369][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.0197, 0.0276, 0.0666, 0.0273, 0.0447, 0.0626, 0.0277, 0.3875, 0.0185,
        0.2777, 0.0102, 0.0106, 0.0181, 0.0013], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:38,370][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.1364, 0.0383, 0.0205, 0.0433, 0.0069, 0.0131, 0.0582, 0.1262, 0.0567,
        0.0930, 0.0447, 0.1079, 0.0514, 0.2034], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:38,372][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.0754, 0.0120, 0.0210, 0.0530, 0.0259, 0.0635, 0.0740, 0.0451, 0.0781,
        0.0486, 0.1265, 0.1105, 0.0707, 0.1957], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:38,374][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.1861, 0.0851, 0.0334, 0.0836, 0.0283, 0.0888, 0.0824, 0.0256, 0.0372,
        0.0621, 0.1112, 0.0820, 0.0592, 0.0351], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:38,376][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0404, 0.0412, 0.0395, 0.0663, 0.0346, 0.0702, 0.0722, 0.0480, 0.0717,
        0.0460, 0.0946, 0.0948, 0.0731, 0.2072], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:38,377][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.0630, 0.2583, 0.0386, 0.0781, 0.0321, 0.0145, 0.0550, 0.0124, 0.0897,
        0.0081, 0.0507, 0.0680, 0.0449, 0.1867], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:38,378][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.4321, 0.0174, 0.0874, 0.0536, 0.0824, 0.0077, 0.0063, 0.0127, 0.0073,
        0.0106, 0.0196, 0.0185, 0.0825, 0.1620], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:38,379][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.1312, 0.0250, 0.0236, 0.0342, 0.0939, 0.0618, 0.0437, 0.3358, 0.0292,
        0.0614, 0.0275, 0.0346, 0.0805, 0.0177], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:38,380][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.1593, 0.1115, 0.1038, 0.0500, 0.0424, 0.0451, 0.0869, 0.0656, 0.0348,
        0.0279, 0.0494, 0.1244, 0.0453, 0.0536], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:38,381][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.0052, 0.0531, 0.0099, 0.1106, 0.0532, 0.0436, 0.1034, 0.0388, 0.1003,
        0.0230, 0.0570, 0.1364, 0.0475, 0.2180], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:38,383][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.0064, 0.0888, 0.1111, 0.0676, 0.0827, 0.0827, 0.0571, 0.0863, 0.0364,
        0.1151, 0.0778, 0.0543, 0.0985, 0.0352], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:38,384][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0132, 0.1232, 0.0006, 0.2096, 0.0138, 0.2291, 0.1945, 0.0320, 0.0155,
        0.0052, 0.0649, 0.0630, 0.0029, 0.0326], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:38,386][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Anthony] are: tensor([0.0317, 0.0425, 0.0201, 0.0241, 0.3740, 0.0600, 0.0343, 0.1185, 0.0681,
        0.0612, 0.0422, 0.0533, 0.0300, 0.0363, 0.0037], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:38,388][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Anthony] are: tensor([0.0420, 0.0226, 0.0091, 0.0367, 0.0055, 0.0223, 0.0366, 0.2054, 0.0450,
        0.1961, 0.0266, 0.1094, 0.0577, 0.1662, 0.0189], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:38,389][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Anthony] are: tensor([0.0626, 0.0141, 0.0172, 0.0556, 0.0219, 0.0627, 0.0673, 0.0386, 0.0717,
        0.0408, 0.1240, 0.0966, 0.0598, 0.1645, 0.1026], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:38,391][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Anthony] are: tensor([0.2177, 0.0856, 0.0269, 0.0823, 0.0217, 0.0890, 0.0789, 0.0190, 0.0337,
        0.0536, 0.1128, 0.0806, 0.0519, 0.0322, 0.0140], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:38,393][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Anthony] are: tensor([0.0377, 0.0616, 0.0280, 0.0879, 0.0368, 0.0837, 0.0783, 0.0287, 0.0653,
        0.0335, 0.0769, 0.0899, 0.0379, 0.2113, 0.0425], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:38,395][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Anthony] are: tensor([0.0051, 0.0914, 0.0576, 0.0171, 0.1180, 0.0023, 0.0143, 0.0021, 0.0107,
        0.0019, 0.0366, 0.0204, 0.0051, 0.1374, 0.4800], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:38,397][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Anthony] are: tensor([0.3223, 0.0138, 0.0974, 0.0500, 0.0752, 0.0073, 0.0048, 0.0119, 0.0062,
        0.0100, 0.0150, 0.0135, 0.0780, 0.1892, 0.1054], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:38,398][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Anthony] are: tensor([0.0374, 0.0499, 0.0415, 0.0471, 0.1280, 0.0310, 0.0303, 0.1185, 0.0337,
        0.0320, 0.0257, 0.0744, 0.1602, 0.1400, 0.0503], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:38,400][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Anthony] are: tensor([0.1557, 0.1124, 0.0928, 0.0454, 0.0386, 0.0423, 0.0841, 0.0610, 0.0294,
        0.0254, 0.0438, 0.1150, 0.0392, 0.0461, 0.0687], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:38,402][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Anthony] are: tensor([0.0059, 0.0499, 0.0097, 0.1181, 0.0522, 0.0428, 0.0960, 0.0405, 0.0983,
        0.0220, 0.0537, 0.1227, 0.0478, 0.2044, 0.0359], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:38,404][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Anthony] are: tensor([0.0068, 0.0908, 0.0984, 0.0687, 0.0733, 0.0752, 0.0572, 0.0748, 0.0350,
        0.0968, 0.0681, 0.0536, 0.0831, 0.0319, 0.0862], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:38,405][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Anthony] are: tensor([9.1882e-02, 6.3981e-01, 4.9817e-03, 5.7737e-02, 2.3593e-02, 3.4410e-02,
        6.9407e-02, 8.0653e-04, 5.5173e-03, 9.0309e-04, 4.0863e-02, 1.1673e-02,
        6.3730e-04, 7.3076e-03, 1.0471e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:38,407][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.0031, 0.0297, 0.0122, 0.0229, 0.0319, 0.0135, 0.0783, 0.2413, 0.0499,
        0.0239, 0.0160, 0.0425, 0.0071, 0.3284, 0.0798, 0.0194],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:38,409][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0555, 0.0248, 0.0111, 0.0409, 0.0043, 0.0175, 0.0466, 0.2545, 0.0468,
        0.1282, 0.0281, 0.0915, 0.0405, 0.1355, 0.0172, 0.0572],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:38,410][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0591, 0.0137, 0.0188, 0.0471, 0.0225, 0.0500, 0.0566, 0.0342, 0.0631,
        0.0372, 0.1019, 0.0792, 0.0552, 0.1436, 0.1015, 0.1163],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:38,412][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.1300, 0.0872, 0.0369, 0.0789, 0.0321, 0.0837, 0.0683, 0.0318, 0.0405,
        0.0610, 0.0856, 0.0670, 0.0470, 0.0437, 0.0225, 0.0837],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:38,414][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.0388, 0.0457, 0.0291, 0.0795, 0.0309, 0.0612, 0.0646, 0.0220, 0.0692,
        0.0282, 0.0823, 0.0804, 0.0410, 0.2128, 0.0467, 0.0675],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:38,416][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.0700, 0.1620, 0.0804, 0.0188, 0.0291, 0.0696, 0.0915, 0.0096, 0.0710,
        0.0082, 0.0635, 0.0623, 0.0601, 0.1130, 0.0553, 0.0359],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:38,417][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.3861, 0.0094, 0.0504, 0.0229, 0.0323, 0.0036, 0.0036, 0.0079, 0.0042,
        0.0071, 0.0127, 0.0142, 0.1059, 0.1926, 0.1194, 0.0277],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:38,419][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0107, 0.0398, 0.0215, 0.0307, 0.0137, 0.0239, 0.0226, 0.5207, 0.0855,
        0.0244, 0.0147, 0.0282, 0.0030, 0.1125, 0.0312, 0.0169],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:38,421][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.1464, 0.0990, 0.0903, 0.0443, 0.0385, 0.0406, 0.0803, 0.0594, 0.0302,
        0.0247, 0.0427, 0.1111, 0.0404, 0.0477, 0.0732, 0.0313],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:38,423][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.0052, 0.0424, 0.0097, 0.1012, 0.0484, 0.0399, 0.0913, 0.0349, 0.0902,
        0.0205, 0.0531, 0.1225, 0.0458, 0.2040, 0.0361, 0.0548],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:38,424][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0049, 0.0752, 0.0978, 0.0546, 0.0679, 0.0692, 0.0464, 0.0712, 0.0325,
        0.0893, 0.0687, 0.0448, 0.0744, 0.0293, 0.0878, 0.0858],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:38,426][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0825, 0.2069, 0.0014, 0.0951, 0.0053, 0.1169, 0.0143, 0.0168, 0.0110,
        0.0139, 0.0134, 0.0096, 0.0176, 0.0224, 0.0007, 0.3721],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:38,428][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ a] are: tensor([3.4530e-04, 8.5224e-03, 4.8538e-03, 7.0393e-03, 2.9526e-03, 2.6372e-02,
        1.4557e-02, 3.8454e-01, 4.9909e-02, 5.5876e-03, 5.2572e-03, 2.6816e-02,
        9.0504e-04, 1.6001e-01, 3.8878e-02, 2.3896e-01, 2.4490e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:38,429][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0618, 0.0250, 0.0132, 0.0266, 0.0061, 0.0108, 0.0341, 0.1426, 0.0635,
        0.1176, 0.0314, 0.1147, 0.0459, 0.1458, 0.0290, 0.0581, 0.0738],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:38,431][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0481, 0.0124, 0.0168, 0.0360, 0.0192, 0.0425, 0.0518, 0.0314, 0.0487,
        0.0338, 0.0832, 0.0704, 0.0527, 0.1178, 0.0904, 0.1034, 0.1412],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:38,433][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.1317, 0.0804, 0.0351, 0.0710, 0.0290, 0.0761, 0.0719, 0.0308, 0.0374,
        0.0520, 0.0734, 0.0671, 0.0447, 0.0371, 0.0212, 0.0752, 0.0658],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:38,435][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0301, 0.0361, 0.0211, 0.0647, 0.0207, 0.0539, 0.0699, 0.0287, 0.0623,
        0.0328, 0.0741, 0.0922, 0.0425, 0.1849, 0.0390, 0.0632, 0.0839],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:38,437][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0255, 0.2441, 0.0155, 0.0201, 0.0104, 0.0210, 0.0319, 0.0103, 0.1309,
        0.0087, 0.0970, 0.0501, 0.1373, 0.1210, 0.0189, 0.0265, 0.0307],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:38,439][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.1906, 0.0133, 0.1057, 0.0442, 0.0614, 0.0048, 0.0041, 0.0093, 0.0057,
        0.0109, 0.0155, 0.0131, 0.0999, 0.2527, 0.1239, 0.0331, 0.0119],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:38,439][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0110, 0.0338, 0.0158, 0.0156, 0.0133, 0.0189, 0.0160, 0.6329, 0.0647,
        0.0125, 0.0087, 0.0178, 0.0031, 0.0762, 0.0186, 0.0271, 0.0142],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:38,440][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.1443, 0.0962, 0.0876, 0.0412, 0.0360, 0.0378, 0.0737, 0.0545, 0.0277,
        0.0226, 0.0397, 0.1036, 0.0375, 0.0444, 0.0685, 0.0292, 0.0553],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:38,441][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0042, 0.0403, 0.0078, 0.0916, 0.0413, 0.0353, 0.0851, 0.0310, 0.0821,
        0.0180, 0.0474, 0.1173, 0.0400, 0.1880, 0.0308, 0.0490, 0.0909],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:38,443][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0056, 0.0628, 0.0875, 0.0499, 0.0692, 0.0627, 0.0500, 0.0756, 0.0277,
        0.0905, 0.0543, 0.0467, 0.0790, 0.0267, 0.0818, 0.0840, 0.0461],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:38,445][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0077, 0.0658, 0.0011, 0.0960, 0.0096, 0.1102, 0.3865, 0.0429, 0.0228,
        0.0183, 0.0689, 0.0494, 0.0137, 0.0576, 0.0020, 0.0052, 0.0422],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:38,446][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ drink] are: tensor([0.0029, 0.0136, 0.0063, 0.0087, 0.0078, 0.0690, 0.0729, 0.3096, 0.0568,
        0.0556, 0.0141, 0.0538, 0.0101, 0.1469, 0.0218, 0.0620, 0.0646, 0.0234],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:38,448][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ drink] are: tensor([0.0406, 0.0178, 0.0099, 0.0318, 0.0054, 0.0135, 0.0225, 0.1847, 0.0295,
        0.1572, 0.0223, 0.0584, 0.0436, 0.0946, 0.0177, 0.0942, 0.0525, 0.1037],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:38,450][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ drink] are: tensor([0.0456, 0.0103, 0.0139, 0.0349, 0.0168, 0.0406, 0.0452, 0.0263, 0.0482,
        0.0320, 0.0789, 0.0641, 0.0454, 0.1191, 0.0818, 0.0987, 0.1271, 0.0711],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:38,451][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ drink] are: tensor([0.1657, 0.0769, 0.0303, 0.0644, 0.0252, 0.0680, 0.0610, 0.0211, 0.0283,
        0.0473, 0.0803, 0.0591, 0.0461, 0.0343, 0.0178, 0.0832, 0.0672, 0.0238],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:38,453][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ drink] are: tensor([0.0353, 0.0428, 0.0239, 0.0684, 0.0299, 0.0567, 0.0607, 0.0216, 0.0622,
        0.0304, 0.0761, 0.0744, 0.0356, 0.1731, 0.0398, 0.0573, 0.0698, 0.0420],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:38,455][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ drink] are: tensor([0.0269, 0.2691, 0.0083, 0.0125, 0.0089, 0.0079, 0.0855, 0.0097, 0.0461,
        0.0067, 0.0636, 0.0825, 0.0845, 0.1520, 0.0076, 0.0101, 0.0934, 0.0247],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:38,457][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ drink] are: tensor([0.1523, 0.0123, 0.1184, 0.0541, 0.0705, 0.0058, 0.0044, 0.0081, 0.0061,
        0.0141, 0.0161, 0.0125, 0.1015, 0.2329, 0.1153, 0.0332, 0.0124, 0.0303],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:38,459][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ drink] are: tensor([0.0519, 0.0397, 0.0336, 0.0229, 0.0420, 0.0219, 0.0359, 0.1152, 0.0468,
        0.0590, 0.0239, 0.0428, 0.0716, 0.2779, 0.0509, 0.0289, 0.0312, 0.0041],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:38,461][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ drink] are: tensor([0.1361, 0.0925, 0.0834, 0.0398, 0.0372, 0.0377, 0.0730, 0.0559, 0.0262,
        0.0235, 0.0386, 0.0999, 0.0365, 0.0411, 0.0642, 0.0293, 0.0548, 0.0304],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:38,462][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ drink] are: tensor([0.0054, 0.0387, 0.0082, 0.0940, 0.0424, 0.0337, 0.0748, 0.0304, 0.0755,
        0.0176, 0.0427, 0.0974, 0.0390, 0.1719, 0.0301, 0.0464, 0.0779, 0.0739],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:38,464][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ drink] are: tensor([0.0058, 0.0673, 0.0814, 0.0523, 0.0591, 0.0600, 0.0424, 0.0561, 0.0264,
        0.0815, 0.0533, 0.0391, 0.0663, 0.0269, 0.0729, 0.0781, 0.0380, 0.0934],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:38,465][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ drink] are: tensor([5.4402e-03, 4.4582e-03, 3.0343e-04, 5.2612e-03, 5.7823e-04, 6.1842e-04,
        1.9073e-04, 6.5783e-04, 6.5145e-04, 1.7483e-03, 5.9912e-04, 2.0671e-04,
        3.5496e-02, 1.2274e-03, 1.6690e-05, 2.4641e-02, 1.2605e-03, 9.1664e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:38,467][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0004, 0.0084, 0.0048, 0.0079, 0.0198, 0.0373, 0.0415, 0.2096, 0.0529,
        0.0140, 0.0035, 0.0174, 0.0012, 0.2422, 0.0411, 0.1966, 0.0850, 0.0143,
        0.0022], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:38,469][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0393, 0.0241, 0.0116, 0.0285, 0.0044, 0.0117, 0.0455, 0.1425, 0.0389,
        0.0836, 0.0301, 0.0854, 0.0383, 0.1009, 0.0210, 0.0434, 0.0840, 0.0860,
        0.0809], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:38,471][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0360, 0.0103, 0.0146, 0.0261, 0.0168, 0.0343, 0.0362, 0.0231, 0.0365,
        0.0260, 0.0621, 0.0520, 0.0437, 0.0909, 0.0779, 0.0940, 0.1072, 0.0706,
        0.1417], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:38,473][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.1303, 0.0747, 0.0313, 0.0669, 0.0251, 0.0715, 0.0636, 0.0264, 0.0353,
        0.0463, 0.0726, 0.0621, 0.0399, 0.0333, 0.0190, 0.0698, 0.0590, 0.0265,
        0.0463], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:38,474][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0317, 0.0316, 0.0206, 0.0540, 0.0240, 0.0516, 0.0588, 0.0207, 0.0564,
        0.0219, 0.0690, 0.0721, 0.0360, 0.1557, 0.0340, 0.0633, 0.0679, 0.0373,
        0.0932], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:38,476][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ to] are: tensor([7.5756e-03, 1.5276e-02, 1.3312e-02, 8.4298e-03, 8.2785e-03, 2.5383e-03,
        1.4480e-02, 2.0856e-04, 4.1077e-02, 4.6926e-04, 3.5146e-02, 1.8112e-02,
        4.8222e-03, 2.0648e-02, 1.3719e-02, 1.2600e-03, 1.8103e-02, 9.5707e-04,
        7.7559e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:38,478][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1061, 0.0130, 0.0718, 0.0342, 0.0352, 0.0041, 0.0039, 0.0077, 0.0062,
        0.0130, 0.0167, 0.0149, 0.1206, 0.2943, 0.1300, 0.0369, 0.0139, 0.0418,
        0.0358], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:38,479][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0372, 0.0665, 0.0212, 0.0325, 0.0327, 0.0450, 0.0367, 0.3196, 0.0761,
        0.0210, 0.0166, 0.0292, 0.0119, 0.1014, 0.0151, 0.0650, 0.0276, 0.0183,
        0.0264], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:38,481][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.1330, 0.0888, 0.0822, 0.0391, 0.0342, 0.0344, 0.0673, 0.0527, 0.0244,
        0.0213, 0.0352, 0.0927, 0.0349, 0.0392, 0.0636, 0.0270, 0.0500, 0.0286,
        0.0516], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:38,483][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0042, 0.0392, 0.0074, 0.0833, 0.0382, 0.0341, 0.0830, 0.0297, 0.0764,
        0.0168, 0.0434, 0.1092, 0.0366, 0.1630, 0.0278, 0.0437, 0.0829, 0.0726,
        0.0087], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:38,485][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0047, 0.0586, 0.0761, 0.0426, 0.0616, 0.0570, 0.0407, 0.0595, 0.0259,
        0.0739, 0.0552, 0.0384, 0.0650, 0.0236, 0.0700, 0.0738, 0.0375, 0.0992,
        0.0366], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:38,487][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0064, 0.0309, 0.0019, 0.1600, 0.0048, 0.1376, 0.0682, 0.0709, 0.0306,
        0.0277, 0.0574, 0.0363, 0.0333, 0.0912, 0.0012, 0.0507, 0.0375, 0.0185,
        0.1349], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:38,516][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:21:38,518][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:38,519][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:38,520][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:38,521][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:38,522][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:38,523][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:38,523][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:38,524][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:38,525][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:38,525][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:38,526][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:38,527][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:38,527][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.8257, 0.1743], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:38,528][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.8139, 0.1861], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:38,529][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.9952, 0.0048], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:38,529][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.4928, 0.5072], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:38,530][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.8987, 0.1013], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:38,531][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.7937, 0.2063], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:38,532][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.2429, 0.7571], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:38,534][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.9771, 0.0229], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:38,536][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.6265, 0.3735], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:38,537][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([9.9968e-01, 3.1934e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:38,537][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.2184, 0.7816], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:38,539][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.1978, 0.8022], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:38,541][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Anthony] are: tensor([0.0105, 0.1531, 0.8364], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:38,542][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Anthony] are: tensor([0.9136, 0.0698, 0.0166], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:38,544][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Anthony] are: tensor([0.8513, 0.0397, 0.1090], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:38,545][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Anthony] are: tensor([0.3698, 0.3716, 0.2586], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:38,547][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Anthony] are: tensor([0.6138, 0.2026, 0.1836], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:38,549][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Anthony] are: tensor([0.3278, 0.4958, 0.1765], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:38,550][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Anthony] are: tensor([0.2162, 0.3346, 0.4492], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:38,552][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Anthony] are: tensor([0.6300, 0.1375, 0.2324], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:38,554][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Anthony] are: tensor([0.3841, 0.2357, 0.3802], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:38,555][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Anthony] are: tensor([1.1602e-01, 1.2883e-04, 8.8385e-01], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:38,556][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Anthony] are: tensor([0.1319, 0.4138, 0.4542], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:38,558][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Anthony] are: tensor([0.1287, 0.8382, 0.0332], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:38,560][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0242, 0.0732, 0.8796, 0.0229], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:38,561][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.2502, 0.3809, 0.2634, 0.1055], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:38,563][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.4381, 0.0257, 0.0858, 0.4503], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:38,564][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.2829, 0.2611, 0.1732, 0.2828], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:38,566][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.4211, 0.1138, 0.2209, 0.2442], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:38,567][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.3258, 0.4502, 0.0236, 0.2004], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:38,569][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0482, 0.1306, 0.3260, 0.4952], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:38,571][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.4201, 0.0618, 0.3147, 0.2034], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:38,572][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.3483, 0.2139, 0.3469, 0.0909], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:38,574][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([1.1974e-01, 8.2141e-05, 8.7027e-01, 9.9031e-03], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:38,575][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0934, 0.3030, 0.3512, 0.2524], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:38,577][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0579, 0.1363, 0.0015, 0.8043], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:38,578][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Travis] are: tensor([0.0046, 0.0255, 0.6407, 0.0264, 0.3027], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:38,580][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Travis] are: tensor([0.9183, 0.0282, 0.0115, 0.0261, 0.0159], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:38,582][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Travis] are: tensor([0.3727, 0.0320, 0.0731, 0.4109, 0.1114], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:38,583][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Travis] are: tensor([0.2241, 0.2088, 0.1412, 0.2349, 0.1911], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:38,583][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Travis] are: tensor([0.3577, 0.2030, 0.1139, 0.2321, 0.0932], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:38,584][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Travis] are: tensor([0.0565, 0.0346, 0.7750, 0.1282, 0.0057], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:38,585][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Travis] are: tensor([0.1082, 0.1590, 0.1709, 0.4203, 0.1417], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:38,586][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Travis] are: tensor([0.4627, 0.1343, 0.1636, 0.2092, 0.0301], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:38,588][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Travis] are: tensor([0.3074, 0.1949, 0.2977, 0.0666, 0.1334], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:38,589][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Travis] are: tensor([5.0499e-02, 1.1464e-04, 9.4366e-01, 4.9273e-03, 7.9461e-04],
       device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:38,591][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Travis] are: tensor([0.0786, 0.2331, 0.2602, 0.1955, 0.2326], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:38,592][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Travis] are: tensor([0.0461, 0.1557, 0.0012, 0.7850, 0.0120], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:38,594][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.1405, 0.0690, 0.1877, 0.0693, 0.4095, 0.1240], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:38,596][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.2500, 0.1964, 0.2091, 0.1609, 0.0386, 0.1451], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:38,597][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.2521, 0.0237, 0.0685, 0.2487, 0.1112, 0.2958], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:38,599][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.1909, 0.1687, 0.1114, 0.1905, 0.1537, 0.1848], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:38,600][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.2654, 0.1139, 0.1289, 0.1725, 0.1077, 0.2117], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:38,602][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.2074, 0.5394, 0.0649, 0.0541, 0.0367, 0.0974], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:38,604][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.0316, 0.0861, 0.2193, 0.3266, 0.1941, 0.1423], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:38,606][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.3907, 0.0578, 0.1523, 0.1306, 0.1345, 0.1342], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:38,607][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.2891, 0.1775, 0.2697, 0.0655, 0.1181, 0.0802], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:38,608][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([6.6646e-02, 1.0214e-04, 9.1494e-01, 2.5416e-03, 2.5405e-03, 1.3234e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:38,610][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.0550, 0.1917, 0.2225, 0.1555, 0.2005, 0.1747], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:38,612][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.0360, 0.1849, 0.0019, 0.5772, 0.0008, 0.1992], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:38,613][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0084, 0.0243, 0.1021, 0.0205, 0.2798, 0.4976, 0.0672],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:38,615][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0813, 0.1164, 0.2029, 0.1537, 0.0333, 0.3337, 0.0786],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:38,616][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.1888, 0.0190, 0.0497, 0.1736, 0.0771, 0.1840, 0.3079],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:38,618][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.1643, 0.1443, 0.0931, 0.1645, 0.1330, 0.1616, 0.1390],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:38,620][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.2112, 0.0892, 0.0931, 0.1523, 0.0842, 0.1730, 0.1969],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:38,621][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.2835, 0.4099, 0.0331, 0.0827, 0.0152, 0.0641, 0.1114],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:38,623][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0235, 0.0786, 0.2056, 0.3148, 0.1780, 0.1250, 0.0745],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:38,625][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.2962, 0.0612, 0.1539, 0.1136, 0.1181, 0.1369, 0.1202],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:38,626][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.2787, 0.1580, 0.2357, 0.0584, 0.1029, 0.0695, 0.0969],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:38,627][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([8.0634e-02, 6.3676e-05, 4.6389e-01, 3.0088e-03, 1.9660e-03, 3.8756e-03,
        4.4656e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:38,629][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0503, 0.1626, 0.1899, 0.1353, 0.1776, 0.1505, 0.1338],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:38,630][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([3.2788e-02, 1.0836e-01, 1.8613e-03, 3.8908e-01, 4.4326e-04, 1.3696e-02,
        4.5377e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:38,632][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ lot] are: tensor([0.0057, 0.0028, 0.0738, 0.0028, 0.0801, 0.0112, 0.7888, 0.0347],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:38,633][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ lot] are: tensor([0.8258, 0.0354, 0.0163, 0.0217, 0.0148, 0.0605, 0.0224, 0.0031],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:38,635][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ lot] are: tensor([0.1517, 0.0178, 0.0406, 0.1519, 0.0696, 0.1604, 0.2668, 0.1414],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:38,637][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ lot] are: tensor([0.1328, 0.1211, 0.0815, 0.1394, 0.1155, 0.1370, 0.1182, 0.1545],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:38,638][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ lot] are: tensor([0.1949, 0.0869, 0.0740, 0.1403, 0.0802, 0.1408, 0.1708, 0.1121],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:38,640][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ lot] are: tensor([0.1566, 0.4241, 0.0092, 0.0764, 0.0067, 0.0327, 0.1253, 0.1691],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:38,642][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ lot] are: tensor([0.0268, 0.0806, 0.1483, 0.2942, 0.1323, 0.1337, 0.0793, 0.1049],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:38,643][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ lot] are: tensor([0.4416, 0.0465, 0.0941, 0.0934, 0.0780, 0.1304, 0.0835, 0.0326],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:38,644][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ lot] are: tensor([0.2279, 0.1322, 0.2150, 0.0481, 0.0901, 0.0606, 0.0828, 0.1434],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:38,645][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ lot] are: tensor([6.9823e-02, 3.3252e-05, 3.9829e-01, 1.6449e-03, 3.1767e-03, 2.7643e-03,
        3.9082e-01, 1.3345e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:38,646][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ lot] are: tensor([0.0446, 0.1392, 0.1673, 0.1146, 0.1528, 0.1264, 0.1138, 0.1413],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:38,646][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ lot] are: tensor([3.6853e-02, 1.6314e-01, 7.3704e-04, 5.8476e-01, 3.5122e-04, 2.2037e-02,
        4.9429e-02, 1.4270e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:38,648][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([2.1425e-04, 7.2383e-04, 4.0882e-02, 1.0146e-03, 5.7693e-02, 2.7245e-03,
        8.4309e-02, 8.1233e-01, 1.0721e-04], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:38,649][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([0.2189, 0.1373, 0.0946, 0.0703, 0.0290, 0.2224, 0.1322, 0.0383, 0.0570],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:38,651][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([0.1126, 0.0146, 0.0365, 0.1131, 0.0588, 0.1286, 0.1920, 0.0904, 0.2533],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:38,652][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([0.1197, 0.1042, 0.0668, 0.1252, 0.0987, 0.1250, 0.1097, 0.1386, 0.1122],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:38,654][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([0.1481, 0.0787, 0.0788, 0.1247, 0.0841, 0.1380, 0.1490, 0.0633, 0.1354],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:38,655][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([3.4137e-02, 4.1723e-03, 1.2491e-03, 5.4467e-03, 6.2885e-04, 2.2139e-03,
        4.4273e-02, 6.8879e-03, 9.0099e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:38,656][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([0.0152, 0.0579, 0.1712, 0.2345, 0.1504, 0.0997, 0.0566, 0.0846, 0.1299],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:38,658][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([0.2619, 0.0884, 0.1323, 0.1061, 0.1155, 0.0864, 0.0810, 0.0383, 0.0900],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:38,660][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([0.2314, 0.1309, 0.1944, 0.0476, 0.0856, 0.0572, 0.0785, 0.1272, 0.0473],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:38,661][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([1.7665e-02, 3.6503e-05, 3.3589e-01, 1.9147e-03, 6.8559e-04, 1.0108e-03,
        3.4177e-01, 5.6964e-02, 2.4406e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:38,663][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([0.0390, 0.1268, 0.1500, 0.1048, 0.1394, 0.1182, 0.1012, 0.1316, 0.0890],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:38,664][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([1.2281e-02, 4.6040e-02, 4.7634e-04, 2.2774e-01, 1.9345e-04, 6.9909e-03,
        2.6259e-02, 1.9222e-03, 6.7809e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:38,665][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ fun] are: tensor([0.0005, 0.0024, 0.0825, 0.0048, 0.0642, 0.0952, 0.1872, 0.5223, 0.0023,
        0.0386], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:38,667][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ fun] are: tensor([0.2043, 0.0897, 0.1967, 0.1183, 0.0573, 0.0563, 0.0526, 0.1003, 0.0908,
        0.0337], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:38,669][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ fun] are: tensor([0.0815, 0.0135, 0.0300, 0.1076, 0.0480, 0.1099, 0.1644, 0.0832, 0.2482,
        0.1137], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:38,670][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ fun] are: tensor([0.1079, 0.0945, 0.0609, 0.1153, 0.0900, 0.1138, 0.1010, 0.1264, 0.1039,
        0.0863], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:38,672][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ fun] are: tensor([0.1638, 0.0768, 0.0519, 0.1222, 0.0519, 0.1092, 0.1207, 0.0819, 0.1327,
        0.0889], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:38,674][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ fun] are: tensor([0.1368, 0.2187, 0.0542, 0.0752, 0.0054, 0.0328, 0.2022, 0.1347, 0.0438,
        0.0963], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:38,675][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ fun] are: tensor([0.0333, 0.0670, 0.0849, 0.1945, 0.0728, 0.0931, 0.0598, 0.0756, 0.1547,
        0.1644], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:38,677][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ fun] are: tensor([0.2704, 0.0587, 0.0863, 0.0813, 0.0751, 0.1914, 0.0759, 0.0798, 0.0669,
        0.0143], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:38,679][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ fun] are: tensor([0.2007, 0.1191, 0.1896, 0.0440, 0.0839, 0.0559, 0.0755, 0.1269, 0.0477,
        0.0567], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:38,680][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ fun] are: tensor([2.0979e-02, 9.6767e-06, 5.0049e-01, 8.6340e-04, 4.0113e-04, 1.5938e-03,
        2.1750e-01, 1.2778e-01, 1.3023e-01, 1.5530e-04], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:38,682][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ fun] are: tensor([0.0363, 0.1134, 0.1307, 0.0930, 0.1189, 0.1022, 0.0908, 0.1120, 0.0765,
        0.1262], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:38,683][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ fun] are: tensor([1.6911e-02, 7.1721e-02, 2.0266e-04, 2.8430e-01, 1.2750e-04, 6.7224e-03,
        2.0185e-02, 4.6556e-03, 5.8311e-01, 1.2067e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:38,685][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.0053, 0.0203, 0.0855, 0.0157, 0.1115, 0.0505, 0.0700, 0.5874, 0.0071,
        0.0394, 0.0075], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:38,687][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.0342, 0.0570, 0.2423, 0.0866, 0.0363, 0.1067, 0.0630, 0.1189, 0.1650,
        0.0539, 0.0361], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:38,688][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.0693, 0.0107, 0.0275, 0.0714, 0.0432, 0.0833, 0.1221, 0.0633, 0.1573,
        0.0811, 0.2708], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:38,690][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.0961, 0.0768, 0.0507, 0.0966, 0.0779, 0.0997, 0.0901, 0.1108, 0.0936,
        0.0782, 0.1294], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:38,692][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.1180, 0.0541, 0.0549, 0.0881, 0.0569, 0.1074, 0.1080, 0.0703, 0.1057,
        0.0827, 0.1540], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:38,693][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([1.8957e-02, 9.8941e-03, 6.3301e-04, 5.5482e-03, 1.9757e-03, 1.5918e-03,
        4.7341e-02, 1.1537e-02, 9.2410e-03, 7.2983e-03, 8.8598e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:38,694][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.0102, 0.0410, 0.1171, 0.1697, 0.1009, 0.0704, 0.0389, 0.0580, 0.0941,
        0.2139, 0.0857], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:38,696][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.1631, 0.0313, 0.1049, 0.0826, 0.1578, 0.1783, 0.0558, 0.0380, 0.0583,
        0.0661, 0.0639], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:38,698][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.2058, 0.1180, 0.1692, 0.0434, 0.0770, 0.0529, 0.0722, 0.1138, 0.0434,
        0.0510, 0.0533], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:38,699][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([1.9697e-02, 1.6606e-05, 3.8451e-01, 1.0848e-03, 1.3739e-03, 1.4022e-03,
        3.7624e-01, 8.6060e-02, 1.2914e-01, 3.9497e-04, 6.8301e-05],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:38,701][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.0321, 0.1007, 0.1189, 0.0835, 0.1096, 0.0924, 0.0802, 0.1052, 0.0688,
        0.1176, 0.0910], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:38,703][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.0155, 0.0782, 0.0009, 0.2863, 0.0005, 0.0099, 0.0128, 0.0035, 0.3886,
        0.0013, 0.2025], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:38,704][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0060, 0.0137, 0.1342, 0.0162, 0.1754, 0.0987, 0.1393, 0.2525, 0.0131,
        0.0292, 0.0977, 0.0240], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:38,706][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0228, 0.0514, 0.0888, 0.0675, 0.0228, 0.2010, 0.0768, 0.0794, 0.2096,
        0.0497, 0.0907, 0.0394], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:38,708][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0539, 0.0093, 0.0238, 0.0566, 0.0362, 0.0661, 0.1006, 0.0568, 0.1208,
        0.0729, 0.2003, 0.2027], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:38,710][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0849, 0.0677, 0.0444, 0.0846, 0.0685, 0.0878, 0.0792, 0.0973, 0.0826,
        0.0693, 0.1147, 0.1190], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:38,711][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.1035, 0.0497, 0.0510, 0.0759, 0.0498, 0.0849, 0.0994, 0.0678, 0.0833,
        0.0769, 0.1232, 0.1345], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:38,712][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.0901, 0.2526, 0.0455, 0.0255, 0.0233, 0.0247, 0.0863, 0.1117, 0.1221,
        0.0334, 0.1194, 0.0654], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:38,713][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0096, 0.0383, 0.1119, 0.1564, 0.0991, 0.0634, 0.0355, 0.0559, 0.0852,
        0.2023, 0.0783, 0.0640], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:38,714][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.1363, 0.0243, 0.1010, 0.0653, 0.0939, 0.1246, 0.0694, 0.0294, 0.0540,
        0.0692, 0.0688, 0.1638], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:38,714][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.1861, 0.1079, 0.1598, 0.0394, 0.0702, 0.0488, 0.0656, 0.1058, 0.0396,
        0.0463, 0.0491, 0.0815], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:38,715][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([2.8717e-02, 1.3712e-05, 2.9406e-01, 1.3837e-03, 5.8101e-04, 1.3760e-03,
        2.4412e-01, 2.5771e-01, 1.4979e-01, 5.2864e-04, 1.0561e-04, 2.1616e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:38,717][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0296, 0.0923, 0.1093, 0.0768, 0.1024, 0.0862, 0.0758, 0.0966, 0.0630,
        0.1091, 0.0824, 0.0765], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:38,718][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([3.0998e-02, 7.4165e-02, 6.1544e-04, 2.6246e-01, 2.9013e-04, 6.9017e-03,
        3.8076e-02, 3.6113e-03, 4.2770e-01, 1.9367e-03, 1.1689e-02, 1.4155e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:38,720][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ hospital] are: tensor([0.0013, 0.0107, 0.2427, 0.0059, 0.3791, 0.0222, 0.0946, 0.0309, 0.0051,
        0.0350, 0.0547, 0.0251, 0.0927], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:38,722][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ hospital] are: tensor([0.1703, 0.0295, 0.0392, 0.0370, 0.0922, 0.0348, 0.0777, 0.0999, 0.0527,
        0.0655, 0.2162, 0.0762, 0.0088], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:38,723][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ hospital] are: tensor([0.0495, 0.0107, 0.0231, 0.0608, 0.0325, 0.0684, 0.0911, 0.0492, 0.1187,
        0.0668, 0.1808, 0.1574, 0.0912], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:38,725][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ hospital] are: tensor([0.0703, 0.0593, 0.0398, 0.0774, 0.0635, 0.0813, 0.0745, 0.0883, 0.0785,
        0.0662, 0.1078, 0.1095, 0.0836], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:38,727][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ hospital] are: tensor([0.1133, 0.0567, 0.0631, 0.0752, 0.0566, 0.0848, 0.0777, 0.0492, 0.0777,
        0.0622, 0.0963, 0.0982, 0.0889], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:38,728][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ hospital] are: tensor([0.0901, 0.1397, 0.0113, 0.0251, 0.0112, 0.0212, 0.1611, 0.0479, 0.0285,
        0.0180, 0.1075, 0.1974, 0.1408], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:38,730][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ hospital] are: tensor([0.0224, 0.0458, 0.0579, 0.1305, 0.0527, 0.0680, 0.0412, 0.0518, 0.1031,
        0.1205, 0.1067, 0.0736, 0.1255], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:38,732][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ hospital] are: tensor([0.1533, 0.0136, 0.0674, 0.0451, 0.0526, 0.1172, 0.0842, 0.0678, 0.0498,
        0.1930, 0.0393, 0.1071, 0.0097], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:38,734][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ hospital] are: tensor([0.1735, 0.1006, 0.1453, 0.0360, 0.0659, 0.0458, 0.0631, 0.1023, 0.0375,
        0.0447, 0.0474, 0.0791, 0.0587], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:38,735][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ hospital] are: tensor([1.9493e-02, 1.1457e-05, 3.2692e-01, 9.8226e-04, 3.0121e-04, 1.3188e-03,
        3.1688e-01, 1.2287e-01, 1.8618e-01, 1.8177e-04, 8.9625e-05, 1.3703e-02,
        1.1067e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:38,737][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ hospital] are: tensor([0.0281, 0.0868, 0.0978, 0.0721, 0.0896, 0.0789, 0.0692, 0.0858, 0.0592,
        0.0971, 0.0760, 0.0681, 0.0912], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:38,738][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ hospital] are: tensor([2.6943e-02, 9.0391e-02, 4.2924e-04, 3.1436e-01, 2.5581e-04, 1.1613e-02,
        1.3117e-02, 3.1870e-03, 4.9559e-01, 1.1730e-03, 2.0293e-02, 1.8153e-02,
        4.4975e-03], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:38,740][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.0044, 0.0083, 0.2133, 0.0086, 0.4466, 0.0129, 0.0669, 0.1017, 0.0053,
        0.0435, 0.0243, 0.0184, 0.0336, 0.0125], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:38,741][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.4528, 0.0942, 0.0423, 0.0253, 0.0256, 0.0569, 0.0413, 0.0143, 0.0275,
        0.0433, 0.0999, 0.0347, 0.0368, 0.0050], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:38,743][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.0361, 0.0061, 0.0179, 0.0356, 0.0260, 0.0491, 0.0645, 0.0406, 0.0811,
        0.0555, 0.1283, 0.1275, 0.0948, 0.2368], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:38,745][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.0761, 0.0635, 0.0385, 0.0781, 0.0573, 0.0779, 0.0699, 0.0850, 0.0720,
        0.0581, 0.1012, 0.1037, 0.0754, 0.0434], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:38,747][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.0862, 0.0453, 0.0507, 0.0546, 0.0423, 0.0662, 0.0660, 0.0597, 0.0618,
        0.0602, 0.0882, 0.0827, 0.1000, 0.1362], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:38,748][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.1532, 0.0628, 0.0354, 0.0389, 0.0214, 0.0345, 0.0883, 0.0569, 0.0348,
        0.0437, 0.0398, 0.1251, 0.0523, 0.2130], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:38,750][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.0088, 0.0279, 0.0764, 0.1051, 0.0691, 0.0479, 0.0267, 0.0375, 0.0586,
        0.1255, 0.0563, 0.0479, 0.1601, 0.1524], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:38,752][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.1052, 0.0126, 0.0970, 0.0491, 0.0533, 0.0559, 0.0315, 0.0334, 0.0479,
        0.0662, 0.0436, 0.0714, 0.2417, 0.0912], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:38,754][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.1511, 0.0943, 0.1375, 0.0364, 0.0626, 0.0456, 0.0619, 0.0985, 0.0375,
        0.0432, 0.0472, 0.0784, 0.0567, 0.0492], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:38,755][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([4.5330e-02, 1.2032e-05, 3.8321e-01, 2.7964e-03, 5.4447e-04, 1.7471e-04,
        7.6603e-02, 3.0946e-01, 1.5069e-01, 6.7167e-04, 5.0154e-05, 6.5451e-03,
        2.3278e-02, 6.3702e-04], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:38,757][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.0250, 0.0798, 0.0931, 0.0658, 0.0863, 0.0733, 0.0638, 0.0819, 0.0542,
        0.0932, 0.0717, 0.0634, 0.0911, 0.0575], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:38,758][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.0279, 0.0585, 0.0011, 0.2107, 0.0006, 0.0116, 0.0239, 0.0041, 0.2546,
        0.0030, 0.0260, 0.0434, 0.0013, 0.3332], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:38,760][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Anthony] are: tensor([0.0009, 0.0121, 0.0700, 0.0049, 0.5427, 0.0403, 0.0387, 0.0618, 0.0057,
        0.0416, 0.0181, 0.0293, 0.0635, 0.0334, 0.0370], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:38,762][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Anthony] are: tensor([0.5150, 0.0397, 0.0055, 0.0285, 0.0195, 0.0446, 0.0577, 0.0065, 0.0203,
        0.0542, 0.1063, 0.0488, 0.0347, 0.0172, 0.0015], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:38,764][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Anthony] are: tensor([0.0292, 0.0078, 0.0149, 0.0383, 0.0226, 0.0480, 0.0583, 0.0334, 0.0733,
        0.0446, 0.1235, 0.1066, 0.0771, 0.1841, 0.1383], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:38,766][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Anthony] are: tensor([0.0712, 0.0582, 0.0350, 0.0755, 0.0549, 0.0766, 0.0691, 0.0828, 0.0733,
        0.0591, 0.1015, 0.1017, 0.0719, 0.0437, 0.0254], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:38,767][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Anthony] are: tensor([0.0680, 0.0690, 0.0359, 0.0749, 0.0456, 0.0791, 0.0747, 0.0375, 0.0598,
        0.0452, 0.0746, 0.0824, 0.0527, 0.1484, 0.0523], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:38,769][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Anthony] are: tensor([0.0093, 0.0215, 0.0570, 0.0165, 0.1213, 0.0048, 0.0235, 0.0093, 0.0045,
        0.0084, 0.0229, 0.0257, 0.0067, 0.1590, 0.5096], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:38,771][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Anthony] are: tensor([0.0181, 0.0336, 0.0469, 0.1070, 0.0403, 0.0530, 0.0345, 0.0404, 0.0814,
        0.0866, 0.0831, 0.0611, 0.0934, 0.1326, 0.0880], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:38,773][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Anthony] are: tensor([0.0339, 0.0211, 0.0177, 0.0249, 0.0387, 0.0594, 0.0260, 0.0855, 0.0368,
        0.0727, 0.0256, 0.0998, 0.1429, 0.2974, 0.0176], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:38,774][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Anthony] are: tensor([0.1492, 0.0942, 0.1262, 0.0309, 0.0552, 0.0419, 0.0574, 0.0919, 0.0341,
        0.0398, 0.0434, 0.0745, 0.0522, 0.0438, 0.0651], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:38,775][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Anthony] are: tensor([1.3317e-02, 1.5401e-05, 1.0651e-01, 9.1944e-04, 3.1113e-04, 1.4150e-03,
        3.1767e-01, 4.1976e-02, 2.1362e-01, 1.1725e-04, 1.4027e-04, 1.3260e-02,
        7.1942e-03, 8.1159e-04, 2.8272e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:38,776][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Anthony] are: tensor([0.0249, 0.0751, 0.0841, 0.0624, 0.0771, 0.0671, 0.0599, 0.0735, 0.0504,
        0.0824, 0.0650, 0.0593, 0.0810, 0.0527, 0.0850], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:38,777][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Anthony] are: tensor([5.7379e-03, 3.5524e-02, 1.2745e-03, 1.4986e-01, 9.9387e-05, 3.0439e-03,
        6.5958e-03, 6.2156e-04, 2.6938e-01, 3.2232e-04, 5.0997e-03, 5.0650e-03,
        1.8110e-04, 5.1638e-01, 8.1856e-04], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:38,778][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.0067, 0.0188, 0.0992, 0.0119, 0.2026, 0.0494, 0.0854, 0.1928, 0.0060,
        0.0472, 0.0477, 0.0279, 0.0627, 0.0390, 0.0608, 0.0422],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:38,780][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0194, 0.0442, 0.0789, 0.0411, 0.0093, 0.0592, 0.0305, 0.1029, 0.0688,
        0.0252, 0.0500, 0.0372, 0.0200, 0.1870, 0.1479, 0.0783],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:38,782][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.0248, 0.0064, 0.0150, 0.0294, 0.0211, 0.0346, 0.0454, 0.0278, 0.0624,
        0.0391, 0.0987, 0.0852, 0.0710, 0.1631, 0.1505, 0.1256],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:38,783][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.0722, 0.0586, 0.0350, 0.0741, 0.0543, 0.0741, 0.0660, 0.0800, 0.0684,
        0.0549, 0.0945, 0.0953, 0.0681, 0.0408, 0.0237, 0.0399],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:38,785][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.0739, 0.0464, 0.0369, 0.0647, 0.0364, 0.0587, 0.0609, 0.0299, 0.0634,
        0.0386, 0.0812, 0.0722, 0.0557, 0.1471, 0.0578, 0.0763],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:38,787][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.0833, 0.0674, 0.0364, 0.0223, 0.0123, 0.0544, 0.1287, 0.0254, 0.0416,
        0.0163, 0.0410, 0.1107, 0.0571, 0.2313, 0.0281, 0.0438],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:38,789][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.0092, 0.0220, 0.0525, 0.0813, 0.0478, 0.0394, 0.0228, 0.0302, 0.0531,
        0.0892, 0.0524, 0.0417, 0.1187, 0.1246, 0.1086, 0.1065],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:38,790][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0856, 0.0383, 0.0649, 0.0527, 0.0462, 0.0465, 0.0474, 0.0293, 0.0482,
        0.0691, 0.0490, 0.0888, 0.1052, 0.1708, 0.0443, 0.0136],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:38,792][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.1393, 0.0847, 0.1195, 0.0319, 0.0556, 0.0405, 0.0570, 0.0879, 0.0333,
        0.0382, 0.0424, 0.0726, 0.0515, 0.0446, 0.0639, 0.0371],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:38,793][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([7.0277e-03, 8.9961e-06, 9.8483e-02, 3.3832e-04, 1.8503e-04, 8.6637e-04,
        4.7623e-01, 2.3419e-02, 9.7492e-02, 6.1410e-05, 1.5661e-04, 3.6100e-02,
        5.7934e-03, 3.1871e-04, 2.5346e-01, 6.6610e-05], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:38,795][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0206, 0.0678, 0.0797, 0.0558, 0.0727, 0.0622, 0.0534, 0.0692, 0.0462,
        0.0775, 0.0609, 0.0532, 0.0755, 0.0485, 0.0810, 0.0757],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:38,797][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([1.5029e-02, 5.1004e-02, 3.3140e-04, 1.8533e-01, 1.3801e-04, 9.4502e-03,
        1.1147e-02, 2.1657e-03, 2.4869e-01, 1.6078e-03, 5.3172e-03, 7.4782e-03,
        3.1053e-04, 4.5249e-01, 2.5452e-04, 9.2515e-03], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:38,798][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0032, 0.0089, 0.0375, 0.0078, 0.1016, 0.1893, 0.0269, 0.3408, 0.0074,
        0.0202, 0.0303, 0.0332, 0.0166, 0.0161, 0.0249, 0.1082, 0.0271],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:38,800][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0068, 0.0408, 0.0541, 0.0410, 0.0058, 0.0686, 0.0162, 0.0559, 0.1055,
        0.0218, 0.0384, 0.0404, 0.0129, 0.1146, 0.1362, 0.1946, 0.0463],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:38,802][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0203, 0.0062, 0.0138, 0.0223, 0.0181, 0.0295, 0.0422, 0.0258, 0.0465,
        0.0353, 0.0773, 0.0744, 0.0672, 0.1275, 0.1278, 0.1077, 0.1582],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:38,804][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0703, 0.0533, 0.0329, 0.0677, 0.0521, 0.0694, 0.0615, 0.0762, 0.0639,
        0.0525, 0.0885, 0.0902, 0.0665, 0.0395, 0.0235, 0.0392, 0.0528],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:38,806][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0628, 0.0395, 0.0282, 0.0529, 0.0259, 0.0527, 0.0637, 0.0375, 0.0547,
        0.0446, 0.0709, 0.0796, 0.0602, 0.1242, 0.0501, 0.0735, 0.0789],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:38,807][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0493, 0.0849, 0.0091, 0.0175, 0.0047, 0.0359, 0.0447, 0.0404, 0.0633,
        0.0340, 0.0622, 0.0877, 0.1607, 0.1645, 0.0100, 0.0901, 0.0411],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:38,809][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0053, 0.0198, 0.0604, 0.0799, 0.0529, 0.0329, 0.0187, 0.0291, 0.0440,
        0.1034, 0.0409, 0.0343, 0.1247, 0.1188, 0.1080, 0.0907, 0.0364],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:38,811][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0804, 0.0260, 0.0535, 0.0377, 0.0425, 0.0513, 0.0382, 0.0314, 0.0408,
        0.0369, 0.0406, 0.0814, 0.1472, 0.1707, 0.0318, 0.0346, 0.0551],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:38,813][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.1402, 0.0818, 0.1191, 0.0301, 0.0537, 0.0385, 0.0532, 0.0828, 0.0309,
        0.0359, 0.0391, 0.0671, 0.0487, 0.0412, 0.0601, 0.0351, 0.0426],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:38,814][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([1.8663e-02, 1.4311e-05, 1.2929e-01, 6.9004e-04, 4.6265e-04, 9.3998e-04,
        1.2965e-01, 7.0720e-02, 9.2518e-02, 2.4309e-04, 1.6930e-04, 1.3888e-02,
        8.0248e-03, 5.4725e-04, 3.2799e-01, 9.6079e-05, 2.0610e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:38,816][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0203, 0.0627, 0.0741, 0.0523, 0.0693, 0.0585, 0.0517, 0.0664, 0.0431,
        0.0740, 0.0559, 0.0510, 0.0725, 0.0455, 0.0763, 0.0724, 0.0540],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:38,817][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([1.0819e-02, 3.7862e-02, 5.6854e-04, 1.3729e-01, 1.4823e-04, 4.4098e-03,
        1.3606e-01, 2.4216e-03, 2.5685e-01, 1.2005e-03, 7.1938e-03, 2.4869e-02,
        3.2909e-04, 3.0104e-01, 4.1240e-04, 7.3633e-04, 7.7790e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:38,818][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ drink] are: tensor([2.8819e-04, 1.2727e-03, 2.9905e-02, 1.4730e-03, 6.6409e-02, 4.2171e-02,
        5.6193e-02, 1.6529e-01, 1.1256e-03, 6.7496e-02, 3.9049e-03, 1.1504e-02,
        4.8649e-02, 7.9272e-03, 2.1298e-02, 3.8828e-01, 6.5593e-02, 2.1218e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:38,820][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ drink] are: tensor([0.1732, 0.0258, 0.0438, 0.0312, 0.0333, 0.0498, 0.0509, 0.0187, 0.0253,
        0.0453, 0.0970, 0.0374, 0.0369, 0.0395, 0.0284, 0.1226, 0.1307, 0.0102],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:38,822][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ drink] are: tensor([0.0191, 0.0052, 0.0116, 0.0222, 0.0164, 0.0283, 0.0367, 0.0214, 0.0475,
        0.0335, 0.0737, 0.0667, 0.0565, 0.1283, 0.1095, 0.0977, 0.1320, 0.0937],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:38,824][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ drink] are: tensor([0.0624, 0.0466, 0.0291, 0.0631, 0.0485, 0.0656, 0.0590, 0.0716, 0.0632,
        0.0516, 0.0872, 0.0878, 0.0643, 0.0396, 0.0236, 0.0398, 0.0530, 0.0441],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:38,825][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ drink] are: tensor([0.0658, 0.0430, 0.0298, 0.0537, 0.0347, 0.0534, 0.0547, 0.0287, 0.0530,
        0.0399, 0.0693, 0.0668, 0.0492, 0.1211, 0.0511, 0.0648, 0.0676, 0.0533],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:38,827][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ drink] are: tensor([0.0700, 0.0946, 0.0028, 0.0086, 0.0020, 0.0061, 0.1042, 0.0224, 0.0122,
        0.0134, 0.0200, 0.1243, 0.1184, 0.1954, 0.0021, 0.0184, 0.1374, 0.0478],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:38,829][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ drink] are: tensor([0.0119, 0.0252, 0.0373, 0.0786, 0.0348, 0.0413, 0.0253, 0.0311, 0.0644,
        0.0761, 0.0661, 0.0461, 0.0839, 0.1012, 0.0735, 0.0920, 0.0445, 0.0668],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:38,831][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ drink] are: tensor([0.0642, 0.0257, 0.0604, 0.0248, 0.0423, 0.0292, 0.0524, 0.0395, 0.0289,
        0.0348, 0.0399, 0.0734, 0.2230, 0.1076, 0.0331, 0.0294, 0.0701, 0.0213],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:38,833][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ drink] are: tensor([0.1293, 0.0779, 0.1154, 0.0280, 0.0533, 0.0372, 0.0509, 0.0830, 0.0301,
        0.0365, 0.0385, 0.0656, 0.0480, 0.0392, 0.0593, 0.0353, 0.0425, 0.0299],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:38,834][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ drink] are: tensor([2.8689e-03, 3.8431e-06, 1.6155e-01, 1.9535e-04, 9.4079e-05, 9.5991e-04,
        8.7085e-02, 2.4902e-02, 5.2817e-02, 1.5650e-04, 1.5560e-05, 3.4984e-03,
        1.2589e-02, 2.5100e-04, 5.1694e-01, 5.6107e-05, 1.3602e-01, 3.4347e-10],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:38,836][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ drink] are: tensor([0.0200, 0.0599, 0.0684, 0.0492, 0.0626, 0.0542, 0.0472, 0.0584, 0.0398,
        0.0672, 0.0512, 0.0469, 0.0648, 0.0421, 0.0689, 0.0661, 0.0486, 0.0846],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:38,836][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ drink] are: tensor([7.8413e-03, 4.5276e-02, 1.1278e-04, 1.5870e-01, 5.2333e-05, 3.4958e-03,
        6.5240e-03, 1.9371e-03, 2.6756e-01, 1.3137e-03, 5.1983e-03, 7.8209e-03,
        2.9848e-04, 4.8929e-01, 9.4761e-05, 5.0944e-04, 3.5010e-03, 4.6513e-04],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:38,837][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([2.7863e-03, 3.8690e-03, 1.3702e-02, 1.8254e-03, 7.0867e-02, 1.0684e-01,
        3.2625e-02, 1.1332e-01, 5.0090e-03, 4.3281e-02, 2.7541e-02, 9.5031e-03,
        2.4705e-02, 7.0632e-03, 9.4501e-03, 3.1237e-01, 3.3459e-02, 1.8164e-01,
        1.5217e-04], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:38,838][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0081, 0.0496, 0.0546, 0.0409, 0.0062, 0.0844, 0.0398, 0.0559, 0.0676,
        0.0165, 0.0388, 0.0334, 0.0127, 0.0901, 0.0953, 0.1619, 0.1001, 0.0217,
        0.0225], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:38,840][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0125, 0.0046, 0.0116, 0.0144, 0.0154, 0.0217, 0.0265, 0.0174, 0.0331,
        0.0257, 0.0540, 0.0514, 0.0545, 0.0923, 0.1096, 0.0928, 0.1086, 0.0961,
        0.1579], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:38,842][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0585, 0.0454, 0.0281, 0.0588, 0.0451, 0.0612, 0.0555, 0.0673, 0.0588,
        0.0476, 0.0811, 0.0826, 0.0602, 0.0367, 0.0219, 0.0365, 0.0493, 0.0413,
        0.0642], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:38,843][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0625, 0.0358, 0.0286, 0.0432, 0.0293, 0.0490, 0.0517, 0.0277, 0.0486,
        0.0316, 0.0649, 0.0620, 0.0538, 0.1017, 0.0461, 0.0723, 0.0629, 0.0506,
        0.0779], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:38,845][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0278, 0.0042, 0.0282, 0.0060, 0.0104, 0.0084, 0.0468, 0.0015, 0.0115,
        0.0042, 0.0188, 0.0611, 0.0084, 0.0506, 0.0232, 0.0084, 0.0675, 0.0019,
        0.6112], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:38,847][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0058, 0.0186, 0.0477, 0.0620, 0.0417, 0.0284, 0.0154, 0.0279, 0.0362,
        0.0822, 0.0349, 0.0273, 0.0945, 0.0790, 0.0839, 0.0761, 0.0291, 0.0785,
        0.1307], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:38,849][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0783, 0.0291, 0.0494, 0.0365, 0.0294, 0.0397, 0.0326, 0.0161, 0.0349,
        0.0234, 0.0356, 0.0541, 0.1181, 0.1292, 0.0221, 0.0287, 0.0410, 0.1494,
        0.0525], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:38,851][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.1324, 0.0780, 0.1138, 0.0301, 0.0520, 0.0362, 0.0504, 0.0790, 0.0281,
        0.0339, 0.0355, 0.0611, 0.0440, 0.0369, 0.0530, 0.0320, 0.0383, 0.0261,
        0.0391], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:38,852][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([9.8918e-03, 5.2839e-06, 1.1640e-01, 4.0711e-04, 1.7127e-04, 3.2497e-04,
        1.4989e-01, 3.8482e-02, 6.8317e-02, 6.8157e-05, 1.4961e-04, 9.8364e-03,
        5.6565e-03, 2.1561e-04, 3.1986e-01, 2.7528e-05, 2.3769e-01, 1.1443e-10,
        4.2607e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:38,854][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0175, 0.0550, 0.0644, 0.0452, 0.0609, 0.0511, 0.0446, 0.0567, 0.0381,
        0.0640, 0.0503, 0.0446, 0.0627, 0.0399, 0.0662, 0.0634, 0.0469, 0.0828,
        0.0458], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:38,855][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([1.1224e-02, 4.0019e-02, 2.3018e-04, 1.7784e-01, 1.7229e-04, 4.5274e-03,
        1.2279e-02, 1.2547e-03, 2.5648e-01, 7.9282e-04, 1.2189e-02, 1.2552e-02,
        1.8169e-04, 3.2388e-01, 1.8930e-04, 4.7514e-04, 7.2030e-03, 1.0021e-04,
        1.3842e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:38,859][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:21:38,861][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[17392],
        [ 5704],
        [ 5979],
        [12839],
        [    2],
        [10881],
        [ 6579],
        [10384],
        [13606],
        [25947],
        [13713],
        [ 9891],
        [16853],
        [ 7601],
        [ 8838],
        [18004],
        [14081],
        [23438],
        [12677]], device='cuda:0')
[2024-07-24 10:21:38,863][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[31858],
        [ 5421],
        [15871],
        [21673],
        [    1],
        [29466],
        [17030],
        [19202],
        [18575],
        [34143],
        [31604],
        [19878],
        [14112],
        [13679],
        [16120],
        [22375],
        [15498],
        [27094],
        [15871]], device='cuda:0')
[2024-07-24 10:21:38,865][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[12704],
        [16559],
        [17596],
        [21208],
        [15471],
        [13487],
        [ 7044],
        [19828],
        [38477],
        [37679],
        [35494],
        [35864],
        [32654],
        [32386],
        [13386],
        [28491],
        [27725],
        [28241],
        [22207]], device='cuda:0')
[2024-07-24 10:21:38,866][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[43438],
        [42196],
        [35025],
        [32936],
        [32057],
        [36634],
        [38141],
        [35533],
        [34342],
        [32416],
        [30821],
        [32382],
        [30195],
        [32035],
        [30915],
        [31355],
        [31430],
        [31229],
        [31196]], device='cuda:0')
[2024-07-24 10:21:38,868][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[15281],
        [15405],
        [18433],
        [25771],
        [27949],
        [30815],
        [36337],
        [33992],
        [37548],
        [39232],
        [41321],
        [40704],
        [39688],
        [40138],
        [42953],
        [43738],
        [43824],
        [43383],
        [43339]], device='cuda:0')
[2024-07-24 10:21:38,870][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[ 9574],
        [ 9436],
        [ 6979],
        [12396],
        [10545],
        [12629],
        [13840],
        [14912],
        [15471],
        [16313],
        [18492],
        [19327],
        [18012],
        [18197],
        [17806],
        [18044],
        [18443],
        [17975],
        [18681]], device='cuda:0')
[2024-07-24 10:21:38,872][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[23142],
        [25860],
        [27505],
        [14529],
        [16399],
        [19169],
        [19957],
        [23831],
        [18228],
        [22010],
        [21525],
        [21859],
        [22686],
        [22367],
        [20727],
        [20629],
        [21924],
        [21955],
        [20153]], device='cuda:0')
[2024-07-24 10:21:38,874][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[39609],
        [15118],
        [16765],
        [13478],
        [25920],
        [15386],
        [18101],
        [16801],
        [29352],
        [24778],
        [17276],
        [24139],
        [37641],
        [43322],
        [38676],
        [42952],
        [40276],
        [43474],
        [36794]], device='cuda:0')
[2024-07-24 10:21:38,876][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[ 4630],
        [ 4633],
        [ 4659],
        [ 4766],
        [ 4782],
        [ 4834],
        [ 5751],
        [ 5919],
        [ 5942],
        [ 5362],
        [ 5819],
        [ 6774],
        [ 7871],
        [ 7198],
        [ 8474],
        [ 8637],
        [10358],
        [11277],
        [12918]], device='cuda:0')
[2024-07-24 10:21:38,878][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[26995],
        [26868],
        [ 5971],
        [21444],
        [ 3489],
        [  793],
        [  626],
        [21959],
        [15497],
        [12675],
        [ 6164],
        [ 8413],
        [11439],
        [11839],
        [ 6009],
        [18629],
        [19035],
        [14071],
        [21855]], device='cuda:0')
[2024-07-24 10:21:38,880][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[24929],
        [29634],
        [28737],
        [28206],
        [27532],
        [26916],
        [25375],
        [24845],
        [24721],
        [24683],
        [24866],
        [24047],
        [23698],
        [23346],
        [23430],
        [23050],
        [22934],
        [22852],
        [23554]], device='cuda:0')
[2024-07-24 10:21:38,882][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[20939],
        [ 5640],
        [ 5250],
        [ 3788],
        [ 3596],
        [ 3402],
        [ 3357],
        [ 3383],
        [ 3186],
        [ 3147],
        [ 2999],
        [ 2809],
        [ 2782],
        [ 2541],
        [ 2550],
        [ 2536],
        [ 2582],
        [ 2546],
        [ 2561]], device='cuda:0')
[2024-07-24 10:21:38,884][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[1630],
        [3969],
        [4126],
        [4328],
        [3758],
        [3562],
        [3326],
        [3152],
        [3531],
        [3311],
        [3080],
        [3001],
        [2946],
        [3055],
        [3259],
        [3092],
        [3010],
        [3217],
        [3212]], device='cuda:0')
[2024-07-24 10:21:38,886][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[41431],
        [41385],
        [40882],
        [26237],
        [43725],
        [34648],
        [31823],
        [38674],
        [33423],
        [37780],
        [30001],
        [30474],
        [38099],
        [31120],
        [37343],
        [32014],
        [31151],
        [28744],
        [29573]], device='cuda:0')
[2024-07-24 10:21:38,888][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[12992],
        [ 8020],
        [19400],
        [12934],
        [11778],
        [40097],
        [26271],
        [ 8696],
        [17889],
        [11907],
        [20255],
        [18054],
        [45627],
        [13409],
        [28255],
        [33406],
        [21083],
        [22043],
        [15855]], device='cuda:0')
[2024-07-24 10:21:38,890][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[23263],
        [20887],
        [25786],
        [26518],
        [34583],
        [37062],
        [43389],
        [24489],
        [13209],
        [15548],
        [14141],
        [21615],
        [34789],
        [33416],
        [35043],
        [23838],
        [26213],
        [31127],
        [30892]], device='cuda:0')
[2024-07-24 10:21:38,892][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[  83],
        [ 165],
        [ 115],
        [ 666],
        [  95],
        [ 404],
        [ 226],
        [  97],
        [ 195],
        [ 417],
        [ 467],
        [ 230],
        [ 253],
        [ 153],
        [ 105],
        [1219],
        [ 557],
        [ 187],
        [ 373]], device='cuda:0')
[2024-07-24 10:21:38,894][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[ 8126],
        [ 8069],
        [ 6352],
        [ 7688],
        [ 7407],
        [ 7431],
        [ 8560],
        [ 8652],
        [ 8938],
        [10225],
        [ 9000],
        [ 8233],
        [ 7556],
        [ 6315],
        [ 4954],
        [ 3957],
        [ 3590],
        [ 3590],
        [ 3422]], device='cuda:0')
[2024-07-24 10:21:38,895][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[20272],
        [26021],
        [34125],
        [35733],
        [40595],
        [42300],
        [42678],
        [42886],
        [42612],
        [42855],
        [42304],
        [41953],
        [42165],
        [42114],
        [42112],
        [42270],
        [42341],
        [42565],
        [42515]], device='cuda:0')
[2024-07-24 10:21:38,897][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[4103],
        [4349],
        [4471],
        [6140],
        [6211],
        [5004],
        [6028],
        [5258],
        [6167],
        [5516],
        [5531],
        [5971],
        [5173],
        [4512],
        [4542],
        [3837],
        [3881],
        [3729],
        [3837]], device='cuda:0')
[2024-07-24 10:21:38,899][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[ 7832],
        [12244],
        [28248],
        [27343],
        [15692],
        [40329],
        [24283],
        [28854],
        [31906],
        [21192],
        [32268],
        [26305],
        [ 7538],
        [ 5647],
        [19946],
        [ 5892],
        [ 7460],
        [ 6211],
        [13738]], device='cuda:0')
[2024-07-24 10:21:38,901][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[22906],
        [19994],
        [18971],
        [17994],
        [18547],
        [18211],
        [18324],
        [18344],
        [17891],
        [18035],
        [17487],
        [17441],
        [17466],
        [16924],
        [16919],
        [16444],
        [16351],
        [16606],
        [16261]], device='cuda:0')
[2024-07-24 10:21:38,903][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[17880],
        [16573],
        [33517],
        [27444],
        [22036],
        [40488],
        [39498],
        [39345],
        [37442],
        [41623],
        [45648],
        [39596],
        [42053],
        [21574],
        [34542],
        [38923],
        [30948],
        [19711],
        [18863]], device='cuda:0')
[2024-07-24 10:21:38,904][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[32129],
        [31027],
        [29312],
        [29664],
        [28807],
        [28443],
        [28747],
        [28898],
        [28741],
        [28157],
        [27808],
        [27464],
        [27154],
        [26673],
        [26420],
        [26302],
        [26314],
        [26037],
        [26239]], device='cuda:0')
[2024-07-24 10:21:38,906][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[34587],
        [34587],
        [38861],
        [38876],
        [38743],
        [39076],
        [21985],
        [26541],
        [26051],
        [33377],
        [25683],
        [33823],
        [27742],
        [39467],
        [26173],
        [19108],
        [25657],
        [30189],
        [22771]], device='cuda:0')
[2024-07-24 10:21:38,908][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[14721],
        [12229],
        [12675],
        [12673],
        [12972],
        [13133],
        [12908],
        [12939],
        [12752],
        [12932],
        [12981],
        [12878],
        [12911],
        [12807],
        [12739],
        [12860],
        [12744],
        [12849],
        [12815]], device='cuda:0')
[2024-07-24 10:21:38,910][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[31699],
        [35969],
        [35537],
        [35326],
        [35176],
        [31851],
        [25424],
        [31503],
        [31292],
        [31798],
        [28724],
        [28858],
        [31713],
        [32868],
        [34705],
        [34327],
        [29478],
        [34561],
        [33046]], device='cuda:0')
[2024-07-24 10:21:38,912][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[42900],
        [42289],
        [38816],
        [34927],
        [39304],
        [28679],
        [31042],
        [37353],
        [36135],
        [36715],
        [33782],
        [36581],
        [38094],
        [44547],
        [39172],
        [41618],
        [43632],
        [45515],
        [42644]], device='cuda:0')
[2024-07-24 10:21:38,913][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[ 4495],
        [18482],
        [ 6932],
        [17924],
        [20565],
        [ 1408],
        [ 6815],
        [19590],
        [17036],
        [20379],
        [ 8939],
        [11483],
        [ 1349],
        [15666],
        [ 5986],
        [ 5435],
        [12609],
        [11324],
        [22819]], device='cuda:0')
[2024-07-24 10:21:38,915][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[10813],
        [10813],
        [10813],
        [10813],
        [10813],
        [10813],
        [10813],
        [10813],
        [10813],
        [10813],
        [10813],
        [10813],
        [10813],
        [10813],
        [10813],
        [10813],
        [10813],
        [10813],
        [10813]], device='cuda:0')
[2024-07-24 10:21:38,955][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:21:38,956][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:38,957][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:38,958][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:38,958][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:38,959][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:38,960][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:38,961][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:38,961][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:38,962][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:38,963][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:38,963][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:38,964][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:38,965][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.3939, 0.6061], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:38,965][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.6884, 0.3116], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:38,966][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.9792, 0.0208], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:38,967][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.6730, 0.3270], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:38,968][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.4998, 0.5002], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:38,970][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.1583, 0.8417], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:38,971][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.8143, 0.1857], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:38,973][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.5172, 0.4828], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:38,975][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.9181, 0.0819], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:38,976][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0037, 0.9963], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:38,977][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [,] are: tensor([1.9384e-04, 9.9981e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:38,979][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.7060, 0.2940], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:38,981][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Anthony] are: tensor([0.1581, 0.6195, 0.2224], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:38,982][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Anthony] are: tensor([0.3582, 0.3033, 0.3385], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:38,983][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Anthony] are: tensor([0.6418, 0.2622, 0.0960], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:38,984][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Anthony] are: tensor([0.2226, 0.0933, 0.6841], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:38,985][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Anthony] are: tensor([0.1667, 0.6411, 0.1922], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:38,985][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Anthony] are: tensor([0.0725, 0.8784, 0.0491], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:38,986][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Anthony] are: tensor([0.1931, 0.0719, 0.7350], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:38,988][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Anthony] are: tensor([0.3063, 0.3357, 0.3581], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:38,989][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Anthony] are: tensor([0.4888, 0.4569, 0.0543], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:38,990][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Anthony] are: tensor([1.5465e-04, 5.0220e-01, 4.9765e-01], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:38,992][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Anthony] are: tensor([0.0380, 0.2701, 0.6919], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:38,993][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Anthony] are: tensor([0.5397, 0.2106, 0.2497], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:38,995][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0567, 0.3422, 0.5414, 0.0596], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:38,996][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.1786, 0.1078, 0.2695, 0.4441], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:38,998][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.1886, 0.0265, 0.7799, 0.0049], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:38,999][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.2105, 0.0696, 0.5840, 0.1360], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:39,001][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.1175, 0.4940, 0.0940, 0.2946], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:39,002][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0788, 0.6489, 0.2101, 0.0622], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:39,004][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.2505, 0.0590, 0.6303, 0.0601], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:39,006][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.2526, 0.2282, 0.3044, 0.2148], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:39,007][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.2712, 0.6195, 0.0942, 0.0151], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:39,008][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ and] are: tensor([1.9224e-05, 3.3215e-02, 4.1893e-01, 5.4783e-01], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:39,010][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0090, 0.4104, 0.5055, 0.0751], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:39,012][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.2739, 0.2093, 0.2336, 0.2832], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:39,013][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Travis] are: tensor([0.0645, 0.1661, 0.5718, 0.1199, 0.0777], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:39,015][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Travis] are: tensor([0.2071, 0.1111, 0.1533, 0.3873, 0.1413], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:39,017][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Travis] are: tensor([0.1514, 0.0528, 0.6331, 0.1617, 0.0010], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:39,018][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Travis] are: tensor([0.1779, 0.0591, 0.4284, 0.1538, 0.1807], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:39,020][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Travis] are: tensor([0.0631, 0.3269, 0.1217, 0.3556, 0.1327], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:39,021][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Travis] are: tensor([0.0403, 0.5106, 0.0999, 0.3281, 0.0210], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:39,023][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Travis] are: tensor([0.1639, 0.0416, 0.4608, 0.0461, 0.2876], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:39,025][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Travis] are: tensor([0.1968, 0.1992, 0.2231, 0.1980, 0.1829], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:39,026][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Travis] are: tensor([0.0895, 0.5374, 0.1222, 0.2476, 0.0033], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:39,027][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Travis] are: tensor([7.8457e-06, 1.1386e-02, 1.2891e-01, 4.9459e-01, 3.6510e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:39,029][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Travis] are: tensor([0.0596, 0.3098, 0.4524, 0.0887, 0.0896], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:39,031][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Travis] are: tensor([0.2985, 0.1022, 0.1919, 0.1776, 0.2298], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:39,032][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.0360, 0.1913, 0.4833, 0.1150, 0.1656, 0.0089], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:39,034][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.1588, 0.0758, 0.1481, 0.3149, 0.1590, 0.1434], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:39,035][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.0340, 0.1462, 0.1471, 0.5450, 0.1255, 0.0022], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:39,037][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.0863, 0.0241, 0.3196, 0.0796, 0.1555, 0.3348], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:39,039][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.1326, 0.2032, 0.0479, 0.3706, 0.0650, 0.1806], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:39,040][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.0565, 0.4630, 0.0711, 0.2317, 0.1472, 0.0306], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:39,042][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.1516, 0.0466, 0.3847, 0.0434, 0.2279, 0.1458], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:39,044][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.1759, 0.1868, 0.1707, 0.1372, 0.1477, 0.1817], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:39,045][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.0364, 0.8659, 0.0452, 0.0410, 0.0078, 0.0037], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:39,046][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ had] are: tensor([2.6385e-06, 4.4561e-03, 2.9102e-02, 1.3301e-01, 4.3191e-01, 4.0152e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:39,047][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.0070, 0.2726, 0.3315, 0.0476, 0.0358, 0.3055], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:39,048][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.2102, 0.1353, 0.1639, 0.1510, 0.2587, 0.0809], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:39,048][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0468, 0.1306, 0.3278, 0.3175, 0.1090, 0.0282, 0.0400],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:39,050][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0859, 0.0478, 0.1048, 0.2088, 0.1148, 0.0824, 0.3555],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:39,051][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ a] are: tensor([3.5283e-01, 3.3318e-02, 6.9051e-02, 2.5844e-01, 1.2436e-01, 1.6171e-01,
        2.8250e-04], device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:39,052][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0999, 0.0230, 0.2432, 0.0629, 0.1281, 0.2625, 0.1804],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:39,054][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0971, 0.1697, 0.0569, 0.2723, 0.1047, 0.1854, 0.1139],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:39,055][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0322, 0.2951, 0.0896, 0.1709, 0.1052, 0.3015, 0.0055],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:39,057][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0941, 0.0251, 0.3137, 0.0343, 0.2218, 0.1246, 0.1863],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:39,059][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.1388, 0.1385, 0.1529, 0.1147, 0.1363, 0.1457, 0.1732],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:39,060][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0357, 0.0662, 0.0232, 0.0916, 0.1044, 0.6760, 0.0030],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:39,062][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ a] are: tensor([1.5691e-06, 1.7609e-03, 1.2672e-02, 4.6641e-02, 2.1919e-01, 4.1118e-01,
        3.0855e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:39,063][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0233, 0.1805, 0.2806, 0.0536, 0.0467, 0.2633, 0.1521],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:39,065][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.1843, 0.1058, 0.1275, 0.2071, 0.1744, 0.1184, 0.0825],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:39,067][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ lot] are: tensor([0.0345, 0.1088, 0.3180, 0.2513, 0.1295, 0.0353, 0.0410, 0.0816],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:39,068][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ lot] are: tensor([0.0696, 0.0344, 0.0562, 0.1374, 0.0593, 0.0633, 0.2762, 0.3036],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:39,070][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ lot] are: tensor([0.0234, 0.0257, 0.5741, 0.0414, 0.2048, 0.0325, 0.0973, 0.0007],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:39,072][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ lot] are: tensor([0.1234, 0.0233, 0.1786, 0.0586, 0.1044, 0.2245, 0.1812, 0.1060],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:39,073][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ lot] are: tensor([0.0483, 0.1704, 0.0226, 0.2080, 0.0498, 0.1244, 0.2224, 0.1541],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:39,075][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ lot] are: tensor([0.0153, 0.3224, 0.1662, 0.2203, 0.1106, 0.1422, 0.0184, 0.0046],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:39,076][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ lot] are: tensor([0.0689, 0.0165, 0.1850, 0.0227, 0.1576, 0.0932, 0.1412, 0.3148],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:39,078][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ lot] are: tensor([0.1075, 0.1155, 0.1294, 0.1006, 0.1040, 0.1234, 0.1504, 0.1693],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:39,080][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ lot] are: tensor([0.0120, 0.2535, 0.0769, 0.0477, 0.0510, 0.5430, 0.0134, 0.0025],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:39,081][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ lot] are: tensor([5.8631e-07, 6.0803e-04, 4.8607e-03, 2.5136e-02, 1.0598e-01, 2.6651e-01,
        3.3980e-01, 2.5710e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:39,083][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ lot] are: tensor([0.0017, 0.1052, 0.0843, 0.0191, 0.0134, 0.1226, 0.0490, 0.6047],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:39,084][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ lot] are: tensor([0.2201, 0.0922, 0.1196, 0.1009, 0.2123, 0.0780, 0.0624, 0.1145],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:39,086][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ of] are: tensor([0.0321, 0.1030, 0.3646, 0.0587, 0.1560, 0.0102, 0.0463, 0.2037, 0.0253],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:39,088][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ of] are: tensor([0.0447, 0.0241, 0.0761, 0.1466, 0.0731, 0.0417, 0.3042, 0.1607, 0.1288],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:39,089][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ of] are: tensor([1.9229e-02, 4.8685e-04, 1.1235e-01, 6.2754e-03, 1.7903e-02, 7.5289e-03,
        4.8033e-03, 8.3142e-01, 1.7335e-06], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:39,091][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ of] are: tensor([0.1074, 0.0178, 0.1497, 0.0438, 0.0805, 0.1748, 0.1400, 0.0920, 0.1941],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:39,092][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ of] are: tensor([0.0134, 0.0508, 0.0687, 0.0692, 0.0639, 0.0340, 0.0725, 0.5968, 0.0306],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:39,094][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ of] are: tensor([0.0404, 0.2730, 0.0487, 0.2246, 0.1704, 0.1832, 0.0267, 0.0271, 0.0058],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:39,096][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ of] are: tensor([0.0317, 0.0104, 0.1268, 0.0142, 0.1025, 0.0551, 0.0962, 0.2223, 0.3408],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:39,097][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ of] are: tensor([0.1006, 0.0848, 0.1197, 0.0913, 0.1051, 0.1225, 0.1404, 0.1503, 0.0853],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:39,098][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ of] are: tensor([3.3983e-03, 2.6725e-02, 2.3747e-01, 7.1480e-02, 2.8740e-01, 3.4667e-01,
        1.3998e-02, 1.2807e-02, 5.2071e-05], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:39,100][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ of] are: tensor([4.6023e-07, 1.3824e-04, 1.5766e-03, 5.3398e-03, 2.9747e-02, 5.9919e-02,
        9.3454e-02, 1.9588e-01, 6.1395e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:39,101][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ of] are: tensor([0.0414, 0.0478, 0.0864, 0.0297, 0.0313, 0.1097, 0.0807, 0.4222, 0.1507],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:39,103][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ of] are: tensor([0.1188, 0.0822, 0.0707, 0.1852, 0.0982, 0.0890, 0.0751, 0.0621, 0.2186],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:39,105][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ fun] are: tensor([0.0600, 0.2011, 0.1563, 0.0953, 0.1017, 0.0290, 0.0264, 0.0951, 0.2053,
        0.0298], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:39,106][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ fun] are: tensor([0.0690, 0.0372, 0.0513, 0.1141, 0.0462, 0.0615, 0.1961, 0.2583, 0.0872,
        0.0791], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:39,108][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ fun] are: tensor([0.0582, 0.0107, 0.0741, 0.0293, 0.3039, 0.2246, 0.0180, 0.0625, 0.2168,
        0.0018], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:39,109][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ fun] are: tensor([0.0315, 0.0051, 0.0471, 0.0152, 0.0289, 0.0615, 0.0486, 0.0313, 0.0827,
        0.6482], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:39,110][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ fun] are: tensor([0.0210, 0.0950, 0.0277, 0.0813, 0.0311, 0.2350, 0.1215, 0.2987, 0.0667,
        0.0221], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:39,111][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ fun] are: tensor([0.0473, 0.3609, 0.0742, 0.1505, 0.1176, 0.0491, 0.0328, 0.0760, 0.0507,
        0.0410], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:39,111][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ fun] are: tensor([0.0089, 0.0039, 0.0418, 0.0054, 0.0348, 0.0208, 0.0360, 0.0907, 0.1365,
        0.6212], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:39,113][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ fun] are: tensor([0.0883, 0.1001, 0.1023, 0.0894, 0.0885, 0.1144, 0.1204, 0.1253, 0.0723,
        0.0992], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:39,114][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ fun] are: tensor([8.8460e-03, 9.4794e-03, 3.5155e-02, 8.1775e-03, 1.0566e-02, 8.9826e-01,
        8.5969e-03, 1.5837e-02, 4.9066e-03, 1.7184e-04], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:39,116][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ fun] are: tensor([1.0317e-07, 3.6153e-05, 7.6344e-04, 7.4200e-04, 5.8879e-03, 7.7001e-03,
        1.7567e-02, 5.6470e-02, 3.3788e-01, 5.7295e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:39,117][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ fun] are: tensor([0.0033, 0.1018, 0.1033, 0.0247, 0.0197, 0.1171, 0.0627, 0.4049, 0.0821,
        0.0805], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:39,119][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ fun] are: tensor([0.1445, 0.0775, 0.0937, 0.1035, 0.1690, 0.0685, 0.0555, 0.1018, 0.1010,
        0.0849], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:39,120][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.0343, 0.1387, 0.1811, 0.0737, 0.2315, 0.0286, 0.0616, 0.0766, 0.0714,
        0.0540, 0.0486], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:39,122][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.0402, 0.0277, 0.0839, 0.1351, 0.0801, 0.0467, 0.2446, 0.1480, 0.0929,
        0.0541, 0.0467], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:39,124][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.0947, 0.0869, 0.1002, 0.0918, 0.2025, 0.1029, 0.0800, 0.0980, 0.0905,
        0.0515, 0.0009], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:39,125][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.0339, 0.0035, 0.0263, 0.0086, 0.0151, 0.0355, 0.0262, 0.0181, 0.0404,
        0.2885, 0.5040], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:39,127][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.0327, 0.1358, 0.0298, 0.1724, 0.0263, 0.0700, 0.1321, 0.2001, 0.1050,
        0.0379, 0.0580], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:39,129][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.0219, 0.1948, 0.0556, 0.1436, 0.0821, 0.1759, 0.0457, 0.1241, 0.0384,
        0.1118, 0.0061], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:39,130][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.0069, 0.0031, 0.0378, 0.0054, 0.0318, 0.0195, 0.0320, 0.0861, 0.1106,
        0.5141, 0.1527], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:39,132][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0915, 0.0771, 0.0900, 0.0700, 0.0880, 0.0975, 0.1110, 0.1454, 0.0559,
        0.1062, 0.0673], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:39,133][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ at] are: tensor([6.4560e-03, 5.2525e-03, 5.6349e-02, 5.9907e-03, 2.1431e-02, 6.2755e-01,
        6.0935e-02, 2.0692e-01, 5.4716e-03, 3.5270e-03, 1.2263e-04],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:39,134][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ at] are: tensor([2.6077e-08, 4.1762e-06, 4.0457e-05, 1.2895e-04, 6.9806e-04, 1.5244e-03,
        3.0360e-03, 5.8494e-03, 2.6175e-02, 6.3658e-01, 3.2597e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:39,136][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.0095, 0.0543, 0.0666, 0.0266, 0.0227, 0.0923, 0.0679, 0.3078, 0.1139,
        0.0996, 0.1389], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:39,138][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.1240, 0.0528, 0.0567, 0.1058, 0.1076, 0.0587, 0.0570, 0.0931, 0.1297,
        0.0714, 0.1433], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:39,139][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0142, 0.0401, 0.1458, 0.0921, 0.0565, 0.0184, 0.0216, 0.1152, 0.1169,
        0.0872, 0.2495, 0.0426], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:39,141][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0388, 0.0213, 0.0579, 0.1103, 0.0638, 0.0423, 0.1844, 0.1317, 0.0970,
        0.0510, 0.0446, 0.1570], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:39,143][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ the] are: tensor([6.0364e-02, 6.0589e-03, 1.0769e-01, 6.8750e-02, 1.4667e-01, 8.1703e-02,
        2.7535e-03, 7.0927e-02, 2.8528e-01, 2.0221e-02, 1.4951e-01, 7.8306e-05],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:39,144][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0155, 0.0020, 0.0175, 0.0053, 0.0111, 0.0206, 0.0168, 0.0117, 0.0249,
        0.2082, 0.3673, 0.2992], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:39,146][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0490, 0.1159, 0.0644, 0.1504, 0.0664, 0.0765, 0.1044, 0.1070, 0.0623,
        0.0423, 0.0821, 0.0794], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:39,148][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0184, 0.1849, 0.0441, 0.1918, 0.0645, 0.1986, 0.0169, 0.0940, 0.0138,
        0.1525, 0.0180, 0.0025], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:39,149][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0044, 0.0021, 0.0264, 0.0045, 0.0263, 0.0165, 0.0276, 0.0808, 0.1068,
        0.4969, 0.1524, 0.0553], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:39,151][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0770, 0.0714, 0.0891, 0.0684, 0.0755, 0.0910, 0.1036, 0.1249, 0.0576,
        0.0945, 0.0650, 0.0820], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:39,153][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0044, 0.0233, 0.0167, 0.0634, 0.0221, 0.3332, 0.0174, 0.1440, 0.0516,
        0.1097, 0.2137, 0.0004], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:39,154][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ the] are: tensor([1.5494e-08, 2.4991e-06, 2.4268e-05, 4.5716e-05, 4.1462e-04, 6.2062e-04,
        3.3835e-04, 2.9568e-03, 1.1017e-02, 2.5542e-01, 3.2556e-01, 4.0360e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:39,156][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0149, 0.0246, 0.0396, 0.0221, 0.0206, 0.0609, 0.0588, 0.1821, 0.1262,
        0.0801, 0.1501, 0.2198], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:39,158][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0943, 0.0607, 0.0377, 0.1329, 0.0625, 0.0755, 0.0466, 0.0517, 0.1726,
        0.0416, 0.1799, 0.0439], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:39,159][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ hospital] are: tensor([0.0227, 0.0459, 0.0847, 0.0594, 0.1394, 0.0130, 0.0340, 0.0757, 0.0924,
        0.0600, 0.1681, 0.1482, 0.0565], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:39,161][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ hospital] are: tensor([0.0640, 0.0437, 0.0390, 0.0933, 0.0375, 0.0642, 0.1124, 0.1923, 0.0690,
        0.0472, 0.0624, 0.1359, 0.0392], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:39,163][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ hospital] are: tensor([0.0738, 0.0426, 0.2257, 0.0281, 0.1065, 0.0989, 0.0480, 0.2286, 0.0182,
        0.0946, 0.0109, 0.0223, 0.0018], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:39,164][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ hospital] are: tensor([0.0051, 0.0007, 0.0051, 0.0021, 0.0032, 0.0074, 0.0063, 0.0042, 0.0112,
        0.0914, 0.2036, 0.2021, 0.4576], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:39,166][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ hospital] are: tensor([0.0139, 0.1326, 0.0186, 0.1214, 0.0397, 0.1137, 0.0982, 0.0774, 0.0994,
        0.0227, 0.0577, 0.1742, 0.0305], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:39,168][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ hospital] are: tensor([0.0183, 0.1320, 0.0500, 0.0844, 0.0855, 0.0985, 0.0640, 0.1543, 0.0489,
        0.2130, 0.0240, 0.0227, 0.0044], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:39,170][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ hospital] are: tensor([0.0063, 0.0018, 0.0209, 0.0037, 0.0189, 0.0139, 0.0229, 0.0647, 0.0850,
        0.3980, 0.1321, 0.0491, 0.1825], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:39,171][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ hospital] are: tensor([0.0715, 0.0767, 0.0765, 0.0672, 0.0680, 0.0932, 0.0884, 0.1129, 0.0511,
        0.0903, 0.0586, 0.0678, 0.0778], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:39,172][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ hospital] are: tensor([0.0247, 0.1584, 0.0201, 0.0920, 0.0057, 0.0191, 0.1041, 0.0940, 0.0910,
        0.1379, 0.1538, 0.0920, 0.0073], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:39,173][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ hospital] are: tensor([9.4063e-09, 1.6420e-06, 8.0119e-06, 3.1411e-05, 1.1698e-04, 2.7343e-04,
        5.0418e-04, 1.3801e-03, 7.8024e-03, 9.9873e-02, 1.6742e-01, 4.4339e-01,
        2.7920e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:39,173][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ hospital] are: tensor([0.0120, 0.0102, 0.0223, 0.0146, 0.0166, 0.0395, 0.0434, 0.0979, 0.0960,
        0.0675, 0.1201, 0.1819, 0.2780], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:39,175][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ hospital] are: tensor([0.1226, 0.0517, 0.0782, 0.0723, 0.1308, 0.0683, 0.0405, 0.0848, 0.0678,
        0.0859, 0.0862, 0.0459, 0.0650], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:39,176][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.0114, 0.0177, 0.0805, 0.0247, 0.0596, 0.0109, 0.1000, 0.1069, 0.0481,
        0.0864, 0.1284, 0.2539, 0.0409, 0.0306], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:39,178][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.0256, 0.0181, 0.0463, 0.0995, 0.0455, 0.0309, 0.1844, 0.0904, 0.0842,
        0.0384, 0.0414, 0.1567, 0.0617, 0.0768], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:39,179][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [.] are: tensor([1.2710e-02, 1.7155e-04, 1.6499e-01, 2.1178e-03, 1.8715e-01, 4.3089e-02,
        3.5442e-02, 3.7529e-01, 2.6861e-03, 8.9212e-02, 1.5300e-02, 3.7628e-03,
        6.8033e-02, 4.0230e-05], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:39,181][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0132, 0.0012, 0.0066, 0.0024, 0.0042, 0.0088, 0.0065, 0.0043, 0.0093,
        0.0722, 0.1329, 0.1098, 0.3771, 0.2514], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:39,182][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0229, 0.0669, 0.0538, 0.0819, 0.0672, 0.0579, 0.1337, 0.1149, 0.0602,
        0.0333, 0.0588, 0.1473, 0.0368, 0.0643], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:39,184][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.0204, 0.1484, 0.0260, 0.1349, 0.0579, 0.1789, 0.0341, 0.1120, 0.0443,
        0.0842, 0.0567, 0.0229, 0.0608, 0.0184], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:39,186][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0023, 0.0014, 0.0169, 0.0041, 0.0193, 0.0136, 0.0231, 0.0712, 0.0759,
        0.3894, 0.1160, 0.0570, 0.2047, 0.0051], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:39,188][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0733, 0.0677, 0.0844, 0.0569, 0.0661, 0.0757, 0.0890, 0.1018, 0.0441,
        0.0843, 0.0518, 0.0656, 0.0792, 0.0600], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:39,189][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [.] are: tensor([2.1806e-02, 1.4002e-02, 3.6891e-01, 1.7422e-02, 3.6717e-02, 8.4002e-02,
        8.8247e-02, 2.0257e-01, 8.9749e-03, 3.4616e-02, 7.0592e-02, 1.9423e-02,
        3.2514e-02, 2.0947e-04], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:39,190][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [.] are: tensor([2.5869e-09, 2.4169e-07, 3.3159e-06, 1.4889e-05, 4.6302e-05, 8.1136e-05,
        2.1945e-04, 4.7545e-04, 2.9876e-03, 1.8692e-02, 5.0354e-02, 1.3550e-01,
        4.8949e-01, 3.0213e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:39,192][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.0190, 0.0118, 0.0247, 0.0145, 0.0149, 0.0414, 0.0435, 0.1214, 0.0861,
        0.0531, 0.1014, 0.1570, 0.2060, 0.1051], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:39,194][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0730, 0.0303, 0.0439, 0.1062, 0.0462, 0.0446, 0.0602, 0.0332, 0.2363,
        0.0372, 0.1446, 0.0639, 0.0385, 0.0419], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:39,196][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Anthony] are: tensor([0.0113, 0.0364, 0.0179, 0.0488, 0.1169, 0.0083, 0.0419, 0.1129, 0.0725,
        0.0458, 0.1498, 0.1569, 0.0634, 0.0987, 0.0186], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:39,197][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Anthony] are: tensor([0.0365, 0.0327, 0.0302, 0.0767, 0.0281, 0.0813, 0.1413, 0.0966, 0.0687,
        0.0528, 0.0477, 0.1516, 0.0528, 0.0716, 0.0315], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:39,199][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Anthony] are: tensor([0.0243, 0.0070, 0.0023, 0.0241, 0.3397, 0.0396, 0.0262, 0.2846, 0.0400,
        0.0830, 0.0076, 0.0123, 0.1069, 0.0017, 0.0007], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:39,200][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Anthony] are: tensor([3.9068e-03, 3.3283e-04, 1.9751e-03, 9.3151e-04, 1.4042e-03, 3.7680e-03,
        2.8322e-03, 1.6922e-03, 4.8509e-03, 3.5914e-02, 8.1310e-02, 7.6639e-02,
        2.0382e-01, 1.9784e-01, 3.8278e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:39,202][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Anthony] are: tensor([0.0146, 0.0753, 0.0158, 0.1131, 0.0472, 0.0559, 0.1160, 0.0847, 0.0674,
        0.0226, 0.0607, 0.1476, 0.0428, 0.1114, 0.0249], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:39,204][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Anthony] are: tensor([0.0137, 0.1569, 0.0074, 0.1091, 0.0339, 0.0838, 0.0265, 0.2284, 0.0286,
        0.1617, 0.0257, 0.0170, 0.0657, 0.0379, 0.0036], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:39,206][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Anthony] are: tensor([0.0019, 0.0014, 0.0148, 0.0043, 0.0207, 0.0139, 0.0212, 0.0660, 0.0722,
        0.3299, 0.1101, 0.0482, 0.1906, 0.0051, 0.0996], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:39,207][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Anthony] are: tensor([0.0644, 0.0674, 0.0722, 0.0575, 0.0586, 0.0788, 0.0812, 0.0904, 0.0465,
        0.0717, 0.0476, 0.0673, 0.0692, 0.0624, 0.0649], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:39,209][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Anthony] are: tensor([0.0652, 0.0659, 0.0103, 0.0865, 0.0310, 0.0550, 0.0822, 0.1311, 0.0923,
        0.1482, 0.0991, 0.0577, 0.0643, 0.0087, 0.0027], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:39,210][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Anthony] are: tensor([3.1654e-09, 2.0712e-07, 2.3919e-07, 5.4892e-06, 1.6205e-05, 3.0843e-05,
        5.3370e-05, 1.6254e-04, 9.4355e-04, 1.0831e-02, 1.6925e-02, 3.8872e-02,
        9.3354e-02, 2.7017e-01, 5.6864e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:39,212][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Anthony] are: tensor([0.0204, 0.0014, 0.0051, 0.0046, 0.0076, 0.0105, 0.0166, 0.0280, 0.0484,
        0.0285, 0.0656, 0.1160, 0.2041, 0.0857, 0.3576], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:39,214][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Anthony] are: tensor([0.1353, 0.0496, 0.0509, 0.0917, 0.0777, 0.0673, 0.0491, 0.0644, 0.0684,
        0.0668, 0.0664, 0.0485, 0.0754, 0.0301, 0.0586], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:39,216][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.0089, 0.0245, 0.1827, 0.0355, 0.0502, 0.0125, 0.0273, 0.0369, 0.0422,
        0.0433, 0.0698, 0.0833, 0.0963, 0.0814, 0.2015, 0.0039],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:39,218][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0501, 0.0315, 0.0335, 0.0843, 0.0339, 0.0576, 0.1114, 0.1400, 0.0693,
        0.0519, 0.0399, 0.1178, 0.0378, 0.0622, 0.0358, 0.0430],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:39,219][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0644, 0.0745, 0.0596, 0.1591, 0.1325, 0.0561, 0.0214, 0.0947, 0.0592,
        0.0390, 0.0231, 0.0612, 0.0871, 0.0374, 0.0291, 0.0017],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:39,221][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([1.7241e-03, 1.0603e-04, 1.0318e-03, 3.7847e-04, 6.3466e-04, 1.1997e-03,
        1.1377e-03, 8.6586e-04, 2.1143e-03, 1.7823e-02, 4.3638e-02, 3.9418e-02,
        1.1990e-01, 1.0895e-01, 2.5725e-01, 4.0383e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:39,222][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.0283, 0.0917, 0.0177, 0.1101, 0.0331, 0.0618, 0.0786, 0.0449, 0.0907,
        0.0329, 0.0664, 0.1102, 0.0485, 0.1436, 0.0313, 0.0102],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:39,224][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.0170, 0.2157, 0.0292, 0.1121, 0.0714, 0.0245, 0.0388, 0.0518, 0.0355,
        0.1383, 0.0413, 0.0418, 0.1024, 0.0606, 0.0158, 0.0039],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:39,226][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0013, 0.0008, 0.0113, 0.0034, 0.0187, 0.0106, 0.0196, 0.0616, 0.0733,
        0.3533, 0.1043, 0.0454, 0.1877, 0.0037, 0.0844, 0.0205],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:39,228][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0621, 0.0670, 0.0639, 0.0514, 0.0559, 0.0713, 0.0802, 0.0782, 0.0403,
        0.0695, 0.0486, 0.0605, 0.0630, 0.0582, 0.0578, 0.0722],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:39,230][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.0210, 0.2024, 0.0518, 0.0572, 0.0034, 0.0096, 0.0853, 0.2873, 0.0254,
        0.0509, 0.0106, 0.0851, 0.0207, 0.0693, 0.0196, 0.0005],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:39,231][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([1.4644e-10, 1.0148e-08, 1.1266e-07, 2.9447e-07, 2.0733e-06, 9.1396e-07,
        5.3355e-06, 1.5598e-05, 7.3746e-05, 4.0898e-04, 2.1021e-03, 3.3475e-03,
        3.1529e-02, 4.6118e-02, 6.6737e-01, 2.4903e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:39,233][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0075, 0.0095, 0.0157, 0.0096, 0.0096, 0.0271, 0.0280, 0.0719, 0.0559,
        0.0427, 0.0719, 0.1070, 0.1570, 0.0726, 0.2416, 0.0724],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:39,234][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0778, 0.0510, 0.0527, 0.0619, 0.0889, 0.0354, 0.0463, 0.0684, 0.0694,
        0.0724, 0.0894, 0.0684, 0.0638, 0.0309, 0.0642, 0.0592],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:39,234][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0073, 0.0213, 0.0730, 0.0734, 0.0272, 0.0070, 0.0121, 0.1045, 0.0874,
        0.0532, 0.1136, 0.0895, 0.0662, 0.1322, 0.1038, 0.0165, 0.0117],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:39,235][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0361, 0.0195, 0.0337, 0.0753, 0.0362, 0.0330, 0.1214, 0.1128, 0.0634,
        0.0423, 0.0341, 0.1069, 0.0394, 0.0547, 0.0401, 0.0317, 0.1194],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:39,237][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ a] are: tensor([1.6167e-01, 1.3629e-02, 2.6433e-02, 1.2856e-01, 5.6324e-02, 7.8098e-02,
        1.0581e-04, 1.0260e-01, 2.2076e-01, 1.9744e-02, 8.1487e-02, 6.8329e-03,
        2.0435e-02, 2.6959e-03, 1.6755e-02, 6.3818e-02, 5.4391e-05],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:39,238][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ a] are: tensor([4.1746e-03, 2.8441e-04, 1.9628e-03, 6.8282e-04, 1.0814e-03, 2.1894e-03,
        1.5829e-03, 1.3024e-03, 2.7487e-03, 1.9583e-02, 4.0038e-02, 3.6420e-02,
        1.0875e-01, 9.2085e-02, 2.0865e-01, 3.3408e-01, 1.4439e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:39,240][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0404, 0.0835, 0.0230, 0.1294, 0.0411, 0.0732, 0.0515, 0.1117, 0.0510,
        0.0203, 0.0513, 0.0973, 0.0231, 0.1005, 0.0316, 0.0195, 0.0517],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:39,242][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0176, 0.1736, 0.0532, 0.1063, 0.0645, 0.1691, 0.0030, 0.0378, 0.0234,
        0.1000, 0.0206, 0.0156, 0.0502, 0.0924, 0.0300, 0.0412, 0.0017],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:39,243][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0006, 0.0007, 0.0109, 0.0039, 0.0207, 0.0106, 0.0216, 0.0647, 0.0763,
        0.3432, 0.0934, 0.0474, 0.1938, 0.0034, 0.0778, 0.0221, 0.0090],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:39,244][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0565, 0.0548, 0.0627, 0.0459, 0.0549, 0.0596, 0.0693, 0.0905, 0.0384,
        0.0693, 0.0431, 0.0559, 0.0641, 0.0526, 0.0568, 0.0637, 0.0620],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:39,246][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ a] are: tensor([3.0950e-04, 8.0734e-04, 4.0725e-04, 1.1104e-03, 1.8874e-03, 9.7551e-03,
        3.8858e-05, 3.1103e-03, 1.8932e-03, 1.1212e-02, 4.5629e-03, 5.6034e-04,
        5.8930e-03, 3.5837e-04, 3.8005e-04, 9.5767e-01, 4.0693e-05],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:39,247][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ a] are: tensor([1.3774e-10, 5.7315e-09, 4.2424e-08, 9.2313e-08, 6.0457e-07, 6.4606e-07,
        4.2288e-07, 4.8486e-06, 1.5605e-05, 2.7016e-04, 3.1887e-04, 4.5892e-04,
        9.5560e-03, 1.0650e-02, 1.6364e-01, 3.9839e-01, 4.1670e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:39,249][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0091, 0.0039, 0.0086, 0.0065, 0.0071, 0.0157, 0.0195, 0.0443, 0.0479,
        0.0305, 0.0613, 0.0935, 0.1412, 0.0724, 0.2480, 0.0696, 0.1209],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:39,250][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0751, 0.0414, 0.0419, 0.0804, 0.0592, 0.0452, 0.0324, 0.0717, 0.1164,
        0.0427, 0.1151, 0.0419, 0.0409, 0.0338, 0.0532, 0.0778, 0.0311],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:39,252][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ drink] are: tensor([0.0049, 0.0145, 0.0702, 0.0316, 0.0612, 0.0116, 0.0268, 0.0331, 0.0557,
        0.1141, 0.0816, 0.1268, 0.1055, 0.0871, 0.0910, 0.0411, 0.0290, 0.0138],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:39,254][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ drink] are: tensor([0.0463, 0.0202, 0.0214, 0.0636, 0.0218, 0.0437, 0.1080, 0.1453, 0.0495,
        0.0495, 0.0320, 0.1034, 0.0396, 0.0477, 0.0267, 0.0449, 0.1017, 0.0347],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:39,256][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ drink] are: tensor([0.0136, 0.0098, 0.0385, 0.0353, 0.0738, 0.4028, 0.0150, 0.1300, 0.0093,
        0.0606, 0.0025, 0.0220, 0.0499, 0.0039, 0.0203, 0.1011, 0.0108, 0.0009],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:39,257][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ drink] are: tensor([2.2463e-03, 1.8277e-04, 1.0682e-03, 4.4151e-04, 6.3461e-04, 1.5723e-03,
        1.1580e-03, 9.1537e-04, 2.0209e-03, 1.2556e-02, 2.8668e-02, 2.7641e-02,
        6.6238e-02, 6.7243e-02, 1.1658e-01, 2.5299e-01, 1.2596e-01, 2.9189e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:39,259][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ drink] are: tensor([0.0197, 0.0574, 0.0244, 0.0639, 0.0301, 0.0795, 0.0590, 0.0914, 0.0593,
        0.0227, 0.0342, 0.1375, 0.0399, 0.1086, 0.0423, 0.0376, 0.0607, 0.0318],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:39,261][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ drink] are: tensor([0.0177, 0.1154, 0.0888, 0.0847, 0.1944, 0.0313, 0.0504, 0.0449, 0.0244,
        0.0820, 0.0244, 0.0455, 0.0313, 0.0279, 0.0479, 0.0525, 0.0345, 0.0020],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:39,263][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ drink] are: tensor([0.0012, 0.0007, 0.0099, 0.0038, 0.0181, 0.0105, 0.0215, 0.0584, 0.0720,
        0.3043, 0.0944, 0.0480, 0.1903, 0.0048, 0.0929, 0.0284, 0.0137, 0.0271],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:39,264][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ drink] are: tensor([0.0535, 0.0522, 0.0594, 0.0465, 0.0485, 0.0628, 0.0682, 0.0788, 0.0346,
        0.0568, 0.0412, 0.0516, 0.0543, 0.0539, 0.0550, 0.0621, 0.0609, 0.0597],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:39,266][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ drink] are: tensor([0.0094, 0.0439, 0.1462, 0.0156, 0.0622, 0.0463, 0.0072, 0.0969, 0.0257,
        0.1360, 0.0243, 0.0767, 0.0616, 0.0174, 0.0535, 0.1598, 0.0064, 0.0109],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:39,268][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ drink] are: tensor([6.8755e-11, 2.9762e-09, 1.9553e-08, 3.5281e-08, 4.7675e-07, 2.7000e-07,
        4.9808e-07, 2.2635e-06, 1.1379e-05, 9.7474e-05, 3.2934e-04, 4.9282e-04,
        4.7390e-03, 4.7922e-03, 5.7714e-02, 1.6621e-01, 3.9201e-01, 3.7360e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:39,269][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ drink] are: tensor([0.0123, 0.0011, 0.0022, 0.0031, 0.0043, 0.0048, 0.0091, 0.0126, 0.0264,
        0.0157, 0.0384, 0.0681, 0.1203, 0.0573, 0.2111, 0.0495, 0.0991, 0.2646],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:39,271][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ drink] are: tensor([0.0919, 0.0368, 0.0431, 0.0510, 0.0860, 0.0410, 0.0334, 0.0854, 0.0492,
        0.0758, 0.0614, 0.0395, 0.0725, 0.0279, 0.0498, 0.0685, 0.0316, 0.0554],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:39,273][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0056, 0.0204, 0.0381, 0.0426, 0.0288, 0.0121, 0.0371, 0.0738, 0.0480,
        0.0550, 0.1656, 0.0735, 0.0786, 0.0752, 0.0616, 0.0195, 0.0371, 0.1190,
        0.0085], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:39,275][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0201, 0.0128, 0.0340, 0.0605, 0.0323, 0.0227, 0.1209, 0.0781, 0.0567,
        0.0341, 0.0253, 0.1093, 0.0359, 0.0469, 0.0430, 0.0310, 0.1223, 0.0272,
        0.0870], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:39,276][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ to] are: tensor([4.0880e-02, 4.8021e-03, 9.7906e-03, 2.4660e-02, 3.8097e-02, 9.0174e-02,
        1.8815e-02, 1.3495e-01, 2.5431e-02, 1.7021e-01, 1.1284e-02, 2.3248e-02,
        1.5812e-02, 6.1365e-04, 5.7084e-03, 7.0546e-02, 1.4529e-02, 3.0044e-01,
        3.4409e-06], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:39,278][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ to] are: tensor([3.1205e-03, 1.9786e-04, 1.2384e-03, 4.6703e-04, 7.0801e-04, 1.5179e-03,
        1.1871e-03, 8.4981e-04, 1.8652e-03, 1.1963e-02, 2.6171e-02, 2.3097e-02,
        6.3899e-02, 5.6500e-02, 1.0838e-01, 1.9795e-01, 9.7369e-02, 2.5302e-01,
        1.5050e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:39,279][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0260, 0.0532, 0.0316, 0.0632, 0.0477, 0.0857, 0.0604, 0.0391, 0.0759,
        0.0256, 0.0533, 0.0627, 0.0257, 0.0778, 0.0505, 0.0519, 0.0582, 0.0666,
        0.0448], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:39,281][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0133, 0.1175, 0.0286, 0.1188, 0.0940, 0.1516, 0.0118, 0.1056, 0.0364,
        0.0606, 0.0256, 0.0160, 0.0472, 0.0290, 0.0149, 0.0925, 0.0103, 0.0228,
        0.0033], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:39,283][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0007, 0.0008, 0.0102, 0.0048, 0.0207, 0.0123, 0.0228, 0.0664, 0.0709,
        0.2998, 0.0847, 0.0498, 0.1849, 0.0045, 0.0809, 0.0300, 0.0142, 0.0312,
        0.0102], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:39,285][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0490, 0.0383, 0.0567, 0.0420, 0.0516, 0.0606, 0.0608, 0.0755, 0.0384,
        0.0521, 0.0440, 0.0529, 0.0572, 0.0503, 0.0586, 0.0625, 0.0569, 0.0609,
        0.0316], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:39,286][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ to] are: tensor([5.3554e-05, 4.4447e-04, 5.5444e-04, 7.0649e-05, 4.1977e-05, 5.3859e-03,
        1.7560e-04, 1.3650e-04, 8.1414e-05, 6.2335e-05, 9.8548e-05, 2.2224e-04,
        6.9622e-04, 8.8832e-05, 4.3764e-04, 9.8108e-01, 1.7335e-04, 1.0198e-02,
        2.1656e-07], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:39,288][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ to] are: tensor([1.9202e-11, 3.2242e-10, 2.5229e-09, 4.4927e-09, 3.6714e-08, 2.5555e-08,
        7.5730e-08, 2.2893e-07, 5.0845e-07, 1.4164e-05, 9.2470e-06, 4.2344e-05,
        4.3995e-04, 4.5928e-04, 7.8382e-03, 1.5987e-02, 6.9951e-02, 2.1843e-01,
        6.8683e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:39,290][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0096, 0.0020, 0.0045, 0.0041, 0.0051, 0.0086, 0.0122, 0.0210, 0.0304,
        0.0193, 0.0373, 0.0607, 0.0926, 0.0502, 0.1654, 0.0453, 0.0780, 0.2147,
        0.1391], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:39,291][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0505, 0.0364, 0.0295, 0.0783, 0.0445, 0.0429, 0.0370, 0.0398, 0.1577,
        0.0270, 0.1268, 0.0524, 0.0219, 0.0374, 0.0378, 0.0533, 0.0373, 0.0143,
        0.0754], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:39,316][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:21:39,317][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:39,318][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:39,318][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:39,319][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:39,320][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:39,321][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:39,321][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:39,323][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:39,324][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:39,325][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:39,326][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:39,327][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:39,329][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.8118, 0.1882], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:39,330][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0199, 0.9801], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:39,332][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.8784, 0.1216], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:39,333][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.9530, 0.0470], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:39,335][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.4863, 0.5137], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:39,337][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.1605, 0.8395], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:39,338][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.7495, 0.2505], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:39,340][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.2845, 0.7155], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:39,341][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.3724, 0.6276], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:39,343][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.9157, 0.0843], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:39,344][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.1112, 0.8888], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:39,346][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.4743, 0.5257], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:39,348][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Anthony] are: tensor([0.7638, 0.1114, 0.1247], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:39,349][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Anthony] are: tensor([0.0130, 0.0437, 0.9433], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:39,351][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Anthony] are: tensor([0.0643, 0.9211, 0.0146], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:39,352][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Anthony] are: tensor([0.9486, 0.0267, 0.0247], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:39,354][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Anthony] are: tensor([0.2323, 0.5329, 0.2348], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:39,356][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Anthony] are: tensor([0.0722, 0.6183, 0.3095], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:39,357][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Anthony] are: tensor([0.4221, 0.2099, 0.3681], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:39,359][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Anthony] are: tensor([0.1817, 0.4898, 0.3284], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:39,360][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Anthony] are: tensor([0.1735, 0.4260, 0.4005], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:39,362][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Anthony] are: tensor([0.8718, 0.0721, 0.0561], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:39,364][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Anthony] are: tensor([0.0767, 0.4052, 0.5181], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:39,365][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Anthony] are: tensor([0.2896, 0.3332, 0.3772], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:39,367][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.6929, 0.0978, 0.1026, 0.1068], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:39,369][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.1731, 0.0660, 0.5196, 0.2413], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:39,370][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0871, 0.3348, 0.5734, 0.0047], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:39,372][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.9453, 0.0201, 0.0177, 0.0169], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:39,373][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.1483, 0.4083, 0.1427, 0.3007], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:39,373][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0534, 0.3133, 0.2888, 0.3445], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:39,374][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.4524, 0.1511, 0.2531, 0.1434], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:39,375][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.1392, 0.3447, 0.2536, 0.2625], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:39,376][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.1049, 0.2349, 0.3530, 0.3072], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:39,377][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.8839, 0.0420, 0.0339, 0.0402], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:39,379][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0642, 0.2503, 0.3047, 0.3808], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:39,380][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.2118, 0.2523, 0.2949, 0.2410], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:39,382][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Travis] are: tensor([0.7430, 0.0645, 0.0628, 0.0715, 0.0583], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:39,384][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Travis] are: tensor([0.0128, 0.0349, 0.3869, 0.1539, 0.4115], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:39,385][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Travis] are: tensor([0.0084, 0.4115, 0.2420, 0.3368, 0.0012], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:39,387][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Travis] are: tensor([0.9648, 0.0100, 0.0080, 0.0083, 0.0088], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:39,388][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Travis] are: tensor([0.0910, 0.3002, 0.1455, 0.3436, 0.1197], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:39,390][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Travis] are: tensor([0.0328, 0.2774, 0.1813, 0.3889, 0.1196], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:39,392][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Travis] are: tensor([0.2324, 0.1260, 0.2295, 0.1473, 0.2648], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:39,393][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Travis] are: tensor([0.1076, 0.2920, 0.1982, 0.2318, 0.1704], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:39,395][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Travis] are: tensor([0.0671, 0.2103, 0.2287, 0.3109, 0.1830], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:39,397][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Travis] are: tensor([0.7774, 0.0572, 0.0433, 0.0569, 0.0650], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:39,398][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Travis] are: tensor([0.0754, 0.2106, 0.2307, 0.2990, 0.1843], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:39,400][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Travis] are: tensor([0.1544, 0.1731, 0.2176, 0.1834, 0.2715], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:39,401][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.6535, 0.0649, 0.0710, 0.0763, 0.0657, 0.0686], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:39,403][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.0121, 0.0334, 0.3014, 0.1379, 0.3266, 0.1886], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:39,404][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([8.2613e-03, 3.5498e-01, 1.3940e-02, 5.8259e-01, 4.0048e-02, 1.8481e-04],
       device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:39,406][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.9500, 0.0111, 0.0098, 0.0100, 0.0115, 0.0077], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:39,407][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.1405, 0.2018, 0.0757, 0.3561, 0.0791, 0.1468], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:39,409][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.0354, 0.2172, 0.1422, 0.2655, 0.1512, 0.1884], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:39,411][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.3144, 0.1051, 0.1747, 0.1002, 0.1733, 0.1324], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:39,412][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.0897, 0.2409, 0.1601, 0.1800, 0.1422, 0.1870], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:39,414][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.0570, 0.1446, 0.1719, 0.1684, 0.2241, 0.2340], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:39,416][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.7019, 0.0541, 0.0555, 0.0776, 0.1013, 0.0096], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:39,417][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.0414, 0.1415, 0.1603, 0.2137, 0.1214, 0.3217], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:39,419][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.1331, 0.1653, 0.1863, 0.1450, 0.2313, 0.1390], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:39,420][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.6782, 0.0512, 0.0508, 0.0551, 0.0485, 0.0521, 0.0640],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:39,422][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0070, 0.0342, 0.2577, 0.1282, 0.2881, 0.1895, 0.0954],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:39,423][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([4.6640e-03, 2.4742e-01, 1.2486e-02, 4.6194e-01, 1.4768e-01, 1.2576e-01,
        4.9605e-05], device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:39,425][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.9546, 0.0084, 0.0069, 0.0068, 0.0080, 0.0050, 0.0103],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:39,426][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.1220, 0.1741, 0.0846, 0.2600, 0.0889, 0.1472, 0.1233],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:39,428][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0244, 0.1542, 0.1267, 0.2086, 0.1199, 0.2717, 0.0945],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:39,430][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.2902, 0.0952, 0.1533, 0.0880, 0.1565, 0.1167, 0.1001],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:39,431][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0772, 0.1962, 0.1387, 0.1511, 0.1240, 0.1516, 0.1612],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:39,433][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0304, 0.0776, 0.1242, 0.1371, 0.2280, 0.3117, 0.0911],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:39,435][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.7392, 0.0541, 0.0481, 0.0658, 0.0836, 0.0082, 0.0010],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:39,436][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0470, 0.1138, 0.1188, 0.1572, 0.0925, 0.2185, 0.2522],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:39,436][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.1154, 0.1344, 0.1589, 0.1421, 0.1998, 0.1381, 0.1113],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:39,437][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ lot] are: tensor([0.5215, 0.0633, 0.0614, 0.0658, 0.0572, 0.0635, 0.0798, 0.0875],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:39,438][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ lot] are: tensor([0.0111, 0.0279, 0.1758, 0.1018, 0.2134, 0.1530, 0.0890, 0.2280],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:39,439][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ lot] are: tensor([3.7720e-03, 1.9501e-01, 2.9982e-01, 3.5189e-02, 3.4299e-01, 1.9987e-02,
        1.0301e-01, 2.2649e-04], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:39,441][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ lot] are: tensor([0.9218, 0.0117, 0.0095, 0.0094, 0.0109, 0.0074, 0.0146, 0.0148],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:39,442][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ lot] are: tensor([0.0788, 0.1531, 0.0393, 0.1910, 0.0526, 0.1217, 0.2001, 0.1634],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:39,444][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ lot] are: tensor([0.0156, 0.1305, 0.1215, 0.1811, 0.0962, 0.1881, 0.0961, 0.1708],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:39,446][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ lot] are: tensor([0.2260, 0.0891, 0.1400, 0.0873, 0.1459, 0.1126, 0.0995, 0.0997],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:39,447][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ lot] are: tensor([0.0616, 0.1709, 0.1180, 0.1361, 0.1023, 0.1348, 0.1427, 0.1336],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:39,449][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ lot] are: tensor([0.0234, 0.0769, 0.1027, 0.1067, 0.1708, 0.3017, 0.0831, 0.1347],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:39,451][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ lot] are: tensor([0.7225, 0.0528, 0.0526, 0.0750, 0.0839, 0.0105, 0.0013, 0.0015],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:39,452][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ lot] are: tensor([0.0255, 0.0848, 0.0932, 0.1202, 0.0696, 0.1764, 0.2040, 0.2263],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:39,454][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ lot] are: tensor([0.1042, 0.1134, 0.1294, 0.1103, 0.1738, 0.1094, 0.0915, 0.1680],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:39,456][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([0.7164, 0.0372, 0.0316, 0.0367, 0.0315, 0.0340, 0.0414, 0.0486, 0.0226],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:39,457][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([0.0041, 0.0275, 0.1765, 0.0998, 0.2072, 0.1330, 0.0714, 0.2173, 0.0632],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:39,459][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([4.9841e-04, 5.4283e-03, 4.4944e-02, 9.6481e-03, 3.0936e-02, 8.9080e-03,
        9.6174e-03, 8.9002e-01, 7.5896e-07], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:39,460][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([0.9740, 0.0040, 0.0029, 0.0031, 0.0032, 0.0019, 0.0039, 0.0044, 0.0027],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:39,462][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([0.0345, 0.0807, 0.0964, 0.1115, 0.0700, 0.0475, 0.0997, 0.4141, 0.0457],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:39,464][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([0.0187, 0.1085, 0.0824, 0.1532, 0.0941, 0.1617, 0.0915, 0.2138, 0.0761],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:39,465][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([0.2210, 0.0799, 0.1268, 0.0749, 0.1268, 0.0960, 0.0859, 0.0830, 0.1058],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:39,467][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([0.0573, 0.1502, 0.1058, 0.1178, 0.0951, 0.1199, 0.1269, 0.1162, 0.1108],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:39,469][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([0.0211, 0.0479, 0.1172, 0.0879, 0.1836, 0.2061, 0.0799, 0.1671, 0.0892],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:39,470][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([0.7860, 0.0520, 0.0368, 0.0499, 0.0652, 0.0067, 0.0009, 0.0013, 0.0013],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:39,472][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([0.0841, 0.0933, 0.0811, 0.1095, 0.0666, 0.1308, 0.1518, 0.1859, 0.0969],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:39,474][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([0.0855, 0.1004, 0.1169, 0.1066, 0.1478, 0.1029, 0.0855, 0.1394, 0.1151],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:39,475][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ fun] are: tensor([0.5441, 0.0487, 0.0478, 0.0522, 0.0460, 0.0489, 0.0609, 0.0669, 0.0352,
        0.0492], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:39,477][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ fun] are: tensor([0.0105, 0.0308, 0.1331, 0.0832, 0.1673, 0.1158, 0.0769, 0.1759, 0.0970,
        0.1095], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:39,479][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ fun] are: tensor([0.0033, 0.0427, 0.0106, 0.0147, 0.2357, 0.1251, 0.0095, 0.0153, 0.5422,
        0.0008], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:39,481][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ fun] are: tensor([0.9158, 0.0091, 0.0076, 0.0076, 0.0086, 0.0055, 0.0107, 0.0119, 0.0075,
        0.0158], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:39,482][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ fun] are: tensor([0.0412, 0.1063, 0.0412, 0.1001, 0.0370, 0.1905, 0.1221, 0.2640, 0.0612,
        0.0364], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:39,484][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ fun] are: tensor([0.0143, 0.0937, 0.0638, 0.1124, 0.0579, 0.1062, 0.0735, 0.1836, 0.0888,
        0.2058], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:39,486][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ fun] are: tensor([0.1300, 0.0688, 0.1046, 0.0762, 0.1153, 0.1045, 0.0910, 0.0919, 0.1159,
        0.1019], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:39,487][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ fun] are: tensor([0.0506, 0.1365, 0.0923, 0.1074, 0.0798, 0.1107, 0.1121, 0.1034, 0.0990,
        0.1083], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:39,489][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ fun] are: tensor([0.0172, 0.0426, 0.0705, 0.0626, 0.1022, 0.2536, 0.0647, 0.1670, 0.1137,
        0.1059], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:39,491][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ fun] are: tensor([0.7167, 0.0595, 0.0488, 0.0775, 0.0801, 0.0098, 0.0013, 0.0017, 0.0018,
        0.0027], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:39,493][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ fun] are: tensor([0.0351, 0.0719, 0.0710, 0.0920, 0.0559, 0.1237, 0.1434, 0.1638, 0.0827,
        0.1605], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:39,494][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ fun] are: tensor([0.0756, 0.0900, 0.0995, 0.0890, 0.1312, 0.0858, 0.0710, 0.1283, 0.0966,
        0.1330], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:39,496][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.5341, 0.0444, 0.0444, 0.0485, 0.0429, 0.0456, 0.0567, 0.0627, 0.0313,
        0.0468, 0.0428], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:39,497][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.0024, 0.0169, 0.1273, 0.0672, 0.1726, 0.1243, 0.0619, 0.1779, 0.0671,
        0.0878, 0.0945], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:39,498][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([2.8400e-02, 7.6695e-01, 4.0397e-03, 4.2050e-02, 5.0011e-02, 1.8063e-02,
        1.5864e-02, 5.5260e-03, 5.1619e-02, 1.7387e-02, 9.2550e-05],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:39,499][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.9184, 0.0079, 0.0066, 0.0065, 0.0073, 0.0045, 0.0089, 0.0100, 0.0058,
        0.0134, 0.0106], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:39,499][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.0506, 0.1353, 0.0500, 0.1639, 0.0315, 0.0692, 0.1252, 0.1766, 0.0818,
        0.0589, 0.0570], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:39,501][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.0109, 0.0681, 0.0569, 0.0999, 0.0533, 0.1126, 0.0644, 0.1789, 0.0680,
        0.2310, 0.0560], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:39,502][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.1870, 0.0669, 0.1063, 0.0617, 0.1088, 0.0770, 0.0699, 0.0700, 0.0857,
        0.0799, 0.0869], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:39,504][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.0478, 0.1179, 0.0846, 0.0926, 0.0775, 0.0982, 0.1022, 0.0999, 0.0859,
        0.1044, 0.0890], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:39,506][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.0147, 0.0340, 0.0686, 0.0569, 0.1052, 0.1765, 0.0763, 0.1654, 0.1038,
        0.1197, 0.0788], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:39,507][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([7.2336e-01, 5.6720e-02, 4.7888e-02, 6.9031e-02, 8.7096e-02, 8.4681e-03,
        1.2085e-03, 1.5351e-03, 1.6192e-03, 2.4344e-03, 6.3613e-04],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:39,509][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.0273, 0.0624, 0.0612, 0.0789, 0.0475, 0.1084, 0.1272, 0.1453, 0.0709,
        0.1443, 0.1266], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:39,511][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.0685, 0.0758, 0.0905, 0.0821, 0.1210, 0.0766, 0.0666, 0.1177, 0.0879,
        0.1266, 0.0869], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:39,512][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.5683, 0.0376, 0.0374, 0.0405, 0.0365, 0.0371, 0.0470, 0.0529, 0.0260,
        0.0402, 0.0366, 0.0398], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:39,514][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0100, 0.0216, 0.0885, 0.0518, 0.1226, 0.1002, 0.0568, 0.1728, 0.0745,
        0.0885, 0.1125, 0.1002], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:39,515][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([2.4936e-04, 4.0380e-02, 4.9828e-03, 2.2516e-02, 4.3090e-02, 2.0191e-02,
        1.5359e-04, 4.9659e-03, 5.9049e-01, 7.2633e-03, 2.6571e-01, 1.3343e-05],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:39,517][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.9267, 0.0059, 0.0048, 0.0048, 0.0054, 0.0033, 0.0067, 0.0075, 0.0044,
        0.0104, 0.0084, 0.0117], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:39,519][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0675, 0.1152, 0.0742, 0.1423, 0.0558, 0.0688, 0.1013, 0.1148, 0.0541,
        0.0545, 0.0699, 0.0817], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:39,520][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.0086, 0.0575, 0.0499, 0.0934, 0.0491, 0.1072, 0.0520, 0.1682, 0.0531,
        0.2450, 0.0676, 0.0484], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:39,522][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.1472, 0.0599, 0.0968, 0.0579, 0.1035, 0.0730, 0.0664, 0.0673, 0.0837,
        0.0790, 0.0856, 0.0795], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:39,524][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0426, 0.1080, 0.0796, 0.0871, 0.0699, 0.0883, 0.0932, 0.0892, 0.0804,
        0.0925, 0.0813, 0.0879], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:39,525][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0107, 0.0308, 0.0521, 0.0606, 0.0868, 0.1277, 0.0521, 0.1316, 0.0923,
        0.1670, 0.1482, 0.0402], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:39,527][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([7.0936e-01, 5.7600e-02, 5.2194e-02, 7.4511e-02, 8.9613e-02, 8.2669e-03,
        1.1824e-03, 1.3503e-03, 1.5986e-03, 2.4490e-03, 6.7658e-04, 1.1947e-03],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:39,528][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0303, 0.0560, 0.0543, 0.0717, 0.0428, 0.0934, 0.1095, 0.1265, 0.0622,
        0.1255, 0.1090, 0.1188], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:39,530][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0600, 0.0727, 0.0839, 0.0785, 0.1075, 0.0782, 0.0611, 0.1039, 0.0837,
        0.1135, 0.0824, 0.0746], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:39,532][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ hospital] are: tensor([0.5255, 0.0394, 0.0383, 0.0418, 0.0378, 0.0381, 0.0473, 0.0539, 0.0270,
        0.0418, 0.0374, 0.0406, 0.0311], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:39,534][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ hospital] are: tensor([0.0018, 0.0232, 0.1097, 0.0517, 0.1090, 0.0798, 0.0438, 0.1381, 0.0553,
        0.0766, 0.0684, 0.0797, 0.1628], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:39,535][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ hospital] are: tensor([0.0335, 0.5069, 0.0413, 0.0185, 0.0606, 0.0487, 0.0178, 0.0647, 0.0093,
        0.0751, 0.0074, 0.1096, 0.0067], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:39,537][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ hospital] are: tensor([0.9137, 0.0066, 0.0052, 0.0053, 0.0059, 0.0035, 0.0069, 0.0080, 0.0047,
        0.0107, 0.0086, 0.0117, 0.0092], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:39,539][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ hospital] are: tensor([0.0329, 0.1267, 0.0316, 0.1204, 0.0437, 0.1006, 0.0994, 0.0833, 0.0825,
        0.0382, 0.0595, 0.1431, 0.0381], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:39,540][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ hospital] are: tensor([0.0068, 0.0502, 0.0398, 0.0675, 0.0375, 0.0801, 0.0549, 0.1527, 0.0558,
        0.2082, 0.0590, 0.0616, 0.1260], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:39,542][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ hospital] are: tensor([0.0716, 0.0469, 0.0759, 0.0560, 0.0868, 0.0747, 0.0685, 0.0706, 0.0880,
        0.0830, 0.0878, 0.0882, 0.1019], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:39,544][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ hospital] are: tensor([0.0366, 0.1034, 0.0692, 0.0822, 0.0607, 0.0866, 0.0850, 0.0843, 0.0755,
        0.0883, 0.0764, 0.0799, 0.0719], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:39,545][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ hospital] are: tensor([0.0137, 0.0355, 0.0334, 0.0530, 0.0413, 0.1048, 0.0568, 0.1329, 0.1124,
        0.1394, 0.1478, 0.0592, 0.0698], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:39,547][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ hospital] are: tensor([0.6989, 0.0609, 0.0535, 0.0817, 0.0842, 0.0083, 0.0013, 0.0012, 0.0017,
        0.0024, 0.0008, 0.0015, 0.0036], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:39,549][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ hospital] are: tensor([0.0388, 0.0569, 0.0535, 0.0704, 0.0442, 0.0843, 0.0967, 0.1130, 0.0587,
        0.1103, 0.0945, 0.1016, 0.0770], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:39,551][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ hospital] are: tensor([0.0539, 0.0617, 0.0748, 0.0630, 0.1014, 0.0655, 0.0487, 0.0965, 0.0669,
        0.1060, 0.0651, 0.0647, 0.1318], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:39,552][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.4772, 0.0386, 0.0382, 0.0414, 0.0378, 0.0377, 0.0467, 0.0530, 0.0267,
        0.0411, 0.0373, 0.0400, 0.0320, 0.0524], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:39,554][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.0036, 0.0305, 0.1030, 0.0516, 0.1083, 0.0686, 0.0426, 0.1039, 0.0542,
        0.0631, 0.0568, 0.0604, 0.1374, 0.1159], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:39,555][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([2.0397e-04, 9.7980e-04, 1.3698e-02, 1.9533e-04, 1.1335e-01, 1.7594e-02,
        1.5079e-02, 7.2615e-02, 1.1454e-03, 1.1559e-01, 1.1195e-02, 1.6262e-02,
        6.2105e-01, 1.0453e-03], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:39,557][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.8799, 0.0075, 0.0061, 0.0061, 0.0070, 0.0040, 0.0074, 0.0088, 0.0050,
        0.0114, 0.0092, 0.0121, 0.0101, 0.0254], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:39,558][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.0353, 0.0767, 0.0647, 0.0952, 0.0534, 0.0567, 0.1209, 0.1040, 0.0564,
        0.0426, 0.0600, 0.1236, 0.0406, 0.0698], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:39,559][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.0072, 0.0424, 0.0335, 0.0687, 0.0383, 0.0732, 0.0430, 0.1230, 0.0438,
        0.1505, 0.0550, 0.0476, 0.1750, 0.0987], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:39,560][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.1191, 0.0512, 0.0814, 0.0511, 0.0853, 0.0651, 0.0594, 0.0580, 0.0740,
        0.0663, 0.0745, 0.0696, 0.0811, 0.0639], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:39,561][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0367, 0.0927, 0.0705, 0.0736, 0.0612, 0.0753, 0.0811, 0.0746, 0.0684,
        0.0815, 0.0702, 0.0754, 0.0706, 0.0683], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:39,563][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.0131, 0.0260, 0.0512, 0.0428, 0.0715, 0.0926, 0.0536, 0.1145, 0.0741,
        0.1253, 0.1154, 0.0534, 0.1117, 0.0549], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:39,564][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([6.5708e-01, 5.6341e-02, 5.8685e-02, 8.8981e-02, 1.1507e-01, 9.1291e-03,
        1.4608e-03, 1.3965e-03, 1.9859e-03, 2.6871e-03, 8.7472e-04, 1.6258e-03,
        4.4929e-03, 1.9503e-04], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:39,565][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.0193, 0.0458, 0.0462, 0.0599, 0.0362, 0.0792, 0.0923, 0.1055, 0.0505,
        0.1040, 0.0896, 0.0978, 0.0706, 0.1030], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:39,567][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.0501, 0.0563, 0.0729, 0.0614, 0.0870, 0.0589, 0.0514, 0.0819, 0.0687,
        0.0932, 0.0650, 0.0642, 0.1218, 0.0671], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:39,569][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Anthony] are: tensor([0.4974, 0.0318, 0.0353, 0.0393, 0.0359, 0.0346, 0.0463, 0.0491, 0.0243,
        0.0393, 0.0338, 0.0375, 0.0294, 0.0499, 0.0162], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:39,571][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Anthony] are: tensor([0.0009, 0.0142, 0.1302, 0.0457, 0.1355, 0.0766, 0.0359, 0.0953, 0.0353,
        0.0432, 0.0341, 0.0389, 0.1042, 0.1106, 0.0993], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:39,572][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Anthony] are: tensor([1.3334e-03, 2.9591e-02, 1.0918e-04, 8.6670e-03, 2.2358e-01, 1.5640e-02,
        9.3670e-03, 6.1390e-02, 3.3989e-02, 6.1633e-02, 5.8389e-03, 4.9845e-02,
        4.4858e-01, 5.0217e-02, 2.1420e-04], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:39,574][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Anthony] are: tensor([0.8952, 0.0057, 0.0046, 0.0048, 0.0053, 0.0032, 0.0061, 0.0073, 0.0038,
        0.0096, 0.0075, 0.0102, 0.0082, 0.0218, 0.0068], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:39,576][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Anthony] are: tensor([0.0339, 0.0882, 0.0283, 0.1122, 0.0433, 0.0567, 0.1045, 0.0911, 0.0595,
        0.0371, 0.0604, 0.1205, 0.0466, 0.0912, 0.0265], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:39,577][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Anthony] are: tensor([0.0033, 0.0321, 0.0163, 0.0520, 0.0211, 0.0624, 0.0360, 0.1478, 0.0376,
        0.1668, 0.0461, 0.0424, 0.1753, 0.1024, 0.0582], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:39,579][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Anthony] are: tensor([0.0564, 0.0375, 0.0651, 0.0449, 0.0817, 0.0579, 0.0536, 0.0594, 0.0690,
        0.0758, 0.0699, 0.0706, 0.0930, 0.0714, 0.0938], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:39,581][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Anthony] are: tensor([0.0321, 0.0876, 0.0618, 0.0705, 0.0538, 0.0740, 0.0749, 0.0694, 0.0649,
        0.0740, 0.0644, 0.0718, 0.0637, 0.0655, 0.0716], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:39,583][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Anthony] are: tensor([0.0094, 0.0234, 0.0234, 0.0397, 0.0446, 0.0878, 0.0484, 0.1111, 0.0926,
        0.1233, 0.1272, 0.0524, 0.0868, 0.0539, 0.0761], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:39,584][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Anthony] are: tensor([6.2308e-01, 6.7874e-02, 6.1679e-02, 1.1035e-01, 1.0548e-01, 1.0943e-02,
        2.0153e-03, 1.5702e-03, 2.5959e-03, 3.3223e-03, 1.2347e-03, 2.5017e-03,
        6.3156e-03, 3.5406e-04, 6.8927e-04], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:39,586][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Anthony] are: tensor([0.0166, 0.0400, 0.0414, 0.0546, 0.0325, 0.0739, 0.0889, 0.0990, 0.0477,
        0.1013, 0.0885, 0.0966, 0.0682, 0.1004, 0.0504], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:39,587][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Anthony] are: tensor([0.0444, 0.0509, 0.0593, 0.0558, 0.0785, 0.0571, 0.0442, 0.0811, 0.0583,
        0.0875, 0.0544, 0.0579, 0.1162, 0.0630, 0.0913], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:39,589][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.4147, 0.0372, 0.0386, 0.0413, 0.0384, 0.0383, 0.0475, 0.0527, 0.0273,
        0.0410, 0.0373, 0.0396, 0.0319, 0.0497, 0.0200, 0.0446],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:39,591][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0008, 0.0185, 0.1053, 0.0420, 0.0936, 0.0476, 0.0277, 0.0854, 0.0322,
        0.0496, 0.0336, 0.0445, 0.1192, 0.1407, 0.0814, 0.0778],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:39,592][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([2.0650e-02, 5.7307e-01, 2.1989e-03, 7.5430e-02, 1.5773e-02, 6.3726e-03,
        2.0766e-03, 7.9930e-03, 1.0104e-02, 5.0494e-03, 4.5143e-03, 4.2553e-02,
        3.8735e-02, 1.9232e-01, 3.0182e-03, 1.4324e-04], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:39,594][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.7752, 0.0102, 0.0092, 0.0090, 0.0106, 0.0064, 0.0114, 0.0138, 0.0077,
        0.0169, 0.0138, 0.0180, 0.0150, 0.0348, 0.0139, 0.0342],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:39,596][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.0393, 0.0878, 0.0316, 0.1151, 0.0374, 0.0645, 0.0858, 0.0496, 0.0707,
        0.0463, 0.0620, 0.0973, 0.0575, 0.1074, 0.0343, 0.0135],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:39,598][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.0051, 0.0397, 0.0259, 0.0572, 0.0275, 0.0463, 0.0391, 0.0932, 0.0405,
        0.1329, 0.0492, 0.0499, 0.1519, 0.1004, 0.0758, 0.0654],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:39,599][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.0883, 0.0416, 0.0687, 0.0436, 0.0744, 0.0561, 0.0512, 0.0514, 0.0637,
        0.0594, 0.0644, 0.0617, 0.0736, 0.0574, 0.0747, 0.0699],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:39,601][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0309, 0.0832, 0.0577, 0.0657, 0.0511, 0.0689, 0.0707, 0.0644, 0.0607,
        0.0704, 0.0626, 0.0655, 0.0595, 0.0608, 0.0663, 0.0615],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:39,603][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.0145, 0.0325, 0.0370, 0.0424, 0.0410, 0.0754, 0.0467, 0.1218, 0.0757,
        0.0967, 0.0788, 0.0483, 0.0738, 0.0532, 0.0954, 0.0668],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:39,604][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([6.0804e-01, 6.1495e-02, 6.6728e-02, 1.0519e-01, 1.2890e-01, 9.9414e-03,
        1.8312e-03, 1.5460e-03, 2.4816e-03, 3.1395e-03, 1.1582e-03, 2.2585e-03,
        5.6348e-03, 3.0266e-04, 6.9485e-04, 6.5983e-04], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:39,606][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0119, 0.0356, 0.0402, 0.0513, 0.0323, 0.0735, 0.0849, 0.0917, 0.0471,
        0.0924, 0.0819, 0.0891, 0.0625, 0.0887, 0.0506, 0.0663],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:39,608][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.0415, 0.0518, 0.0568, 0.0497, 0.0752, 0.0464, 0.0419, 0.0739, 0.0539,
        0.0824, 0.0537, 0.0563, 0.1036, 0.0578, 0.0854, 0.0697],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:39,610][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.4180, 0.0324, 0.0355, 0.0382, 0.0366, 0.0358, 0.0450, 0.0496, 0.0249,
        0.0379, 0.0340, 0.0363, 0.0292, 0.0453, 0.0176, 0.0430, 0.0409],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:39,611][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0011, 0.0166, 0.0915, 0.0392, 0.0937, 0.0552, 0.0301, 0.0936, 0.0423,
        0.0523, 0.0438, 0.0513, 0.1124, 0.1003, 0.0733, 0.0735, 0.0300],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:39,613][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([4.8571e-03, 3.6942e-01, 2.1377e-03, 1.2830e-01, 2.3693e-02, 2.9064e-02,
        2.9744e-06, 1.9343e-02, 1.8381e-01, 9.9780e-03, 8.8203e-02, 5.1402e-03,
        4.3780e-02, 3.9337e-02, 4.6892e-03, 4.8236e-02, 6.5914e-06],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:39,615][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.7804, 0.0081, 0.0075, 0.0074, 0.0087, 0.0052, 0.0093, 0.0117, 0.0060,
        0.0145, 0.0114, 0.0151, 0.0126, 0.0305, 0.0113, 0.0305, 0.0300],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:39,616][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0530, 0.0842, 0.0367, 0.1222, 0.0377, 0.0604, 0.0597, 0.1023, 0.0452,
        0.0336, 0.0512, 0.0898, 0.0346, 0.0837, 0.0348, 0.0215, 0.0495],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:39,618][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0046, 0.0326, 0.0292, 0.0522, 0.0274, 0.0656, 0.0219, 0.0859, 0.0328,
        0.1206, 0.0379, 0.0367, 0.1380, 0.0921, 0.0912, 0.1035, 0.0277],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:39,620][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0910, 0.0403, 0.0652, 0.0404, 0.0718, 0.0509, 0.0466, 0.0477, 0.0589,
        0.0554, 0.0601, 0.0559, 0.0697, 0.0526, 0.0683, 0.0647, 0.0606],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:39,621][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0302, 0.0758, 0.0554, 0.0607, 0.0495, 0.0613, 0.0651, 0.0640, 0.0570,
        0.0663, 0.0575, 0.0622, 0.0576, 0.0571, 0.0636, 0.0569, 0.0596],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:39,622][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0075, 0.0190, 0.0285, 0.0337, 0.0552, 0.0758, 0.0230, 0.0670, 0.0593,
        0.1022, 0.0887, 0.0335, 0.0831, 0.0439, 0.0843, 0.1651, 0.0302],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:39,623][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([5.9120e-01, 6.6885e-02, 6.9869e-02, 1.0933e-01, 1.3204e-01, 1.0458e-02,
        1.8589e-03, 1.5785e-03, 2.4215e-03, 3.0500e-03, 1.1453e-03, 2.2319e-03,
        5.6883e-03, 3.1184e-04, 7.3203e-04, 6.5836e-04, 5.3508e-04],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:39,625][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0130, 0.0336, 0.0366, 0.0488, 0.0299, 0.0681, 0.0798, 0.0881, 0.0438,
        0.0886, 0.0771, 0.0839, 0.0586, 0.0846, 0.0451, 0.0622, 0.0582],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:39,626][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0395, 0.0474, 0.0551, 0.0504, 0.0695, 0.0481, 0.0381, 0.0725, 0.0551,
        0.0733, 0.0532, 0.0496, 0.0948, 0.0539, 0.0817, 0.0712, 0.0467],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:39,628][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ drink] are: tensor([0.3315, 0.0343, 0.0390, 0.0420, 0.0410, 0.0396, 0.0488, 0.0522, 0.0276,
        0.0413, 0.0363, 0.0394, 0.0328, 0.0498, 0.0202, 0.0470, 0.0443, 0.0329],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:39,630][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ drink] are: tensor([0.0005, 0.0184, 0.0918, 0.0403, 0.0800, 0.0462, 0.0266, 0.0707, 0.0331,
        0.0467, 0.0305, 0.0432, 0.1011, 0.1310, 0.0708, 0.0782, 0.0281, 0.0626],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:39,632][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ drink] are: tensor([0.0246, 0.3873, 0.0033, 0.0265, 0.0175, 0.1482, 0.0026, 0.0214, 0.0011,
        0.0160, 0.0006, 0.0574, 0.0896, 0.1140, 0.0065, 0.0633, 0.0181, 0.0019],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:39,633][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ drink] are: tensor([0.6613, 0.0114, 0.0113, 0.0110, 0.0133, 0.0079, 0.0135, 0.0164, 0.0087,
        0.0198, 0.0160, 0.0206, 0.0177, 0.0404, 0.0169, 0.0389, 0.0403, 0.0346],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:39,635][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ drink] are: tensor([0.0352, 0.0662, 0.0319, 0.0786, 0.0350, 0.0681, 0.0692, 0.0800, 0.0585,
        0.0354, 0.0422, 0.1069, 0.0461, 0.0940, 0.0345, 0.0345, 0.0519, 0.0317],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:39,637][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ drink] are: tensor([0.0040, 0.0309, 0.0280, 0.0482, 0.0270, 0.0439, 0.0355, 0.0802, 0.0313,
        0.1013, 0.0364, 0.0416, 0.1137, 0.0782, 0.0849, 0.1004, 0.0458, 0.0686],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:39,639][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ drink] are: tensor([0.0498, 0.0317, 0.0492, 0.0377, 0.0574, 0.0504, 0.0456, 0.0477, 0.0595,
        0.0534, 0.0599, 0.0586, 0.0656, 0.0572, 0.0679, 0.0689, 0.0652, 0.0743],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:39,641][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ drink] are: tensor([0.0257, 0.0714, 0.0505, 0.0596, 0.0435, 0.0608, 0.0626, 0.0599, 0.0547,
        0.0621, 0.0554, 0.0592, 0.0527, 0.0559, 0.0588, 0.0537, 0.0570, 0.0564],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:39,642][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ drink] are: tensor([0.0083, 0.0193, 0.0255, 0.0297, 0.0423, 0.0763, 0.0262, 0.0831, 0.0663,
        0.0776, 0.0741, 0.0351, 0.0606, 0.0409, 0.0743, 0.1204, 0.0354, 0.1046],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:39,644][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ drink] are: tensor([5.0306e-01, 7.5296e-02, 8.6242e-02, 1.4626e-01, 1.4960e-01, 1.2996e-02,
        2.5353e-03, 1.7179e-03, 3.0818e-03, 3.5306e-03, 1.5479e-03, 3.2041e-03,
        6.9570e-03, 4.8148e-04, 9.9708e-04, 9.2577e-04, 8.0569e-04, 7.6034e-04],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:39,646][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ drink] are: tensor([0.0111, 0.0323, 0.0369, 0.0482, 0.0306, 0.0667, 0.0768, 0.0825, 0.0424,
        0.0828, 0.0723, 0.0789, 0.0561, 0.0785, 0.0446, 0.0587, 0.0558, 0.0450],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:39,647][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ drink] are: tensor([0.0344, 0.0422, 0.0474, 0.0434, 0.0646, 0.0429, 0.0335, 0.0635, 0.0460,
        0.0698, 0.0450, 0.0443, 0.0921, 0.0499, 0.0725, 0.0628, 0.0416, 0.1042],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:39,649][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.3959, 0.0275, 0.0321, 0.0354, 0.0356, 0.0332, 0.0426, 0.0457, 0.0227,
        0.0368, 0.0304, 0.0331, 0.0268, 0.0418, 0.0151, 0.0394, 0.0376, 0.0276,
        0.0407], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:39,651][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0002, 0.0103, 0.0957, 0.0355, 0.0904, 0.0566, 0.0255, 0.0682, 0.0232,
        0.0331, 0.0249, 0.0365, 0.1009, 0.1211, 0.0779, 0.0757, 0.0230, 0.0591,
        0.0421], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:39,652][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([3.2912e-03, 1.2753e-01, 9.4342e-05, 4.9374e-03, 2.0537e-03, 9.0199e-03,
        7.4484e-04, 4.2586e-03, 3.0526e-03, 3.7466e-02, 1.0757e-03, 1.8896e-02,
        1.1574e-02, 7.0413e-03, 2.5741e-04, 1.4073e-02, 5.7940e-03, 7.4884e-01,
        1.1705e-06], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:39,654][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.7380, 0.0075, 0.0073, 0.0072, 0.0083, 0.0050, 0.0090, 0.0112, 0.0054,
        0.0137, 0.0108, 0.0141, 0.0119, 0.0288, 0.0105, 0.0300, 0.0295, 0.0254,
        0.0263], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:39,656][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0308, 0.0611, 0.0429, 0.0850, 0.0416, 0.0626, 0.0708, 0.0452, 0.0660,
        0.0356, 0.0528, 0.0670, 0.0332, 0.0755, 0.0452, 0.0414, 0.0530, 0.0520,
        0.0383], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:39,658][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0036, 0.0244, 0.0222, 0.0444, 0.0274, 0.0532, 0.0247, 0.0874, 0.0288,
        0.0936, 0.0327, 0.0296, 0.1223, 0.0681, 0.0747, 0.1089, 0.0339, 0.0978,
        0.0220], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:39,660][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0805, 0.0361, 0.0582, 0.0362, 0.0624, 0.0451, 0.0420, 0.0420, 0.0523,
        0.0487, 0.0530, 0.0497, 0.0605, 0.0462, 0.0594, 0.0561, 0.0534, 0.0678,
        0.0503], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:39,662][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0273, 0.0680, 0.0500, 0.0546, 0.0452, 0.0570, 0.0586, 0.0554, 0.0514,
        0.0587, 0.0525, 0.0556, 0.0520, 0.0511, 0.0576, 0.0520, 0.0539, 0.0561,
        0.0430], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:39,663][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0056, 0.0152, 0.0313, 0.0255, 0.0432, 0.0594, 0.0255, 0.0552, 0.0421,
        0.0664, 0.0534, 0.0247, 0.0669, 0.0344, 0.0892, 0.1347, 0.0342, 0.1750,
        0.0182], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:39,665][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([5.0034e-01, 6.4685e-02, 8.7110e-02, 1.3423e-01, 1.7267e-01, 1.2102e-02,
        2.5159e-03, 1.7835e-03, 3.2391e-03, 3.5957e-03, 1.6570e-03, 3.2421e-03,
        6.9823e-03, 4.7999e-04, 1.0592e-03, 9.0185e-04, 8.0543e-04, 7.6738e-04,
        1.8256e-03], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:39,667][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0100, 0.0285, 0.0327, 0.0450, 0.0274, 0.0650, 0.0764, 0.0834, 0.0408,
        0.0840, 0.0727, 0.0795, 0.0541, 0.0781, 0.0415, 0.0565, 0.0532, 0.0417,
        0.0294], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:39,668][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0327, 0.0415, 0.0471, 0.0439, 0.0605, 0.0422, 0.0343, 0.0575, 0.0487,
        0.0619, 0.0467, 0.0454, 0.0794, 0.0484, 0.0702, 0.0591, 0.0423, 0.0916,
        0.0465], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:39,672][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:21:39,674][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[10564],
        [ 3996],
        [ 4733],
        [ 2314],
        [    2],
        [  682],
        [  348],
        [ 2165],
        [ 1708],
        [ 9660],
        [ 2209],
        [ 1692],
        [10218],
        [ 2120],
        [ 1251],
        [ 3980],
        [  747],
        [ 5286],
        [  292]], device='cuda:0')
[2024-07-24 10:21:39,676][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[22026],
        [12187],
        [10714],
        [21538],
        [    6],
        [18204],
        [ 9565],
        [16835],
        [19759],
        [32441],
        [19305],
        [15257],
        [20123],
        [11598],
        [10995],
        [19617],
        [15686],
        [27188],
        [14114]], device='cuda:0')
[2024-07-24 10:21:39,678][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[49438],
        [40216],
        [29770],
        [21131],
        [19327],
        [16983],
        [30322],
        [24513],
        [13400],
        [21947],
        [16651],
        [18951],
        [24163],
        [32133],
        [25376],
        [16975],
        [21157],
        [20846],
        [18601]], device='cuda:0')
[2024-07-24 10:21:39,680][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[17013],
        [17764],
        [ 4500],
        [ 4113],
        [ 1262],
        [  617],
        [  670],
        [  404],
        [  449],
        [  405],
        [  292],
        [  571],
        [  836],
        [  942],
        [ 1043],
        [  765],
        [  843],
        [ 1092],
        [ 1181]], device='cuda:0')
[2024-07-24 10:21:39,682][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 7270],
        [ 7031],
        [ 5744],
        [34399],
        [29300],
        [ 4774],
        [ 6714],
        [30561],
        [35021],
        [15840],
        [13936],
        [19266],
        [32003],
        [34227],
        [21871],
        [12352],
        [12633],
        [27673],
        [24011]], device='cuda:0')
[2024-07-24 10:21:39,684][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[31136],
        [26684],
        [14560],
        [14852],
        [13703],
        [11183],
        [11788],
        [12413],
        [12417],
        [12713],
        [13615],
        [14668],
        [16863],
        [16907],
        [13795],
        [13274],
        [13953],
        [17745],
        [17719]], device='cuda:0')
[2024-07-24 10:21:39,685][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[15010],
        [16304],
        [10983],
        [13121],
        [ 8216],
        [12093],
        [10190],
        [ 9541],
        [ 4868],
        [ 8142],
        [ 8861],
        [ 8515],
        [10335],
        [ 8134],
        [ 9786],
        [10888],
        [ 9686],
        [ 9184],
        [ 9113]], device='cuda:0')
[2024-07-24 10:21:39,687][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[37075],
        [39909],
        [39243],
        [39385],
        [39994],
        [42932],
        [47367],
        [44978],
        [46740],
        [44491],
        [46417],
        [45878],
        [44949],
        [46837],
        [43959],
        [43602],
        [45993],
        [45870],
        [47442]], device='cuda:0')
[2024-07-24 10:21:39,689][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[23251],
        [19855],
        [ 8720],
        [ 8940],
        [ 6645],
        [ 6049],
        [ 6002],
        [ 5055],
        [ 4916],
        [ 3001],
        [ 3053],
        [ 2937],
        [ 2764],
        [ 2718],
        [ 2592],
        [ 2554],
        [ 2561],
        [ 2482],
        [ 2501]], device='cuda:0')
[2024-07-24 10:21:39,691][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[2745],
        [2876],
        [5027],
        [4986],
        [5766],
        [5435],
        [6120],
        [6380],
        [6568],
        [6501],
        [6421],
        [6422],
        [6240],
        [6460],
        [6699],
        [6474],
        [6707],
        [6434],
        [6442]], device='cuda:0')
[2024-07-24 10:21:39,693][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[44301],
        [43609],
        [35227],
        [27936],
        [23949],
        [19059],
        [17290],
        [17160],
        [15131],
        [18074],
        [20112],
        [13349],
        [27212],
        [30217],
        [30291],
        [30695],
        [ 5821],
        [21954],
        [ 5899]], device='cuda:0')
[2024-07-24 10:21:39,694][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[ 8063],
        [ 3887],
        [ 6114],
        [ 3159],
        [ 7716],
        [10471],
        [ 7013],
        [ 5405],
        [ 2791],
        [ 6143],
        [ 7417],
        [ 6417],
        [10152],
        [15592],
        [10051],
        [ 5600],
        [ 3636],
        [ 4152],
        [ 1455]], device='cuda:0')
[2024-07-24 10:21:39,696][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[ 8797],
        [23461],
        [19824],
        [20387],
        [20111],
        [17975],
        [16032],
        [18971],
        [17994],
        [19297],
        [19224],
        [19493],
        [23656],
        [22341],
        [26832],
        [24598],
        [24444],
        [26727],
        [26018]], device='cuda:0')
[2024-07-24 10:21:39,698][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[ 8348],
        [11176],
        [16766],
        [30298],
        [36860],
        [35655],
        [31518],
        [26476],
        [22325],
        [24523],
        [16273],
        [15563],
        [20832],
        [17120],
        [21442],
        [21276],
        [16970],
        [19147],
        [16827]], device='cuda:0')
[2024-07-24 10:21:39,700][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 8780],
        [  982],
        [14536],
        [ 5325],
        [ 8116],
        [ 4436],
        [ 5735],
        [28583],
        [14904],
        [11448],
        [30190],
        [20502],
        [40256],
        [11323],
        [22816],
        [25434],
        [10493],
        [ 8244],
        [19461]], device='cuda:0')
[2024-07-24 10:21:39,702][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[5703],
        [6164],
        [6060],
        [6018],
        [6033],
        [6141],
        [6071],
        [6166],
        [5950],
        [6044],
        [6026],
        [6006],
        [5961],
        [6010],
        [5973],
        [6029],
        [6066],
        [6128],
        [6144]], device='cuda:0')
[2024-07-24 10:21:39,704][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[18009],
        [12845],
        [ 8228],
        [ 8408],
        [ 5776],
        [ 4655],
        [ 4291],
        [ 4431],
        [ 4809],
        [ 4730],
        [ 4844],
        [ 5145],
        [ 5215],
        [ 5205],
        [ 5911],
        [ 5769],
        [ 5492],
        [ 5287],
        [ 5341]], device='cuda:0')
[2024-07-24 10:21:39,706][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[12476],
        [11734],
        [16788],
        [ 5759],
        [26623],
        [39178],
        [42703],
        [28616],
        [29576],
        [32486],
        [20380],
        [21199],
        [23900],
        [14360],
        [21149],
        [24906],
        [35427],
        [31607],
        [24020]], device='cuda:0')
[2024-07-24 10:21:39,708][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[9551],
        [9649],
        [9657],
        [9643],
        [9597],
        [9613],
        [9582],
        [9600],
        [9560],
        [9592],
        [9570],
        [9555],
        [9562],
        [9593],
        [9574],
        [9578],
        [9537],
        [9551],
        [9535]], device='cuda:0')
[2024-07-24 10:21:39,710][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[22484],
        [24021],
        [28146],
        [27233],
        [27133],
        [25589],
        [26243],
        [26245],
        [24620],
        [25438],
        [26056],
        [25723],
        [25772],
        [25811],
        [25672],
        [25901],
        [25838],
        [26176],
        [26287]], device='cuda:0')
[2024-07-24 10:21:39,712][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[8605],
        [7064],
        [7392],
        [6932],
        [6236],
        [6256],
        [6291],
        [6515],
        [6392],
        [6716],
        [6680],
        [6523],
        [5864],
        [5494],
        [5687],
        [5516],
        [5543],
        [5313],
        [5250]], device='cuda:0')
[2024-07-24 10:21:39,714][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[4171],
        [4206],
        [5145],
        [4875],
        [5772],
        [5273],
        [5460],
        [5969],
        [6224],
        [7130],
        [6375],
        [6872],
        [7607],
        [7127],
        [7711],
        [7451],
        [7413],
        [8046],
        [7713]], device='cuda:0')
[2024-07-24 10:21:39,716][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[36813],
        [39086],
        [37076],
        [37651],
        [36583],
        [36405],
        [36558],
        [36919],
        [36864],
        [36864],
        [36930],
        [37102],
        [37689],
        [37732],
        [37411],
        [37354],
        [37340],
        [37377],
        [37296]], device='cuda:0')
[2024-07-24 10:21:39,718][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[19212],
        [20159],
        [19992],
        [21027],
        [20874],
        [18130],
        [17290],
        [17369],
        [18555],
        [17753],
        [18546],
        [19117],
        [19981],
        [20129],
        [20141],
        [19878],
        [19096],
        [18707],
        [18256]], device='cuda:0')
[2024-07-24 10:21:39,719][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[14564],
        [14051],
        [13109],
        [13169],
        [11776],
        [10799],
        [11256],
        [11078],
        [11868],
        [11030],
        [11082],
        [10916],
        [10792],
        [10240],
        [ 9978],
        [ 9736],
        [ 9623],
        [ 8945],
        [ 8893]], device='cuda:0')
[2024-07-24 10:21:39,722][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[17597],
        [13402],
        [11487],
        [10845],
        [11098],
        [10101],
        [ 9353],
        [ 8848],
        [ 8926],
        [ 8088],
        [ 7583],
        [ 7508],
        [ 7772],
        [ 7753],
        [ 7916],
        [ 7910],
        [ 7842],
        [ 7889],
        [ 7838]], device='cuda:0')
[2024-07-24 10:21:39,723][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[23497],
        [22231],
        [17343],
        [17783],
        [18076],
        [20105],
        [20796],
        [23655],
        [23165],
        [24935],
        [24176],
        [23944],
        [23383],
        [23679],
        [22706],
        [22352],
        [22350],
        [22845],
        [22610]], device='cuda:0')
[2024-07-24 10:21:39,725][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[26736],
        [24919],
        [24411],
        [26594],
        [24076],
        [22884],
        [22647],
        [26309],
        [26700],
        [24085],
        [25911],
        [25222],
        [25765],
        [27805],
        [26808],
        [24916],
        [23758],
        [25118],
        [27467]], device='cuda:0')
[2024-07-24 10:21:39,727][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[25142],
        [45161],
        [29105],
        [30816],
        [28675],
        [24083],
        [26999],
        [17655],
        [21152],
        [39663],
        [17181],
        [27389],
        [19793],
        [31372],
        [20220],
        [22217],
        [27000],
        [30785],
        [13061]], device='cuda:0')
[2024-07-24 10:21:39,729][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[20063],
        [20063],
        [20063],
        [20063],
        [20063],
        [20063],
        [20063],
        [20063],
        [20063],
        [20063],
        [20063],
        [20063],
        [20063],
        [20063],
        [20063],
        [20063],
        [20063],
        [20063],
        [20063]], device='cuda:0')
[2024-07-24 10:21:39,772][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:21:39,773][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:39,775][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:39,776][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:39,777][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:39,777][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:39,778][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:39,779][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:39,779][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:39,780][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:39,781][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:39,781][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:39,782][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:39,783][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.8118, 0.1882], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:39,783][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.4419, 0.5581], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:39,784][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.4348, 0.5652], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:39,785][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.6658, 0.3342], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:39,786][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.1035, 0.8965], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:39,786][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0058, 0.9942], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:39,787][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0655, 0.9345], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:39,789][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.1446, 0.8554], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:39,790][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.3555, 0.6445], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:39,792][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.9775, 0.0225], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:39,793][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.7666, 0.2334], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:39,795][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.9854, 0.0146], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:39,797][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Anthony] are: tensor([0.7444, 0.1072, 0.1483], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:39,798][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Anthony] are: tensor([0.2818, 0.3878, 0.3305], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:39,800][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Anthony] are: tensor([0.2646, 0.3770, 0.3584], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:39,801][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Anthony] are: tensor([0.6037, 0.3254, 0.0709], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:39,803][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Anthony] are: tensor([0.0091, 0.2229, 0.7680], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:39,805][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Anthony] are: tensor([0.0024, 0.1393, 0.8583], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:39,806][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Anthony] are: tensor([0.0340, 0.5975, 0.3685], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:39,808][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Anthony] are: tensor([0.0912, 0.4974, 0.4114], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:39,809][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Anthony] are: tensor([0.3358, 0.5599, 0.1044], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:39,811][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Anthony] are: tensor([0.3773, 0.5696, 0.0531], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:39,813][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Anthony] are: tensor([0.6311, 0.2017, 0.1673], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:39,814][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Anthony] are: tensor([0.5385, 0.4287, 0.0328], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:39,816][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.5278, 0.1105, 0.1845, 0.1772], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:39,817][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.2074, 0.2798, 0.2390, 0.2737], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:39,819][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.1885, 0.2628, 0.2767, 0.2720], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:39,821][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.5358, 0.3473, 0.0871, 0.0298], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:39,822][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0049, 0.0905, 0.4423, 0.4622], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:39,824][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0016, 0.1000, 0.5409, 0.3574], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:39,825][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0181, 0.3353, 0.2338, 0.4127], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:39,826][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0508, 0.2878, 0.2490, 0.4124], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:39,827][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.1876, 0.3393, 0.2513, 0.2217], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:39,828][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.4595, 0.3775, 0.0183, 0.1446], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:39,829][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.5318, 0.1915, 0.1640, 0.1127], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:39,829][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.8283, 0.1028, 0.0126, 0.0563], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:39,831][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Travis] are: tensor([0.4706, 0.0771, 0.1070, 0.0997, 0.2456], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:39,832][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Travis] are: tensor([0.1606, 0.2162, 0.1887, 0.2273, 0.2072], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:39,834][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Travis] are: tensor([0.1427, 0.2068, 0.2111, 0.2226, 0.2169], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:39,836][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Travis] are: tensor([0.5355, 0.3352, 0.0757, 0.0238, 0.0298], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:39,837][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Travis] are: tensor([0.0017, 0.0540, 0.3220, 0.3552, 0.2671], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:39,839][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Travis] are: tensor([0.0004, 0.0464, 0.3829, 0.2333, 0.3370], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:39,840][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Travis] are: tensor([0.0153, 0.2843, 0.1848, 0.3393, 0.1762], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:39,842][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Travis] are: tensor([0.0498, 0.2430, 0.1914, 0.3351, 0.1807], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:39,844][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Travis] are: tensor([0.1423, 0.2687, 0.1418, 0.4264, 0.0208], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:39,845][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Travis] are: tensor([0.1944, 0.2840, 0.0296, 0.4328, 0.0592], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:39,847][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Travis] are: tensor([0.4702, 0.1663, 0.1470, 0.1056, 0.1109], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:39,849][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Travis] are: tensor([0.4195, 0.1475, 0.0479, 0.2422, 0.1430], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:39,850][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.4423, 0.0742, 0.0980, 0.0960, 0.1862, 0.1034], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:39,852][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.1398, 0.1763, 0.1504, 0.1842, 0.1656, 0.1837], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:39,854][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.1206, 0.1661, 0.1789, 0.1852, 0.1852, 0.1640], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:39,855][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.5008, 0.3163, 0.0776, 0.0307, 0.0363, 0.0383], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:39,857][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.0007, 0.0412, 0.2251, 0.2522, 0.1982, 0.2826], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:39,858][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.0009, 0.0551, 0.2829, 0.1872, 0.2534, 0.2205], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:39,860][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.0080, 0.1882, 0.1386, 0.2545, 0.1338, 0.2770], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:39,862][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.0228, 0.1668, 0.1549, 0.2626, 0.1623, 0.2306], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:39,863][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.1275, 0.2469, 0.1152, 0.3300, 0.0919, 0.0884], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:39,865][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.0861, 0.6452, 0.0011, 0.1986, 0.0084, 0.0606], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:39,867][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.4162, 0.1630, 0.1414, 0.1030, 0.1068, 0.0697], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:39,868][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.2760, 0.2142, 0.0147, 0.3621, 0.0880, 0.0450], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:39,870][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.3059, 0.0687, 0.1057, 0.1012, 0.1874, 0.1123, 0.1187],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:39,872][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.1158, 0.1499, 0.1302, 0.1517, 0.1469, 0.1575, 0.1480],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:39,873][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.1037, 0.1423, 0.1395, 0.1529, 0.1530, 0.1496, 0.1590],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:39,875][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.4983, 0.2997, 0.0758, 0.0259, 0.0322, 0.0358, 0.0322],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:39,876][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0020, 0.0357, 0.1851, 0.2043, 0.1621, 0.1868, 0.2240],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:39,878][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0006, 0.0395, 0.2197, 0.1440, 0.2019, 0.1773, 0.2170],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:39,880][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0054, 0.1455, 0.1114, 0.2023, 0.1120, 0.2339, 0.1895],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:39,881][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0152, 0.1329, 0.1283, 0.2196, 0.1363, 0.2017, 0.1661],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:39,883][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.1250, 0.2303, 0.1070, 0.2423, 0.1328, 0.1001, 0.0625],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:39,885][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.1231, 0.1304, 0.0085, 0.4779, 0.0368, 0.1815, 0.0418],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:39,886][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.3657, 0.1430, 0.1315, 0.0965, 0.1021, 0.0669, 0.0944],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:39,888][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.3860, 0.1495, 0.0162, 0.2307, 0.1331, 0.0524, 0.0321],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:39,889][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ lot] are: tensor([0.2623, 0.0608, 0.0862, 0.0902, 0.1538, 0.0965, 0.1030, 0.1471],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:39,890][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ lot] are: tensor([0.0935, 0.1302, 0.1087, 0.1333, 0.1250, 0.1371, 0.1295, 0.1427],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:39,890][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ lot] are: tensor([0.0871, 0.1237, 0.1238, 0.1366, 0.1344, 0.1265, 0.1571, 0.1107],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:39,891][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ lot] are: tensor([0.4840, 0.3028, 0.0697, 0.0233, 0.0287, 0.0328, 0.0307, 0.0279],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:39,892][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ lot] are: tensor([1.0010e-04, 1.3869e-02, 1.4274e-01, 1.5797e-01, 1.3204e-01, 1.8556e-01,
        1.9680e-01, 1.7092e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:39,894][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ lot] are: tensor([0.0007, 0.0382, 0.1829, 0.1215, 0.1723, 0.1449, 0.1780, 0.1614],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:39,895][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ lot] are: tensor([0.0094, 0.1373, 0.0910, 0.1729, 0.0866, 0.1891, 0.1610, 0.1527],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:39,897][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ lot] are: tensor([0.0184, 0.1246, 0.1046, 0.1921, 0.1074, 0.1789, 0.1485, 0.1256],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:39,899][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ lot] are: tensor([0.0935, 0.1321, 0.0928, 0.2460, 0.1576, 0.1276, 0.1355, 0.0149],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:39,900][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ lot] are: tensor([0.1876, 0.1456, 0.0397, 0.3961, 0.0232, 0.1144, 0.0673, 0.0261],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:39,902][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ lot] are: tensor([0.3642, 0.1331, 0.1125, 0.0813, 0.0883, 0.0543, 0.0773, 0.0889],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:39,904][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ lot] are: tensor([0.5041, 0.0688, 0.0127, 0.1594, 0.0517, 0.0173, 0.0634, 0.1225],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:39,905][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ of] are: tensor([0.2008, 0.0511, 0.0800, 0.0772, 0.1436, 0.0864, 0.0882, 0.1172, 0.1555],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:39,907][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ of] are: tensor([0.0861, 0.1131, 0.1009, 0.1160, 0.1097, 0.1217, 0.1172, 0.1303, 0.1050],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:39,909][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ of] are: tensor([0.0776, 0.1075, 0.1126, 0.1177, 0.1165, 0.1100, 0.1371, 0.1037, 0.1171],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:39,911][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ of] are: tensor([0.4313, 0.3009, 0.0701, 0.0269, 0.0323, 0.0345, 0.0323, 0.0380, 0.0338],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:39,912][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ of] are: tensor([0.0007, 0.0233, 0.1276, 0.1470, 0.1233, 0.1464, 0.1704, 0.1198, 0.1416],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:39,914][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ of] are: tensor([0.0003, 0.0247, 0.1549, 0.1027, 0.1530, 0.1343, 0.1620, 0.1500, 0.1183],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:39,916][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ of] are: tensor([0.0055, 0.0945, 0.0684, 0.1255, 0.0684, 0.1359, 0.1127, 0.1228, 0.2662],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:39,917][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ of] are: tensor([0.0134, 0.0963, 0.0889, 0.1516, 0.0938, 0.1359, 0.1129, 0.1076, 0.1994],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:39,919][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ of] are: tensor([0.0666, 0.1671, 0.1117, 0.1844, 0.0931, 0.1275, 0.1904, 0.0124, 0.0469],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:39,920][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ of] are: tensor([0.6393, 0.0509, 0.0038, 0.0375, 0.0054, 0.0101, 0.0063, 0.0120, 0.2348],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:39,922][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ of] are: tensor([0.3499, 0.1128, 0.0931, 0.0672, 0.0727, 0.0454, 0.0710, 0.0708, 0.1171],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:39,924][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ of] are: tensor([0.6716, 0.0160, 0.0057, 0.0148, 0.0195, 0.0038, 0.0083, 0.1101, 0.1501],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:39,926][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ fun] are: tensor([0.1654, 0.0439, 0.0697, 0.0685, 0.1201, 0.0767, 0.0825, 0.1134, 0.1408,
        0.1190], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:39,927][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ fun] are: tensor([0.0733, 0.1016, 0.0850, 0.1055, 0.1000, 0.1075, 0.0999, 0.1204, 0.0922,
        0.1145], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:39,929][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ fun] are: tensor([0.0646, 0.0962, 0.0978, 0.1074, 0.1061, 0.0971, 0.1244, 0.0951, 0.1171,
        0.0942], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:39,930][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ fun] are: tensor([0.4159, 0.2697, 0.0690, 0.0234, 0.0280, 0.0345, 0.0341, 0.0327, 0.0326,
        0.0599], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:39,932][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ fun] are: tensor([0.0002, 0.0161, 0.0994, 0.1211, 0.0971, 0.1391, 0.1596, 0.1049, 0.1256,
        0.1368], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:39,934][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ fun] are: tensor([0.0004, 0.0272, 0.1383, 0.0952, 0.1322, 0.1156, 0.1426, 0.1270, 0.1094,
        0.1121], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:39,936][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ fun] are: tensor([0.0090, 0.0961, 0.0605, 0.1093, 0.0573, 0.1288, 0.1088, 0.1067, 0.2323,
        0.0912], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:39,937][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ fun] are: tensor([0.0185, 0.0954, 0.0736, 0.1399, 0.0750, 0.1300, 0.1077, 0.0878, 0.1934,
        0.0789], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:39,939][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ fun] are: tensor([0.0692, 0.0982, 0.0832, 0.2178, 0.1175, 0.0788, 0.1062, 0.0310, 0.1782,
        0.0199], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:39,941][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ fun] are: tensor([0.1092, 0.0224, 0.0027, 0.0340, 0.0025, 0.0399, 0.0126, 0.0246, 0.6345,
        0.1177], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:39,943][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ fun] are: tensor([0.2806, 0.1059, 0.0964, 0.0686, 0.0746, 0.0457, 0.0651, 0.0726, 0.1215,
        0.0691], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:39,944][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ fun] are: tensor([0.1481, 0.0092, 0.0026, 0.0090, 0.0089, 0.0014, 0.0121, 0.0663, 0.3485,
        0.3940], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:39,946][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.2203, 0.0417, 0.0566, 0.0535, 0.1102, 0.0578, 0.0612, 0.0956, 0.1316,
        0.0979, 0.0736], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:39,948][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.0731, 0.0935, 0.0821, 0.0950, 0.0906, 0.0987, 0.0945, 0.1070, 0.0862,
        0.1082, 0.0713], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:39,949][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.0606, 0.0857, 0.0904, 0.0943, 0.0930, 0.0903, 0.1111, 0.0817, 0.1020,
        0.0942, 0.0968], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:39,950][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.4028, 0.2646, 0.0647, 0.0234, 0.0288, 0.0323, 0.0295, 0.0328, 0.0333,
        0.0547, 0.0332], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:39,951][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.0002, 0.0182, 0.0748, 0.0932, 0.0730, 0.1234, 0.1234, 0.1059, 0.0963,
        0.1402, 0.1516], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:39,952][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.0003, 0.0220, 0.1270, 0.0816, 0.1172, 0.1031, 0.1240, 0.1135, 0.0906,
        0.1001, 0.1207], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:39,953][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.0070, 0.0798, 0.0545, 0.0957, 0.0534, 0.1032, 0.0893, 0.0940, 0.1974,
        0.0928, 0.1328], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:39,954][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0115, 0.0746, 0.0698, 0.1166, 0.0731, 0.1047, 0.0881, 0.0839, 0.1559,
        0.0858, 0.1360], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:39,956][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.0490, 0.1518, 0.0909, 0.1510, 0.0958, 0.1180, 0.1385, 0.0205, 0.0640,
        0.0602, 0.0603], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:39,958][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.3010, 0.0137, 0.0007, 0.0133, 0.0024, 0.0035, 0.0040, 0.0016, 0.2014,
        0.4229, 0.0353], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:39,960][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.2825, 0.0931, 0.0780, 0.0603, 0.0626, 0.0405, 0.0651, 0.0636, 0.0996,
        0.0607, 0.0940], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:39,961][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ at] are: tensor([1.1908e-01, 4.2526e-03, 6.1689e-04, 2.9365e-03, 1.5977e-03, 5.7347e-04,
        1.2309e-03, 2.1106e-02, 1.2133e-01, 6.6997e-01, 5.7306e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:39,963][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.1695, 0.0359, 0.0576, 0.0579, 0.1070, 0.0608, 0.0656, 0.0965, 0.1172,
        0.0975, 0.0678, 0.0668], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:39,964][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0644, 0.0845, 0.0736, 0.0871, 0.0813, 0.0898, 0.0842, 0.0980, 0.0766,
        0.0976, 0.0659, 0.0970], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:39,966][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0544, 0.0783, 0.0767, 0.0838, 0.0861, 0.0827, 0.0929, 0.0748, 0.0938,
        0.0844, 0.0947, 0.0974], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:39,968][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.3374, 0.2540, 0.0729, 0.0222, 0.0305, 0.0321, 0.0291, 0.0372, 0.0305,
        0.0706, 0.0313, 0.0521], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:39,969][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0004, 0.0134, 0.0649, 0.0862, 0.0673, 0.1035, 0.1100, 0.0744, 0.0942,
        0.1195, 0.1444, 0.1216], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:39,971][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0003, 0.0200, 0.1139, 0.0748, 0.1061, 0.0932, 0.1115, 0.1027, 0.0845,
        0.0878, 0.1108, 0.0945], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:39,973][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0034, 0.0653, 0.0481, 0.0890, 0.0487, 0.0984, 0.0823, 0.0845, 0.1929,
        0.0822, 0.1215, 0.0838], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:39,975][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0075, 0.0639, 0.0626, 0.1066, 0.0670, 0.0971, 0.0801, 0.0801, 0.1435,
        0.0806, 0.1258, 0.0850], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:39,976][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0557, 0.1188, 0.0589, 0.1408, 0.0789, 0.0788, 0.0755, 0.0339, 0.0712,
        0.1128, 0.1131, 0.0616], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:39,978][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.1686, 0.0088, 0.0005, 0.0109, 0.0031, 0.0034, 0.0011, 0.0046, 0.1578,
        0.3749, 0.2060, 0.0603], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:39,980][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.2394, 0.0846, 0.0779, 0.0560, 0.0615, 0.0379, 0.0558, 0.0598, 0.0945,
        0.0551, 0.0914, 0.0862], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:39,981][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ the] are: tensor([1.9255e-01, 2.5899e-03, 5.9085e-04, 1.7680e-03, 3.0754e-03, 5.6133e-04,
        1.2439e-03, 1.0748e-02, 6.7262e-02, 5.8694e-01, 1.0413e-01, 2.8543e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:39,983][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ hospital] are: tensor([0.1205, 0.0311, 0.0540, 0.0548, 0.0975, 0.0619, 0.0645, 0.0905, 0.1040,
        0.0915, 0.0611, 0.0629, 0.1059], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:39,984][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ hospital] are: tensor([0.0541, 0.0797, 0.0691, 0.0815, 0.0790, 0.0820, 0.0778, 0.0882, 0.0738,
        0.0922, 0.0628, 0.0908, 0.0692], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:39,986][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ hospital] are: tensor([0.0469, 0.0727, 0.0710, 0.0797, 0.0767, 0.0747, 0.0907, 0.0692, 0.0875,
        0.0725, 0.0909, 0.0998, 0.0677], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:39,988][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ hospital] are: tensor([0.4101, 0.2243, 0.0448, 0.0172, 0.0183, 0.0266, 0.0253, 0.0237, 0.0255,
        0.0417, 0.0303, 0.0408, 0.0714], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:39,990][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ hospital] are: tensor([0.0004, 0.0126, 0.0767, 0.0884, 0.0707, 0.0963, 0.1126, 0.0751, 0.0877,
        0.1088, 0.1180, 0.0985, 0.0543], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:39,991][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ hospital] are: tensor([0.0002, 0.0164, 0.1061, 0.0679, 0.0998, 0.0838, 0.1012, 0.0882, 0.0759,
        0.0811, 0.1007, 0.0807, 0.0980], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:39,993][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ hospital] are: tensor([0.0058, 0.0686, 0.0416, 0.0799, 0.0390, 0.0936, 0.0809, 0.0787, 0.1870,
        0.0684, 0.1177, 0.0852, 0.0536], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:39,995][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ hospital] are: tensor([0.0123, 0.0689, 0.0545, 0.1019, 0.0542, 0.0958, 0.0793, 0.0670, 0.1462,
        0.0612, 0.1318, 0.0873, 0.0396], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:39,997][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ hospital] are: tensor([0.0350, 0.0807, 0.0531, 0.1986, 0.0346, 0.0550, 0.1165, 0.0215, 0.1225,
        0.0479, 0.1272, 0.0874, 0.0201], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:39,998][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ hospital] are: tensor([2.7146e-01, 6.1500e-03, 3.2907e-04, 5.5647e-03, 1.0640e-03, 2.4234e-03,
        1.1380e-03, 1.7872e-03, 5.1502e-02, 8.5461e-02, 4.4354e-01, 4.2503e-02,
        8.7082e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:40,000][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ hospital] are: tensor([0.2281, 0.0743, 0.0695, 0.0485, 0.0557, 0.0344, 0.0505, 0.0550, 0.0921,
        0.0537, 0.0869, 0.0807, 0.0707], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:40,001][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ hospital] are: tensor([0.2595, 0.0048, 0.0015, 0.0029, 0.0024, 0.0013, 0.0012, 0.0063, 0.0629,
        0.2591, 0.1475, 0.0899, 0.1606], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:40,003][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.1047, 0.0263, 0.0475, 0.0506, 0.0937, 0.0542, 0.0572, 0.0910, 0.1039,
        0.0919, 0.0592, 0.0608, 0.1093, 0.0496], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:40,005][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.0540, 0.0720, 0.0611, 0.0726, 0.0689, 0.0770, 0.0741, 0.0830, 0.0688,
        0.0837, 0.0576, 0.0860, 0.0655, 0.0756], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:40,006][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.0484, 0.0674, 0.0684, 0.0710, 0.0710, 0.0689, 0.0838, 0.0647, 0.0758,
        0.0733, 0.0819, 0.0896, 0.0692, 0.0668], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:40,008][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.3841, 0.2189, 0.0484, 0.0175, 0.0206, 0.0261, 0.0210, 0.0274, 0.0259,
        0.0471, 0.0261, 0.0343, 0.0756, 0.0270], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:40,010][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0004, 0.0112, 0.0693, 0.0799, 0.0685, 0.0847, 0.0960, 0.0713, 0.0877,
        0.0941, 0.1087, 0.0944, 0.0538, 0.0801], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:40,011][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.0002, 0.0144, 0.0949, 0.0602, 0.0878, 0.0791, 0.0961, 0.0862, 0.0704,
        0.0731, 0.0930, 0.0808, 0.0818, 0.0821], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:40,012][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0037, 0.0580, 0.0413, 0.0754, 0.0409, 0.0819, 0.0720, 0.0727, 0.1609,
        0.0695, 0.1034, 0.0723, 0.0587, 0.0892], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:40,013][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0089, 0.0603, 0.0546, 0.0935, 0.0568, 0.0852, 0.0714, 0.0663, 0.1278,
        0.0635, 0.1133, 0.0776, 0.0444, 0.0763], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:40,014][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.0341, 0.0884, 0.0604, 0.1072, 0.0379, 0.0605, 0.1769, 0.0191, 0.0487,
        0.0252, 0.0880, 0.1445, 0.0727, 0.0364], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:40,015][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [.] are: tensor([4.4762e-01, 9.9851e-03, 3.6857e-04, 4.7516e-03, 1.0936e-03, 2.2956e-03,
        6.3622e-04, 2.1322e-03, 4.6013e-02, 1.2090e-01, 5.5171e-02, 4.2615e-02,
        4.7314e-02, 2.1910e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:40,016][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.1977, 0.0787, 0.0709, 0.0516, 0.0533, 0.0365, 0.0498, 0.0531, 0.0856,
        0.0511, 0.0766, 0.0721, 0.0662, 0.0569], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:40,018][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [.] are: tensor([1.6475e-01, 1.3623e-03, 4.3515e-04, 1.3348e-03, 1.1418e-03, 2.2227e-04,
        5.6653e-04, 5.4854e-03, 2.6756e-02, 2.3113e-01, 5.9357e-02, 2.7981e-02,
        2.4795e-01, 2.3153e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:40,020][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Anthony] are: tensor([0.2136, 0.0302, 0.0411, 0.0388, 0.0877, 0.0394, 0.0425, 0.0720, 0.0889,
        0.0744, 0.0490, 0.0488, 0.0986, 0.0428, 0.0322], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:40,021][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Anthony] are: tensor([0.0455, 0.0673, 0.0558, 0.0693, 0.0682, 0.0736, 0.0684, 0.0784, 0.0638,
        0.0842, 0.0541, 0.0799, 0.0616, 0.0720, 0.0580], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:40,023][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Anthony] are: tensor([0.0406, 0.0626, 0.0591, 0.0690, 0.0661, 0.0641, 0.0790, 0.0601, 0.0759,
        0.0657, 0.0775, 0.0884, 0.0610, 0.0687, 0.0620], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:40,025][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Anthony] are: tensor([0.3922, 0.2084, 0.0365, 0.0132, 0.0140, 0.0208, 0.0187, 0.0218, 0.0216,
        0.0394, 0.0230, 0.0321, 0.0667, 0.0281, 0.0634], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:40,026][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Anthony] are: tensor([0.0006, 0.0135, 0.0700, 0.0798, 0.0669, 0.0864, 0.0944, 0.0737, 0.0786,
        0.0913, 0.1013, 0.0844, 0.0511, 0.0683, 0.0397], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:40,028][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Anthony] are: tensor([5.5784e-05, 9.7636e-03, 8.7619e-02, 5.1211e-02, 7.7475e-02, 7.1432e-02,
        9.0235e-02, 7.8674e-02, 6.4530e-02, 6.6604e-02, 8.7876e-02, 6.9618e-02,
        8.3138e-02, 7.6581e-02, 8.5186e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:40,029][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Anthony] are: tensor([0.0032, 0.0535, 0.0345, 0.0667, 0.0338, 0.0832, 0.0681, 0.0674, 0.1635,
        0.0619, 0.1031, 0.0723, 0.0495, 0.0857, 0.0537], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:40,031][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Anthony] are: tensor([0.0097, 0.0603, 0.0470, 0.0894, 0.0489, 0.0837, 0.0676, 0.0588, 0.1236,
        0.0572, 0.1123, 0.0755, 0.0383, 0.0757, 0.0519], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:40,033][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Anthony] are: tensor([0.0544, 0.0870, 0.0194, 0.1356, 0.0335, 0.0496, 0.0872, 0.0253, 0.0971,
        0.0368, 0.1447, 0.0845, 0.0743, 0.0540, 0.0166], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:40,034][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Anthony] are: tensor([2.5263e-01, 4.6698e-03, 1.1048e-04, 2.1441e-03, 6.4733e-04, 3.9111e-04,
        5.1263e-04, 6.9288e-04, 4.2360e-02, 2.6549e-02, 2.4107e-02, 4.6770e-02,
        1.3235e-01, 4.0925e-01, 5.6814e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:40,036][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Anthony] are: tensor([0.2638, 0.0657, 0.0548, 0.0368, 0.0396, 0.0267, 0.0417, 0.0442, 0.0673,
        0.0388, 0.0660, 0.0573, 0.0561, 0.0481, 0.0931], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:40,037][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Anthony] are: tensor([2.0228e-01, 1.4344e-03, 5.5967e-05, 4.5491e-04, 3.9518e-04, 1.8317e-04,
        3.8056e-04, 2.7884e-03, 1.7881e-02, 4.8517e-02, 4.0211e-02, 3.0371e-02,
        2.3941e-01, 3.5693e-01, 5.8709e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:40,039][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.1079, 0.0264, 0.0451, 0.0465, 0.0839, 0.0484, 0.0519, 0.0855, 0.0924,
        0.0853, 0.0535, 0.0548, 0.0979, 0.0439, 0.0327, 0.0439],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:40,041][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0453, 0.0626, 0.0529, 0.0654, 0.0620, 0.0680, 0.0651, 0.0744, 0.0604,
        0.0779, 0.0518, 0.0774, 0.0567, 0.0680, 0.0545, 0.0575],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:40,043][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0381, 0.0572, 0.0618, 0.0622, 0.0630, 0.0570, 0.0746, 0.0567, 0.0690,
        0.0615, 0.0734, 0.0840, 0.0587, 0.0627, 0.0658, 0.0544],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:40,044][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.3590, 0.1989, 0.0401, 0.0153, 0.0160, 0.0213, 0.0193, 0.0204, 0.0203,
        0.0367, 0.0216, 0.0298, 0.0630, 0.0250, 0.0619, 0.0513],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:40,046][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.0001, 0.0092, 0.0550, 0.0625, 0.0485, 0.0916, 0.0811, 0.0780, 0.0637,
        0.0992, 0.1072, 0.0848, 0.0475, 0.0570, 0.0292, 0.0854],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:40,048][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.0002, 0.0142, 0.0800, 0.0519, 0.0709, 0.0661, 0.0809, 0.0717, 0.0588,
        0.0646, 0.0792, 0.0652, 0.0757, 0.0769, 0.0724, 0.0714],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:40,050][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0028, 0.0497, 0.0344, 0.0655, 0.0341, 0.0738, 0.0627, 0.0636, 0.1442,
        0.0597, 0.0903, 0.0654, 0.0523, 0.0838, 0.0550, 0.0626],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:40,052][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0072, 0.0526, 0.0463, 0.0828, 0.0493, 0.0710, 0.0620, 0.0583, 0.1118,
        0.0590, 0.0993, 0.0688, 0.0413, 0.0707, 0.0549, 0.0647],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:40,053][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.0527, 0.0845, 0.0432, 0.1296, 0.0636, 0.0772, 0.0669, 0.0168, 0.0846,
        0.0341, 0.0877, 0.0754, 0.0647, 0.0658, 0.0387, 0.0145],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:40,055][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([3.6768e-01, 1.0855e-02, 1.0080e-04, 1.7879e-03, 2.8586e-04, 1.6494e-03,
        3.7470e-04, 6.7523e-04, 1.6522e-02, 3.9785e-02, 3.5665e-02, 1.7094e-02,
        4.5646e-02, 4.0880e-01, 2.0927e-02, 3.2156e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:40,056][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.1760, 0.0606, 0.0562, 0.0403, 0.0441, 0.0304, 0.0444, 0.0454, 0.0696,
        0.0447, 0.0662, 0.0627, 0.0557, 0.0489, 0.0934, 0.0613],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:40,058][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([3.3793e-01, 3.1599e-03, 7.4424e-05, 7.2530e-04, 4.0070e-04, 9.7521e-05,
        3.1224e-04, 4.2666e-03, 2.1121e-02, 5.1018e-02, 2.8954e-02, 9.7887e-03,
        8.7538e-02, 3.5019e-01, 5.1433e-02, 5.2990e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:40,059][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.1319, 0.0269, 0.0448, 0.0438, 0.0813, 0.0438, 0.0474, 0.0771, 0.0901,
        0.0771, 0.0505, 0.0514, 0.0926, 0.0407, 0.0312, 0.0427, 0.0265],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:40,061][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0451, 0.0600, 0.0522, 0.0616, 0.0594, 0.0632, 0.0598, 0.0687, 0.0553,
        0.0702, 0.0473, 0.0689, 0.0561, 0.0632, 0.0530, 0.0582, 0.0575],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:40,063][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0389, 0.0558, 0.0542, 0.0597, 0.0596, 0.0590, 0.0624, 0.0503, 0.0665,
        0.0597, 0.0691, 0.0735, 0.0563, 0.0591, 0.0562, 0.0573, 0.0624],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:40,065][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.3203, 0.1904, 0.0413, 0.0140, 0.0159, 0.0196, 0.0177, 0.0217, 0.0189,
        0.0386, 0.0206, 0.0290, 0.0645, 0.0230, 0.0631, 0.0521, 0.0495],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:40,067][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0004, 0.0101, 0.0568, 0.0659, 0.0518, 0.0734, 0.0794, 0.0549, 0.0647,
        0.0835, 0.0924, 0.0731, 0.0456, 0.0580, 0.0323, 0.0791, 0.0785],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:40,068][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0002, 0.0125, 0.0763, 0.0488, 0.0700, 0.0630, 0.0756, 0.0688, 0.0551,
        0.0588, 0.0741, 0.0640, 0.0647, 0.0671, 0.0711, 0.0649, 0.0650],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:40,070][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0021, 0.0448, 0.0337, 0.0641, 0.0348, 0.0728, 0.0615, 0.0599, 0.1378,
        0.0575, 0.0839, 0.0615, 0.0504, 0.0772, 0.0547, 0.0614, 0.0421],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:40,072][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0045, 0.0443, 0.0452, 0.0781, 0.0494, 0.0697, 0.0582, 0.0595, 0.1056,
        0.0595, 0.0921, 0.0630, 0.0424, 0.0651, 0.0534, 0.0630, 0.0472],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:40,074][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0457, 0.0902, 0.0474, 0.1136, 0.0526, 0.0478, 0.0311, 0.0276, 0.0712,
        0.0656, 0.0853, 0.0489, 0.0935, 0.0716, 0.0431, 0.0304, 0.0344],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:40,075][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ a] are: tensor([7.6901e-02, 7.2244e-04, 2.5838e-05, 6.6077e-04, 7.6350e-05, 2.7054e-04,
        5.1080e-05, 3.0308e-04, 8.8301e-03, 2.2484e-02, 1.4234e-02, 5.3006e-03,
        2.6161e-02, 1.7856e-01, 1.1736e-02, 6.0624e-01, 4.7443e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:40,076][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.1680, 0.0582, 0.0552, 0.0389, 0.0432, 0.0280, 0.0408, 0.0428, 0.0661,
        0.0404, 0.0623, 0.0596, 0.0511, 0.0439, 0.0904, 0.0541, 0.0571],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:40,077][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ a] are: tensor([1.9459e-01, 5.9484e-04, 4.4299e-05, 1.6811e-04, 2.2588e-04, 4.6090e-05,
        2.7248e-05, 1.9480e-03, 6.7000e-03, 8.2048e-02, 1.2000e-02, 9.3955e-03,
        7.9848e-02, 3.2594e-01, 7.7529e-02, 1.5575e-01, 5.3143e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:40,078][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ drink] are: tensor([0.1022, 0.0252, 0.0444, 0.0440, 0.0775, 0.0440, 0.0477, 0.0791, 0.0870,
        0.0767, 0.0490, 0.0497, 0.0896, 0.0408, 0.0328, 0.0411, 0.0265, 0.0425],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:40,080][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ drink] are: tensor([0.0394, 0.0565, 0.0494, 0.0591, 0.0562, 0.0602, 0.0572, 0.0646, 0.0531,
        0.0663, 0.0452, 0.0662, 0.0509, 0.0600, 0.0511, 0.0548, 0.0543, 0.0555],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:40,082][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ drink] are: tensor([0.0328, 0.0505, 0.0525, 0.0557, 0.0550, 0.0528, 0.0653, 0.0495, 0.0612,
        0.0530, 0.0662, 0.0736, 0.0510, 0.0539, 0.0567, 0.0510, 0.0661, 0.0532],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:40,084][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ drink] are: tensor([0.3578, 0.1802, 0.0308, 0.0110, 0.0107, 0.0166, 0.0161, 0.0154, 0.0158,
        0.0270, 0.0184, 0.0242, 0.0482, 0.0185, 0.0462, 0.0421, 0.0431, 0.0781],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:40,085][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ drink] are: tensor([0.0003, 0.0093, 0.0562, 0.0638, 0.0495, 0.0689, 0.0755, 0.0587, 0.0617,
        0.0750, 0.0851, 0.0726, 0.0413, 0.0534, 0.0306, 0.0740, 0.0744, 0.0497],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:40,087][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ drink] are: tensor([0.0001, 0.0103, 0.0728, 0.0445, 0.0649, 0.0572, 0.0710, 0.0628, 0.0505,
        0.0561, 0.0676, 0.0547, 0.0675, 0.0640, 0.0673, 0.0597, 0.0592, 0.0700],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:40,089][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ drink] are: tensor([0.0050, 0.0533, 0.0323, 0.0605, 0.0305, 0.0769, 0.0679, 0.0582, 0.1367,
        0.0470, 0.0823, 0.0657, 0.0380, 0.0711, 0.0439, 0.0574, 0.0449, 0.0282],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:40,091][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ drink] are: tensor([0.0084, 0.0503, 0.0402, 0.0781, 0.0404, 0.0733, 0.0619, 0.0495, 0.1150,
        0.0433, 0.1011, 0.0671, 0.0279, 0.0643, 0.0421, 0.0615, 0.0510, 0.0245],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:40,093][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ drink] are: tensor([0.0220, 0.0516, 0.0637, 0.1181, 0.0416, 0.0467, 0.0974, 0.0133, 0.0579,
        0.0323, 0.0688, 0.0914, 0.0370, 0.0461, 0.0477, 0.0611, 0.0993, 0.0041],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:40,094][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ drink] are: tensor([8.7882e-02, 1.0097e-03, 1.1404e-04, 4.5457e-04, 7.8515e-05, 5.2136e-04,
        2.0933e-04, 2.2089e-04, 1.1320e-02, 1.8484e-02, 8.4770e-03, 1.0678e-02,
        1.5121e-02, 1.8207e-01, 4.0193e-02, 3.3466e-01, 1.2690e-01, 1.6161e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:40,096][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ drink] are: tensor([0.1675, 0.0541, 0.0496, 0.0341, 0.0385, 0.0252, 0.0371, 0.0389, 0.0634,
        0.0376, 0.0604, 0.0558, 0.0493, 0.0411, 0.0867, 0.0532, 0.0540, 0.0537],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:40,097][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ drink] are: tensor([6.0067e-02, 5.9720e-04, 5.6009e-05, 1.6882e-04, 2.3549e-04, 3.9504e-05,
        1.3383e-04, 3.0405e-03, 1.2235e-02, 6.9211e-02, 1.3373e-02, 9.8837e-03,
        9.2397e-02, 1.6248e-01, 6.2858e-02, 1.5957e-01, 1.3182e-01, 2.2182e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:40,099][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.1574, 0.0274, 0.0377, 0.0385, 0.0752, 0.0374, 0.0405, 0.0746, 0.0841,
        0.0697, 0.0440, 0.0436, 0.0859, 0.0377, 0.0265, 0.0407, 0.0228, 0.0385,
        0.0178], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:40,101][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0388, 0.0519, 0.0471, 0.0540, 0.0518, 0.0585, 0.0544, 0.0627, 0.0498,
        0.0617, 0.0423, 0.0621, 0.0493, 0.0565, 0.0484, 0.0517, 0.0527, 0.0567,
        0.0497], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:40,102][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0332, 0.0477, 0.0509, 0.0514, 0.0533, 0.0499, 0.0599, 0.0463, 0.0558,
        0.0533, 0.0590, 0.0669, 0.0522, 0.0509, 0.0534, 0.0517, 0.0607, 0.0557,
        0.0478], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:40,104][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.2763, 0.1569, 0.0360, 0.0135, 0.0148, 0.0184, 0.0162, 0.0207, 0.0189,
        0.0316, 0.0194, 0.0241, 0.0576, 0.0221, 0.0549, 0.0432, 0.0407, 0.0928,
        0.0419], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:40,106][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0003, 0.0090, 0.0512, 0.0573, 0.0469, 0.0655, 0.0702, 0.0531, 0.0590,
        0.0737, 0.0837, 0.0693, 0.0419, 0.0552, 0.0314, 0.0685, 0.0688, 0.0460,
        0.0491], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:40,107][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ to] are: tensor([5.9895e-05, 8.3742e-03, 7.1566e-02, 4.1253e-02, 6.3343e-02, 5.5841e-02,
        6.7902e-02, 6.2643e-02, 4.7276e-02, 5.2872e-02, 6.5754e-02, 5.4931e-02,
        6.0813e-02, 6.0339e-02, 6.7649e-02, 5.7415e-02, 5.7539e-02, 5.9624e-02,
        4.4807e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:40,109][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0028, 0.0465, 0.0298, 0.0584, 0.0284, 0.0651, 0.0572, 0.0543, 0.1329,
        0.0511, 0.0822, 0.0591, 0.0413, 0.0714, 0.0458, 0.0560, 0.0402, 0.0296,
        0.0476], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:40,111][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0052, 0.0432, 0.0414, 0.0721, 0.0436, 0.0636, 0.0532, 0.0525, 0.0989,
        0.0524, 0.0868, 0.0586, 0.0359, 0.0601, 0.0454, 0.0570, 0.0428, 0.0290,
        0.0584], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:40,113][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0264, 0.0810, 0.0478, 0.1135, 0.0266, 0.0855, 0.0902, 0.0122, 0.0434,
        0.0240, 0.0401, 0.1206, 0.0568, 0.0393, 0.0327, 0.0308, 0.0886, 0.0112,
        0.0292], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:40,114][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ to] are: tensor([1.6660e-01, 9.7664e-04, 1.8658e-05, 1.6819e-04, 4.3903e-05, 1.0870e-04,
        4.7788e-05, 9.8492e-05, 1.7406e-03, 5.2091e-03, 5.7954e-04, 2.3826e-03,
        3.5850e-03, 1.0462e-01, 1.0077e-02, 4.5157e-01, 4.9204e-02, 1.6237e-01,
        4.0604e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:40,116][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.1738, 0.0505, 0.0448, 0.0310, 0.0357, 0.0227, 0.0358, 0.0349, 0.0561,
        0.0331, 0.0549, 0.0498, 0.0440, 0.0396, 0.0734, 0.0509, 0.0512, 0.0483,
        0.0698], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:40,117][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ to] are: tensor([8.8299e-02, 1.3230e-04, 6.6905e-06, 2.9677e-05, 2.8685e-05, 6.5892e-06,
        2.5152e-05, 4.5707e-04, 1.5438e-03, 4.7417e-02, 4.6707e-03, 3.8751e-03,
        3.3283e-02, 6.5908e-02, 1.3755e-02, 6.2683e-02, 6.6337e-02, 3.9114e-01,
        2.2041e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:40,167][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:21:40,168][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:40,168][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:40,169][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:40,170][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:40,170][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:40,171][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:40,172][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:40,172][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:40,173][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:40,174][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:40,174][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:40,175][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:40,176][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.7341, 0.2659], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:40,177][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.8525, 0.1475], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:40,178][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.4430, 0.5570], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:40,179][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.9231, 0.0769], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:40,179][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.5597, 0.4403], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:40,180][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.1938, 0.8062], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:40,181][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.9885, 0.0115], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:40,182][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.7844, 0.2156], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:40,182][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.9500, 0.0500], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:40,183][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.9885, 0.0115], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:40,184][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.7384, 0.2616], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:40,184][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.9854, 0.0146], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:40,185][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Anthony] are: tensor([0.6971, 0.1832, 0.1197], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:40,186][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Anthony] are: tensor([0.2916, 0.6323, 0.0761], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:40,186][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Anthony] are: tensor([0.2895, 0.3685, 0.3420], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:40,188][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Anthony] are: tensor([0.1230, 0.6227, 0.2542], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:40,190][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Anthony] are: tensor([0.6215, 0.2978, 0.0807], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:40,191][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Anthony] are: tensor([0.0917, 0.4982, 0.4101], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:40,193][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Anthony] are: tensor([0.4449, 0.4325, 0.1226], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:40,195][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Anthony] are: tensor([0.0419, 0.8834, 0.0748], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:40,196][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Anthony] are: tensor([0.2725, 0.6836, 0.0439], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:40,198][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Anthony] are: tensor([0.4972, 0.4192, 0.0835], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:40,199][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Anthony] are: tensor([0.6235, 0.0742, 0.3023], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:40,201][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Anthony] are: tensor([0.5385, 0.4287, 0.0328], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:40,203][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.4991, 0.1820, 0.0900, 0.2289], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:40,204][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.4411, 0.4369, 0.0494, 0.0726], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:40,206][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.2093, 0.2740, 0.2599, 0.2569], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:40,207][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.1186, 0.0967, 0.1938, 0.5909], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:40,209][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.5066, 0.3214, 0.0787, 0.0934], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:40,211][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0469, 0.2293, 0.3501, 0.3736], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:40,212][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.7747, 0.0692, 0.1088, 0.0473], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:40,214][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0604, 0.0941, 0.1395, 0.7060], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:40,215][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.3475, 0.2214, 0.0341, 0.3970], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:40,217][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.5518, 0.2629, 0.0330, 0.1524], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:40,219][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.6119, 0.1177, 0.0717, 0.1988], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:40,220][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.8283, 0.1028, 0.0126, 0.0563], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:40,222][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Travis] are: tensor([0.5553, 0.1518, 0.0436, 0.1696, 0.0797], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:40,224][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Travis] are: tensor([0.1929, 0.3523, 0.0763, 0.3277, 0.0508], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:40,225][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Travis] are: tensor([0.1764, 0.2200, 0.2082, 0.2113, 0.1841], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:40,226][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Travis] are: tensor([0.0662, 0.0618, 0.0825, 0.6717, 0.1178], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:40,227][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Travis] are: tensor([0.5700, 0.2166, 0.0644, 0.0882, 0.0608], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:40,227][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Travis] are: tensor([0.0354, 0.1773, 0.1659, 0.3117, 0.3097], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:40,228][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Travis] are: tensor([0.3294, 0.1045, 0.1178, 0.2276, 0.2207], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:40,230][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Travis] are: tensor([0.0107, 0.0849, 0.0442, 0.8281, 0.0322], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:40,231][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Travis] are: tensor([0.0936, 0.0751, 0.0169, 0.8019, 0.0125], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:40,233][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Travis] are: tensor([0.2122, 0.2030, 0.0441, 0.4376, 0.1031], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:40,235][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Travis] are: tensor([0.3677, 0.0624, 0.2670, 0.1578, 0.1450], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:40,236][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Travis] are: tensor([0.4195, 0.1475, 0.0479, 0.2422, 0.1430], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:40,238][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.4176, 0.1368, 0.0516, 0.1649, 0.0458, 0.1834], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:40,240][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.1122, 0.3961, 0.0254, 0.4185, 0.0251, 0.0228], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:40,241][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.1398, 0.1801, 0.1722, 0.1732, 0.1540, 0.1808], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:40,243][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.0061, 0.0113, 0.0083, 0.6659, 0.2724, 0.0360], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:40,244][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.4812, 0.2261, 0.0558, 0.0793, 0.0554, 0.1023], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:40,246][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.0217, 0.1136, 0.1757, 0.1933, 0.2559, 0.2398], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:40,248][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.0516, 0.0574, 0.0577, 0.2464, 0.5244, 0.0624], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:40,249][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.0028, 0.0231, 0.0252, 0.7187, 0.1974, 0.0328], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:40,251][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.0205, 0.0727, 0.0079, 0.8316, 0.0378, 0.0294], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:40,253][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.1363, 0.5308, 0.0023, 0.2245, 0.0190, 0.0872], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:40,254][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.2569, 0.1227, 0.0923, 0.3692, 0.0340, 0.1249], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:40,256][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.2760, 0.2142, 0.0147, 0.3621, 0.0880, 0.0450], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:40,258][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.3642, 0.1092, 0.0652, 0.1323, 0.0419, 0.1015, 0.1856],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:40,259][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.1226, 0.4130, 0.0268, 0.3009, 0.0315, 0.0246, 0.0807],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:40,261][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.1220, 0.1539, 0.1460, 0.1479, 0.1299, 0.1520, 0.1485],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:40,263][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0129, 0.0121, 0.0052, 0.3054, 0.5006, 0.1324, 0.0316],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:40,264][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.4833, 0.2391, 0.0452, 0.0613, 0.0483, 0.0855, 0.0373],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:40,266][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0198, 0.0972, 0.1368, 0.1430, 0.1977, 0.2041, 0.2014],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:40,267][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.1580, 0.0557, 0.0465, 0.1794, 0.4201, 0.1100, 0.0303],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:40,269][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0083, 0.0450, 0.0351, 0.5634, 0.1541, 0.1068, 0.0873],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:40,271][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0471, 0.0747, 0.0120, 0.7124, 0.0691, 0.0518, 0.0330],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:40,272][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.1214, 0.0854, 0.0125, 0.4570, 0.0642, 0.2024, 0.0572],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:40,274][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.2194, 0.0341, 0.1388, 0.1350, 0.1070, 0.1807, 0.1850],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:40,276][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.3860, 0.1495, 0.0162, 0.2307, 0.1331, 0.0524, 0.0321],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:40,277][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ lot] are: tensor([0.3490, 0.1055, 0.0304, 0.1342, 0.0289, 0.1031, 0.1434, 0.1055],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:40,279][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ lot] are: tensor([0.1815, 0.3718, 0.0306, 0.2178, 0.0278, 0.0309, 0.0891, 0.0507],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:40,281][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ lot] are: tensor([0.1043, 0.1312, 0.1238, 0.1262, 0.1101, 0.1313, 0.1305, 0.1426],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:40,282][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ lot] are: tensor([0.0357, 0.0120, 0.0062, 0.2897, 0.1991, 0.1191, 0.1689, 0.1691],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:40,284][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ lot] are: tensor([0.5193, 0.1597, 0.0386, 0.0576, 0.0489, 0.0741, 0.0336, 0.0683],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:40,286][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ lot] are: tensor([0.0109, 0.0644, 0.0901, 0.1449, 0.1473, 0.1846, 0.2009, 0.1570],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:40,287][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ lot] are: tensor([0.2716, 0.0779, 0.0291, 0.1952, 0.2282, 0.0699, 0.0690, 0.0592],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:40,288][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ lot] are: tensor([0.0123, 0.0485, 0.0249, 0.5503, 0.0818, 0.0945, 0.0727, 0.1150],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:40,289][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ lot] are: tensor([0.0999, 0.0469, 0.0086, 0.5284, 0.1235, 0.0899, 0.0375, 0.0654],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:40,290][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ lot] are: tensor([0.1975, 0.1049, 0.0532, 0.3450, 0.0352, 0.1394, 0.0875, 0.0373],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:40,291][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ lot] are: tensor([0.3332, 0.0439, 0.0327, 0.0832, 0.0461, 0.2616, 0.0170, 0.1824],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:40,292][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ lot] are: tensor([0.5041, 0.0688, 0.0127, 0.1594, 0.0517, 0.0173, 0.0634, 0.1225],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:40,294][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([0.2924, 0.1047, 0.0483, 0.1245, 0.0371, 0.0934, 0.1249, 0.0607, 0.1141],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:40,295][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([0.5367, 0.1669, 0.0102, 0.0385, 0.0049, 0.0050, 0.0244, 0.0161, 0.1973],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:40,297][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([0.0963, 0.1164, 0.1102, 0.1119, 0.0977, 0.1155, 0.1147, 0.1282, 0.1090],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:40,298][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([1.5432e-02, 8.7336e-05, 2.3802e-05, 4.1595e-04, 3.3826e-04, 2.4551e-04,
        1.3507e-04, 7.0081e-02, 9.1324e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:40,300][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([0.4561, 0.1802, 0.0421, 0.0566, 0.0451, 0.0730, 0.0350, 0.0634, 0.0484],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:40,301][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([0.0106, 0.0629, 0.1109, 0.1034, 0.1620, 0.1350, 0.1562, 0.1523, 0.1067],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:40,303][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([0.4599, 0.0102, 0.0048, 0.0123, 0.0268, 0.0069, 0.0105, 0.0509, 0.4177],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:40,304][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([1.8876e-02, 1.4336e-03, 2.8927e-04, 3.0355e-03, 1.9552e-03, 9.1037e-04,
        2.0312e-03, 1.0313e-02, 9.6116e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:40,306][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([0.2968, 0.0107, 0.0014, 0.0222, 0.0072, 0.0052, 0.0031, 0.0062, 0.6474],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:40,307][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([0.4586, 0.0278, 0.0051, 0.0348, 0.0086, 0.0124, 0.0096, 0.0205, 0.4226],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:40,309][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([0.1468, 0.0402, 0.0557, 0.1069, 0.0268, 0.0721, 0.0438, 0.0187, 0.4890],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:40,311][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([0.6716, 0.0160, 0.0057, 0.0148, 0.0195, 0.0038, 0.0083, 0.1101, 0.1501],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:40,312][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ fun] are: tensor([0.3555, 0.0971, 0.0271, 0.1173, 0.0237, 0.0772, 0.1162, 0.0495, 0.1056,
        0.0308], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:40,314][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ fun] are: tensor([0.4318, 0.1546, 0.0056, 0.0394, 0.0059, 0.0049, 0.0258, 0.0344, 0.2153,
        0.0823], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:40,316][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ fun] are: tensor([0.0829, 0.1047, 0.0980, 0.1003, 0.0868, 0.1042, 0.1055, 0.1184, 0.1028,
        0.0963], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:40,317][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ fun] are: tensor([4.3116e-03, 3.4434e-05, 7.5289e-06, 3.3934e-04, 3.0396e-04, 6.6847e-04,
        5.1719e-05, 1.5605e-03, 8.1797e-01, 1.7476e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:40,319][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ fun] are: tensor([0.4661, 0.1298, 0.0379, 0.0541, 0.0435, 0.0678, 0.0321, 0.0647, 0.0435,
        0.0605], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:40,320][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ fun] are: tensor([0.0121, 0.0668, 0.0828, 0.1132, 0.1275, 0.1643, 0.1400, 0.1276, 0.0962,
        0.0696], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:40,322][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ fun] are: tensor([0.1198, 0.0050, 0.0013, 0.0083, 0.0123, 0.0111, 0.0043, 0.0365, 0.4655,
        0.3359], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:40,323][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ fun] are: tensor([3.1531e-03, 5.1611e-04, 1.6309e-04, 2.4074e-03, 9.6175e-04, 8.5317e-04,
        1.7452e-03, 5.4217e-03, 7.8699e-01, 1.9779e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:40,325][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ fun] are: tensor([0.1064, 0.0046, 0.0012, 0.0167, 0.0111, 0.0030, 0.0008, 0.0117, 0.7661,
        0.0784], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:40,327][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ fun] are: tensor([0.0545, 0.0093, 0.0022, 0.0208, 0.0025, 0.0319, 0.0122, 0.0255, 0.6224,
        0.2187], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:40,328][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ fun] are: tensor([0.2248, 0.0328, 0.0335, 0.1613, 0.0341, 0.1446, 0.0303, 0.0382, 0.0836,
        0.2168], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:40,330][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ fun] are: tensor([0.1481, 0.0092, 0.0026, 0.0090, 0.0089, 0.0014, 0.0121, 0.0663, 0.3485,
        0.3940], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:40,332][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.2478, 0.0935, 0.0321, 0.1142, 0.0300, 0.0770, 0.1001, 0.0471, 0.1052,
        0.0230, 0.1301], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:40,334][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.3991, 0.1377, 0.0034, 0.0249, 0.0031, 0.0038, 0.0173, 0.0154, 0.1564,
        0.1382, 0.1007], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:40,335][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.0781, 0.0957, 0.0904, 0.0914, 0.0798, 0.0945, 0.0954, 0.1062, 0.0927,
        0.0898, 0.0861], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:40,337][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([3.5050e-03, 8.5675e-06, 5.0069e-06, 3.3532e-05, 1.1645e-05, 1.1364e-05,
        5.9652e-06, 8.7476e-05, 4.0880e-01, 3.0710e-01, 2.8044e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:40,338][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.3530, 0.1444, 0.0434, 0.0568, 0.0484, 0.0751, 0.0328, 0.0651, 0.0444,
        0.0642, 0.0724], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:40,340][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.0127, 0.0517, 0.0960, 0.0890, 0.1224, 0.1318, 0.1357, 0.1134, 0.0880,
        0.0885, 0.0710], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:40,342][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.2242, 0.0033, 0.0010, 0.0025, 0.0078, 0.0029, 0.0019, 0.0100, 0.1686,
        0.4432, 0.1345], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:40,343][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([1.6949e-03, 5.5716e-05, 2.0290e-05, 1.3117e-04, 1.5303e-04, 6.6193e-05,
        1.4835e-04, 2.1024e-03, 1.5031e-01, 5.6412e-01, 2.8120e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:40,345][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.0837, 0.0031, 0.0004, 0.0061, 0.0017, 0.0014, 0.0007, 0.0096, 0.3639,
        0.2793, 0.2501], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:40,346][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([1.1904e-01, 4.3983e-03, 4.7420e-04, 6.2225e-03, 1.8475e-03, 2.3865e-03,
        3.1105e-03, 1.4751e-03, 1.6028e-01, 6.5284e-01, 4.7922e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:40,348][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.1912, 0.0667, 0.0596, 0.1463, 0.0095, 0.0599, 0.0347, 0.0231, 0.1288,
        0.0629, 0.2172], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:40,349][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([1.1908e-01, 4.2526e-03, 6.1689e-04, 2.9365e-03, 1.5977e-03, 5.7347e-04,
        1.2309e-03, 2.1106e-02, 1.2133e-01, 6.6997e-01, 5.7306e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:40,350][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.2452, 0.0786, 0.0356, 0.0961, 0.0288, 0.0707, 0.1017, 0.0510, 0.0854,
        0.0249, 0.0653, 0.1167], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:40,351][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.3686, 0.0539, 0.0033, 0.0127, 0.0025, 0.0021, 0.0051, 0.0077, 0.0691,
        0.0763, 0.0712, 0.3275], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:40,352][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0725, 0.0871, 0.0818, 0.0838, 0.0732, 0.0858, 0.0858, 0.0967, 0.0850,
        0.0816, 0.0805, 0.0860], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:40,353][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([6.3849e-04, 1.3433e-06, 9.8544e-07, 8.1082e-06, 2.2302e-05, 4.5109e-06,
        1.9860e-06, 1.1473e-04, 2.7591e-02, 1.2320e-01, 8.1024e-01, 3.8175e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:40,354][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.4223, 0.1316, 0.0352, 0.0483, 0.0412, 0.0622, 0.0274, 0.0521, 0.0383,
        0.0530, 0.0580, 0.0305], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:40,356][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.0091, 0.0487, 0.0769, 0.0779, 0.1058, 0.1080, 0.1121, 0.1089, 0.0884,
        0.0735, 0.0690, 0.1216], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:40,358][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.2266, 0.0024, 0.0010, 0.0018, 0.0070, 0.0017, 0.0014, 0.0072, 0.1273,
        0.3309, 0.2005, 0.0924], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:40,359][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([3.2739e-03, 9.5321e-05, 2.1952e-05, 1.1175e-04, 8.9761e-05, 5.3965e-05,
        8.5523e-05, 1.5964e-03, 8.2106e-02, 4.0517e-01, 3.8377e-01, 1.2362e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:40,360][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([8.4561e-02, 7.0614e-04, 1.1647e-04, 1.8482e-03, 6.0540e-04, 3.6014e-04,
        1.4510e-04, 3.2603e-03, 1.4725e-01, 1.6563e-01, 4.8930e-01, 1.0621e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:40,361][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([6.9747e-02, 2.9314e-03, 3.6155e-04, 5.3768e-03, 2.7011e-03, 2.1821e-03,
        9.1105e-04, 3.6430e-03, 1.1969e-01, 4.9406e-01, 2.2996e-01, 6.8440e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:40,363][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.1662, 0.0199, 0.0543, 0.0441, 0.0327, 0.0988, 0.0505, 0.0953, 0.0297,
        0.1030, 0.0261, 0.2794], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:40,364][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([1.9255e-01, 2.5899e-03, 5.9085e-04, 1.7680e-03, 3.0754e-03, 5.6133e-04,
        1.2439e-03, 1.0748e-02, 6.7262e-02, 5.8694e-01, 1.0413e-01, 2.8543e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:40,366][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ hospital] are: tensor([0.3327, 0.0780, 0.0178, 0.0904, 0.0205, 0.0682, 0.0812, 0.0351, 0.0828,
        0.0132, 0.0671, 0.0903, 0.0225], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:40,367][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ hospital] are: tensor([0.4094, 0.0409, 0.0024, 0.0079, 0.0019, 0.0013, 0.0032, 0.0023, 0.0427,
        0.0242, 0.0444, 0.2386, 0.1806], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:40,369][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ hospital] are: tensor([0.0649, 0.0782, 0.0733, 0.0764, 0.0665, 0.0799, 0.0795, 0.0903, 0.0798,
        0.0753, 0.0757, 0.0828, 0.0772], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:40,370][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ hospital] are: tensor([1.0770e-02, 8.8717e-06, 3.2810e-06, 1.8132e-05, 8.0968e-05, 1.2687e-05,
        6.1536e-06, 1.1905e-04, 5.6885e-02, 3.0135e-02, 4.7030e-01, 1.0463e-01,
        3.2703e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:40,372][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ hospital] are: tensor([0.4559, 0.1069, 0.0311, 0.0440, 0.0346, 0.0571, 0.0244, 0.0569, 0.0331,
        0.0510, 0.0574, 0.0279, 0.0197], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:40,374][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ hospital] are: tensor([0.0070, 0.0410, 0.0653, 0.0765, 0.1014, 0.1370, 0.1021, 0.0827, 0.0670,
        0.0731, 0.0591, 0.1234, 0.0645], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:40,376][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ hospital] are: tensor([0.3339, 0.0027, 0.0008, 0.0013, 0.0046, 0.0022, 0.0006, 0.0041, 0.0833,
        0.0546, 0.1118, 0.0466, 0.3536], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:40,377][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ hospital] are: tensor([9.8972e-03, 1.9387e-04, 4.2947e-05, 1.1036e-04, 1.4399e-04, 8.0266e-05,
        6.4371e-05, 1.2471e-03, 5.5451e-02, 8.2836e-02, 3.7222e-01, 1.7712e-01,
        3.0059e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:40,378][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ hospital] are: tensor([1.2614e-01, 6.5482e-04, 5.9671e-05, 8.3518e-04, 2.1668e-04, 1.8168e-04,
        6.5956e-05, 8.1474e-04, 6.9145e-02, 1.2094e-01, 3.6269e-01, 4.9223e-02,
        2.6904e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:40,379][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ hospital] are: tensor([1.0266e-01, 2.2749e-03, 2.3463e-04, 3.0057e-03, 8.4423e-04, 1.6420e-03,
        9.6656e-04, 1.6074e-03, 4.6607e-02, 1.2709e-01, 5.1036e-01, 5.4242e-02,
        1.4847e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:40,381][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ hospital] are: tensor([0.2458, 0.0218, 0.0340, 0.0696, 0.0203, 0.1488, 0.0165, 0.0335, 0.0281,
        0.0779, 0.0611, 0.0897, 0.1529], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:40,383][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ hospital] are: tensor([0.2595, 0.0048, 0.0015, 0.0029, 0.0024, 0.0013, 0.0012, 0.0063, 0.0629,
        0.2591, 0.1475, 0.0899, 0.1606], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:40,385][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.1982, 0.0758, 0.0340, 0.0906, 0.0263, 0.0708, 0.0936, 0.0441, 0.0730,
        0.0242, 0.0618, 0.0924, 0.0227, 0.0928], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:40,386][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.5593, 0.0301, 0.0015, 0.0062, 0.0012, 0.0010, 0.0037, 0.0014, 0.0297,
        0.0178, 0.0371, 0.1474, 0.0388, 0.1247], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:40,388][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.0597, 0.0756, 0.0710, 0.0719, 0.0631, 0.0738, 0.0734, 0.0829, 0.0717,
        0.0699, 0.0677, 0.0743, 0.0706, 0.0744], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:40,389][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([1.4124e-03, 1.4886e-07, 6.3969e-08, 5.0984e-07, 2.5349e-06, 6.2972e-07,
        1.4754e-06, 1.7337e-05, 1.2822e-02, 3.3502e-02, 2.6330e-02, 1.9706e-02,
        4.9540e-01, 4.1081e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:40,391][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.3314, 0.1138, 0.0365, 0.0565, 0.0470, 0.0634, 0.0321, 0.0562, 0.0444,
        0.0541, 0.0658, 0.0358, 0.0229, 0.0402], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:40,393][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.0080, 0.0381, 0.0618, 0.0650, 0.0816, 0.1014, 0.1088, 0.0858, 0.0705,
        0.0657, 0.0537, 0.1118, 0.0752, 0.0727], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:40,394][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([6.7660e-02, 4.6791e-04, 4.2697e-04, 6.1621e-04, 1.3570e-03, 2.7840e-04,
        3.3944e-04, 1.6907e-03, 2.0322e-02, 4.6230e-02, 3.1838e-02, 3.4704e-02,
        6.2673e-01, 1.6734e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:40,395][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([1.3038e-03, 6.4777e-06, 2.6299e-06, 1.1629e-05, 9.5188e-06, 4.4419e-06,
        1.5059e-05, 1.8930e-04, 9.4957e-03, 1.7422e-02, 4.4085e-02, 3.4313e-02,
        3.9137e-01, 5.0177e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:40,397][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([3.6711e-02, 1.3607e-04, 1.2668e-05, 1.4045e-04, 3.8840e-05, 3.0435e-05,
        4.7213e-05, 6.0972e-04, 1.5485e-02, 8.6909e-03, 3.5635e-02, 2.7906e-02,
        5.6599e-01, 3.0856e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:40,398][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.3193, 0.0048, 0.0004, 0.0030, 0.0014, 0.0019, 0.0007, 0.0022, 0.0470,
        0.1937, 0.0759, 0.0589, 0.1023, 0.1883], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:40,400][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.2522, 0.0516, 0.0676, 0.0688, 0.0223, 0.0380, 0.0188, 0.0237, 0.0486,
        0.0305, 0.0335, 0.0983, 0.0713, 0.1747], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:40,401][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([1.6475e-01, 1.3623e-03, 4.3515e-04, 1.3348e-03, 1.1418e-03, 2.2227e-04,
        5.6653e-04, 5.4854e-03, 2.6756e-02, 2.3113e-01, 5.9357e-02, 2.7981e-02,
        2.4795e-01, 2.3153e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:40,403][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Anthony] are: tensor([0.2895, 0.0716, 0.0439, 0.0820, 0.0196, 0.0529, 0.0762, 0.0261, 0.0762,
        0.0126, 0.0491, 0.0762, 0.0125, 0.0822, 0.0297], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:40,404][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Anthony] are: tensor([2.0185e-01, 1.0372e-02, 2.1123e-04, 1.3989e-03, 3.3563e-04, 2.1091e-04,
        7.0575e-04, 4.8579e-04, 8.8965e-03, 1.4339e-02, 1.4152e-02, 7.3723e-02,
        1.0288e-01, 4.1088e-01, 1.5956e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:40,406][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Anthony] are: tensor([0.0580, 0.0689, 0.0637, 0.0664, 0.0573, 0.0673, 0.0676, 0.0767, 0.0670,
        0.0645, 0.0635, 0.0698, 0.0658, 0.0716, 0.0718], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:40,407][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Anthony] are: tensor([1.7880e-03, 4.5337e-07, 3.2280e-08, 4.4193e-07, 1.7238e-06, 1.5110e-07,
        2.4963e-07, 5.4811e-06, 1.6922e-03, 1.1074e-03, 1.4000e-02, 4.1194e-03,
        8.2987e-02, 4.4165e-01, 4.5265e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:40,409][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Anthony] are: tensor([0.3048, 0.0857, 0.0355, 0.0540, 0.0473, 0.0633, 0.0287, 0.0664, 0.0400,
        0.0535, 0.0702, 0.0371, 0.0278, 0.0419, 0.0437], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:40,411][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Anthony] are: tensor([0.0058, 0.0360, 0.0301, 0.0620, 0.0554, 0.1191, 0.1061, 0.0946, 0.0718,
        0.0550, 0.0585, 0.1211, 0.0604, 0.0808, 0.0433], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:40,412][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Anthony] are: tensor([1.0913e-01, 6.1719e-04, 6.0949e-05, 1.3828e-04, 4.1623e-04, 4.4511e-05,
        9.3881e-05, 5.1856e-04, 8.2008e-03, 1.1980e-02, 1.1985e-02, 5.0298e-03,
        1.3395e-01, 5.5158e-01, 1.6625e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:40,413][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Anthony] are: tensor([2.5178e-03, 1.2418e-05, 3.0615e-07, 2.6273e-06, 4.4590e-06, 1.8870e-06,
        4.6169e-06, 1.9248e-04, 3.1470e-03, 7.0941e-03, 1.6728e-02, 1.8685e-02,
        1.3198e-01, 7.0186e-01, 1.1777e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:40,414][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Anthony] are: tensor([2.8141e-02, 7.4507e-05, 9.0221e-07, 4.6964e-05, 1.1557e-05, 1.4809e-05,
        1.1558e-05, 1.5869e-04, 6.9939e-03, 8.9694e-03, 2.6067e-02, 1.0956e-02,
        4.9699e-01, 3.8535e-01, 3.6212e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:40,415][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Anthony] are: tensor([1.3967e-01, 2.0464e-03, 9.4975e-05, 1.3361e-03, 6.4809e-04, 3.4169e-04,
        5.1605e-04, 7.3977e-04, 4.3167e-02, 4.5209e-02, 3.4003e-02, 6.4405e-02,
        2.5080e-01, 3.4149e-01, 7.5534e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:40,416][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Anthony] are: tensor([0.1425, 0.0116, 0.0669, 0.0335, 0.0280, 0.0684, 0.0391, 0.0417, 0.0370,
        0.1298, 0.0302, 0.1184, 0.0879, 0.0311, 0.1341], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:40,417][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Anthony] are: tensor([2.0228e-01, 1.4344e-03, 5.5967e-05, 4.5491e-04, 3.9518e-04, 1.8317e-04,
        3.8056e-04, 2.7884e-03, 1.7881e-02, 4.8517e-02, 4.0211e-02, 3.0371e-02,
        2.3941e-01, 3.5693e-01, 5.8709e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:40,419][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.2440, 0.0696, 0.0220, 0.0865, 0.0178, 0.0640, 0.0869, 0.0346, 0.0732,
        0.0186, 0.0533, 0.0764, 0.0159, 0.0828, 0.0153, 0.0391],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:40,420][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([2.6571e-01, 1.5926e-02, 4.2431e-04, 2.6659e-03, 2.8457e-04, 2.3139e-04,
        1.0618e-03, 1.0811e-03, 7.6578e-03, 1.3564e-02, 5.0344e-03, 7.3600e-02,
        3.5825e-02, 2.5452e-01, 2.5028e-01, 7.2141e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:40,422][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.0534, 0.0643, 0.0607, 0.0615, 0.0542, 0.0630, 0.0628, 0.0713, 0.0622,
        0.0595, 0.0576, 0.0640, 0.0614, 0.0656, 0.0671, 0.0716],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:40,423][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([1.7538e-03, 7.8093e-07, 5.6831e-08, 6.5056e-07, 3.0391e-07, 6.5088e-08,
        1.4096e-07, 2.4567e-06, 3.1044e-03, 3.8212e-03, 5.9351e-03, 5.5718e-03,
        8.0778e-02, 4.3123e-01, 3.9548e-01, 7.2316e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:40,425][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.3135, 0.0988, 0.0339, 0.0518, 0.0360, 0.0633, 0.0262, 0.0572, 0.0341,
        0.0522, 0.0607, 0.0331, 0.0224, 0.0381, 0.0301, 0.0486],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:40,427][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.0062, 0.0384, 0.0475, 0.0620, 0.0626, 0.0897, 0.0787, 0.0674, 0.0661,
        0.0440, 0.0553, 0.0956, 0.0631, 0.0819, 0.0590, 0.0824],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:40,428][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([2.5330e-02, 1.5112e-04, 6.2463e-05, 7.8726e-05, 4.4326e-04, 4.3399e-05,
        8.7519e-05, 2.3046e-04, 3.6988e-03, 1.0820e-02, 6.4588e-03, 7.5203e-03,
        2.6874e-01, 3.3981e-01, 2.9583e-01, 4.0695e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:40,429][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([1.0534e-03, 5.2390e-06, 1.0832e-06, 2.4030e-06, 2.0398e-06, 1.7793e-07,
        4.3424e-06, 9.5361e-05, 1.4463e-03, 6.9288e-03, 5.4633e-03, 4.6754e-03,
        1.0620e-01, 3.6209e-01, 4.3735e-01, 7.4683e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:40,430][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([2.6681e-02, 1.4804e-04, 7.1314e-06, 7.7577e-05, 2.9846e-05, 1.7645e-05,
        1.2608e-05, 5.5736e-05, 6.4296e-03, 1.8317e-02, 8.4309e-03, 1.2521e-02,
        2.0979e-01, 4.2379e-01, 2.1841e-01, 7.5283e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:40,432][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([2.1236e-01, 5.7135e-03, 1.0542e-04, 1.3468e-03, 3.3162e-04, 1.5647e-03,
        4.3980e-04, 8.1889e-04, 2.0360e-02, 7.5891e-02, 5.6733e-02, 2.8045e-02,
        1.0085e-01, 4.0885e-01, 3.3109e-02, 5.3487e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:40,433][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0470, 0.0236, 0.0179, 0.0546, 0.0133, 0.1046, 0.0498, 0.0707, 0.0682,
        0.1298, 0.0685, 0.0933, 0.0831, 0.0728, 0.0420, 0.0608],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:40,435][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([3.3793e-01, 3.1599e-03, 7.4424e-05, 7.2530e-04, 4.0070e-04, 9.7521e-05,
        3.1224e-04, 4.2666e-03, 2.1121e-02, 5.1018e-02, 2.8954e-02, 9.7887e-03,
        8.7538e-02, 3.5019e-01, 5.1433e-02, 5.2990e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:40,437][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.1950, 0.0579, 0.0336, 0.0716, 0.0217, 0.0542, 0.1010, 0.0350, 0.0648,
        0.0185, 0.0511, 0.0766, 0.0159, 0.0732, 0.0252, 0.0227, 0.0819],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:40,438][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([1.9710e-01, 6.4237e-03, 1.8469e-04, 8.9019e-04, 1.5069e-04, 9.7127e-05,
        2.6483e-04, 4.4108e-04, 4.2535e-03, 7.7329e-03, 3.2932e-03, 2.9062e-02,
        5.1383e-02, 2.5696e-01, 1.7137e-01, 1.2194e-01, 1.4845e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:40,440][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0528, 0.0601, 0.0562, 0.0573, 0.0499, 0.0575, 0.0578, 0.0661, 0.0579,
        0.0564, 0.0549, 0.0602, 0.0568, 0.0618, 0.0626, 0.0654, 0.0662],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:40,441][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([8.4969e-04, 7.7721e-08, 5.1651e-09, 5.4732e-08, 2.1947e-07, 5.4250e-08,
        1.2366e-08, 7.0488e-06, 2.6698e-04, 1.1006e-03, 3.7693e-03, 7.4992e-04,
        6.5701e-02, 1.5125e-01, 1.1066e-01, 6.1234e-01, 5.3300e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:40,443][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.3437, 0.1138, 0.0300, 0.0449, 0.0334, 0.0557, 0.0245, 0.0483, 0.0326,
        0.0461, 0.0531, 0.0291, 0.0198, 0.0350, 0.0232, 0.0431, 0.0240],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:40,445][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0067, 0.0333, 0.0474, 0.0494, 0.0628, 0.0736, 0.0732, 0.0779, 0.0577,
        0.0492, 0.0482, 0.0910, 0.0550, 0.0710, 0.0634, 0.0754, 0.0647],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:40,446][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([6.5653e-02, 9.7952e-05, 2.9014e-05, 4.5269e-05, 2.5362e-04, 4.5059e-05,
        1.3995e-05, 3.2573e-04, 5.0406e-03, 1.5317e-02, 3.8220e-03, 2.6792e-03,
        2.5056e-01, 3.4225e-01, 1.5854e-01, 8.8260e-02, 6.7063e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:40,447][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([5.1400e-04, 6.0193e-07, 1.6016e-07, 3.9046e-07, 4.2141e-07, 1.7181e-07,
        1.3290e-07, 1.2812e-05, 4.7449e-04, 2.8445e-03, 2.0306e-03, 1.8460e-03,
        6.4541e-02, 2.0172e-01, 2.1008e-01, 4.4358e-01, 7.2362e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:40,449][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([1.9121e-02, 2.6359e-05, 1.9375e-06, 2.1086e-05, 7.2623e-06, 3.7342e-06,
        1.2990e-06, 7.3573e-05, 2.1888e-03, 4.5114e-03, 5.7795e-03, 1.6133e-03,
        9.8062e-02, 2.1572e-01, 1.2272e-01, 4.7631e-01, 5.3847e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:40,450][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([2.6813e-02, 2.4563e-04, 1.8730e-05, 3.6248e-04, 6.8444e-05, 1.8613e-04,
        4.6617e-05, 2.7198e-04, 8.1982e-03, 3.4455e-02, 1.9131e-02, 7.2470e-03,
        4.6904e-02, 1.3378e-01, 1.4398e-02, 6.5624e-01, 5.1637e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:40,452][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0843, 0.0107, 0.0506, 0.0391, 0.0359, 0.0510, 0.0507, 0.0993, 0.0243,
        0.0762, 0.0232, 0.1042, 0.0756, 0.0428, 0.1095, 0.0287, 0.0938],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:40,453][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([1.9459e-01, 5.9484e-04, 4.4299e-05, 1.6811e-04, 2.2588e-04, 4.6090e-05,
        2.7248e-05, 1.9480e-03, 6.7000e-03, 8.2048e-02, 1.2000e-02, 9.3955e-03,
        7.9848e-02, 3.2594e-01, 7.7529e-02, 1.5575e-01, 5.3143e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:40,455][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ drink] are: tensor([0.2349, 0.0647, 0.0201, 0.0791, 0.0146, 0.0549, 0.0779, 0.0331, 0.0685,
        0.0145, 0.0499, 0.0764, 0.0124, 0.0805, 0.0136, 0.0198, 0.0587, 0.0264],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:40,456][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ drink] are: tensor([1.3619e-01, 4.3809e-03, 2.0807e-04, 6.1633e-04, 2.0972e-04, 1.0581e-04,
        5.7053e-04, 7.4791e-04, 4.8568e-03, 5.6870e-03, 4.2194e-03, 4.8866e-02,
        3.9314e-02, 1.7144e-01, 1.3852e-01, 8.5137e-02, 2.2359e-01, 1.3535e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:40,458][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ drink] are: tensor([0.0492, 0.0558, 0.0515, 0.0537, 0.0460, 0.0546, 0.0551, 0.0627, 0.0551,
        0.0521, 0.0517, 0.0568, 0.0532, 0.0580, 0.0575, 0.0632, 0.0639, 0.0600],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:40,459][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ drink] are: tensor([4.3576e-04, 1.1643e-07, 8.3264e-09, 2.8743e-08, 4.4994e-08, 2.9594e-08,
        7.3024e-08, 1.2549e-06, 6.1066e-04, 1.5607e-03, 1.3225e-03, 1.4490e-03,
        2.9391e-02, 1.5858e-01, 9.4521e-02, 3.5238e-01, 2.7118e-01, 8.8568e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:40,461][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ drink] are: tensor([0.3076, 0.0787, 0.0272, 0.0449, 0.0320, 0.0520, 0.0227, 0.0553, 0.0290,
        0.0462, 0.0585, 0.0304, 0.0209, 0.0361, 0.0330, 0.0509, 0.0309, 0.0434],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:40,463][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ drink] are: tensor([0.0051, 0.0310, 0.0342, 0.0520, 0.0532, 0.0978, 0.0716, 0.0653, 0.0556,
        0.0389, 0.0444, 0.0915, 0.0543, 0.0692, 0.0479, 0.0946, 0.0625, 0.0309],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:40,464][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ drink] are: tensor([4.5879e-02, 8.5789e-05, 3.1159e-05, 3.8161e-05, 2.1620e-04, 6.7297e-05,
        2.7852e-05, 1.4246e-04, 3.4339e-03, 6.9413e-03, 4.9210e-03, 2.9316e-03,
        9.0953e-02, 2.1277e-01, 1.0556e-01, 1.6118e-01, 1.0460e-01, 2.6022e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:40,466][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ drink] are: tensor([7.6391e-04, 1.8042e-06, 1.9741e-07, 3.8519e-07, 1.1294e-06, 1.2768e-07,
        6.5649e-07, 4.7662e-05, 7.9578e-04, 2.6848e-03, 3.4392e-03, 4.6621e-03,
        6.1770e-02, 1.6453e-01, 1.0412e-01, 2.9935e-01, 2.0358e-01, 1.5426e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:40,467][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ drink] are: tensor([2.7026e-02, 2.5689e-05, 3.6539e-06, 1.6353e-05, 1.1260e-05, 3.6865e-06,
        2.2210e-06, 8.1166e-05, 1.8437e-03, 1.8441e-03, 5.5468e-03, 1.4799e-03,
        2.2311e-02, 8.9959e-02, 1.3518e-01, 6.1037e-01, 5.5504e-02, 4.8787e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:40,469][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ drink] are: tensor([2.3928e-02, 3.0883e-04, 6.0390e-05, 2.2919e-04, 5.1281e-05, 3.1995e-04,
        1.6209e-04, 1.8873e-04, 9.6145e-03, 2.6710e-02, 1.0161e-02, 1.2729e-02,
        2.3159e-02, 1.3700e-01, 3.8310e-02, 3.4613e-01, 1.2294e-01, 2.4800e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:40,470][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ drink] are: tensor([0.0672, 0.0115, 0.0243, 0.0368, 0.0102, 0.0914, 0.0212, 0.0312, 0.0363,
        0.1063, 0.0350, 0.0603, 0.1033, 0.0316, 0.0529, 0.0959, 0.0399, 0.1446],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:40,472][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ drink] are: tensor([6.0067e-02, 5.9720e-04, 5.6009e-05, 1.6882e-04, 2.3549e-04, 3.9504e-05,
        1.3383e-04, 3.0405e-03, 1.2235e-02, 6.9211e-02, 1.3373e-02, 9.8837e-03,
        9.2397e-02, 1.6248e-01, 6.2858e-02, 1.5957e-01, 1.3182e-01, 2.2182e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:40,474][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.1701, 0.0605, 0.0236, 0.0716, 0.0218, 0.0542, 0.0696, 0.0308, 0.0646,
        0.0179, 0.0536, 0.0717, 0.0161, 0.0747, 0.0174, 0.0253, 0.0572, 0.0225,
        0.0766], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:40,474][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([2.5060e-01, 2.9299e-03, 1.0462e-04, 2.5871e-04, 3.0645e-05, 6.4362e-05,
        2.1815e-04, 2.7249e-04, 1.3899e-03, 1.9464e-03, 1.3107e-03, 1.8443e-02,
        1.0259e-02, 9.7036e-02, 7.2538e-02, 6.9926e-02, 1.3052e-01, 1.2876e-01,
        2.1339e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:40,475][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0469, 0.0532, 0.0498, 0.0510, 0.0441, 0.0510, 0.0527, 0.0593, 0.0513,
        0.0502, 0.0485, 0.0539, 0.0502, 0.0543, 0.0552, 0.0580, 0.0603, 0.0562,
        0.0538], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:40,476][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([5.2388e-04, 3.2275e-09, 1.5805e-10, 9.2164e-10, 1.4634e-09, 2.1063e-09,
        2.9298e-09, 8.2946e-08, 2.8559e-05, 3.3099e-04, 6.0740e-05, 8.8552e-05,
        2.4159e-03, 7.4563e-03, 6.8314e-03, 8.7951e-02, 2.8186e-02, 9.1860e-02,
        7.7427e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:40,477][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.2983, 0.0995, 0.0283, 0.0411, 0.0325, 0.0530, 0.0237, 0.0511, 0.0324,
        0.0473, 0.0543, 0.0292, 0.0199, 0.0331, 0.0245, 0.0405, 0.0238, 0.0315,
        0.0357], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:40,479][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0052, 0.0295, 0.0432, 0.0453, 0.0604, 0.0728, 0.0734, 0.0686, 0.0517,
        0.0495, 0.0367, 0.0838, 0.0513, 0.0647, 0.0579, 0.0780, 0.0612, 0.0381,
        0.0287], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:40,480][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([4.6919e-02, 1.5662e-05, 5.8103e-06, 5.9362e-06, 4.0035e-05, 6.9207e-06,
        6.6539e-06, 4.7457e-05, 4.5256e-04, 2.7497e-03, 9.7448e-04, 1.1661e-03,
        4.7748e-02, 5.1247e-02, 4.5710e-02, 1.3598e-02, 4.9478e-02, 3.4620e-01,
        3.9363e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:40,481][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([3.2161e-04, 5.1867e-08, 6.2433e-09, 1.3283e-08, 3.1315e-08, 4.1084e-09,
        3.2166e-08, 1.4297e-06, 2.5058e-05, 1.8573e-04, 1.6230e-04, 2.2891e-04,
        9.4332e-03, 1.1700e-02, 1.0201e-02, 5.9108e-02, 3.0204e-02, 2.7753e-01,
        6.0090e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:40,483][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([1.8908e-02, 3.5496e-06, 2.2925e-07, 1.1435e-06, 4.4154e-07, 4.9591e-07,
        2.0636e-07, 4.4860e-06, 1.5098e-04, 2.2547e-04, 3.8590e-04, 6.2585e-04,
        2.5074e-02, 3.3484e-02, 1.8516e-02, 4.3252e-02, 1.8683e-02, 4.0679e-01,
        4.3389e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:40,484][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([3.7702e-02, 2.1151e-04, 1.0218e-05, 7.4936e-05, 3.1282e-05, 5.9454e-05,
        3.6363e-05, 8.0699e-05, 1.5366e-03, 8.3933e-03, 9.2354e-04, 3.3078e-03,
        7.0610e-03, 7.3375e-02, 1.1637e-02, 4.5512e-01, 5.0897e-02, 2.9283e-01,
        5.6710e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:40,486][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0410, 0.0125, 0.0376, 0.0313, 0.0102, 0.0783, 0.0100, 0.0099, 0.0331,
        0.0219, 0.0994, 0.0423, 0.0666, 0.0514, 0.0916, 0.0550, 0.0204, 0.1427,
        0.1447], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:40,487][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([8.8299e-02, 1.3230e-04, 6.6905e-06, 2.9677e-05, 2.8685e-05, 6.5892e-06,
        2.5152e-05, 4.5707e-04, 1.5438e-03, 4.7417e-02, 4.6707e-03, 3.8751e-03,
        3.3283e-02, 6.5908e-02, 1.3755e-02, 6.2683e-02, 6.6337e-02, 3.9114e-01,
        2.2041e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:40,491][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:21:40,493][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[10322],
        [ 5539],
        [10780],
        [ 4900],
        [  832],
        [ 2801],
        [ 2708],
        [ 4220],
        [ 3864],
        [12995],
        [ 5466],
        [ 7441],
        [16611],
        [ 3646],
        [ 8386],
        [ 5925],
        [ 5944],
        [ 6449],
        [ 2155]], device='cuda:0')
[2024-07-24 10:21:40,495][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[10229],
        [ 3936],
        [ 9119],
        [ 4645],
        [  362],
        [ 1536],
        [  765],
        [ 3566],
        [ 3372],
        [14974],
        [ 3876],
        [ 3344],
        [13090],
        [ 3141],
        [ 3018],
        [ 6570],
        [ 1439],
        [ 7105],
        [  444]], device='cuda:0')
[2024-07-24 10:21:40,497][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[2094],
        [2413],
        [2864],
        [3524],
        [3705],
        [4090],
        [5041],
        [5442],
        [5227],
        [5334],
        [4785],
        [4998],
        [5296],
        [5078],
        [4314],
        [4972],
        [4774],
        [4947],
        [4554]], device='cuda:0')
[2024-07-24 10:21:40,499][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[15792],
        [14845],
        [ 9932],
        [10615],
        [ 8701],
        [ 8869],
        [ 8302],
        [ 8912],
        [ 9270],
        [ 9092],
        [ 9209],
        [ 9167],
        [ 9298],
        [ 9396],
        [ 8849],
        [ 9098],
        [ 9008],
        [ 9307],
        [ 9452]], device='cuda:0')
[2024-07-24 10:21:40,501][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[1289],
        [1158],
        [1489],
        [1462],
        [1449],
        [1560],
        [1734],
        [1828],
        [1842],
        [1880],
        [2056],
        [2036],
        [2100],
        [1989],
        [1992],
        [1957],
        [1998],
        [2049],
        [2036]], device='cuda:0')
[2024-07-24 10:21:40,503][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[47098],
        [47297],
        [47693],
        [47779],
        [47962],
        [48051],
        [48003],
        [47957],
        [47941],
        [47956],
        [47968],
        [48005],
        [47956],
        [47916],
        [48022],
        [48072],
        [48063],
        [47930],
        [47917]], device='cuda:0')
[2024-07-24 10:21:40,504][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[ 8798],
        [11092],
        [12724],
        [14174],
        [14139],
        [13428],
        [13166],
        [13152],
        [13629],
        [12925],
        [12794],
        [12871],
        [12806],
        [12913],
        [12883],
        [12570],
        [12627],
        [12610],
        [12658]], device='cuda:0')
[2024-07-24 10:21:40,506][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[39458],
        [40818],
        [40969],
        [39977],
        [39173],
        [38064],
        [36749],
        [36728],
        [35732],
        [35697],
        [35602],
        [35585],
        [35877],
        [35622],
        [35836],
        [35756],
        [35640],
        [35489],
        [35568]], device='cuda:0')
[2024-07-24 10:21:40,508][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[31137],
        [27723],
        [26697],
        [25663],
        [25829],
        [24487],
        [24019],
        [23496],
        [22926],
        [22595],
        [22057],
        [21827],
        [21769],
        [21885],
        [21897],
        [21947],
        [21968],
        [22026],
        [21988]], device='cuda:0')
[2024-07-24 10:21:40,510][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[46888],
        [48642],
        [48665],
        [48580],
        [48641],
        [48573],
        [48393],
        [48397],
        [48170],
        [48195],
        [48104],
        [48035],
        [48034],
        [48046],
        [47985],
        [48000],
        [47948],
        [47915],
        [47958]], device='cuda:0')
[2024-07-24 10:21:40,512][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[49453],
        [49380],
        [49004],
        [47366],
        [47773],
        [47729],
        [47715],
        [47462],
        [47637],
        [46198],
        [45815],
        [44343],
        [46027],
        [46827],
        [45547],
        [45118],
        [42818],
        [45006],
        [46056]], device='cuda:0')
[2024-07-24 10:21:40,514][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[11563],
        [11705],
        [16954],
        [16079],
        [16238],
        [22862],
        [26130],
        [22046],
        [17442],
        [22406],
        [ 7935],
        [14326],
        [24850],
        [12609],
        [13215],
        [17452],
        [40531],
        [32503],
        [36472]], device='cuda:0')
[2024-07-24 10:21:40,516][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[11375],
        [11192],
        [11386],
        [11086],
        [10980],
        [10956],
        [10687],
        [11393],
        [11804],
        [12003],
        [11545],
        [11727],
        [11358],
        [10787],
        [10310],
        [ 9927],
        [ 9669],
        [ 9439],
        [ 9076]], device='cuda:0')
[2024-07-24 10:21:40,518][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[31054],
        [31226],
        [34893],
        [32405],
        [37345],
        [35497],
        [36285],
        [33172],
        [34947],
        [43694],
        [43226],
        [42584],
        [38421],
        [35255],
        [31434],
        [31944],
        [31872],
        [28964],
        [31945]], device='cuda:0')
[2024-07-24 10:21:40,520][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 5616],
        [38185],
        [32423],
        [37925],
        [33128],
        [35396],
        [40826],
        [36354],
        [33413],
        [36242],
        [41545],
        [45739],
        [39571],
        [43007],
        [46716],
        [33723],
        [46250],
        [26235],
        [46178]], device='cuda:0')
[2024-07-24 10:21:40,522][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[39380],
        [39412],
        [40114],
        [40448],
        [40511],
        [40693],
        [41555],
        [41013],
        [41128],
        [40887],
        [41499],
        [41226],
        [41275],
        [41213],
        [41231],
        [41122],
        [41609],
        [41308],
        [41377]], device='cuda:0')
[2024-07-24 10:21:40,524][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[ 733],
        [ 778],
        [2915],
        [1903],
        [2055],
        [3082],
        [3025],
        [2827],
        [1650],
        [3678],
        [5212],
        [5785],
        [4021],
        [3056],
        [5100],
        [3028],
        [4635],
        [8701],
        [7577]], device='cuda:0')
[2024-07-24 10:21:40,526][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[24865],
        [23187],
        [21868],
        [21722],
        [21364],
        [21508],
        [21107],
        [20661],
        [20586],
        [20641],
        [20578],
        [20161],
        [20015],
        [19743],
        [19410],
        [19352],
        [19115],
        [19185],
        [19091]], device='cuda:0')
[2024-07-24 10:21:40,528][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[25328],
        [26665],
        [16094],
        [26008],
        [30898],
        [30380],
        [16926],
        [14576],
        [32588],
        [29149],
        [31847],
        [42484],
        [40624],
        [33809],
        [18705],
        [22079],
        [35727],
        [24701],
        [38008]], device='cuda:0')
[2024-07-24 10:21:40,530][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[34289],
        [38328],
        [38932],
        [38427],
        [38601],
        [38912],
        [38719],
        [38675],
        [38375],
        [38217],
        [37859],
        [37790],
        [37748],
        [37318],
        [37075],
        [37402],
        [37422],
        [37151],
        [37148]], device='cuda:0')
[2024-07-24 10:21:40,532][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[5458],
        [5272],
        [5541],
        [6788],
        [5452],
        [4927],
        [4702],
        [4126],
        [4250],
        [4098],
        [4137],
        [4425],
        [4314],
        [4145],
        [4159],
        [4123],
        [4089],
        [3759],
        [3680]], device='cuda:0')
[2024-07-24 10:21:40,534][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[26946],
        [26647],
        [18354],
        [21691],
        [16283],
        [17392],
        [18905],
        [17032],
        [14333],
        [16321],
        [23992],
        [22660],
        [31159],
        [36211],
        [15718],
        [17915],
        [19594],
        [20237],
        [18190]], device='cuda:0')
[2024-07-24 10:21:40,536][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[24207],
        [16659],
        [ 6114],
        [16431],
        [15203],
        [16110],
        [18023],
        [17620],
        [24904],
        [27529],
        [32251],
        [35474],
        [28067],
        [12128],
        [13641],
        [18629],
        [21310],
        [20392],
        [18678]], device='cuda:0')
[2024-07-24 10:21:40,538][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[18459],
        [18610],
        [10235],
        [ 9180],
        [11572],
        [11856],
        [10819],
        [ 8039],
        [15191],
        [14005],
        [ 9783],
        [14840],
        [ 8609],
        [ 8128],
        [ 8724],
        [10880],
        [21276],
        [23662],
        [ 7102]], device='cuda:0')
[2024-07-24 10:21:40,539][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[13362],
        [13264],
        [16090],
        [ 9573],
        [ 5052],
        [ 9818],
        [ 4666],
        [ 5521],
        [ 6909],
        [ 8577],
        [23177],
        [16213],
        [ 9130],
        [12917],
        [11462],
        [ 8907],
        [ 5606],
        [ 3585],
        [ 2893]], device='cuda:0')
[2024-07-24 10:21:40,541][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[12399],
        [24099],
        [17664],
        [32994],
        [26703],
        [45797],
        [31441],
        [32610],
        [38838],
        [32682],
        [42490],
        [38168],
        [32468],
        [36376],
        [26806],
        [38739],
        [33921],
        [28141],
        [28197]], device='cuda:0')
[2024-07-24 10:21:40,543][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 9222],
        [ 9234],
        [ 8820],
        [10002],
        [15777],
        [15304],
        [14643],
        [13091],
        [10861],
        [25512],
        [25739],
        [24861],
        [19444],
        [16848],
        [12187],
        [10036],
        [10263],
        [14770],
        [19726]], device='cuda:0')
[2024-07-24 10:21:40,544][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[23346],
        [23632],
        [28206],
        [25407],
        [24987],
        [20912],
        [26375],
        [28359],
        [25170],
        [19645],
        [13697],
        [10565],
        [15909],
        [20771],
        [28320],
        [26941],
        [22090],
        [22819],
        [24098]], device='cuda:0')
[2024-07-24 10:21:40,546][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[37518],
        [16598],
        [23642],
        [ 7629],
        [19200],
        [12585],
        [12648],
        [14519],
        [ 4719],
        [ 5945],
        [ 5104],
        [ 9459],
        [13685],
        [ 4220],
        [ 8717],
        [11040],
        [ 9609],
        [ 9388],
        [ 6114]], device='cuda:0')
[2024-07-24 10:21:40,548][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[6566],
        [6566],
        [6566],
        [6566],
        [6566],
        [6566],
        [6566],
        [6566],
        [6566],
        [6566],
        [6566],
        [6566],
        [6566],
        [6566],
        [6566],
        [6566],
        [6566],
        [6566],
        [6566]], device='cuda:0')
[2024-07-24 10:21:40,589][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:21:40,590][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:40,591][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:40,591][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:40,592][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:40,593][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:40,593][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:40,594][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:40,595][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:40,595][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:40,596][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:40,597][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:40,597][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:40,598][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0060, 0.9940], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:40,599][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0669, 0.9331], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:40,599][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.5852, 0.4148], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:40,601][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.5926, 0.4074], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:40,602][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.6232, 0.3768], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:40,602][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.1626, 0.8374], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:40,603][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.6081, 0.3919], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:40,604][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.2687, 0.7313], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:40,605][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0380, 0.9620], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:40,607][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0078, 0.9922], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:40,609][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.1964, 0.8036], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:40,610][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0239, 0.9761], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:40,612][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Anthony] are: tensor([0.0129, 0.9823, 0.0048], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:40,613][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Anthony] are: tensor([2.6495e-03, 4.3411e-05, 9.9731e-01], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:40,615][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Anthony] are: tensor([0.3424, 0.2887, 0.3689], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:40,616][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Anthony] are: tensor([0.6498, 0.2203, 0.1299], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:40,618][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Anthony] are: tensor([0.5320, 0.2332, 0.2348], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:40,619][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Anthony] are: tensor([0.0624, 0.6526, 0.2850], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:40,621][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Anthony] are: tensor([0.4516, 0.2518, 0.2966], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:40,622][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Anthony] are: tensor([0.1736, 0.5426, 0.2838], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:40,624][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Anthony] are: tensor([0.7325, 0.2062, 0.0613], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:40,626][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Anthony] are: tensor([0.0039, 0.3500, 0.6462], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:40,626][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Anthony] are: tensor([0.0809, 0.4510, 0.4682], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:40,627][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Anthony] are: tensor([1.9924e-05, 9.9997e-01, 1.3294e-05], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:40,628][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0195, 0.8789, 0.0053, 0.0963], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:40,628][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ and] are: tensor([3.1020e-05, 8.8232e-08, 2.8078e-03, 9.9716e-01], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:40,629][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.2465, 0.2158, 0.2840, 0.2536], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:40,631][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.3399, 0.2413, 0.1792, 0.2395], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:40,632][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.4033, 0.1867, 0.1885, 0.2215], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:40,634][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0290, 0.2856, 0.1722, 0.5133], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:40,636][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.3560, 0.1887, 0.2312, 0.2241], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:40,637][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.1741, 0.3672, 0.1653, 0.2934], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:40,639][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.1882, 0.3269, 0.0680, 0.4169], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:40,640][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0016, 0.2387, 0.4790, 0.2807], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:40,642][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0644, 0.3157, 0.3291, 0.2908], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:40,643][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ and] are: tensor([7.6831e-09, 1.2640e-01, 2.9083e-02, 8.4452e-01], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:40,644][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Travis] are: tensor([5.5969e-03, 8.1002e-01, 5.1446e-03, 1.7881e-01, 4.3026e-04],
       device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:40,645][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Travis] are: tensor([6.0170e-04, 1.7126e-06, 3.9277e-03, 7.3478e-01, 2.6069e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:40,647][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Travis] are: tensor([0.1890, 0.1795, 0.2070, 0.1879, 0.2365], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:40,649][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Travis] are: tensor([0.5093, 0.1572, 0.0951, 0.1445, 0.0939], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:40,650][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Travis] are: tensor([0.3425, 0.1542, 0.1381, 0.1560, 0.2092], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:40,652][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Travis] are: tensor([0.0189, 0.2119, 0.1208, 0.5124, 0.1361], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:40,653][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Travis] are: tensor([0.2964, 0.1503, 0.1822, 0.1754, 0.1957], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:40,655][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Travis] are: tensor([0.1170, 0.3027, 0.1478, 0.2604, 0.1721], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:40,656][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Travis] are: tensor([0.2287, 0.1719, 0.1289, 0.4406, 0.0299], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:40,658][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Travis] are: tensor([0.0014, 0.1579, 0.3527, 0.2075, 0.2805], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:40,660][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Travis] are: tensor([0.0408, 0.2458, 0.2533, 0.2241, 0.2360], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:40,661][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Travis] are: tensor([8.0720e-06, 1.9179e-01, 2.5049e-04, 8.0779e-01, 1.6199e-04],
       device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:40,662][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ had] are: tensor([8.3524e-03, 7.3042e-01, 2.7842e-03, 2.4476e-01, 3.0394e-04, 1.3379e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:40,663][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ had] are: tensor([5.7873e-05, 6.5538e-10, 9.4057e-06, 6.9292e-03, 4.6144e-03, 9.8839e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:40,665][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.1576, 0.1479, 0.1737, 0.1575, 0.2016, 0.1615], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:40,666][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.1854, 0.1662, 0.1229, 0.1720, 0.1313, 0.2221], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:40,668][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.2943, 0.1285, 0.1183, 0.1326, 0.1778, 0.1484], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:40,670][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.0150, 0.1272, 0.1138, 0.4155, 0.2243, 0.1042], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:40,671][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.2469, 0.1237, 0.1505, 0.1441, 0.1624, 0.1724], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:40,673][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.1115, 0.2323, 0.1060, 0.1915, 0.1099, 0.2487], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:40,675][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.0948, 0.0489, 0.0235, 0.3570, 0.0442, 0.4315], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:40,676][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.0010, 0.1328, 0.2561, 0.1578, 0.2890, 0.1632], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:40,678][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.0402, 0.1970, 0.2072, 0.1776, 0.1925, 0.1856], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:40,679][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ had] are: tensor([1.3582e-10, 1.3623e-03, 5.1141e-04, 5.3957e-01, 4.5853e-01, 1.9970e-05],
       device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:40,681][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0190, 0.5928, 0.0022, 0.1459, 0.0012, 0.2314, 0.0076],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:40,682][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ a] are: tensor([4.7215e-06, 3.6444e-10, 4.7997e-06, 2.1497e-03, 1.5076e-03, 5.2574e-01,
        4.7059e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:40,683][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.1333, 0.1289, 0.1476, 0.1387, 0.1687, 0.1400, 0.1428],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:40,685][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.1615, 0.1427, 0.1038, 0.1411, 0.1085, 0.1771, 0.1653],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:40,687][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.2493, 0.1014, 0.1046, 0.1162, 0.1568, 0.1268, 0.1448],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:40,688][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0113, 0.1613, 0.1096, 0.3376, 0.1430, 0.1084, 0.1288],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:40,689][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.2226, 0.1027, 0.1261, 0.1188, 0.1361, 0.1454, 0.1481],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:40,690][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0985, 0.2006, 0.0819, 0.1623, 0.0805, 0.1892, 0.1870],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:40,691][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.3542, 0.0476, 0.0160, 0.1799, 0.0205, 0.3393, 0.0426],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:40,693][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0007, 0.1126, 0.2408, 0.1309, 0.2438, 0.1313, 0.1399],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:40,694][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0388, 0.1681, 0.1727, 0.1500, 0.1601, 0.1535, 0.1568],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:40,695][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ a] are: tensor([7.5690e-10, 7.6157e-03, 1.1078e-03, 3.8027e-01, 5.6646e-01, 4.4539e-02,
        9.3492e-07], device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:40,697][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ lot] are: tensor([0.0052, 0.5509, 0.0069, 0.1976, 0.0022, 0.1986, 0.0347, 0.0040],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:40,698][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ lot] are: tensor([4.1603e-05, 3.0371e-11, 8.7941e-08, 8.9020e-05, 1.1717e-04, 8.5098e-03,
        1.1724e-02, 9.7952e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:40,700][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ lot] are: tensor([0.1276, 0.1145, 0.1221, 0.1188, 0.1449, 0.1145, 0.1221, 0.1355],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:40,701][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ lot] are: tensor([0.2133, 0.1109, 0.0780, 0.1091, 0.0794, 0.1572, 0.1427, 0.1095],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:40,703][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ lot] are: tensor([0.2084, 0.0928, 0.0931, 0.1038, 0.1403, 0.1109, 0.1251, 0.1256],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:40,705][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ lot] are: tensor([0.0082, 0.1025, 0.0828, 0.3540, 0.1186, 0.0681, 0.1406, 0.1253],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:40,706][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ lot] are: tensor([0.1965, 0.0872, 0.1092, 0.1018, 0.1190, 0.1283, 0.1311, 0.1270],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:40,708][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ lot] are: tensor([0.0713, 0.1564, 0.0830, 0.1352, 0.0868, 0.1795, 0.1597, 0.1282],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:40,710][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ lot] are: tensor([0.3626, 0.0465, 0.0291, 0.1545, 0.0319, 0.2762, 0.0894, 0.0099],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:40,711][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ lot] are: tensor([0.0007, 0.0932, 0.1963, 0.1200, 0.1867, 0.1098, 0.1459, 0.1473],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:40,713][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ lot] are: tensor([0.0354, 0.1464, 0.1493, 0.1291, 0.1352, 0.1282, 0.1313, 0.1450],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:40,714][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ lot] are: tensor([7.4781e-08, 1.2347e-03, 2.5965e-02, 4.9835e-03, 9.6455e-01, 4.6487e-04,
        2.7894e-03, 1.3757e-05], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:40,716][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ of] are: tensor([0.0090, 0.5789, 0.0228, 0.1542, 0.0023, 0.1575, 0.0643, 0.0072, 0.0038],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:40,717][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ of] are: tensor([1.4847e-06, 2.4736e-11, 6.8363e-08, 2.2777e-05, 3.4786e-05, 5.3365e-03,
        3.8576e-03, 9.2444e-01, 6.6311e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:40,718][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ of] are: tensor([0.1062, 0.0886, 0.1117, 0.1090, 0.1293, 0.1038, 0.1119, 0.1205, 0.1190],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:40,720][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ of] are: tensor([0.1239, 0.1088, 0.0817, 0.1035, 0.0858, 0.1226, 0.1174, 0.1149, 0.1414],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:40,722][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ of] are: tensor([0.1880, 0.0834, 0.0756, 0.0886, 0.1048, 0.0887, 0.1073, 0.1007, 0.1629],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:40,723][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ of] are: tensor([0.0081, 0.0874, 0.0671, 0.2826, 0.0857, 0.0907, 0.1589, 0.1635, 0.0559],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:40,725][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ of] are: tensor([0.1794, 0.0783, 0.0977, 0.0907, 0.1073, 0.1164, 0.1186, 0.1129, 0.0987],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:40,727][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ of] are: tensor([0.0713, 0.1592, 0.0766, 0.1226, 0.0762, 0.1571, 0.1361, 0.1159, 0.0851],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:40,728][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ of] are: tensor([0.1731, 0.0337, 0.0102, 0.2133, 0.0206, 0.3562, 0.0715, 0.0064, 0.1150],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:40,730][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ of] are: tensor([0.0006, 0.0836, 0.1835, 0.0959, 0.1640, 0.0974, 0.1151, 0.1504, 0.1095],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:40,732][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ of] are: tensor([0.0274, 0.1273, 0.1306, 0.1139, 0.1205, 0.1145, 0.1186, 0.1306, 0.1165],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:40,733][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ of] are: tensor([1.1693e-10, 3.4045e-06, 1.4961e-06, 1.4287e-07, 6.9106e-03, 1.9341e-07,
        8.4854e-11, 5.9779e-04, 9.9249e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:40,734][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ fun] are: tensor([0.0079, 0.4356, 0.0167, 0.2521, 0.0050, 0.1749, 0.0717, 0.0092, 0.0264,
        0.0005], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:40,736][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ fun] are: tensor([1.4653e-05, 1.5610e-11, 2.8818e-08, 1.5816e-05, 3.9787e-05, 2.5406e-03,
        2.1341e-03, 4.6389e-01, 5.1523e-02, 4.7984e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:40,737][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ fun] are: tensor([0.0904, 0.0840, 0.0950, 0.0962, 0.1124, 0.0910, 0.0977, 0.1065, 0.1107,
        0.1162], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:40,739][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ fun] are: tensor([0.2638, 0.0786, 0.0466, 0.0702, 0.0458, 0.1197, 0.1090, 0.0772, 0.1389,
        0.0503], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:40,741][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ fun] are: tensor([0.1459, 0.0685, 0.0680, 0.0787, 0.0990, 0.0780, 0.0930, 0.0918, 0.1533,
        0.1237], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:40,743][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ fun] are: tensor([0.0072, 0.0735, 0.0650, 0.2178, 0.1684, 0.0859, 0.0993, 0.1315, 0.1255,
        0.0260], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:40,744][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ fun] are: tensor([0.1599, 0.0717, 0.0881, 0.0818, 0.0952, 0.1023, 0.1039, 0.1000, 0.0910,
        0.1061], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:40,746][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ fun] are: tensor([0.0777, 0.1424, 0.0658, 0.1107, 0.0678, 0.1377, 0.1309, 0.1036, 0.0675,
        0.0961], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:40,748][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ fun] are: tensor([0.2058, 0.0347, 0.0282, 0.1739, 0.0403, 0.2218, 0.1062, 0.0218, 0.1157,
        0.0516], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:40,749][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ fun] are: tensor([0.0005, 0.0678, 0.1682, 0.0853, 0.1332, 0.0777, 0.1038, 0.1161, 0.0899,
        0.1574], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:40,750][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ fun] are: tensor([0.0220, 0.1125, 0.1170, 0.1006, 0.1063, 0.1027, 0.1055, 0.1170, 0.1050,
        0.1114], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:40,751][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ fun] are: tensor([4.7177e-11, 8.1195e-08, 4.4270e-07, 7.2957e-07, 7.2704e-05, 2.0676e-07,
        1.3002e-09, 7.2118e-07, 9.9969e-01, 2.3548e-04], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:40,752][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.0181, 0.4169, 0.0049, 0.0805, 0.0007, 0.2772, 0.1542, 0.0220, 0.0191,
        0.0059, 0.0007], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:40,753][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ at] are: tensor([1.3383e-06, 1.5981e-12, 7.3341e-09, 5.9026e-06, 1.2316e-05, 1.0329e-03,
        9.4318e-04, 2.5766e-01, 1.8346e-02, 3.3058e-01, 3.9141e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:40,754][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.0836, 0.0719, 0.0938, 0.0857, 0.1035, 0.0867, 0.0912, 0.1019, 0.0966,
        0.1082, 0.0770], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:40,755][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.1110, 0.0850, 0.0638, 0.0832, 0.0679, 0.1008, 0.0978, 0.0929, 0.1208,
        0.0697, 0.1068], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:40,757][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.1468, 0.0606, 0.0625, 0.0703, 0.0873, 0.0693, 0.0800, 0.0803, 0.1346,
        0.1122, 0.0959], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:40,759][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.0055, 0.0704, 0.0404, 0.2880, 0.0651, 0.0660, 0.1607, 0.1313, 0.0890,
        0.0601, 0.0235], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:40,760][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.1446, 0.0650, 0.0784, 0.0746, 0.0853, 0.0915, 0.0943, 0.0925, 0.0827,
        0.0976, 0.0935], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:40,762][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0968, 0.1451, 0.0563, 0.1015, 0.0511, 0.1114, 0.1161, 0.0918, 0.0621,
        0.0796, 0.0883], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:40,764][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.0998, 0.0521, 0.0208, 0.1450, 0.0293, 0.3226, 0.0676, 0.0094, 0.1293,
        0.0391, 0.0850], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:40,765][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.0004, 0.0584, 0.1330, 0.0629, 0.1308, 0.0703, 0.0860, 0.1000, 0.0769,
        0.1898, 0.0916], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:40,767][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.0130, 0.0996, 0.1057, 0.0884, 0.0946, 0.0927, 0.0957, 0.1095, 0.0950,
        0.1015, 0.1043], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:40,768][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ at] are: tensor([2.5983e-12, 2.7499e-07, 1.5478e-07, 2.8960e-08, 4.5952e-05, 3.0520e-08,
        1.5611e-11, 7.6899e-06, 2.7059e-01, 6.9622e-01, 3.3136e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:40,770][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0056, 0.4014, 0.0035, 0.1822, 0.0010, 0.3102, 0.0133, 0.0190, 0.0383,
        0.0058, 0.0122, 0.0074], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:40,772][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ the] are: tensor([1.8898e-06, 1.9213e-12, 7.9741e-09, 4.3872e-06, 1.2252e-05, 7.6623e-04,
        5.2261e-04, 1.9524e-01, 1.1629e-02, 2.8688e-01, 2.7589e-01, 2.2905e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:40,773][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0737, 0.0666, 0.0846, 0.0802, 0.0954, 0.0808, 0.0850, 0.0935, 0.0923,
        0.1019, 0.0717, 0.0743], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:40,775][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0882, 0.0789, 0.0576, 0.0768, 0.0615, 0.0935, 0.0891, 0.0854, 0.1133,
        0.0638, 0.1014, 0.0905], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:40,777][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.1370, 0.0519, 0.0584, 0.0637, 0.0800, 0.0632, 0.0736, 0.0731, 0.1232,
        0.1003, 0.0872, 0.0883], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:40,778][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0040, 0.0800, 0.0387, 0.2439, 0.0956, 0.0579, 0.1053, 0.1055, 0.0691,
        0.0467, 0.0435, 0.1097], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:40,780][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.1379, 0.0577, 0.0708, 0.0662, 0.0767, 0.0829, 0.0840, 0.0803, 0.0731,
        0.0864, 0.0859, 0.0981], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:40,782][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0900, 0.1197, 0.0459, 0.0872, 0.0424, 0.0945, 0.0986, 0.0787, 0.0538,
        0.0705, 0.0824, 0.1364], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:40,784][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.1534, 0.0451, 0.0225, 0.1894, 0.0213, 0.3199, 0.0529, 0.0091, 0.0923,
        0.0220, 0.0554, 0.0166], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:40,785][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0003, 0.0513, 0.1202, 0.0617, 0.1200, 0.0639, 0.0801, 0.0919, 0.0819,
        0.1354, 0.1270, 0.0662], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:40,787][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0153, 0.0911, 0.0953, 0.0808, 0.0867, 0.0836, 0.0863, 0.0967, 0.0862,
        0.0912, 0.0924, 0.0943], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:40,788][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ the] are: tensor([9.0653e-13, 3.2570e-08, 1.0985e-08, 6.6078e-08, 6.0844e-06, 3.9824e-09,
        1.3643e-13, 7.3167e-08, 5.0567e-01, 1.0059e-02, 4.8427e-01, 7.5458e-07],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:40,790][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ hospital] are: tensor([0.0025, 0.5706, 0.0024, 0.2180, 0.0025, 0.0445, 0.0804, 0.0116, 0.0229,
        0.0015, 0.0107, 0.0308, 0.0017], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:40,791][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ hospital] are: tensor([1.9246e-05, 1.8452e-12, 2.0756e-09, 3.0130e-06, 7.9156e-06, 3.6923e-04,
        3.9653e-04, 9.8269e-02, 8.0106e-03, 1.1017e-01, 2.3339e-01, 1.9199e-01,
        3.5738e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:40,793][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ hospital] are: tensor([0.0655, 0.0591, 0.0761, 0.0717, 0.0866, 0.0711, 0.0772, 0.0910, 0.0859,
        0.1001, 0.0682, 0.0692, 0.0783], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:40,795][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ hospital] are: tensor([0.2380, 0.0623, 0.0331, 0.0506, 0.0320, 0.0867, 0.0818, 0.0542, 0.1044,
        0.0353, 0.0947, 0.0918, 0.0351], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:40,796][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ hospital] are: tensor([0.1243, 0.0523, 0.0543, 0.0560, 0.0751, 0.0549, 0.0625, 0.0656, 0.1121,
        0.0920, 0.0812, 0.0798, 0.0899], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:40,798][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ hospital] are: tensor([0.0036, 0.0824, 0.0420, 0.2567, 0.0815, 0.0530, 0.0748, 0.0751, 0.1360,
        0.0274, 0.0548, 0.0664, 0.0462], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:40,800][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ hospital] are: tensor([0.1261, 0.0532, 0.0642, 0.0594, 0.0689, 0.0746, 0.0763, 0.0739, 0.0670,
        0.0797, 0.0780, 0.0912, 0.0876], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:40,802][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ hospital] are: tensor([0.0550, 0.0954, 0.0462, 0.0784, 0.0473, 0.1011, 0.0933, 0.0772, 0.0507,
        0.0721, 0.0719, 0.1026, 0.1087], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:40,803][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ hospital] are: tensor([0.1565, 0.0444, 0.0213, 0.1227, 0.0170, 0.2313, 0.0431, 0.0082, 0.1404,
        0.0453, 0.1118, 0.0289, 0.0291], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:40,805][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ hospital] are: tensor([0.0006, 0.0477, 0.1201, 0.0670, 0.0848, 0.0560, 0.0800, 0.0777, 0.0733,
        0.1034, 0.1236, 0.0663, 0.0994], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:40,807][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ hospital] are: tensor([0.0146, 0.0834, 0.0851, 0.0744, 0.0778, 0.0768, 0.0788, 0.0883, 0.0785,
        0.0822, 0.0851, 0.0844, 0.0906], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:40,808][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ hospital] are: tensor([8.6226e-08, 1.1089e-06, 1.6888e-07, 3.5634e-09, 5.9967e-06, 8.5144e-09,
        7.6258e-11, 2.7662e-06, 1.0320e-02, 2.4466e-02, 7.0854e-03, 1.7981e-05,
        9.5810e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:40,810][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.0028, 0.4427, 0.0099, 0.1210, 0.0014, 0.0941, 0.1607, 0.0153, 0.0165,
        0.0051, 0.0054, 0.0660, 0.0057, 0.0536], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:40,811][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [.] are: tensor([9.2172e-07, 1.5583e-13, 5.4942e-10, 5.7323e-07, 2.4103e-06, 8.8825e-05,
        7.1031e-05, 2.2202e-02, 1.7383e-03, 3.4232e-02, 5.1048e-02, 3.0684e-02,
        1.6409e-01, 6.9584e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:40,812][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.0643, 0.0527, 0.0696, 0.0658, 0.0791, 0.0687, 0.0719, 0.0850, 0.0782,
        0.0910, 0.0671, 0.0654, 0.0755, 0.0657], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:40,813][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0954, 0.0641, 0.0464, 0.0620, 0.0483, 0.0845, 0.0816, 0.0700, 0.1009,
        0.0512, 0.0890, 0.0846, 0.0481, 0.0739], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:40,814][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.1127, 0.0456, 0.0524, 0.0539, 0.0727, 0.0519, 0.0601, 0.0634, 0.1081,
        0.0860, 0.0745, 0.0736, 0.0823, 0.0628], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:40,815][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.0040, 0.0608, 0.0471, 0.2154, 0.0833, 0.0479, 0.1090, 0.0868, 0.0585,
        0.0323, 0.0262, 0.1130, 0.0540, 0.0618], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:40,817][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.1131, 0.0460, 0.0588, 0.0542, 0.0640, 0.0697, 0.0709, 0.0694, 0.0632,
        0.0751, 0.0732, 0.0850, 0.0839, 0.0735], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:40,819][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0612, 0.0922, 0.0384, 0.0694, 0.0359, 0.0839, 0.0783, 0.0696, 0.0466,
        0.0622, 0.0638, 0.1020, 0.1000, 0.0965], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:40,820][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.1941, 0.0447, 0.0169, 0.1032, 0.0192, 0.3088, 0.0367, 0.0042, 0.0718,
        0.0380, 0.0708, 0.0177, 0.0306, 0.0435], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:40,822][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.0003, 0.0448, 0.0954, 0.0527, 0.0848, 0.0537, 0.0717, 0.0843, 0.0616,
        0.1247, 0.0865, 0.0581, 0.1201, 0.0612], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:40,824][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.0103, 0.0764, 0.0770, 0.0691, 0.0709, 0.0701, 0.0730, 0.0843, 0.0748,
        0.0771, 0.0771, 0.0789, 0.0823, 0.0786], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:40,825][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [.] are: tensor([2.0441e-13, 7.3347e-11, 5.9776e-10, 5.9856e-13, 3.2368e-08, 1.4341e-12,
        5.8337e-14, 7.2026e-09, 1.0627e-05, 1.5643e-04, 1.2613e-05, 2.0293e-08,
        9.9857e-01, 1.2490e-03], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:40,827][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Anthony] are: tensor([0.0047, 0.4680, 0.0016, 0.1480, 0.0008, 0.0594, 0.0975, 0.0296, 0.0456,
        0.0029, 0.0193, 0.0427, 0.0025, 0.0754, 0.0019], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:40,828][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Anthony] are: tensor([1.3284e-05, 1.2456e-12, 4.9807e-09, 5.1911e-06, 1.4315e-05, 2.7288e-04,
        3.3489e-04, 3.6097e-02, 7.0693e-03, 4.1962e-02, 1.0136e-01, 5.4198e-02,
        1.3179e-01, 5.0229e-01, 1.2459e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:40,829][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Anthony] are: tensor([0.0630, 0.0505, 0.0613, 0.0588, 0.0737, 0.0604, 0.0640, 0.0778, 0.0756,
        0.0869, 0.0623, 0.0610, 0.0692, 0.0601, 0.0753], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:40,831][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Anthony] are: tensor([0.1751, 0.0548, 0.0302, 0.0494, 0.0303, 0.0811, 0.0754, 0.0534, 0.1023,
        0.0343, 0.0907, 0.0830, 0.0329, 0.0714, 0.0358], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:40,833][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Anthony] are: tensor([0.1209, 0.0415, 0.0464, 0.0473, 0.0671, 0.0468, 0.0536, 0.0596, 0.0969,
        0.0794, 0.0690, 0.0699, 0.0772, 0.0599, 0.0645], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:40,835][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Anthony] are: tensor([0.0031, 0.0492, 0.0178, 0.1655, 0.0698, 0.0330, 0.0885, 0.1044, 0.0851,
        0.0266, 0.0419, 0.0958, 0.0669, 0.1179, 0.0345], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:40,837][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Anthony] are: tensor([0.1106, 0.0416, 0.0526, 0.0490, 0.0581, 0.0647, 0.0661, 0.0635, 0.0570,
        0.0695, 0.0682, 0.0806, 0.0788, 0.0705, 0.0692], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:40,838][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Anthony] are: tensor([0.0383, 0.0735, 0.0380, 0.0619, 0.0400, 0.0804, 0.0755, 0.0624, 0.0437,
        0.0595, 0.0646, 0.0910, 0.0907, 0.0926, 0.0879], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:40,840][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Anthony] are: tensor([0.2814, 0.0331, 0.0153, 0.1008, 0.0271, 0.2760, 0.0529, 0.0032, 0.0467,
        0.0363, 0.0561, 0.0191, 0.0163, 0.0256, 0.0102], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:40,842][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Anthony] are: tensor([0.0003, 0.0346, 0.0756, 0.0448, 0.0691, 0.0541, 0.0616, 0.0699, 0.0551,
        0.1118, 0.0873, 0.0526, 0.1178, 0.0596, 0.1057], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:40,844][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Anthony] are: tensor([0.0070, 0.0699, 0.0724, 0.0632, 0.0673, 0.0671, 0.0688, 0.0794, 0.0689,
        0.0718, 0.0716, 0.0744, 0.0766, 0.0718, 0.0698], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:40,845][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Anthony] are: tensor([4.9686e-08, 2.8234e-07, 3.8623e-12, 1.0246e-11, 1.1962e-09, 1.1302e-11,
        1.8407e-13, 6.3053e-10, 3.1264e-06, 6.4904e-06, 3.0932e-05, 3.9581e-07,
        4.1321e-01, 2.8149e-01, 3.0526e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:40,846][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([2.7995e-03, 4.7778e-01, 2.2726e-03, 1.8472e-01, 1.8635e-04, 7.3945e-02,
        9.4745e-02, 5.9347e-03, 4.7792e-02, 6.5612e-04, 1.5128e-02, 3.5621e-02,
        1.6578e-03, 5.3588e-02, 1.6316e-03, 1.5399e-03], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:40,848][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([1.4118e-05, 6.3704e-13, 1.8594e-09, 2.2700e-06, 5.9849e-06, 9.1281e-05,
        1.3367e-04, 8.1270e-03, 1.9979e-03, 8.1036e-03, 2.6372e-02, 1.5690e-02,
        2.9112e-02, 1.6794e-01, 1.0332e-01, 6.3909e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:40,850][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0615, 0.0491, 0.0590, 0.0549, 0.0654, 0.0549, 0.0586, 0.0680, 0.0667,
        0.0781, 0.0595, 0.0571, 0.0673, 0.0605, 0.0724, 0.0669],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:40,851][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.0839, 0.0556, 0.0395, 0.0548, 0.0423, 0.0685, 0.0657, 0.0604, 0.0869,
        0.0443, 0.0793, 0.0700, 0.0456, 0.0695, 0.0492, 0.0844],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:40,853][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.0973, 0.0436, 0.0473, 0.0480, 0.0669, 0.0485, 0.0535, 0.0570, 0.0945,
        0.0737, 0.0648, 0.0643, 0.0709, 0.0546, 0.0595, 0.0557],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:40,855][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.0032, 0.0611, 0.0323, 0.1584, 0.0902, 0.0396, 0.0879, 0.0735, 0.1009,
        0.0241, 0.0193, 0.0756, 0.0624, 0.0914, 0.0588, 0.0214],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:40,857][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0991, 0.0436, 0.0516, 0.0488, 0.0554, 0.0599, 0.0614, 0.0600, 0.0546,
        0.0646, 0.0622, 0.0725, 0.0698, 0.0631, 0.0629, 0.0704],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:40,858][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0392, 0.0651, 0.0290, 0.0569, 0.0299, 0.0708, 0.0665, 0.0561, 0.0388,
        0.0512, 0.0564, 0.0843, 0.0810, 0.0829, 0.0744, 0.1172],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:40,860][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.0811, 0.0243, 0.0199, 0.1148, 0.0122, 0.1503, 0.0493, 0.0079, 0.1250,
        0.0382, 0.1270, 0.0266, 0.0378, 0.0356, 0.0140, 0.1360],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:40,862][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.0003, 0.0351, 0.0744, 0.0445, 0.0704, 0.0417, 0.0551, 0.0652, 0.0525,
        0.0958, 0.0889, 0.0566, 0.0884, 0.0620, 0.0973, 0.0719],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:40,864][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0108, 0.0673, 0.0689, 0.0598, 0.0629, 0.0615, 0.0638, 0.0737, 0.0641,
        0.0664, 0.0684, 0.0676, 0.0729, 0.0654, 0.0641, 0.0624],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:40,865][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([1.5272e-13, 7.2535e-11, 1.3742e-11, 1.9205e-12, 7.0024e-10, 2.1201e-13,
        7.4891e-16, 3.3293e-11, 1.7784e-07, 4.0785e-07, 5.2876e-07, 1.1184e-09,
        1.1987e-02, 2.1264e-03, 9.8589e-01, 9.2951e-08], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:40,867][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0087, 0.4888, 0.0013, 0.1184, 0.0006, 0.1741, 0.0066, 0.0136, 0.0317,
        0.0020, 0.0128, 0.0073, 0.0024, 0.0917, 0.0021, 0.0329, 0.0050],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:40,868][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ a] are: tensor([9.5450e-07, 1.1169e-13, 4.9940e-10, 4.2590e-07, 1.4778e-06, 3.1858e-05,
        2.5588e-05, 4.0579e-03, 4.6124e-04, 5.1227e-03, 6.2711e-03, 3.6067e-03,
        2.6804e-02, 7.5214e-02, 4.9898e-02, 5.7888e-01, 2.4963e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:40,870][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0532, 0.0486, 0.0561, 0.0537, 0.0647, 0.0557, 0.0570, 0.0662, 0.0656,
        0.0747, 0.0520, 0.0528, 0.0611, 0.0551, 0.0684, 0.0608, 0.0545],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:40,872][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0646, 0.0554, 0.0403, 0.0535, 0.0424, 0.0626, 0.0590, 0.0583, 0.0791,
        0.0443, 0.0720, 0.0624, 0.0425, 0.0625, 0.0473, 0.0787, 0.0750],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:40,873][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.1044, 0.0364, 0.0427, 0.0446, 0.0613, 0.0449, 0.0510, 0.0533, 0.0878,
        0.0688, 0.0607, 0.0595, 0.0682, 0.0513, 0.0549, 0.0516, 0.0586],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:40,874][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0033, 0.0592, 0.0306, 0.1290, 0.0516, 0.0445, 0.0477, 0.0593, 0.0757,
        0.0341, 0.0244, 0.0904, 0.0559, 0.1292, 0.0574, 0.0494, 0.0584],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:40,875][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0965, 0.0395, 0.0478, 0.0448, 0.0512, 0.0559, 0.0567, 0.0549, 0.0500,
        0.0597, 0.0580, 0.0666, 0.0647, 0.0580, 0.0578, 0.0660, 0.0720],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:40,876][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0438, 0.0636, 0.0245, 0.0509, 0.0238, 0.0591, 0.0596, 0.0505, 0.0341,
        0.0432, 0.0495, 0.0804, 0.0702, 0.0731, 0.0635, 0.1006, 0.1097],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:40,878][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.1795, 0.0801, 0.0230, 0.0887, 0.0146, 0.1500, 0.0221, 0.0065, 0.0452,
        0.0290, 0.0485, 0.0106, 0.0282, 0.0172, 0.0088, 0.2246, 0.0234],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:40,880][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0002, 0.0331, 0.0727, 0.0389, 0.0716, 0.0397, 0.0450, 0.0579, 0.0487,
        0.0791, 0.0777, 0.0389, 0.1083, 0.0558, 0.1019, 0.0830, 0.0477],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:40,881][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0099, 0.0630, 0.0648, 0.0559, 0.0597, 0.0579, 0.0604, 0.0687, 0.0600,
        0.0626, 0.0643, 0.0641, 0.0677, 0.0609, 0.0606, 0.0580, 0.0612],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:40,883][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ a] are: tensor([7.2635e-15, 1.8492e-11, 2.1220e-12, 1.3204e-14, 5.3810e-10, 1.9748e-14,
        1.5646e-19, 5.0896e-12, 9.5920e-08, 7.8463e-07, 1.8922e-07, 7.5124e-12,
        4.8954e-02, 9.5234e-03, 9.4151e-01, 8.4290e-06, 2.9197e-08],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:40,884][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ drink] are: tensor([0.0017, 0.5104, 0.0085, 0.1800, 0.0020, 0.0760, 0.0672, 0.0158, 0.0087,
        0.0014, 0.0040, 0.0206, 0.0021, 0.0511, 0.0053, 0.0110, 0.0330, 0.0011],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:40,885][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ drink] are: tensor([3.9117e-06, 2.1051e-14, 3.6178e-11, 8.6227e-08, 3.7518e-07, 4.4074e-06,
        5.9341e-06, 4.4560e-04, 1.1944e-04, 6.2397e-04, 2.0924e-03, 1.0414e-03,
        1.6785e-03, 1.2803e-02, 6.6136e-03, 8.4821e-02, 9.1506e-02, 7.9824e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:40,887][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ drink] are: tensor([0.0472, 0.0457, 0.0529, 0.0494, 0.0600, 0.0480, 0.0530, 0.0627, 0.0613,
        0.0689, 0.0484, 0.0504, 0.0586, 0.0529, 0.0668, 0.0568, 0.0511, 0.0658],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:40,889][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ drink] are: tensor([0.1528, 0.0446, 0.0247, 0.0391, 0.0245, 0.0630, 0.0595, 0.0425, 0.0784,
        0.0273, 0.0687, 0.0666, 0.0282, 0.0582, 0.0310, 0.0776, 0.0831, 0.0303],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:40,891][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ drink] are: tensor([0.0950, 0.0389, 0.0435, 0.0438, 0.0592, 0.0425, 0.0474, 0.0508, 0.0824,
        0.0649, 0.0566, 0.0554, 0.0634, 0.0484, 0.0513, 0.0480, 0.0541, 0.0545],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:40,893][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ drink] are: tensor([0.0017, 0.0500, 0.0369, 0.1529, 0.0534, 0.0630, 0.0502, 0.0343, 0.0953,
        0.0165, 0.0306, 0.0560, 0.0433, 0.1097, 0.0759, 0.0539, 0.0598, 0.0167],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:40,894][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ drink] are: tensor([0.0889, 0.0367, 0.0447, 0.0417, 0.0478, 0.0520, 0.0530, 0.0517, 0.0474,
        0.0564, 0.0545, 0.0632, 0.0608, 0.0543, 0.0545, 0.0619, 0.0681, 0.0624],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:40,896][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ drink] are: tensor([0.0407, 0.0530, 0.0181, 0.0435, 0.0182, 0.0498, 0.0536, 0.0425, 0.0280,
        0.0337, 0.0414, 0.0689, 0.0562, 0.0648, 0.0496, 0.0868, 0.0973, 0.1539],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:40,898][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ drink] are: tensor([0.4263, 0.0193, 0.0095, 0.0610, 0.0093, 0.1380, 0.0263, 0.0045, 0.0408,
        0.0169, 0.0496, 0.0124, 0.0222, 0.0233, 0.0122, 0.1055, 0.0177, 0.0051],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:40,900][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ drink] are: tensor([0.0002, 0.0295, 0.0753, 0.0419, 0.0662, 0.0355, 0.0504, 0.0512, 0.0439,
        0.0720, 0.0634, 0.0380, 0.0807, 0.0461, 0.1019, 0.0733, 0.0513, 0.0791],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:40,902][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ drink] are: tensor([0.0076, 0.0596, 0.0604, 0.0519, 0.0546, 0.0536, 0.0567, 0.0643, 0.0559,
        0.0587, 0.0612, 0.0607, 0.0646, 0.0574, 0.0547, 0.0541, 0.0583, 0.0657],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:40,903][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ drink] are: tensor([5.9258e-14, 4.4532e-12, 8.7469e-12, 7.2110e-13, 1.0777e-09, 1.7863e-12,
        5.3293e-14, 3.7051e-10, 1.0085e-06, 7.8364e-07, 3.6199e-06, 1.0853e-08,
        1.0071e-02, 3.7292e-03, 9.8608e-01, 9.7470e-06, 9.2836e-05, 1.4738e-05],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:40,905][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0126, 0.3645, 0.0052, 0.0840, 0.0005, 0.1931, 0.0972, 0.0252, 0.0115,
        0.0039, 0.0027, 0.0497, 0.0054, 0.0499, 0.0043, 0.0345, 0.0401, 0.0034,
        0.0125], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:40,906][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ to] are: tensor([2.4662e-08, 9.3485e-15, 5.3432e-11, 3.5549e-08, 1.1041e-07, 3.4050e-06,
        2.5089e-06, 3.9712e-04, 3.5482e-05, 6.2266e-04, 5.1318e-04, 2.9319e-04,
        2.7849e-03, 6.6911e-03, 5.7984e-03, 1.0238e-01, 3.2607e-02, 8.2014e-01,
        2.7731e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:40,908][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0446, 0.0402, 0.0536, 0.0502, 0.0598, 0.0522, 0.0540, 0.0612, 0.0563,
        0.0663, 0.0459, 0.0464, 0.0524, 0.0479, 0.0600, 0.0550, 0.0507, 0.0596,
        0.0440], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:40,910][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0726, 0.0505, 0.0357, 0.0459, 0.0379, 0.0538, 0.0523, 0.0517, 0.0707,
        0.0371, 0.0650, 0.0559, 0.0341, 0.0540, 0.0402, 0.0641, 0.0675, 0.0385,
        0.0727], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:40,912][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.1019, 0.0358, 0.0401, 0.0411, 0.0557, 0.0404, 0.0453, 0.0483, 0.0753,
        0.0627, 0.0524, 0.0524, 0.0599, 0.0463, 0.0475, 0.0464, 0.0517, 0.0521,
        0.0447], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:40,914][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0022, 0.0369, 0.0242, 0.1435, 0.0385, 0.0263, 0.0755, 0.0633, 0.0613,
        0.0318, 0.0172, 0.0983, 0.0511, 0.0990, 0.0486, 0.0311, 0.0845, 0.0499,
        0.0168], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:40,915][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0812, 0.0326, 0.0413, 0.0388, 0.0449, 0.0492, 0.0505, 0.0489, 0.0449,
        0.0531, 0.0518, 0.0603, 0.0591, 0.0525, 0.0526, 0.0592, 0.0654, 0.0604,
        0.0532], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:40,917][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0397, 0.0430, 0.0168, 0.0338, 0.0165, 0.0377, 0.0405, 0.0347, 0.0232,
        0.0291, 0.0347, 0.0610, 0.0550, 0.0560, 0.0501, 0.0768, 0.0848, 0.1364,
        0.1302], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:40,919][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.1183, 0.0625, 0.0179, 0.0755, 0.0149, 0.1518, 0.0309, 0.0038, 0.0452,
        0.0274, 0.0632, 0.0144, 0.0192, 0.0272, 0.0104, 0.2229, 0.0314, 0.0067,
        0.0566], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:40,921][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0001, 0.0258, 0.0663, 0.0312, 0.0637, 0.0288, 0.0445, 0.0479, 0.0412,
        0.0794, 0.0572, 0.0317, 0.0913, 0.0460, 0.0953, 0.0691, 0.0471, 0.1024,
        0.0307], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:40,923][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0058, 0.0546, 0.0558, 0.0477, 0.0512, 0.0506, 0.0540, 0.0638, 0.0532,
        0.0566, 0.0567, 0.0584, 0.0607, 0.0545, 0.0531, 0.0505, 0.0552, 0.0599,
        0.0576], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:40,924][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ to] are: tensor([3.3291e-14, 4.2819e-12, 7.6871e-14, 3.2843e-18, 5.5480e-11, 1.4576e-16,
        3.1589e-20, 8.5434e-13, 2.1283e-11, 6.5299e-08, 6.4735e-11, 7.9187e-14,
        1.8167e-01, 5.3316e-05, 4.0315e-01, 2.1155e-06, 6.0395e-08, 1.3016e-01,
        2.8497e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:40,979][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:21:40,980][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:40,980][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:40,981][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:40,981][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:40,981][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:40,982][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:40,982][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:40,982][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:40,983][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:40,983][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:40,983][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:40,984][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:40,984][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.6267, 0.3733], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:40,984][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.2385, 0.7615], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:40,985][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0870, 0.9130], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:40,985][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.7736, 0.2264], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:40,985][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.6623, 0.3377], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:40,985][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.2822, 0.7178], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:40,986][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.2607, 0.7393], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:40,986][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.1283, 0.8717], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:40,986][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0880, 0.9120], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:40,987][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.9379, 0.0621], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:40,987][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.1291, 0.8709], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:40,987][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.9662, 0.0338], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:40,988][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Anthony] are: tensor([0.0949, 0.7481, 0.1570], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:40,988][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Anthony] are: tensor([0.0864, 0.7032, 0.2104], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:40,988][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Anthony] are: tensor([0.0360, 0.4714, 0.4926], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:40,989][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Anthony] are: tensor([0.5161, 0.0504, 0.4335], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:40,989][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Anthony] are: tensor([0.5764, 0.1706, 0.2530], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:40,989][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Anthony] are: tensor([0.0687, 0.5631, 0.3682], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:40,990][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Anthony] are: tensor([0.1533, 0.4336, 0.4132], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:40,990][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Anthony] are: tensor([0.0267, 0.1318, 0.8415], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:40,990][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Anthony] are: tensor([0.0481, 0.4109, 0.5410], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:40,991][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Anthony] are: tensor([0.7361, 0.1899, 0.0739], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:41,001][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Anthony] are: tensor([0.0590, 0.5118, 0.4292], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:41,002][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Anthony] are: tensor([1.3028e-04, 9.9987e-01, 2.5245e-06], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:41,003][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0773, 0.2654, 0.0437, 0.6136], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:41,005][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0423, 0.4358, 0.1742, 0.3477], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:41,006][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0243, 0.3230, 0.3442, 0.3085], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:41,007][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.1225, 0.0375, 0.3626, 0.4774], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:41,009][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.4499, 0.1484, 0.2005, 0.2012], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:41,010][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0544, 0.2337, 0.2184, 0.4935], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:41,011][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0920, 0.2988, 0.3036, 0.3056], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:41,011][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0162, 0.0900, 0.4601, 0.4337], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:41,011][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0294, 0.2772, 0.3681, 0.3254], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:41,012][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.8311, 0.0892, 0.0555, 0.0242], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:41,012][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0495, 0.3367, 0.3188, 0.2950], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:41,013][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([4.3902e-06, 9.5166e-01, 2.7974e-03, 4.5541e-02], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:41,013][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Travis] are: tensor([0.0303, 0.1347, 0.0613, 0.7141, 0.0597], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:41,013][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Travis] are: tensor([0.0441, 0.3946, 0.1139, 0.3662, 0.0812], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:41,014][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Travis] are: tensor([0.0171, 0.2453, 0.2574, 0.2303, 0.2499], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:41,014][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Travis] are: tensor([0.5235, 0.0084, 0.0503, 0.1941, 0.2236], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:41,016][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Travis] are: tensor([0.4644, 0.1161, 0.1649, 0.1562, 0.0983], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:41,017][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Travis] are: tensor([0.0297, 0.1834, 0.1424, 0.4074, 0.2372], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:41,018][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Travis] are: tensor([0.0784, 0.2306, 0.2253, 0.2412, 0.2244], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:41,020][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Travis] are: tensor([0.0090, 0.0260, 0.1790, 0.1043, 0.6816], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:41,021][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Travis] are: tensor([0.0237, 0.2035, 0.2690, 0.2381, 0.2656], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:41,022][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Travis] are: tensor([0.5860, 0.1126, 0.0687, 0.1318, 0.1009], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:41,024][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Travis] are: tensor([0.0411, 0.2493, 0.2302, 0.2190, 0.2603], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:41,025][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Travis] are: tensor([3.3658e-05, 3.2849e-01, 5.9483e-05, 6.7134e-01, 7.1514e-05],
       device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:41,026][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.0114, 0.1192, 0.0221, 0.7174, 0.0609, 0.0690], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:41,027][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.0569, 0.3118, 0.1212, 0.3449, 0.0951, 0.0702], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:41,029][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.0132, 0.1952, 0.2078, 0.1851, 0.2023, 0.1963], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:41,030][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.0199, 0.0078, 0.0501, 0.1424, 0.2284, 0.5514], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:41,032][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.3929, 0.0961, 0.1484, 0.1449, 0.0897, 0.1280], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:41,033][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.0265, 0.1211, 0.1205, 0.3453, 0.2864, 0.1001], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:41,034][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.0627, 0.1851, 0.1871, 0.1926, 0.1923, 0.1802], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:41,036][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.0079, 0.0294, 0.1219, 0.0873, 0.4085, 0.3450], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:41,037][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.0158, 0.1612, 0.2155, 0.1895, 0.2134, 0.2046], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:41,038][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.2121, 0.2507, 0.0870, 0.1235, 0.1684, 0.1584], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:41,040][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.0320, 0.2053, 0.1910, 0.1738, 0.2090, 0.1889], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:41,041][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([6.7137e-09, 1.7909e-02, 2.6882e-04, 5.0759e-01, 4.7405e-01, 1.8555e-04],
       device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:41,042][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0094, 0.1265, 0.0207, 0.4999, 0.0584, 0.2426, 0.0426],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:41,044][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0622, 0.2796, 0.1278, 0.2538, 0.1048, 0.0792, 0.0926],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:41,045][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0115, 0.1617, 0.1726, 0.1530, 0.1679, 0.1625, 0.1707],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:41,047][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0085, 0.0054, 0.0479, 0.1123, 0.2184, 0.4207, 0.1869],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:41,048][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.3527, 0.0853, 0.1330, 0.1254, 0.0813, 0.1179, 0.1045],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:41,049][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0137, 0.1055, 0.0867, 0.2271, 0.1912, 0.0727, 0.3031],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:41,051][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0482, 0.1555, 0.1572, 0.1645, 0.1622, 0.1585, 0.1539],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:41,052][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0115, 0.0288, 0.0791, 0.0737, 0.2236, 0.2138, 0.3695],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:41,054][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0127, 0.1346, 0.1808, 0.1587, 0.1788, 0.1717, 0.1626],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:41,055][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.3250, 0.1300, 0.0540, 0.0786, 0.1352, 0.1848, 0.0924],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:41,056][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0271, 0.1685, 0.1596, 0.1490, 0.1722, 0.1515, 0.1721],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:41,057][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([1.5889e-07, 1.1785e-01, 3.2974e-04, 4.1078e-01, 1.9974e-01, 2.7128e-01,
        1.4291e-05], device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:41,059][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ lot] are: tensor([0.0175, 0.0853, 0.0255, 0.4178, 0.0567, 0.2419, 0.0700, 0.0853],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:41,060][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ lot] are: tensor([0.0431, 0.2613, 0.0992, 0.3047, 0.0706, 0.0666, 0.1116, 0.0428],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:41,062][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ lot] are: tensor([0.0101, 0.1388, 0.1471, 0.1301, 0.1417, 0.1376, 0.1437, 0.1509],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:41,063][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ lot] are: tensor([0.0346, 0.0039, 0.0301, 0.1019, 0.1543, 0.4595, 0.1846, 0.0312],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:41,065][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ lot] are: tensor([0.3852, 0.0837, 0.1167, 0.1083, 0.0673, 0.0943, 0.0797, 0.0648],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:41,066][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ lot] are: tensor([0.0105, 0.0674, 0.0677, 0.1975, 0.1309, 0.0520, 0.2853, 0.1888],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:41,067][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ lot] are: tensor([0.0414, 0.1338, 0.1357, 0.1413, 0.1407, 0.1398, 0.1353, 0.1319],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:41,069][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ lot] are: tensor([0.0087, 0.0198, 0.0626, 0.0427, 0.1555, 0.1178, 0.1876, 0.4051],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:41,069][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ lot] are: tensor([0.0107, 0.1139, 0.1541, 0.1346, 0.1520, 0.1465, 0.1390, 0.1492],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:41,070][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ lot] are: tensor([0.2428, 0.1162, 0.0625, 0.0879, 0.1108, 0.1264, 0.1194, 0.1340],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:41,070][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ lot] are: tensor([0.0216, 0.1448, 0.1251, 0.1248, 0.1427, 0.1255, 0.1456, 0.1698],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:41,071][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ lot] are: tensor([3.2480e-05, 5.9804e-02, 1.5506e-02, 2.8092e-02, 6.6482e-01, 1.4103e-02,
        2.0215e-01, 1.5497e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:41,071][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([0.0281, 0.0829, 0.0125, 0.1079, 0.0238, 0.0824, 0.0181, 0.0325, 0.6117],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:41,071][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([0.0394, 0.2177, 0.1056, 0.2395, 0.0879, 0.0671, 0.1179, 0.0751, 0.0497],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:41,072][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([0.0073, 0.1191, 0.1285, 0.1139, 0.1263, 0.1216, 0.1272, 0.1342, 0.1218],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:41,073][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([0.0170, 0.0048, 0.0254, 0.0827, 0.1174, 0.3235, 0.1652, 0.0481, 0.2159],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:41,074][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([0.3408, 0.0810, 0.1070, 0.1144, 0.0692, 0.0952, 0.0819, 0.0653, 0.0453],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:41,075][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([0.0132, 0.0542, 0.0585, 0.1485, 0.1057, 0.0484, 0.2712, 0.1834, 0.1171],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:41,077][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([0.0376, 0.1182, 0.1188, 0.1238, 0.1219, 0.1206, 0.1200, 0.1150, 0.1240],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:41,078][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([0.0096, 0.0130, 0.0281, 0.0232, 0.0663, 0.0662, 0.1229, 0.2086, 0.4621],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:41,079][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([0.0102, 0.1005, 0.1350, 0.1179, 0.1329, 0.1277, 0.1207, 0.1301, 0.1252],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:41,081][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([0.5350, 0.0525, 0.0208, 0.0161, 0.0279, 0.0462, 0.0332, 0.0691, 0.1994],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:41,082][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([0.0179, 0.1305, 0.1180, 0.1091, 0.1287, 0.1103, 0.1250, 0.1391, 0.1214],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:41,083][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([3.1112e-09, 4.5797e-06, 2.4241e-08, 5.3765e-08, 5.0460e-05, 3.6347e-07,
        6.4701e-10, 1.0348e-02, 9.8960e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:41,085][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ fun] are: tensor([0.0087, 0.0206, 0.0048, 0.0481, 0.0125, 0.0474, 0.0128, 0.0287, 0.5831,
        0.2334], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:41,086][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ fun] are: tensor([0.0402, 0.1753, 0.0921, 0.2180, 0.0902, 0.0695, 0.1061, 0.0723, 0.1167,
        0.0196], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:41,087][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ fun] are: tensor([0.0079, 0.1075, 0.1141, 0.1015, 0.1101, 0.1071, 0.1120, 0.1179, 0.1071,
        0.1148], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:41,089][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ fun] are: tensor([0.0798, 0.0044, 0.0172, 0.0770, 0.0601, 0.3203, 0.1510, 0.0294, 0.1910,
        0.0699], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:41,090][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ fun] are: tensor([0.2995, 0.0727, 0.0987, 0.1064, 0.0640, 0.0915, 0.0776, 0.0649, 0.0406,
        0.0840], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:41,092][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ fun] are: tensor([0.0110, 0.0496, 0.0549, 0.1237, 0.1264, 0.0427, 0.1857, 0.1708, 0.1608,
        0.0745], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:41,093][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ fun] are: tensor([0.0405, 0.1055, 0.1035, 0.1097, 0.1052, 0.1084, 0.1025, 0.1049, 0.1148,
        0.1049], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:41,095][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ fun] are: tensor([0.0069, 0.0094, 0.0235, 0.0211, 0.0535, 0.0552, 0.0843, 0.1343, 0.2784,
        0.3333], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:41,096][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ fun] are: tensor([0.0094, 0.0863, 0.1163, 0.1023, 0.1147, 0.1108, 0.1052, 0.1126, 0.1091,
        0.1334], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:41,098][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ fun] are: tensor([0.2079, 0.0578, 0.0283, 0.0279, 0.0361, 0.0589, 0.0268, 0.0816, 0.2797,
        0.1950], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:41,099][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ fun] are: tensor([0.0144, 0.1106, 0.0980, 0.1017, 0.1086, 0.1017, 0.1125, 0.1313, 0.1141,
        0.1071], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:41,100][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ fun] are: tensor([1.5268e-10, 1.0443e-07, 2.2668e-09, 1.1352e-07, 5.5473e-07, 1.9638e-07,
        1.1153e-09, 3.0822e-06, 9.9881e-01, 1.1815e-03], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:41,101][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.0070, 0.0156, 0.0011, 0.0131, 0.0018, 0.0109, 0.0037, 0.0170, 0.2716,
        0.6227, 0.0354], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:41,103][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.0373, 0.2215, 0.1073, 0.1770, 0.0882, 0.0928, 0.0904, 0.0637, 0.0608,
        0.0297, 0.0312], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:41,104][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.0053, 0.0959, 0.1039, 0.0915, 0.1020, 0.0975, 0.1024, 0.1080, 0.0976,
        0.1054, 0.0905], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:41,106][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.0211, 0.0048, 0.0227, 0.0809, 0.0897, 0.2346, 0.1385, 0.0418, 0.1933,
        0.0789, 0.0936], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:41,107][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.2299, 0.0644, 0.0969, 0.1009, 0.0637, 0.0928, 0.0844, 0.0682, 0.0404,
        0.0906, 0.0678], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:41,109][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.0117, 0.0463, 0.0411, 0.1368, 0.0766, 0.0373, 0.2177, 0.1264, 0.1281,
        0.0904, 0.0876], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:41,110][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.0339, 0.0947, 0.0948, 0.0982, 0.0974, 0.0972, 0.0963, 0.0942, 0.1030,
        0.1008, 0.0895], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:41,112][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.0055, 0.0072, 0.0144, 0.0137, 0.0298, 0.0335, 0.0596, 0.0966, 0.2116,
        0.2366, 0.2914], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:41,113][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.0076, 0.0783, 0.1058, 0.0926, 0.1050, 0.1006, 0.0952, 0.1021, 0.0985,
        0.1199, 0.0944], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:41,115][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.2046, 0.0339, 0.0093, 0.0122, 0.0173, 0.0230, 0.0210, 0.0330, 0.1534,
        0.2811, 0.2109], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:41,116][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.0134, 0.1053, 0.0983, 0.0906, 0.1089, 0.0889, 0.1024, 0.1122, 0.0999,
        0.0908, 0.0894], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:41,117][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([1.0842e-11, 7.7984e-08, 1.6270e-10, 1.2784e-09, 4.1462e-08, 5.6058e-09,
        7.6545e-12, 1.1910e-05, 4.9256e-02, 9.2260e-01, 2.8133e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:41,118][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0062, 0.0167, 0.0011, 0.0138, 0.0027, 0.0096, 0.0013, 0.0118, 0.2843,
        0.3101, 0.2662, 0.0763], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:41,120][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0348, 0.2028, 0.0702, 0.1618, 0.0731, 0.0713, 0.0623, 0.0610, 0.0717,
        0.0344, 0.0795, 0.0772], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:41,121][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0054, 0.0874, 0.0945, 0.0835, 0.0923, 0.0891, 0.0934, 0.0985, 0.0896,
        0.0965, 0.0837, 0.0861], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:41,123][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0045, 0.0031, 0.0198, 0.0689, 0.1028, 0.2078, 0.1115, 0.0420, 0.1930,
        0.0740, 0.0949, 0.0778], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:41,124][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.2321, 0.0591, 0.0921, 0.0915, 0.0619, 0.0856, 0.0776, 0.0611, 0.0384,
        0.0834, 0.0637, 0.0535], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:41,126][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.0066, 0.0387, 0.0339, 0.1029, 0.0766, 0.0312, 0.1626, 0.1225, 0.0980,
        0.0742, 0.1020, 0.1507], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:41,127][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0272, 0.0854, 0.0873, 0.0907, 0.0895, 0.0879, 0.0880, 0.0861, 0.0925,
        0.0910, 0.0849, 0.0896], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:41,128][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0040, 0.0049, 0.0113, 0.0102, 0.0272, 0.0307, 0.0508, 0.0796, 0.1673,
        0.2063, 0.2466, 0.1610], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:41,128][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0072, 0.0714, 0.0964, 0.0849, 0.0955, 0.0918, 0.0866, 0.0933, 0.0900,
        0.1104, 0.0861, 0.0864], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:41,128][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.2442, 0.0177, 0.0069, 0.0058, 0.0161, 0.0151, 0.0097, 0.0238, 0.1097,
        0.1641, 0.2821, 0.1048], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:41,129][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0139, 0.0929, 0.0822, 0.0831, 0.0928, 0.0883, 0.0931, 0.1061, 0.0903,
        0.0841, 0.0825, 0.0908], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:41,129][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([8.4024e-12, 9.9852e-09, 1.6873e-11, 1.5419e-09, 7.7985e-09, 1.1386e-09,
        8.5796e-14, 2.2684e-07, 1.3123e-01, 2.3572e-02, 8.4519e-01, 7.8930e-06],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:41,130][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ hospital] are: tensor([0.0171, 0.0097, 0.0004, 0.0040, 0.0018, 0.0049, 0.0020, 0.0083, 0.1186,
        0.1194, 0.2200, 0.0840, 0.4098], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:41,130][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ hospital] are: tensor([0.0189, 0.1883, 0.0617, 0.2014, 0.0516, 0.0576, 0.0643, 0.0416, 0.0865,
        0.0188, 0.0650, 0.0872, 0.0571], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:41,131][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ hospital] are: tensor([0.0058, 0.0813, 0.0860, 0.0767, 0.0833, 0.0813, 0.0850, 0.0893, 0.0817,
        0.0879, 0.0769, 0.0787, 0.0862], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:41,133][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ hospital] are: tensor([0.0785, 0.0035, 0.0125, 0.0598, 0.0396, 0.2392, 0.1253, 0.0220, 0.1547,
        0.0469, 0.0969, 0.1031, 0.0180], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:41,134][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ hospital] are: tensor([0.2835, 0.0614, 0.0854, 0.0826, 0.0508, 0.0735, 0.0627, 0.0500, 0.0310,
        0.0662, 0.0533, 0.0430, 0.0565], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:41,136][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ hospital] are: tensor([0.0051, 0.0337, 0.0285, 0.0875, 0.0661, 0.0261, 0.1160, 0.0898, 0.1299,
        0.0485, 0.1162, 0.1175, 0.1352], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:41,137][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ hospital] are: tensor([0.0269, 0.0791, 0.0792, 0.0827, 0.0816, 0.0824, 0.0795, 0.0801, 0.0880,
        0.0852, 0.0766, 0.0852, 0.0733], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:41,138][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ hospital] are: tensor([0.0056, 0.0052, 0.0099, 0.0077, 0.0214, 0.0229, 0.0369, 0.0621, 0.1197,
        0.1598, 0.1784, 0.1157, 0.2547], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:41,140][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ hospital] are: tensor([0.0065, 0.0645, 0.0877, 0.0772, 0.0873, 0.0837, 0.0794, 0.0844, 0.0821,
        0.1001, 0.0784, 0.0796, 0.0889], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:41,141][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ hospital] are: tensor([0.1805, 0.0222, 0.0099, 0.0098, 0.0159, 0.0110, 0.0116, 0.0211, 0.0701,
        0.0723, 0.2566, 0.0940, 0.2249], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:41,143][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ hospital] are: tensor([0.0093, 0.0879, 0.0734, 0.0757, 0.0902, 0.0763, 0.0886, 0.1035, 0.0824,
        0.0785, 0.0708, 0.0829, 0.0806], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:41,144][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ hospital] are: tensor([3.9707e-08, 1.6864e-07, 2.4284e-10, 4.5927e-10, 8.0481e-09, 2.1161e-09,
        7.3024e-11, 2.7828e-06, 4.5684e-03, 2.3859e-02, 1.6501e-02, 2.8043e-04,
        9.5479e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:41,144][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([1.5670e-02, 7.9766e-03, 2.2257e-04, 2.8920e-03, 2.7219e-04, 2.9344e-03,
        8.3109e-04, 4.8416e-03, 4.5916e-02, 5.9089e-02, 2.9031e-02, 3.0920e-02,
        2.1153e-01, 5.8787e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:41,146][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.0188, 0.1423, 0.0623, 0.1273, 0.0402, 0.0553, 0.0775, 0.0553, 0.0469,
        0.0350, 0.0737, 0.1173, 0.0657, 0.0825], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:41,148][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.0044, 0.0732, 0.0797, 0.0707, 0.0779, 0.0756, 0.0791, 0.0834, 0.0764,
        0.0817, 0.0713, 0.0735, 0.0802, 0.0727], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:41,149][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.0072, 0.0030, 0.0223, 0.0487, 0.0925, 0.2168, 0.1261, 0.0323, 0.1668,
        0.0725, 0.0752, 0.0909, 0.0285, 0.0173], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:41,150][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.1941, 0.0565, 0.0848, 0.0796, 0.0542, 0.0766, 0.0671, 0.0504, 0.0363,
        0.0706, 0.0569, 0.0469, 0.0620, 0.0639], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:41,152][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.0090, 0.0289, 0.0329, 0.0734, 0.0621, 0.0263, 0.1526, 0.0934, 0.0790,
        0.0596, 0.0686, 0.1304, 0.1254, 0.0584], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:41,154][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.0218, 0.0726, 0.0749, 0.0757, 0.0761, 0.0751, 0.0751, 0.0726, 0.0789,
        0.0768, 0.0717, 0.0773, 0.0739, 0.0773], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:41,155][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0035, 0.0046, 0.0123, 0.0100, 0.0300, 0.0254, 0.0385, 0.0668, 0.1215,
        0.1320, 0.1586, 0.1123, 0.1950, 0.0895], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:41,156][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.0054, 0.0602, 0.0817, 0.0720, 0.0812, 0.0779, 0.0735, 0.0789, 0.0764,
        0.0927, 0.0730, 0.0734, 0.0825, 0.0713], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:41,158][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.2924, 0.0139, 0.0046, 0.0034, 0.0061, 0.0111, 0.0072, 0.0165, 0.0564,
        0.0746, 0.1303, 0.0608, 0.2238, 0.0988], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:41,160][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.0123, 0.0800, 0.0795, 0.0682, 0.0840, 0.0675, 0.0787, 0.0872, 0.0783,
        0.0709, 0.0681, 0.0742, 0.0691, 0.0820], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:41,160][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([7.6330e-13, 1.4868e-11, 8.8411e-13, 2.4519e-14, 4.8031e-11, 4.3269e-13,
        4.6810e-14, 5.5216e-09, 2.0770e-06, 1.2941e-04, 1.8256e-05, 2.2192e-07,
        9.9651e-01, 3.3443e-03], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:41,162][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Anthony] are: tensor([1.3281e-02, 3.6518e-03, 1.3857e-04, 1.0088e-03, 2.0259e-04, 7.1789e-04,
        4.8963e-04, 1.7948e-03, 2.4470e-02, 2.1838e-02, 3.8215e-02, 2.5679e-02,
        1.1475e-01, 5.2552e-01, 2.2824e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:41,163][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Anthony] are: tensor([0.0187, 0.1897, 0.0439, 0.1571, 0.0349, 0.0430, 0.0515, 0.0524, 0.0569,
        0.0227, 0.0471, 0.0761, 0.0450, 0.1247, 0.0364], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:41,165][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Anthony] are: tensor([0.0031, 0.0689, 0.0744, 0.0655, 0.0725, 0.0704, 0.0743, 0.0780, 0.0710,
        0.0765, 0.0662, 0.0684, 0.0751, 0.0668, 0.0689], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:41,166][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Anthony] are: tensor([0.0762, 0.0022, 0.0075, 0.0482, 0.0338, 0.1988, 0.0963, 0.0225, 0.1846,
        0.0623, 0.0993, 0.0945, 0.0247, 0.0225, 0.0266], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:41,168][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Anthony] are: tensor([0.1905, 0.0491, 0.0773, 0.0722, 0.0496, 0.0678, 0.0593, 0.0498, 0.0314,
        0.0654, 0.0520, 0.0438, 0.0557, 0.0576, 0.0785], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:41,169][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Anthony] are: tensor([0.0035, 0.0256, 0.0172, 0.0713, 0.0511, 0.0193, 0.1166, 0.0879, 0.0968,
        0.0444, 0.1049, 0.1176, 0.1320, 0.0783, 0.0335], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:41,170][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Anthony] are: tensor([0.0198, 0.0682, 0.0652, 0.0716, 0.0692, 0.0705, 0.0682, 0.0691, 0.0742,
        0.0723, 0.0665, 0.0729, 0.0700, 0.0757, 0.0668], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:41,172][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Anthony] are: tensor([0.0020, 0.0017, 0.0048, 0.0030, 0.0138, 0.0106, 0.0216, 0.0367, 0.0883,
        0.1134, 0.1205, 0.0814, 0.1934, 0.0677, 0.2413], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:41,173][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Anthony] are: tensor([0.0056, 0.0554, 0.0752, 0.0661, 0.0745, 0.0718, 0.0680, 0.0726, 0.0707,
        0.0857, 0.0672, 0.0680, 0.0765, 0.0655, 0.0771], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:41,175][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Anthony] are: tensor([0.1473, 0.0118, 0.0019, 0.0026, 0.0027, 0.0063, 0.0035, 0.0078, 0.0292,
        0.0285, 0.0696, 0.0404, 0.3005, 0.2057, 0.1421], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:41,176][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Anthony] are: tensor([0.0085, 0.0771, 0.0630, 0.0667, 0.0747, 0.0661, 0.0792, 0.0891, 0.0722,
        0.0672, 0.0602, 0.0747, 0.0609, 0.0811, 0.0593], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:41,177][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Anthony] are: tensor([1.2693e-08, 1.8059e-09, 2.6303e-15, 1.2593e-13, 1.9829e-12, 6.2778e-13,
        3.5091e-14, 6.8767e-10, 7.0866e-07, 6.0659e-06, 2.2069e-05, 1.1895e-06,
        3.3307e-01, 5.9257e-01, 7.4332e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:41,178][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([2.0820e-02, 6.5400e-03, 1.8657e-04, 2.6426e-03, 3.0327e-04, 1.7905e-03,
        6.5020e-04, 2.6889e-03, 3.2732e-02, 1.9992e-02, 2.4201e-02, 3.0061e-02,
        1.2832e-01, 4.3552e-01, 1.3201e-01, 1.6154e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:41,180][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0164, 0.1470, 0.0493, 0.1512, 0.0329, 0.0299, 0.0501, 0.0391, 0.0432,
        0.0206, 0.0669, 0.0852, 0.0607, 0.1378, 0.0506, 0.0193],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:41,181][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.0036, 0.0652, 0.0697, 0.0614, 0.0676, 0.0655, 0.0688, 0.0724, 0.0654,
        0.0713, 0.0613, 0.0633, 0.0700, 0.0625, 0.0646, 0.0672],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:41,183][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.0110, 0.0036, 0.0152, 0.0559, 0.0621, 0.2114, 0.0977, 0.0221, 0.1417,
        0.0580, 0.0842, 0.0828, 0.0365, 0.0247, 0.0527, 0.0404],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:41,184][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.1906, 0.0461, 0.0719, 0.0691, 0.0459, 0.0674, 0.0543, 0.0443, 0.0287,
        0.0597, 0.0464, 0.0388, 0.0478, 0.0495, 0.0686, 0.0707],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:41,185][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.0053, 0.0311, 0.0263, 0.0692, 0.0567, 0.0207, 0.1234, 0.0765, 0.0955,
        0.0414, 0.0723, 0.1117, 0.1318, 0.0645, 0.0446, 0.0292],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:41,186][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.0222, 0.0640, 0.0631, 0.0665, 0.0652, 0.0651, 0.0641, 0.0645, 0.0697,
        0.0680, 0.0620, 0.0677, 0.0648, 0.0691, 0.0651, 0.0588],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:41,186][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0037, 0.0034, 0.0078, 0.0054, 0.0182, 0.0155, 0.0258, 0.0419, 0.0910,
        0.0991, 0.1243, 0.0822, 0.1527, 0.0662, 0.1743, 0.0886],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:41,187][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.0046, 0.0514, 0.0702, 0.0614, 0.0700, 0.0670, 0.0635, 0.0675, 0.0655,
        0.0795, 0.0628, 0.0630, 0.0711, 0.0612, 0.0722, 0.0692],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:41,187][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.0509, 0.0151, 0.0033, 0.0026, 0.0085, 0.0043, 0.0036, 0.0089, 0.0472,
        0.0341, 0.0660, 0.0505, 0.2192, 0.1954, 0.1442, 0.1460],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:41,187][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0104, 0.0696, 0.0624, 0.0609, 0.0711, 0.0644, 0.0700, 0.0844, 0.0653,
        0.0614, 0.0579, 0.0680, 0.0618, 0.0719, 0.0592, 0.0614],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:41,188][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([3.1056e-13, 5.4664e-12, 1.9830e-14, 3.8581e-14, 1.5063e-12, 3.1477e-14,
        2.4401e-16, 8.1045e-11, 6.1137e-08, 1.1652e-06, 1.4165e-06, 1.1247e-08,
        3.1615e-02, 9.7214e-03, 9.5864e-01, 2.0165e-05], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:41,189][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([1.5160e-03, 1.1927e-03, 4.9096e-05, 2.4739e-04, 6.0374e-05, 3.9277e-04,
        3.6288e-05, 5.0542e-04, 6.8799e-03, 2.2055e-02, 3.5176e-03, 2.3655e-03,
        6.4303e-02, 2.5938e-01, 1.1271e-01, 4.7876e-01, 4.6034e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:41,191][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0218, 0.1696, 0.0569, 0.1297, 0.0530, 0.0310, 0.0404, 0.0377, 0.0482,
        0.0203, 0.0494, 0.0676, 0.0665, 0.1016, 0.0514, 0.0269, 0.0278],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:41,192][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0033, 0.0604, 0.0655, 0.0575, 0.0637, 0.0614, 0.0646, 0.0682, 0.0615,
        0.0670, 0.0578, 0.0597, 0.0657, 0.0587, 0.0612, 0.0632, 0.0606],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:41,194][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0020, 0.0023, 0.0200, 0.0565, 0.1109, 0.1978, 0.0896, 0.0264, 0.1574,
        0.0503, 0.0775, 0.0719, 0.0243, 0.0173, 0.0510, 0.0306, 0.0142],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:41,195][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.1534, 0.0378, 0.0658, 0.0606, 0.0448, 0.0622, 0.0539, 0.0440, 0.0277,
        0.0613, 0.0455, 0.0386, 0.0526, 0.0523, 0.0727, 0.0732, 0.0536],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:41,196][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0035, 0.0305, 0.0243, 0.0629, 0.0557, 0.0214, 0.0872, 0.0750, 0.0781,
        0.0516, 0.0643, 0.1019, 0.1133, 0.0732, 0.0433, 0.0410, 0.0729],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:41,198][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0183, 0.0591, 0.0603, 0.0632, 0.0620, 0.0609, 0.0592, 0.0604, 0.0648,
        0.0630, 0.0598, 0.0638, 0.0624, 0.0656, 0.0615, 0.0583, 0.0575],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:41,199][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0023, 0.0025, 0.0061, 0.0049, 0.0153, 0.0137, 0.0229, 0.0410, 0.0899,
        0.1011, 0.1181, 0.0786, 0.1413, 0.0599, 0.1589, 0.0766, 0.0668],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:41,201][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0043, 0.0485, 0.0659, 0.0580, 0.0656, 0.0630, 0.0596, 0.0635, 0.0616,
        0.0743, 0.0590, 0.0591, 0.0665, 0.0577, 0.0677, 0.0649, 0.0608],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:41,202][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0794, 0.0075, 0.0016, 0.0012, 0.0027, 0.0037, 0.0011, 0.0065, 0.0228,
        0.0215, 0.0447, 0.0223, 0.1606, 0.1012, 0.1205, 0.3385, 0.0643],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:41,204][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0111, 0.0642, 0.0611, 0.0564, 0.0666, 0.0576, 0.0650, 0.0728, 0.0616,
        0.0589, 0.0574, 0.0629, 0.0574, 0.0670, 0.0604, 0.0559, 0.0637],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:41,205][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([1.5037e-13, 4.4252e-12, 3.4428e-15, 8.7056e-16, 5.8602e-13, 8.5524e-15,
        2.0914e-19, 1.8794e-11, 6.5700e-08, 1.6937e-06, 6.0874e-07, 1.6066e-10,
        1.1587e-01, 5.6295e-02, 8.2237e-01, 5.4459e-03, 1.1506e-05],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:41,206][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ drink] are: tensor([2.2068e-03, 5.2172e-04, 1.7177e-05, 2.4311e-04, 4.9163e-05, 5.8326e-04,
        8.9438e-05, 1.1902e-03, 8.9771e-03, 6.7976e-03, 6.3463e-03, 5.0723e-03,
        2.1925e-02, 1.4318e-01, 4.5884e-02, 5.1311e-01, 9.5627e-02, 1.4818e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:41,207][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ drink] are: tensor([0.0071, 0.1474, 0.0612, 0.1337, 0.0468, 0.0250, 0.0622, 0.0208, 0.0432,
        0.0117, 0.0495, 0.0960, 0.0527, 0.1037, 0.0548, 0.0184, 0.0525, 0.0134],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:41,209][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ drink] are: tensor([0.0032, 0.0578, 0.0612, 0.0542, 0.0589, 0.0576, 0.0608, 0.0637, 0.0576,
        0.0625, 0.0543, 0.0560, 0.0614, 0.0548, 0.0562, 0.0589, 0.0563, 0.0644],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:41,210][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ drink] are: tensor([0.0104, 0.0028, 0.0141, 0.0597, 0.0616, 0.2236, 0.1111, 0.0211, 0.1562,
        0.0443, 0.0710, 0.0847, 0.0214, 0.0242, 0.0335, 0.0309, 0.0217, 0.0077],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:41,212][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ drink] are: tensor([0.1934, 0.0429, 0.0651, 0.0611, 0.0410, 0.0563, 0.0445, 0.0393, 0.0240,
        0.0508, 0.0384, 0.0323, 0.0418, 0.0464, 0.0638, 0.0667, 0.0443, 0.0480],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:41,213][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ drink] are: tensor([0.0029, 0.0248, 0.0239, 0.0605, 0.0496, 0.0210, 0.0883, 0.0591, 0.0935,
        0.0332, 0.0853, 0.0839, 0.1161, 0.0651, 0.0460, 0.0385, 0.0696, 0.0389],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:41,215][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ drink] are: tensor([0.0182, 0.0561, 0.0563, 0.0603, 0.0585, 0.0584, 0.0565, 0.0566, 0.0619,
        0.0599, 0.0559, 0.0607, 0.0576, 0.0623, 0.0587, 0.0548, 0.0548, 0.0526],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:41,216][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ drink] are: tensor([0.0021, 0.0024, 0.0062, 0.0045, 0.0161, 0.0127, 0.0212, 0.0436, 0.0834,
        0.0924, 0.1077, 0.0692, 0.1331, 0.0541, 0.1537, 0.0744, 0.0603, 0.0630],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:41,218][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ drink] are: tensor([0.0043, 0.0450, 0.0617, 0.0542, 0.0616, 0.0589, 0.0560, 0.0593, 0.0580,
        0.0702, 0.0554, 0.0561, 0.0625, 0.0538, 0.0634, 0.0604, 0.0567, 0.0624],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:41,219][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ drink] are: tensor([0.0321, 0.0064, 0.0019, 0.0024, 0.0047, 0.0033, 0.0027, 0.0073, 0.0266,
        0.0265, 0.0491, 0.0318, 0.1515, 0.0629, 0.1544, 0.2040, 0.1435, 0.0891],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:41,221][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ drink] are: tensor([0.0077, 0.0625, 0.0564, 0.0546, 0.0628, 0.0542, 0.0652, 0.0692, 0.0598,
        0.0585, 0.0518, 0.0595, 0.0532, 0.0634, 0.0524, 0.0508, 0.0616, 0.0563],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:41,222][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ drink] are: tensor([7.4431e-13, 2.9192e-12, 2.3471e-14, 2.8061e-14, 2.8614e-12, 3.8945e-13,
        1.6424e-14, 1.0100e-09, 3.3955e-07, 1.5536e-06, 5.3895e-06, 7.9879e-08,
        2.4050e-02, 2.7087e-02, 9.2807e-01, 2.6528e-03, 1.3891e-02, 4.2402e-03],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:41,223][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([1.7635e-03, 4.2330e-04, 9.3833e-06, 4.2824e-05, 7.3958e-06, 8.6342e-05,
        1.8601e-05, 1.5693e-04, 1.1748e-03, 5.9242e-03, 5.6325e-04, 1.4184e-03,
        1.3315e-02, 7.1520e-02, 2.6684e-02, 2.8035e-01, 4.6147e-02, 3.1132e-01,
        2.3907e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:41,225][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0173, 0.1563, 0.0636, 0.1147, 0.0380, 0.0265, 0.0599, 0.0395, 0.0325,
        0.0226, 0.0374, 0.0740, 0.0530, 0.0858, 0.0529, 0.0177, 0.0418, 0.0089,
        0.0577], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:41,226][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0025, 0.0537, 0.0581, 0.0509, 0.0568, 0.0548, 0.0578, 0.0608, 0.0549,
        0.0598, 0.0511, 0.0530, 0.0585, 0.0518, 0.0539, 0.0560, 0.0537, 0.0621,
        0.0497], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:41,228][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0027, 0.0024, 0.0190, 0.0438, 0.1209, 0.1570, 0.0833, 0.0324, 0.1731,
        0.0586, 0.0766, 0.0659, 0.0261, 0.0166, 0.0556, 0.0245, 0.0130, 0.0078,
        0.0207], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:41,229][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.1510, 0.0378, 0.0604, 0.0578, 0.0408, 0.0547, 0.0470, 0.0394, 0.0252,
        0.0521, 0.0374, 0.0325, 0.0449, 0.0455, 0.0625, 0.0612, 0.0454, 0.0485,
        0.0557], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:41,231][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0041, 0.0236, 0.0215, 0.0585, 0.0418, 0.0154, 0.1023, 0.0665, 0.0721,
        0.0505, 0.0517, 0.0925, 0.1053, 0.0565, 0.0379, 0.0317, 0.0826, 0.0630,
        0.0226], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:41,232][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0154, 0.0531, 0.0543, 0.0565, 0.0557, 0.0551, 0.0545, 0.0533, 0.0583,
        0.0571, 0.0533, 0.0569, 0.0552, 0.0572, 0.0544, 0.0516, 0.0527, 0.0533,
        0.0521], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:41,234][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0010, 0.0012, 0.0038, 0.0026, 0.0115, 0.0085, 0.0166, 0.0362, 0.0833,
        0.0896, 0.0931, 0.0598, 0.1489, 0.0506, 0.1683, 0.0686, 0.0601, 0.0694,
        0.0270], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:41,235][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0040, 0.0431, 0.0588, 0.0514, 0.0581, 0.0558, 0.0526, 0.0566, 0.0547,
        0.0665, 0.0526, 0.0522, 0.0597, 0.0508, 0.0602, 0.0576, 0.0536, 0.0604,
        0.0513], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:41,237][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0762, 0.0033, 0.0007, 0.0005, 0.0013, 0.0016, 0.0008, 0.0026, 0.0101,
        0.0148, 0.0243, 0.0131, 0.0752, 0.0457, 0.0763, 0.2285, 0.0661, 0.0914,
        0.2676], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:41,238][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0092, 0.0605, 0.0545, 0.0523, 0.0577, 0.0501, 0.0605, 0.0666, 0.0565,
        0.0519, 0.0504, 0.0575, 0.0506, 0.0601, 0.0522, 0.0483, 0.0579, 0.0502,
        0.0529], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:41,239][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([3.8714e-15, 3.4754e-15, 7.6239e-19, 2.9886e-21, 2.1118e-16, 5.8942e-19,
        1.1109e-21, 3.5379e-14, 3.0239e-13, 1.6983e-09, 4.6317e-12, 6.4007e-14,
        1.8997e-03, 4.8711e-06, 2.4916e-03, 1.0787e-05, 5.2372e-07, 1.2213e-01,
        8.7346e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:41,241][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:21:41,243][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[7505],
        [ 773],
        [2027],
        [ 371],
        [ 631],
        [ 167],
        [ 131],
        [ 221],
        [ 118],
        [ 593],
        [ 631],
        [ 474],
        [ 854],
        [ 189],
        [1026],
        [ 722],
        [ 225],
        [ 401],
        [  86]], device='cuda:0')
[2024-07-24 10:21:41,244][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 9702],
        [ 4992],
        [15867],
        [ 7556],
        [14762],
        [ 6203],
        [ 5915],
        [ 6545],
        [ 7057],
        [17525],
        [ 9838],
        [11990],
        [13508],
        [ 4721],
        [17117],
        [10753],
        [10555],
        [ 8279],
        [ 4738]], device='cuda:0')
[2024-07-24 10:21:41,245][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[ 5841],
        [18905],
        [18860],
        [18088],
        [17587],
        [17064],
        [15813],
        [15507],
        [15619],
        [14251],
        [13924],
        [13924],
        [15310],
        [14331],
        [13357],
        [13870],
        [14382],
        [15089],
        [14798]], device='cuda:0')
[2024-07-24 10:21:41,247][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[ 1400],
        [11948],
        [ 5750],
        [ 3068],
        [ 4207],
        [13794],
        [14970],
        [ 8186],
        [ 8496],
        [10645],
        [13279],
        [14126],
        [14792],
        [12494],
        [13337],
        [17533],
        [18469],
        [13656],
        [13580]], device='cuda:0')
[2024-07-24 10:21:41,248][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[14866],
        [10130],
        [ 6506],
        [ 4461],
        [ 3774],
        [ 3286],
        [ 2918],
        [ 2715],
        [ 2240],
        [ 2111],
        [ 2011],
        [ 1866],
        [ 1754],
        [ 1695],
        [ 1802],
        [ 1890],
        [ 1740],
        [ 1486],
        [ 1502]], device='cuda:0')
[2024-07-24 10:21:41,250][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[33333],
        [42430],
        [42301],
        [45910],
        [44856],
        [45825],
        [45203],
        [44624],
        [44436],
        [44111],
        [44241],
        [44019],
        [43667],
        [43992],
        [43885],
        [43930],
        [43770],
        [43488],
        [43875]], device='cuda:0')
[2024-07-24 10:21:41,251][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[ 7072],
        [ 8166],
        [ 9257],
        [10921],
        [ 9684],
        [10635],
        [10816],
        [11162],
        [13428],
        [14097],
        [14134],
        [14461],
        [14109],
        [13614],
        [12904],
        [12575],
        [12514],
        [12107],
        [11767]], device='cuda:0')
[2024-07-24 10:21:41,253][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[25937],
        [40308],
        [31987],
        [32254],
        [25350],
        [17621],
        [25715],
        [26097],
        [27768],
        [21152],
        [29162],
        [26575],
        [26681],
        [26215],
        [26468],
        [24265],
        [26481],
        [26213],
        [27591]], device='cuda:0')
[2024-07-24 10:21:41,254][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[39728],
        [42205],
        [40872],
        [41038],
        [39828],
        [39234],
        [38389],
        [38108],
        [37357],
        [37395],
        [37259],
        [36722],
        [36719],
        [37075],
        [37189],
        [37446],
        [37639],
        [37780],
        [37642]], device='cuda:0')
[2024-07-24 10:21:41,256][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[3501],
        [1828],
        [1856],
        [1890],
        [1827],
        [1965],
        [2138],
        [2149],
        [2174],
        [2185],
        [2241],
        [2440],
        [2458],
        [2592],
        [2654],
        [2697],
        [2786],
        [3155],
        [3317]], device='cuda:0')
[2024-07-24 10:21:41,257][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[19971],
        [16663],
        [15873],
        [ 8666],
        [ 7643],
        [ 7436],
        [ 8039],
        [ 8143],
        [ 7298],
        [ 7292],
        [ 7154],
        [ 7064],
        [ 6548],
        [ 6937],
        [ 7122],
        [ 6155],
        [ 7159],
        [ 6534],
        [ 6628]], device='cuda:0')
[2024-07-24 10:21:41,259][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[ 4276],
        [ 8839],
        [12105],
        [ 9520],
        [11007],
        [13466],
        [13471],
        [12715],
        [13269],
        [12586],
        [13697],
        [14489],
        [14138],
        [13617],
        [13952],
        [14824],
        [14940],
        [14651],
        [14557]], device='cuda:0')
[2024-07-24 10:21:41,260][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[205],
        [146],
        [165],
        [161],
        [188],
        [184],
        [176],
        [195],
        [172],
        [167],
        [143],
        [130],
        [143],
        [145],
        [150],
        [156],
        [158],
        [162],
        [153]], device='cuda:0')
[2024-07-24 10:21:41,262][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[ 8040],
        [16444],
        [16635],
        [ 9621],
        [10038],
        [13839],
        [15279],
        [21753],
        [ 5930],
        [ 5892],
        [10166],
        [ 8809],
        [30965],
        [31841],
        [17846],
        [10552],
        [11105],
        [10512],
        [15494]], device='cuda:0')
[2024-07-24 10:21:41,264][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 758],
        [ 460],
        [1545],
        [2381],
        [3739],
        [3056],
        [1175],
        [2863],
        [1477],
        [2219],
        [6521],
        [1655],
        [3072],
        [1834],
        [2874],
        [4988],
        [1765],
        [3539],
        [2467]], device='cuda:0')
[2024-07-24 10:21:41,265][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[2932],
        [4296],
        [3676],
        [2695],
        [2910],
        [1804],
        [ 936],
        [ 815],
        [ 647],
        [1254],
        [8392],
        [1223],
        [2884],
        [2861],
        [3652],
        [3121],
        [1658],
        [2043],
        [4063]], device='cuda:0')
[2024-07-24 10:21:41,266][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[36707],
        [41294],
        [40955],
        [40735],
        [40842],
        [40038],
        [40153],
        [40377],
        [40242],
        [39914],
        [39444],
        [39516],
        [39334],
        [39295],
        [39693],
        [39221],
        [39085],
        [39719],
        [39406]], device='cuda:0')
[2024-07-24 10:21:41,268][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[ 932],
        [ 961],
        [ 968],
        [1039],
        [1007],
        [1086],
        [1078],
        [ 975],
        [1022],
        [1028],
        [1072],
        [1089],
        [1064],
        [1036],
        [1009],
        [ 998],
        [ 942],
        [ 895],
        [ 863]], device='cuda:0')
[2024-07-24 10:21:41,270][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[6132],
        [2403],
        [1838],
        [1715],
        [2575],
        [2282],
        [2504],
        [2870],
        [2474],
        [2799],
        [2361],
        [2357],
        [2979],
        [2460],
        [2756],
        [2390],
        [2179],
        [2577],
        [2053]], device='cuda:0')
[2024-07-24 10:21:41,271][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[5974],
        [7886],
        [5412],
        [4848],
        [4350],
        [4590],
        [4300],
        [3724],
        [3768],
        [3407],
        [3560],
        [3462],
        [3160],
        [3190],
        [3264],
        [3209],
        [3098],
        [2925],
        [2994]], device='cuda:0')
[2024-07-24 10:21:41,273][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[14955],
        [22766],
        [20814],
        [20271],
        [21075],
        [22908],
        [20192],
        [16581],
        [17170],
        [18369],
        [18896],
        [21493],
        [22634],
        [22503],
        [22902],
        [22636],
        [22427],
        [22417],
        [21853]], device='cuda:0')
[2024-07-24 10:21:41,274][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[3674],
        [3752],
        [3545],
        [3708],
        [3582],
        [3619],
        [3707],
        [3702],
        [3703],
        [3670],
        [3675],
        [3586],
        [3575],
        [3739],
        [3819],
        [3751],
        [3778],
        [3668],
        [3694]], device='cuda:0')
[2024-07-24 10:21:41,276][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[35316],
        [ 5817],
        [ 9728],
        [ 5595],
        [ 3642],
        [ 5191],
        [ 9298],
        [ 7961],
        [ 5488],
        [ 9061],
        [ 8279],
        [ 9176],
        [15166],
        [13439],
        [15424],
        [13911],
        [13264],
        [13673],
        [13366]], device='cuda:0')
[2024-07-24 10:21:41,277][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[13633],
        [15011],
        [14419],
        [14477],
        [14388],
        [13160],
        [12725],
        [12608],
        [12598],
        [13233],
        [12988],
        [13256],
        [13524],
        [13685],
        [13976],
        [13731],
        [13713],
        [13935],
        [13895]], device='cuda:0')
[2024-07-24 10:21:41,279][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[27927],
        [19295],
        [ 6450],
        [12477],
        [ 6617],
        [ 4149],
        [ 3844],
        [ 4419],
        [ 7347],
        [ 6955],
        [ 8842],
        [10296],
        [ 9931],
        [10408],
        [ 9801],
        [ 4214],
        [  987],
        [ 1917],
        [ 1427]], device='cuda:0')
[2024-07-24 10:21:41,280][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[11382],
        [ 5944],
        [ 7232],
        [ 6418],
        [ 5367],
        [ 5837],
        [ 6333],
        [ 6856],
        [ 6986],
        [ 7195],
        [ 7483],
        [ 7992],
        [ 7442],
        [ 7034],
        [ 7159],
        [ 7228],
        [ 7319],
        [ 6983],
        [ 6989]], device='cuda:0')
[2024-07-24 10:21:41,282][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[42010],
        [41762],
        [24347],
        [24514],
        [24605],
        [12327],
        [22778],
        [ 9596],
        [31235],
        [31226],
        [ 9197],
        [21965],
        [11397],
        [11004],
        [18109],
        [19809],
        [19178],
        [19971],
        [20124]], device='cuda:0')
[2024-07-24 10:21:41,283][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[44373],
        [46107],
        [46755],
        [46891],
        [47669],
        [47757],
        [47448],
        [48145],
        [47375],
        [46319],
        [45820],
        [46194],
        [45969],
        [46183],
        [45457],
        [46198],
        [47721],
        [47219],
        [47156]], device='cuda:0')
[2024-07-24 10:21:41,285][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[49361],
        [48844],
        [43968],
        [42815],
        [36145],
        [43803],
        [45212],
        [45234],
        [45438],
        [44260],
        [40857],
        [44421],
        [42668],
        [44239],
        [43283],
        [43470],
        [44202],
        [43921],
        [43558]], device='cuda:0')
[2024-07-24 10:21:41,286][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[4240],
        [4240],
        [4240],
        [4240],
        [4240],
        [4240],
        [4240],
        [4240],
        [4240],
        [4240],
        [4240],
        [4240],
        [4240],
        [4240],
        [4240],
        [4240],
        [4240],
        [4240],
        [4240]], device='cuda:0')
[2024-07-24 10:21:41,324][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:21:41,325][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:41,326][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:41,327][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:41,329][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:41,330][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:41,331][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:41,346][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:41,347][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:41,348][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:41,349][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:41,350][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:41,351][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:41,352][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0524, 0.9476], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:41,354][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0606, 0.9394], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:41,355][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.9966, 0.0034], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:41,357][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.5280, 0.4720], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:41,358][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.8796, 0.1204], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:41,359][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.1434, 0.8566], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:41,361][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.6709, 0.3291], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:41,362][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.8603, 0.1397], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:41,364][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.6015, 0.3985], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:41,365][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0617, 0.9383], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:41,366][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0407, 0.9593], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:41,368][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.1974, 0.8026], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:41,369][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Anthony] are: tensor([0.0071, 0.6249, 0.3680], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:41,371][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Anthony] are: tensor([0.0307, 0.5494, 0.4199], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:41,372][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Anthony] are: tensor([9.9779e-01, 5.9599e-04, 1.6182e-03], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:41,372][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Anthony] are: tensor([0.3448, 0.3266, 0.3286], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:41,373][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Anthony] are: tensor([0.8092, 0.0396, 0.1512], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:41,373][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Anthony] are: tensor([0.0704, 0.4545, 0.4751], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:41,373][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Anthony] are: tensor([0.2998, 0.4367, 0.2635], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:41,374][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Anthony] are: tensor([0.7021, 0.2005, 0.0974], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:41,374][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Anthony] are: tensor([0.2160, 0.3752, 0.4087], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:41,374][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Anthony] are: tensor([0.0342, 0.4744, 0.4914], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:41,375][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Anthony] are: tensor([0.0263, 0.4548, 0.5189], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:41,375][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Anthony] are: tensor([0.0877, 0.3742, 0.5381], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:41,375][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.5652, 0.1002, 0.0274, 0.3072], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:41,376][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0229, 0.3865, 0.2962, 0.2945], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:41,377][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ and] are: tensor([9.9544e-01, 4.7511e-04, 1.6558e-03, 2.4247e-03], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:41,378][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.2563, 0.2448, 0.2465, 0.2524], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:41,379][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.5766, 0.0189, 0.0949, 0.3096], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:41,381][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0410, 0.2945, 0.3667, 0.2978], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:41,382][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.3337, 0.1973, 0.3076, 0.1615], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:41,383][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.7522, 0.1340, 0.0726, 0.0412], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:41,385][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.2346, 0.1986, 0.4542, 0.1125], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:41,386][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0217, 0.3169, 0.3301, 0.3313], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:41,388][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0170, 0.3087, 0.3361, 0.3382], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:41,389][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0633, 0.2597, 0.3804, 0.2966], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:41,390][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Travis] are: tensor([0.0248, 0.0428, 0.0151, 0.2540, 0.6633], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:41,392][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Travis] are: tensor([0.0160, 0.2988, 0.2285, 0.2284, 0.2283], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:41,393][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Travis] are: tensor([9.9457e-01, 3.2489e-04, 1.2205e-03, 1.6341e-03, 2.2462e-03],
       device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:41,394][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Travis] are: tensor([0.2055, 0.1973, 0.1985, 0.2051, 0.1936], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:41,396][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Travis] are: tensor([0.4425, 0.0145, 0.0686, 0.3413, 0.1332], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:41,397][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Travis] are: tensor([0.0386, 0.2315, 0.2604, 0.2394, 0.2302], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:41,398][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Travis] are: tensor([0.1013, 0.3003, 0.1682, 0.2828, 0.1473], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:41,400][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Travis] are: tensor([0.6001, 0.0746, 0.1188, 0.0571, 0.1494], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:41,401][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Travis] are: tensor([0.1584, 0.1305, 0.3841, 0.1853, 0.1417], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:41,402][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Travis] are: tensor([0.0150, 0.2400, 0.2499, 0.2503, 0.2448], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:41,404][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Travis] are: tensor([0.0127, 0.2264, 0.2606, 0.2508, 0.2496], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:41,405][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Travis] are: tensor([0.0423, 0.1974, 0.2950, 0.2281, 0.2372], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:41,406][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.0098, 0.0462, 0.0259, 0.1952, 0.6311, 0.0917], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:41,408][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.0128, 0.2468, 0.1889, 0.1878, 0.1866, 0.1770], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:41,409][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ had] are: tensor([9.9263e-01, 3.4032e-04, 1.3264e-03, 1.6899e-03, 2.3647e-03, 1.6458e-03],
       device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:41,410][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.1706, 0.1655, 0.1657, 0.1733, 0.1656, 0.1592], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:41,412][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.2500, 0.0106, 0.0695, 0.2624, 0.1742, 0.2333], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:41,413][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.0281, 0.1826, 0.2033, 0.1924, 0.2092, 0.1844], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:41,415][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.1621, 0.1757, 0.1474, 0.1583, 0.2218, 0.1347], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:41,416][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.5152, 0.1160, 0.0579, 0.1048, 0.1275, 0.0786], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:41,417][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.1249, 0.1566, 0.2601, 0.1461, 0.2002, 0.1122], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:41,419][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.0113, 0.1933, 0.2016, 0.2012, 0.1974, 0.1952], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:41,420][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.0080, 0.1823, 0.2024, 0.2088, 0.1940, 0.2044], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:41,422][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0383, 0.1634, 0.2462, 0.1894, 0.1963, 0.1665], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:41,423][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0195, 0.2777, 0.0662, 0.1952, 0.1994, 0.0533, 0.1886],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:41,425][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0124, 0.2048, 0.1578, 0.1568, 0.1568, 0.1477, 0.1636],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:41,425][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ a] are: tensor([9.9012e-01, 3.2464e-04, 1.4120e-03, 1.7704e-03, 2.4820e-03, 1.7501e-03,
        2.1369e-03], device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:41,427][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.1464, 0.1423, 0.1429, 0.1495, 0.1424, 0.1365, 0.1401],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:41,428][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0747, 0.0078, 0.0786, 0.2035, 0.2010, 0.2946, 0.1399],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:41,430][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0228, 0.1556, 0.1795, 0.1628, 0.1614, 0.1586, 0.1592],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:41,430][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.1126, 0.1095, 0.1654, 0.1140, 0.2796, 0.1322, 0.0866],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:41,431][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.4795, 0.0860, 0.0298, 0.0852, 0.0703, 0.1736, 0.0756],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:41,431][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.1251, 0.1540, 0.2084, 0.1187, 0.1540, 0.1712, 0.0685],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:41,432][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0100, 0.1616, 0.1680, 0.1682, 0.1649, 0.1634, 0.1640],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:41,432][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0091, 0.1533, 0.1717, 0.1688, 0.1618, 0.1650, 0.1704],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:41,432][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0359, 0.1414, 0.2099, 0.1652, 0.1683, 0.1440, 0.1353],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:41,433][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ lot] are: tensor([0.0161, 0.0108, 0.0111, 0.0775, 0.1243, 0.0485, 0.1527, 0.5590],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:41,433][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ lot] are: tensor([0.0121, 0.1732, 0.1327, 0.1323, 0.1316, 0.1249, 0.1378, 0.1555],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:41,434][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ lot] are: tensor([9.8684e-01, 4.3304e-04, 1.3666e-03, 1.7540e-03, 2.3775e-03, 1.7838e-03,
        2.1956e-03, 3.2456e-03], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:41,435][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ lot] are: tensor([0.1270, 0.1233, 0.1249, 0.1317, 0.1258, 0.1201, 0.1231, 0.1241],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:41,437][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ lot] are: tensor([0.1999, 0.0099, 0.0537, 0.1390, 0.1062, 0.1983, 0.1287, 0.1643],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:41,438][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ lot] are: tensor([0.0187, 0.1280, 0.1608, 0.1361, 0.1566, 0.1351, 0.1406, 0.1241],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:41,439][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ lot] are: tensor([0.0770, 0.1375, 0.0844, 0.1873, 0.1602, 0.1464, 0.1413, 0.0659],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:41,441][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ lot] are: tensor([0.5081, 0.0912, 0.0473, 0.0519, 0.0815, 0.1086, 0.0474, 0.0641],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:41,442][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ lot] are: tensor([0.1010, 0.0857, 0.2505, 0.1109, 0.1621, 0.1348, 0.1087, 0.0463],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:41,443][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ lot] are: tensor([0.0086, 0.1388, 0.1444, 0.1446, 0.1419, 0.1405, 0.1415, 0.1396],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:41,445][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ lot] are: tensor([0.0057, 0.1315, 0.1419, 0.1449, 0.1381, 0.1413, 0.1468, 0.1497],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:41,446][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ lot] are: tensor([0.0298, 0.1252, 0.1914, 0.1491, 0.1508, 0.1275, 0.1192, 0.1071],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:41,448][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ of] are: tensor([0.0017, 0.0126, 0.0078, 0.0500, 0.0707, 0.0164, 0.0364, 0.2159, 0.5886],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:41,449][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ of] are: tensor([0.0101, 0.1533, 0.1157, 0.1159, 0.1134, 0.1075, 0.1205, 0.1353, 0.1284],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:41,450][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ of] are: tensor([9.8173e-01, 3.0546e-04, 1.4639e-03, 2.0186e-03, 3.0394e-03, 2.1469e-03,
        2.6786e-03, 3.8795e-03, 2.7367e-03], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:41,451][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ of] are: tensor([0.1130, 0.1129, 0.1119, 0.1174, 0.1124, 0.1072, 0.1103, 0.1122, 0.1028],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:41,453][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ of] are: tensor([0.1604, 0.0044, 0.0265, 0.0837, 0.0651, 0.0845, 0.0541, 0.1059, 0.4153],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:41,454][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ of] are: tensor([0.0166, 0.1155, 0.1408, 0.1177, 0.1324, 0.1257, 0.1276, 0.1226, 0.1012],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:41,456][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ of] are: tensor([0.1045, 0.0985, 0.1106, 0.0960, 0.1888, 0.0966, 0.1001, 0.1103, 0.0946],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:41,457][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ of] are: tensor([0.4423, 0.0660, 0.0196, 0.0256, 0.0205, 0.0406, 0.0267, 0.1157, 0.2429],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:41,459][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ of] are: tensor([0.1149, 0.0879, 0.2061, 0.0686, 0.1517, 0.1408, 0.1137, 0.0848, 0.0316],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:41,460][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ of] are: tensor([0.0075, 0.1218, 0.1263, 0.1269, 0.1242, 0.1233, 0.1243, 0.1232, 0.1224],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:41,462][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ of] are: tensor([0.0055, 0.1153, 0.1266, 0.1290, 0.1204, 0.1232, 0.1283, 0.1269, 0.1248],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:41,463][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ of] are: tensor([0.0343, 0.1155, 0.1639, 0.1287, 0.1283, 0.1131, 0.1055, 0.0939, 0.1168],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:41,464][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ fun] are: tensor([1.9704e-04, 7.7565e-04, 7.5828e-04, 3.5263e-03, 4.2938e-03, 1.7176e-03,
        1.1322e-02, 3.0100e-02, 4.5235e-02, 9.0207e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:41,465][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ fun] are: tensor([0.0078, 0.1369, 0.1034, 0.1037, 0.1027, 0.0974, 0.1092, 0.1223, 0.1151,
        0.1014], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:41,466][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ fun] are: tensor([9.8627e-01, 3.1156e-04, 1.0037e-03, 1.2885e-03, 2.0410e-03, 1.3964e-03,
        1.6874e-03, 2.4519e-03, 1.8389e-03, 1.7153e-03], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:41,468][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ fun] are: tensor([0.1003, 0.1014, 0.0991, 0.1046, 0.0990, 0.0952, 0.0986, 0.1008, 0.0938,
        0.1072], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:41,469][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ fun] are: tensor([0.2533, 0.0061, 0.0231, 0.0710, 0.0429, 0.0959, 0.0729, 0.0683, 0.3029,
        0.0636], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:41,471][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ fun] are: tensor([0.0141, 0.1008, 0.1215, 0.1053, 0.1286, 0.1127, 0.1152, 0.1036, 0.1032,
        0.0949], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:41,472][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ fun] are: tensor([0.0487, 0.1137, 0.0809, 0.1394, 0.1010, 0.0991, 0.1383, 0.0662, 0.1493,
        0.0633], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:41,473][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ fun] are: tensor([0.2528, 0.0396, 0.0151, 0.0289, 0.0295, 0.0479, 0.0233, 0.0389, 0.1859,
        0.3381], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:41,475][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ fun] are: tensor([0.0805, 0.0755, 0.1627, 0.0805, 0.2132, 0.1212, 0.0969, 0.0543, 0.0551,
        0.0600], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:41,476][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ fun] are: tensor([0.0062, 0.1089, 0.1129, 0.1132, 0.1112, 0.1101, 0.1106, 0.1093, 0.1090,
        0.1083], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:41,477][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ fun] are: tensor([0.0047, 0.1024, 0.1133, 0.1150, 0.1111, 0.1128, 0.1151, 0.1155, 0.1146,
        0.0955], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:41,479][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ fun] are: tensor([0.0252, 0.1034, 0.1515, 0.1188, 0.1185, 0.1016, 0.0938, 0.0851, 0.1027,
        0.0995], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:41,480][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.0007, 0.0015, 0.0008, 0.0040, 0.0033, 0.0012, 0.0052, 0.0256, 0.0744,
        0.6944, 0.1888], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:41,482][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.0070, 0.1254, 0.0941, 0.0944, 0.0931, 0.0888, 0.0993, 0.1112, 0.1034,
        0.0919, 0.0914], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:41,482][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ at] are: tensor([9.8356e-01, 3.0774e-04, 9.8003e-04, 1.3112e-03, 2.1273e-03, 1.5881e-03,
        1.9172e-03, 2.7107e-03, 2.2317e-03, 2.1187e-03, 1.1513e-03],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:41,484][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.0891, 0.0922, 0.0907, 0.0951, 0.0905, 0.0871, 0.0902, 0.0930, 0.0852,
        0.0996, 0.0874], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:41,485][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.1223, 0.0037, 0.0245, 0.0658, 0.0462, 0.0713, 0.0446, 0.0805, 0.2916,
        0.0817, 0.1679], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:41,487][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.0125, 0.0909, 0.1136, 0.0967, 0.1025, 0.1014, 0.1090, 0.1003, 0.0889,
        0.0958, 0.0882], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:41,488][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.0853, 0.0900, 0.0860, 0.0869, 0.1242, 0.0803, 0.0893, 0.0882, 0.0724,
        0.1653, 0.0323], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:41,489][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.2420, 0.0175, 0.0137, 0.0082, 0.0160, 0.0182, 0.0155, 0.0202, 0.1002,
        0.4360, 0.1125], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:41,489][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.0913, 0.0578, 0.1482, 0.0583, 0.1195, 0.1131, 0.1164, 0.0914, 0.0394,
        0.1384, 0.0262], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:41,489][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.0051, 0.0986, 0.1026, 0.1025, 0.1006, 0.0996, 0.0999, 0.0989, 0.0988,
        0.0981, 0.0953], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:41,490][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.0033, 0.0956, 0.1074, 0.1087, 0.1014, 0.0998, 0.1068, 0.1035, 0.1026,
        0.0887, 0.0822], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:41,490][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.0280, 0.0936, 0.1412, 0.1113, 0.1090, 0.0963, 0.0888, 0.0768, 0.1007,
        0.0901, 0.0642], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:41,491][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ the] are: tensor([2.3587e-04, 1.0162e-03, 1.8062e-03, 9.6963e-03, 1.0949e-02, 1.8271e-03,
        6.4316e-03, 2.1738e-02, 5.1995e-02, 4.6974e-01, 1.4534e-01, 2.7922e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:41,491][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0060, 0.1146, 0.0866, 0.0868, 0.0859, 0.0813, 0.0907, 0.1019, 0.0945,
        0.0833, 0.0829, 0.0854], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:41,492][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ the] are: tensor([9.8248e-01, 3.3589e-04, 9.9987e-04, 1.2321e-03, 1.9700e-03, 1.5886e-03,
        1.8047e-03, 2.7207e-03, 2.0989e-03, 2.0625e-03, 1.1167e-03, 1.5946e-03],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:41,493][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0810, 0.0847, 0.0826, 0.0870, 0.0823, 0.0791, 0.0823, 0.0842, 0.0779,
        0.0903, 0.0803, 0.0883], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:41,495][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0297, 0.0023, 0.0224, 0.0554, 0.0475, 0.0740, 0.0419, 0.0787, 0.3255,
        0.0699, 0.1911, 0.0616], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:41,496][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0110, 0.0831, 0.1021, 0.0894, 0.0971, 0.0905, 0.0923, 0.0889, 0.0843,
        0.0899, 0.0913, 0.0802], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:41,498][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0774, 0.0733, 0.0965, 0.0678, 0.1570, 0.0639, 0.0559, 0.0726, 0.0779,
        0.1405, 0.0543, 0.0628], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:41,499][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.1228, 0.0296, 0.0066, 0.0120, 0.0120, 0.0189, 0.0095, 0.0276, 0.1414,
        0.3553, 0.1818, 0.0824], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:41,500][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0853, 0.0615, 0.1304, 0.0680, 0.1240, 0.1157, 0.0794, 0.0685, 0.0501,
        0.1252, 0.0614, 0.0306], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:41,502][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0050, 0.0901, 0.0931, 0.0934, 0.0915, 0.0906, 0.0909, 0.0900, 0.0902,
        0.0892, 0.0871, 0.0888], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:41,503][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0034, 0.0869, 0.0965, 0.0990, 0.0925, 0.0921, 0.0967, 0.0952, 0.0948,
        0.0818, 0.0755, 0.0856], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:41,505][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0246, 0.0879, 0.1324, 0.1046, 0.1032, 0.0890, 0.0832, 0.0746, 0.0926,
        0.0891, 0.0598, 0.0588], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:41,506][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ hospital] are: tensor([8.5997e-05, 7.6498e-04, 1.1646e-03, 8.5469e-03, 7.9088e-03, 8.5614e-03,
        6.8008e-03, 5.8837e-03, 2.9265e-02, 1.5156e-01, 8.5753e-02, 1.9334e-01,
        5.0036e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:41,507][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ hospital] are: tensor([0.0060, 0.1063, 0.0796, 0.0797, 0.0787, 0.0747, 0.0835, 0.0943, 0.0877,
        0.0771, 0.0763, 0.0787, 0.0774], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:41,508][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ hospital] are: tensor([9.9171e-01, 1.9793e-04, 4.3399e-04, 5.1778e-04, 8.4740e-04, 6.8278e-04,
        7.6406e-04, 1.1718e-03, 8.8630e-04, 9.4111e-04, 4.9272e-04, 7.1705e-04,
        6.3804e-04], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:41,510][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ hospital] are: tensor([0.0779, 0.0768, 0.0758, 0.0797, 0.0741, 0.0712, 0.0744, 0.0761, 0.0706,
        0.0828, 0.0737, 0.0817, 0.0852], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:41,511][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ hospital] are: tensor([0.1438, 0.0043, 0.0179, 0.0513, 0.0312, 0.0665, 0.0511, 0.0476, 0.2086,
        0.0481, 0.1786, 0.0934, 0.0577], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:41,513][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ hospital] are: tensor([0.0115, 0.0834, 0.0961, 0.0845, 0.0828, 0.0859, 0.0867, 0.0865, 0.0755,
        0.0838, 0.0841, 0.0774, 0.0617], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:41,514][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ hospital] are: tensor([0.0535, 0.0899, 0.0712, 0.1047, 0.0752, 0.0693, 0.0762, 0.0455, 0.0966,
        0.0857, 0.0598, 0.0992, 0.0734], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:41,516][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ hospital] are: tensor([0.2171, 0.0531, 0.0101, 0.0102, 0.0111, 0.0188, 0.0074, 0.0151, 0.0753,
        0.1453, 0.0786, 0.0594, 0.2983], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:41,517][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ hospital] are: tensor([0.0675, 0.0717, 0.1210, 0.0729, 0.0833, 0.1044, 0.1085, 0.0797, 0.0495,
        0.1044, 0.0441, 0.0524, 0.0405], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:41,519][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ hospital] are: tensor([0.0045, 0.0831, 0.0858, 0.0862, 0.0843, 0.0834, 0.0838, 0.0828, 0.0829,
        0.0823, 0.0805, 0.0821, 0.0783], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:41,520][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ hospital] are: tensor([0.0029, 0.0812, 0.0891, 0.0902, 0.0872, 0.0881, 0.0874, 0.0877, 0.0848,
        0.0700, 0.0685, 0.0782, 0.0847], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:41,522][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ hospital] are: tensor([0.0202, 0.0836, 0.1209, 0.0989, 0.0980, 0.0844, 0.0766, 0.0685, 0.0825,
        0.0779, 0.0549, 0.0526, 0.0809], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:41,523][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [.] are: tensor([1.1205e-04, 1.0370e-04, 2.3167e-04, 5.1576e-03, 4.5399e-03, 1.2166e-03,
        2.4614e-03, 1.2301e-02, 3.6792e-02, 1.1137e-01, 6.6161e-02, 1.4564e-01,
        4.1007e-01, 2.0384e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:41,524][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.0052, 0.1000, 0.0754, 0.0747, 0.0741, 0.0699, 0.0782, 0.0884, 0.0814,
        0.0711, 0.0703, 0.0723, 0.0717, 0.0673], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:41,525][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [.] are: tensor([9.8377e-01, 2.8818e-04, 7.4365e-04, 9.7709e-04, 1.5600e-03, 1.2694e-03,
        1.4423e-03, 2.1751e-03, 1.7884e-03, 1.7072e-03, 8.8862e-04, 1.3456e-03,
        1.2172e-03, 8.2771e-04], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:41,526][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0693, 0.0698, 0.0704, 0.0737, 0.0697, 0.0663, 0.0690, 0.0706, 0.0658,
        0.0773, 0.0681, 0.0758, 0.0799, 0.0745], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:41,528][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0806, 0.0027, 0.0196, 0.0409, 0.0339, 0.0654, 0.0365, 0.0658, 0.2013,
        0.0612, 0.1507, 0.0611, 0.0793, 0.1011], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:41,530][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.0091, 0.0719, 0.0923, 0.0772, 0.0890, 0.0818, 0.0806, 0.0805, 0.0681,
        0.0756, 0.0759, 0.0712, 0.0685, 0.0583], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:41,531][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0729, 0.0441, 0.0778, 0.0449, 0.1367, 0.0697, 0.0707, 0.0714, 0.0466,
        0.1232, 0.0316, 0.0816, 0.1096, 0.0191], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:41,532][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.2161, 0.0327, 0.0049, 0.0067, 0.0097, 0.0128, 0.0042, 0.0108, 0.0526,
        0.0806, 0.0483, 0.0329, 0.2264, 0.2613], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:41,534][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.0848, 0.0545, 0.1238, 0.0514, 0.1161, 0.0873, 0.0911, 0.0592, 0.0342,
        0.1041, 0.0435, 0.0462, 0.0840, 0.0198], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:41,535][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.0042, 0.0769, 0.0794, 0.0798, 0.0777, 0.0771, 0.0777, 0.0770, 0.0770,
        0.0765, 0.0744, 0.0763, 0.0722, 0.0738], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:41,537][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.0031, 0.0745, 0.0828, 0.0837, 0.0781, 0.0793, 0.0834, 0.0808, 0.0810,
        0.0692, 0.0643, 0.0739, 0.0725, 0.0735], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:41,538][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0219, 0.0768, 0.1127, 0.0924, 0.0887, 0.0753, 0.0711, 0.0629, 0.0780,
        0.0707, 0.0499, 0.0493, 0.0726, 0.0777], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:41,539][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Anthony] are: tensor([3.9655e-06, 1.7835e-04, 4.1052e-04, 3.2493e-03, 5.3999e-03, 2.2172e-03,
        1.4963e-03, 2.9753e-03, 3.1926e-02, 1.7567e-01, 3.3835e-02, 1.0435e-01,
        3.4673e-01, 1.0587e-01, 1.8569e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:41,541][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Anthony] are: tensor([0.0053, 0.0936, 0.0701, 0.0698, 0.0690, 0.0651, 0.0726, 0.0829, 0.0758,
        0.0659, 0.0648, 0.0666, 0.0667, 0.0631, 0.0688], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:41,542][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Anthony] are: tensor([9.8944e-01, 1.4851e-04, 4.4622e-04, 5.6456e-04, 9.4001e-04, 7.3871e-04,
        8.8414e-04, 1.4481e-03, 9.9961e-04, 1.0847e-03, 5.3083e-04, 8.7081e-04,
        8.4161e-04, 5.1415e-04, 5.4642e-04], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:41,543][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Anthony] are: tensor([0.0656, 0.0657, 0.0649, 0.0681, 0.0635, 0.0612, 0.0638, 0.0658, 0.0606,
        0.0708, 0.0635, 0.0700, 0.0747, 0.0699, 0.0719], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:41,545][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Anthony] are: tensor([0.1809, 0.0024, 0.0085, 0.0346, 0.0185, 0.0426, 0.0287, 0.0335, 0.1519,
        0.0314, 0.1420, 0.0586, 0.0486, 0.1215, 0.0962], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:41,546][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Anthony] are: tensor([0.0096, 0.0736, 0.0754, 0.0736, 0.0717, 0.0794, 0.0782, 0.0761, 0.0654,
        0.0707, 0.0711, 0.0668, 0.0661, 0.0585, 0.0636], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:41,547][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Anthony] are: tensor([0.0408, 0.0740, 0.0363, 0.0858, 0.0626, 0.0653, 0.0753, 0.0558, 0.0821,
        0.0913, 0.0463, 0.1200, 0.0773, 0.0448, 0.0424], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:41,547][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Anthony] are: tensor([0.4347, 0.0293, 0.0031, 0.0050, 0.0046, 0.0052, 0.0027, 0.0058, 0.0254,
        0.0257, 0.0331, 0.0188, 0.1587, 0.1853, 0.0629], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:41,548][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Anthony] are: tensor([0.0580, 0.0815, 0.0674, 0.0622, 0.0808, 0.0926, 0.0875, 0.0684, 0.0413,
        0.0771, 0.0448, 0.0476, 0.0751, 0.0348, 0.0810], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:41,548][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Anthony] are: tensor([0.0039, 0.0715, 0.0741, 0.0745, 0.0726, 0.0720, 0.0724, 0.0717, 0.0716,
        0.0709, 0.0689, 0.0709, 0.0672, 0.0685, 0.0691], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:41,549][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Anthony] are: tensor([0.0031, 0.0691, 0.0772, 0.0762, 0.0739, 0.0749, 0.0749, 0.0757, 0.0745,
        0.0630, 0.0596, 0.0685, 0.0698, 0.0681, 0.0715], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:41,549][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Anthony] are: tensor([0.0179, 0.0707, 0.1059, 0.0842, 0.0859, 0.0692, 0.0636, 0.0573, 0.0699,
        0.0660, 0.0440, 0.0429, 0.0685, 0.0673, 0.0866], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:41,549][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([1.6215e-05, 1.0372e-04, 3.2522e-04, 1.3137e-03, 3.0510e-03, 1.5303e-03,
        4.9388e-03, 5.3700e-03, 3.1224e-02, 2.2748e-01, 1.3965e-01, 2.1084e-01,
        2.1120e-01, 5.8115e-02, 3.0377e-02, 7.4458e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:41,550][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0049, 0.0876, 0.0662, 0.0654, 0.0651, 0.0609, 0.0687, 0.0780, 0.0718,
        0.0627, 0.0613, 0.0630, 0.0630, 0.0595, 0.0643, 0.0577],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:41,551][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([9.7025e-01, 5.2026e-04, 1.3892e-03, 1.6432e-03, 2.5879e-03, 1.8600e-03,
        2.1541e-03, 3.3358e-03, 2.8094e-03, 2.7157e-03, 1.3736e-03, 2.0089e-03,
        1.9333e-03, 1.2515e-03, 1.4621e-03, 2.7030e-03], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:41,552][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.0624, 0.0605, 0.0604, 0.0629, 0.0593, 0.0572, 0.0592, 0.0614, 0.0564,
        0.0664, 0.0590, 0.0660, 0.0687, 0.0653, 0.0674, 0.0677],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:41,554][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.0862, 0.0022, 0.0132, 0.0309, 0.0259, 0.0292, 0.0212, 0.0428, 0.1552,
        0.0447, 0.1202, 0.0500, 0.0719, 0.1068, 0.1526, 0.0468],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:41,555][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.0083, 0.0661, 0.0757, 0.0679, 0.0760, 0.0666, 0.0698, 0.0660, 0.0579,
        0.0663, 0.0678, 0.0643, 0.0634, 0.0563, 0.0698, 0.0577],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:41,557][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0470, 0.0793, 0.0533, 0.0838, 0.0816, 0.0579, 0.0676, 0.0358, 0.0752,
        0.0595, 0.0363, 0.0866, 0.0828, 0.0488, 0.0581, 0.0465],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:41,558][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.1342, 0.0120, 0.0028, 0.0031, 0.0076, 0.0037, 0.0028, 0.0135, 0.0433,
        0.1463, 0.0416, 0.0237, 0.1975, 0.2035, 0.0957, 0.0685],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:41,559][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.0766, 0.0652, 0.1153, 0.0624, 0.0905, 0.0598, 0.0571, 0.0410, 0.0306,
        0.0652, 0.0576, 0.0422, 0.0630, 0.0320, 0.1042, 0.0374],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:41,561][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.0036, 0.0671, 0.0696, 0.0696, 0.0680, 0.0675, 0.0680, 0.0671, 0.0671,
        0.0665, 0.0647, 0.0664, 0.0631, 0.0644, 0.0647, 0.0625],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:41,562][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0026, 0.0638, 0.0727, 0.0721, 0.0679, 0.0702, 0.0730, 0.0689, 0.0714,
        0.0582, 0.0560, 0.0651, 0.0607, 0.0636, 0.0666, 0.0671],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:41,564][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0161, 0.0667, 0.0996, 0.0796, 0.0790, 0.0651, 0.0601, 0.0546, 0.0663,
        0.0630, 0.0420, 0.0404, 0.0642, 0.0634, 0.0805, 0.0597],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:41,565][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ a] are: tensor([3.4997e-05, 1.7840e-04, 1.7721e-04, 3.0827e-04, 4.7944e-04, 1.2818e-04,
        1.0087e-03, 2.0369e-03, 1.6352e-02, 2.1298e-01, 1.0332e-01, 9.3682e-02,
        3.5566e-01, 4.3691e-02, 4.7256e-02, 4.4794e-02, 7.7909e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:41,566][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0047, 0.0815, 0.0621, 0.0618, 0.0611, 0.0577, 0.0642, 0.0720, 0.0671,
        0.0586, 0.0579, 0.0591, 0.0592, 0.0552, 0.0591, 0.0541, 0.0645],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:41,567][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ a] are: tensor([9.5919e-01, 6.2293e-04, 1.5837e-03, 1.9057e-03, 2.8159e-03, 2.1543e-03,
        2.4003e-03, 3.8056e-03, 3.0528e-03, 3.2400e-03, 1.6814e-03, 2.3694e-03,
        2.3322e-03, 1.5183e-03, 1.7589e-03, 3.3451e-03, 6.2282e-03],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:41,569][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0570, 0.0566, 0.0565, 0.0595, 0.0559, 0.0539, 0.0556, 0.0572, 0.0529,
        0.0622, 0.0552, 0.0611, 0.0654, 0.0617, 0.0640, 0.0647, 0.0607],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:41,570][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0102, 0.0014, 0.0182, 0.0289, 0.0360, 0.0381, 0.0184, 0.0522, 0.1747,
        0.0508, 0.1079, 0.0371, 0.0657, 0.0827, 0.1984, 0.0614, 0.0181],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:41,572][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0086, 0.0614, 0.0708, 0.0649, 0.0648, 0.0630, 0.0640, 0.0629, 0.0587,
        0.0632, 0.0633, 0.0578, 0.0555, 0.0532, 0.0640, 0.0624, 0.0616],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:41,573][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0434, 0.0499, 0.0650, 0.0519, 0.0990, 0.0494, 0.0360, 0.0477, 0.0627,
        0.1079, 0.0403, 0.0502, 0.0964, 0.0332, 0.0713, 0.0504, 0.0452],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:41,575][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0910, 0.0068, 0.0012, 0.0020, 0.0019, 0.0057, 0.0009, 0.0050, 0.0164,
        0.0482, 0.0220, 0.0101, 0.2343, 0.2242, 0.0551, 0.2542, 0.0210],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:41,576][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0710, 0.0734, 0.0813, 0.0593, 0.0687, 0.0744, 0.0355, 0.0507, 0.0360,
        0.0716, 0.0445, 0.0309, 0.0699, 0.0348, 0.0862, 0.0713, 0.0408],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:41,578][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0034, 0.0631, 0.0647, 0.0649, 0.0637, 0.0633, 0.0638, 0.0629, 0.0630,
        0.0626, 0.0614, 0.0627, 0.0595, 0.0607, 0.0605, 0.0585, 0.0612],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:41,579][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0032, 0.0603, 0.0681, 0.0656, 0.0635, 0.0640, 0.0665, 0.0653, 0.0638,
        0.0577, 0.0531, 0.0601, 0.0602, 0.0591, 0.0637, 0.0614, 0.0644],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:41,580][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0154, 0.0622, 0.0921, 0.0748, 0.0749, 0.0619, 0.0575, 0.0536, 0.0631,
        0.0609, 0.0412, 0.0395, 0.0622, 0.0606, 0.0736, 0.0552, 0.0512],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:41,582][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ drink] are: tensor([8.9234e-05, 2.0882e-04, 5.1879e-04, 3.0402e-03, 9.0930e-03, 5.6004e-03,
        8.9521e-03, 1.5935e-02, 1.8548e-02, 1.4588e-01, 5.2263e-02, 1.5431e-01,
        2.3246e-01, 1.0935e-01, 3.5731e-02, 1.4935e-01, 2.0397e-02, 3.8273e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:41,583][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ drink] are: tensor([0.0047, 0.0760, 0.0579, 0.0575, 0.0569, 0.0538, 0.0604, 0.0674, 0.0629,
        0.0549, 0.0544, 0.0556, 0.0554, 0.0519, 0.0555, 0.0508, 0.0613, 0.0627],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:41,584][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ drink] are: tensor([9.6598e-01, 6.0696e-04, 1.2575e-03, 1.4792e-03, 2.1171e-03, 1.5854e-03,
        1.7507e-03, 2.8184e-03, 2.2426e-03, 2.3052e-03, 1.2127e-03, 1.7051e-03,
        1.6050e-03, 1.0844e-03, 1.2216e-03, 2.3604e-03, 4.5538e-03, 4.1157e-03],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:41,586][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ drink] are: tensor([0.0541, 0.0537, 0.0535, 0.0564, 0.0525, 0.0504, 0.0522, 0.0540, 0.0497,
        0.0582, 0.0518, 0.0575, 0.0616, 0.0581, 0.0605, 0.0606, 0.0568, 0.0584],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:41,587][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ drink] are: tensor([0.1037, 0.0028, 0.0135, 0.0340, 0.0216, 0.0434, 0.0344, 0.0324, 0.1420,
        0.0278, 0.1087, 0.0596, 0.0382, 0.1034, 0.1099, 0.0685, 0.0378, 0.0183],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:41,589][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ drink] are: tensor([0.0085, 0.0575, 0.0700, 0.0583, 0.0707, 0.0636, 0.0620, 0.0627, 0.0542,
        0.0572, 0.0621, 0.0557, 0.0503, 0.0486, 0.0592, 0.0555, 0.0571, 0.0468],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:41,590][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ drink] are: tensor([0.0252, 0.0705, 0.0539, 0.0822, 0.0532, 0.0484, 0.0631, 0.0357, 0.0693,
        0.0465, 0.0365, 0.0821, 0.0669, 0.0422, 0.0607, 0.0368, 0.0718, 0.0552],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:41,592][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ drink] are: tensor([0.0993, 0.0066, 0.0013, 0.0020, 0.0020, 0.0036, 0.0014, 0.0039, 0.0163,
        0.0554, 0.0217, 0.0157, 0.1162, 0.1517, 0.0716, 0.2030, 0.0296, 0.1986],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:41,593][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ drink] are: tensor([0.0544, 0.0431, 0.0988, 0.0431, 0.1003, 0.0658, 0.0653, 0.0471, 0.0276,
        0.0564, 0.0388, 0.0368, 0.0560, 0.0255, 0.0993, 0.0537, 0.0613, 0.0267],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:41,595][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ drink] are: tensor([0.0031, 0.0594, 0.0610, 0.0612, 0.0601, 0.0596, 0.0601, 0.0592, 0.0594,
        0.0590, 0.0578, 0.0592, 0.0561, 0.0570, 0.0570, 0.0552, 0.0577, 0.0579],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:41,596][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ drink] are: tensor([0.0024, 0.0585, 0.0624, 0.0630, 0.0599, 0.0628, 0.0630, 0.0622, 0.0609,
        0.0521, 0.0492, 0.0573, 0.0554, 0.0557, 0.0569, 0.0560, 0.0602, 0.0621],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:41,598][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ drink] are: tensor([0.0125, 0.0589, 0.0875, 0.0712, 0.0717, 0.0580, 0.0520, 0.0494, 0.0571,
        0.0555, 0.0376, 0.0357, 0.0582, 0.0587, 0.0745, 0.0541, 0.0470, 0.0604],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:41,599][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ to] are: tensor([2.1327e-04, 8.1107e-05, 5.4704e-05, 1.4014e-04, 2.9011e-04, 1.0772e-04,
        7.8201e-04, 2.8033e-03, 1.3240e-02, 1.5820e-01, 5.4687e-02, 6.7748e-02,
        3.7652e-01, 3.4423e-02, 3.7697e-02, 5.0137e-02, 7.2553e-02, 4.6270e-02,
        8.4054e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:41,600][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0042, 0.0722, 0.0544, 0.0543, 0.0536, 0.0507, 0.0570, 0.0638, 0.0593,
        0.0520, 0.0512, 0.0524, 0.0522, 0.0487, 0.0523, 0.0475, 0.0578, 0.0591,
        0.0572], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:41,601][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ to] are: tensor([9.7170e-01, 3.2860e-04, 8.1693e-04, 1.0434e-03, 1.6962e-03, 1.2819e-03,
        1.4661e-03, 2.3316e-03, 2.0781e-03, 1.9435e-03, 1.0016e-03, 1.4290e-03,
        1.2830e-03, 8.4856e-04, 9.2979e-04, 1.7879e-03, 3.9469e-03, 3.4294e-03,
        6.5289e-04], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:41,603][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0496, 0.0499, 0.0506, 0.0530, 0.0502, 0.0480, 0.0502, 0.0515, 0.0469,
        0.0556, 0.0488, 0.0548, 0.0589, 0.0551, 0.0572, 0.0584, 0.0543, 0.0560,
        0.0509], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:41,605][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0540, 0.0012, 0.0109, 0.0230, 0.0200, 0.0319, 0.0187, 0.0406, 0.1354,
        0.0337, 0.0874, 0.0322, 0.0446, 0.0750, 0.1378, 0.0539, 0.0193, 0.0239,
        0.1569], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:41,605][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0073, 0.0534, 0.0646, 0.0557, 0.0625, 0.0587, 0.0606, 0.0591, 0.0494,
        0.0559, 0.0540, 0.0517, 0.0500, 0.0441, 0.0572, 0.0550, 0.0576, 0.0538,
        0.0495], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:41,606][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0393, 0.0435, 0.0643, 0.0411, 0.0871, 0.0461, 0.0486, 0.0481, 0.0377,
        0.0980, 0.0236, 0.0616, 0.0843, 0.0193, 0.0713, 0.0389, 0.0559, 0.0761,
        0.0150], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:41,606][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.1230, 0.0046, 0.0007, 0.0007, 0.0007, 0.0028, 0.0006, 0.0027, 0.0067,
        0.0207, 0.0060, 0.0050, 0.0523, 0.1021, 0.0464, 0.1798, 0.0181, 0.2833,
        0.1437], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:41,607][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0514, 0.0325, 0.0787, 0.0387, 0.0589, 0.0591, 0.0676, 0.0554, 0.0261,
        0.0855, 0.0314, 0.0409, 0.0607, 0.0200, 0.0899, 0.0610, 0.0718, 0.0489,
        0.0214], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:41,607][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0028, 0.0563, 0.0577, 0.0581, 0.0569, 0.0565, 0.0571, 0.0563, 0.0563,
        0.0559, 0.0545, 0.0560, 0.0529, 0.0540, 0.0540, 0.0521, 0.0545, 0.0548,
        0.0533], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:41,608][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0022, 0.0542, 0.0592, 0.0594, 0.0561, 0.0574, 0.0600, 0.0601, 0.0575,
        0.0522, 0.0478, 0.0531, 0.0542, 0.0526, 0.0547, 0.0542, 0.0562, 0.0583,
        0.0505], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:41,608][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0144, 0.0550, 0.0808, 0.0668, 0.0664, 0.0553, 0.0509, 0.0469, 0.0566,
        0.0550, 0.0374, 0.0362, 0.0576, 0.0540, 0.0668, 0.0490, 0.0450, 0.0549,
        0.0510], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:41,648][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:21:41,649][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:41,651][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:41,652][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:41,653][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:41,653][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:41,654][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:41,654][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:41,654][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:41,654][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:41,655][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:41,655][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:41,655][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:41,656][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0043, 0.9957], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:41,656][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0342, 0.9658], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:41,656][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.8002, 0.1998], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:41,657][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.4367, 0.5633], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:41,657][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.9179, 0.0821], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:41,657][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.1977, 0.8023], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:41,658][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.7290, 0.2710], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:41,658][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.8603, 0.1397], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:41,658][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.8145, 0.1855], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:41,659][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.8913, 0.1087], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:41,659][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.4062, 0.5938], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:41,659][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.5698, 0.4302], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:41,660][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Anthony] are: tensor([0.0015, 0.8334, 0.1652], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:41,660][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Anthony] are: tensor([0.0034, 0.4291, 0.5675], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:41,660][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Anthony] are: tensor([0.5999, 0.2665, 0.1336], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:41,661][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Anthony] are: tensor([0.5142, 0.0847, 0.4011], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:41,661][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Anthony] are: tensor([0.7619, 0.1296, 0.1085], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:41,661][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Anthony] are: tensor([0.0602, 0.3805, 0.5593], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:41,662][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Anthony] are: tensor([0.3555, 0.5111, 0.1335], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:41,662][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Anthony] are: tensor([0.7021, 0.2005, 0.0974], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:41,662][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Anthony] are: tensor([0.7353, 0.1746, 0.0901], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:41,663][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Anthony] are: tensor([0.9081, 0.0788, 0.0132], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:41,663][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Anthony] are: tensor([0.3889, 0.2953, 0.3158], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:41,664][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Anthony] are: tensor([0.3789, 0.3031, 0.3180], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:41,666][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0014, 0.5815, 0.1511, 0.2660], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:41,667][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0072, 0.1460, 0.7158, 0.1311], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:41,669][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.3557, 0.2873, 0.2702, 0.0868], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:41,670][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.1228, 0.0464, 0.6580, 0.1728], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:41,672][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.5325, 0.1174, 0.1629, 0.1872], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:41,673][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0522, 0.2560, 0.4259, 0.2659], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:41,674][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.2312, 0.3111, 0.2156, 0.2420], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:41,676][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.7522, 0.1340, 0.0726, 0.0412], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:41,677][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.6185, 0.1810, 0.0858, 0.1147], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:41,679][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.7813, 0.0634, 0.0913, 0.0640], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:41,680][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.1065, 0.2349, 0.2962, 0.3624], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:41,681][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.2897, 0.2297, 0.2416, 0.2390], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:41,683][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Travis] are: tensor([0.0012, 0.5036, 0.0978, 0.2556, 0.1418], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:41,684][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Travis] are: tensor([0.0092, 0.1534, 0.2704, 0.1679, 0.3990], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:41,685][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Travis] are: tensor([0.2077, 0.2559, 0.2136, 0.1655, 0.1573], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:41,685][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Travis] are: tensor([0.1701, 0.0205, 0.2505, 0.5003, 0.0586], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:41,686][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Travis] are: tensor([0.4300, 0.0663, 0.1228, 0.1906, 0.1903], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:41,686][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Travis] are: tensor([0.0331, 0.2030, 0.2810, 0.2222, 0.2608], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:41,686][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Travis] are: tensor([0.2798, 0.2086, 0.1638, 0.1772, 0.1707], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:41,687][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Travis] are: tensor([0.6001, 0.0746, 0.1188, 0.0571, 0.1494], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:41,687][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Travis] are: tensor([0.5976, 0.1444, 0.0753, 0.1060, 0.0767], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:41,687][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Travis] are: tensor([0.6348, 0.0845, 0.1313, 0.1436, 0.0058], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:41,688][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Travis] are: tensor([0.2218, 0.1787, 0.1914, 0.2990, 0.1092], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:41,689][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Travis] are: tensor([0.2347, 0.1861, 0.1970, 0.1924, 0.1898], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:41,690][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.0005, 0.4202, 0.0909, 0.2263, 0.1482, 0.1139], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:41,692][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.0068, 0.0994, 0.1932, 0.1046, 0.4303, 0.1657], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:41,693][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.1346, 0.1892, 0.1923, 0.1654, 0.2643, 0.0543], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:41,694][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.0793, 0.0051, 0.5066, 0.1579, 0.2262, 0.0248], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:41,696][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.1527, 0.0749, 0.1471, 0.1955, 0.3098, 0.1200], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:41,697][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.0388, 0.1569, 0.2033, 0.1672, 0.2503, 0.1835], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:41,699][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.0388, 0.1799, 0.1021, 0.2262, 0.3623, 0.0907], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:41,700][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.5152, 0.1160, 0.0579, 0.1048, 0.1275, 0.0786], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:41,701][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.5239, 0.1401, 0.0753, 0.1063, 0.0805, 0.0738], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:41,703][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.6276, 0.0584, 0.1226, 0.0391, 0.1044, 0.0480], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:41,704][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.0588, 0.1448, 0.2017, 0.2335, 0.1241, 0.2371], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:41,705][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.1910, 0.1560, 0.1656, 0.1635, 0.1602, 0.1638], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:41,707][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0006, 0.3627, 0.0768, 0.1962, 0.1136, 0.1151, 0.1350],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:41,708][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0016, 0.0704, 0.1713, 0.0696, 0.3618, 0.2606, 0.0648],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:41,710][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.2915, 0.0832, 0.1227, 0.1075, 0.2135, 0.0700, 0.1116],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:41,711][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0266, 0.0034, 0.2098, 0.1914, 0.3919, 0.1611, 0.0158],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:41,712][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.1724, 0.0481, 0.1390, 0.0811, 0.3189, 0.1553, 0.0851],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:41,714][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0298, 0.1320, 0.1977, 0.1409, 0.1956, 0.1605, 0.1435],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:41,715][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0776, 0.2076, 0.0600, 0.1505, 0.2689, 0.2024, 0.0330],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:41,716][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.4795, 0.0860, 0.0298, 0.0852, 0.0703, 0.1736, 0.0756],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:41,717][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.4620, 0.1285, 0.0705, 0.0997, 0.0706, 0.0688, 0.1000],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:41,719][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.5088, 0.0395, 0.0978, 0.0562, 0.0664, 0.0619, 0.1694],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:41,720][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0414, 0.1165, 0.1587, 0.1939, 0.1039, 0.1848, 0.2008],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:41,722][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.1657, 0.1335, 0.1426, 0.1399, 0.1381, 0.1393, 0.1410],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:41,723][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ lot] are: tensor([0.0005, 0.3144, 0.0751, 0.1557, 0.1046, 0.0968, 0.1243, 0.1285],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:41,724][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ lot] are: tensor([0.0063, 0.0888, 0.1515, 0.0846, 0.3407, 0.1509, 0.0915, 0.0856],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:41,726][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ lot] are: tensor([0.1705, 0.0718, 0.1228, 0.0780, 0.2836, 0.0445, 0.1420, 0.0869],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:41,727][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ lot] are: tensor([0.0495, 0.0081, 0.1644, 0.5079, 0.1110, 0.0493, 0.0489, 0.0610],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:41,729][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ lot] are: tensor([0.1357, 0.0567, 0.1389, 0.0780, 0.2557, 0.1156, 0.1009, 0.1185],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:41,730][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ lot] are: tensor([0.0185, 0.1065, 0.1808, 0.1102, 0.2025, 0.1359, 0.1274, 0.1182],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:41,732][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ lot] are: tensor([0.0806, 0.1854, 0.1151, 0.1042, 0.1844, 0.1452, 0.0756, 0.1094],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:41,733][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ lot] are: tensor([0.5081, 0.0912, 0.0473, 0.0519, 0.0815, 0.1086, 0.0474, 0.0641],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:41,735][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ lot] are: tensor([0.4130, 0.1215, 0.0663, 0.0915, 0.0630, 0.0633, 0.0929, 0.0885],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:41,736][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ lot] are: tensor([0.3912, 0.0550, 0.0487, 0.0567, 0.0785, 0.1176, 0.1757, 0.0765],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:41,738][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ lot] are: tensor([0.0467, 0.0960, 0.1475, 0.1495, 0.0826, 0.1641, 0.1589, 0.1547],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:41,739][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ lot] are: tensor([0.1498, 0.1190, 0.1241, 0.1234, 0.1207, 0.1224, 0.1234, 0.1171],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:41,740][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([0.0005, 0.2657, 0.0581, 0.1363, 0.0790, 0.0822, 0.1103, 0.1294, 0.1385],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:41,742][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([0.0008, 0.0291, 0.1578, 0.0238, 0.3663, 0.1738, 0.0677, 0.1305, 0.0501],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:41,743][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([0.3655, 0.0625, 0.0600, 0.0263, 0.1139, 0.0215, 0.0499, 0.1366, 0.1637],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:41,743][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([0.0475, 0.0008, 0.3173, 0.0604, 0.3050, 0.0265, 0.0261, 0.1215, 0.0949],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:41,744][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([0.1823, 0.0514, 0.0563, 0.0351, 0.0994, 0.0554, 0.0448, 0.0427, 0.4325],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:41,744][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([0.0180, 0.0910, 0.1598, 0.0928, 0.1742, 0.1250, 0.1147, 0.1388, 0.0858],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:41,744][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([0.0181, 0.0662, 0.0204, 0.0339, 0.0596, 0.0504, 0.0145, 0.3133, 0.4237],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:41,745][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([0.4423, 0.0660, 0.0196, 0.0256, 0.0205, 0.0406, 0.0267, 0.1157, 0.2429],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:41,745][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([0.4050, 0.1050, 0.0578, 0.0813, 0.0569, 0.0583, 0.0856, 0.0828, 0.0674],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:41,746][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([0.3945, 0.0135, 0.0692, 0.0258, 0.0408, 0.0321, 0.1017, 0.2979, 0.0243],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:41,746][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([0.0266, 0.0892, 0.1159, 0.1343, 0.0761, 0.1248, 0.1296, 0.1371, 0.1664],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:41,747][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([0.1308, 0.1057, 0.1117, 0.1104, 0.1086, 0.1097, 0.1102, 0.1037, 0.1092],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:41,749][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ fun] are: tensor([0.0004, 0.2560, 0.0550, 0.1307, 0.0776, 0.0748, 0.0986, 0.1024, 0.1522,
        0.0522], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:41,750][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ fun] are: tensor([0.0007, 0.0281, 0.1059, 0.0325, 0.4412, 0.0952, 0.0649, 0.0687, 0.0721,
        0.0908], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:41,752][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ fun] are: tensor([0.2542, 0.0368, 0.0428, 0.0242, 0.0686, 0.0180, 0.0566, 0.1437, 0.2454,
        0.1099], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:41,753][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ fun] are: tensor([0.0488, 0.0017, 0.0575, 0.0845, 0.0529, 0.0256, 0.0538, 0.0831, 0.5466,
        0.0454], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:41,754][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ fun] are: tensor([0.1540, 0.0174, 0.0376, 0.0177, 0.0680, 0.0529, 0.0424, 0.0531, 0.3052,
        0.2516], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:41,755][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ fun] are: tensor([0.0109, 0.0709, 0.1349, 0.0737, 0.1859, 0.1048, 0.0947, 0.1066, 0.0863,
        0.1312], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:41,757][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ fun] are: tensor([0.0055, 0.0167, 0.0127, 0.0203, 0.0179, 0.0484, 0.0115, 0.1126, 0.6227,
        0.1319], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:41,758][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ fun] are: tensor([0.2528, 0.0396, 0.0151, 0.0289, 0.0295, 0.0479, 0.0233, 0.0389, 0.1859,
        0.3381], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:41,760][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ fun] are: tensor([0.4009, 0.0969, 0.0525, 0.0738, 0.0506, 0.0525, 0.0772, 0.0759, 0.0611,
        0.0585], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:41,761][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ fun] are: tensor([0.3108, 0.0878, 0.0587, 0.0487, 0.0298, 0.1214, 0.0593, 0.2359, 0.0394,
        0.0083], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:41,763][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ fun] are: tensor([0.0485, 0.0668, 0.0818, 0.1134, 0.0459, 0.1526, 0.1225, 0.1030, 0.1762,
        0.0894], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:41,764][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ fun] are: tensor([0.1173, 0.0951, 0.1007, 0.0994, 0.0976, 0.0984, 0.0993, 0.0942, 0.0985,
        0.0995], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:41,766][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.0005, 0.2201, 0.0517, 0.1104, 0.0680, 0.0745, 0.0873, 0.1054, 0.1265,
        0.0548, 0.1008], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:41,767][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.0014, 0.0304, 0.1254, 0.0255, 0.2744, 0.1197, 0.0828, 0.0777, 0.0877,
        0.1447, 0.0302], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:41,769][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.1970, 0.0468, 0.0324, 0.0186, 0.0567, 0.0127, 0.0250, 0.0803, 0.1819,
        0.1323, 0.2163], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:41,770][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.0781, 0.0026, 0.0965, 0.0744, 0.1324, 0.0366, 0.0206, 0.1109, 0.1319,
        0.2236, 0.0922], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:41,771][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.0908, 0.0201, 0.0319, 0.0146, 0.0469, 0.0334, 0.0203, 0.0284, 0.2292,
        0.2938, 0.1907], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:41,773][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.0152, 0.0700, 0.1260, 0.0760, 0.1282, 0.0941, 0.1000, 0.1105, 0.0778,
        0.1393, 0.0629], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:41,774][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.0102, 0.0273, 0.0078, 0.0139, 0.0114, 0.0380, 0.0084, 0.0723, 0.3927,
        0.2843, 0.1336], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:41,776][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.2420, 0.0175, 0.0137, 0.0082, 0.0160, 0.0182, 0.0155, 0.0202, 0.1002,
        0.4360, 0.1125], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:41,777][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.3757, 0.0986, 0.0483, 0.0719, 0.0498, 0.0502, 0.0730, 0.0729, 0.0503,
        0.0519, 0.0575], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:41,779][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.2119, 0.0224, 0.0528, 0.0178, 0.0971, 0.0348, 0.1179, 0.2116, 0.0322,
        0.1571, 0.0444], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:41,780][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.0208, 0.0722, 0.1027, 0.1189, 0.0722, 0.0952, 0.1084, 0.1044, 0.1514,
        0.0770, 0.0768], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:41,781][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.1081, 0.0855, 0.0920, 0.0899, 0.0886, 0.0897, 0.0905, 0.0850, 0.0892,
        0.0898, 0.0918], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:41,783][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0003, 0.1962, 0.0391, 0.1026, 0.0601, 0.0625, 0.0772, 0.0918, 0.1254,
        0.0467, 0.1206, 0.0775], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:41,784][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0006, 0.0309, 0.0720, 0.0311, 0.3128, 0.1679, 0.0462, 0.0741, 0.0932,
        0.0952, 0.0581, 0.0179], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:41,786][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.2512, 0.0236, 0.0262, 0.0148, 0.0458, 0.0065, 0.0225, 0.0934, 0.1307,
        0.1003, 0.2050, 0.0800], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:41,787][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0280, 0.0006, 0.0920, 0.0320, 0.1749, 0.0260, 0.0050, 0.0757, 0.0792,
        0.2369, 0.2257, 0.0239], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:41,789][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0543, 0.0095, 0.0184, 0.0101, 0.0342, 0.0210, 0.0179, 0.0253, 0.1990,
        0.2289, 0.2849, 0.0964], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:41,790][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.0136, 0.0672, 0.1059, 0.0733, 0.1219, 0.0919, 0.0830, 0.0942, 0.0817,
        0.1266, 0.0770, 0.0638], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:41,792][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0124, 0.0172, 0.0079, 0.0134, 0.0203, 0.0219, 0.0038, 0.0840, 0.3107,
        0.2253, 0.2265, 0.0566], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:41,793][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.1228, 0.0296, 0.0066, 0.0120, 0.0120, 0.0189, 0.0095, 0.0276, 0.1414,
        0.3553, 0.1818, 0.0824], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:41,795][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.3588, 0.0861, 0.0445, 0.0663, 0.0432, 0.0448, 0.0667, 0.0674, 0.0539,
        0.0559, 0.0576, 0.0548], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:41,796][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.2891, 0.0227, 0.0543, 0.0253, 0.0386, 0.0232, 0.1198, 0.1471, 0.0287,
        0.0773, 0.0739, 0.1002], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:41,798][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0138, 0.0655, 0.1004, 0.1110, 0.0694, 0.0918, 0.1036, 0.0925, 0.1325,
        0.0687, 0.0696, 0.0810], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:41,799][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0979, 0.0792, 0.0843, 0.0834, 0.0821, 0.0826, 0.0834, 0.0787, 0.0823,
        0.0830, 0.0839, 0.0792], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:41,801][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ hospital] are: tensor([0.0004, 0.1821, 0.0447, 0.1019, 0.0606, 0.0586, 0.0816, 0.0852, 0.1206,
        0.0443, 0.1006, 0.0762, 0.0430], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:41,801][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ hospital] are: tensor([0.0009, 0.0357, 0.0646, 0.0390, 0.1811, 0.0958, 0.0771, 0.0807, 0.0949,
        0.1358, 0.0513, 0.0452, 0.0979], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:41,802][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ hospital] are: tensor([0.2557, 0.0232, 0.0228, 0.0107, 0.0274, 0.0074, 0.0201, 0.0632, 0.0852,
        0.0613, 0.1107, 0.0700, 0.2422], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:41,802][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ hospital] are: tensor([0.0318, 0.0009, 0.0350, 0.0409, 0.0304, 0.0110, 0.0225, 0.0229, 0.1277,
        0.0448, 0.4223, 0.1431, 0.0667], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:41,802][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ hospital] are: tensor([0.0943, 0.0176, 0.0186, 0.0094, 0.0217, 0.0168, 0.0151, 0.0209, 0.1126,
        0.1263, 0.1358, 0.1013, 0.3095], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:41,803][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ hospital] are: tensor([0.0087, 0.0642, 0.1053, 0.0654, 0.1047, 0.0792, 0.0794, 0.0937, 0.0667,
        0.1261, 0.0616, 0.0631, 0.0818], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:41,803][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ hospital] are: tensor([0.0251, 0.0129, 0.0087, 0.0062, 0.0161, 0.0182, 0.0036, 0.0398, 0.1804,
        0.1378, 0.1192, 0.0772, 0.3548], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:41,804][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ hospital] are: tensor([0.2171, 0.0531, 0.0101, 0.0102, 0.0111, 0.0188, 0.0074, 0.0151, 0.0753,
        0.1453, 0.0786, 0.0594, 0.2983], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:41,804][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ hospital] are: tensor([0.3812, 0.0830, 0.0405, 0.0623, 0.0377, 0.0401, 0.0572, 0.0584, 0.0460,
        0.0471, 0.0500, 0.0498, 0.0467], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:41,805][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ hospital] are: tensor([0.1941, 0.0205, 0.0274, 0.0240, 0.0904, 0.0286, 0.0834, 0.1078, 0.0337,
        0.2910, 0.0326, 0.0646, 0.0019], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:41,807][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ hospital] are: tensor([0.0661, 0.0537, 0.0693, 0.0806, 0.0339, 0.1213, 0.0979, 0.0793, 0.1305,
        0.0686, 0.0750, 0.0802, 0.0435], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:41,808][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ hospital] are: tensor([0.0933, 0.0736, 0.0785, 0.0766, 0.0760, 0.0765, 0.0768, 0.0721, 0.0752,
        0.0755, 0.0775, 0.0718, 0.0765], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:41,810][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.0004, 0.1582, 0.0432, 0.0786, 0.0595, 0.0505, 0.0692, 0.0860, 0.1052,
        0.0454, 0.0924, 0.0737, 0.0517, 0.0861], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:41,811][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.0007, 0.0127, 0.0944, 0.0157, 0.2913, 0.1056, 0.0559, 0.0643, 0.0462,
        0.1100, 0.0260, 0.0261, 0.1347, 0.0165], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:41,812][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.3312, 0.0255, 0.0191, 0.0068, 0.0260, 0.0042, 0.0122, 0.0412, 0.0465,
        0.0445, 0.0663, 0.0491, 0.2320, 0.0953], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:41,813][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([9.1542e-03, 8.0823e-05, 6.9995e-02, 9.7911e-03, 6.5136e-02, 8.5324e-03,
        3.2175e-02, 2.8729e-02, 3.3563e-02, 7.0409e-02, 1.8691e-01, 9.3898e-02,
        3.9016e-01, 1.4712e-03], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:41,815][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.0893, 0.0103, 0.0153, 0.0078, 0.0194, 0.0159, 0.0142, 0.0161, 0.0742,
        0.1073, 0.1072, 0.0805, 0.3010, 0.1415], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:41,816][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.0109, 0.0531, 0.0962, 0.0602, 0.1128, 0.0817, 0.0721, 0.0874, 0.0608,
        0.1050, 0.0581, 0.0574, 0.0983, 0.0462], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:41,818][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.0115, 0.0103, 0.0048, 0.0056, 0.0124, 0.0087, 0.0047, 0.0360, 0.0840,
        0.0809, 0.0615, 0.0538, 0.4400, 0.1858], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:41,819][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.2161, 0.0327, 0.0049, 0.0067, 0.0097, 0.0128, 0.0042, 0.0108, 0.0526,
        0.0806, 0.0483, 0.0329, 0.2264, 0.2613], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:41,821][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.3294, 0.0757, 0.0409, 0.0664, 0.0397, 0.0406, 0.0600, 0.0617, 0.0493,
        0.0521, 0.0513, 0.0516, 0.0485, 0.0328], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:41,822][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.2260, 0.0198, 0.0217, 0.0201, 0.0324, 0.0292, 0.0686, 0.1472, 0.0440,
        0.0978, 0.1087, 0.1331, 0.0273, 0.0242], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:41,824][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.0181, 0.0589, 0.0863, 0.0977, 0.0547, 0.0810, 0.0963, 0.0875, 0.1170,
        0.0559, 0.0595, 0.0692, 0.0393, 0.0786], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:41,825][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.0866, 0.0689, 0.0726, 0.0719, 0.0703, 0.0708, 0.0713, 0.0670, 0.0699,
        0.0702, 0.0713, 0.0667, 0.0701, 0.0724], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:41,827][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Anthony] are: tensor([0.0003, 0.1754, 0.0342, 0.0880, 0.0523, 0.0488, 0.0637, 0.0732, 0.1022,
        0.0349, 0.0924, 0.0645, 0.0428, 0.0915, 0.0359], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:41,828][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Anthony] are: tensor([0.0004, 0.0344, 0.0472, 0.0387, 0.1511, 0.1191, 0.0689, 0.0539, 0.0655,
        0.1113, 0.0426, 0.0385, 0.1203, 0.0462, 0.0621], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:41,830][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Anthony] are: tensor([0.2882, 0.0191, 0.0055, 0.0039, 0.0090, 0.0029, 0.0043, 0.0176, 0.0479,
        0.0271, 0.0642, 0.0364, 0.1291, 0.0913, 0.2537], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:41,831][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Anthony] are: tensor([0.0503, 0.0011, 0.0146, 0.0339, 0.0319, 0.0147, 0.0200, 0.0653, 0.1179,
        0.0443, 0.3297, 0.0843, 0.0362, 0.0571, 0.0988], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:41,833][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Anthony] are: tensor([0.1379, 0.0076, 0.0040, 0.0027, 0.0054, 0.0052, 0.0035, 0.0059, 0.0321,
        0.0404, 0.0520, 0.0303, 0.2353, 0.1254, 0.3122], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:41,834][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Anthony] are: tensor([0.0064, 0.0496, 0.0756, 0.0528, 0.0912, 0.0700, 0.0670, 0.0798, 0.0511,
        0.1220, 0.0477, 0.0521, 0.1155, 0.0432, 0.0762], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:41,836][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Anthony] are: tensor([0.0348, 0.0127, 0.0034, 0.0030, 0.0097, 0.0035, 0.0035, 0.0159, 0.0380,
        0.0371, 0.0413, 0.0440, 0.3228, 0.1856, 0.2447], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:41,837][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Anthony] are: tensor([0.4347, 0.0293, 0.0031, 0.0050, 0.0046, 0.0052, 0.0027, 0.0058, 0.0254,
        0.0257, 0.0331, 0.0188, 0.1587, 0.1853, 0.0629], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:41,839][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Anthony] are: tensor([0.3099, 0.0753, 0.0374, 0.0619, 0.0369, 0.0390, 0.0554, 0.0580, 0.0472,
        0.0486, 0.0469, 0.0507, 0.0449, 0.0351, 0.0528], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:41,840][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Anthony] are: tensor([0.3510, 0.0194, 0.0048, 0.0291, 0.0699, 0.0478, 0.0370, 0.1042, 0.0397,
        0.0980, 0.0678, 0.0682, 0.0225, 0.0344, 0.0063], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:41,842][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Anthony] are: tensor([0.0534, 0.0518, 0.0586, 0.0684, 0.0289, 0.0997, 0.0812, 0.0738, 0.1203,
        0.0536, 0.0712, 0.0711, 0.0291, 0.0565, 0.0825], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:41,843][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Anthony] are: tensor([0.0819, 0.0644, 0.0676, 0.0668, 0.0656, 0.0664, 0.0668, 0.0629, 0.0655,
        0.0654, 0.0667, 0.0625, 0.0659, 0.0674, 0.0644], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:41,845][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.0002, 0.1447, 0.0395, 0.0793, 0.0549, 0.0419, 0.0674, 0.0691, 0.0909,
        0.0395, 0.0862, 0.0620, 0.0449, 0.0872, 0.0429, 0.0493],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:41,846][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0007, 0.0282, 0.0666, 0.0257, 0.1469, 0.0478, 0.0367, 0.0492, 0.0426,
        0.0846, 0.0433, 0.0290, 0.1553, 0.0442, 0.1137, 0.0855],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:41,848][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.0920, 0.0168, 0.0089, 0.0046, 0.0151, 0.0018, 0.0080, 0.0213, 0.0382,
        0.0284, 0.0526, 0.0310, 0.1756, 0.0889, 0.3502, 0.0667],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:41,849][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([2.6806e-02, 3.0412e-04, 4.4405e-02, 9.5320e-03, 3.0349e-02, 3.8226e-03,
        8.2045e-03, 3.6820e-02, 3.4304e-02, 3.7457e-02, 6.0229e-02, 1.5778e-01,
        1.0929e-01, 2.4863e-02, 4.1435e-01, 1.4794e-03], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:41,850][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.0289, 0.0051, 0.0075, 0.0032, 0.0082, 0.0037, 0.0036, 0.0077, 0.0352,
        0.0489, 0.0481, 0.0314, 0.2067, 0.1006, 0.4218, 0.0395],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:41,852][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.0071, 0.0488, 0.0713, 0.0481, 0.0880, 0.0650, 0.0576, 0.0732, 0.0472,
        0.1019, 0.0565, 0.0489, 0.0994, 0.0452, 0.0776, 0.0642],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:41,853][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.0047, 0.0066, 0.0035, 0.0031, 0.0156, 0.0056, 0.0015, 0.0152, 0.0383,
        0.0398, 0.0466, 0.0258, 0.3548, 0.1196, 0.2585, 0.0608],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:41,855][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.1342, 0.0120, 0.0028, 0.0031, 0.0076, 0.0037, 0.0028, 0.0135, 0.0433,
        0.1463, 0.0416, 0.0237, 0.1975, 0.2035, 0.0957, 0.0685],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:41,856][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.2663, 0.0751, 0.0378, 0.0572, 0.0391, 0.0372, 0.0533, 0.0557, 0.0453,
        0.0470, 0.0467, 0.0488, 0.0429, 0.0365, 0.0554, 0.0557],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:41,858][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.2799, 0.0144, 0.0348, 0.0105, 0.1059, 0.0228, 0.0586, 0.1109, 0.0232,
        0.0574, 0.0897, 0.0698, 0.0193, 0.0289, 0.0562, 0.0178],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:41,859][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0198, 0.0485, 0.0685, 0.0730, 0.0431, 0.0672, 0.0672, 0.0710, 0.0961,
        0.0525, 0.0540, 0.0575, 0.0390, 0.0530, 0.0829, 0.1068],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:41,860][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.0758, 0.0601, 0.0632, 0.0623, 0.0612, 0.0620, 0.0628, 0.0587, 0.0613,
        0.0614, 0.0629, 0.0586, 0.0623, 0.0633, 0.0603, 0.0640],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:41,860][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0002, 0.1448, 0.0313, 0.0788, 0.0469, 0.0464, 0.0532, 0.0701, 0.0924,
        0.0352, 0.0879, 0.0595, 0.0390, 0.0862, 0.0332, 0.0500, 0.0449],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:41,861][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0005, 0.0234, 0.0691, 0.0244, 0.1546, 0.0934, 0.0246, 0.0475, 0.0632,
        0.0887, 0.0385, 0.0196, 0.1101, 0.0276, 0.0917, 0.0942, 0.0289],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:41,861][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.1498, 0.0083, 0.0051, 0.0025, 0.0096, 0.0016, 0.0030, 0.0138, 0.0286,
        0.0222, 0.0432, 0.0253, 0.1622, 0.0873, 0.2631, 0.0763, 0.0981],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:41,861][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0090, 0.0003, 0.0300, 0.0197, 0.0533, 0.0147, 0.0009, 0.0312, 0.0678,
        0.1074, 0.0838, 0.0215, 0.2758, 0.0151, 0.2436, 0.0214, 0.0044],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:41,862][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0170, 0.0024, 0.0053, 0.0007, 0.0058, 0.0021, 0.0011, 0.0043, 0.0175,
        0.0437, 0.0274, 0.0137, 0.1830, 0.0710, 0.4739, 0.0711, 0.0600],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:41,863][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0099, 0.0469, 0.0728, 0.0495, 0.0739, 0.0577, 0.0520, 0.0638, 0.0507,
        0.0934, 0.0507, 0.0448, 0.0854, 0.0425, 0.0791, 0.0750, 0.0521],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:41,864][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([3.5482e-03, 3.8754e-03, 1.0715e-03, 9.1568e-04, 4.0818e-03, 2.5205e-03,
        2.5252e-04, 1.2083e-02, 3.3355e-02, 5.5738e-02, 2.2841e-02, 1.0162e-02,
        3.4742e-01, 1.6045e-01, 1.7030e-01, 1.5174e-01, 1.9647e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:41,866][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0910, 0.0068, 0.0012, 0.0020, 0.0019, 0.0057, 0.0009, 0.0050, 0.0164,
        0.0482, 0.0220, 0.0101, 0.2343, 0.2242, 0.0551, 0.2542, 0.0210],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:41,867][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.2134, 0.0679, 0.0356, 0.0561, 0.0361, 0.0363, 0.0533, 0.0562, 0.0466,
        0.0478, 0.0472, 0.0511, 0.0425, 0.0366, 0.0544, 0.0531, 0.0659],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:41,868][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.1450, 0.0084, 0.0256, 0.0151, 0.0186, 0.0163, 0.0531, 0.1431, 0.0234,
        0.0321, 0.0910, 0.0898, 0.0125, 0.0590, 0.0534, 0.1073, 0.1063],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:41,870][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0142, 0.0470, 0.0697, 0.0708, 0.0451, 0.0599, 0.0659, 0.0623, 0.0839,
        0.0458, 0.0452, 0.0515, 0.0332, 0.0529, 0.0811, 0.0857, 0.0857],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:41,871][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0702, 0.0561, 0.0599, 0.0588, 0.0580, 0.0583, 0.0592, 0.0553, 0.0579,
        0.0582, 0.0590, 0.0553, 0.0583, 0.0595, 0.0570, 0.0595, 0.0595],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:41,873][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ drink] are: tensor([0.0003, 0.1258, 0.0353, 0.0674, 0.0506, 0.0404, 0.0606, 0.0675, 0.0822,
        0.0305, 0.0772, 0.0570, 0.0369, 0.0696, 0.0360, 0.0478, 0.0532, 0.0616],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:41,874][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ drink] are: tensor([0.0004, 0.0151, 0.0649, 0.0160, 0.1961, 0.0439, 0.0325, 0.0571, 0.0352,
        0.0812, 0.0261, 0.0234, 0.0939, 0.0261, 0.1065, 0.0803, 0.0447, 0.0566],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:41,876][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ drink] are: tensor([0.0823, 0.0082, 0.0052, 0.0019, 0.0076, 0.0013, 0.0045, 0.0114, 0.0274,
        0.0170, 0.0322, 0.0296, 0.1191, 0.0747, 0.3485, 0.0607, 0.1450, 0.0234],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:41,877][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ drink] are: tensor([0.0139, 0.0017, 0.0283, 0.0509, 0.0194, 0.0038, 0.0081, 0.0034, 0.0698,
        0.0106, 0.2132, 0.0485, 0.1968, 0.0646, 0.2067, 0.0057, 0.0400, 0.0146],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:41,879][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ drink] are: tensor([0.0180, 0.0034, 0.0039, 0.0020, 0.0041, 0.0041, 0.0036, 0.0052, 0.0269,
        0.0234, 0.0265, 0.0237, 0.0834, 0.0905, 0.4077, 0.0837, 0.1102, 0.0797],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:41,880][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ drink] are: tensor([0.0055, 0.0394, 0.0738, 0.0398, 0.0921, 0.0558, 0.0482, 0.0672, 0.0448,
        0.0842, 0.0437, 0.0399, 0.0726, 0.0390, 0.0776, 0.0616, 0.0469, 0.0676],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:41,882][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ drink] are: tensor([0.0047, 0.0033, 0.0025, 0.0014, 0.0043, 0.0042, 0.0015, 0.0128, 0.0311,
        0.0313, 0.0285, 0.0327, 0.2595, 0.1118, 0.2586, 0.0826, 0.0607, 0.0686],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:41,883][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ drink] are: tensor([0.0993, 0.0066, 0.0013, 0.0020, 0.0020, 0.0036, 0.0014, 0.0039, 0.0163,
        0.0554, 0.0217, 0.0157, 0.1162, 0.1517, 0.0716, 0.2030, 0.0296, 0.1986],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:41,885][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ drink] are: tensor([0.2108, 0.0646, 0.0319, 0.0480, 0.0318, 0.0317, 0.0471, 0.0481, 0.0413,
        0.0426, 0.0432, 0.0469, 0.0387, 0.0342, 0.0502, 0.0507, 0.0641, 0.0741],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:41,886][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ drink] are: tensor([0.2495, 0.0070, 0.0527, 0.0209, 0.0437, 0.0334, 0.0508, 0.0493, 0.0280,
        0.0860, 0.0424, 0.0575, 0.0168, 0.0338, 0.1039, 0.0648, 0.0591, 0.0003],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:41,888][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ drink] are: tensor([0.0588, 0.0372, 0.0493, 0.0523, 0.0262, 0.0703, 0.0602, 0.0589, 0.0804,
        0.0458, 0.0470, 0.0515, 0.0256, 0.0400, 0.0703, 0.1005, 0.0824, 0.0432],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:41,889][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ drink] are: tensor([0.0700, 0.0537, 0.0566, 0.0551, 0.0545, 0.0549, 0.0555, 0.0523, 0.0543,
        0.0543, 0.0558, 0.0518, 0.0550, 0.0558, 0.0536, 0.0566, 0.0561, 0.0541],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:41,891][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0003, 0.1175, 0.0291, 0.0587, 0.0402, 0.0403, 0.0534, 0.0653, 0.0709,
        0.0338, 0.0619, 0.0554, 0.0392, 0.0700, 0.0319, 0.0478, 0.0497, 0.0735,
        0.0611], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:41,892][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0009, 0.0090, 0.0568, 0.0105, 0.1367, 0.0744, 0.0399, 0.0404, 0.0309,
        0.0742, 0.0208, 0.0234, 0.0984, 0.0133, 0.0874, 0.1074, 0.0485, 0.0932,
        0.0342], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:41,894][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1322, 0.0069, 0.0033, 0.0009, 0.0057, 0.0012, 0.0023, 0.0083, 0.0112,
        0.0120, 0.0189, 0.0145, 0.1287, 0.0429, 0.2169, 0.0604, 0.1073, 0.0413,
        0.1852], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:41,895][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0236, 0.0004, 0.0368, 0.0098, 0.0296, 0.0040, 0.0043, 0.0073, 0.0335,
        0.0283, 0.0560, 0.0169, 0.3256, 0.0147, 0.2753, 0.0187, 0.0247, 0.0606,
        0.0298], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:41,897][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0250, 0.0029, 0.0031, 0.0006, 0.0029, 0.0021, 0.0016, 0.0030, 0.0092,
        0.0223, 0.0133, 0.0112, 0.1003, 0.0453, 0.2248, 0.0526, 0.0833, 0.1321,
        0.2645], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:41,898][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0070, 0.0374, 0.0640, 0.0407, 0.0713, 0.0543, 0.0523, 0.0617, 0.0406,
        0.0792, 0.0402, 0.0434, 0.0729, 0.0351, 0.0700, 0.0624, 0.0517, 0.0775,
        0.0383], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:41,899][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([4.5530e-03, 2.0399e-03, 7.0568e-04, 2.1976e-04, 1.8917e-03, 1.2073e-03,
        3.9530e-04, 1.4080e-02, 7.4654e-03, 1.9432e-02, 6.1579e-03, 5.5568e-03,
        2.0719e-01, 5.3834e-02, 1.0881e-01, 9.9354e-02, 2.6461e-02, 2.6885e-01,
        1.7180e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:41,901][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.1230, 0.0046, 0.0007, 0.0007, 0.0007, 0.0028, 0.0006, 0.0027, 0.0067,
        0.0207, 0.0060, 0.0050, 0.0523, 0.1021, 0.0464, 0.1798, 0.0181, 0.2833,
        0.1437], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:41,902][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.2145, 0.0638, 0.0301, 0.0478, 0.0299, 0.0315, 0.0456, 0.0453, 0.0392,
        0.0412, 0.0425, 0.0429, 0.0368, 0.0316, 0.0458, 0.0475, 0.0544, 0.0620,
        0.0475], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:41,904][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.1240, 0.0096, 0.0300, 0.0122, 0.0239, 0.0184, 0.0698, 0.1448, 0.0270,
        0.0328, 0.0973, 0.0895, 0.0183, 0.0341, 0.0454, 0.0741, 0.1182, 0.0077,
        0.0226], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:41,905][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0239, 0.0474, 0.0581, 0.0564, 0.0339, 0.0508, 0.0565, 0.0579, 0.0749,
        0.0399, 0.0432, 0.0472, 0.0287, 0.0440, 0.0751, 0.0617, 0.0734, 0.0293,
        0.0977], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:41,907][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0649, 0.0508, 0.0535, 0.0530, 0.0518, 0.0524, 0.0528, 0.0497, 0.0518,
        0.0519, 0.0528, 0.0491, 0.0521, 0.0534, 0.0508, 0.0533, 0.0529, 0.0510,
        0.0519], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:41,908][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:21:41,910][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[6873],
        [ 682],
        [ 695],
        [ 268],
        [ 447],
        [ 116],
        [  35],
        [  24],
        [  28],
        [ 499],
        [ 252],
        [ 158],
        [ 239],
        [  25],
        [ 193],
        [ 352],
        [  68],
        [ 111],
        [  24]], device='cuda:0')
[2024-07-24 10:21:41,912][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[7219],
        [ 441],
        [3154],
        [ 522],
        [2203],
        [ 288],
        [ 240],
        [ 266],
        [ 258],
        [1452],
        [1044],
        [ 857],
        [ 309],
        [  70],
        [1275],
        [ 705],
        [ 339],
        [ 281],
        [ 118]], device='cuda:0')
[2024-07-24 10:21:41,913][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[15613],
        [ 1185],
        [  785],
        [  393],
        [  297],
        [  316],
        [  300],
        [  181],
        [  214],
        [  348],
        [  275],
        [  222],
        [  298],
        [  270],
        [  302],
        [  245],
        [  267],
        [  293],
        [  266]], device='cuda:0')
[2024-07-24 10:21:41,915][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[43849],
        [44984],
        [44478],
        [44290],
        [44472],
        [44132],
        [43937],
        [43806],
        [43774],
        [43648],
        [43589],
        [43507],
        [43407],
        [43417],
        [43398],
        [43467],
        [43441],
        [43489],
        [43542]], device='cuda:0')
[2024-07-24 10:21:41,916][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[9303],
        [9244],
        [9237],
        [9196],
        [9164],
        [9112],
        [9054],
        [8964],
        [8813],
        [8917],
        [8849],
        [8825],
        [9066],
        [8865],
        [9010],
        [8584],
        [8372],
        [8526],
        [8659]], device='cuda:0')
[2024-07-24 10:21:41,918][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[11829],
        [ 5344],
        [ 5044],
        [ 5303],
        [ 5060],
        [ 4943],
        [ 5013],
        [ 4854],
        [ 5104],
        [ 5076],
        [ 5085],
        [ 5269],
        [ 5325],
        [ 5528],
        [ 5594],
        [ 5627],
        [ 5697],
        [ 5682],
        [ 5707]], device='cuda:0')
[2024-07-24 10:21:41,919][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[28422],
        [21689],
        [22359],
        [15651],
        [16448],
        [16565],
        [14434],
        [13461],
        [11788],
        [12159],
        [12702],
        [12671],
        [13851],
        [13874],
        [14585],
        [14862],
        [14636],
        [14081],
        [14465]], device='cuda:0')
[2024-07-24 10:21:41,920][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[7809],
        [3626],
        [2599],
        [2397],
        [2180],
        [2427],
        [2522],
        [2652],
        [2707],
        [2918],
        [2980],
        [2912],
        [2932],
        [2879],
        [2831],
        [2853],
        [2878],
        [2897],
        [2899]], device='cuda:0')
[2024-07-24 10:21:41,921][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[20849],
        [16041],
        [11544],
        [12129],
        [11366],
        [10808],
        [10445],
        [11543],
        [11038],
        [11069],
        [ 9567],
        [ 9159],
        [ 9795],
        [ 8841],
        [ 9394],
        [ 9367],
        [ 8614],
        [ 8962],
        [ 7973]], device='cuda:0')
[2024-07-24 10:21:41,923][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[18698],
        [26619],
        [25848],
        [24237],
        [28002],
        [31797],
        [28744],
        [28340],
        [25721],
        [33193],
        [31254],
        [29355],
        [33425],
        [36029],
        [31490],
        [31878],
        [28732],
        [27354],
        [25849]], device='cuda:0')
[2024-07-24 10:21:41,924][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[26451],
        [25451],
        [22279],
        [23368],
        [22387],
        [20177],
        [19270],
        [18462],
        [17721],
        [17256],
        [16700],
        [17017],
        [17400],
        [17156],
        [17494],
        [17988],
        [18131],
        [16966],
        [16724]], device='cuda:0')
[2024-07-24 10:21:41,926][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[14170],
        [18931],
        [19758],
        [19618],
        [19374],
        [19484],
        [19142],
        [18916],
        [18798],
        [18793],
        [18795],
        [18863],
        [18851],
        [18925],
        [18876],
        [18916],
        [18878],
        [18913],
        [18808]], device='cuda:0')
[2024-07-24 10:21:41,928][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[15740],
        [23044],
        [15539],
        [17178],
        [14670],
        [15707],
        [15629],
        [15518],
        [15695],
        [15699],
        [15471],
        [15430],
        [15139],
        [15471],
        [14973],
        [14926],
        [14713],
        [14900],
        [14842]], device='cuda:0')
[2024-07-24 10:21:41,929][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[ 378],
        [ 361],
        [ 640],
        [ 735],
        [ 712],
        [ 708],
        [ 724],
        [ 754],
        [ 724],
        [ 730],
        [ 735],
        [ 772],
        [ 838],
        [ 891],
        [ 951],
        [1000],
        [1009],
        [1036],
        [ 987]], device='cuda:0')
[2024-07-24 10:21:41,931][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[10683],
        [29794],
        [30150],
        [24618],
        [24851],
        [29723],
        [19128],
        [33864],
        [12325],
        [21869],
        [21082],
        [12678],
        [30257],
        [17723],
        [14107],
        [33479],
        [14856],
        [23200],
        [18091]], device='cuda:0')
[2024-07-24 10:21:41,932][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[26779],
        [35318],
        [35746],
        [35721],
        [35765],
        [35843],
        [35464],
        [35301],
        [34838],
        [35002],
        [34890],
        [34743],
        [34880],
        [34318],
        [34250],
        [34401],
        [34316],
        [34659],
        [34848]], device='cuda:0')
[2024-07-24 10:21:41,934][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[37882],
        [35237],
        [36296],
        [36178],
        [39100],
        [41029],
        [41158],
        [40059],
        [40851],
        [41182],
        [39884],
        [40360],
        [38808],
        [40401],
        [38921],
        [38794],
        [39039],
        [39117],
        [38941]], device='cuda:0')
[2024-07-24 10:21:41,935][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[32489],
        [45441],
        [39831],
        [30940],
        [27557],
        [26187],
        [29189],
        [24967],
        [30833],
        [27048],
        [21596],
        [20911],
        [25415],
        [29337],
        [28024],
        [25662],
        [26834],
        [24668],
        [27473]], device='cuda:0')
[2024-07-24 10:21:41,937][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[30222],
        [24582],
        [15518],
        [15221],
        [14748],
        [17618],
        [18353],
        [16894],
        [22974],
        [14843],
        [21970],
        [20382],
        [15145],
        [19482],
        [14550],
        [15853],
        [17510],
        [13761],
        [18823]], device='cuda:0')
[2024-07-24 10:21:41,938][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[ 2990],
        [ 1454],
        [ 1561],
        [ 9289],
        [11358],
        [14195],
        [13501],
        [16996],
        [18141],
        [24404],
        [23982],
        [23679],
        [28094],
        [27712],
        [31676],
        [33365],
        [35355],
        [38010],
        [39077]], device='cuda:0')
[2024-07-24 10:21:41,940][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[23917],
        [38164],
        [39062],
        [39222],
        [38443],
        [38717],
        [38507],
        [37888],
        [38076],
        [38016],
        [38167],
        [38455],
        [38131],
        [38114],
        [38112],
        [38280],
        [38320],
        [38315],
        [38393]], device='cuda:0')
[2024-07-24 10:21:41,941][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[48444],
        [36763],
        [17440],
        [22356],
        [24675],
        [25627],
        [29178],
        [27683],
        [29378],
        [30351],
        [25489],
        [27655],
        [30038],
        [29614],
        [26667],
        [26595],
        [27664],
        [24655],
        [21612]], device='cuda:0')
[2024-07-24 10:21:41,943][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[6868],
        [5334],
        [5699],
        [4691],
        [7457],
        [4651],
        [2719],
        [3196],
        [2544],
        [1195],
        [ 850],
        [1398],
        [4423],
        [6226],
        [6062],
        [5203],
        [4731],
        [5829],
        [6310]], device='cuda:0')
[2024-07-24 10:21:41,944][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[24393],
        [21417],
        [20233],
        [18528],
        [18174],
        [17777],
        [17150],
        [17279],
        [17254],
        [17133],
        [17691],
        [17729],
        [18057],
        [17707],
        [17698],
        [17702],
        [17707],
        [18203],
        [18074]], device='cuda:0')
[2024-07-24 10:21:41,946][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[12274],
        [12453],
        [12666],
        [14883],
        [16938],
        [18550],
        [22682],
        [24838],
        [29411],
        [26690],
        [32194],
        [30537],
        [30914],
        [31616],
        [28971],
        [31561],
        [32749],
        [30324],
        [33677]], device='cuda:0')
[2024-07-24 10:21:41,947][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[10079],
        [12644],
        [13385],
        [15174],
        [14799],
        [15870],
        [16387],
        [16612],
        [16692],
        [17171],
        [17338],
        [17932],
        [17930],
        [17866],
        [17750],
        [17116],
        [16994],
        [16776],
        [16852]], device='cuda:0')
[2024-07-24 10:21:41,949][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[21641],
        [17368],
        [16498],
        [15645],
        [15581],
        [15762],
        [15708],
        [15216],
        [14761],
        [14526],
        [14522],
        [14307],
        [14553],
        [14810],
        [14978],
        [14852],
        [14925],
        [14641],
        [14571]], device='cuda:0')
[2024-07-24 10:21:41,950][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[14210],
        [19595],
        [26913],
        [23972],
        [22147],
        [21522],
        [20762],
        [21629],
        [19281],
        [23115],
        [23529],
        [22813],
        [19874],
        [17105],
        [18213],
        [18720],
        [17779],
        [17950],
        [15910]], device='cuda:0')
[2024-07-24 10:21:41,952][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[44005],
        [16446],
        [16017],
        [20363],
        [13835],
        [17719],
        [18194],
        [ 8391],
        [20641],
        [12743],
        [13586],
        [20601],
        [11072],
        [15438],
        [15735],
        [11456],
        [22384],
        [17486],
        [16450]], device='cuda:0')
[2024-07-24 10:21:41,953][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[30805],
        [30805],
        [30805],
        [30805],
        [30805],
        [30805],
        [30805],
        [30805],
        [30805],
        [30805],
        [30805],
        [30805],
        [30805],
        [30805],
        [30805],
        [30805],
        [30805],
        [30805],
        [30805]], device='cuda:0')
[2024-07-24 10:21:41,995][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:21:41,995][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:41,996][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:41,996][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:41,996][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:41,997][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:41,997][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:41,997][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:41,997][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:41,998][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:41,998][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:41,998][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:41,999][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:41,999][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.8811, 0.1189], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:41,999][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.9824, 0.0176], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:42,000][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.8375, 0.1625], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:42,000][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.2591, 0.7409], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:42,000][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.4107, 0.5893], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:42,001][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.3576, 0.6424], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:42,001][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0915, 0.9085], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:42,001][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.7740, 0.2260], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:42,002][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.9310, 0.0690], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:42,002][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0618, 0.9382], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:42,002][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0908, 0.9092], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:42,003][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.8246, 0.1754], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:42,003][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Anthony] are: tensor([0.6408, 0.3231, 0.0361], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:42,003][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Anthony] are: tensor([0.5410, 0.1897, 0.2693], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:42,004][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Anthony] are: tensor([0.6955, 0.1820, 0.1226], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:42,004][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Anthony] are: tensor([0.1120, 0.4909, 0.3971], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:42,004][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Anthony] are: tensor([0.1921, 0.3732, 0.4346], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:42,005][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Anthony] are: tensor([0.2197, 0.3350, 0.4453], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:42,005][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Anthony] are: tensor([0.0619, 0.5108, 0.4272], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:42,005][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Anthony] are: tensor([0.5814, 0.2029, 0.2157], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:42,006][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Anthony] are: tensor([0.9168, 0.0609, 0.0224], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:42,007][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Anthony] are: tensor([0.0811, 0.6170, 0.3019], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:42,008][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Anthony] are: tensor([0.0528, 0.5595, 0.3877], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:42,010][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Anthony] are: tensor([0.6186, 0.2132, 0.1682], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:42,011][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.8533, 0.0902, 0.0254, 0.0311], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:42,012][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.9426, 0.0123, 0.0330, 0.0121], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:42,014][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.5784, 0.1734, 0.1115, 0.1368], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:42,015][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.1199, 0.3128, 0.2511, 0.3162], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:42,016][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.1684, 0.2770, 0.3034, 0.2512], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:42,018][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1536, 0.2363, 0.3076, 0.3025], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:42,019][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0603, 0.3768, 0.2619, 0.3010], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:42,021][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.4086, 0.1906, 0.1586, 0.2422], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:42,022][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.8243, 0.0855, 0.0312, 0.0590], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:42,023][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0417, 0.1705, 0.3930, 0.3948], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:42,025][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0406, 0.3894, 0.2643, 0.3057], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:42,026][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.6263, 0.1069, 0.0768, 0.1900], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:42,028][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Travis] are: tensor([0.2188, 0.4314, 0.0376, 0.2813, 0.0309], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:42,029][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Travis] are: tensor([0.5073, 0.0908, 0.1239, 0.1530, 0.1250], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:42,030][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Travis] are: tensor([0.4448, 0.1694, 0.1088, 0.1306, 0.1464], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:42,032][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Travis] are: tensor([0.0848, 0.2647, 0.2009, 0.2374, 0.2122], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:42,033][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Travis] are: tensor([0.0726, 0.2118, 0.2915, 0.2109, 0.2133], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:42,034][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Travis] are: tensor([0.1254, 0.1790, 0.2337, 0.2311, 0.2307], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:42,035][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Travis] are: tensor([0.0484, 0.3201, 0.1930, 0.1937, 0.2448], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:42,037][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Travis] are: tensor([0.3765, 0.0920, 0.0987, 0.2141, 0.2187], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:42,038][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Travis] are: tensor([0.8364, 0.0512, 0.0200, 0.0534, 0.0390], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:42,040][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Travis] are: tensor([0.0553, 0.1497, 0.2852, 0.3537, 0.1561], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:42,041][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Travis] are: tensor([0.0271, 0.3273, 0.2125, 0.2546, 0.1785], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:42,042][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Travis] are: tensor([0.3317, 0.0845, 0.1036, 0.2472, 0.2330], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:42,043][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.4304, 0.1743, 0.0494, 0.1136, 0.0819, 0.1504], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:42,045][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.3807, 0.1311, 0.0756, 0.1739, 0.1324, 0.1063], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:42,046][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.3865, 0.1542, 0.0994, 0.1248, 0.1286, 0.1066], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:42,048][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.0666, 0.2034, 0.1784, 0.1953, 0.2107, 0.1457], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:42,049][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.0731, 0.1818, 0.2020, 0.1769, 0.1684, 0.1978], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:42,050][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.0938, 0.1488, 0.1966, 0.1944, 0.1967, 0.1696], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:42,052][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.0384, 0.3982, 0.1812, 0.1415, 0.1089, 0.1318], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:42,053][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.1891, 0.1024, 0.1051, 0.1614, 0.2002, 0.2418], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:42,055][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.5057, 0.1021, 0.0357, 0.1414, 0.0894, 0.1257], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:42,056][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.0014, 0.1659, 0.0918, 0.3975, 0.2088, 0.1346], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:42,057][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.0243, 0.2589, 0.1703, 0.2121, 0.1471, 0.1873], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:42,059][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.2872, 0.0760, 0.0815, 0.1295, 0.2852, 0.1406], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:42,060][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.5582, 0.1446, 0.0206, 0.1187, 0.0360, 0.0982, 0.0237],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:42,061][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.5716, 0.0758, 0.0524, 0.0866, 0.0823, 0.0562, 0.0751],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:42,061][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.3468, 0.1276, 0.0830, 0.1056, 0.1133, 0.0943, 0.1293],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:42,061][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0526, 0.1559, 0.1464, 0.1729, 0.1796, 0.1473, 0.1453],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:42,062][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0661, 0.1436, 0.1989, 0.1384, 0.1423, 0.1924, 0.1184],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:42,062][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0804, 0.1247, 0.1666, 0.1644, 0.1676, 0.1441, 0.1523],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:42,062][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0355, 0.2824, 0.1518, 0.1572, 0.0889, 0.1023, 0.1818],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:42,063][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.2623, 0.0841, 0.0650, 0.1307, 0.1418, 0.1962, 0.1200],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:42,064][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.7666, 0.0284, 0.0090, 0.0358, 0.0310, 0.0902, 0.0389],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:42,065][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0140, 0.1030, 0.1041, 0.3162, 0.2144, 0.1519, 0.0964],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:42,067][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0241, 0.2043, 0.1381, 0.1684, 0.1182, 0.1522, 0.1948],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:42,068][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.2977, 0.0561, 0.0488, 0.1312, 0.2158, 0.1622, 0.0882],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:42,069][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ lot] are: tensor([0.2169, 0.2518, 0.0211, 0.1762, 0.0451, 0.1450, 0.0898, 0.0541],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:42,071][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ lot] are: tensor([0.2929, 0.0494, 0.0638, 0.1345, 0.0895, 0.0805, 0.1822, 0.1072],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:42,072][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ lot] are: tensor([0.2592, 0.1261, 0.0845, 0.1042, 0.1067, 0.0917, 0.1193, 0.1083],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:42,074][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ lot] are: tensor([0.0383, 0.1398, 0.1152, 0.1484, 0.1461, 0.1166, 0.1532, 0.1423],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:42,075][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ lot] are: tensor([0.0552, 0.1297, 0.1497, 0.1264, 0.1157, 0.1562, 0.1109, 0.1561],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:42,076][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ lot] are: tensor([0.0672, 0.1089, 0.1453, 0.1437, 0.1457, 0.1256, 0.1334, 0.1302],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:42,078][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ lot] are: tensor([0.0247, 0.2402, 0.1078, 0.1271, 0.0675, 0.0744, 0.0846, 0.2736],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:42,079][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ lot] are: tensor([0.1586, 0.0799, 0.0651, 0.1118, 0.1125, 0.1517, 0.1764, 0.1441],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:42,081][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ lot] are: tensor([0.5133, 0.0642, 0.0267, 0.0514, 0.0519, 0.0847, 0.1358, 0.0721],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:42,082][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ lot] are: tensor([0.0038, 0.0945, 0.0511, 0.2170, 0.1120, 0.1060, 0.3770, 0.0385],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:42,083][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ lot] are: tensor([0.0193, 0.1797, 0.1177, 0.1433, 0.1011, 0.1306, 0.1665, 0.1418],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:42,085][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ lot] are: tensor([0.2038, 0.0613, 0.0791, 0.0915, 0.1583, 0.1505, 0.1378, 0.1177],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:42,086][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ of] are: tensor([0.3825, 0.1439, 0.0233, 0.1170, 0.0367, 0.1475, 0.0567, 0.0663, 0.0261],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:42,087][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ of] are: tensor([0.7183, 0.0214, 0.0320, 0.0219, 0.0429, 0.0381, 0.0352, 0.0399, 0.0503],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:42,089][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ of] are: tensor([0.2440, 0.1100, 0.0701, 0.0863, 0.0937, 0.0762, 0.1011, 0.0950, 0.1236],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:42,090][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ of] are: tensor([0.0452, 0.1209, 0.1013, 0.1296, 0.1274, 0.1053, 0.1149, 0.1144, 0.1410],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:42,092][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ of] are: tensor([0.0393, 0.1194, 0.1367, 0.1083, 0.1118, 0.1442, 0.1036, 0.1301, 0.1066],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:42,093][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ of] are: tensor([0.0659, 0.0967, 0.1294, 0.1270, 0.1278, 0.1098, 0.1151, 0.1130, 0.1153],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:42,095][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ of] are: tensor([0.0202, 0.2226, 0.1601, 0.1347, 0.0881, 0.0578, 0.0877, 0.0891, 0.1395],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:42,096][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ of] are: tensor([0.2974, 0.0722, 0.0423, 0.0594, 0.0667, 0.1012, 0.0683, 0.1040, 0.1885],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:42,097][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ of] are: tensor([0.5243, 0.0338, 0.0079, 0.0166, 0.0188, 0.0419, 0.0422, 0.0841, 0.2304],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:42,099][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ of] are: tensor([0.0032, 0.0280, 0.0579, 0.1458, 0.0890, 0.0952, 0.1549, 0.1302, 0.2959],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:42,100][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ of] are: tensor([0.0181, 0.1504, 0.0968, 0.1164, 0.0835, 0.1095, 0.1343, 0.1161, 0.1749],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:42,102][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ of] are: tensor([0.2868, 0.0480, 0.0371, 0.0435, 0.0925, 0.0498, 0.0484, 0.0824, 0.3114],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:42,103][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ fun] are: tensor([0.1894, 0.2061, 0.0147, 0.1874, 0.0239, 0.1327, 0.0694, 0.0626, 0.0666,
        0.0471], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:42,104][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ fun] are: tensor([0.0984, 0.0371, 0.0680, 0.0820, 0.0533, 0.0558, 0.1429, 0.0811, 0.3330,
        0.0484], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:42,106][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ fun] are: tensor([0.2590, 0.0968, 0.0569, 0.0740, 0.0790, 0.0684, 0.0907, 0.0832, 0.1163,
        0.0757], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:42,107][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ fun] are: tensor([0.0302, 0.1106, 0.0927, 0.1147, 0.1120, 0.0797, 0.1104, 0.1188, 0.1427,
        0.0881], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:42,109][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ fun] are: tensor([0.0273, 0.0958, 0.1226, 0.1133, 0.1079, 0.1107, 0.0956, 0.1140, 0.0982,
        0.1145], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:42,110][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ fun] are: tensor([0.0569, 0.0862, 0.1160, 0.1147, 0.1158, 0.0990, 0.1050, 0.1029, 0.1058,
        0.0977], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:42,112][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ fun] are: tensor([0.0319, 0.1729, 0.0889, 0.1069, 0.0843, 0.0706, 0.0747, 0.1408, 0.0781,
        0.1509], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:42,113][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ fun] are: tensor([0.1469, 0.0533, 0.0334, 0.0528, 0.0573, 0.0873, 0.0761, 0.1099, 0.2189,
        0.1641], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:42,115][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ fun] are: tensor([0.3847, 0.0233, 0.0072, 0.0182, 0.0157, 0.0460, 0.0384, 0.0586, 0.3235,
        0.0843], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:42,116][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ fun] are: tensor([0.0027, 0.0425, 0.0393, 0.1104, 0.0982, 0.0783, 0.2004, 0.0641, 0.2835,
        0.0806], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:42,118][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ fun] are: tensor([0.0129, 0.1260, 0.0810, 0.1031, 0.0722, 0.0960, 0.1206, 0.1032, 0.1591,
        0.1259], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:42,118][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ fun] are: tensor([0.1114, 0.0242, 0.0209, 0.0339, 0.0431, 0.0383, 0.0405, 0.0687, 0.3853,
        0.2338], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:42,119][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.5497, 0.0748, 0.0162, 0.0427, 0.0195, 0.0959, 0.0246, 0.0252, 0.0155,
        0.0825, 0.0534], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:42,119][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.2369, 0.0137, 0.0190, 0.0472, 0.0606, 0.0463, 0.0899, 0.0957, 0.2448,
        0.1343, 0.0117], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:42,119][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.2018, 0.0970, 0.0561, 0.0750, 0.0754, 0.0658, 0.0856, 0.0801, 0.1044,
        0.0705, 0.0883], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:42,120][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.0420, 0.0956, 0.0787, 0.1052, 0.1030, 0.0830, 0.1029, 0.0941, 0.1269,
        0.0881, 0.0804], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:42,120][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.0278, 0.1096, 0.1164, 0.1072, 0.0933, 0.0994, 0.0826, 0.1050, 0.0906,
        0.1000, 0.0681], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:42,121][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.0505, 0.0776, 0.1056, 0.1043, 0.1062, 0.0902, 0.0956, 0.0938, 0.0973,
        0.0896, 0.0894], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:42,121][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.0204, 0.2049, 0.1189, 0.1207, 0.0793, 0.0538, 0.0702, 0.1082, 0.0805,
        0.0640, 0.0791], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:42,122][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.2470, 0.0513, 0.0291, 0.0440, 0.0505, 0.0632, 0.0412, 0.0676, 0.1224,
        0.1615, 0.1223], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:42,124][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.3217, 0.0191, 0.0041, 0.0105, 0.0085, 0.0272, 0.0176, 0.0463, 0.1887,
        0.1101, 0.2463], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:42,125][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.0042, 0.0256, 0.0380, 0.1210, 0.0648, 0.1030, 0.0754, 0.0978, 0.1297,
        0.2012, 0.1393], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:42,127][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.0114, 0.1131, 0.0715, 0.0931, 0.0639, 0.0845, 0.1083, 0.0923, 0.1425,
        0.1116, 0.1079], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:42,128][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.1509, 0.0234, 0.0199, 0.0226, 0.0498, 0.0332, 0.0309, 0.0363, 0.2265,
        0.2565, 0.1500], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:42,129][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.3805, 0.0748, 0.0176, 0.0796, 0.0201, 0.1246, 0.0287, 0.0399, 0.0249,
        0.0935, 0.0972, 0.0184], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:42,131][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.3316, 0.0192, 0.0251, 0.0359, 0.0416, 0.0548, 0.0573, 0.0667, 0.2556,
        0.0493, 0.0195, 0.0434], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:42,132][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.2253, 0.0824, 0.0466, 0.0639, 0.0658, 0.0554, 0.0725, 0.0721, 0.0930,
        0.0619, 0.0790, 0.0820], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:42,134][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0255, 0.0882, 0.0767, 0.0958, 0.0972, 0.0874, 0.0863, 0.0919, 0.1117,
        0.0784, 0.0768, 0.0841], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:42,135][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0239, 0.0988, 0.1203, 0.0958, 0.0872, 0.1070, 0.0778, 0.1026, 0.0833,
        0.0891, 0.0615, 0.0528], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:42,136][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0459, 0.0704, 0.0969, 0.0955, 0.0974, 0.0829, 0.0882, 0.0867, 0.0899,
        0.0830, 0.0827, 0.0804], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:42,138][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0247, 0.1740, 0.1032, 0.1061, 0.0695, 0.0651, 0.0882, 0.0953, 0.0842,
        0.0677, 0.0469, 0.0750], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:42,139][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.1336, 0.0458, 0.0268, 0.0370, 0.0533, 0.0622, 0.0382, 0.0619, 0.1137,
        0.1369, 0.1570, 0.1338], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:42,141][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.2595, 0.0128, 0.0031, 0.0071, 0.0075, 0.0122, 0.0133, 0.0291, 0.1676,
        0.0823, 0.2598, 0.1457], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:42,142][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0017, 0.0196, 0.0342, 0.1184, 0.0581, 0.0581, 0.0562, 0.0873, 0.1420,
        0.1431, 0.1561, 0.1253], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:42,144][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0113, 0.1014, 0.0647, 0.0829, 0.0578, 0.0750, 0.0941, 0.0813, 0.1260,
        0.1000, 0.0943, 0.1113], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:42,145][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.1136, 0.0167, 0.0122, 0.0178, 0.0358, 0.0196, 0.0164, 0.0367, 0.1767,
        0.2431, 0.1933, 0.1180], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:42,147][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ hospital] are: tensor([0.1405, 0.1489, 0.0100, 0.1082, 0.0194, 0.1886, 0.0533, 0.0404, 0.0358,
        0.0424, 0.1320, 0.0353, 0.0454], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:42,148][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ hospital] are: tensor([0.0974, 0.0204, 0.0236, 0.0540, 0.0362, 0.0464, 0.1250, 0.0598, 0.3289,
        0.0596, 0.0558, 0.0517, 0.0411], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:42,150][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ hospital] are: tensor([0.2203, 0.0841, 0.0472, 0.0589, 0.0571, 0.0495, 0.0630, 0.0649, 0.0806,
        0.0565, 0.0716, 0.0736, 0.0728], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:42,151][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ hospital] are: tensor([0.0192, 0.0852, 0.0764, 0.0881, 0.0815, 0.0686, 0.0866, 0.0874, 0.1072,
        0.0730, 0.0749, 0.0811, 0.0708], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:42,152][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ hospital] are: tensor([0.0163, 0.0809, 0.0888, 0.0949, 0.0705, 0.0943, 0.0699, 0.0966, 0.0849,
        0.0744, 0.0617, 0.0503, 0.1165], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:42,154][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ hospital] are: tensor([0.0433, 0.0668, 0.0892, 0.0879, 0.0891, 0.0762, 0.0810, 0.0791, 0.0827,
        0.0764, 0.0767, 0.0740, 0.0777], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:42,155][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ hospital] are: tensor([0.0216, 0.1549, 0.0907, 0.1198, 0.0794, 0.0591, 0.0711, 0.0968, 0.0881,
        0.0710, 0.0609, 0.0461, 0.0405], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:42,157][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ hospital] are: tensor([0.1831, 0.0340, 0.0203, 0.0223, 0.0340, 0.0354, 0.0254, 0.0486, 0.0740,
        0.0774, 0.0918, 0.0958, 0.2577], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:42,158][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ hospital] are: tensor([0.3764, 0.0096, 0.0021, 0.0036, 0.0039, 0.0078, 0.0093, 0.0165, 0.0743,
        0.0393, 0.1120, 0.1271, 0.2180], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:42,160][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ hospital] are: tensor([0.0003, 0.0097, 0.0254, 0.2100, 0.0484, 0.0626, 0.0983, 0.0364, 0.1738,
        0.0556, 0.1470, 0.1188, 0.0137], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:42,161][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ hospital] are: tensor([0.0097, 0.0927, 0.0602, 0.0765, 0.0522, 0.0714, 0.0884, 0.0773, 0.1170,
        0.0928, 0.0871, 0.1029, 0.0720], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:42,163][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ hospital] are: tensor([0.1136, 0.0156, 0.0089, 0.0111, 0.0188, 0.0126, 0.0117, 0.0200, 0.0896,
        0.0979, 0.0882, 0.0915, 0.4205], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:42,164][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.2979, 0.0737, 0.0150, 0.0535, 0.0154, 0.1566, 0.0461, 0.0303, 0.0209,
        0.0705, 0.0962, 0.0310, 0.0731, 0.0198], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:42,166][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.6472, 0.0087, 0.0150, 0.0109, 0.0296, 0.0263, 0.0314, 0.0418, 0.0584,
        0.0243, 0.0080, 0.0240, 0.0667, 0.0078], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:42,167][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.1944, 0.0713, 0.0422, 0.0552, 0.0561, 0.0491, 0.0623, 0.0634, 0.0795,
        0.0551, 0.0682, 0.0701, 0.0694, 0.0635], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:42,169][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0326, 0.0754, 0.0654, 0.0786, 0.0833, 0.0720, 0.0726, 0.0793, 0.0932,
        0.0639, 0.0654, 0.0734, 0.0690, 0.0759], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:42,170][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0183, 0.0727, 0.0942, 0.0826, 0.0745, 0.0839, 0.0708, 0.0716, 0.0804,
        0.0744, 0.0612, 0.0455, 0.0949, 0.0750], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:42,172][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.0370, 0.0594, 0.0819, 0.0809, 0.0832, 0.0713, 0.0756, 0.0739, 0.0776,
        0.0715, 0.0721, 0.0702, 0.0729, 0.0726], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:42,173][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0187, 0.1594, 0.1034, 0.1145, 0.0921, 0.0589, 0.0621, 0.0763, 0.0783,
        0.0636, 0.0565, 0.0365, 0.0255, 0.0541], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:42,175][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.1723, 0.0486, 0.0220, 0.0251, 0.0304, 0.0377, 0.0263, 0.0393, 0.0670,
        0.0647, 0.0676, 0.0753, 0.2188, 0.1052], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:42,176][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.3469, 0.0134, 0.0021, 0.0035, 0.0036, 0.0071, 0.0068, 0.0152, 0.0410,
        0.0385, 0.0674, 0.0692, 0.2487, 0.1367], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:42,177][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.0004, 0.0124, 0.0271, 0.0975, 0.0494, 0.0341, 0.0782, 0.0299, 0.1345,
        0.0878, 0.1542, 0.1349, 0.0401, 0.1194], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:42,177][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.0095, 0.0875, 0.0553, 0.0688, 0.0491, 0.0638, 0.0780, 0.0691, 0.1057,
        0.0857, 0.0800, 0.0963, 0.0674, 0.0840], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:42,178][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.1899, 0.0148, 0.0088, 0.0105, 0.0206, 0.0123, 0.0093, 0.0183, 0.0723,
        0.0687, 0.0625, 0.0509, 0.2808, 0.1803], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:42,178][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Anthony] are: tensor([0.1096, 0.1453, 0.0066, 0.1333, 0.0141, 0.1384, 0.0643, 0.0405, 0.0369,
        0.0547, 0.1135, 0.0410, 0.0450, 0.0453, 0.0115], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:42,179][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Anthony] are: tensor([0.0816, 0.0166, 0.0181, 0.0623, 0.0251, 0.0429, 0.0832, 0.0560, 0.3687,
        0.0250, 0.0363, 0.0470, 0.0409, 0.0576, 0.0387], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:42,179][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Anthony] are: tensor([0.1728, 0.0714, 0.0431, 0.0519, 0.0535, 0.0463, 0.0590, 0.0572, 0.0711,
        0.0512, 0.0644, 0.0671, 0.0666, 0.0606, 0.0638], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:42,179][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Anthony] are: tensor([0.0173, 0.0722, 0.0611, 0.0743, 0.0735, 0.0607, 0.0708, 0.0832, 0.0907,
        0.0656, 0.0564, 0.0675, 0.0669, 0.0751, 0.0647], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:42,181][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Anthony] are: tensor([0.0180, 0.0803, 0.0890, 0.0794, 0.0722, 0.0915, 0.0661, 0.0779, 0.0693,
        0.0738, 0.0447, 0.0384, 0.0821, 0.0656, 0.0516], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:42,182][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Anthony] are: tensor([0.0372, 0.0565, 0.0776, 0.0767, 0.0771, 0.0659, 0.0698, 0.0688, 0.0728,
        0.0667, 0.0674, 0.0655, 0.0682, 0.0672, 0.0626], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:42,184][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Anthony] are: tensor([0.0154, 0.1497, 0.1042, 0.0777, 0.0566, 0.0545, 0.0724, 0.0789, 0.1052,
        0.0558, 0.0475, 0.0582, 0.0203, 0.0465, 0.0571], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:42,185][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Anthony] are: tensor([0.1406, 0.0213, 0.0094, 0.0126, 0.0155, 0.0212, 0.0172, 0.0259, 0.0555,
        0.0463, 0.0485, 0.0617, 0.2133, 0.1043, 0.2066], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:42,186][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Anthony] are: tensor([0.4373, 0.0069, 0.0006, 0.0014, 0.0015, 0.0027, 0.0020, 0.0042, 0.0244,
        0.0175, 0.0382, 0.0375, 0.1794, 0.1348, 0.1118], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:42,187][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Anthony] are: tensor([0.0015, 0.0206, 0.0114, 0.0861, 0.0535, 0.0553, 0.0289, 0.0790, 0.0854,
        0.0742, 0.0863, 0.0935, 0.0621, 0.2027, 0.0593], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:42,189][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Anthony] are: tensor([0.0093, 0.0803, 0.0527, 0.0652, 0.0458, 0.0599, 0.0756, 0.0663, 0.1002,
        0.0795, 0.0770, 0.0922, 0.0649, 0.0791, 0.0518], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:42,190][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Anthony] are: tensor([0.1106, 0.0068, 0.0026, 0.0023, 0.0043, 0.0044, 0.0026, 0.0066, 0.0287,
        0.0312, 0.0323, 0.0258, 0.1865, 0.1752, 0.3801], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:42,192][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.1228, 0.1069, 0.0111, 0.0927, 0.0260, 0.0777, 0.0417, 0.0400, 0.0365,
        0.0574, 0.1277, 0.0380, 0.1050, 0.0412, 0.0220, 0.0534],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:42,193][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0777, 0.0381, 0.0397, 0.0454, 0.0365, 0.0224, 0.0726, 0.0633, 0.1565,
        0.0583, 0.0357, 0.0623, 0.0882, 0.0684, 0.0989, 0.0360],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:42,195][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.1719, 0.0611, 0.0380, 0.0481, 0.0489, 0.0432, 0.0547, 0.0536, 0.0690,
        0.0480, 0.0614, 0.0644, 0.0632, 0.0565, 0.0588, 0.0593],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:42,196][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.0176, 0.0676, 0.0622, 0.0679, 0.0713, 0.0580, 0.0700, 0.0690, 0.0921,
        0.0602, 0.0555, 0.0649, 0.0589, 0.0705, 0.0667, 0.0477],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:42,198][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.0165, 0.0689, 0.0901, 0.0719, 0.0692, 0.0847, 0.0594, 0.0840, 0.0622,
        0.0671, 0.0418, 0.0354, 0.0751, 0.0587, 0.0531, 0.0617],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:42,199][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.0349, 0.0523, 0.0722, 0.0715, 0.0731, 0.0622, 0.0658, 0.0648, 0.0690,
        0.0627, 0.0636, 0.0618, 0.0639, 0.0631, 0.0586, 0.0604],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:42,201][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0157, 0.1450, 0.0813, 0.0837, 0.0512, 0.0545, 0.0605, 0.0900, 0.0877,
        0.0680, 0.0489, 0.0478, 0.0166, 0.0403, 0.0443, 0.0645],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:42,202][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0550, 0.0171, 0.0103, 0.0147, 0.0192, 0.0187, 0.0166, 0.0278, 0.0482,
        0.0534, 0.0700, 0.0599, 0.1968, 0.0904, 0.1988, 0.1032],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:42,204][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.1418, 0.0073, 0.0011, 0.0026, 0.0023, 0.0056, 0.0051, 0.0116, 0.0391,
        0.0292, 0.0807, 0.0841, 0.2127, 0.1306, 0.1746, 0.0716],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:42,205][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.0007, 0.0137, 0.0252, 0.0551, 0.0511, 0.0258, 0.0579, 0.0342, 0.1631,
        0.0900, 0.1159, 0.0941, 0.0740, 0.1490, 0.0401, 0.0102],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:42,207][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0091, 0.0758, 0.0500, 0.0629, 0.0437, 0.0578, 0.0726, 0.0630, 0.0950,
        0.0761, 0.0724, 0.0859, 0.0617, 0.0743, 0.0481, 0.0517],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:42,208][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0484, 0.0058, 0.0042, 0.0041, 0.0081, 0.0054, 0.0041, 0.0096, 0.0395,
        0.0394, 0.0294, 0.0317, 0.1689, 0.1051, 0.3826, 0.1139],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:42,210][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.2004, 0.1036, 0.0086, 0.0881, 0.0177, 0.0654, 0.0154, 0.0321, 0.0328,
        0.0437, 0.1393, 0.0170, 0.0547, 0.0633, 0.0219, 0.0774, 0.0185],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:42,211][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.1209, 0.0271, 0.0187, 0.0325, 0.0300, 0.0233, 0.0258, 0.0821, 0.2153,
        0.0389, 0.0284, 0.0789, 0.1137, 0.0633, 0.0410, 0.0406, 0.0198],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:42,213][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.1539, 0.0582, 0.0351, 0.0469, 0.0469, 0.0416, 0.0521, 0.0522, 0.0658,
        0.0449, 0.0581, 0.0601, 0.0560, 0.0532, 0.0538, 0.0535, 0.0677],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:42,214][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0195, 0.0601, 0.0569, 0.0666, 0.0697, 0.0593, 0.0569, 0.0643, 0.0784,
        0.0574, 0.0555, 0.0612, 0.0640, 0.0637, 0.0631, 0.0544, 0.0491],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:42,216][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0165, 0.0646, 0.0856, 0.0676, 0.0591, 0.0739, 0.0503, 0.0676, 0.0568,
        0.0638, 0.0422, 0.0340, 0.0814, 0.0593, 0.0581, 0.0547, 0.0644],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:42,217][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0329, 0.0485, 0.0678, 0.0673, 0.0696, 0.0590, 0.0627, 0.0617, 0.0645,
        0.0592, 0.0594, 0.0579, 0.0608, 0.0599, 0.0558, 0.0579, 0.0553],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:42,219][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0174, 0.1208, 0.0678, 0.0802, 0.0448, 0.0512, 0.0926, 0.0662, 0.0806,
        0.0468, 0.0485, 0.0594, 0.0311, 0.0481, 0.0427, 0.0410, 0.0609],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:42,220][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0844, 0.0202, 0.0092, 0.0102, 0.0150, 0.0183, 0.0088, 0.0218, 0.0357,
        0.0487, 0.0429, 0.0365, 0.1652, 0.0749, 0.1956, 0.1540, 0.0587],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:42,222][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.2032, 0.0056, 0.0008, 0.0016, 0.0021, 0.0037, 0.0019, 0.0069, 0.0262,
        0.0146, 0.0379, 0.0357, 0.1714, 0.1451, 0.1323, 0.1315, 0.0796],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:42,223][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0007, 0.0123, 0.0193, 0.0835, 0.0413, 0.0342, 0.0266, 0.0780, 0.0979,
        0.1094, 0.1279, 0.0683, 0.0497, 0.1396, 0.0461, 0.0212, 0.0441],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:42,225][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0098, 0.0679, 0.0457, 0.0576, 0.0420, 0.0549, 0.0671, 0.0580, 0.0878,
        0.0704, 0.0683, 0.0785, 0.0570, 0.0680, 0.0448, 0.0483, 0.0739],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:42,226][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0376, 0.0039, 0.0026, 0.0022, 0.0063, 0.0032, 0.0017, 0.0050, 0.0227,
        0.0392, 0.0211, 0.0158, 0.1752, 0.0923, 0.3177, 0.2025, 0.0510],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:42,228][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ drink] are: tensor([0.0572, 0.1716, 0.0091, 0.1361, 0.0132, 0.1695, 0.0509, 0.0260, 0.0293,
        0.0293, 0.1066, 0.0243, 0.0294, 0.0322, 0.0094, 0.0589, 0.0338, 0.0132],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:42,229][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ drink] are: tensor([0.1123, 0.0139, 0.0294, 0.0387, 0.0499, 0.0332, 0.0600, 0.0585, 0.1909,
        0.0464, 0.0256, 0.0413, 0.0869, 0.0285, 0.0714, 0.0566, 0.0396, 0.0171],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:42,231][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ drink] are: tensor([0.1452, 0.0542, 0.0344, 0.0438, 0.0453, 0.0392, 0.0487, 0.0487, 0.0608,
        0.0439, 0.0542, 0.0582, 0.0583, 0.0518, 0.0520, 0.0534, 0.0643, 0.0438],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:42,232][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ drink] are: tensor([0.0153, 0.0613, 0.0524, 0.0619, 0.0602, 0.0520, 0.0593, 0.0617, 0.0710,
        0.0543, 0.0507, 0.0557, 0.0564, 0.0624, 0.0565, 0.0503, 0.0539, 0.0648],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:42,234][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ drink] are: tensor([0.0106, 0.0635, 0.0747, 0.0685, 0.0545, 0.0695, 0.0547, 0.0634, 0.0523,
        0.0600, 0.0353, 0.0322, 0.0805, 0.0535, 0.0412, 0.0418, 0.0694, 0.0746],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:42,235][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ drink] are: tensor([0.0309, 0.0464, 0.0642, 0.0635, 0.0650, 0.0554, 0.0591, 0.0580, 0.0611,
        0.0562, 0.0565, 0.0553, 0.0577, 0.0564, 0.0527, 0.0549, 0.0524, 0.0545],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:42,235][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ drink] are: tensor([0.0250, 0.1477, 0.0789, 0.0904, 0.0674, 0.0514, 0.0516, 0.0815, 0.0691,
        0.0645, 0.0427, 0.0345, 0.0228, 0.0430, 0.0364, 0.0438, 0.0305, 0.0187],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:42,236][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ drink] are: tensor([0.0347, 0.0172, 0.0073, 0.0116, 0.0118, 0.0143, 0.0120, 0.0177, 0.0490,
        0.0420, 0.0500, 0.0527, 0.1405, 0.0794, 0.1573, 0.1181, 0.0839, 0.1004],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:42,236][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ drink] are: tensor([0.1685, 0.0037, 0.0007, 0.0016, 0.0015, 0.0043, 0.0025, 0.0048, 0.0265,
        0.0140, 0.0285, 0.0441, 0.1674, 0.1394, 0.1571, 0.1038, 0.0911, 0.0404],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:42,237][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ drink] are: tensor([0.0006, 0.0072, 0.0137, 0.0325, 0.0317, 0.0264, 0.0790, 0.0405, 0.2582,
        0.0180, 0.0980, 0.0821, 0.0267, 0.1274, 0.0371, 0.0277, 0.0847, 0.0085],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:42,237][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ drink] are: tensor([0.0084, 0.0662, 0.0448, 0.0547, 0.0391, 0.0517, 0.0633, 0.0547, 0.0830,
        0.0661, 0.0637, 0.0743, 0.0538, 0.0659, 0.0430, 0.0458, 0.0724, 0.0490],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:42,238][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ drink] are: tensor([0.0210, 0.0048, 0.0022, 0.0025, 0.0035, 0.0037, 0.0040, 0.0074, 0.0234,
        0.0247, 0.0215, 0.0237, 0.1036, 0.1170, 0.2919, 0.1408, 0.0844, 0.1200],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:42,239][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.2428, 0.0832, 0.0118, 0.0661, 0.0173, 0.0757, 0.0345, 0.0330, 0.0171,
        0.0429, 0.0687, 0.0222, 0.0590, 0.0293, 0.0182, 0.0711, 0.0350, 0.0370,
        0.0349], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:42,240][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.4534, 0.0135, 0.0132, 0.0114, 0.0213, 0.0189, 0.0329, 0.0597, 0.0613,
        0.0380, 0.0067, 0.0384, 0.1058, 0.0139, 0.0295, 0.0277, 0.0320, 0.0161,
        0.0064], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:42,242][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1331, 0.0555, 0.0345, 0.0434, 0.0444, 0.0390, 0.0467, 0.0477, 0.0567,
        0.0410, 0.0501, 0.0515, 0.0510, 0.0476, 0.0497, 0.0501, 0.0589, 0.0433,
        0.0555], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:42,243][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0170, 0.0539, 0.0490, 0.0575, 0.0610, 0.0523, 0.0560, 0.0538, 0.0708,
        0.0504, 0.0510, 0.0557, 0.0539, 0.0569, 0.0530, 0.0449, 0.0480, 0.0589,
        0.0558], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:42,245][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0121, 0.0653, 0.0759, 0.0684, 0.0560, 0.0649, 0.0518, 0.0607, 0.0532,
        0.0547, 0.0339, 0.0308, 0.0612, 0.0479, 0.0424, 0.0413, 0.0589, 0.0615,
        0.0592], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:42,246][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0289, 0.0442, 0.0615, 0.0607, 0.0624, 0.0532, 0.0563, 0.0553, 0.0577,
        0.0534, 0.0534, 0.0518, 0.0542, 0.0539, 0.0501, 0.0520, 0.0493, 0.0511,
        0.0504], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:42,248][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0206, 0.1152, 0.0878, 0.1040, 0.0669, 0.0428, 0.0605, 0.0494, 0.0771,
        0.0480, 0.0489, 0.0402, 0.0204, 0.0450, 0.0458, 0.0336, 0.0357, 0.0171,
        0.0412], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:42,249][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0950, 0.0192, 0.0077, 0.0071, 0.0107, 0.0133, 0.0068, 0.0151, 0.0242,
        0.0294, 0.0254, 0.0266, 0.0894, 0.0453, 0.1279, 0.1390, 0.0464, 0.1455,
        0.1260], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:42,251][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.2208, 0.0047, 0.0006, 0.0007, 0.0011, 0.0029, 0.0013, 0.0044, 0.0102,
        0.0085, 0.0126, 0.0180, 0.1020, 0.0761, 0.1018, 0.1084, 0.0625, 0.0532,
        0.2101], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:42,252][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0009, 0.0107, 0.0324, 0.0497, 0.0344, 0.0361, 0.0583, 0.0521, 0.0874,
        0.1006, 0.0963, 0.0988, 0.0267, 0.0980, 0.0452, 0.0260, 0.0788, 0.0216,
        0.0460], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:42,254][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0087, 0.0622, 0.0401, 0.0504, 0.0365, 0.0482, 0.0591, 0.0506, 0.0772,
        0.0627, 0.0600, 0.0701, 0.0502, 0.0610, 0.0403, 0.0433, 0.0655, 0.0458,
        0.0680], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:42,255][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0444, 0.0032, 0.0018, 0.0010, 0.0040, 0.0024, 0.0017, 0.0041, 0.0108,
        0.0193, 0.0096, 0.0103, 0.0803, 0.0545, 0.1985, 0.1546, 0.0480, 0.1482,
        0.2033], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:42,299][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:21:42,301][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:42,302][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:42,303][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:42,304][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:42,304][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:42,305][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:42,305][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:42,305][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:42,305][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:42,306][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:42,306][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:42,306][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:42,307][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.9489, 0.0511], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:42,308][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.7936, 0.2064], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:42,310][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.2920, 0.7080], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:42,311][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.9266, 0.0734], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:42,312][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.9757, 0.0243], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:42,314][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.7755, 0.2245], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:42,315][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.1776, 0.8224], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:42,316][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.8357, 0.1643], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:42,318][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.9513, 0.0487], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:42,319][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0618, 0.9382], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:42,320][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.8975, 0.1025], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:42,322][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.8246, 0.1754], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:42,323][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Anthony] are: tensor([0.8603, 0.0747, 0.0649], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:42,325][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Anthony] are: tensor([0.7167, 0.1282, 0.1551], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:42,326][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Anthony] are: tensor([0.4169, 0.3672, 0.2159], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:42,327][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Anthony] are: tensor([0.9767, 0.0116, 0.0116], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:42,329][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Anthony] are: tensor([0.9228, 0.0330, 0.0442], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:42,330][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Anthony] are: tensor([0.4072, 0.1665, 0.4264], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:42,331][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Anthony] are: tensor([0.1847, 0.2372, 0.5782], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:42,333][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Anthony] are: tensor([0.6497, 0.1544, 0.1958], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:42,334][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Anthony] are: tensor([0.9148, 0.0575, 0.0278], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:42,335][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Anthony] are: tensor([0.0811, 0.6170, 0.3019], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:42,337][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Anthony] are: tensor([0.5275, 0.2769, 0.1955], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:42,338][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Anthony] are: tensor([0.6186, 0.2132, 0.1682], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:42,339][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.8522, 0.0542, 0.0452, 0.0484], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:42,341][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.2237, 0.1470, 0.1383, 0.4910], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:42,342][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.3930, 0.1963, 0.1653, 0.2454], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:42,343][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.9561, 0.0188, 0.0129, 0.0122], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:42,345][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.9237, 0.0277, 0.0311, 0.0174], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:42,346][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.3018, 0.0717, 0.4772, 0.1493], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:42,347][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.2000, 0.1978, 0.3407, 0.2615], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:42,349][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.5993, 0.1130, 0.1765, 0.1112], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:42,350][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.7295, 0.0548, 0.0275, 0.1882], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:42,352][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0417, 0.1705, 0.3930, 0.3948], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:42,353][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.7239, 0.1510, 0.0524, 0.0727], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:42,354][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.6263, 0.1069, 0.0768, 0.1900], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:42,356][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Travis] are: tensor([0.7377, 0.0449, 0.0414, 0.0724, 0.1037], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:42,357][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Travis] are: tensor([0.4313, 0.0481, 0.0632, 0.2312, 0.2262], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:42,358][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Travis] are: tensor([0.1925, 0.1737, 0.1429, 0.2728, 0.2180], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:42,360][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Travis] are: tensor([0.9530, 0.0110, 0.0090, 0.0097, 0.0173], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:42,361][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Travis] are: tensor([0.9397, 0.0165, 0.0169, 0.0124, 0.0144], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:42,363][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Travis] are: tensor([0.1902, 0.0500, 0.2059, 0.3555, 0.1983], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:42,363][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Travis] are: tensor([0.5006, 0.0854, 0.1249, 0.0348, 0.2544], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:42,363][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Travis] are: tensor([0.4105, 0.1374, 0.1508, 0.1435, 0.1578], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:42,364][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Travis] are: tensor([0.5222, 0.0620, 0.0359, 0.2891, 0.0908], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:42,364][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Travis] are: tensor([0.0553, 0.1497, 0.2852, 0.3537, 0.1561], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:42,364][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Travis] are: tensor([0.5335, 0.0912, 0.1133, 0.1472, 0.1148], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:42,365][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Travis] are: tensor([0.3317, 0.0845, 0.1036, 0.2472, 0.2330], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:42,365][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.5642, 0.0710, 0.0496, 0.0671, 0.1875, 0.0607], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:42,366][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.0729, 0.0637, 0.0401, 0.3080, 0.3182, 0.1971], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:42,366][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.3352, 0.1390, 0.0798, 0.1444, 0.1414, 0.1603], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:42,367][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.6172, 0.0350, 0.0297, 0.0536, 0.0515, 0.2130], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:42,369][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.6926, 0.0370, 0.0456, 0.0388, 0.0352, 0.1507], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:42,370][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.0536, 0.0262, 0.2061, 0.2094, 0.3669, 0.1379], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:42,371][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.1605, 0.3618, 0.2348, 0.0505, 0.0588, 0.1335], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:42,373][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.3344, 0.1204, 0.1410, 0.1091, 0.1557, 0.1395], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:42,374][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.4293, 0.0568, 0.0168, 0.2252, 0.0533, 0.2186], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:42,376][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.0014, 0.1659, 0.0918, 0.3975, 0.2088, 0.1346], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:42,377][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.7732, 0.0202, 0.0149, 0.0405, 0.0194, 0.1318], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:42,378][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.2872, 0.0760, 0.0815, 0.1295, 0.2852, 0.1406], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:42,380][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.7008, 0.0247, 0.0248, 0.0299, 0.1137, 0.0618, 0.0442],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:42,381][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.2923, 0.0376, 0.0395, 0.1273, 0.2328, 0.1296, 0.1410],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:42,383][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.3702, 0.1165, 0.0685, 0.1165, 0.1228, 0.1346, 0.0709],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:42,384][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.8334, 0.0091, 0.0106, 0.0112, 0.0209, 0.0695, 0.0454],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:42,386][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.5081, 0.0337, 0.0459, 0.0441, 0.0340, 0.1858, 0.1484],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:42,387][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0606, 0.0250, 0.1903, 0.1004, 0.4669, 0.1049, 0.0519],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:42,388][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.1886, 0.1025, 0.1371, 0.0392, 0.0155, 0.0272, 0.4899],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:42,390][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.3312, 0.0894, 0.1255, 0.0896, 0.1280, 0.1233, 0.1130],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:42,391][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.6117, 0.0119, 0.0037, 0.0569, 0.0174, 0.2164, 0.0821],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:42,392][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0140, 0.1030, 0.1041, 0.3162, 0.2144, 0.1519, 0.0964],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:42,394][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.2388, 0.0377, 0.0426, 0.0534, 0.0410, 0.5516, 0.0348],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:42,395][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.2977, 0.0561, 0.0488, 0.1312, 0.2158, 0.1622, 0.0882],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:42,396][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ lot] are: tensor([0.3585, 0.0432, 0.0530, 0.0580, 0.1677, 0.0658, 0.0954, 0.1584],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:42,398][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ lot] are: tensor([0.2183, 0.0571, 0.0587, 0.1083, 0.1607, 0.1249, 0.1630, 0.1090],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:42,399][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ lot] are: tensor([0.2747, 0.1530, 0.0760, 0.1004, 0.1032, 0.0890, 0.0555, 0.1481],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:42,400][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ lot] are: tensor([0.5277, 0.0287, 0.0248, 0.0263, 0.0372, 0.0991, 0.1101, 0.1461],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:42,402][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ lot] are: tensor([0.5479, 0.0360, 0.0587, 0.0319, 0.0366, 0.1016, 0.1058, 0.0815],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:42,403][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ lot] are: tensor([0.0898, 0.0520, 0.1354, 0.1601, 0.2669, 0.1217, 0.0661, 0.1080],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:42,405][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ lot] are: tensor([0.2107, 0.0924, 0.0440, 0.0232, 0.0134, 0.0124, 0.0326, 0.5715],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:42,406][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ lot] are: tensor([0.2821, 0.0828, 0.0957, 0.0922, 0.1071, 0.1091, 0.1320, 0.0990],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:42,408][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ lot] are: tensor([0.2874, 0.0385, 0.0170, 0.0734, 0.0344, 0.1437, 0.3399, 0.0657],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:42,409][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ lot] are: tensor([0.0038, 0.0945, 0.0511, 0.2170, 0.1120, 0.1060, 0.3770, 0.0385],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:42,411][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ lot] are: tensor([0.0564, 0.0676, 0.0156, 0.0432, 0.0327, 0.6843, 0.0172, 0.0831],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:42,412][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ lot] are: tensor([0.2038, 0.0613, 0.0791, 0.0915, 0.1583, 0.1505, 0.1378, 0.1177],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:42,413][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([0.5586, 0.0253, 0.0177, 0.0184, 0.0630, 0.0276, 0.0310, 0.0963, 0.1621],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:42,415][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([0.1450, 0.0344, 0.0268, 0.0698, 0.1122, 0.0866, 0.1164, 0.1461, 0.2627],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:42,416][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([0.1431, 0.0960, 0.0798, 0.1159, 0.0894, 0.0937, 0.0577, 0.1596, 0.1648],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:42,418][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([0.8964, 0.0046, 0.0040, 0.0026, 0.0066, 0.0212, 0.0126, 0.0207, 0.0314],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:42,419][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([0.5029, 0.0337, 0.0480, 0.0252, 0.0276, 0.0988, 0.0830, 0.0585, 0.1224],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:42,421][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([0.0709, 0.0157, 0.1741, 0.0806, 0.2767, 0.1189, 0.0373, 0.0846, 0.1411],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:42,422][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([0.0157, 0.0145, 0.0497, 0.0119, 0.0074, 0.0016, 0.0192, 0.0064, 0.8736],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:42,423][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([0.3129, 0.0667, 0.0851, 0.0647, 0.0989, 0.1005, 0.0975, 0.0706, 0.1030],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:42,425][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([0.4403, 0.0101, 0.0018, 0.0110, 0.0052, 0.0431, 0.0564, 0.0683, 0.3638],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:42,426][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([0.0032, 0.0280, 0.0579, 0.1458, 0.0890, 0.0952, 0.1549, 0.1302, 0.2959],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:42,426][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([0.1816, 0.0132, 0.0454, 0.0389, 0.0594, 0.1989, 0.0572, 0.3851, 0.0204],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:42,427][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([0.2868, 0.0480, 0.0371, 0.0435, 0.0925, 0.0498, 0.0484, 0.0824, 0.3114],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:42,427][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ fun] are: tensor([0.3121, 0.0189, 0.0210, 0.0262, 0.0579, 0.0450, 0.0317, 0.1063, 0.2321,
        0.1490], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:42,427][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ fun] are: tensor([0.1482, 0.0228, 0.0208, 0.0394, 0.0635, 0.0486, 0.0982, 0.1102, 0.2434,
        0.2049], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:42,428][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ fun] are: tensor([0.1045, 0.1183, 0.0820, 0.1119, 0.1108, 0.0816, 0.0501, 0.1056, 0.1329,
        0.1023], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:42,428][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ fun] are: tensor([0.5689, 0.0168, 0.0124, 0.0136, 0.0210, 0.0557, 0.0517, 0.0917, 0.1264,
        0.0420], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:42,429][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ fun] are: tensor([0.3273, 0.0260, 0.0431, 0.0346, 0.0327, 0.0892, 0.1334, 0.0781, 0.1751,
        0.0605], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:42,429][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ fun] are: tensor([0.0529, 0.0305, 0.0872, 0.0992, 0.2409, 0.0436, 0.0375, 0.0940, 0.2242,
        0.0900], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:42,431][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ fun] are: tensor([0.1257, 0.0616, 0.0230, 0.0143, 0.0283, 0.0144, 0.0180, 0.0945, 0.0722,
        0.5478], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:42,432][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ fun] are: tensor([0.2234, 0.0640, 0.0839, 0.0639, 0.0927, 0.0950, 0.0882, 0.0822, 0.1132,
        0.0935], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:42,434][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ fun] are: tensor([0.2458, 0.0062, 0.0016, 0.0114, 0.0037, 0.0432, 0.0426, 0.0371, 0.5342,
        0.0741], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:42,435][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ fun] are: tensor([0.0027, 0.0425, 0.0393, 0.1104, 0.0982, 0.0783, 0.2004, 0.0641, 0.2835,
        0.0806], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:42,436][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ fun] are: tensor([0.0338, 0.0712, 0.0543, 0.1184, 0.0205, 0.4533, 0.0271, 0.1291, 0.0675,
        0.0248], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:42,437][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ fun] are: tensor([0.1114, 0.0242, 0.0209, 0.0339, 0.0431, 0.0383, 0.0405, 0.0687, 0.3853,
        0.2338], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:42,439][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.4532, 0.0201, 0.0133, 0.0137, 0.0400, 0.0242, 0.0189, 0.0756, 0.1346,
        0.1482, 0.0581], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:42,440][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.1340, 0.0222, 0.0156, 0.0435, 0.0788, 0.0430, 0.0449, 0.0867, 0.1977,
        0.2652, 0.0685], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:42,442][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.2051, 0.0670, 0.0519, 0.0658, 0.0699, 0.0690, 0.0387, 0.0753, 0.1169,
        0.1095, 0.1309], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:42,443][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.7151, 0.0082, 0.0089, 0.0059, 0.0122, 0.0422, 0.0275, 0.0373, 0.0589,
        0.0304, 0.0533], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:42,445][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.3216, 0.0304, 0.0538, 0.0324, 0.0413, 0.1041, 0.0896, 0.0681, 0.1474,
        0.0528, 0.0584], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:42,446][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.0705, 0.0208, 0.0957, 0.0800, 0.1532, 0.0961, 0.0236, 0.1359, 0.0928,
        0.1296, 0.1019], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:42,448][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.0040, 0.0386, 0.0228, 0.0199, 0.0076, 0.0033, 0.0112, 0.0361, 0.1209,
        0.0290, 0.7066], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:42,449][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.1707, 0.0617, 0.0816, 0.0674, 0.0963, 0.0859, 0.0898, 0.0649, 0.1040,
        0.1013, 0.0764], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:42,451][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.1833, 0.0035, 0.0006, 0.0052, 0.0014, 0.0201, 0.0145, 0.0248, 0.2341,
        0.1014, 0.4111], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:42,452][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.0042, 0.0256, 0.0380, 0.1210, 0.0648, 0.1030, 0.0754, 0.0978, 0.1297,
        0.2012, 0.1393], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:42,453][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.0679, 0.0330, 0.0417, 0.0742, 0.0481, 0.2249, 0.0783, 0.1650, 0.0310,
        0.0703, 0.1657], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:42,455][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.1509, 0.0234, 0.0199, 0.0226, 0.0498, 0.0332, 0.0309, 0.0363, 0.2265,
        0.2565, 0.1500], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:42,456][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.4071, 0.0121, 0.0117, 0.0116, 0.0410, 0.0175, 0.0173, 0.0588, 0.1114,
        0.1308, 0.0951, 0.0856], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:42,458][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0740, 0.0179, 0.0182, 0.0472, 0.0736, 0.0437, 0.0546, 0.0445, 0.1471,
        0.2721, 0.0958, 0.1113], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:42,459][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.1490, 0.0628, 0.0432, 0.0739, 0.0630, 0.0726, 0.0421, 0.0886, 0.0953,
        0.0923, 0.1449, 0.0723], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:42,461][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.6306, 0.0049, 0.0052, 0.0051, 0.0090, 0.0425, 0.0196, 0.0396, 0.0550,
        0.0257, 0.0672, 0.0955], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:42,462][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.1374, 0.0224, 0.0419, 0.0312, 0.0283, 0.1319, 0.1122, 0.0551, 0.1810,
        0.0367, 0.0786, 0.1434], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:42,464][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.0520, 0.0145, 0.1084, 0.0480, 0.1543, 0.0669, 0.0240, 0.0765, 0.0763,
        0.0924, 0.1643, 0.1226], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:42,465][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0639, 0.0477, 0.0432, 0.0139, 0.0102, 0.0093, 0.0477, 0.0299, 0.1477,
        0.0512, 0.0721, 0.4630], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:42,467][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.2019, 0.0551, 0.0774, 0.0559, 0.0838, 0.0719, 0.0745, 0.0631, 0.0888,
        0.1005, 0.0706, 0.0565], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:42,467][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([1.2423e-01, 1.8490e-03, 3.3617e-04, 2.3729e-03, 1.0053e-03, 5.4283e-03,
        8.2409e-03, 1.1185e-02, 1.8339e-01, 6.0943e-02, 4.1463e-01, 1.8640e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:42,469][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0017, 0.0196, 0.0342, 0.1184, 0.0581, 0.0581, 0.0562, 0.0873, 0.1420,
        0.1431, 0.1561, 0.1253], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:42,470][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0342, 0.0188, 0.0298, 0.0373, 0.0526, 0.3213, 0.0433, 0.2135, 0.0305,
        0.0205, 0.1054, 0.0929], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:42,472][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.1136, 0.0167, 0.0122, 0.0178, 0.0358, 0.0196, 0.0164, 0.0367, 0.1767,
        0.2431, 0.1933, 0.1180], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:42,473][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ hospital] are: tensor([0.3233, 0.0114, 0.0083, 0.0085, 0.0176, 0.0151, 0.0125, 0.0344, 0.0733,
        0.0838, 0.0542, 0.0900, 0.2674], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:42,475][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ hospital] are: tensor([0.1248, 0.0091, 0.0091, 0.0183, 0.0287, 0.0333, 0.0288, 0.0265, 0.0832,
        0.1433, 0.0649, 0.0799, 0.3501], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:42,476][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ hospital] are: tensor([0.1050, 0.0881, 0.0572, 0.0743, 0.0795, 0.0671, 0.0324, 0.0738, 0.1116,
        0.0997, 0.0988, 0.0563, 0.0560], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:42,478][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ hospital] are: tensor([0.7675, 0.0031, 0.0026, 0.0025, 0.0037, 0.0198, 0.0093, 0.0169, 0.0199,
        0.0106, 0.0280, 0.0371, 0.0791], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:42,479][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ hospital] are: tensor([0.4300, 0.0281, 0.0376, 0.0220, 0.0283, 0.0616, 0.0748, 0.0508, 0.0833,
        0.0390, 0.0349, 0.0717, 0.0378], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:42,481][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ hospital] are: tensor([0.0361, 0.0193, 0.0869, 0.0891, 0.0575, 0.0580, 0.0275, 0.0777, 0.1668,
        0.0813, 0.1201, 0.1142, 0.0654], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:42,482][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ hospital] are: tensor([0.0630, 0.0339, 0.0237, 0.0110, 0.0172, 0.0056, 0.0162, 0.0346, 0.1140,
        0.0787, 0.1955, 0.0387, 0.3679], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:42,484][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ hospital] are: tensor([0.2435, 0.0430, 0.0560, 0.0450, 0.0631, 0.0556, 0.0664, 0.0595, 0.0849,
        0.0777, 0.0689, 0.0536, 0.0827], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:42,484][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ hospital] are: tensor([0.2970, 0.0028, 0.0003, 0.0013, 0.0007, 0.0041, 0.0074, 0.0081, 0.0803,
        0.0316, 0.1756, 0.2144, 0.1764], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:42,485][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ hospital] are: tensor([0.0003, 0.0097, 0.0254, 0.2100, 0.0484, 0.0626, 0.0983, 0.0364, 0.1738,
        0.0556, 0.1470, 0.1188, 0.0137], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:42,485][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ hospital] are: tensor([0.0194, 0.0278, 0.0248, 0.0560, 0.0132, 0.1983, 0.0722, 0.2995, 0.0483,
        0.0204, 0.0665, 0.1165, 0.0371], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:42,485][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ hospital] are: tensor([0.1136, 0.0156, 0.0089, 0.0111, 0.0188, 0.0126, 0.0117, 0.0200, 0.0896,
        0.0979, 0.0882, 0.0915, 0.4205], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:42,486][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.3768, 0.0110, 0.0072, 0.0073, 0.0227, 0.0100, 0.0114, 0.0316, 0.0516,
        0.0683, 0.0317, 0.0549, 0.2405, 0.0750], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:42,486][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.0779, 0.0088, 0.0053, 0.0108, 0.0189, 0.0192, 0.0179, 0.0194, 0.0455,
        0.0977, 0.0399, 0.0473, 0.3584, 0.2331], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:42,487][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.1062, 0.0592, 0.0430, 0.0620, 0.0673, 0.0615, 0.0265, 0.0843, 0.0884,
        0.0996, 0.1010, 0.0540, 0.0596, 0.0875], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:42,487][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.6473, 0.0043, 0.0030, 0.0039, 0.0049, 0.0348, 0.0182, 0.0252, 0.0315,
        0.0170, 0.0477, 0.0578, 0.0734, 0.0309], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:42,489][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.2552, 0.0313, 0.0337, 0.0249, 0.0205, 0.1284, 0.1101, 0.0482, 0.1194,
        0.0210, 0.0548, 0.1137, 0.0204, 0.0183], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:42,490][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.0336, 0.0087, 0.0769, 0.0423, 0.0988, 0.0718, 0.0337, 0.0505, 0.0597,
        0.0745, 0.1297, 0.1051, 0.1624, 0.0522], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:42,491][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.0089, 0.0183, 0.0285, 0.0150, 0.0137, 0.0027, 0.0128, 0.0197, 0.1714,
        0.0696, 0.3712, 0.0160, 0.0731, 0.1792], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:42,493][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.1746, 0.0474, 0.0592, 0.0438, 0.0725, 0.0669, 0.0662, 0.0517, 0.0744,
        0.0771, 0.0593, 0.0510, 0.0834, 0.0727], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:42,494][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.2093, 0.0038, 0.0003, 0.0014, 0.0006, 0.0037, 0.0049, 0.0063, 0.0349,
        0.0303, 0.0929, 0.0959, 0.1922, 0.3234], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:42,496][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.0004, 0.0124, 0.0271, 0.0975, 0.0494, 0.0341, 0.0782, 0.0299, 0.1345,
        0.0878, 0.1542, 0.1349, 0.0401, 0.1194], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:42,497][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.0600, 0.0105, 0.0186, 0.0452, 0.0444, 0.0865, 0.0430, 0.2062, 0.0269,
        0.0234, 0.1253, 0.1258, 0.1462, 0.0380], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:42,499][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.1899, 0.0148, 0.0088, 0.0105, 0.0206, 0.0123, 0.0093, 0.0183, 0.0723,
        0.0687, 0.0625, 0.0509, 0.2808, 0.1803], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:42,500][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Anthony] are: tensor([0.2307, 0.0062, 0.0031, 0.0025, 0.0070, 0.0037, 0.0040, 0.0153, 0.0404,
        0.0436, 0.0254, 0.0416, 0.1904, 0.0970, 0.2890], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:42,502][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Anthony] are: tensor([0.1091, 0.0031, 0.0016, 0.0029, 0.0040, 0.0062, 0.0068, 0.0149, 0.0223,
        0.0353, 0.0244, 0.0329, 0.3519, 0.1500, 0.2347], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:42,503][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Anthony] are: tensor([0.0889, 0.0641, 0.0382, 0.0561, 0.0580, 0.0544, 0.0215, 0.0625, 0.0933,
        0.0863, 0.0864, 0.0441, 0.0451, 0.0888, 0.1124], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:42,504][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Anthony] are: tensor([8.7865e-01, 1.4164e-03, 8.3993e-04, 6.6814e-04, 1.0419e-03, 5.6512e-03,
        2.4564e-03, 5.1825e-03, 7.1743e-03, 2.9101e-03, 1.0292e-02, 1.1308e-02,
        3.2238e-02, 1.2868e-02, 2.7299e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:42,506][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Anthony] are: tensor([0.5519, 0.0219, 0.0234, 0.0140, 0.0164, 0.0512, 0.0550, 0.0399, 0.0601,
        0.0256, 0.0223, 0.0499, 0.0255, 0.0085, 0.0344], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:42,507][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Anthony] are: tensor([0.0606, 0.0107, 0.0390, 0.0525, 0.0626, 0.0488, 0.0131, 0.1424, 0.0597,
        0.0921, 0.0516, 0.0636, 0.0813, 0.0560, 0.1660], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:42,509][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Anthony] are: tensor([0.0343, 0.0196, 0.0492, 0.0081, 0.0075, 0.0082, 0.0401, 0.0254, 0.3670,
        0.0328, 0.1024, 0.1099, 0.0296, 0.0606, 0.1054], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:42,510][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Anthony] are: tensor([0.2004, 0.0406, 0.0484, 0.0425, 0.0560, 0.0557, 0.0548, 0.0496, 0.0708,
        0.0705, 0.0537, 0.0455, 0.0750, 0.0714, 0.0651], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:42,511][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Anthony] are: tensor([2.9874e-01, 2.2615e-03, 6.9047e-05, 3.7542e-04, 2.0821e-04, 1.0008e-03,
        9.5496e-04, 1.2278e-03, 1.8605e-02, 1.1105e-02, 4.5397e-02, 4.3199e-02,
        1.5050e-01, 3.4835e-01, 7.8003e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:42,513][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Anthony] are: tensor([0.0015, 0.0206, 0.0114, 0.0861, 0.0535, 0.0553, 0.0289, 0.0790, 0.0854,
        0.0742, 0.0863, 0.0935, 0.0621, 0.2027, 0.0593], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:42,514][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Anthony] are: tensor([0.0484, 0.0432, 0.0469, 0.0452, 0.0335, 0.1009, 0.0339, 0.1356, 0.0682,
        0.0619, 0.0904, 0.0861, 0.0816, 0.0752, 0.0491], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:42,516][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Anthony] are: tensor([0.1106, 0.0068, 0.0026, 0.0023, 0.0043, 0.0044, 0.0026, 0.0066, 0.0287,
        0.0312, 0.0323, 0.0258, 0.1865, 0.1752, 0.3801], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:42,517][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.0843, 0.0058, 0.0031, 0.0038, 0.0109, 0.0051, 0.0047, 0.0180, 0.0416,
        0.0386, 0.0227, 0.0404, 0.2546, 0.0824, 0.2764, 0.1077],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:42,518][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0206, 0.0033, 0.0015, 0.0041, 0.0053, 0.0046, 0.0104, 0.0173, 0.0376,
        0.0762, 0.0309, 0.0467, 0.2279, 0.2418, 0.1921, 0.0798],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:42,520][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.1133, 0.0543, 0.0411, 0.0539, 0.0546, 0.0480, 0.0300, 0.0660, 0.0730,
        0.0785, 0.0793, 0.0449, 0.0473, 0.0728, 0.1008, 0.0420],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:42,522][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.2579, 0.0039, 0.0033, 0.0029, 0.0044, 0.0131, 0.0119, 0.0211, 0.0438,
        0.0226, 0.0669, 0.0864, 0.1930, 0.0449, 0.1200, 0.1039],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:42,523][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.1815, 0.0285, 0.0378, 0.0251, 0.0252, 0.0971, 0.1129, 0.0518, 0.1055,
        0.0312, 0.0531, 0.1256, 0.0341, 0.0178, 0.0453, 0.0275],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:42,525][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.0248, 0.0092, 0.0481, 0.0503, 0.0523, 0.0280, 0.0156, 0.0688, 0.0627,
        0.0629, 0.0946, 0.0702, 0.1071, 0.0627, 0.2132, 0.0295],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:42,526][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.0224, 0.0372, 0.0258, 0.0110, 0.0070, 0.0078, 0.0230, 0.0403, 0.2129,
        0.0967, 0.1393, 0.1146, 0.0242, 0.0694, 0.0616, 0.1067],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:42,528][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.1800, 0.0404, 0.0535, 0.0380, 0.0552, 0.0506, 0.0501, 0.0471, 0.0622,
        0.0669, 0.0527, 0.0456, 0.0788, 0.0614, 0.0669, 0.0505],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:42,529][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([6.7334e-02, 1.5650e-03, 1.2215e-04, 8.0820e-04, 3.0231e-04, 2.4095e-03,
        2.8093e-03, 4.4143e-03, 3.1618e-02, 1.9671e-02, 1.1011e-01, 1.2259e-01,
        1.7403e-01, 2.8381e-01, 1.3956e-01, 3.8848e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:42,530][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.0007, 0.0137, 0.0252, 0.0551, 0.0511, 0.0258, 0.0579, 0.0342, 0.1631,
        0.0900, 0.1159, 0.0941, 0.0740, 0.1490, 0.0401, 0.0102],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:42,532][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0636, 0.0158, 0.0202, 0.0336, 0.0200, 0.1071, 0.0369, 0.1176, 0.0258,
        0.0316, 0.0788, 0.0733, 0.1111, 0.0400, 0.0334, 0.1911],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:42,533][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.0484, 0.0058, 0.0042, 0.0041, 0.0081, 0.0054, 0.0041, 0.0096, 0.0395,
        0.0394, 0.0294, 0.0317, 0.1689, 0.1051, 0.3826, 0.1139],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:42,534][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.1505, 0.0041, 0.0028, 0.0022, 0.0099, 0.0041, 0.0027, 0.0149, 0.0182,
        0.0395, 0.0169, 0.0203, 0.2012, 0.0654, 0.2576, 0.1351, 0.0547],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:42,536][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0631, 0.0025, 0.0016, 0.0025, 0.0082, 0.0032, 0.0034, 0.0220, 0.0223,
        0.0665, 0.0156, 0.0201, 0.2918, 0.1384, 0.2153, 0.0640, 0.0595],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:42,537][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.1159, 0.0468, 0.0414, 0.0503, 0.0495, 0.0481, 0.0280, 0.0624, 0.0669,
        0.0680, 0.0834, 0.0459, 0.0547, 0.0715, 0.0929, 0.0430, 0.0314],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:42,539][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.4524, 0.0019, 0.0021, 0.0014, 0.0029, 0.0088, 0.0055, 0.0116, 0.0227,
        0.0123, 0.0298, 0.0438, 0.1154, 0.0337, 0.0671, 0.1183, 0.0701],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:42,540][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0658, 0.0193, 0.0310, 0.0252, 0.0210, 0.1320, 0.1043, 0.0397, 0.1400,
        0.0220, 0.0748, 0.1519, 0.0241, 0.0219, 0.0361, 0.0322, 0.0586],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:42,542][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0212, 0.0066, 0.0505, 0.0208, 0.1040, 0.0249, 0.0100, 0.0356, 0.0286,
        0.0612, 0.0825, 0.0541, 0.1192, 0.0459, 0.2670, 0.0363, 0.0318],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:42,543][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0339, 0.0153, 0.0141, 0.0052, 0.0021, 0.0042, 0.1048, 0.0095, 0.1394,
        0.0162, 0.0754, 0.1375, 0.0914, 0.0636, 0.0405, 0.0129, 0.2340],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:42,543][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.1371, 0.0387, 0.0551, 0.0384, 0.0559, 0.0513, 0.0483, 0.0425, 0.0649,
        0.0683, 0.0511, 0.0425, 0.0776, 0.0623, 0.0662, 0.0520, 0.0477],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:42,544][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([9.0978e-02, 9.1615e-04, 7.2150e-05, 4.1520e-04, 2.3988e-04, 1.3738e-03,
        7.1904e-04, 2.0667e-03, 1.8749e-02, 7.5577e-03, 4.0238e-02, 3.6034e-02,
        1.1961e-01, 3.6154e-01, 8.8525e-02, 8.6240e-02, 1.4473e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:42,544][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0007, 0.0123, 0.0193, 0.0835, 0.0413, 0.0342, 0.0266, 0.0780, 0.0979,
        0.1094, 0.1279, 0.0683, 0.0497, 0.1396, 0.0461, 0.0212, 0.0441],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:42,544][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0430, 0.0137, 0.0220, 0.0219, 0.0182, 0.1824, 0.0231, 0.0910, 0.0182,
        0.0345, 0.1176, 0.0850, 0.1430, 0.0269, 0.0247, 0.1065, 0.0283],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:42,545][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0376, 0.0039, 0.0026, 0.0022, 0.0063, 0.0032, 0.0017, 0.0050, 0.0227,
        0.0392, 0.0211, 0.0158, 0.1752, 0.0923, 0.3177, 0.2025, 0.0510],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:42,545][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ drink] are: tensor([0.0597, 0.0032, 0.0028, 0.0024, 0.0068, 0.0039, 0.0058, 0.0125, 0.0274,
        0.0275, 0.0143, 0.0320, 0.1764, 0.0648, 0.3238, 0.0855, 0.0931, 0.0581],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:42,547][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ drink] are: tensor([0.0340, 0.0024, 0.0013, 0.0032, 0.0026, 0.0028, 0.0055, 0.0149, 0.0240,
        0.0334, 0.0200, 0.0231, 0.1595, 0.1023, 0.1809, 0.0799, 0.1091, 0.2010],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:42,548][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ drink] are: tensor([0.0626, 0.0585, 0.0483, 0.0634, 0.0617, 0.0566, 0.0255, 0.0710, 0.0711,
        0.0750, 0.0726, 0.0387, 0.0404, 0.0614, 0.1003, 0.0354, 0.0238, 0.0337],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:42,550][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ drink] are: tensor([0.3986, 0.0049, 0.0030, 0.0017, 0.0036, 0.0089, 0.0052, 0.0137, 0.0194,
        0.0091, 0.0270, 0.0309, 0.1165, 0.0447, 0.1011, 0.1207, 0.0630, 0.0281],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:42,551][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ drink] are: tensor([0.1561, 0.0265, 0.0427, 0.0226, 0.0263, 0.0696, 0.0957, 0.0650, 0.0953,
        0.0481, 0.0369, 0.0861, 0.0448, 0.0113, 0.0560, 0.0339, 0.0485, 0.0347],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:42,552][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ drink] are: tensor([0.0388, 0.0063, 0.0384, 0.0235, 0.0644, 0.0419, 0.0113, 0.0755, 0.0307,
        0.0350, 0.0726, 0.0534, 0.0695, 0.0597, 0.2195, 0.0512, 0.0399, 0.0686],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:42,554][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ drink] are: tensor([0.0937, 0.0135, 0.0137, 0.0067, 0.0149, 0.0055, 0.0121, 0.0332, 0.1240,
        0.1269, 0.1229, 0.0179, 0.1321, 0.0688, 0.0398, 0.0322, 0.0205, 0.1217],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:42,555][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ drink] are: tensor([0.1283, 0.0364, 0.0463, 0.0376, 0.0552, 0.0509, 0.0469, 0.0404, 0.0663,
        0.0624, 0.0526, 0.0409, 0.0733, 0.0651, 0.0613, 0.0488, 0.0459, 0.0414],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:42,556][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ drink] are: tensor([5.6622e-02, 7.0964e-04, 7.7963e-05, 5.0135e-04, 2.0395e-04, 1.8283e-03,
        1.1629e-03, 1.3191e-03, 1.9414e-02, 7.2006e-03, 2.6622e-02, 5.0221e-02,
        1.1994e-01, 3.2586e-01, 1.1947e-01, 6.7738e-02, 1.7218e-01, 2.8929e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:42,558][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ drink] are: tensor([0.0006, 0.0072, 0.0137, 0.0325, 0.0317, 0.0264, 0.0790, 0.0405, 0.2582,
        0.0180, 0.0980, 0.0821, 0.0267, 0.1274, 0.0371, 0.0277, 0.0847, 0.0085],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:42,559][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ drink] are: tensor([0.0260, 0.0173, 0.0213, 0.0460, 0.0213, 0.2283, 0.0314, 0.0895, 0.0196,
        0.0098, 0.0501, 0.0513, 0.0283, 0.0554, 0.0174, 0.0993, 0.0254, 0.1622],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:42,561][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ drink] are: tensor([0.0210, 0.0048, 0.0022, 0.0025, 0.0035, 0.0037, 0.0040, 0.0074, 0.0234,
        0.0247, 0.0215, 0.0237, 0.1036, 0.1170, 0.2919, 0.1408, 0.0844, 0.1200],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:42,562][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.1610, 0.0041, 0.0023, 0.0012, 0.0057, 0.0024, 0.0029, 0.0100, 0.0131,
        0.0256, 0.0099, 0.0167, 0.1602, 0.0473, 0.1902, 0.0968, 0.0567, 0.1082,
        0.0857], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:42,564][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0444, 0.0031, 0.0015, 0.0025, 0.0049, 0.0036, 0.0036, 0.0087, 0.0131,
        0.0355, 0.0096, 0.0159, 0.1607, 0.1049, 0.1282, 0.0520, 0.0728, 0.2409,
        0.0940], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:42,565][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1218, 0.0347, 0.0281, 0.0445, 0.0338, 0.0406, 0.0195, 0.0566, 0.0663,
        0.0683, 0.0841, 0.0421, 0.0371, 0.0680, 0.0718, 0.0384, 0.0261, 0.0356,
        0.0826], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:42,567][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.6580, 0.0020, 0.0012, 0.0007, 0.0016, 0.0053, 0.0033, 0.0047, 0.0095,
        0.0068, 0.0128, 0.0203, 0.0680, 0.0179, 0.0303, 0.0639, 0.0367, 0.0150,
        0.0418], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:42,568][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.1458, 0.0211, 0.0322, 0.0210, 0.0212, 0.0994, 0.0872, 0.0469, 0.1077,
        0.0266, 0.0567, 0.1114, 0.0295, 0.0168, 0.0397, 0.0366, 0.0479, 0.0143,
        0.0378], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:42,570][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0275, 0.0035, 0.0538, 0.0152, 0.0374, 0.0192, 0.0125, 0.0327, 0.0211,
        0.0539, 0.0499, 0.0403, 0.0689, 0.0297, 0.3211, 0.0521, 0.0486, 0.0663,
        0.0465], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:42,571][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0308, 0.0106, 0.0197, 0.0110, 0.0075, 0.0012, 0.0115, 0.0031, 0.1173,
        0.0174, 0.1776, 0.0230, 0.0435, 0.0619, 0.0522, 0.0052, 0.0174, 0.0417,
        0.3475], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:42,573][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.1261, 0.0337, 0.0500, 0.0341, 0.0586, 0.0483, 0.0495, 0.0393, 0.0590,
        0.0597, 0.0445, 0.0414, 0.0669, 0.0553, 0.0590, 0.0499, 0.0482, 0.0386,
        0.0379], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:42,574][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([1.1868e-01, 7.8362e-04, 5.0447e-05, 1.3309e-04, 9.0467e-05, 9.7270e-04,
        4.3363e-04, 1.0934e-03, 4.7828e-03, 3.5560e-03, 8.4209e-03, 1.3342e-02,
        6.2048e-02, 1.5395e-01, 6.4728e-02, 6.6512e-02, 1.0731e-01, 4.8148e-02,
        3.4496e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:42,575][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0009, 0.0107, 0.0324, 0.0497, 0.0344, 0.0361, 0.0583, 0.0521, 0.0874,
        0.1006, 0.0963, 0.0988, 0.0267, 0.0980, 0.0452, 0.0260, 0.0788, 0.0216,
        0.0460], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:42,577][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0408, 0.0221, 0.0209, 0.0254, 0.0126, 0.1748, 0.0133, 0.2220, 0.0097,
        0.0258, 0.0816, 0.0327, 0.0599, 0.0139, 0.0180, 0.0789, 0.0119, 0.0793,
        0.0566], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:42,579][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0444, 0.0032, 0.0018, 0.0010, 0.0040, 0.0024, 0.0017, 0.0041, 0.0108,
        0.0193, 0.0096, 0.0103, 0.0803, 0.0545, 0.1985, 0.1546, 0.0480, 0.1482,
        0.2033], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:42,580][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:21:42,582][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[5156],
        [  14],
        [  10],
        [   9],
        [ 306],
        [  24],
        [  13],
        [  54],
        [   9],
        [  70],
        [  34],
        [  15],
        [  14],
        [  13],
        [  70],
        [  18],
        [  16],
        [  15],
        [  11]], device='cuda:0')
[2024-07-24 10:21:42,584][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 6264],
        [  535],
        [ 2449],
        [  680],
        [15619],
        [ 1137],
        [  356],
        [  451],
        [  253],
        [ 2833],
        [ 1401],
        [ 1099],
        [  246],
        [   69],
        [ 1123],
        [  932],
        [  468],
        [  321],
        [  166]], device='cuda:0')
[2024-07-24 10:21:42,585][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[19505],
        [12071],
        [ 7022],
        [ 9887],
        [ 4685],
        [ 4258],
        [ 5006],
        [ 4272],
        [ 4517],
        [ 4342],
        [ 5252],
        [ 4728],
        [ 4340],
        [ 3922],
        [ 4112],
        [ 3461],
        [ 3998],
        [ 4056],
        [ 3371]], device='cuda:0')
[2024-07-24 10:21:42,587][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[6472],
        [5726],
        [3713],
        [4724],
        [2480],
        [3363],
        [3527],
        [5495],
        [2969],
        [1590],
        [1827],
        [1498],
        [1629],
        [3329],
        [1306],
        [2676],
        [2371],
        [2643],
        [4042]], device='cuda:0')
[2024-07-24 10:21:42,588][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[6230],
        [5929],
        [5904],
        [5731],
        [5708],
        [5944],
        [6039],
        [5949],
        [5648],
        [5611],
        [5564],
        [5515],
        [5548],
        [5559],
        [5542],
        [5655],
        [5611],
        [5696],
        [5657]], device='cuda:0')
[2024-07-24 10:21:42,590][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[7191],
        [8904],
        [8485],
        [6827],
        [8970],
        [8601],
        [7819],
        [7947],
        [7547],
        [7080],
        [6755],
        [6573],
        [6399],
        [6355],
        [6376],
        [6047],
        [5865],
        [6022],
        [5891]], device='cuda:0')
[2024-07-24 10:21:42,591][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[4704],
        [ 966],
        [  66],
        [ 101],
        [   2],
        [   6],
        [  17],
        [  21],
        [  43],
        [  37],
        [  46],
        [  57],
        [  85],
        [  80],
        [  54],
        [  61],
        [  96],
        [ 146],
        [ 156]], device='cuda:0')
[2024-07-24 10:21:42,593][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[25399],
        [18466],
        [16761],
        [15946],
        [15615],
        [16018],
        [16589],
        [16611],
        [16552],
        [16859],
        [17060],
        [17188],
        [17001],
        [17005],
        [16882],
        [16979],
        [17013],
        [17264],
        [17345]], device='cuda:0')
[2024-07-24 10:21:42,594][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[6950],
        [3843],
        [5631],
        [3943],
        [8956],
        [5154],
        [3880],
        [3394],
        [3560],
        [2400],
        [3244],
        [2847],
        [2902],
        [3356],
        [3038],
        [2854],
        [2796],
        [3141],
        [3494]], device='cuda:0')
[2024-07-24 10:21:42,596][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[14845],
        [23757],
        [28131],
        [28886],
        [33217],
        [29656],
        [27730],
        [23767],
        [19541],
        [19040],
        [18591],
        [18355],
        [20301],
        [21640],
        [21914],
        [20022],
        [18913],
        [19395],
        [19008]], device='cuda:0')
[2024-07-24 10:21:42,597][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[ 9110],
        [10032],
        [10417],
        [13527],
        [14282],
        [29846],
        [21436],
        [29771],
        [24752],
        [27937],
        [31302],
        [30606],
        [26323],
        [29138],
        [25312],
        [29547],
        [31601],
        [30592],
        [31052]], device='cuda:0')
[2024-07-24 10:21:42,599][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[22468],
        [32409],
        [38559],
        [42418],
        [48190],
        [48078],
        [47973],
        [42712],
        [42284],
        [39837],
        [32998],
        [33997],
        [35425],
        [34151],
        [36775],
        [34665],
        [34539],
        [35520],
        [34548]], device='cuda:0')
[2024-07-24 10:21:42,600][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[1199],
        [ 844],
        [ 855],
        [ 821],
        [ 800],
        [ 740],
        [ 690],
        [ 674],
        [ 678],
        [ 663],
        [ 647],
        [ 644],
        [ 643],
        [ 650],
        [ 654],
        [ 654],
        [ 652],
        [ 650],
        [ 651]], device='cuda:0')
[2024-07-24 10:21:42,602][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[47027],
        [47116],
        [47195],
        [47088],
        [45324],
        [47115],
        [47431],
        [47060],
        [46372],
        [45246],
        [44689],
        [44517],
        [45266],
        [46443],
        [46356],
        [46068],
        [45789],
        [44711],
        [43215]], device='cuda:0')
[2024-07-24 10:21:42,603][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[2083],
        [ 152],
        [ 205],
        [ 188],
        [ 972],
        [1297],
        [ 749],
        [2536],
        [ 354],
        [1149],
        [ 807],
        [ 474],
        [ 539],
        [ 998],
        [1282],
        [ 771],
        [1181],
        [ 267],
        [ 749]], device='cuda:0')
[2024-07-24 10:21:42,605][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[19081],
        [15846],
        [13650],
        [15464],
        [15015],
        [17440],
        [18756],
        [28963],
        [34366],
        [35981],
        [33546],
        [36882],
        [25370],
        [23990],
        [24434],
        [24971],
        [27084],
        [27396],
        [28365]], device='cuda:0')
[2024-07-24 10:21:42,606][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[27790],
        [35253],
        [26361],
        [24261],
        [21477],
        [17607],
        [20543],
        [22917],
        [21925],
        [18620],
        [18222],
        [18582],
        [18575],
        [21670],
        [29151],
        [24842],
        [25774],
        [30701],
        [32952]], device='cuda:0')
[2024-07-24 10:21:42,607][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[ 5699],
        [ 2713],
        [ 2566],
        [ 2971],
        [ 4164],
        [ 3992],
        [ 4222],
        [ 4543],
        [ 5296],
        [ 5932],
        [ 7476],
        [ 7550],
        [ 7339],
        [ 8518],
        [ 8828],
        [ 9259],
        [ 9965],
        [ 9558],
        [10970]], device='cuda:0')
[2024-07-24 10:21:42,608][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[ 5533],
        [10796],
        [ 5920],
        [ 6796],
        [ 7042],
        [13819],
        [12528],
        [21873],
        [11007],
        [23348],
        [21644],
        [22167],
        [18793],
        [20787],
        [11191],
        [20389],
        [19444],
        [19188],
        [17200]], device='cuda:0')
[2024-07-24 10:21:42,609][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[21117],
        [23995],
        [28913],
        [27283],
        [25613],
        [32832],
        [32898],
        [32937],
        [32094],
        [31779],
        [31900],
        [30958],
        [31927],
        [31514],
        [32640],
        [31917],
        [31437],
        [31948],
        [31621]], device='cuda:0')
[2024-07-24 10:21:42,611][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[ 5167],
        [ 5370],
        [12970],
        [12408],
        [11337],
        [16760],
        [17872],
        [16739],
        [17235],
        [13476],
        [13445],
        [13564],
        [12552],
        [13782],
        [11866],
        [11415],
        [11525],
        [10751],
        [ 9173]], device='cuda:0')
[2024-07-24 10:21:42,612][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[36835],
        [36107],
        [41157],
        [40197],
        [35188],
        [41620],
        [36096],
        [39614],
        [43901],
        [40488],
        [44653],
        [36930],
        [36713],
        [41176],
        [42336],
        [41156],
        [37424],
        [40208],
        [42991]], device='cuda:0')
[2024-07-24 10:21:42,614][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[ 1147],
        [ 2427],
        [ 7866],
        [ 6834],
        [ 9067],
        [10377],
        [10454],
        [10362],
        [ 9785],
        [10633],
        [10375],
        [10186],
        [ 9873],
        [10018],
        [10479],
        [10775],
        [11033],
        [11011],
        [11206]], device='cuda:0')
[2024-07-24 10:21:42,616][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[13929],
        [15237],
        [18098],
        [25656],
        [28414],
        [29715],
        [26718],
        [31581],
        [26171],
        [26328],
        [21929],
        [22710],
        [24658],
        [29097],
        [31269],
        [31652],
        [31273],
        [32300],
        [29139]], device='cuda:0')
[2024-07-24 10:21:42,617][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[34463],
        [27223],
        [30060],
        [37429],
        [36359],
        [37397],
        [38927],
        [40187],
        [36309],
        [35350],
        [36637],
        [36624],
        [37374],
        [36259],
        [37387],
        [35937],
        [36430],
        [34306],
        [35856]], device='cuda:0')
[2024-07-24 10:21:42,618][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[38591],
        [27253],
        [22540],
        [22590],
        [21491],
        [26217],
        [24219],
        [23305],
        [18173],
        [17888],
        [14129],
        [14753],
        [14116],
        [13234],
        [12401],
        [13402],
        [14430],
        [16452],
        [15189]], device='cuda:0')
[2024-07-24 10:21:42,619][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[13195],
        [13032],
        [16643],
        [11376],
        [17770],
        [20490],
        [20538],
        [23995],
        [14777],
        [11392],
        [11433],
        [10682],
        [12107],
        [ 9351],
        [17671],
        [18625],
        [17289],
        [16142],
        [13967]], device='cuda:0')
[2024-07-24 10:21:42,620][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[37752],
        [38394],
        [29673],
        [28048],
        [27137],
        [18115],
        [21785],
        [14429],
        [21564],
        [19554],
        [21755],
        [22905],
        [26017],
        [22613],
        [20943],
        [19250],
        [20051],
        [18608],
        [18088]], device='cuda:0')
[2024-07-24 10:21:42,621][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[46720],
        [47193],
        [49451],
        [48805],
        [48407],
        [43969],
        [39781],
        [47032],
        [43556],
        [47780],
        [39462],
        [44369],
        [48167],
        [46018],
        [46126],
        [46293],
        [41589],
        [48455],
        [44246]], device='cuda:0')
[2024-07-24 10:21:42,623][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[6250],
        [6250],
        [6250],
        [6250],
        [6250],
        [6250],
        [6250],
        [6250],
        [6250],
        [6250],
        [6250],
        [6250],
        [6250],
        [6250],
        [6250],
        [6250],
        [6250],
        [6250],
        [6250]], device='cuda:0')
[2024-07-24 10:21:42,670][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:21:42,670][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:42,670][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:42,671][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:42,671][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:42,672][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:42,672][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:42,673][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:42,673][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:42,673][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:42,674][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:42,674][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:42,674][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:42,675][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.6312, 0.3688], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:42,676][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.3481, 0.6519], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:42,677][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0117, 0.9883], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:42,678][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.2609, 0.7391], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:42,680][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.9790, 0.0210], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:42,681][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.5859, 0.4141], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:42,682][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.5266, 0.4734], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:42,684][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.2783, 0.7217], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:42,685][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.8337, 0.1663], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:42,686][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.1711, 0.8289], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:42,688][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0148, 0.9852], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:42,689][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.9678, 0.0322], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:42,691][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Anthony] are: tensor([0.2772, 0.2617, 0.4610], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:42,692][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Anthony] are: tensor([0.1626, 0.3525, 0.4850], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:42,693][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Anthony] are: tensor([0.0027, 0.4399, 0.5574], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:42,695][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Anthony] are: tensor([0.1199, 0.3972, 0.4829], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:42,696][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Anthony] are: tensor([0.8755, 0.0769, 0.0476], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:42,697][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Anthony] are: tensor([0.1787, 0.3934, 0.4280], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:42,699][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Anthony] are: tensor([0.3096, 0.3072, 0.3832], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:42,700][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Anthony] are: tensor([0.1225, 0.4776, 0.3999], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:42,702][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Anthony] are: tensor([0.4022, 0.1356, 0.4622], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:42,703][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Anthony] are: tensor([0.1061, 0.3417, 0.5521], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:42,704][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Anthony] are: tensor([0.0116, 0.5148, 0.4737], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:42,706][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Anthony] are: tensor([0.3590, 0.4966, 0.1444], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:42,707][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.1609, 0.0666, 0.1169, 0.6556], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:42,708][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.1660, 0.2848, 0.3265, 0.2227], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:42,710][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0037, 0.2662, 0.3548, 0.3753], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:42,711][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.1032, 0.2315, 0.2592, 0.4061], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:42,713][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.9751, 0.0098, 0.0066, 0.0085], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:42,714][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0914, 0.1854, 0.3770, 0.3462], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:42,715][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.2736, 0.2378, 0.2617, 0.2269], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:42,717][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.1190, 0.3253, 0.3337, 0.2220], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:42,718][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.7974, 0.0365, 0.1096, 0.0566], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:42,719][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0733, 0.2100, 0.3086, 0.4081], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:42,721][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0012, 0.0716, 0.2154, 0.7118], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:42,722][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.4973, 0.2493, 0.1354, 0.1180], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:42,723][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Travis] are: tensor([0.0468, 0.0272, 0.0517, 0.6063, 0.2680], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:42,725][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Travis] are: tensor([0.1247, 0.2545, 0.2014, 0.2130, 0.2064], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:42,726][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Travis] are: tensor([0.0012, 0.1906, 0.2532, 0.2801, 0.2748], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:42,728][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Travis] are: tensor([0.0942, 0.1697, 0.1772, 0.3049, 0.2540], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:42,729][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Travis] are: tensor([0.9115, 0.0178, 0.0109, 0.0217, 0.0381], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:42,729][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Travis] are: tensor([0.0841, 0.1504, 0.2677, 0.2585, 0.2394], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:42,729][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Travis] are: tensor([0.2150, 0.1783, 0.1976, 0.1707, 0.2384], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:42,730][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Travis] are: tensor([0.0768, 0.2596, 0.2033, 0.1990, 0.2614], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:42,730][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Travis] are: tensor([0.2878, 0.0667, 0.1361, 0.1504, 0.3590], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:42,731][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Travis] are: tensor([0.0440, 0.1489, 0.2204, 0.3059, 0.2808], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:42,731][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Travis] are: tensor([0.0033, 0.0433, 0.1769, 0.5693, 0.2072], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:42,731][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Travis] are: tensor([0.3165, 0.2022, 0.0489, 0.2885, 0.1438], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:42,732][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.0419, 0.0298, 0.0372, 0.2286, 0.2561, 0.4065], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:42,732][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.1477, 0.2054, 0.1960, 0.1654, 0.1735, 0.1118], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:42,733][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.0011, 0.1765, 0.1982, 0.2284, 0.2296, 0.1663], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:42,735][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.0475, 0.1191, 0.1385, 0.2173, 0.1931, 0.2845], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:42,736][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.9227, 0.0125, 0.0056, 0.0150, 0.0256, 0.0186], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:42,737][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.0680, 0.0958, 0.3602, 0.1828, 0.2232, 0.0700], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:42,739][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.1644, 0.1570, 0.1623, 0.1443, 0.2203, 0.1516], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:42,740][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.0664, 0.1851, 0.1738, 0.1313, 0.2436, 0.1998], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:42,741][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.4849, 0.0347, 0.0682, 0.0724, 0.1895, 0.1502], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:42,743][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.0419, 0.1304, 0.1809, 0.2621, 0.2293, 0.1554], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:42,744][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ had] are: tensor([1.2272e-04, 4.7487e-02, 7.0441e-02, 6.1238e-01, 1.3593e-01, 1.3364e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:42,745][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.8770, 0.0380, 0.0092, 0.0465, 0.0171, 0.0122], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:42,746][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0622, 0.0149, 0.0138, 0.1020, 0.1223, 0.5185, 0.1662],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:42,748][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0836, 0.1541, 0.2233, 0.1390, 0.1586, 0.1241, 0.1173],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:42,749][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0010, 0.1354, 0.1674, 0.1848, 0.1842, 0.1357, 0.1915],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:42,751][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0421, 0.0940, 0.1076, 0.1665, 0.1535, 0.2201, 0.2162],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:42,752][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.5680, 0.0531, 0.0262, 0.0843, 0.0723, 0.0809, 0.1151],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:42,754][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0578, 0.0749, 0.3632, 0.1946, 0.2099, 0.0603, 0.0393],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:42,755][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.1628, 0.1344, 0.1382, 0.1154, 0.1810, 0.1279, 0.1402],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:42,756][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0520, 0.1396, 0.1672, 0.1102, 0.2111, 0.1983, 0.1217],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:42,758][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.4944, 0.0296, 0.0588, 0.0536, 0.1682, 0.1256, 0.0698],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:42,759][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0359, 0.1019, 0.1477, 0.2117, 0.1835, 0.1346, 0.1847],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:42,760][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0005, 0.0288, 0.0428, 0.3050, 0.1156, 0.1235, 0.3838],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:42,762][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.1742, 0.2978, 0.0403, 0.4002, 0.0167, 0.0528, 0.0180],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:42,763][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ lot] are: tensor([0.0436, 0.0153, 0.0209, 0.0866, 0.0629, 0.3254, 0.3066, 0.1387],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:42,765][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ lot] are: tensor([0.1127, 0.1293, 0.1470, 0.1278, 0.1259, 0.0881, 0.1504, 0.1188],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:42,766][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ lot] are: tensor([0.0007, 0.1156, 0.1445, 0.1607, 0.1441, 0.1164, 0.1800, 0.1381],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:42,767][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ lot] are: tensor([0.0340, 0.0797, 0.0886, 0.1416, 0.1197, 0.1994, 0.1921, 0.1449],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:42,768][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ lot] are: tensor([0.8622, 0.0122, 0.0066, 0.0187, 0.0248, 0.0182, 0.0405, 0.0168],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:42,770][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ lot] are: tensor([0.0486, 0.0432, 0.3958, 0.1512, 0.2365, 0.0516, 0.0241, 0.0490],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:42,771][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ lot] are: tensor([0.1744, 0.1231, 0.1229, 0.1006, 0.1589, 0.1131, 0.1293, 0.0778],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:42,773][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ lot] are: tensor([0.0471, 0.1336, 0.1540, 0.1080, 0.2071, 0.1644, 0.1093, 0.0765],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:42,774][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ lot] are: tensor([0.3824, 0.0228, 0.0398, 0.0571, 0.1288, 0.1089, 0.1018, 0.1586],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:42,776][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ lot] are: tensor([0.0262, 0.0895, 0.1242, 0.1807, 0.1528, 0.1166, 0.1596, 0.1505],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:42,776][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ lot] are: tensor([8.8674e-05, 2.4140e-02, 2.2035e-02, 1.0908e-01, 2.7266e-02, 4.0613e-02,
        7.6498e-01, 1.1801e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:42,778][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ lot] are: tensor([0.2934, 0.1437, 0.0720, 0.2096, 0.1561, 0.0554, 0.0412, 0.0285],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:42,779][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ of] are: tensor([0.0384, 0.0076, 0.0047, 0.0177, 0.0299, 0.0780, 0.0448, 0.1165, 0.6624],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:42,781][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ of] are: tensor([0.0702, 0.1559, 0.1565, 0.1268, 0.1143, 0.0644, 0.1018, 0.0854, 0.1246],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:42,782][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ of] are: tensor([0.0007, 0.0888, 0.1184, 0.1343, 0.1284, 0.0897, 0.1395, 0.1324, 0.1680],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:42,784][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ of] are: tensor([0.0427, 0.0720, 0.0766, 0.1187, 0.1012, 0.1467, 0.1400, 0.1180, 0.1840],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:42,785][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ of] are: tensor([0.7982, 0.0109, 0.0056, 0.0151, 0.0193, 0.0248, 0.0408, 0.0166, 0.0689],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:42,787][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ of] are: tensor([0.0825, 0.0502, 0.3693, 0.1285, 0.2301, 0.0467, 0.0257, 0.0405, 0.0264],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:42,787][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ of] are: tensor([0.1218, 0.1207, 0.1121, 0.0942, 0.1427, 0.1023, 0.1138, 0.0736, 0.1189],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:42,788][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ of] are: tensor([0.0496, 0.1158, 0.1263, 0.0958, 0.1825, 0.1520, 0.1091, 0.0736, 0.0953],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:42,788][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ of] are: tensor([0.6039, 0.0108, 0.0237, 0.0222, 0.0738, 0.0499, 0.0441, 0.0833, 0.0882],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:42,788][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ of] are: tensor([0.0310, 0.0750, 0.1009, 0.1499, 0.1253, 0.0921, 0.1334, 0.1275, 0.1648],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:42,789][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ of] are: tensor([3.6157e-05, 1.3217e-02, 2.7878e-02, 1.4228e-01, 5.5016e-02, 4.9782e-02,
        5.1255e-01, 3.3326e-02, 1.6591e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:42,789][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ of] are: tensor([0.8831, 0.0153, 0.0211, 0.0115, 0.0236, 0.0113, 0.0166, 0.0074, 0.0101],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:42,789][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ fun] are: tensor([0.0049, 0.0015, 0.0023, 0.0087, 0.0066, 0.0448, 0.0271, 0.0423, 0.7466,
        0.1150], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:42,790][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ fun] are: tensor([0.0518, 0.1393, 0.1166, 0.0984, 0.1037, 0.0688, 0.0875, 0.0847, 0.1294,
        0.1197], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:42,790][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ fun] are: tensor([0.0003, 0.0925, 0.1075, 0.1198, 0.1014, 0.0873, 0.1309, 0.1100, 0.1355,
        0.1150], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:42,792][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ fun] are: tensor([0.0284, 0.0574, 0.0611, 0.0986, 0.0867, 0.1382, 0.1286, 0.1046, 0.1781,
        0.1182], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:42,793][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ fun] are: tensor([0.6968, 0.0131, 0.0063, 0.0216, 0.0248, 0.0188, 0.0424, 0.0229, 0.1229,
        0.0303], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:42,794][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ fun] are: tensor([0.0532, 0.0569, 0.3855, 0.1388, 0.1900, 0.0454, 0.0249, 0.0489, 0.0265,
        0.0299], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:42,796][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ fun] are: tensor([0.1253, 0.1016, 0.0992, 0.0821, 0.1266, 0.0867, 0.1012, 0.0628, 0.1085,
        0.1060], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:42,797][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ fun] are: tensor([0.0298, 0.1457, 0.1240, 0.0949, 0.1713, 0.1351, 0.1193, 0.0575, 0.0801,
        0.0424], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:42,798][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ fun] are: tensor([0.2114, 0.0247, 0.0450, 0.0616, 0.0987, 0.0769, 0.0810, 0.1207, 0.2131,
        0.0668], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:42,800][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ fun] are: tensor([0.0280, 0.0657, 0.0922, 0.1343, 0.1036, 0.0815, 0.1157, 0.1104, 0.1463,
        0.1223], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:42,801][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ fun] are: tensor([5.9515e-05, 1.3110e-02, 1.8416e-02, 9.2749e-02, 5.2201e-02, 3.5509e-02,
        6.0708e-01, 2.4534e-02, 1.4592e-01, 1.0421e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:42,802][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ fun] are: tensor([0.2134, 0.1053, 0.1208, 0.1421, 0.1002, 0.0620, 0.0667, 0.0252, 0.0900,
        0.0742], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:42,804][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.0168, 0.0025, 0.0023, 0.0059, 0.0123, 0.0439, 0.0177, 0.0625, 0.3879,
        0.2661, 0.1820], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:42,805][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.0564, 0.1238, 0.1238, 0.0929, 0.0903, 0.0715, 0.0750, 0.0736, 0.1107,
        0.0953, 0.0867], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:42,807][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.0002, 0.0783, 0.0953, 0.1048, 0.0915, 0.0733, 0.1146, 0.1062, 0.1335,
        0.1143, 0.0880], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:42,808][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.0397, 0.0536, 0.0584, 0.0922, 0.0791, 0.1124, 0.1134, 0.0936, 0.1415,
        0.0938, 0.1222], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:42,809][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.5882, 0.0152, 0.0096, 0.0202, 0.0291, 0.0334, 0.0585, 0.0189, 0.1506,
        0.0309, 0.0455], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:42,811][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.0628, 0.0292, 0.5340, 0.0970, 0.2128, 0.0213, 0.0084, 0.0141, 0.0086,
        0.0088, 0.0029], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:42,812][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.1100, 0.0925, 0.0924, 0.0795, 0.1178, 0.0842, 0.0931, 0.0598, 0.1040,
        0.0976, 0.0691], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:42,814][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0334, 0.0865, 0.1095, 0.0849, 0.1504, 0.1330, 0.0948, 0.0607, 0.0908,
        0.0597, 0.0963], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:42,815][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.3135, 0.0145, 0.0407, 0.0253, 0.0964, 0.0796, 0.0476, 0.0924, 0.1387,
        0.0822, 0.0690], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:42,817][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.0261, 0.0545, 0.0814, 0.1163, 0.0947, 0.0722, 0.1057, 0.1017, 0.1308,
        0.1165, 0.1000], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:42,818][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ at] are: tensor([7.3467e-05, 2.5299e-02, 3.6279e-02, 1.8800e-01, 6.0749e-02, 5.6655e-02,
        3.8893e-01, 3.6475e-02, 1.5032e-01, 2.0368e-02, 3.6847e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:42,819][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.3962, 0.0672, 0.0555, 0.1143, 0.0422, 0.0245, 0.1105, 0.0133, 0.0726,
        0.0405, 0.0631], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:42,820][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0078, 0.0018, 0.0015, 0.0060, 0.0080, 0.0255, 0.0105, 0.0480, 0.3551,
        0.1617, 0.2803, 0.0937], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:42,822][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0490, 0.0960, 0.1032, 0.0813, 0.0818, 0.0630, 0.0707, 0.0855, 0.0951,
        0.0995, 0.1050, 0.0700], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:42,823][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0002, 0.0664, 0.0849, 0.0942, 0.0915, 0.0659, 0.1011, 0.0923, 0.1208,
        0.1013, 0.0830, 0.0985], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:42,825][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0290, 0.0480, 0.0538, 0.0828, 0.0732, 0.1044, 0.1033, 0.0857, 0.1291,
        0.0894, 0.1101, 0.0913], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:42,826][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.2484, 0.0274, 0.0103, 0.0413, 0.0492, 0.0584, 0.0726, 0.0287, 0.2436,
        0.0422, 0.1091, 0.0687], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:42,828][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0542, 0.0283, 0.5272, 0.1031, 0.2126, 0.0235, 0.0093, 0.0169, 0.0101,
        0.0103, 0.0032, 0.0012], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:42,829][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0951, 0.0824, 0.0862, 0.0676, 0.1116, 0.0735, 0.0834, 0.0551, 0.0922,
        0.0946, 0.0709, 0.0872], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:42,831][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0318, 0.0868, 0.1017, 0.0684, 0.1312, 0.1114, 0.0877, 0.0552, 0.0859,
        0.0571, 0.1010, 0.0818], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:42,832][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.2811, 0.0140, 0.0219, 0.0305, 0.0684, 0.0625, 0.0345, 0.0956, 0.1650,
        0.0791, 0.0943, 0.0531], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:42,834][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0228, 0.0496, 0.0735, 0.1084, 0.0864, 0.0666, 0.0972, 0.0930, 0.1239,
        0.1066, 0.0940, 0.0781], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:42,834][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ the] are: tensor([6.0700e-05, 8.6476e-03, 3.0649e-02, 1.4897e-01, 9.0014e-02, 4.2039e-02,
        3.4720e-01, 5.0667e-02, 1.3568e-01, 2.2691e-02, 5.3053e-02, 7.0327e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:42,836][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.1542, 0.2243, 0.0464, 0.2150, 0.0296, 0.0319, 0.0314, 0.0130, 0.0808,
        0.0264, 0.1268, 0.0202], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:42,837][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ hospital] are: tensor([0.0100, 0.0015, 0.0012, 0.0039, 0.0041, 0.0149, 0.0106, 0.0233, 0.1676,
        0.0601, 0.1010, 0.0759, 0.5260], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:42,839][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ hospital] are: tensor([0.0395, 0.1221, 0.0729, 0.0744, 0.0635, 0.0586, 0.0696, 0.0824, 0.0723,
        0.0715, 0.0883, 0.0718, 0.1132], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:42,840][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ hospital] are: tensor([0.0002, 0.0570, 0.0779, 0.0935, 0.0775, 0.0664, 0.0980, 0.0883, 0.1118,
        0.0910, 0.0745, 0.0882, 0.0757], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:42,842][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ hospital] are: tensor([0.0208, 0.0408, 0.0431, 0.0665, 0.0587, 0.0951, 0.0895, 0.0713, 0.1249,
        0.0825, 0.1076, 0.0886, 0.1106], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:42,843][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ hospital] are: tensor([0.6874, 0.0085, 0.0053, 0.0120, 0.0182, 0.0163, 0.0254, 0.0126, 0.0929,
        0.0157, 0.0408, 0.0293, 0.0358], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:42,845][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ hospital] are: tensor([0.0627, 0.0394, 0.4412, 0.1200, 0.2070, 0.0300, 0.0144, 0.0279, 0.0156,
        0.0163, 0.0064, 0.0026, 0.0166], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:42,846][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ hospital] are: tensor([0.0978, 0.0836, 0.0769, 0.0668, 0.0935, 0.0705, 0.0838, 0.0487, 0.0867,
        0.0802, 0.0625, 0.0811, 0.0677], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:42,846][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ hospital] are: tensor([0.0241, 0.1027, 0.1040, 0.0658, 0.1289, 0.1023, 0.0856, 0.0440, 0.0718,
        0.0381, 0.0857, 0.0909, 0.0559], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:42,847][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ hospital] are: tensor([0.1882, 0.0094, 0.0166, 0.0287, 0.0539, 0.0411, 0.0441, 0.0728, 0.1379,
        0.0450, 0.0871, 0.0643, 0.2110], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:42,847][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ hospital] are: tensor([0.0257, 0.0502, 0.0682, 0.0998, 0.0777, 0.0632, 0.0888, 0.0841, 0.1067,
        0.0961, 0.0841, 0.0706, 0.0848], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:42,847][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ hospital] are: tensor([4.5815e-05, 5.2136e-03, 2.6609e-02, 1.5894e-01, 7.2318e-02, 3.9465e-02,
        3.1965e-01, 4.8723e-02, 1.1744e-01, 2.7142e-02, 7.4249e-02, 8.8457e-02,
        2.1754e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:42,848][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ hospital] are: tensor([0.1135, 0.1330, 0.0483, 0.1376, 0.0562, 0.0439, 0.0313, 0.0261, 0.1519,
        0.0374, 0.1608, 0.0275, 0.0326], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:42,848][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.0189, 0.0014, 0.0010, 0.0024, 0.0043, 0.0090, 0.0055, 0.0177, 0.0703,
        0.0505, 0.0431, 0.0324, 0.5498, 0.1935], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:42,849][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.0375, 0.0669, 0.0839, 0.0603, 0.0606, 0.0446, 0.0508, 0.0505, 0.0670,
        0.0832, 0.0888, 0.0640, 0.1514, 0.0905], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:42,850][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.0002, 0.0601, 0.0781, 0.0854, 0.0771, 0.0603, 0.0909, 0.0811, 0.1005,
        0.0806, 0.0670, 0.0784, 0.0737, 0.0667], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:42,851][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0246, 0.0383, 0.0425, 0.0630, 0.0553, 0.0850, 0.0847, 0.0667, 0.1092,
        0.0723, 0.0920, 0.0770, 0.0976, 0.0919], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:42,852][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.6191, 0.0109, 0.0069, 0.0101, 0.0186, 0.0311, 0.0302, 0.0174, 0.0574,
        0.0258, 0.0333, 0.0395, 0.0433, 0.0564], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:42,853][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [.] are: tensor([5.0918e-02, 1.6797e-02, 5.8774e-01, 9.5087e-02, 2.0439e-01, 1.5641e-02,
        5.5453e-03, 7.9831e-03, 4.6525e-03, 4.2591e-03, 1.0840e-03, 4.0279e-04,
        4.8069e-03, 6.9391e-04], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:42,855][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0882, 0.0855, 0.0692, 0.0592, 0.0982, 0.0646, 0.0840, 0.0427, 0.0852,
        0.0860, 0.0610, 0.0780, 0.0661, 0.0321], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:42,856][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0295, 0.0864, 0.0903, 0.0596, 0.1263, 0.0966, 0.0793, 0.0441, 0.0660,
        0.0403, 0.0897, 0.0805, 0.0568, 0.0545], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:42,858][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.2988, 0.0076, 0.0191, 0.0125, 0.0570, 0.0483, 0.0287, 0.0838, 0.0709,
        0.0517, 0.0444, 0.0459, 0.1904, 0.0410], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:42,859][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.0224, 0.0444, 0.0636, 0.0897, 0.0726, 0.0581, 0.0797, 0.0773, 0.1005,
        0.0874, 0.0799, 0.0654, 0.0763, 0.0828], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:42,860][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [.] are: tensor([2.2963e-05, 4.7825e-03, 3.2741e-02, 9.7891e-02, 8.3783e-02, 3.3632e-02,
        3.9336e-01, 1.8332e-02, 1.3519e-01, 8.5207e-03, 4.5523e-02, 6.7249e-02,
        3.6014e-02, 4.2959e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:42,861][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.2107, 0.0199, 0.0616, 0.0182, 0.0560, 0.0218, 0.0472, 0.0352, 0.0318,
        0.0753, 0.1057, 0.0542, 0.2398, 0.0226], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:42,862][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Anthony] are: tensor([8.1634e-03, 3.9713e-04, 2.1890e-04, 3.4549e-04, 4.9136e-04, 1.8325e-03,
        1.2837e-03, 3.9750e-03, 2.8584e-02, 1.4389e-02, 2.1136e-02, 1.7183e-02,
        3.0451e-01, 1.3081e-01, 4.6668e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:42,864][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Anthony] are: tensor([0.0264, 0.0557, 0.0865, 0.0596, 0.0560, 0.0526, 0.0352, 0.0626, 0.0517,
        0.0875, 0.0607, 0.0538, 0.1518, 0.0816, 0.0784], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:42,865][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Anthony] are: tensor([7.3422e-05, 4.7429e-02, 6.7200e-02, 7.6541e-02, 6.9176e-02, 5.6364e-02,
        8.0016e-02, 7.9930e-02, 9.8909e-02, 7.3045e-02, 5.8514e-02, 7.1715e-02,
        6.6822e-02, 6.0763e-02, 9.3501e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:42,866][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Anthony] are: tensor([0.0196, 0.0347, 0.0350, 0.0565, 0.0466, 0.0824, 0.0761, 0.0589, 0.1056,
        0.0675, 0.0877, 0.0728, 0.0910, 0.0848, 0.0807], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:42,868][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Anthony] are: tensor([0.3144, 0.0119, 0.0064, 0.0201, 0.0308, 0.0239, 0.0452, 0.0252, 0.1440,
        0.0323, 0.0475, 0.0538, 0.0606, 0.1595, 0.0245], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:42,869][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Anthony] are: tensor([0.0773, 0.0316, 0.4821, 0.1169, 0.2005, 0.0262, 0.0100, 0.0162, 0.0099,
        0.0081, 0.0027, 0.0012, 0.0097, 0.0020, 0.0057], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:42,871][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Anthony] are: tensor([0.0819, 0.0747, 0.0696, 0.0553, 0.0928, 0.0645, 0.0749, 0.0419, 0.0785,
        0.0851, 0.0596, 0.0725, 0.0666, 0.0348, 0.0472], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:42,872][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Anthony] are: tensor([0.0233, 0.0925, 0.0809, 0.0665, 0.1057, 0.0807, 0.0681, 0.0397, 0.0657,
        0.0341, 0.0797, 0.0701, 0.0547, 0.0599, 0.0784], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:42,874][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Anthony] are: tensor([0.1633, 0.0051, 0.0126, 0.0172, 0.0390, 0.0245, 0.0284, 0.0522, 0.0922,
        0.0416, 0.0516, 0.0494, 0.1811, 0.0783, 0.1636], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:42,875][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Anthony] are: tensor([0.0224, 0.0400, 0.0572, 0.0798, 0.0660, 0.0512, 0.0708, 0.0684, 0.0887,
        0.0829, 0.0750, 0.0604, 0.0770, 0.0832, 0.0772], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:42,876][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Anthony] are: tensor([1.1332e-04, 6.8390e-03, 9.2061e-03, 6.7864e-02, 5.2114e-02, 3.0071e-02,
        1.3816e-01, 4.1609e-02, 1.4623e-01, 3.1938e-02, 7.2631e-02, 1.0708e-01,
        6.7577e-02, 1.4202e-01, 8.6540e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:42,878][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Anthony] are: tensor([0.0606, 0.1146, 0.0311, 0.0915, 0.0349, 0.0297, 0.0412, 0.0065, 0.0755,
        0.0247, 0.1480, 0.0298, 0.0452, 0.2175, 0.0493], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:42,879][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([3.5533e-03, 4.0376e-04, 2.4510e-04, 6.3527e-04, 1.1133e-03, 2.6939e-03,
        1.3032e-03, 6.3096e-03, 3.1813e-02, 1.4269e-02, 2.4691e-02, 1.3355e-02,
        2.5541e-01, 9.5356e-02, 4.3052e-01, 1.1832e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:42,880][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0512, 0.0702, 0.0527, 0.0620, 0.0490, 0.0364, 0.0529, 0.0736, 0.0529,
        0.0643, 0.0984, 0.0600, 0.0837, 0.0674, 0.0479, 0.0776],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:42,882][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0001, 0.0531, 0.0636, 0.0711, 0.0637, 0.0488, 0.0809, 0.0751, 0.0901,
        0.0781, 0.0558, 0.0689, 0.0633, 0.0593, 0.0779, 0.0502],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:42,883][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.0145, 0.0309, 0.0342, 0.0533, 0.0467, 0.0716, 0.0704, 0.0567, 0.0955,
        0.0644, 0.0810, 0.0664, 0.0861, 0.0761, 0.0772, 0.0751],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:42,885][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.4719, 0.0101, 0.0072, 0.0191, 0.0199, 0.0155, 0.0338, 0.0181, 0.1082,
        0.0220, 0.0453, 0.0354, 0.0464, 0.1074, 0.0237, 0.0160],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:42,886][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.0798, 0.0269, 0.5376, 0.0956, 0.1994, 0.0165, 0.0073, 0.0104, 0.0056,
        0.0060, 0.0016, 0.0007, 0.0075, 0.0011, 0.0032, 0.0007],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:42,888][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0681, 0.0752, 0.0665, 0.0583, 0.0886, 0.0622, 0.0726, 0.0427, 0.0825,
        0.0785, 0.0565, 0.0679, 0.0659, 0.0343, 0.0419, 0.0384],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:42,889][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0202, 0.0736, 0.0744, 0.0599, 0.1038, 0.0934, 0.0633, 0.0379, 0.0613,
        0.0392, 0.0825, 0.0715, 0.0485, 0.0485, 0.0759, 0.0461],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:42,891][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.1874, 0.0059, 0.0116, 0.0144, 0.0356, 0.0267, 0.0227, 0.0520, 0.0821,
        0.0350, 0.0491, 0.0406, 0.1922, 0.0602, 0.1291, 0.0553],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:42,892][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.0192, 0.0394, 0.0550, 0.0790, 0.0626, 0.0475, 0.0693, 0.0639, 0.0850,
        0.0768, 0.0655, 0.0545, 0.0651, 0.0727, 0.0752, 0.0695],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:42,893][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([4.0731e-05, 9.0683e-03, 1.9470e-02, 8.6106e-02, 3.7822e-02, 2.5830e-02,
        3.3273e-01, 1.1749e-02, 1.4359e-01, 2.5170e-02, 6.5127e-02, 9.8765e-02,
        3.7092e-02, 6.4343e-02, 3.7896e-02, 5.2079e-03], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:42,895][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.1467, 0.0847, 0.0496, 0.0961, 0.0490, 0.0365, 0.0462, 0.0123, 0.0714,
        0.0477, 0.0691, 0.0419, 0.0707, 0.0794, 0.0737, 0.0250],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:42,896][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ a] are: tensor([5.0551e-03, 3.3784e-04, 1.5705e-04, 3.0636e-04, 7.6055e-04, 2.4145e-03,
        4.9367e-04, 4.8387e-03, 1.3534e-02, 1.3908e-02, 9.9180e-03, 6.4735e-03,
        2.2991e-01, 8.2079e-02, 3.5095e-01, 2.1416e-01, 6.4700e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:42,897][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0232, 0.0508, 0.0739, 0.0411, 0.0498, 0.0434, 0.0373, 0.0538, 0.0513,
        0.0626, 0.0677, 0.0487, 0.1057, 0.0771, 0.0785, 0.0898, 0.0453],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:42,899][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0001, 0.0462, 0.0578, 0.0638, 0.0604, 0.0471, 0.0712, 0.0697, 0.0855,
        0.0706, 0.0562, 0.0647, 0.0617, 0.0543, 0.0766, 0.0531, 0.0609],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:42,900][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0161, 0.0349, 0.0375, 0.0546, 0.0487, 0.0686, 0.0663, 0.0563, 0.0837,
        0.0598, 0.0692, 0.0572, 0.0783, 0.0700, 0.0721, 0.0694, 0.0573],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:42,902][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.1318, 0.0197, 0.0100, 0.0313, 0.0277, 0.0311, 0.0425, 0.0234, 0.1564,
        0.0389, 0.0665, 0.0791, 0.0601, 0.1792, 0.0320, 0.0292, 0.0411],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:42,903][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ a] are: tensor([7.2847e-02, 1.8926e-02, 6.0836e-01, 8.3337e-02, 1.8157e-01, 1.1099e-02,
        4.1026e-03, 5.8927e-03, 3.4591e-03, 3.3266e-03, 7.5962e-04, 2.6515e-04,
        3.6642e-03, 4.8661e-04, 1.5037e-03, 3.4522e-04, 5.5020e-05],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:42,904][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0813, 0.0775, 0.0644, 0.0531, 0.0871, 0.0586, 0.0683, 0.0386, 0.0743,
        0.0751, 0.0526, 0.0653, 0.0615, 0.0297, 0.0390, 0.0346, 0.0390],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:42,904][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0214, 0.0612, 0.0738, 0.0452, 0.0952, 0.0856, 0.0509, 0.0389, 0.0611,
        0.0439, 0.0738, 0.0639, 0.0514, 0.0466, 0.0818, 0.0499, 0.0555],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:42,905][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.1608, 0.0066, 0.0117, 0.0146, 0.0342, 0.0285, 0.0177, 0.0527, 0.0818,
        0.0392, 0.0548, 0.0370, 0.1750, 0.0691, 0.1265, 0.0598, 0.0300],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:42,905][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0191, 0.0368, 0.0483, 0.0702, 0.0545, 0.0452, 0.0624, 0.0612, 0.0780,
        0.0718, 0.0634, 0.0529, 0.0649, 0.0695, 0.0658, 0.0687, 0.0674],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:42,906][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ a] are: tensor([4.6003e-05, 7.6033e-03, 2.0572e-02, 1.1586e-01, 4.4387e-02, 3.4793e-02,
        1.8489e-01, 5.0530e-02, 1.0092e-01, 2.4060e-02, 5.8701e-02, 7.3969e-02,
        5.8315e-02, 8.6819e-02, 6.8112e-02, 1.8774e-02, 5.1649e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:42,906][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0588, 0.1717, 0.0268, 0.2566, 0.0093, 0.0318, 0.0131, 0.0093, 0.0677,
        0.0208, 0.1081, 0.0295, 0.0453, 0.0938, 0.0346, 0.0108, 0.0122],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:42,907][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ drink] are: tensor([1.4213e-03, 1.2492e-04, 1.2508e-04, 2.9731e-04, 4.2907e-04, 1.6199e-03,
        1.2758e-03, 3.0052e-03, 2.6023e-02, 9.2913e-03, 1.3439e-02, 1.3737e-02,
        1.7879e-01, 5.8968e-02, 3.5070e-01, 1.3425e-01, 1.2671e-01, 7.9795e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:42,907][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ drink] are: tensor([0.0216, 0.0713, 0.0635, 0.0544, 0.0586, 0.0386, 0.0456, 0.0466, 0.0498,
        0.0613, 0.0700, 0.0416, 0.0869, 0.0727, 0.0607, 0.0534, 0.0499, 0.0537],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:42,909][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ drink] are: tensor([9.7629e-05, 4.2657e-02, 6.3705e-02, 7.1182e-02, 5.9719e-02, 4.9554e-02,
        7.9195e-02, 7.2132e-02, 8.3821e-02, 5.9250e-02, 5.0026e-02, 5.7160e-02,
        5.1183e-02, 5.0191e-02, 6.5950e-02, 4.5814e-02, 5.5845e-02, 4.2520e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:42,910][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ drink] are: tensor([0.0124, 0.0267, 0.0301, 0.0458, 0.0400, 0.0658, 0.0623, 0.0502, 0.0853,
        0.0590, 0.0738, 0.0603, 0.0769, 0.0674, 0.0666, 0.0679, 0.0545, 0.0551],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:42,912][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ drink] are: tensor([0.2249, 0.0116, 0.0048, 0.0195, 0.0226, 0.0216, 0.0413, 0.0207, 0.1369,
        0.0308, 0.0455, 0.0517, 0.0493, 0.2188, 0.0206, 0.0256, 0.0425, 0.0115],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:42,913][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ drink] are: tensor([5.9877e-02, 1.9410e-02, 5.9731e-01, 8.1646e-02, 1.9863e-01, 1.2467e-02,
        4.9975e-03, 7.7821e-03, 4.2015e-03, 4.4160e-03, 9.1210e-04, 3.3723e-04,
        4.9020e-03, 5.7673e-04, 1.8941e-03, 3.8498e-04, 6.2229e-05, 1.9200e-04],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:42,914][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ drink] are: tensor([0.0618, 0.0717, 0.0642, 0.0510, 0.0869, 0.0548, 0.0632, 0.0377, 0.0732,
        0.0732, 0.0487, 0.0585, 0.0623, 0.0302, 0.0396, 0.0348, 0.0404, 0.0476],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:42,915][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ drink] are: tensor([0.0155, 0.0713, 0.0732, 0.0472, 0.0971, 0.0723, 0.0637, 0.0303, 0.0497,
        0.0282, 0.0685, 0.0638, 0.0435, 0.0489, 0.0759, 0.0409, 0.0707, 0.0391],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:42,916][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ drink] are: tensor([0.1185, 0.0049, 0.0113, 0.0145, 0.0314, 0.0229, 0.0238, 0.0383, 0.0700,
        0.0322, 0.0409, 0.0435, 0.1550, 0.0688, 0.1569, 0.0485, 0.0388, 0.0799],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:42,918][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ drink] are: tensor([0.0160, 0.0349, 0.0457, 0.0655, 0.0523, 0.0423, 0.0587, 0.0549, 0.0725,
        0.0674, 0.0586, 0.0486, 0.0588, 0.0641, 0.0611, 0.0623, 0.0623, 0.0740],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:42,919][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ drink] are: tensor([1.2058e-04, 3.3730e-03, 1.4643e-02, 4.1266e-02, 5.7178e-02, 2.5177e-02,
        3.0311e-01, 2.4514e-02, 1.5354e-01, 1.3140e-02, 6.2101e-02, 6.4773e-02,
        3.3693e-02, 5.5222e-02, 4.4393e-02, 1.4531e-02, 8.1882e-02, 7.3388e-03],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:42,921][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ drink] are: tensor([0.2222, 0.0487, 0.0478, 0.0326, 0.0801, 0.0186, 0.0353, 0.0114, 0.0344,
        0.0404, 0.0712, 0.0301, 0.0603, 0.1113, 0.0783, 0.0181, 0.0344, 0.0249],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:42,922][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ to] are: tensor([1.0012e-02, 2.9155e-04, 1.2716e-04, 9.9848e-05, 3.9934e-04, 9.0629e-04,
        3.3699e-04, 2.3406e-03, 4.2294e-03, 8.0512e-03, 2.7607e-03, 3.6012e-03,
        1.1894e-01, 4.0213e-02, 2.4411e-01, 1.4074e-01, 4.4789e-02, 1.6671e-01,
        2.1134e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:42,923][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0304, 0.0611, 0.0615, 0.0465, 0.0431, 0.0324, 0.0393, 0.0442, 0.0504,
        0.0648, 0.0560, 0.0453, 0.1031, 0.0640, 0.0675, 0.0529, 0.0441, 0.0547,
        0.0389], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:42,925][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0002, 0.0373, 0.0514, 0.0563, 0.0527, 0.0409, 0.0655, 0.0623, 0.0746,
        0.0584, 0.0473, 0.0583, 0.0526, 0.0488, 0.0692, 0.0472, 0.0563, 0.0485,
        0.0723], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:42,926][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0171, 0.0310, 0.0331, 0.0485, 0.0430, 0.0606, 0.0595, 0.0506, 0.0734,
        0.0512, 0.0617, 0.0505, 0.0725, 0.0650, 0.0657, 0.0611, 0.0526, 0.0516,
        0.0515], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:42,928][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.4827, 0.0100, 0.0064, 0.0127, 0.0160, 0.0197, 0.0424, 0.0146, 0.0681,
        0.0223, 0.0346, 0.0376, 0.0374, 0.0831, 0.0222, 0.0193, 0.0418, 0.0089,
        0.0201], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:42,929][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ to] are: tensor([6.8317e-02, 1.3667e-02, 6.3490e-01, 7.5945e-02, 1.8318e-01, 7.7393e-03,
        2.8773e-03, 3.9676e-03, 2.6027e-03, 2.1439e-03, 3.7758e-04, 1.3813e-04,
        2.6178e-03, 2.6730e-04, 9.6414e-04, 1.6264e-04, 2.2971e-05, 8.2068e-05,
        2.7175e-05], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:42,930][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0749, 0.0801, 0.0632, 0.0510, 0.0827, 0.0529, 0.0637, 0.0350, 0.0693,
        0.0700, 0.0461, 0.0566, 0.0558, 0.0261, 0.0353, 0.0307, 0.0368, 0.0440,
        0.0258], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:42,931][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0232, 0.0612, 0.0698, 0.0447, 0.0853, 0.0761, 0.0544, 0.0365, 0.0538,
        0.0359, 0.0599, 0.0565, 0.0447, 0.0392, 0.0700, 0.0417, 0.0558, 0.0412,
        0.0501], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:42,933][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.1997, 0.0035, 0.0103, 0.0099, 0.0244, 0.0225, 0.0195, 0.0436, 0.0553,
        0.0288, 0.0371, 0.0372, 0.1563, 0.0392, 0.1122, 0.0522, 0.0289, 0.0945,
        0.0248], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:42,935][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0163, 0.0312, 0.0420, 0.0606, 0.0473, 0.0387, 0.0551, 0.0521, 0.0668,
        0.0620, 0.0544, 0.0458, 0.0566, 0.0614, 0.0564, 0.0591, 0.0600, 0.0735,
        0.0607], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:42,936][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ to] are: tensor([5.4846e-05, 7.6238e-03, 2.9140e-02, 8.2808e-02, 4.0545e-02, 3.0917e-02,
        3.3035e-01, 2.1407e-02, 9.6159e-02, 1.1382e-02, 2.9506e-02, 6.3427e-02,
        2.7847e-02, 5.2608e-02, 5.7971e-02, 1.5630e-02, 6.7296e-02, 1.5983e-02,
        1.9345e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:42,937][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.3060, 0.0541, 0.0300, 0.0364, 0.0130, 0.0132, 0.0374, 0.0212, 0.0301,
        0.0532, 0.0536, 0.0500, 0.1107, 0.0296, 0.0474, 0.0347, 0.0422, 0.0237,
        0.0133], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:42,987][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:21:42,988][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:42,989][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:42,990][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:42,991][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:42,993][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:42,994][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:42,995][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:42,996][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:42,997][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:42,998][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:42,999][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:43,000][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:43,002][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.6312, 0.3688], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:43,003][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.8678, 0.1322], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:43,004][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0022, 0.9978], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:43,006][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.8645, 0.1355], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:43,007][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.4757, 0.5243], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:43,008][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.9691, 0.0309], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:43,010][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.8580, 0.1420], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:43,011][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.1175, 0.8825], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:43,012][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.4123, 0.5877], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:43,014][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.3370, 0.6630], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:43,015][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0148, 0.9852], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:43,017][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.6254, 0.3746], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:43,018][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Anthony] are: tensor([0.2772, 0.2617, 0.4610], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:43,019][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Anthony] are: tensor([0.6840, 0.0986, 0.2174], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:43,021][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Anthony] are: tensor([0.0006, 0.4399, 0.5595], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:43,022][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Anthony] are: tensor([0.8683, 0.0757, 0.0560], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:43,023][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Anthony] are: tensor([0.4146, 0.2923, 0.2930], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:43,025][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Anthony] are: tensor([0.9198, 0.0486, 0.0316], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:43,026][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Anthony] are: tensor([0.8215, 0.0979, 0.0806], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:43,028][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Anthony] are: tensor([0.0969, 0.6239, 0.2793], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:43,028][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Anthony] are: tensor([0.3349, 0.2786, 0.3866], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:43,028][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Anthony] are: tensor([0.2481, 0.2841, 0.4678], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:43,029][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Anthony] are: tensor([0.0116, 0.5148, 0.4737], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:43,029][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Anthony] are: tensor([0.7484, 0.1346, 0.1170], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:43,029][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.1609, 0.0666, 0.1169, 0.6556], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:43,030][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.7350, 0.1173, 0.0769, 0.0708], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:43,030][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([5.2028e-04, 5.3627e-02, 1.4566e-01, 8.0020e-01], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:43,030][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.8650, 0.0535, 0.0218, 0.0597], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:43,031][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.3321, 0.1380, 0.1160, 0.4139], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:43,032][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.9813, 0.0122, 0.0044, 0.0022], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:43,033][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.8963, 0.0603, 0.0205, 0.0229], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:43,034][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0762, 0.3043, 0.1064, 0.5131], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:43,036][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.1803, 0.2679, 0.1866, 0.3652], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:43,037][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.1243, 0.1468, 0.2300, 0.4989], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:43,038][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0012, 0.0716, 0.2154, 0.7118], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:43,040][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.6834, 0.1304, 0.1194, 0.0668], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:43,041][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Travis] are: tensor([0.0468, 0.0272, 0.0517, 0.6063, 0.2680], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:43,043][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Travis] are: tensor([0.5784, 0.0997, 0.0835, 0.0899, 0.1485], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:43,043][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Travis] are: tensor([2.7053e-04, 6.8265e-02, 7.6759e-02, 6.8183e-01, 1.7287e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:43,045][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Travis] are: tensor([0.8740, 0.0324, 0.0110, 0.0368, 0.0458], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:43,046][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Travis] are: tensor([0.1574, 0.0978, 0.0822, 0.3234, 0.3392], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:43,048][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Travis] are: tensor([0.9309, 0.0254, 0.0116, 0.0065, 0.0256], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:43,049][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Travis] are: tensor([0.7186, 0.0964, 0.0445, 0.0497, 0.0908], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:43,050][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Travis] are: tensor([0.0468, 0.1560, 0.0634, 0.5211, 0.2127], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:43,052][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Travis] are: tensor([0.0962, 0.1055, 0.0905, 0.2317, 0.4761], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:43,053][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Travis] are: tensor([0.0967, 0.1151, 0.1080, 0.3618, 0.3184], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:43,055][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Travis] are: tensor([0.0033, 0.0433, 0.1769, 0.5693, 0.2072], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:43,056][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Travis] are: tensor([0.5675, 0.1364, 0.0869, 0.0863, 0.1229], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:43,058][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.0419, 0.0298, 0.0372, 0.2286, 0.2561, 0.4065], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:43,059][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.1483, 0.0989, 0.1372, 0.1568, 0.1897, 0.2690], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:43,060][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([3.2786e-05, 6.0572e-02, 4.4072e-02, 6.6835e-01, 1.8657e-01, 4.0404e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:43,061][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.5107, 0.0518, 0.0258, 0.0733, 0.1099, 0.2284], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:43,063][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.1363, 0.0685, 0.0588, 0.2759, 0.2199, 0.2405], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:43,064][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.8471, 0.0405, 0.0179, 0.0150, 0.0423, 0.0372], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:43,066][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.5727, 0.0929, 0.0385, 0.0566, 0.1439, 0.0954], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:43,067][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.0194, 0.1594, 0.0683, 0.4109, 0.2520, 0.0899], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:43,068][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.0488, 0.0747, 0.0628, 0.2209, 0.3918, 0.2009], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:43,070][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.0310, 0.0668, 0.0831, 0.2596, 0.3581, 0.2015], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:43,071][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([1.2272e-04, 4.7487e-02, 7.0441e-02, 6.1238e-01, 1.3593e-01, 1.3364e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:43,072][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.2027, 0.1344, 0.0992, 0.1531, 0.2439, 0.1667], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:43,073][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0622, 0.0149, 0.0138, 0.1020, 0.1223, 0.5185, 0.1662],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:43,075][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.5502, 0.0413, 0.0655, 0.0468, 0.1355, 0.1339, 0.0268],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:43,076][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([2.7433e-04, 3.2720e-02, 4.4424e-02, 4.7420e-01, 1.4672e-01, 5.2099e-02,
        2.4956e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:43,077][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.7101, 0.0290, 0.0122, 0.0288, 0.0545, 0.1081, 0.0573],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:43,079][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.3440, 0.0369, 0.0225, 0.0922, 0.0938, 0.1444, 0.2662],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:43,080][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.9320, 0.0160, 0.0066, 0.0045, 0.0197, 0.0191, 0.0022],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:43,081][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.8205, 0.0344, 0.0178, 0.0175, 0.0550, 0.0418, 0.0129],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:43,083][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0692, 0.1453, 0.0750, 0.2529, 0.1768, 0.1042, 0.1766],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:43,084][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.1186, 0.0693, 0.0415, 0.1381, 0.3262, 0.2047, 0.1014],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:43,086][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0624, 0.0396, 0.0536, 0.1592, 0.2025, 0.2130, 0.2698],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:43,086][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0005, 0.0288, 0.0428, 0.3050, 0.1156, 0.1235, 0.3838],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:43,087][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.5328, 0.1042, 0.0771, 0.0661, 0.0949, 0.0805, 0.0445],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:43,087][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ lot] are: tensor([0.0436, 0.0153, 0.0209, 0.0866, 0.0629, 0.3254, 0.3066, 0.1387],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:43,087][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ lot] are: tensor([0.2356, 0.1043, 0.0813, 0.0811, 0.0867, 0.2008, 0.1160, 0.0942],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:43,088][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ lot] are: tensor([4.9542e-05, 3.6357e-02, 2.7855e-02, 3.0949e-01, 5.6069e-02, 3.8588e-02,
        5.2086e-01, 1.0730e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:43,088][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ lot] are: tensor([0.3996, 0.0394, 0.0336, 0.0465, 0.0770, 0.1564, 0.1081, 0.1394],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:43,089][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ lot] are: tensor([0.0610, 0.0361, 0.0316, 0.1094, 0.0942, 0.1135, 0.4246, 0.1296],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:43,089][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ lot] are: tensor([0.8309, 0.0302, 0.0187, 0.0114, 0.0365, 0.0385, 0.0082, 0.0257],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:43,090][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ lot] are: tensor([0.6257, 0.0685, 0.0338, 0.0331, 0.0826, 0.0676, 0.0354, 0.0534],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:43,092][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ lot] are: tensor([0.0387, 0.0753, 0.0568, 0.1754, 0.1474, 0.1116, 0.2454, 0.1494],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:43,093][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ lot] are: tensor([0.0631, 0.0474, 0.0457, 0.0937, 0.2022, 0.1549, 0.1675, 0.2254],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:43,094][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ lot] are: tensor([0.0259, 0.0394, 0.0441, 0.1389, 0.1475, 0.1696, 0.2590, 0.1755],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:43,095][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ lot] are: tensor([8.8674e-05, 2.4140e-02, 2.2035e-02, 1.0908e-01, 2.7266e-02, 4.0613e-02,
        7.6498e-01, 1.1801e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:43,097][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ lot] are: tensor([0.1214, 0.0813, 0.0808, 0.0652, 0.1955, 0.1262, 0.1805, 0.1492],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:43,098][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([0.0384, 0.0076, 0.0047, 0.0177, 0.0299, 0.0780, 0.0448, 0.1165, 0.6624],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:43,100][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([0.2545, 0.0639, 0.0827, 0.0839, 0.1299, 0.1606, 0.0477, 0.0936, 0.0832],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:43,101][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([1.2938e-05, 1.2111e-02, 2.3330e-02, 3.1148e-01, 8.0037e-02, 1.5836e-02,
        3.0788e-01, 1.2452e-02, 2.3686e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:43,102][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([0.6258, 0.0194, 0.0053, 0.0128, 0.0196, 0.0527, 0.0311, 0.0588, 0.1745],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:43,103][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([0.1410, 0.0250, 0.0095, 0.0342, 0.0288, 0.0549, 0.1070, 0.0855, 0.5140],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:43,105][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([0.9138, 0.0165, 0.0064, 0.0029, 0.0174, 0.0140, 0.0021, 0.0112, 0.0156],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:43,106][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([0.7936, 0.0353, 0.0193, 0.0127, 0.0435, 0.0343, 0.0116, 0.0291, 0.0206],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:43,108][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([0.0186, 0.0882, 0.0408, 0.2327, 0.1194, 0.0976, 0.1403, 0.0843, 0.1783],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:43,109][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([0.0774, 0.0328, 0.0160, 0.0313, 0.0762, 0.0651, 0.0463, 0.1840, 0.4710],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:43,111][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([0.0338, 0.0157, 0.0142, 0.0360, 0.0474, 0.0503, 0.0908, 0.1127, 0.5992],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:43,112][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([3.6157e-05, 1.3217e-02, 2.7878e-02, 1.4228e-01, 5.5016e-02, 4.9782e-02,
        5.1255e-01, 3.3326e-02, 1.6591e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:43,113][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([0.4008, 0.0703, 0.0630, 0.0415, 0.1267, 0.0791, 0.0655, 0.0984, 0.0546],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:43,114][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ fun] are: tensor([0.0049, 0.0015, 0.0023, 0.0087, 0.0066, 0.0448, 0.0271, 0.0423, 0.7466,
        0.1150], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:43,116][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ fun] are: tensor([0.1824, 0.0585, 0.0836, 0.0916, 0.1172, 0.1261, 0.0796, 0.0884, 0.0911,
        0.0815], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:43,117][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ fun] are: tensor([2.2229e-05, 3.7787e-02, 2.9442e-02, 2.7008e-01, 3.8710e-02, 2.7129e-02,
        2.9015e-01, 8.5862e-03, 2.2618e-01, 7.1906e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:43,118][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ fun] are: tensor([0.3174, 0.0191, 0.0064, 0.0170, 0.0232, 0.0568, 0.0420, 0.0859, 0.2397,
        0.1924], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:43,120][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ fun] are: tensor([0.0382, 0.0139, 0.0067, 0.0345, 0.0212, 0.0392, 0.1262, 0.0888, 0.5187,
        0.1126], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:43,121][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ fun] are: tensor([0.8228, 0.0295, 0.0120, 0.0067, 0.0239, 0.0243, 0.0040, 0.0200, 0.0345,
        0.0220], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:43,123][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ fun] are: tensor([0.5929, 0.0429, 0.0284, 0.0308, 0.0659, 0.0550, 0.0257, 0.0577, 0.0563,
        0.0446], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:43,124][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ fun] are: tensor([0.0143, 0.0506, 0.0392, 0.1000, 0.1226, 0.0489, 0.1409, 0.0690, 0.2244,
        0.1902], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:43,125][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ fun] are: tensor([0.0207, 0.0098, 0.0084, 0.0315, 0.0330, 0.0512, 0.0403, 0.1026, 0.5421,
        0.1604], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:43,127][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ fun] are: tensor([0.0156, 0.0108, 0.0141, 0.0370, 0.0323, 0.0574, 0.0865, 0.0941, 0.5502,
        0.1019], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:43,128][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ fun] are: tensor([5.9515e-05, 1.3110e-02, 1.8416e-02, 9.2749e-02, 5.2201e-02, 3.5509e-02,
        6.0708e-01, 2.4534e-02, 1.4592e-01, 1.0421e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:43,129][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ fun] are: tensor([0.2128, 0.0862, 0.0687, 0.0532, 0.0855, 0.0740, 0.0848, 0.1026, 0.1011,
        0.1311], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:43,131][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.0168, 0.0025, 0.0023, 0.0059, 0.0123, 0.0439, 0.0177, 0.0625, 0.3879,
        0.2661, 0.1820], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:43,132][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.3867, 0.0604, 0.0495, 0.0481, 0.0747, 0.1288, 0.0254, 0.0839, 0.0489,
        0.0555, 0.0379], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:43,133][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([1.3795e-05, 1.0893e-02, 1.6311e-02, 2.3808e-01, 3.8484e-02, 1.8505e-02,
        2.3956e-01, 9.6029e-03, 2.2491e-01, 1.0961e-01, 9.4034e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:43,135][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.3847, 0.0149, 0.0039, 0.0099, 0.0151, 0.0359, 0.0238, 0.0707, 0.1499,
        0.1510, 0.1403], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:43,136][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.0617, 0.0141, 0.0056, 0.0232, 0.0183, 0.0367, 0.0768, 0.0571, 0.3329,
        0.0989, 0.2747], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:43,138][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.8867, 0.0190, 0.0075, 0.0032, 0.0162, 0.0138, 0.0017, 0.0101, 0.0167,
        0.0142, 0.0110], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:43,139][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.7945, 0.0289, 0.0145, 0.0100, 0.0325, 0.0244, 0.0080, 0.0264, 0.0171,
        0.0204, 0.0233], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:43,141][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.0324, 0.0877, 0.0391, 0.1453, 0.1058, 0.0786, 0.0706, 0.0592, 0.1289,
        0.1353, 0.1172], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:43,142][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.0244, 0.0134, 0.0071, 0.0138, 0.0351, 0.0288, 0.0226, 0.0846, 0.2627,
        0.2103, 0.2973], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:43,144][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.0210, 0.0081, 0.0111, 0.0208, 0.0336, 0.0355, 0.0580, 0.0858, 0.3246,
        0.1115, 0.2901], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:43,144][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([7.3467e-05, 2.5299e-02, 3.6279e-02, 1.8800e-01, 6.0749e-02, 5.6655e-02,
        3.8893e-01, 3.6475e-02, 1.5032e-01, 2.0368e-02, 3.6847e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:43,144][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.3366, 0.0695, 0.0565, 0.0443, 0.0794, 0.0755, 0.0487, 0.0764, 0.0494,
        0.1181, 0.0456], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:43,145][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0078, 0.0018, 0.0015, 0.0060, 0.0080, 0.0255, 0.0105, 0.0480, 0.3551,
        0.1617, 0.2803, 0.0937], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:43,145][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.2549, 0.0459, 0.0674, 0.0526, 0.1186, 0.1555, 0.0287, 0.0857, 0.0582,
        0.0521, 0.0417, 0.0387], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:43,146][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([3.0194e-05, 1.0903e-02, 1.5926e-02, 2.3815e-01, 5.5886e-02, 1.5857e-02,
        1.4999e-01, 8.8541e-03, 1.9670e-01, 9.1030e-02, 1.0294e-01, 1.1372e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:43,146][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.3787, 0.0148, 0.0038, 0.0094, 0.0143, 0.0322, 0.0173, 0.0483, 0.1222,
        0.1360, 0.1096, 0.1133], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:43,147][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0555, 0.0083, 0.0035, 0.0130, 0.0119, 0.0202, 0.0490, 0.0382, 0.2305,
        0.0557, 0.2811, 0.2331], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:43,147][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.8646, 0.0173, 0.0098, 0.0033, 0.0245, 0.0140, 0.0018, 0.0081, 0.0156,
        0.0175, 0.0139, 0.0097], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:43,149][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.6775, 0.0367, 0.0219, 0.0144, 0.0516, 0.0302, 0.0113, 0.0361, 0.0236,
        0.0321, 0.0349, 0.0297], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:43,150][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0089, 0.0414, 0.0251, 0.1101, 0.0627, 0.0435, 0.0818, 0.0462, 0.1441,
        0.1294, 0.1320, 0.1747], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:43,152][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0229, 0.0104, 0.0065, 0.0140, 0.0306, 0.0214, 0.0117, 0.0550, 0.2478,
        0.1210, 0.3520, 0.1066], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:43,153][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0225, 0.0072, 0.0086, 0.0181, 0.0208, 0.0279, 0.0386, 0.0701, 0.2841,
        0.0817, 0.2266, 0.1937], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:43,154][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([6.0700e-05, 8.6476e-03, 3.0649e-02, 1.4897e-01, 9.0014e-02, 4.2039e-02,
        3.4720e-01, 5.0667e-02, 1.3568e-01, 2.2691e-02, 5.3053e-02, 7.0327e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:43,155][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.2810, 0.0476, 0.0599, 0.0435, 0.0821, 0.0573, 0.0417, 0.1004, 0.0477,
        0.1025, 0.0527, 0.0837], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:43,157][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ hospital] are: tensor([0.0100, 0.0015, 0.0012, 0.0039, 0.0041, 0.0149, 0.0106, 0.0233, 0.1676,
        0.0601, 0.1010, 0.0759, 0.5260], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:43,158][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ hospital] are: tensor([0.2382, 0.0354, 0.0291, 0.0412, 0.0634, 0.1095, 0.0506, 0.1087, 0.0704,
        0.0646, 0.0613, 0.0676, 0.0600], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:43,159][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ hospital] are: tensor([4.6160e-06, 6.0689e-03, 1.1367e-02, 2.6072e-01, 2.2968e-02, 1.6766e-02,
        2.0709e-01, 5.5948e-03, 1.8981e-01, 4.3708e-02, 1.1056e-01, 1.1143e-01,
        1.3914e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:43,161][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ hospital] are: tensor([0.3040, 0.0096, 0.0021, 0.0055, 0.0070, 0.0204, 0.0115, 0.0278, 0.0647,
        0.0559, 0.0681, 0.0863, 0.3369], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:43,162][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ hospital] are: tensor([0.0286, 0.0096, 0.0031, 0.0133, 0.0078, 0.0154, 0.0471, 0.0270, 0.1577,
        0.0364, 0.1769, 0.2682, 0.2089], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:43,164][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ hospital] are: tensor([0.8087, 0.0198, 0.0107, 0.0049, 0.0225, 0.0157, 0.0031, 0.0110, 0.0162,
        0.0131, 0.0142, 0.0095, 0.0507], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:43,165][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ hospital] are: tensor([0.6271, 0.0458, 0.0213, 0.0155, 0.0412, 0.0276, 0.0145, 0.0279, 0.0251,
        0.0278, 0.0353, 0.0385, 0.0523], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:43,167][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ hospital] are: tensor([0.0082, 0.0349, 0.0232, 0.0794, 0.0375, 0.0319, 0.0593, 0.0332, 0.1390,
        0.0691, 0.1516, 0.1719, 0.1607], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:43,168][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ hospital] are: tensor([0.0382, 0.0075, 0.0046, 0.0083, 0.0134, 0.0203, 0.0125, 0.0430, 0.1672,
        0.0634, 0.1558, 0.1049, 0.3609], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:43,170][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ hospital] are: tensor([0.0146, 0.0040, 0.0042, 0.0089, 0.0083, 0.0164, 0.0221, 0.0307, 0.1268,
        0.0461, 0.1002, 0.1026, 0.5150], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:43,171][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ hospital] are: tensor([4.5815e-05, 5.2136e-03, 2.6609e-02, 1.5894e-01, 7.2318e-02, 3.9465e-02,
        3.1965e-01, 4.8723e-02, 1.1744e-01, 2.7142e-02, 7.4249e-02, 8.8457e-02,
        2.1754e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:43,172][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ hospital] are: tensor([0.1403, 0.0449, 0.0490, 0.0535, 0.0653, 0.0750, 0.0607, 0.0708, 0.0874,
        0.0904, 0.0834, 0.0963, 0.0830], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:43,174][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.0189, 0.0014, 0.0010, 0.0024, 0.0043, 0.0090, 0.0055, 0.0177, 0.0703,
        0.0505, 0.0431, 0.0324, 0.5498, 0.1935], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:43,175][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.2848, 0.0369, 0.0347, 0.0361, 0.0645, 0.1466, 0.0277, 0.0760, 0.0546,
        0.0491, 0.0382, 0.0449, 0.0695, 0.0364], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:43,176][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([1.3720e-05, 7.4377e-03, 1.6417e-02, 2.3998e-01, 5.2058e-02, 1.8115e-02,
        2.2864e-01, 6.7452e-03, 1.5099e-01, 4.5281e-02, 7.9580e-02, 8.5088e-02,
        2.5540e-02, 4.4114e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:43,178][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.4199, 0.0091, 0.0020, 0.0046, 0.0070, 0.0193, 0.0091, 0.0217, 0.0434,
        0.0401, 0.0488, 0.0550, 0.1846, 0.1355], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:43,179][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.0354, 0.0113, 0.0032, 0.0162, 0.0070, 0.0132, 0.0333, 0.0317, 0.1122,
        0.0301, 0.1226, 0.1538, 0.1496, 0.2805], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:43,180][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([9.2136e-01, 9.0356e-03, 3.5872e-03, 1.0784e-03, 1.0978e-02, 7.4274e-03,
        7.1341e-04, 3.4453e-03, 4.7332e-03, 5.3706e-03, 3.5036e-03, 3.2940e-03,
        2.1839e-02, 3.6368e-03], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:43,182][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.6389, 0.0355, 0.0160, 0.0126, 0.0396, 0.0278, 0.0115, 0.0284, 0.0186,
        0.0267, 0.0297, 0.0263, 0.0528, 0.0357], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:43,183][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0085, 0.0244, 0.0138, 0.0821, 0.0439, 0.0412, 0.0600, 0.0363, 0.1005,
        0.0800, 0.1108, 0.1314, 0.1524, 0.1147], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:43,185][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.0409, 0.0101, 0.0046, 0.0076, 0.0149, 0.0137, 0.0075, 0.0404, 0.0869,
        0.0537, 0.1320, 0.0523, 0.2748, 0.2607], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:43,186][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.0228, 0.0046, 0.0044, 0.0067, 0.0095, 0.0108, 0.0147, 0.0289, 0.0744,
        0.0237, 0.0784, 0.0647, 0.4114, 0.2451], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:43,187][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([2.2963e-05, 4.7825e-03, 3.2741e-02, 9.7891e-02, 8.3783e-02, 3.3632e-02,
        3.9336e-01, 1.8332e-02, 1.3519e-01, 8.5207e-03, 4.5523e-02, 6.7249e-02,
        3.6014e-02, 4.2959e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:43,189][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.2983, 0.0362, 0.0379, 0.0263, 0.0860, 0.0480, 0.0427, 0.0645, 0.0361,
        0.0748, 0.0428, 0.0556, 0.0780, 0.0727], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:43,190][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Anthony] are: tensor([8.1634e-03, 3.9713e-04, 2.1890e-04, 3.4549e-04, 4.9136e-04, 1.8325e-03,
        1.2837e-03, 3.9750e-03, 2.8584e-02, 1.4389e-02, 2.1136e-02, 1.7183e-02,
        3.0451e-01, 1.3081e-01, 4.6668e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:43,191][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Anthony] are: tensor([0.1670, 0.0357, 0.0510, 0.0469, 0.0738, 0.1099, 0.0282, 0.1083, 0.0518,
        0.0469, 0.0278, 0.0366, 0.0607, 0.0380, 0.1174], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:43,192][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Anthony] are: tensor([7.3706e-06, 8.4325e-03, 1.5412e-02, 2.1525e-01, 3.9910e-02, 2.1450e-02,
        1.3041e-01, 1.2455e-02, 1.7511e-01, 4.9907e-02, 5.7939e-02, 9.1025e-02,
        2.7211e-02, 9.6761e-02, 5.8712e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:43,194][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Anthony] are: tensor([0.2245, 0.0050, 0.0013, 0.0025, 0.0033, 0.0124, 0.0056, 0.0120, 0.0303,
        0.0260, 0.0325, 0.0450, 0.1843, 0.1652, 0.2501], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:43,195][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Anthony] are: tensor([0.0283, 0.0046, 0.0013, 0.0041, 0.0032, 0.0052, 0.0142, 0.0144, 0.0752,
        0.0172, 0.0846, 0.1197, 0.1332, 0.2088, 0.2861], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:43,197][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Anthony] are: tensor([0.7808, 0.0218, 0.0093, 0.0021, 0.0126, 0.0125, 0.0021, 0.0067, 0.0121,
        0.0096, 0.0088, 0.0082, 0.0588, 0.0119, 0.0426], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:43,198][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Anthony] are: tensor([0.5905, 0.0410, 0.0235, 0.0125, 0.0415, 0.0295, 0.0115, 0.0219, 0.0166,
        0.0277, 0.0216, 0.0257, 0.0569, 0.0371, 0.0424], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:43,200][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Anthony] are: tensor([0.0088, 0.0287, 0.0136, 0.0678, 0.0333, 0.0261, 0.0297, 0.0447, 0.0982,
        0.0845, 0.0822, 0.1098, 0.1362, 0.1728, 0.0636], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:43,201][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Anthony] are: tensor([0.0106, 0.0020, 0.0011, 0.0018, 0.0031, 0.0035, 0.0024, 0.0085, 0.0280,
        0.0161, 0.0412, 0.0251, 0.1903, 0.2119, 0.4547], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:43,202][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Anthony] are: tensor([0.0095, 0.0017, 0.0011, 0.0019, 0.0021, 0.0052, 0.0046, 0.0094, 0.0366,
        0.0161, 0.0357, 0.0329, 0.2195, 0.1892, 0.4345], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:43,202][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Anthony] are: tensor([1.1332e-04, 6.8390e-03, 9.2061e-03, 6.7864e-02, 5.2114e-02, 3.0071e-02,
        1.3816e-01, 4.1609e-02, 1.4623e-01, 3.1938e-02, 7.2631e-02, 1.0708e-01,
        6.7577e-02, 1.4202e-01, 8.6540e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:43,203][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Anthony] are: tensor([0.2131, 0.0241, 0.0291, 0.0166, 0.0567, 0.0564, 0.0328, 0.0520, 0.0452,
        0.0823, 0.0609, 0.0683, 0.1014, 0.0821, 0.0791], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:43,203][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([3.5533e-03, 4.0376e-04, 2.4510e-04, 6.3527e-04, 1.1133e-03, 2.6939e-03,
        1.3032e-03, 6.3096e-03, 3.1813e-02, 1.4269e-02, 2.4691e-02, 1.3355e-02,
        2.5541e-01, 9.5356e-02, 4.3052e-01, 1.1832e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:43,204][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0402, 0.0435, 0.0643, 0.0603, 0.0740, 0.0877, 0.0632, 0.0629, 0.0655,
        0.0907, 0.0602, 0.0548, 0.0569, 0.0649, 0.0776, 0.0333],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:43,204][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([4.2907e-06, 1.1674e-02, 1.0757e-02, 1.3100e-01, 2.3786e-02, 9.1347e-03,
        2.0734e-01, 6.8174e-03, 2.0009e-01, 8.2900e-02, 9.7066e-02, 9.1896e-02,
        2.2934e-02, 7.1384e-02, 2.9250e-02, 3.9688e-03], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:43,205][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.0587, 0.0048, 0.0018, 0.0037, 0.0052, 0.0096, 0.0093, 0.0156, 0.0478,
        0.0404, 0.0468, 0.0464, 0.1743, 0.1368, 0.2702, 0.1285],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:43,206][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.0114, 0.0030, 0.0014, 0.0048, 0.0032, 0.0071, 0.0173, 0.0130, 0.0740,
        0.0191, 0.0698, 0.1017, 0.0994, 0.1497, 0.2562, 0.1691],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:43,207][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.4718, 0.0251, 0.0144, 0.0071, 0.0283, 0.0216, 0.0054, 0.0190, 0.0378,
        0.0328, 0.0265, 0.0241, 0.1412, 0.0306, 0.0739, 0.0404],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:43,209][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.2565, 0.0558, 0.0328, 0.0291, 0.0533, 0.0482, 0.0246, 0.0507, 0.0458,
        0.0390, 0.0484, 0.0445, 0.0798, 0.0717, 0.0663, 0.0535],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:43,210][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0042, 0.0151, 0.0144, 0.0356, 0.0327, 0.0252, 0.0453, 0.0308, 0.0763,
        0.0939, 0.1107, 0.1182, 0.1828, 0.1065, 0.0699, 0.0384],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:43,211][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.0046, 0.0022, 0.0011, 0.0020, 0.0046, 0.0028, 0.0030, 0.0092, 0.0353,
        0.0208, 0.0450, 0.0240, 0.1716, 0.1610, 0.4232, 0.0895],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:43,213][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.0019, 0.0017, 0.0025, 0.0051, 0.0061, 0.0053, 0.0114, 0.0083, 0.0470,
        0.0169, 0.0284, 0.0347, 0.1339, 0.1211, 0.4958, 0.0801],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:43,214][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([4.0731e-05, 9.0683e-03, 1.9470e-02, 8.6106e-02, 3.7822e-02, 2.5830e-02,
        3.3273e-01, 1.1749e-02, 1.4359e-01, 2.5170e-02, 6.5127e-02, 9.8765e-02,
        3.7092e-02, 6.4343e-02, 3.7896e-02, 5.2079e-03], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:43,215][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.0428, 0.0195, 0.0361, 0.0255, 0.0608, 0.0558, 0.0731, 0.0846, 0.0731,
        0.0883, 0.0592, 0.0819, 0.0686, 0.0872, 0.0780, 0.0655],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:43,216][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([5.0551e-03, 3.3784e-04, 1.5705e-04, 3.0636e-04, 7.6055e-04, 2.4145e-03,
        4.9367e-04, 4.8387e-03, 1.3534e-02, 1.3908e-02, 9.9180e-03, 6.4735e-03,
        2.2991e-01, 8.2079e-02, 3.5095e-01, 2.1416e-01, 6.4700e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:43,218][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.2170, 0.0269, 0.0350, 0.0355, 0.0528, 0.0968, 0.0251, 0.0622, 0.0516,
        0.0585, 0.0383, 0.0466, 0.0545, 0.0312, 0.0904, 0.0603, 0.0172],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:43,219][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([1.5033e-05, 6.5805e-03, 1.0704e-02, 1.4745e-01, 2.7123e-02, 1.3528e-02,
        1.0732e-01, 1.3109e-02, 1.7346e-01, 8.5666e-02, 1.0627e-01, 8.1552e-02,
        3.6231e-02, 5.7524e-02, 3.8363e-02, 1.0426e-02, 8.4681e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:43,220][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.1678, 0.0044, 0.0008, 0.0020, 0.0031, 0.0074, 0.0036, 0.0125, 0.0252,
        0.0320, 0.0269, 0.0301, 0.1362, 0.1227, 0.1729, 0.1419, 0.1104],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:43,222][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0288, 0.0028, 0.0008, 0.0026, 0.0020, 0.0044, 0.0077, 0.0095, 0.0436,
        0.0150, 0.0495, 0.0578, 0.0768, 0.1068, 0.1774, 0.1790, 0.2355],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:43,223][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([8.2120e-01, 9.1549e-03, 4.1013e-03, 1.3868e-03, 9.1388e-03, 6.5959e-03,
        6.5127e-04, 5.6278e-03, 7.7717e-03, 1.0668e-02, 7.1762e-03, 5.7734e-03,
        3.9711e-02, 9.4400e-03, 2.4285e-02, 3.4270e-02, 3.0477e-03],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:43,224][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.6502, 0.0259, 0.0129, 0.0101, 0.0255, 0.0225, 0.0082, 0.0268, 0.0146,
        0.0204, 0.0204, 0.0177, 0.0435, 0.0290, 0.0266, 0.0329, 0.0126],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:43,226][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0120, 0.0218, 0.0149, 0.0470, 0.0355, 0.0238, 0.0275, 0.0316, 0.0632,
        0.0922, 0.0797, 0.0957, 0.1932, 0.0993, 0.0491, 0.0505, 0.0631],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:43,227][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0083, 0.0020, 0.0007, 0.0012, 0.0034, 0.0018, 0.0008, 0.0077, 0.0207,
        0.0135, 0.0256, 0.0103, 0.1170, 0.1350, 0.3514, 0.2399, 0.0605],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:43,229][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0035, 0.0010, 0.0011, 0.0018, 0.0025, 0.0032, 0.0036, 0.0067, 0.0329,
        0.0101, 0.0239, 0.0253, 0.1809, 0.1209, 0.4146, 0.0831, 0.0850],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:43,230][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([4.6003e-05, 7.6033e-03, 2.0572e-02, 1.1586e-01, 4.4387e-02, 3.4793e-02,
        1.8489e-01, 5.0530e-02, 1.0092e-01, 2.4060e-02, 5.8701e-02, 7.3969e-02,
        5.8315e-02, 8.6819e-02, 6.8112e-02, 1.8774e-02, 5.1649e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:43,231][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.1544, 0.0442, 0.0350, 0.0268, 0.0403, 0.0373, 0.0231, 0.0610, 0.0411,
        0.0773, 0.0419, 0.0636, 0.0834, 0.0793, 0.0826, 0.0637, 0.0449],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:43,232][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ drink] are: tensor([1.4213e-03, 1.2492e-04, 1.2508e-04, 2.9731e-04, 4.2907e-04, 1.6199e-03,
        1.2758e-03, 3.0052e-03, 2.6023e-02, 9.2913e-03, 1.3439e-02, 1.3737e-02,
        1.7879e-01, 5.8968e-02, 3.5070e-01, 1.3425e-01, 1.2671e-01, 7.9795e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:43,234][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ drink] are: tensor([0.0648, 0.0451, 0.0407, 0.0520, 0.0567, 0.0464, 0.0384, 0.0633, 0.0850,
        0.0699, 0.0584, 0.0668, 0.0617, 0.0515, 0.0940, 0.0408, 0.0250, 0.0393],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:43,235][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ drink] are: tensor([9.9026e-06, 5.7418e-03, 1.4748e-02, 1.2547e-01, 2.2539e-02, 1.3029e-02,
        2.3833e-01, 9.7239e-03, 2.1152e-01, 3.0770e-02, 8.4528e-02, 6.0363e-02,
        1.2236e-02, 5.5133e-02, 1.7520e-02, 5.6030e-03, 8.7993e-02, 4.7344e-03],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:43,236][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ drink] are: tensor([0.0777, 0.0037, 0.0011, 0.0020, 0.0031, 0.0068, 0.0048, 0.0096, 0.0302,
        0.0255, 0.0282, 0.0291, 0.1384, 0.1284, 0.2073, 0.1137, 0.1019, 0.0886],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:43,238][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ drink] are: tensor([0.0082, 0.0025, 0.0010, 0.0032, 0.0022, 0.0046, 0.0105, 0.0070, 0.0470,
        0.0136, 0.0374, 0.0642, 0.0718, 0.0889, 0.1722, 0.1218, 0.2707, 0.0732],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:43,239][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ drink] are: tensor([0.6346, 0.0198, 0.0136, 0.0037, 0.0306, 0.0139, 0.0042, 0.0103, 0.0167,
        0.0148, 0.0084, 0.0101, 0.0705, 0.0157, 0.0545, 0.0556, 0.0106, 0.0127],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:43,241][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ drink] are: tensor([0.4173, 0.0456, 0.0269, 0.0142, 0.0470, 0.0274, 0.0126, 0.0367, 0.0268,
        0.0359, 0.0227, 0.0258, 0.0783, 0.0355, 0.0569, 0.0391, 0.0195, 0.0317],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:43,242][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ drink] are: tensor([0.0073, 0.0222, 0.0167, 0.0372, 0.0277, 0.0248, 0.0461, 0.0423, 0.0865,
        0.0776, 0.0910, 0.0931, 0.1040, 0.0959, 0.0539, 0.0568, 0.0803, 0.0366],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:43,244][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ drink] are: tensor([0.0049, 0.0016, 0.0007, 0.0010, 0.0019, 0.0016, 0.0017, 0.0062, 0.0234,
        0.0110, 0.0255, 0.0219, 0.1348, 0.1310, 0.3207, 0.0869, 0.0982, 0.1269],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:43,245][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ drink] are: tensor([0.0035, 0.0013, 0.0011, 0.0023, 0.0030, 0.0036, 0.0057, 0.0063, 0.0309,
        0.0126, 0.0228, 0.0253, 0.1549, 0.1112, 0.3373, 0.0749, 0.1191, 0.0843],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:43,246][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ drink] are: tensor([1.2058e-04, 3.3730e-03, 1.4643e-02, 4.1266e-02, 5.7178e-02, 2.5177e-02,
        3.0311e-01, 2.4514e-02, 1.5354e-01, 1.3140e-02, 6.2101e-02, 6.4773e-02,
        3.3693e-02, 5.5222e-02, 4.4393e-02, 1.4531e-02, 8.1882e-02, 7.3388e-03],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:43,248][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ drink] are: tensor([0.0919, 0.0287, 0.0343, 0.0178, 0.0718, 0.0442, 0.0602, 0.0802, 0.0591,
        0.0465, 0.0492, 0.0440, 0.0485, 0.0685, 0.0601, 0.0741, 0.0750, 0.0458],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:43,249][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([1.0012e-02, 2.9155e-04, 1.2716e-04, 9.9848e-05, 3.9934e-04, 9.0629e-04,
        3.3699e-04, 2.3406e-03, 4.2294e-03, 8.0512e-03, 2.7607e-03, 3.6012e-03,
        1.1894e-01, 4.0213e-02, 2.4411e-01, 1.4074e-01, 4.4789e-02, 1.6671e-01,
        2.1134e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:43,251][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.2020, 0.0377, 0.0345, 0.0334, 0.0474, 0.0704, 0.0214, 0.0666, 0.0466,
        0.0524, 0.0352, 0.0408, 0.0556, 0.0306, 0.0810, 0.0743, 0.0159, 0.0376,
        0.0164], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:43,252][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([1.0960e-05, 6.0672e-03, 1.3550e-02, 1.4484e-01, 2.0522e-02, 1.0277e-02,
        1.7351e-01, 8.4990e-03, 1.4447e-01, 4.2661e-02, 5.5451e-02, 6.8504e-02,
        1.5028e-02, 4.6796e-02, 2.8953e-02, 8.1195e-03, 1.2414e-01, 1.1869e-02,
        7.6727e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:43,253][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.2471, 0.0041, 0.0006, 0.0014, 0.0024, 0.0054, 0.0031, 0.0096, 0.0155,
        0.0187, 0.0216, 0.0209, 0.0829, 0.0752, 0.1052, 0.1145, 0.0882, 0.0558,
        0.1277], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:43,255][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0346, 0.0028, 0.0006, 0.0018, 0.0016, 0.0035, 0.0049, 0.0048, 0.0264,
        0.0085, 0.0237, 0.0354, 0.0816, 0.0783, 0.0912, 0.1289, 0.1552, 0.0504,
        0.2657], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:43,256][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([8.6142e-01, 9.2897e-03, 3.9280e-03, 8.4259e-04, 7.9256e-03, 4.4704e-03,
        6.1715e-04, 3.3926e-03, 4.3000e-03, 5.0539e-03, 3.3969e-03, 3.6533e-03,
        3.1191e-02, 5.6067e-03, 1.7300e-02, 2.4672e-02, 2.1895e-03, 5.1778e-03,
        5.5736e-03], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:43,257][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.6885, 0.0277, 0.0120, 0.0077, 0.0212, 0.0170, 0.0060, 0.0193, 0.0104,
        0.0143, 0.0141, 0.0144, 0.0394, 0.0207, 0.0247, 0.0240, 0.0094, 0.0151,
        0.0141], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:43,259][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0187, 0.0220, 0.0178, 0.0437, 0.0393, 0.0308, 0.0357, 0.0336, 0.0498,
        0.0762, 0.0685, 0.0849, 0.1558, 0.0617, 0.0400, 0.0511, 0.0807, 0.0401,
        0.0497], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:43,260][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0089, 0.0019, 0.0005, 0.0005, 0.0020, 0.0011, 0.0006, 0.0040, 0.0077,
        0.0078, 0.0115, 0.0072, 0.0714, 0.0723, 0.2099, 0.1608, 0.0463, 0.2058,
        0.1797], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:43,260][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0049, 0.0010, 0.0010, 0.0012, 0.0020, 0.0025, 0.0033, 0.0050, 0.0168,
        0.0073, 0.0144, 0.0167, 0.1254, 0.0744, 0.2742, 0.0540, 0.0727, 0.0625,
        0.2607], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:43,261][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([5.4846e-05, 7.6238e-03, 2.9140e-02, 8.2808e-02, 4.0545e-02, 3.0917e-02,
        3.3035e-01, 2.1407e-02, 9.6159e-02, 1.1382e-02, 2.9506e-02, 6.3427e-02,
        2.7847e-02, 5.2608e-02, 5.7971e-02, 1.5630e-02, 6.7296e-02, 1.5983e-02,
        1.9345e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:43,261][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.2258, 0.0299, 0.0314, 0.0186, 0.0491, 0.0440, 0.0394, 0.0481, 0.0290,
        0.0598, 0.0332, 0.0495, 0.0534, 0.0534, 0.0454, 0.0535, 0.0631, 0.0373,
        0.0359], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:43,263][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:21:43,264][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[5886],
        [ 293],
        [ 248],
        [ 104],
        [4258],
        [ 465],
        [ 112],
        [ 887],
        [ 413],
        [1471],
        [ 996],
        [ 615],
        [ 180],
        [ 126],
        [ 433],
        [ 503],
        [ 323],
        [ 191],
        [ 217]], device='cuda:0')
[2024-07-24 10:21:43,266][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 6329],
        [ 1139],
        [ 3018],
        [ 1205],
        [20852],
        [ 3314],
        [ 1358],
        [ 8751],
        [ 3815],
        [11251],
        [ 9240],
        [ 5761],
        [ 1256],
        [ 1245],
        [ 5148],
        [ 4193],
        [ 3742],
        [ 1617],
        [ 2084]], device='cuda:0')
[2024-07-24 10:21:43,267][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[43250],
        [44858],
        [40899],
        [37424],
        [44291],
        [46906],
        [43412],
        [37520],
        [43569],
        [43529],
        [44638],
        [43994],
        [48721],
        [49123],
        [47997],
        [47985],
        [47532],
        [45651],
        [45846]], device='cuda:0')
[2024-07-24 10:21:43,269][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[23005],
        [14891],
        [ 8308],
        [ 9654],
        [ 7746],
        [ 9736],
        [11195],
        [14486],
        [13964],
        [18027],
        [17304],
        [18953],
        [17937],
        [18466],
        [17531],
        [20253],
        [19944],
        [20392],
        [21051]], device='cuda:0')
[2024-07-24 10:21:43,270][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[16289],
        [ 1407],
        [ 1638],
        [ 1115],
        [ 8361],
        [ 4363],
        [ 3017],
        [ 1987],
        [ 1968],
        [ 1421],
        [ 1662],
        [ 1705],
        [ 1399],
        [ 1553],
        [ 1604],
        [ 1537],
        [ 1498],
        [ 1489],
        [ 1643]], device='cuda:0')
[2024-07-24 10:21:43,272][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[1532],
        [ 101],
        [  95],
        [ 123],
        [  85],
        [ 133],
        [ 131],
        [ 121],
        [ 133],
        [ 136],
        [ 131],
        [ 132],
        [ 139],
        [ 136],
        [ 147],
        [ 162],
        [ 167],
        [ 172],
        [ 168]], device='cuda:0')
[2024-07-24 10:21:43,273][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[ 4879],
        [ 4895],
        [ 8020],
        [ 5038],
        [ 6269],
        [ 5903],
        [16286],
        [ 8541],
        [11668],
        [15208],
        [17770],
        [20796],
        [15115],
        [16062],
        [20016],
        [18354],
        [20948],
        [20644],
        [18491]], device='cuda:0')
[2024-07-24 10:21:43,275][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[23325],
        [22620],
        [20092],
        [19144],
        [20628],
        [20377],
        [20163],
        [20853],
        [20972],
        [21169],
        [20071],
        [20142],
        [20930],
        [19702],
        [20510],
        [20111],
        [19513],
        [19732],
        [19345]], device='cuda:0')
[2024-07-24 10:21:43,276][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[ 790],
        [1136],
        [ 768],
        [ 704],
        [ 499],
        [ 428],
        [ 358],
        [ 349],
        [ 313],
        [ 279],
        [ 258],
        [ 233],
        [ 231],
        [ 226],
        [ 217],
        [ 216],
        [ 210],
        [ 209],
        [ 203]], device='cuda:0')
[2024-07-24 10:21:43,278][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[39968],
        [20796],
        [14269],
        [16386],
        [15277],
        [20927],
        [21870],
        [21588],
        [21456],
        [22027],
        [24041],
        [23361],
        [23110],
        [23826],
        [22787],
        [24569],
        [25089],
        [25816],
        [26871]], device='cuda:0')
[2024-07-24 10:21:43,279][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[31087],
        [36373],
        [29882],
        [32210],
        [29581],
        [33912],
        [34601],
        [37613],
        [36780],
        [38411],
        [37785],
        [38564],
        [39244],
        [38872],
        [37229],
        [37949],
        [38104],
        [38468],
        [39194]], device='cuda:0')
[2024-07-24 10:21:43,281][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[36037],
        [30630],
        [34739],
        [32494],
        [28553],
        [29122],
        [28610],
        [28161],
        [28177],
        [28563],
        [28515],
        [29031],
        [29546],
        [29738],
        [30277],
        [30423],
        [30248],
        [30388],
        [30037]], device='cuda:0')
[2024-07-24 10:21:43,283][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[ 4576],
        [ 5728],
        [ 3766],
        [ 3700],
        [36061],
        [23368],
        [29986],
        [21557],
        [23237],
        [24811],
        [21018],
        [29209],
        [24662],
        [28150],
        [16901],
        [17396],
        [16985],
        [23898],
        [19636]], device='cuda:0')
[2024-07-24 10:21:43,284][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[25544],
        [20943],
        [ 3652],
        [ 3634],
        [ 3563],
        [10329],
        [ 6505],
        [ 2736],
        [ 7849],
        [ 2331],
        [ 3498],
        [ 4528],
        [ 3817],
        [ 4910],
        [ 4791],
        [ 3091],
        [ 5486],
        [ 2448],
        [ 3826]], device='cuda:0')
[2024-07-24 10:21:43,285][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 5394],
        [11363],
        [15300],
        [11993],
        [ 4287],
        [ 9173],
        [10982],
        [ 9364],
        [ 9875],
        [15788],
        [ 9967],
        [11698],
        [ 9285],
        [10088],
        [ 8136],
        [14163],
        [13742],
        [13588],
        [12333]], device='cuda:0')
[2024-07-24 10:21:43,287][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[20046],
        [16034],
        [16962],
        [19529],
        [22568],
        [33621],
        [33747],
        [31906],
        [27325],
        [25820],
        [29944],
        [26965],
        [17954],
        [14664],
        [12371],
        [11194],
        [11305],
        [14802],
        [15457]], device='cuda:0')
[2024-07-24 10:21:43,289][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[19377],
        [11095],
        [ 4482],
        [ 4172],
        [ 2025],
        [ 1939],
        [ 1818],
        [ 2388],
        [ 2215],
        [ 2278],
        [ 2437],
        [ 2379],
        [ 3480],
        [ 3112],
        [ 2790],
        [ 3018],
        [ 3001],
        [ 3587],
        [ 3470]], device='cuda:0')
[2024-07-24 10:21:43,290][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[18021],
        [44551],
        [36264],
        [43885],
        [43274],
        [44197],
        [47489],
        [48934],
        [49015],
        [48886],
        [48792],
        [47531],
        [48232],
        [48108],
        [47021],
        [47840],
        [47717],
        [48739],
        [48299]], device='cuda:0')
[2024-07-24 10:21:43,291][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[16511],
        [ 6604],
        [ 5935],
        [ 6835],
        [ 8600],
        [ 2791],
        [ 3144],
        [ 2876],
        [ 1682],
        [ 1960],
        [ 2369],
        [ 2444],
        [  957],
        [ 2094],
        [ 3151],
        [ 2329],
        [ 1933],
        [ 2298],
        [ 2203]], device='cuda:0')
[2024-07-24 10:21:43,293][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[30153],
        [44245],
        [43127],
        [42762],
        [42507],
        [38850],
        [37184],
        [39157],
        [42001],
        [41625],
        [42672],
        [41884],
        [39246],
        [40317],
        [41101],
        [40296],
        [40765],
        [40913],
        [40120]], device='cuda:0')
[2024-07-24 10:21:43,295][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[26435],
        [23343],
        [19395],
        [24475],
        [20428],
        [14102],
        [19470],
        [12882],
        [17815],
        [13336],
        [17616],
        [17193],
        [12662],
        [19782],
        [10284],
        [11045],
        [15375],
        [ 9853],
        [17575]], device='cuda:0')
[2024-07-24 10:21:43,296][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[47720],
        [49320],
        [49252],
        [48980],
        [48954],
        [47566],
        [48626],
        [46803],
        [48365],
        [45521],
        [47985],
        [46510],
        [47059],
        [46949],
        [46827],
        [43581],
        [45972],
        [45122],
        [46646]], device='cuda:0')
[2024-07-24 10:21:43,297][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[30361],
        [ 7847],
        [ 6266],
        [ 8067],
        [ 6962],
        [ 6133],
        [ 6662],
        [ 7348],
        [ 8749],
        [ 9161],
        [ 8668],
        [10606],
        [14640],
        [13581],
        [13346],
        [14443],
        [14454],
        [13235],
        [13906]], device='cuda:0')
[2024-07-24 10:21:43,299][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[44532],
        [39041],
        [36363],
        [40442],
        [32713],
        [33643],
        [34398],
        [26699],
        [38454],
        [39305],
        [34077],
        [31543],
        [33772],
        [34198],
        [22459],
        [25213],
        [29432],
        [23103],
        [26889]], device='cuda:0')
[2024-07-24 10:21:43,301][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[34070],
        [32903],
        [36483],
        [42505],
        [34823],
        [31753],
        [32692],
        [36651],
        [35485],
        [35119],
        [31965],
        [31804],
        [35227],
        [34260],
        [38418],
        [39472],
        [38595],
        [36365],
        [35410]], device='cuda:0')
[2024-07-24 10:21:43,302][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[44872],
        [24222],
        [31894],
        [42980],
        [41813],
        [43104],
        [42503],
        [42991],
        [40593],
        [40425],
        [40119],
        [38248],
        [38029],
        [37816],
        [33739],
        [36109],
        [36157],
        [34514],
        [36458]], device='cuda:0')
[2024-07-24 10:21:43,303][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[37005],
        [32047],
        [34484],
        [33683],
        [32636],
        [28596],
        [31262],
        [25742],
        [29643],
        [25167],
        [25561],
        [24447],
        [20585],
        [23262],
        [21172],
        [20751],
        [20479],
        [19822],
        [19935]], device='cuda:0')
[2024-07-24 10:21:43,305][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[ 3526],
        [ 6450],
        [ 9195],
        [ 5027],
        [ 9103],
        [12348],
        [ 9410],
        [12257],
        [ 8262],
        [11025],
        [10062],
        [12863],
        [14204],
        [12268],
        [16629],
        [16689],
        [14230],
        [16602],
        [14381]], device='cuda:0')
[2024-07-24 10:21:43,307][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[38575],
        [24471],
        [27126],
        [20048],
        [33622],
        [31508],
        [24759],
        [23343],
        [23842],
        [17848],
        [20387],
        [21173],
        [25830],
        [22504],
        [31607],
        [25481],
        [23601],
        [22943],
        [18946]], device='cuda:0')
[2024-07-24 10:21:43,308][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[9884],
        [9884],
        [9884],
        [9884],
        [9884],
        [9884],
        [9884],
        [9884],
        [9884],
        [9884],
        [9884],
        [9884],
        [9884],
        [9884],
        [9884],
        [9884],
        [9884],
        [9884],
        [9884]], device='cuda:0')
[2024-07-24 10:21:43,370][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:21:43,372][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:43,373][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:43,374][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:43,375][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:43,376][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:43,377][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:43,378][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:43,379][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:43,381][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:43,381][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:43,381][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:43,382][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:43,382][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.2253, 0.7747], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:43,382][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0796, 0.9204], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:43,383][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.5085, 0.4915], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:43,383][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.7999, 0.2001], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:43,383][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.1415, 0.8585], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:43,384][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.5304, 0.4696], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:43,384][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0357, 0.9643], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:43,385][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [,] are: tensor([9.9994e-01, 5.7245e-05], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:43,386][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.2249, 0.7751], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:43,387][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0958, 0.9042], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:43,389][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.4323, 0.5677], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:43,390][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.3942, 0.6058], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:43,391][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Anthony] are: tensor([0.1826, 0.6924, 0.1250], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:43,393][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Anthony] are: tensor([0.0485, 0.2692, 0.6823], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:43,394][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Anthony] are: tensor([0.4019, 0.3401, 0.2580], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:43,396][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Anthony] are: tensor([0.3912, 0.0926, 0.5163], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:43,397][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Anthony] are: tensor([0.0405, 0.2380, 0.7215], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:43,398][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Anthony] are: tensor([0.4070, 0.0949, 0.4981], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:43,400][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Anthony] are: tensor([0.0319, 0.4709, 0.4972], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:43,401][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Anthony] are: tensor([9.9938e-01, 4.1115e-04, 2.1236e-04], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:43,402][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Anthony] are: tensor([0.0903, 0.3676, 0.5421], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:43,403][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Anthony] are: tensor([0.0594, 0.5148, 0.4258], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:43,405][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Anthony] are: tensor([0.3835, 0.3861, 0.2304], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:43,406][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Anthony] are: tensor([0.1435, 0.1800, 0.6765], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:43,408][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.1458, 0.6771, 0.0505, 0.1266], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:43,409][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0149, 0.0982, 0.2704, 0.6165], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:43,410][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.3353, 0.2729, 0.1894, 0.2024], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:43,412][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.1273, 0.0284, 0.1441, 0.7002], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:43,413][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0162, 0.0616, 0.1465, 0.7757], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:43,415][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.2110, 0.0419, 0.0942, 0.6528], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:43,416][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0139, 0.2680, 0.3001, 0.4179], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:43,417][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ and] are: tensor([9.9972e-01, 1.1586e-04, 7.6456e-05, 9.0463e-05], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:43,418][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0926, 0.2349, 0.3437, 0.3288], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:43,420][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0406, 0.1718, 0.0720, 0.7156], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:43,421][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.5750, 0.1882, 0.0890, 0.1478], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:43,423][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.1470, 0.0632, 0.2257, 0.5641], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:43,424][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Travis] are: tensor([0.1247, 0.5827, 0.0613, 0.1570, 0.0743], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:43,425][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Travis] are: tensor([0.0186, 0.0773, 0.1869, 0.4810, 0.2361], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:43,427][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Travis] are: tensor([0.2461, 0.2228, 0.1630, 0.1595, 0.2086], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:43,428][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Travis] are: tensor([0.0874, 0.0180, 0.1119, 0.5436, 0.2390], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:43,430][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Travis] are: tensor([0.0045, 0.0343, 0.0920, 0.6570, 0.2122], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:43,431][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Travis] are: tensor([0.1421, 0.0222, 0.0445, 0.5656, 0.2257], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:43,432][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Travis] are: tensor([0.0123, 0.2073, 0.2105, 0.3299, 0.2400], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:43,433][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Travis] are: tensor([9.9989e-01, 4.2959e-05, 1.6654e-05, 3.3162e-05, 1.5148e-05],
       device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:43,435][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Travis] are: tensor([0.0484, 0.1897, 0.2452, 0.2609, 0.2558], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:43,436][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Travis] are: tensor([0.0127, 0.1181, 0.0522, 0.6381, 0.1789], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:43,437][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Travis] are: tensor([0.3708, 0.2439, 0.0685, 0.1411, 0.1756], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:43,439][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Travis] are: tensor([0.0510, 0.0486, 0.1250, 0.3899, 0.3855], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:43,439][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.1109, 0.5951, 0.0530, 0.1414, 0.0676, 0.0320], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:43,440][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.0064, 0.0662, 0.1802, 0.3279, 0.2472, 0.1721], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:43,440][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.2000, 0.1797, 0.1375, 0.1346, 0.1749, 0.1733], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:43,440][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.0505, 0.0111, 0.0958, 0.5735, 0.2426, 0.0265], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:43,441][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.0022, 0.0244, 0.0518, 0.5274, 0.1409, 0.2533], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:43,441][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.1960, 0.0129, 0.0315, 0.3513, 0.1166, 0.2917], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:43,442][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.0064, 0.1627, 0.1903, 0.2571, 0.2097, 0.1738], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:43,442][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ had] are: tensor([9.9972e-01, 5.3963e-05, 3.1978e-05, 6.0212e-05, 5.2160e-05, 8.5302e-05],
       device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:43,444][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.0587, 0.1590, 0.1906, 0.2015, 0.2002, 0.1899], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:43,445][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.0172, 0.0851, 0.0421, 0.4895, 0.1460, 0.2200], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:43,446][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.2369, 0.1666, 0.0854, 0.1599, 0.1455, 0.2055], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:43,448][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0242, 0.0370, 0.1011, 0.3408, 0.2854, 0.2115], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:43,449][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ a] are: tensor([4.5544e-03, 1.7551e-02, 8.8506e-04, 2.4779e-03, 1.2422e-03, 5.7691e-04,
        9.7271e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:43,450][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0089, 0.0403, 0.1114, 0.2431, 0.1534, 0.1419, 0.3011],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:43,451][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.1786, 0.1627, 0.1121, 0.1161, 0.1437, 0.1530, 0.1338],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:43,453][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0535, 0.0130, 0.0982, 0.5468, 0.2119, 0.0293, 0.0472],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:43,454][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0027, 0.0189, 0.0357, 0.3048, 0.0781, 0.1682, 0.3917],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:43,455][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.1887, 0.0081, 0.0125, 0.1237, 0.0453, 0.1027, 0.5191],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:43,457][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0057, 0.1307, 0.1529, 0.2080, 0.1658, 0.1398, 0.1971],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:43,458][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ a] are: tensor([9.9976e-01, 3.9783e-05, 1.5850e-05, 3.3326e-05, 1.9210e-05, 2.5356e-05,
        1.0481e-04], device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:43,459][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0587, 0.1394, 0.1608, 0.1800, 0.1698, 0.1658, 0.1255],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:43,461][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0225, 0.0698, 0.0261, 0.2562, 0.0859, 0.1388, 0.4007],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:43,462][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.5390, 0.1220, 0.0410, 0.0547, 0.0757, 0.0992, 0.0684],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:43,463][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0429, 0.0323, 0.0470, 0.1562, 0.1459, 0.1353, 0.4404],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:43,464][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ lot] are: tensor([4.1252e-03, 1.5208e-02, 1.0031e-03, 2.8810e-03, 1.6202e-03, 6.0693e-04,
        9.7286e-01, 1.6972e-03], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:43,466][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ lot] are: tensor([0.0058, 0.0253, 0.0922, 0.2148, 0.1332, 0.1044, 0.3205, 0.1038],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:43,467][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ lot] are: tensor([0.1339, 0.1252, 0.1010, 0.1120, 0.1130, 0.1298, 0.1361, 0.1490],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:43,469][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ lot] are: tensor([0.0426, 0.0107, 0.1002, 0.5748, 0.1976, 0.0233, 0.0371, 0.0136],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:43,470][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ lot] are: tensor([0.0024, 0.0163, 0.0319, 0.2338, 0.0594, 0.1455, 0.3374, 0.1732],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:43,472][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ lot] are: tensor([0.0524, 0.0019, 0.0067, 0.0839, 0.0348, 0.0802, 0.6601, 0.0800],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:43,473][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ lot] are: tensor([0.0048, 0.0995, 0.1121, 0.1803, 0.1265, 0.1253, 0.1899, 0.1615],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:43,474][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ lot] are: tensor([9.9721e-01, 2.6071e-04, 6.5040e-05, 3.7809e-04, 1.0560e-04, 1.2979e-04,
        1.4505e-03, 4.0435e-04], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:43,475][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ lot] are: tensor([0.0612, 0.1151, 0.1424, 0.1597, 0.1443, 0.1410, 0.1143, 0.1221],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:43,477][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ lot] are: tensor([0.0094, 0.0296, 0.0125, 0.2058, 0.0531, 0.1387, 0.4815, 0.0694],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:43,478][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ lot] are: tensor([0.1561, 0.1311, 0.0517, 0.1132, 0.1089, 0.1444, 0.1477, 0.1469],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:43,480][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ lot] are: tensor([0.0159, 0.0127, 0.0360, 0.1064, 0.0711, 0.0845, 0.3693, 0.3040],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:43,481][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ of] are: tensor([1.2509e-02, 2.3632e-02, 1.1789e-03, 2.6244e-03, 2.3338e-03, 7.6677e-04,
        9.4484e-01, 1.5463e-03, 1.0569e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:43,482][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ of] are: tensor([0.0030, 0.0243, 0.0812, 0.1655, 0.1147, 0.0965, 0.2283, 0.1239, 0.1625],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:43,483][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ of] are: tensor([0.1203, 0.1366, 0.0915, 0.0921, 0.1113, 0.1061, 0.1134, 0.1154, 0.1133],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:43,485][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ of] are: tensor([0.0772, 0.0131, 0.0893, 0.5020, 0.1847, 0.0278, 0.0430, 0.0163, 0.0466],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:43,486][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ of] are: tensor([0.0027, 0.0159, 0.0214, 0.1700, 0.0351, 0.0670, 0.1746, 0.1137, 0.3996],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:43,488][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ of] are: tensor([0.1410, 0.0038, 0.0040, 0.0317, 0.0084, 0.0184, 0.1268, 0.0206, 0.6452],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:43,489][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ of] are: tensor([0.0035, 0.0969, 0.1119, 0.1455, 0.1197, 0.0954, 0.1353, 0.1423, 0.1495],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:43,490][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ of] are: tensor([9.9846e-01, 1.0255e-04, 3.4510e-05, 8.2443e-05, 4.8565e-05, 8.0789e-05,
        3.6679e-04, 2.5344e-04, 5.6978e-04], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:43,491][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ of] are: tensor([0.0405, 0.1079, 0.1281, 0.1348, 0.1416, 0.1252, 0.0997, 0.0904, 0.1318],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:43,493][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ of] are: tensor([0.0205, 0.0462, 0.0113, 0.2154, 0.0413, 0.0847, 0.3055, 0.0392, 0.2358],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:43,494][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ of] are: tensor([0.4733, 0.0876, 0.0250, 0.0363, 0.0497, 0.0586, 0.0371, 0.0532, 0.1791],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:43,496][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ of] are: tensor([0.0225, 0.0102, 0.0216, 0.0385, 0.0483, 0.0474, 0.1441, 0.1733, 0.4941],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:43,497][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ fun] are: tensor([0.0042, 0.0313, 0.0013, 0.0033, 0.0032, 0.0010, 0.9387, 0.0021, 0.0128,
        0.0021], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:43,497][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ fun] are: tensor([0.0030, 0.0254, 0.0787, 0.1556, 0.1020, 0.0855, 0.2248, 0.1019, 0.1429,
        0.0802], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:43,498][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ fun] are: tensor([0.1069, 0.1231, 0.0818, 0.0726, 0.1034, 0.1008, 0.0932, 0.1079, 0.0987,
        0.1115], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:43,498][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ fun] are: tensor([0.0591, 0.0097, 0.1013, 0.5191, 0.1926, 0.0216, 0.0325, 0.0113, 0.0328,
        0.0200], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:43,498][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ fun] are: tensor([0.0015, 0.0088, 0.0135, 0.1430, 0.0286, 0.0570, 0.1686, 0.0955, 0.3967,
        0.0868], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:43,499][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ fun] are: tensor([0.0698, 0.0010, 0.0017, 0.0214, 0.0041, 0.0098, 0.0923, 0.0163, 0.6677,
        0.1161], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:43,499][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ fun] are: tensor([0.0051, 0.0661, 0.0716, 0.1154, 0.0859, 0.0898, 0.1283, 0.1238, 0.1494,
        0.1645], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:43,500][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ fun] are: tensor([9.9464e-01, 1.9721e-04, 6.2987e-05, 2.3674e-04, 1.1919e-04, 1.2865e-04,
        1.2349e-03, 4.8006e-04, 2.7128e-03, 1.8362e-04], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:43,500][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ fun] are: tensor([0.0366, 0.0850, 0.1110, 0.1150, 0.1209, 0.1119, 0.0881, 0.0875, 0.1242,
        0.1199], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:43,501][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ fun] are: tensor([0.0044, 0.0313, 0.0094, 0.1561, 0.0385, 0.0930, 0.2421, 0.0478, 0.2630,
        0.1144], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:43,503][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ fun] are: tensor([0.1593, 0.0699, 0.0200, 0.0516, 0.0430, 0.0701, 0.0638, 0.0732, 0.1841,
        0.2650], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:43,504][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ fun] are: tensor([0.0062, 0.0061, 0.0117, 0.0437, 0.0249, 0.0378, 0.1145, 0.1029, 0.4898,
        0.1624], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:43,505][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ at] are: tensor([1.4309e-02, 4.0391e-02, 1.7586e-03, 2.9048e-03, 2.5715e-03, 6.3591e-04,
        9.2507e-01, 1.5565e-03, 9.7109e-03, 6.3631e-04, 4.5438e-04],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:43,506][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.0028, 0.0251, 0.0755, 0.1399, 0.0878, 0.0728, 0.2019, 0.1028, 0.1325,
        0.0905, 0.0685], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:43,508][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.1247, 0.1269, 0.0781, 0.0648, 0.0893, 0.0901, 0.0762, 0.0964, 0.0857,
        0.1003, 0.0675], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:43,509][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.0623, 0.0111, 0.1020, 0.5050, 0.1783, 0.0215, 0.0327, 0.0117, 0.0341,
        0.0219, 0.0194], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:43,511][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.0009, 0.0049, 0.0104, 0.1142, 0.0258, 0.0460, 0.1366, 0.0900, 0.3736,
        0.1012, 0.0963], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:43,512][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.0825, 0.0016, 0.0020, 0.0180, 0.0046, 0.0089, 0.0595, 0.0169, 0.3997,
        0.1049, 0.3014], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:43,513][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.0026, 0.0680, 0.0811, 0.1093, 0.0862, 0.0718, 0.1032, 0.1100, 0.1139,
        0.1576, 0.0963], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:43,514][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ at] are: tensor([9.6522e-01, 1.1993e-03, 6.1669e-04, 1.4277e-03, 6.7076e-04, 2.0031e-03,
        6.1144e-03, 3.9798e-03, 1.4256e-02, 1.7517e-03, 2.7603e-03],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:43,516][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.0245, 0.0765, 0.1165, 0.1096, 0.1258, 0.0956, 0.0788, 0.0741, 0.1039,
        0.1116, 0.0830], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:43,517][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.0124, 0.0363, 0.0126, 0.1636, 0.0378, 0.0800, 0.2014, 0.0408, 0.1863,
        0.0865, 0.1422], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:43,519][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.2410, 0.0660, 0.0203, 0.0307, 0.0364, 0.0480, 0.0314, 0.0518, 0.1338,
        0.1785, 0.1621], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:43,520][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.0102, 0.0044, 0.0092, 0.0154, 0.0197, 0.0182, 0.0619, 0.0772, 0.2674,
        0.1030, 0.4133], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:43,521][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ the] are: tensor([1.0625e-02, 3.3622e-02, 1.0361e-03, 2.5319e-03, 1.1742e-03, 6.4806e-04,
        6.5096e-01, 9.2250e-04, 7.9924e-03, 6.0306e-04, 4.7961e-04, 2.8941e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:43,523][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0038, 0.0187, 0.0648, 0.1328, 0.0745, 0.0664, 0.1725, 0.1037, 0.1239,
        0.0798, 0.0801, 0.0789], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:43,524][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0916, 0.1161, 0.0759, 0.0641, 0.0866, 0.0785, 0.0783, 0.0867, 0.0864,
        0.0976, 0.0703, 0.0680], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:43,525][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0558, 0.0101, 0.0993, 0.5146, 0.1840, 0.0194, 0.0290, 0.0104, 0.0314,
        0.0197, 0.0170, 0.0091], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:43,527][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0007, 0.0045, 0.0082, 0.1022, 0.0204, 0.0322, 0.1118, 0.0813, 0.3820,
        0.0912, 0.0859, 0.0796], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:43,528][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0396, 0.0005, 0.0010, 0.0113, 0.0031, 0.0061, 0.0485, 0.0112, 0.3527,
        0.0882, 0.3013, 0.1364], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:43,530][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0022, 0.0642, 0.0781, 0.1012, 0.0812, 0.0647, 0.0927, 0.0931, 0.1033,
        0.1424, 0.0894, 0.0874], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:43,531][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ the] are: tensor([9.8420e-01, 6.2510e-04, 2.1727e-04, 5.5117e-04, 3.7816e-04, 5.6491e-04,
        1.4710e-03, 1.5479e-03, 6.5056e-03, 6.6561e-04, 1.7211e-03, 1.5482e-03],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:43,532][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0261, 0.0767, 0.0944, 0.1005, 0.1030, 0.0949, 0.0661, 0.0681, 0.0966,
        0.1082, 0.0800, 0.0854], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:43,534][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0069, 0.0208, 0.0079, 0.1355, 0.0305, 0.0688, 0.2135, 0.0342, 0.1868,
        0.0713, 0.1186, 0.1052], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:43,535][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.1862, 0.0643, 0.0254, 0.0366, 0.0427, 0.0517, 0.0304, 0.0457, 0.1253,
        0.1493, 0.1283, 0.1141], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:43,537][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0070, 0.0050, 0.0132, 0.0196, 0.0270, 0.0201, 0.0653, 0.0700, 0.2094,
        0.0968, 0.3341, 0.1324], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:43,538][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ hospital] are: tensor([1.1592e-02, 2.5461e-02, 1.1823e-03, 2.1318e-03, 1.9684e-03, 5.1199e-04,
        6.4413e-01, 1.0686e-03, 8.7020e-03, 6.8887e-04, 5.7962e-04, 3.0078e-01,
        1.2115e-03], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:43,539][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ hospital] are: tensor([0.0045, 0.0185, 0.0550, 0.1240, 0.0683, 0.0590, 0.1828, 0.0913, 0.1199,
        0.0696, 0.0786, 0.0850, 0.0436], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:43,541][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ hospital] are: tensor([0.0967, 0.1081, 0.0635, 0.0634, 0.0797, 0.0738, 0.0658, 0.0852, 0.0726,
        0.0807, 0.0638, 0.0581, 0.0886], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:43,542][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ hospital] are: tensor([0.0516, 0.0089, 0.1032, 0.4934, 0.1958, 0.0181, 0.0277, 0.0099, 0.0313,
        0.0157, 0.0155, 0.0085, 0.0203], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:43,544][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ hospital] are: tensor([0.0021, 0.0051, 0.0087, 0.0889, 0.0168, 0.0313, 0.1036, 0.0691, 0.2909,
        0.0704, 0.0692, 0.0676, 0.1762], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:43,545][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ hospital] are: tensor([0.0758, 0.0006, 0.0006, 0.0069, 0.0012, 0.0032, 0.0282, 0.0068, 0.2094,
        0.0586, 0.1389, 0.0909, 0.3791], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:43,547][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ hospital] are: tensor([0.0040, 0.0490, 0.0546, 0.0835, 0.0638, 0.0645, 0.0909, 0.0898, 0.1047,
        0.1134, 0.0899, 0.0897, 0.1021], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:43,548][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ hospital] are: tensor([9.9597e-01, 1.2458e-04, 3.4669e-05, 1.1695e-04, 3.6428e-05, 8.7106e-05,
        4.9606e-04, 2.4057e-04, 1.6365e-03, 9.9699e-05, 3.9872e-04, 5.0266e-04,
        2.5386e-04], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:43,549][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ hospital] are: tensor([0.0142, 0.0642, 0.0818, 0.0819, 0.0903, 0.0897, 0.0695, 0.0633, 0.0939,
        0.0777, 0.0735, 0.0821, 0.1178], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:43,550][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ hospital] are: tensor([0.0110, 0.0457, 0.0071, 0.1408, 0.0291, 0.0619, 0.2392, 0.0262, 0.1418,
        0.0553, 0.1052, 0.0957, 0.0410], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:43,552][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ hospital] are: tensor([0.1315, 0.0525, 0.0126, 0.0236, 0.0209, 0.0315, 0.0256, 0.0257, 0.0627,
        0.0841, 0.0927, 0.0790, 0.3576], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:43,553][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ hospital] are: tensor([0.0093, 0.0056, 0.0104, 0.0205, 0.0172, 0.0165, 0.0567, 0.0497, 0.1885,
        0.0487, 0.2669, 0.1251, 0.1849], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:43,554][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [.] are: tensor([1.4230e-02, 4.4437e-02, 1.2684e-03, 2.6998e-03, 2.6554e-03, 4.8907e-04,
        6.6727e-01, 1.0261e-03, 5.4324e-03, 4.1894e-04, 3.1805e-04, 2.5180e-01,
        6.7433e-04, 7.2768e-03], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:43,555][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.0029, 0.0170, 0.0584, 0.1175, 0.0751, 0.0633, 0.1659, 0.0711, 0.1038,
        0.0619, 0.0660, 0.0706, 0.0421, 0.0845], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:43,555][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.0814, 0.0922, 0.0594, 0.0609, 0.0738, 0.0702, 0.0630, 0.0840, 0.0681,
        0.0806, 0.0587, 0.0503, 0.0837, 0.0739], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:43,556][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0413, 0.0104, 0.1107, 0.4930, 0.1956, 0.0190, 0.0288, 0.0092, 0.0280,
        0.0167, 0.0156, 0.0086, 0.0146, 0.0085], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:43,556][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0012, 0.0044, 0.0085, 0.0676, 0.0176, 0.0330, 0.0910, 0.0658, 0.2287,
        0.0708, 0.0837, 0.0708, 0.1679, 0.0890], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:43,557][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.0195, 0.0004, 0.0008, 0.0079, 0.0023, 0.0050, 0.0347, 0.0083, 0.2031,
        0.0544, 0.1591, 0.0771, 0.3639, 0.0635], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:43,557][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0019, 0.0525, 0.0593, 0.0836, 0.0670, 0.0564, 0.0798, 0.0779, 0.0850,
        0.1126, 0.0723, 0.0732, 0.0932, 0.0852], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:43,558][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [.] are: tensor([9.7329e-01, 6.2232e-04, 3.8937e-04, 5.6449e-04, 5.0304e-04, 7.5339e-04,
        2.9705e-03, 1.9592e-03, 5.2667e-03, 1.0517e-03, 1.7849e-03, 3.2885e-03,
        3.0805e-03, 4.4759e-03], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:43,558][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.0177, 0.0645, 0.0803, 0.0798, 0.0857, 0.0815, 0.0606, 0.0579, 0.0773,
        0.0796, 0.0639, 0.0774, 0.1057, 0.0682], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:43,558][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.0060, 0.0186, 0.0074, 0.1243, 0.0322, 0.0669, 0.2491, 0.0285, 0.1466,
        0.0579, 0.1010, 0.0912, 0.0284, 0.0421], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:43,560][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.2653, 0.0442, 0.0135, 0.0173, 0.0190, 0.0246, 0.0158, 0.0225, 0.0478,
        0.0701, 0.0644, 0.0514, 0.1988, 0.1452], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:43,561][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0117, 0.0050, 0.0075, 0.0140, 0.0138, 0.0158, 0.0413, 0.0530, 0.1106,
        0.0530, 0.2414, 0.1161, 0.1563, 0.1602], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:43,562][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Anthony] are: tensor([7.4487e-03, 2.8997e-02, 1.1511e-03, 1.7790e-03, 1.4760e-03, 3.8088e-04,
        6.0541e-01, 9.6739e-04, 6.3294e-03, 1.5917e-03, 3.6729e-04, 3.1741e-01,
        1.1071e-03, 1.1889e-02, 1.3698e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:43,564][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Anthony] are: tensor([0.0026, 0.0133, 0.0415, 0.0899, 0.0513, 0.0545, 0.1305, 0.0658, 0.1009,
        0.0673, 0.0650, 0.0674, 0.0375, 0.0912, 0.1215], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:43,565][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Anthony] are: tensor([0.0644, 0.0856, 0.0587, 0.0540, 0.0720, 0.0623, 0.0547, 0.0677, 0.0591,
        0.0769, 0.0592, 0.0490, 0.0808, 0.0744, 0.0811], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:43,566][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Anthony] are: tensor([0.0455, 0.0101, 0.0949, 0.4883, 0.1895, 0.0188, 0.0290, 0.0107, 0.0312,
        0.0166, 0.0168, 0.0088, 0.0187, 0.0094, 0.0117], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:43,568][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Anthony] are: tensor([0.0019, 0.0043, 0.0067, 0.0650, 0.0122, 0.0280, 0.0841, 0.0509, 0.2000,
        0.0507, 0.0727, 0.0669, 0.1601, 0.0866, 0.1099], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:43,569][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Anthony] are: tensor([4.7334e-02, 4.2167e-04, 2.8028e-04, 2.8080e-03, 5.1760e-04, 1.6086e-03,
        1.2423e-02, 2.7785e-03, 1.4133e-01, 4.1250e-02, 1.0949e-01, 5.8670e-02,
        3.0930e-01, 5.4331e-02, 2.1746e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:43,570][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Anthony] are: tensor([0.0028, 0.0469, 0.0470, 0.0711, 0.0536, 0.0536, 0.0763, 0.0719, 0.0877,
        0.0939, 0.0747, 0.0730, 0.0824, 0.0821, 0.0830], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:43,571][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Anthony] are: tensor([9.9057e-01, 2.7280e-04, 7.4330e-05, 2.2181e-04, 8.1744e-05, 1.2966e-04,
        8.3268e-04, 5.4062e-04, 2.7610e-03, 2.4847e-04, 6.7396e-04, 8.8610e-04,
        6.7982e-04, 1.4965e-03, 5.2853e-04], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:43,573][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Anthony] are: tensor([0.0131, 0.0561, 0.0750, 0.0770, 0.0720, 0.0764, 0.0563, 0.0508, 0.0813,
        0.0695, 0.0544, 0.0592, 0.0834, 0.0746, 0.1008], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:43,574][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Anthony] are: tensor([0.0090, 0.0391, 0.0112, 0.1082, 0.0273, 0.0541, 0.1919, 0.0254, 0.1433,
        0.0501, 0.0956, 0.0877, 0.0327, 0.0403, 0.0839], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:43,576][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Anthony] are: tensor([0.1283, 0.0384, 0.0076, 0.0093, 0.0131, 0.0167, 0.0107, 0.0109, 0.0327,
        0.0493, 0.0471, 0.0418, 0.2159, 0.1514, 0.2267], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:43,577][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Anthony] are: tensor([0.0054, 0.0034, 0.0036, 0.0063, 0.0058, 0.0066, 0.0224, 0.0293, 0.0903,
        0.0326, 0.1356, 0.0689, 0.1128, 0.1284, 0.3487], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:43,579][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.0037, 0.0276, 0.0030, 0.0038, 0.0064, 0.0010, 0.6630, 0.0023, 0.0112,
        0.0020, 0.0009, 0.2375, 0.0015, 0.0127, 0.0210, 0.0024],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:43,580][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0013, 0.0101, 0.0412, 0.0930, 0.0527, 0.0430, 0.1471, 0.0579, 0.1007,
        0.0678, 0.0676, 0.0714, 0.0372, 0.0836, 0.1076, 0.0177],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:43,582][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0529, 0.0666, 0.0617, 0.0512, 0.0654, 0.0612, 0.0637, 0.0681, 0.0654,
        0.0704, 0.0526, 0.0472, 0.0641, 0.0644, 0.0762, 0.0690],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:43,583][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.0458, 0.0085, 0.0924, 0.5101, 0.1824, 0.0163, 0.0275, 0.0095, 0.0278,
        0.0174, 0.0165, 0.0080, 0.0160, 0.0088, 0.0099, 0.0030],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:43,585][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.0016, 0.0030, 0.0050, 0.0546, 0.0095, 0.0236, 0.0717, 0.0493, 0.2009,
        0.0525, 0.0781, 0.0646, 0.1479, 0.0796, 0.0878, 0.0703],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:43,586][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([4.2095e-02, 1.8532e-04, 2.7478e-04, 2.9664e-03, 4.8642e-04, 1.4946e-03,
        1.6058e-02, 3.2024e-03, 1.3089e-01, 3.0548e-02, 9.8153e-02, 6.1661e-02,
        2.7594e-01, 4.2906e-02, 1.9609e-01, 9.7062e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:43,587][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0015, 0.0383, 0.0474, 0.0651, 0.0528, 0.0466, 0.0683, 0.0687, 0.0766,
        0.0996, 0.0661, 0.0671, 0.0824, 0.0758, 0.0841, 0.0598],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:43,588][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([9.8901e-01, 2.1060e-04, 7.0333e-05, 2.1722e-04, 1.1850e-04, 1.3886e-04,
        1.0552e-03, 5.7941e-04, 2.7722e-03, 2.9050e-04, 7.0262e-04, 1.1724e-03,
        8.5866e-04, 1.7021e-03, 7.3189e-04, 3.7044e-04], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:43,590][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.0120, 0.0538, 0.0705, 0.0742, 0.0730, 0.0713, 0.0540, 0.0478, 0.0771,
        0.0669, 0.0540, 0.0636, 0.0850, 0.0661, 0.0845, 0.0463],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:43,591][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.0072, 0.0208, 0.0090, 0.0917, 0.0247, 0.0432, 0.1560, 0.0240, 0.1358,
        0.0649, 0.0981, 0.0866, 0.0433, 0.0500, 0.0969, 0.0476],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:43,593][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0432, 0.0196, 0.0073, 0.0147, 0.0127, 0.0170, 0.0146, 0.0138, 0.0499,
        0.0593, 0.0630, 0.0438, 0.1557, 0.1308, 0.1883, 0.1662],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:43,594][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0011, 0.0015, 0.0048, 0.0103, 0.0077, 0.0057, 0.0397, 0.0290, 0.0942,
        0.0269, 0.1545, 0.0600, 0.0555, 0.1003, 0.3684, 0.0404],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:43,595][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ a] are: tensor([6.9591e-03, 3.2370e-02, 7.1186e-04, 1.5200e-03, 8.4081e-04, 2.8832e-04,
        3.3884e-01, 7.1304e-04, 3.8123e-03, 3.0508e-04, 2.7831e-04, 1.3284e-01,
        3.3712e-04, 5.2886e-03, 4.1473e-03, 5.2490e-04, 4.7022e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:43,597][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0019, 0.0107, 0.0375, 0.0776, 0.0472, 0.0391, 0.0989, 0.0643, 0.0885,
        0.0594, 0.0579, 0.0616, 0.0357, 0.0705, 0.1144, 0.0226, 0.1121],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:43,598][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0496, 0.0809, 0.0522, 0.0483, 0.0628, 0.0539, 0.0522, 0.0627, 0.0603,
        0.0671, 0.0486, 0.0454, 0.0647, 0.0681, 0.0677, 0.0644, 0.0513],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:43,600][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0446, 0.0096, 0.0922, 0.4727, 0.1766, 0.0184, 0.0289, 0.0109, 0.0325,
        0.0224, 0.0196, 0.0103, 0.0189, 0.0114, 0.0115, 0.0042, 0.0153],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:43,601][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0006, 0.0028, 0.0041, 0.0522, 0.0095, 0.0213, 0.0597, 0.0486, 0.1930,
        0.0506, 0.0575, 0.0515, 0.1417, 0.0679, 0.0866, 0.0750, 0.0774],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:43,603][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0178, 0.0004, 0.0006, 0.0048, 0.0013, 0.0027, 0.0147, 0.0047, 0.1040,
        0.0322, 0.0789, 0.0401, 0.2183, 0.0545, 0.1824, 0.0976, 0.1450],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:43,604][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0013, 0.0394, 0.0497, 0.0635, 0.0537, 0.0424, 0.0587, 0.0626, 0.0649,
        0.0996, 0.0566, 0.0577, 0.0836, 0.0678, 0.0834, 0.0540, 0.0611],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:43,605][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ a] are: tensor([9.8309e-01, 4.1714e-04, 1.3825e-04, 3.2780e-04, 1.9798e-04, 2.2029e-04,
        9.8409e-04, 8.1199e-04, 3.4539e-03, 3.9677e-04, 1.3259e-03, 1.3067e-03,
        1.6802e-03, 2.4612e-03, 1.1747e-03, 6.6853e-04, 1.3494e-03],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:43,607][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0173, 0.0533, 0.0593, 0.0655, 0.0622, 0.0630, 0.0467, 0.0487, 0.0654,
        0.0729, 0.0586, 0.0597, 0.0916, 0.0632, 0.0717, 0.0514, 0.0494],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:43,609][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0059, 0.0237, 0.0090, 0.0788, 0.0284, 0.0438, 0.1368, 0.0261, 0.1228,
        0.0647, 0.0843, 0.0768, 0.0445, 0.0504, 0.0758, 0.0473, 0.0810],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:43,610][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.1117, 0.0219, 0.0055, 0.0082, 0.0070, 0.0122, 0.0074, 0.0130, 0.0310,
        0.0508, 0.0363, 0.0323, 0.1460, 0.1130, 0.1561, 0.1561, 0.0912],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:43,612][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0050, 0.0026, 0.0028, 0.0060, 0.0049, 0.0055, 0.0183, 0.0264, 0.0671,
        0.0283, 0.1072, 0.0544, 0.0850, 0.1116, 0.2459, 0.0583, 0.1706],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:43,613][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ drink] are: tensor([1.1848e-03, 1.5359e-02, 7.4687e-04, 8.8500e-04, 9.0744e-04, 1.8043e-04,
        2.4219e-01, 6.0885e-04, 3.7014e-03, 8.3187e-04, 2.9828e-04, 1.5251e-01,
        5.3017e-04, 6.9175e-03, 9.1334e-03, 5.5350e-04, 5.6336e-01, 1.0154e-04],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:43,614][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ drink] are: tensor([0.0017, 0.0127, 0.0398, 0.0870, 0.0535, 0.0412, 0.1239, 0.0596, 0.0838,
        0.0480, 0.0516, 0.0544, 0.0271, 0.0613, 0.0780, 0.0172, 0.1065, 0.0526],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:43,614][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ drink] are: tensor([0.0441, 0.0689, 0.0535, 0.0446, 0.0605, 0.0542, 0.0529, 0.0593, 0.0559,
        0.0614, 0.0475, 0.0424, 0.0588, 0.0602, 0.0647, 0.0600, 0.0484, 0.0628],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:43,615][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ drink] are: tensor([0.0409, 0.0102, 0.0894, 0.4734, 0.1799, 0.0167, 0.0285, 0.0112, 0.0313,
        0.0199, 0.0166, 0.0087, 0.0165, 0.0097, 0.0109, 0.0038, 0.0140, 0.0183],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:43,615][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ drink] are: tensor([0.0008, 0.0020, 0.0036, 0.0378, 0.0090, 0.0177, 0.0616, 0.0416, 0.1597,
        0.0424, 0.0610, 0.0613, 0.1479, 0.0647, 0.0829, 0.0695, 0.0870, 0.0494],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:43,615][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ drink] are: tensor([8.3303e-03, 1.3572e-04, 2.7616e-04, 2.2367e-03, 5.4682e-04, 1.4077e-03,
        1.3441e-02, 2.3047e-03, 8.7700e-02, 2.8743e-02, 6.7334e-02, 4.4762e-02,
        2.1818e-01, 3.6737e-02, 1.7607e-01, 8.6246e-02, 1.5968e-01, 6.5865e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:43,616][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ drink] are: tensor([0.0021, 0.0335, 0.0380, 0.0548, 0.0436, 0.0434, 0.0593, 0.0593, 0.0700,
        0.0762, 0.0600, 0.0589, 0.0686, 0.0650, 0.0682, 0.0556, 0.0611, 0.0824],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:43,616][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ drink] are: tensor([9.6997e-01, 3.7646e-04, 1.4082e-04, 5.0756e-04, 2.1097e-04, 3.7297e-04,
        2.1704e-03, 1.2139e-03, 7.7593e-03, 6.4442e-04, 1.3610e-03, 2.6268e-03,
        1.8443e-03, 4.9457e-03, 1.5764e-03, 1.0763e-03, 2.8242e-03, 3.7719e-04],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:43,618][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ drink] are: tensor([0.0120, 0.0509, 0.0624, 0.0655, 0.0641, 0.0554, 0.0453, 0.0414, 0.0626,
        0.0644, 0.0470, 0.0554, 0.0828, 0.0585, 0.0718, 0.0421, 0.0470, 0.0714],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:43,619][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ drink] are: tensor([0.0038, 0.0277, 0.0115, 0.0642, 0.0253, 0.0432, 0.1073, 0.0332, 0.1135,
        0.0615, 0.0732, 0.0727, 0.0400, 0.0388, 0.1029, 0.0575, 0.0618, 0.0618],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:43,620][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ drink] are: tensor([0.0358, 0.0188, 0.0055, 0.0083, 0.0100, 0.0109, 0.0095, 0.0120, 0.0281,
        0.0445, 0.0374, 0.0303, 0.1295, 0.0994, 0.1711, 0.1194, 0.0857, 0.1436],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:43,622][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ drink] are: tensor([0.0013, 0.0010, 0.0018, 0.0052, 0.0042, 0.0035, 0.0195, 0.0231, 0.0688,
        0.0169, 0.1083, 0.0393, 0.0586, 0.0592, 0.3070, 0.0442, 0.1605, 0.0774],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:43,623][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ to] are: tensor([1.0268e-02, 2.8080e-02, 1.0990e-03, 1.3324e-03, 1.2413e-03, 2.4802e-04,
        3.1486e-01, 8.9529e-04, 3.4478e-03, 3.9534e-04, 1.9828e-04, 1.6628e-01,
        4.4645e-04, 5.7762e-03, 6.3090e-03, 8.5201e-04, 4.4529e-01, 7.7299e-05,
        1.2916e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:43,624][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0019, 0.0103, 0.0367, 0.0641, 0.0415, 0.0318, 0.0973, 0.0486, 0.0662,
        0.0412, 0.0396, 0.0473, 0.0295, 0.0547, 0.0830, 0.0173, 0.1067, 0.0703,
        0.1119], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:43,625][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0487, 0.0680, 0.0471, 0.0438, 0.0573, 0.0467, 0.0474, 0.0533, 0.0523,
        0.0595, 0.0447, 0.0400, 0.0558, 0.0624, 0.0617, 0.0562, 0.0464, 0.0578,
        0.0507], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:43,627][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0498, 0.0112, 0.0929, 0.4390, 0.1677, 0.0190, 0.0298, 0.0113, 0.0314,
        0.0205, 0.0190, 0.0103, 0.0187, 0.0114, 0.0116, 0.0042, 0.0151, 0.0170,
        0.0203], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:43,629][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0009, 0.0032, 0.0052, 0.0405, 0.0110, 0.0196, 0.0551, 0.0383, 0.1350,
        0.0452, 0.0474, 0.0484, 0.1190, 0.0600, 0.0825, 0.0647, 0.0692, 0.0481,
        0.1068], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:43,630][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0154, 0.0004, 0.0005, 0.0032, 0.0010, 0.0019, 0.0118, 0.0033, 0.0702,
        0.0234, 0.0625, 0.0355, 0.1802, 0.0442, 0.1388, 0.0789, 0.1247, 0.0694,
        0.1347], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:43,631][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0013, 0.0354, 0.0433, 0.0550, 0.0462, 0.0362, 0.0525, 0.0520, 0.0558,
        0.0802, 0.0470, 0.0485, 0.0692, 0.0571, 0.0698, 0.0444, 0.0525, 0.0875,
        0.0661], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:43,633][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ to] are: tensor([9.3011e-01, 1.2815e-03, 4.6140e-04, 9.7574e-04, 6.2793e-04, 1.1705e-03,
        4.7815e-03, 3.5125e-03, 1.1295e-02, 1.3805e-03, 3.9884e-03, 6.6331e-03,
        5.2098e-03, 1.0521e-02, 4.0851e-03, 2.5220e-03, 6.4401e-03, 1.3429e-03,
        3.6585e-03], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:43,634][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0166, 0.0447, 0.0586, 0.0619, 0.0663, 0.0530, 0.0399, 0.0378, 0.0567,
        0.0648, 0.0482, 0.0555, 0.0824, 0.0518, 0.0647, 0.0409, 0.0419, 0.0631,
        0.0511], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:43,635][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0072, 0.0212, 0.0094, 0.0764, 0.0234, 0.0379, 0.1237, 0.0235, 0.1063,
        0.0629, 0.0734, 0.0674, 0.0356, 0.0428, 0.0729, 0.0439, 0.0679, 0.0418,
        0.0626], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:43,637][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.1447, 0.0227, 0.0051, 0.0059, 0.0060, 0.0092, 0.0053, 0.0088, 0.0188,
        0.0298, 0.0267, 0.0216, 0.1061, 0.0776, 0.1277, 0.1338, 0.0653, 0.0862,
        0.0986], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:43,639][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0110, 0.0025, 0.0019, 0.0037, 0.0035, 0.0043, 0.0133, 0.0239, 0.0376,
        0.0180, 0.0748, 0.0416, 0.0669, 0.0736, 0.1605, 0.0386, 0.1217, 0.0681,
        0.2345], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:43,692][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:21:43,694][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:43,695][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:43,696][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:43,697][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:43,698][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:43,699][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:43,701][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:43,702][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:43,703][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:43,714][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:43,715][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:43,717][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:43,718][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.6078, 0.3922], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:43,719][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.2252, 0.7748], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:43,721][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.6458, 0.3542], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:43,722][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.3864, 0.6136], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:43,723][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.3880, 0.6120], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:43,725][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.6223, 0.3777], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:43,726][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.2102, 0.7898], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:43,728][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.2990, 0.7010], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:43,729][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.8722, 0.1278], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:43,730][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.8600, 0.1400], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:43,732][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.4323, 0.5677], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:43,733][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.3942, 0.6058], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:43,734][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Anthony] are: tensor([0.6334, 0.3059, 0.0607], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:43,736][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Anthony] are: tensor([0.1193, 0.2536, 0.6271], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:43,737][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Anthony] are: tensor([0.5974, 0.2889, 0.1137], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:43,739][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Anthony] are: tensor([0.2973, 0.2137, 0.4890], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:43,740][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Anthony] are: tensor([0.2390, 0.4129, 0.3481], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:43,740][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Anthony] are: tensor([0.5813, 0.2858, 0.1329], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:43,741][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Anthony] are: tensor([0.1746, 0.5679, 0.2574], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:43,741][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Anthony] are: tensor([0.0769, 0.6413, 0.2818], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:43,741][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Anthony] are: tensor([0.8354, 0.1320, 0.0327], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:43,742][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Anthony] are: tensor([0.8325, 0.1023, 0.0652], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:43,742][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Anthony] are: tensor([0.3835, 0.3861, 0.2304], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:43,742][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Anthony] are: tensor([0.1435, 0.1800, 0.6765], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:43,743][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.7912, 0.1895, 0.0138, 0.0055], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:43,744][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0859, 0.0944, 0.4181, 0.4017], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:43,745][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.5719, 0.3095, 0.0756, 0.0430], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:43,746][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.1503, 0.1195, 0.1521, 0.5780], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:43,748][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.2042, 0.1166, 0.0410, 0.6382], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:43,749][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.6208, 0.1367, 0.0484, 0.1941], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:43,750][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.2543, 0.4336, 0.2357, 0.0764], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:43,752][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.1028, 0.1367, 0.0188, 0.7418], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:43,753][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.9186, 0.0595, 0.0138, 0.0081], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:43,754][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.9121, 0.0476, 0.0173, 0.0230], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:43,756][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.5750, 0.1882, 0.0890, 0.1478], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:43,757][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.1470, 0.0632, 0.2257, 0.5641], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:43,759][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Travis] are: tensor([0.6340, 0.2963, 0.0408, 0.0174, 0.0115], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:43,760][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Travis] are: tensor([0.0522, 0.0754, 0.2045, 0.3560, 0.3118], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:43,762][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Travis] are: tensor([0.5103, 0.2500, 0.0797, 0.0336, 0.1263], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:43,763][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Travis] are: tensor([0.1933, 0.1082, 0.1460, 0.3725, 0.1800], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:43,764][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Travis] are: tensor([0.0311, 0.0426, 0.0406, 0.6507, 0.2350], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:43,766][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Travis] are: tensor([0.4483, 0.1374, 0.0354, 0.1923, 0.1867], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:43,767][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Travis] are: tensor([0.3130, 0.3715, 0.1052, 0.1019, 0.1084], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:43,768][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Travis] are: tensor([0.0104, 0.0369, 0.0198, 0.7854, 0.1475], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:43,770][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Travis] are: tensor([0.7309, 0.0999, 0.0292, 0.0256, 0.1144], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:43,771][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Travis] are: tensor([0.7368, 0.0916, 0.0319, 0.0489, 0.0907], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:43,773][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Travis] are: tensor([0.3708, 0.2439, 0.0685, 0.1411, 0.1756], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:43,774][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Travis] are: tensor([0.0510, 0.0486, 0.1250, 0.3899, 0.3855], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:43,775][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.6292, 0.2942, 0.0395, 0.0162, 0.0124, 0.0085], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:43,776][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.0122, 0.0571, 0.2613, 0.1437, 0.4904, 0.0353], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:43,778][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.3727, 0.2372, 0.0793, 0.0408, 0.1524, 0.1176], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:43,779][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.0591, 0.0776, 0.1325, 0.4014, 0.1539, 0.1754], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:43,781][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.0501, 0.0614, 0.0333, 0.3035, 0.2247, 0.3270], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:43,782][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.3227, 0.0931, 0.0353, 0.1112, 0.1553, 0.2824], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:43,783][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.1450, 0.2715, 0.2286, 0.0535, 0.2564, 0.0450], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:43,785][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.0272, 0.0645, 0.0105, 0.3219, 0.1633, 0.4126], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:43,786][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.6961, 0.1206, 0.0246, 0.0210, 0.0592, 0.0785], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:43,788][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.6759, 0.0683, 0.0328, 0.0506, 0.0958, 0.0766], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:43,789][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.2369, 0.1666, 0.0854, 0.1599, 0.1455, 0.2055], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:43,791][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.0242, 0.0370, 0.1011, 0.3408, 0.2854, 0.2115], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:43,792][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([1.1585e-01, 3.5861e-02, 2.3202e-03, 8.2621e-04, 6.2422e-04, 4.7706e-04,
        8.4404e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:43,793][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0743, 0.0523, 0.2095, 0.2018, 0.3219, 0.0700, 0.0701],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:43,794][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.4789, 0.2219, 0.0425, 0.0242, 0.1052, 0.0985, 0.0287],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:43,796][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.1321, 0.0617, 0.1167, 0.2686, 0.0995, 0.1598, 0.1615],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:43,797][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0997, 0.0367, 0.0083, 0.1556, 0.0763, 0.3582, 0.2653],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:43,798][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.6815, 0.0455, 0.0101, 0.0300, 0.0595, 0.1217, 0.0518],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:43,798][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.5492, 0.1735, 0.0911, 0.0221, 0.1070, 0.0358, 0.0213],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:43,799][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0497, 0.0468, 0.0032, 0.1428, 0.0714, 0.3451, 0.3409],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:43,799][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.8902, 0.0351, 0.0087, 0.0057, 0.0249, 0.0249, 0.0105],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:43,799][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.8459, 0.0368, 0.0136, 0.0157, 0.0431, 0.0312, 0.0136],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:43,800][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.5390, 0.1220, 0.0410, 0.0547, 0.0757, 0.0992, 0.0684],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:43,800][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0429, 0.0323, 0.0470, 0.1562, 0.1459, 0.1353, 0.4404],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:43,801][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ lot] are: tensor([0.0783, 0.0366, 0.0045, 0.0019, 0.0019, 0.0011, 0.8691, 0.0066],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:43,801][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ lot] are: tensor([0.0160, 0.0306, 0.1341, 0.1906, 0.2896, 0.0418, 0.1791, 0.1182],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:43,801][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ lot] are: tensor([0.3335, 0.2067, 0.0581, 0.0482, 0.0720, 0.1241, 0.0680, 0.0894],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:43,802][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ lot] are: tensor([0.0292, 0.0592, 0.1304, 0.2399, 0.0588, 0.1306, 0.1637, 0.1882],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:43,803][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ lot] are: tensor([0.0298, 0.0195, 0.0095, 0.0926, 0.0434, 0.2188, 0.3844, 0.2020],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:43,805][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ lot] are: tensor([0.2082, 0.0597, 0.0258, 0.0678, 0.0978, 0.1773, 0.1501, 0.2132],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:43,806][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ lot] are: tensor([0.2290, 0.1717, 0.1334, 0.0761, 0.1351, 0.0719, 0.1127, 0.0700],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:43,808][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ lot] are: tensor([0.0083, 0.0216, 0.0046, 0.1177, 0.0438, 0.1834, 0.4952, 0.1255],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:43,809][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ lot] are: tensor([0.6379, 0.0540, 0.0172, 0.0179, 0.0414, 0.0620, 0.0422, 0.1274],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:43,810][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ lot] are: tensor([0.4500, 0.0781, 0.0383, 0.0582, 0.0930, 0.1053, 0.0655, 0.1116],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:43,812][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ lot] are: tensor([0.1561, 0.1311, 0.0517, 0.1132, 0.1089, 0.1444, 0.1477, 0.1469],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:43,813][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ lot] are: tensor([0.0159, 0.0127, 0.0360, 0.1064, 0.0711, 0.0845, 0.3693, 0.3040],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:43,814][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([2.3157e-01, 4.5687e-02, 3.5953e-03, 8.5328e-04, 1.4568e-03, 6.9591e-04,
        7.0347e-01, 3.9900e-03, 8.6798e-03], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:43,816][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([0.0104, 0.0178, 0.1423, 0.1121, 0.2402, 0.0363, 0.0789, 0.2150, 0.1471],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:43,817][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([0.4052, 0.2475, 0.0477, 0.0249, 0.0705, 0.0703, 0.0337, 0.0487, 0.0515],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:43,819][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([0.1153, 0.0661, 0.0757, 0.1452, 0.0515, 0.0891, 0.0929, 0.1642, 0.2000],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:43,820][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([0.0386, 0.0130, 0.0038, 0.0154, 0.0176, 0.0498, 0.0592, 0.1021, 0.7005],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:43,821][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([0.4656, 0.0290, 0.0055, 0.0085, 0.0153, 0.0432, 0.0252, 0.0935, 0.3142],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:43,823][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([0.4656, 0.1704, 0.0962, 0.0144, 0.0920, 0.0276, 0.0205, 0.0558, 0.0576],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:43,824][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([1.7379e-02, 9.5346e-03, 5.3753e-04, 7.2588e-03, 6.1199e-03, 2.4191e-02,
        3.1837e-02, 4.9168e-02, 8.5397e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:43,825][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([0.8149, 0.0326, 0.0071, 0.0034, 0.0166, 0.0173, 0.0071, 0.0606, 0.0403],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:43,827][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([0.8238, 0.0318, 0.0105, 0.0105, 0.0264, 0.0231, 0.0103, 0.0308, 0.0328],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:43,828][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([0.4733, 0.0876, 0.0250, 0.0363, 0.0497, 0.0586, 0.0371, 0.0532, 0.1791],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:43,830][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([0.0225, 0.0102, 0.0216, 0.0385, 0.0483, 0.0474, 0.1441, 0.1733, 0.4941],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:43,831][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ fun] are: tensor([0.0979, 0.0542, 0.0055, 0.0017, 0.0029, 0.0013, 0.8094, 0.0064, 0.0137,
        0.0070], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:43,832][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ fun] are: tensor([0.0137, 0.0266, 0.1495, 0.1131, 0.1920, 0.0369, 0.1026, 0.1400, 0.1275,
        0.0981], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:43,834][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ fun] are: tensor([0.3097, 0.1934, 0.0406, 0.0202, 0.0795, 0.0825, 0.0296, 0.0636, 0.0539,
        0.1269], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:43,835][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ fun] are: tensor([0.0471, 0.0329, 0.0812, 0.1116, 0.0430, 0.0949, 0.0976, 0.1456, 0.1522,
        0.1940], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:43,837][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ fun] are: tensor([0.0037, 0.0047, 0.0034, 0.0155, 0.0115, 0.0410, 0.1202, 0.0799, 0.5927,
        0.1275], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:43,838][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ fun] are: tensor([0.1712, 0.0209, 0.0061, 0.0127, 0.0167, 0.0431, 0.0374, 0.1204, 0.4577,
        0.1138], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:43,840][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ fun] are: tensor([0.0708, 0.0627, 0.0494, 0.0357, 0.0598, 0.0370, 0.0508, 0.0573, 0.1088,
        0.4677], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:43,841][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ fun] are: tensor([2.2693e-03, 3.1751e-03, 5.1458e-04, 9.2157e-03, 4.0053e-03, 2.6275e-02,
        4.2203e-02, 2.8734e-02, 7.9795e-01, 8.5654e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:43,842][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ fun] are: tensor([0.5332, 0.0412, 0.0103, 0.0091, 0.0258, 0.0354, 0.0247, 0.1476, 0.1008,
        0.0719], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:43,844][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ fun] are: tensor([0.5489, 0.0423, 0.0149, 0.0193, 0.0470, 0.0431, 0.0217, 0.0641, 0.0941,
        0.1047], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:43,845][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ fun] are: tensor([0.1593, 0.0699, 0.0200, 0.0516, 0.0430, 0.0701, 0.0638, 0.0732, 0.1841,
        0.2650], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:43,846][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ fun] are: tensor([0.0062, 0.0061, 0.0117, 0.0437, 0.0249, 0.0378, 0.1145, 0.1029, 0.4898,
        0.1624], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:43,848][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.1806, 0.0579, 0.0055, 0.0012, 0.0020, 0.0008, 0.7334, 0.0048, 0.0088,
        0.0032, 0.0017], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:43,849][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.0085, 0.0335, 0.1688, 0.1037, 0.1519, 0.0257, 0.0822, 0.1695, 0.0999,
        0.1314, 0.0249], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:43,851][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.3720, 0.2359, 0.0344, 0.0162, 0.0494, 0.0683, 0.0184, 0.0465, 0.0372,
        0.0966, 0.0250], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:43,852][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.0772, 0.0350, 0.0463, 0.0878, 0.0273, 0.0607, 0.0683, 0.1416, 0.1250,
        0.2022, 0.1285], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:43,854][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.0107, 0.0052, 0.0023, 0.0086, 0.0137, 0.0392, 0.0322, 0.0599, 0.3758,
        0.1686, 0.2836], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:43,855][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.2599, 0.0262, 0.0051, 0.0069, 0.0135, 0.0298, 0.0134, 0.0909, 0.2176,
        0.0945, 0.2423], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:43,856][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.2860, 0.1036, 0.0539, 0.0142, 0.0476, 0.0220, 0.0172, 0.0561, 0.0503,
        0.2702, 0.0789], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:43,857][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([6.0491e-03, 4.1671e-03, 2.7531e-04, 2.8790e-03, 3.0117e-03, 1.1495e-02,
        1.3150e-02, 2.0599e-02, 3.2450e-01, 1.2267e-01, 4.9120e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:43,857][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.7207, 0.0269, 0.0041, 0.0034, 0.0126, 0.0165, 0.0059, 0.0848, 0.0463,
        0.0428, 0.0360], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:43,858][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.7352, 0.0308, 0.0113, 0.0101, 0.0268, 0.0235, 0.0085, 0.0310, 0.0314,
        0.0450, 0.0463], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:43,858][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.2410, 0.0660, 0.0203, 0.0307, 0.0364, 0.0480, 0.0314, 0.0518, 0.1338,
        0.1785, 0.1621], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:43,858][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.0102, 0.0044, 0.0092, 0.0154, 0.0197, 0.0182, 0.0619, 0.0772, 0.2674,
        0.1030, 0.4133], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:43,859][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.1071, 0.0395, 0.0031, 0.0009, 0.0009, 0.0006, 0.4117, 0.0027, 0.0063,
        0.0026, 0.0015, 0.4231], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:43,859][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0123, 0.0198, 0.1184, 0.0911, 0.1197, 0.0261, 0.0516, 0.2237, 0.1032,
        0.1232, 0.0603, 0.0507], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:43,860][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.3007, 0.2217, 0.0359, 0.0185, 0.0499, 0.0656, 0.0240, 0.0413, 0.0468,
        0.1109, 0.0330, 0.0517], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:43,861][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0439, 0.0284, 0.0523, 0.0835, 0.0304, 0.0556, 0.0518, 0.1308, 0.1102,
        0.1667, 0.0965, 0.1499], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:43,863][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0116, 0.0072, 0.0021, 0.0092, 0.0081, 0.0173, 0.0240, 0.0476, 0.3086,
        0.0953, 0.2455, 0.2235], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:43,864][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.2373, 0.0173, 0.0037, 0.0053, 0.0094, 0.0205, 0.0112, 0.0598, 0.1870,
        0.0586, 0.2380, 0.1518], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:43,866][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.2872, 0.1139, 0.0693, 0.0107, 0.0577, 0.0220, 0.0123, 0.0314, 0.0423,
        0.2021, 0.0887, 0.0623], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:43,867][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([2.4787e-03, 2.7764e-03, 1.8249e-04, 3.5013e-03, 1.6102e-03, 6.7238e-03,
        9.1319e-03, 1.4112e-02, 3.0089e-01, 5.6702e-02, 4.4093e-01, 1.6097e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:43,868][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.6610, 0.0382, 0.0091, 0.0047, 0.0203, 0.0193, 0.0065, 0.0794, 0.0440,
        0.0517, 0.0367, 0.0291], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:43,870][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.6362, 0.0361, 0.0119, 0.0164, 0.0326, 0.0302, 0.0133, 0.0385, 0.0432,
        0.0468, 0.0483, 0.0465], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:43,871][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.1862, 0.0643, 0.0254, 0.0366, 0.0427, 0.0517, 0.0304, 0.0457, 0.1253,
        0.1493, 0.1283, 0.1141], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:43,872][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0070, 0.0050, 0.0132, 0.0196, 0.0270, 0.0201, 0.0653, 0.0700, 0.2094,
        0.0968, 0.3341, 0.1324], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:43,874][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ hospital] are: tensor([0.0966, 0.0310, 0.0038, 0.0009, 0.0016, 0.0007, 0.3910, 0.0034, 0.0085,
        0.0035, 0.0021, 0.4533, 0.0037], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:43,875][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ hospital] are: tensor([0.0121, 0.0250, 0.0802, 0.0959, 0.0938, 0.0231, 0.0806, 0.1466, 0.1130,
        0.0884, 0.0682, 0.0811, 0.0921], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:43,877][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ hospital] are: tensor([0.3126, 0.1824, 0.0278, 0.0142, 0.0384, 0.0497, 0.0135, 0.0325, 0.0248,
        0.0509, 0.0236, 0.0285, 0.2011], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:43,878][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ hospital] are: tensor([0.0294, 0.0227, 0.0362, 0.0448, 0.0249, 0.0438, 0.0447, 0.0892, 0.0957,
        0.0821, 0.0764, 0.1284, 0.2817], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:43,880][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ hospital] are: tensor([0.0067, 0.0044, 0.0018, 0.0075, 0.0035, 0.0135, 0.0307, 0.0226, 0.1896,
        0.0493, 0.1001, 0.1655, 0.4049], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:43,881][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ hospital] are: tensor([0.1432, 0.0140, 0.0022, 0.0035, 0.0032, 0.0116, 0.0075, 0.0338, 0.0826,
        0.0289, 0.0731, 0.1099, 0.4865], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:43,883][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ hospital] are: tensor([0.1633, 0.0492, 0.0262, 0.0134, 0.0266, 0.0215, 0.0171, 0.0360, 0.0379,
        0.1284, 0.0574, 0.0694, 0.3535], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:43,884][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ hospital] are: tensor([3.2973e-03, 2.1276e-03, 1.9493e-04, 2.6214e-03, 1.0355e-03, 6.4639e-03,
        1.4950e-02, 1.2120e-02, 1.9185e-01, 4.0008e-02, 2.1791e-01, 1.6561e-01,
        3.4181e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:43,885][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ hospital] are: tensor([0.6780, 0.0207, 0.0044, 0.0022, 0.0071, 0.0122, 0.0048, 0.0317, 0.0230,
        0.0258, 0.0258, 0.0212, 0.1430], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:43,887][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ hospital] are: tensor([0.5985, 0.0387, 0.0062, 0.0099, 0.0180, 0.0178, 0.0092, 0.0187, 0.0247,
        0.0298, 0.0326, 0.0382, 0.1576], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:43,888][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ hospital] are: tensor([0.1315, 0.0525, 0.0126, 0.0236, 0.0209, 0.0315, 0.0256, 0.0257, 0.0627,
        0.0841, 0.0927, 0.0790, 0.3576], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:43,889][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ hospital] are: tensor([0.0093, 0.0056, 0.0104, 0.0205, 0.0172, 0.0165, 0.0567, 0.0497, 0.1885,
        0.0487, 0.2669, 0.1251, 0.1849], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:43,891][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.2043, 0.0479, 0.0036, 0.0008, 0.0015, 0.0005, 0.3733, 0.0026, 0.0047,
        0.0018, 0.0009, 0.3488, 0.0019, 0.0074], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:43,892][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.0126, 0.0159, 0.1142, 0.0653, 0.1584, 0.0330, 0.0642, 0.1023, 0.0817,
        0.0840, 0.0482, 0.0554, 0.0978, 0.0671], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:43,894][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.2804, 0.1374, 0.0223, 0.0133, 0.0343, 0.0516, 0.0120, 0.0357, 0.0253,
        0.0779, 0.0218, 0.0210, 0.2408, 0.0261], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:43,895][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.0314, 0.0272, 0.0420, 0.0614, 0.0223, 0.0467, 0.0459, 0.0832, 0.0810,
        0.1066, 0.0882, 0.1340, 0.1269, 0.1033], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:43,897][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.0270, 0.0055, 0.0007, 0.0030, 0.0023, 0.0066, 0.0085, 0.0161, 0.0677,
        0.0292, 0.0668, 0.0864, 0.3327, 0.3475], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:43,899][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.2370, 0.0116, 0.0017, 0.0021, 0.0029, 0.0073, 0.0037, 0.0235, 0.0390,
        0.0133, 0.0493, 0.0401, 0.3696, 0.1990], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:43,900][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.2087, 0.0983, 0.0380, 0.0109, 0.0383, 0.0224, 0.0155, 0.0192, 0.0262,
        0.1146, 0.0509, 0.0467, 0.2584, 0.0518], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:43,901][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([1.3926e-02, 3.4302e-03, 1.1788e-04, 1.6040e-03, 7.2156e-04, 3.1110e-03,
        4.5480e-03, 8.5462e-03, 5.8757e-02, 1.5420e-02, 8.5354e-02, 5.4332e-02,
        3.0699e-01, 4.4315e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:43,903][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.7509, 0.0216, 0.0041, 0.0011, 0.0083, 0.0085, 0.0023, 0.0323, 0.0149,
        0.0185, 0.0139, 0.0119, 0.0889, 0.0228], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:43,904][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.7202, 0.0253, 0.0065, 0.0078, 0.0172, 0.0158, 0.0063, 0.0158, 0.0153,
        0.0224, 0.0229, 0.0233, 0.0770, 0.0242], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:43,905][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.2653, 0.0442, 0.0135, 0.0173, 0.0190, 0.0246, 0.0158, 0.0225, 0.0478,
        0.0701, 0.0644, 0.0514, 0.1988, 0.1452], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:43,907][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.0117, 0.0050, 0.0075, 0.0140, 0.0138, 0.0158, 0.0413, 0.0530, 0.1106,
        0.0530, 0.2414, 0.1161, 0.1563, 0.1602], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:43,908][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Anthony] are: tensor([0.1057, 0.0361, 0.0035, 0.0008, 0.0012, 0.0005, 0.3938, 0.0027, 0.0055,
        0.0040, 0.0013, 0.4166, 0.0026, 0.0106, 0.0152], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:43,910][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Anthony] are: tensor([0.0086, 0.0132, 0.0457, 0.0370, 0.0529, 0.0224, 0.0329, 0.0760, 0.0770,
        0.0974, 0.0461, 0.0494, 0.0808, 0.0929, 0.2678], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:43,911][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Anthony] are: tensor([0.2055, 0.1494, 0.0301, 0.0119, 0.0443, 0.0441, 0.0116, 0.0265, 0.0226,
        0.0789, 0.0222, 0.0218, 0.2169, 0.0345, 0.0794], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:43,913][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Anthony] are: tensor([0.0419, 0.0225, 0.0194, 0.0317, 0.0132, 0.0295, 0.0289, 0.0855, 0.0620,
        0.0675, 0.0601, 0.0956, 0.1653, 0.0953, 0.1816], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:43,914][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Anthony] are: tensor([6.9668e-03, 1.8279e-03, 2.1252e-04, 9.9055e-04, 6.2231e-04, 4.1137e-03,
        4.4432e-03, 5.7437e-03, 5.3069e-02, 1.1837e-02, 4.6307e-02, 7.1141e-02,
        2.5525e-01, 2.8067e-01, 2.5681e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:43,914][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Anthony] are: tensor([0.0679, 0.0043, 0.0005, 0.0006, 0.0009, 0.0033, 0.0017, 0.0115, 0.0326,
        0.0129, 0.0371, 0.0384, 0.3003, 0.2387, 0.2495], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:43,915][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Anthony] are: tensor([0.1906, 0.1297, 0.0333, 0.0099, 0.0227, 0.0159, 0.0116, 0.0124, 0.0240,
        0.0880, 0.0398, 0.0379, 0.2168, 0.0579, 0.1096], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:43,915][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Anthony] are: tensor([1.5020e-03, 4.8244e-04, 2.5860e-05, 1.6423e-04, 1.2774e-04, 5.4615e-04,
        9.0565e-04, 1.8235e-03, 2.6070e-02, 7.9632e-03, 5.0358e-02, 2.9320e-02,
        1.9036e-01, 4.0791e-01, 2.8244e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:43,916][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Anthony] are: tensor([0.5905, 0.0188, 0.0023, 0.0011, 0.0046, 0.0065, 0.0032, 0.0363, 0.0148,
        0.0189, 0.0187, 0.0175, 0.1593, 0.0307, 0.0768], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:43,916][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Anthony] are: tensor([0.5779, 0.0257, 0.0102, 0.0078, 0.0159, 0.0154, 0.0073, 0.0194, 0.0224,
        0.0216, 0.0244, 0.0274, 0.0923, 0.0328, 0.0996], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:43,917][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Anthony] are: tensor([0.1283, 0.0384, 0.0076, 0.0093, 0.0131, 0.0167, 0.0107, 0.0109, 0.0327,
        0.0493, 0.0471, 0.0418, 0.2159, 0.1514, 0.2267], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:43,917][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Anthony] are: tensor([0.0054, 0.0034, 0.0036, 0.0063, 0.0058, 0.0066, 0.0224, 0.0293, 0.0903,
        0.0326, 0.1356, 0.0689, 0.1128, 0.1284, 0.3487], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:43,917][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.0627, 0.0366, 0.0070, 0.0018, 0.0039, 0.0012, 0.4656, 0.0054, 0.0106,
        0.0051, 0.0026, 0.3494, 0.0038, 0.0128, 0.0229, 0.0084],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:43,919][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0028, 0.0103, 0.0578, 0.0554, 0.0767, 0.0141, 0.0653, 0.0525, 0.0817,
        0.0925, 0.0593, 0.0642, 0.0732, 0.0800, 0.1992, 0.0149],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:43,920][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.1352, 0.0702, 0.0389, 0.0168, 0.0396, 0.0541, 0.0208, 0.0324, 0.0356,
        0.0666, 0.0261, 0.0248, 0.1363, 0.0285, 0.0862, 0.1878],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:43,922][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.0117, 0.0128, 0.0265, 0.0365, 0.0161, 0.0254, 0.0396, 0.0562, 0.0562,
        0.0982, 0.0589, 0.0714, 0.1223, 0.0805, 0.2195, 0.0682],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:43,923][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.0020, 0.0012, 0.0004, 0.0022, 0.0011, 0.0036, 0.0064, 0.0075, 0.0528,
        0.0153, 0.0336, 0.0506, 0.1968, 0.1864, 0.2559, 0.1844],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:43,924][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.0364, 0.0037, 0.0010, 0.0012, 0.0015, 0.0050, 0.0039, 0.0170, 0.0351,
        0.0128, 0.0336, 0.0400, 0.2367, 0.1327, 0.2590, 0.1805],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:43,925][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.0403, 0.0388, 0.0279, 0.0096, 0.0237, 0.0110, 0.0160, 0.0183, 0.0306,
        0.1311, 0.0608, 0.0602, 0.2472, 0.0743, 0.1349, 0.0753],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:43,926][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([1.8526e-03, 6.7483e-04, 4.3423e-05, 4.4062e-04, 3.4760e-04, 1.0878e-03,
        1.7966e-03, 3.8059e-03, 4.2454e-02, 1.2049e-02, 6.2631e-02, 3.5128e-02,
        1.8531e-01, 2.7427e-01, 2.5685e-01, 1.2126e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:43,928][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.1314, 0.0132, 0.0054, 0.0046, 0.0096, 0.0151, 0.0090, 0.0678, 0.0553,
        0.0454, 0.0351, 0.0370, 0.2288, 0.0799, 0.1509, 0.1113],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:43,929][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.2695, 0.0236, 0.0117, 0.0120, 0.0224, 0.0190, 0.0100, 0.0248, 0.0312,
        0.0388, 0.0350, 0.0354, 0.1385, 0.0514, 0.1235, 0.1530],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:43,931][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0432, 0.0196, 0.0073, 0.0147, 0.0127, 0.0170, 0.0146, 0.0138, 0.0499,
        0.0593, 0.0630, 0.0438, 0.1557, 0.1308, 0.1883, 0.1662],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:43,932][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.0011, 0.0015, 0.0048, 0.0103, 0.0077, 0.0057, 0.0397, 0.0290, 0.0942,
        0.0269, 0.1545, 0.0600, 0.0555, 0.1003, 0.3684, 0.0404],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:43,933][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([7.9164e-02, 2.6133e-02, 1.5072e-03, 3.6314e-04, 4.8222e-04, 2.5363e-04,
        1.8569e-01, 1.4278e-03, 2.4812e-03, 9.1246e-04, 5.9298e-04, 1.8249e-01,
        8.1557e-04, 4.4864e-03, 5.6842e-03, 2.1245e-03, 5.0540e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:43,935][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0112, 0.0085, 0.0466, 0.0310, 0.0506, 0.0107, 0.0150, 0.0989, 0.0636,
        0.0912, 0.0404, 0.0455, 0.0785, 0.0531, 0.2788, 0.0323, 0.0440],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:43,936][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.1903, 0.1072, 0.0162, 0.0097, 0.0266, 0.0353, 0.0083, 0.0223, 0.0205,
        0.0530, 0.0150, 0.0183, 0.1741, 0.0262, 0.0452, 0.2117, 0.0201],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:43,938][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0206, 0.0108, 0.0197, 0.0315, 0.0115, 0.0182, 0.0201, 0.0509, 0.0525,
        0.1155, 0.0541, 0.0761, 0.1195, 0.0925, 0.1420, 0.0900, 0.0745],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:43,939][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([4.8520e-03, 1.3943e-03, 1.7667e-04, 9.6669e-04, 6.9164e-04, 2.7363e-03,
        1.4781e-03, 6.9865e-03, 2.6085e-02, 9.6539e-03, 1.7266e-02, 2.3678e-02,
        1.3102e-01, 1.8665e-01, 1.7085e-01, 2.6738e-01, 1.4813e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:43,940][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0792, 0.0029, 0.0004, 0.0004, 0.0008, 0.0023, 0.0008, 0.0091, 0.0161,
        0.0067, 0.0224, 0.0164, 0.2442, 0.1366, 0.1929, 0.2092, 0.0595],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:43,942][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.1702, 0.0343, 0.0200, 0.0033, 0.0154, 0.0075, 0.0033, 0.0114, 0.0116,
        0.1006, 0.0267, 0.0258, 0.3577, 0.0335, 0.0840, 0.0734, 0.0213],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:43,943][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([2.2737e-03, 6.0540e-04, 1.8763e-05, 1.7778e-04, 1.4186e-04, 6.9735e-04,
        5.0912e-04, 2.0044e-03, 1.4675e-02, 6.0653e-03, 2.4172e-02, 1.3089e-02,
        1.8358e-01, 2.9332e-01, 1.5815e-01, 1.6161e-01, 1.3891e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:43,944][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.5048, 0.0130, 0.0030, 0.0012, 0.0061, 0.0054, 0.0015, 0.0340, 0.0136,
        0.0187, 0.0114, 0.0101, 0.1527, 0.0384, 0.0900, 0.0798, 0.0162],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:43,946][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.5320, 0.0149, 0.0051, 0.0043, 0.0123, 0.0085, 0.0035, 0.0122, 0.0141,
        0.0219, 0.0167, 0.0173, 0.1039, 0.0282, 0.0564, 0.1220, 0.0269],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:43,947][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.1117, 0.0219, 0.0055, 0.0082, 0.0070, 0.0122, 0.0074, 0.0130, 0.0310,
        0.0508, 0.0363, 0.0323, 0.1460, 0.1130, 0.1561, 0.1561, 0.0912],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:43,948][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0050, 0.0026, 0.0028, 0.0060, 0.0049, 0.0055, 0.0183, 0.0264, 0.0671,
        0.0283, 0.1072, 0.0544, 0.0850, 0.1116, 0.2459, 0.0583, 0.1706],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:43,949][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ drink] are: tensor([2.1110e-02, 1.6148e-02, 1.9230e-03, 4.4674e-04, 7.5592e-04, 2.4859e-04,
        1.8617e-01, 1.5462e-03, 3.6209e-03, 2.2642e-03, 9.0952e-04, 2.1435e-01,
        1.2847e-03, 6.4363e-03, 9.3649e-03, 2.1991e-03, 5.3096e-01, 2.5856e-04],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:43,951][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ drink] are: tensor([0.0068, 0.0161, 0.0642, 0.0587, 0.0994, 0.0169, 0.0577, 0.0878, 0.0765,
        0.0634, 0.0412, 0.0446, 0.0525, 0.0517, 0.1325, 0.0217, 0.0611, 0.0473],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:43,952][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ drink] are: tensor([0.1201, 0.1020, 0.0266, 0.0097, 0.0289, 0.0445, 0.0124, 0.0241, 0.0250,
        0.0508, 0.0211, 0.0198, 0.1411, 0.0222, 0.0566, 0.1713, 0.0203, 0.1036],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:43,954][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ drink] are: tensor([0.0098, 0.0143, 0.0142, 0.0369, 0.0134, 0.0139, 0.0275, 0.0561, 0.0609,
        0.0973, 0.0396, 0.0524, 0.0793, 0.0658, 0.1202, 0.0584, 0.0734, 0.1667],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:43,955][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ drink] are: tensor([1.8929e-03, 6.1471e-04, 1.0331e-04, 5.7881e-04, 4.2422e-04, 1.4875e-03,
        3.8894e-03, 4.1598e-03, 2.7065e-02, 6.6307e-03, 2.3625e-02, 3.7095e-02,
        1.0598e-01, 1.4475e-01, 1.3380e-01, 1.4611e-01, 2.9234e-01, 6.9451e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:43,956][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ drink] are: tensor([0.0182, 0.0017, 0.0004, 0.0005, 0.0007, 0.0022, 0.0025, 0.0065, 0.0231,
        0.0079, 0.0218, 0.0305, 0.1882, 0.1158, 0.2223, 0.1402, 0.1364, 0.0809],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:43,958][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ drink] are: tensor([0.0597, 0.0516, 0.0327, 0.0095, 0.0249, 0.0130, 0.0106, 0.0183, 0.0280,
        0.0916, 0.0383, 0.0349, 0.2015, 0.0609, 0.1145, 0.0776, 0.0364, 0.0961],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:43,959][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ drink] are: tensor([9.4107e-04, 2.7938e-04, 2.7696e-05, 2.1024e-04, 1.7681e-04, 6.9084e-04,
        1.6513e-03, 1.8063e-03, 2.6725e-02, 6.3012e-03, 3.6029e-02, 2.7340e-02,
        1.1276e-01, 1.8073e-01, 2.1160e-01, 7.8696e-02, 2.4809e-01, 6.5940e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:43,960][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ drink] are: tensor([0.2326, 0.0137, 0.0033, 0.0018, 0.0065, 0.0078, 0.0040, 0.0396, 0.0231,
        0.0260, 0.0172, 0.0172, 0.1789, 0.0473, 0.1129, 0.0823, 0.0355, 0.1507],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:43,962][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ drink] are: tensor([0.3636, 0.0207, 0.0086, 0.0049, 0.0156, 0.0109, 0.0039, 0.0233, 0.0177,
        0.0213, 0.0158, 0.0185, 0.0833, 0.0210, 0.0847, 0.1486, 0.0216, 0.1159],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:43,963][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ drink] are: tensor([0.0358, 0.0188, 0.0055, 0.0083, 0.0100, 0.0109, 0.0095, 0.0120, 0.0281,
        0.0445, 0.0374, 0.0303, 0.1295, 0.0994, 0.1711, 0.1194, 0.0857, 0.1436],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:43,965][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ drink] are: tensor([0.0013, 0.0010, 0.0018, 0.0052, 0.0042, 0.0035, 0.0195, 0.0231, 0.0688,
        0.0169, 0.1083, 0.0393, 0.0586, 0.0592, 0.3070, 0.0442, 0.1605, 0.0774],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:43,966][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([1.2128e-01, 3.2413e-02, 2.4095e-03, 4.0376e-04, 8.0032e-04, 2.6993e-04,
        1.7794e-01, 1.8665e-03, 2.6638e-03, 1.2261e-03, 4.9984e-04, 2.0496e-01,
        1.0253e-03, 4.8606e-03, 7.1738e-03, 2.7108e-03, 4.2948e-01, 1.8143e-04,
        7.8247e-03], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:43,968][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0095, 0.0106, 0.0721, 0.0244, 0.0572, 0.0096, 0.0309, 0.0767, 0.0441,
        0.0514, 0.0199, 0.0317, 0.0702, 0.0376, 0.1781, 0.0231, 0.0670, 0.1188,
        0.0670], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:43,969][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.2796, 0.0967, 0.0168, 0.0083, 0.0209, 0.0278, 0.0065, 0.0162, 0.0138,
        0.0395, 0.0131, 0.0124, 0.1296, 0.0185, 0.0380, 0.1635, 0.0134, 0.0707,
        0.0149], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:43,971][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0332, 0.0183, 0.0146, 0.0277, 0.0099, 0.0151, 0.0168, 0.0432, 0.0369,
        0.0666, 0.0391, 0.0592, 0.1015, 0.0730, 0.0961, 0.0737, 0.0647, 0.1123,
        0.0983], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:43,972][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([4.5935e-03, 7.3842e-04, 6.0673e-05, 2.3816e-04, 3.0337e-04, 8.3048e-04,
        1.1009e-03, 2.4981e-03, 8.5440e-03, 4.9687e-03, 9.8652e-03, 1.5703e-02,
        7.0472e-02, 9.5259e-02, 8.7681e-02, 1.3119e-01, 1.2647e-01, 6.4632e-02,
        3.7485e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:43,973][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0953, 0.0037, 0.0004, 0.0003, 0.0006, 0.0016, 0.0007, 0.0057, 0.0088,
        0.0040, 0.0133, 0.0129, 0.1623, 0.0971, 0.1322, 0.1497, 0.0469, 0.0610,
        0.2037], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:43,973][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.2967, 0.0586, 0.0376, 0.0031, 0.0210, 0.0072, 0.0050, 0.0096, 0.0093,
        0.0493, 0.0133, 0.0170, 0.2110, 0.0211, 0.0820, 0.0549, 0.0184, 0.0565,
        0.0283], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:43,974][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([4.3771e-03, 4.4714e-04, 9.0569e-06, 3.5515e-05, 6.6829e-05, 1.9584e-04,
        1.5265e-04, 1.0195e-03, 2.8847e-03, 2.1971e-03, 5.2526e-03, 4.1711e-03,
        8.2316e-02, 1.0519e-01, 7.0167e-02, 5.8318e-02, 4.8488e-02, 1.1938e-01,
        4.9532e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:43,974][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([6.0609e-01, 1.1091e-02, 2.0057e-03, 4.8558e-04, 3.5640e-03, 3.6138e-03,
        8.4875e-04, 1.8016e-02, 6.1956e-03, 9.8959e-03, 6.2059e-03, 5.6050e-03,
        8.8578e-02, 1.6225e-02, 4.4590e-02, 5.2631e-02, 9.2345e-03, 8.5732e-02,
        2.9391e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:43,975][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.6499, 0.0147, 0.0044, 0.0025, 0.0079, 0.0055, 0.0020, 0.0088, 0.0073,
        0.0119, 0.0106, 0.0108, 0.0551, 0.0150, 0.0368, 0.0842, 0.0134, 0.0422,
        0.0170], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:43,975][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.1447, 0.0227, 0.0051, 0.0059, 0.0060, 0.0092, 0.0053, 0.0088, 0.0188,
        0.0298, 0.0267, 0.0216, 0.1061, 0.0776, 0.1277, 0.1338, 0.0653, 0.0862,
        0.0986], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:43,975][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0110, 0.0025, 0.0019, 0.0037, 0.0035, 0.0043, 0.0133, 0.0239, 0.0376,
        0.0180, 0.0748, 0.0416, 0.0669, 0.0736, 0.1605, 0.0386, 0.1217, 0.0681,
        0.2345], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:43,977][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:21:43,978][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[2696],
        [  35],
        [  24],
        [  12],
        [ 653],
        [ 234],
        [ 384],
        [  72],
        [  55],
        [ 134],
        [ 156],
        [ 377],
        [  12],
        [   2],
        [  50],
        [  64],
        [ 350],
        [   5],
        [  10]], device='cuda:0')
[2024-07-24 10:21:43,980][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[3271],
        [  26],
        [  49],
        [  14],
        [1814],
        [ 221],
        [ 113],
        [ 214],
        [ 103],
        [ 227],
        [ 528],
        [ 332],
        [  20],
        [  22],
        [ 186],
        [ 170],
        [ 198],
        [  22],
        [ 102]], device='cuda:0')
[2024-07-24 10:21:43,981][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[11547],
        [12226],
        [ 8727],
        [10354],
        [ 8820],
        [ 9056],
        [ 8584],
        [ 8591],
        [ 8601],
        [ 8597],
        [ 8592],
        [ 7335],
        [ 7288],
        [ 7474],
        [ 7113],
        [ 7313],
        [ 8298],
        [ 8281],
        [ 8209]], device='cuda:0')
[2024-07-24 10:21:43,983][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[19142],
        [27618],
        [25023],
        [23840],
        [31736],
        [33420],
        [30833],
        [29490],
        [27655],
        [27588],
        [26888],
        [26893],
        [26992],
        [27361],
        [26457],
        [26459],
        [26861],
        [27571],
        [28360]], device='cuda:0')
[2024-07-24 10:21:43,985][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[  968],
        [26815],
        [37972],
        [39009],
        [43409],
        [42367],
        [39594],
        [40557],
        [40298],
        [39205],
        [38379],
        [36956],
        [35049],
        [33880],
        [32544],
        [31642],
        [30687],
        [30390],
        [30048]], device='cuda:0')
[2024-07-24 10:21:43,986][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[37188],
        [27761],
        [28838],
        [17392],
        [16670],
        [16509],
        [16765],
        [16658],
        [17152],
        [16968],
        [17027],
        [16958],
        [17177],
        [17215],
        [17218],
        [17056],
        [17276],
        [17327],
        [17641]], device='cuda:0')
[2024-07-24 10:21:43,988][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[46088],
        [38744],
        [25072],
        [32025],
        [32271],
        [32404],
        [32581],
        [32222],
        [33533],
        [34178],
        [34182],
        [33958],
        [33373],
        [33359],
        [32917],
        [33197],
        [33097],
        [32901],
        [33886]], device='cuda:0')
[2024-07-24 10:21:43,989][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[20451],
        [17903],
        [26591],
        [22567],
        [23033],
        [23211],
        [25013],
        [24950],
        [28595],
        [29621],
        [29061],
        [28615],
        [27862],
        [27938],
        [27336],
        [28138],
        [28553],
        [28624],
        [29246]], device='cuda:0')
[2024-07-24 10:21:43,991][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[12004],
        [ 6035],
        [ 5363],
        [ 4426],
        [ 5863],
        [ 5184],
        [ 5031],
        [ 4574],
        [ 4576],
        [ 3908],
        [ 4242],
        [ 4474],
        [ 4133],
        [ 4195],
        [ 4248],
        [ 4200],
        [ 4291],
        [ 4088],
        [ 4182]], device='cuda:0')
[2024-07-24 10:21:43,992][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[32541],
        [32543],
        [32547],
        [32540],
        [32543],
        [32536],
        [32539],
        [32555],
        [32551],
        [32573],
        [32754],
        [32671],
        [32573],
        [32711],
        [32596],
        [32611],
        [32612],
        [32679],
        [32681]], device='cuda:0')
[2024-07-24 10:21:43,994][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[12354],
        [33853],
        [29808],
        [32104],
        [ 4173],
        [ 5871],
        [ 7882],
        [10165],
        [11275],
        [13642],
        [12501],
        [14846],
        [11140],
        [11847],
        [13858],
        [12583],
        [12721],
        [12807],
        [12463]], device='cuda:0')
[2024-07-24 10:21:43,995][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[16599],
        [14280],
        [ 9302],
        [ 6395],
        [ 5066],
        [ 4350],
        [ 6486],
        [ 6250],
        [ 6600],
        [ 5890],
        [ 6079],
        [ 6448],
        [ 6403],
        [ 6329],
        [ 5968],
        [ 5669],
        [ 6076],
        [ 5593],
        [ 6080]], device='cuda:0')
[2024-07-24 10:21:43,997][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[32292],
        [11945],
        [ 8582],
        [ 8634],
        [ 2262],
        [ 3230],
        [ 4941],
        [ 3235],
        [ 7336],
        [11904],
        [12287],
        [10167],
        [15677],
        [13828],
        [16328],
        [16721],
        [17813],
        [21947],
        [21299]], device='cuda:0')
[2024-07-24 10:21:43,998][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[29125],
        [41772],
        [27483],
        [39761],
        [50218],
        [50131],
        [45016],
        [28487],
        [38561],
        [33297],
        [31106],
        [32048],
        [17828],
        [18906],
        [13142],
        [15388],
        [11324],
        [ 9559],
        [16936]], device='cuda:0')
[2024-07-24 10:21:44,000][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 6652],
        [ 5799],
        [ 3902],
        [15250],
        [ 5584],
        [26890],
        [28168],
        [14324],
        [ 7767],
        [11384],
        [ 3631],
        [18145],
        [ 9521],
        [ 1463],
        [ 3657],
        [13570],
        [29279],
        [ 4726],
        [ 3961]], device='cuda:0')
[2024-07-24 10:21:44,001][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[21470],
        [21769],
        [17746],
        [20139],
        [18403],
        [17850],
        [40218],
        [39941],
        [39956],
        [39675],
        [39821],
        [40869],
        [40681],
        [40777],
        [40297],
        [39678],
        [44270],
        [44105],
        [43909]], device='cuda:0')
[2024-07-24 10:21:44,003][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[16104],
        [33647],
        [23505],
        [34989],
        [23377],
        [14437],
        [19023],
        [22697],
        [24997],
        [23302],
        [24405],
        [23756],
        [20415],
        [20185],
        [21436],
        [21635],
        [21916],
        [21623],
        [19880]], device='cuda:0')
[2024-07-24 10:21:44,004][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[24072],
        [25074],
        [13408],
        [15839],
        [ 9723],
        [14400],
        [15486],
        [15434],
        [14147],
        [ 9207],
        [10027],
        [10170],
        [12879],
        [13262],
        [11811],
        [13488],
        [15257],
        [16949],
        [17271]], device='cuda:0')
[2024-07-24 10:21:44,006][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[43529],
        [ 9908],
        [ 6973],
        [ 4926],
        [ 6357],
        [ 5279],
        [ 4625],
        [ 5866],
        [ 7364],
        [ 8969],
        [10189],
        [10486],
        [ 7232],
        [ 8177],
        [ 8165],
        [ 8635],
        [ 8338],
        [10526],
        [ 9040]], device='cuda:0')
[2024-07-24 10:21:44,007][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[21900],
        [35642],
        [36117],
        [41714],
        [44402],
        [46402],
        [44152],
        [40285],
        [34040],
        [33887],
        [32956],
        [34961],
        [33944],
        [29438],
        [34757],
        [39876],
        [39031],
        [34914],
        [34501]], device='cuda:0')
[2024-07-24 10:21:44,009][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[40264],
        [41074],
        [34454],
        [35586],
        [33018],
        [24643],
        [32118],
        [25970],
        [22808],
        [19481],
        [22310],
        [21685],
        [17437],
        [20360],
        [19022],
        [17770],
        [17685],
        [17426],
        [16022]], device='cuda:0')
[2024-07-24 10:21:44,010][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[21731],
        [ 2539],
        [ 1800],
        [ 1617],
        [ 1159],
        [  920],
        [ 1548],
        [ 1515],
        [ 1713],
        [ 2766],
        [ 2782],
        [ 2237],
        [ 7855],
        [ 5501],
        [ 4055],
        [ 4415],
        [ 7714],
        [ 3949],
        [ 5215]], device='cuda:0')
[2024-07-24 10:21:44,012][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[18233],
        [ 9301],
        [10861],
        [ 9194],
        [11150],
        [13070],
        [15421],
        [13785],
        [15689],
        [17494],
        [28476],
        [26798],
        [24388],
        [15066],
        [18841],
        [24098],
        [24233],
        [28146],
        [23271]], device='cuda:0')
[2024-07-24 10:21:44,014][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[26375],
        [36519],
        [35905],
        [35491],
        [43153],
        [38441],
        [40730],
        [34768],
        [40142],
        [34489],
        [40979],
        [40709],
        [33012],
        [37395],
        [29382],
        [22480],
        [29208],
        [21101],
        [32967]], device='cuda:0')
[2024-07-24 10:21:44,015][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[26107],
        [17229],
        [13606],
        [19868],
        [13548],
        [13952],
        [17714],
        [11066],
        [16750],
        [13882],
        [15936],
        [14278],
        [17557],
        [17980],
        [14616],
        [12779],
        [15608],
        [13528],
        [16627]], device='cuda:0')
[2024-07-24 10:21:44,016][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[ 4820],
        [20043],
        [19452],
        [24624],
        [25585],
        [32460],
        [32686],
        [35779],
        [38186],
        [45225],
        [44598],
        [44125],
        [38165],
        [39567],
        [38462],
        [37816],
        [35964],
        [36628],
        [35617]], device='cuda:0')
[2024-07-24 10:21:44,018][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[16353],
        [48457],
        [46467],
        [47453],
        [40254],
        [40792],
        [46470],
        [42910],
        [42511],
        [45605],
        [49834],
        [49865],
        [49704],
        [49536],
        [49194],
        [49411],
        [49387],
        [49596],
        [49393]], device='cuda:0')
[2024-07-24 10:21:44,020][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[15095],
        [12275],
        [22951],
        [11953],
        [17298],
        [18654],
        [12147],
        [19794],
        [18137],
        [16984],
        [ 8817],
        [10310],
        [12642],
        [13417],
        [15626],
        [13947],
        [10835],
        [12281],
        [11654]], device='cuda:0')
[2024-07-24 10:21:44,021][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[39115],
        [25114],
        [32324],
        [28269],
        [32023],
        [34803],
        [20766],
        [34416],
        [28276],
        [44851],
        [34795],
        [19777],
        [32698],
        [42227],
        [43568],
        [39329],
        [25479],
        [45178],
        [31877]], device='cuda:0')
[2024-07-24 10:21:44,022][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[19507],
        [19507],
        [19507],
        [19507],
        [19507],
        [19507],
        [19507],
        [19507],
        [19507],
        [19507],
        [19507],
        [19507],
        [19507],
        [19507],
        [19507],
        [19507],
        [19507],
        [19507],
        [19507]], device='cuda:0')
[2024-07-24 10:21:44,090][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:21:44,090][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:44,090][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:44,091][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:44,091][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:44,091][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:44,092][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:44,092][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:44,092][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:44,093][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:44,093][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:44,093][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:44,093][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:44,094][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.8743, 0.1257], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:44,094][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0202, 0.9798], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:44,096][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.5933, 0.4067], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:44,097][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.5945, 0.4055], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:44,098][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.2866, 0.7134], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:44,100][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.1684, 0.8316], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:44,101][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0391, 0.9609], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:44,103][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.1221, 0.8779], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:44,104][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.3968, 0.6032], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:44,105][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.3335, 0.6665], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:44,107][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.2686, 0.7314], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:44,108][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0969, 0.9031], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:44,110][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Anthony] are: tensor([0.3891, 0.1602, 0.4507], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:44,111][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Anthony] are: tensor([0.0165, 0.7091, 0.2744], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:44,112][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Anthony] are: tensor([0.5687, 0.2691, 0.1622], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:44,114][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Anthony] are: tensor([0.5356, 0.3360, 0.1284], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:44,115][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Anthony] are: tensor([0.0797, 0.2604, 0.6599], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:44,116][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Anthony] are: tensor([0.1790, 0.2920, 0.5291], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:44,116][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Anthony] are: tensor([0.0028, 0.0369, 0.9602], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:44,116][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Anthony] are: tensor([0.0513, 0.4389, 0.5098], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:44,117][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Anthony] are: tensor([0.2665, 0.2551, 0.4784], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:44,117][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Anthony] are: tensor([0.1680, 0.0595, 0.7725], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:44,117][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Anthony] are: tensor([0.2153, 0.4214, 0.3633], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:44,118][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Anthony] are: tensor([0.0527, 0.5717, 0.3756], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:44,118][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.7223, 0.0616, 0.1415, 0.0746], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:44,118][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0211, 0.4891, 0.2072, 0.2826], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:44,119][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.6141, 0.2193, 0.0600, 0.1066], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:44,120][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.3251, 0.2326, 0.0468, 0.3954], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:44,121][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.2955, 0.1493, 0.2787, 0.2765], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:44,122][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.2111, 0.2704, 0.3658, 0.1526], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:44,123][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ and] are: tensor([4.7238e-04, 9.5256e-03, 2.1619e-01, 7.7382e-01], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:44,124][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0265, 0.2350, 0.2949, 0.4437], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:44,125][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.2011, 0.2603, 0.2327, 0.3059], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:44,127][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.1915, 0.0981, 0.5385, 0.1719], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:44,128][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0650, 0.0182, 0.0076, 0.9093], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:44,129][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0058, 0.1537, 0.1439, 0.6966], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:44,131][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Travis] are: tensor([0.3173, 0.1250, 0.2666, 0.1249, 0.1661], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:44,132][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Travis] are: tensor([0.0064, 0.4804, 0.1220, 0.2014, 0.1897], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:44,133][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Travis] are: tensor([0.3226, 0.1916, 0.0816, 0.0969, 0.3073], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:44,135][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Travis] are: tensor([0.1680, 0.1619, 0.0535, 0.5706, 0.0460], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:44,136][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Travis] are: tensor([0.0709, 0.1673, 0.2044, 0.1809, 0.3765], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:44,138][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Travis] are: tensor([0.0722, 0.1924, 0.2818, 0.0677, 0.3859], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:44,139][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Travis] are: tensor([0.0009, 0.0085, 0.1453, 0.6856, 0.1597], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:44,140][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Travis] are: tensor([0.0286, 0.1828, 0.2019, 0.3304, 0.2564], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:44,142][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Travis] are: tensor([0.2172, 0.1447, 0.1888, 0.2175, 0.2317], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:44,143][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Travis] are: tensor([0.1779, 0.0668, 0.2915, 0.1822, 0.2816], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:44,144][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Travis] are: tensor([0.0091, 0.0102, 0.0091, 0.8330, 0.1386], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:44,146][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Travis] are: tensor([0.0242, 0.1362, 0.1086, 0.6093, 0.1217], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:44,147][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.5146, 0.0537, 0.0845, 0.0650, 0.0517, 0.2305], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:44,148][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.0073, 0.4108, 0.1074, 0.1546, 0.0898, 0.2301], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:44,150][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.2290, 0.1419, 0.0962, 0.1272, 0.2420, 0.1637], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:44,151][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.1649, 0.2433, 0.0542, 0.3341, 0.0634, 0.1401], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:44,153][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.0344, 0.0662, 0.1990, 0.1695, 0.4218, 0.1091], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:44,154][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.0375, 0.1371, 0.2143, 0.0784, 0.3676, 0.1652], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:44,155][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ had] are: tensor([1.5893e-04, 3.6397e-03, 1.5947e-01, 5.7919e-01, 1.6062e-01, 9.6927e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:44,156][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.0168, 0.1384, 0.1672, 0.2542, 0.2353, 0.1882], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:44,158][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.1041, 0.1216, 0.1168, 0.1229, 0.1625, 0.3721], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:44,159][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.0162, 0.0346, 0.2528, 0.0933, 0.1660, 0.4371], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:44,160][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.0409, 0.0124, 0.0028, 0.2427, 0.0599, 0.6412], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:44,162][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0027, 0.1069, 0.0979, 0.4455, 0.1473, 0.1997], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:44,163][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.4065, 0.0466, 0.1064, 0.0591, 0.0541, 0.2344, 0.0929],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:44,164][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0040, 0.3299, 0.0632, 0.1391, 0.0497, 0.1448, 0.2692],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:44,166][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.4670, 0.1041, 0.0370, 0.0488, 0.2063, 0.0910, 0.0457],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:44,167][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.2729, 0.1568, 0.0221, 0.2276, 0.0416, 0.2161, 0.0629],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:44,169][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.2274, 0.0939, 0.2035, 0.1026, 0.2468, 0.0759, 0.0498],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:44,170][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.1249, 0.1402, 0.2142, 0.0637, 0.2725, 0.1099, 0.0747],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:44,171][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ a] are: tensor([2.1907e-04, 3.5363e-03, 7.4441e-02, 3.2524e-01, 8.7467e-02, 7.1364e-02,
        4.3773e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:44,172][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0143, 0.1082, 0.1130, 0.1712, 0.1659, 0.1403, 0.2871],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:44,174][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.1662, 0.1025, 0.1011, 0.1179, 0.1198, 0.2385, 0.1541],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:44,175][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0216, 0.0223, 0.2367, 0.0956, 0.1683, 0.3520, 0.1035],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:44,176][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ a] are: tensor([1.2487e-01, 6.3707e-03, 4.0494e-04, 8.1868e-02, 1.0431e-02, 2.1296e-01,
        5.6310e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:44,177][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0050, 0.0854, 0.0640, 0.2718, 0.1327, 0.1157, 0.3255],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:44,179][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ lot] are: tensor([0.2761, 0.0432, 0.0745, 0.0710, 0.0377, 0.2458, 0.0677, 0.1840],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:44,179][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ lot] are: tensor([0.0010, 0.1986, 0.0446, 0.0784, 0.0501, 0.1164, 0.2630, 0.2479],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:44,180][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ lot] are: tensor([0.1658, 0.1058, 0.0668, 0.0695, 0.1519, 0.1022, 0.1276, 0.2104],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:44,180][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ lot] are: tensor([0.1598, 0.1382, 0.0323, 0.2514, 0.0282, 0.1653, 0.1782, 0.0465],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:44,181][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ lot] are: tensor([0.0137, 0.0889, 0.1813, 0.1736, 0.2067, 0.0689, 0.1223, 0.1447],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:44,181][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ lot] are: tensor([0.0727, 0.0903, 0.1245, 0.0336, 0.1113, 0.0852, 0.0460, 0.4364],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:44,181][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ lot] are: tensor([7.8069e-05, 1.2516e-03, 6.0277e-02, 2.5720e-01, 6.6261e-02, 4.2724e-02,
        5.5595e-01, 1.6267e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:44,182][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ lot] are: tensor([0.0090, 0.0729, 0.0903, 0.1427, 0.1261, 0.1142, 0.2584, 0.1864],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:44,182][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ lot] are: tensor([0.0516, 0.0678, 0.0836, 0.0999, 0.0984, 0.2323, 0.1291, 0.2374],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:44,184][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ lot] are: tensor([0.0289, 0.0320, 0.1894, 0.0764, 0.1767, 0.3227, 0.1026, 0.0712],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:44,185][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ lot] are: tensor([1.0756e-02, 2.3758e-03, 5.2083e-04, 3.1223e-02, 3.2346e-03, 6.4279e-02,
        8.2208e-01, 6.5526e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:44,186][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ lot] are: tensor([0.0004, 0.0175, 0.0442, 0.2882, 0.0860, 0.0759, 0.3181, 0.1698],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:44,187][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ of] are: tensor([0.3023, 0.0449, 0.0850, 0.0568, 0.0514, 0.1722, 0.0811, 0.1239, 0.0824],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:44,189][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ of] are: tensor([0.0031, 0.1917, 0.0690, 0.0912, 0.0509, 0.1260, 0.2386, 0.1185, 0.1111],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:44,190][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ of] are: tensor([0.2280, 0.0990, 0.0478, 0.0368, 0.2080, 0.0690, 0.0402, 0.1016, 0.1696],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:44,191][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ of] are: tensor([0.1284, 0.1706, 0.0291, 0.1177, 0.0181, 0.0611, 0.0681, 0.0392, 0.3677],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:44,193][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ of] are: tensor([0.1047, 0.0881, 0.1501, 0.0923, 0.2984, 0.0493, 0.0629, 0.1022, 0.0520],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:44,194][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ of] are: tensor([0.0334, 0.0504, 0.0945, 0.0371, 0.1204, 0.0605, 0.0357, 0.2945, 0.2734],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:44,195][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ of] are: tensor([8.2494e-05, 1.6325e-03, 5.4646e-02, 1.8344e-01, 6.0109e-02, 3.6588e-02,
        3.8287e-01, 1.9858e-02, 2.6078e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:44,196][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ of] are: tensor([0.0097, 0.0669, 0.0706, 0.1100, 0.1015, 0.0891, 0.1979, 0.1373, 0.2169],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:44,198][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ of] are: tensor([0.0425, 0.0646, 0.0613, 0.0777, 0.0949, 0.1453, 0.1075, 0.1981, 0.2081],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:44,199][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ of] are: tensor([0.0123, 0.0202, 0.2668, 0.0619, 0.1453, 0.2162, 0.0857, 0.1035, 0.0880],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:44,200][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ of] are: tensor([2.6670e-02, 6.7186e-04, 3.7262e-05, 1.4175e-03, 4.1262e-04, 9.5286e-03,
        2.8783e-02, 3.3200e-02, 8.9928e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:44,202][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ of] are: tensor([0.0016, 0.0544, 0.0426, 0.1912, 0.0669, 0.0636, 0.2928, 0.1223, 0.1646],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:44,203][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ fun] are: tensor([0.2741, 0.0364, 0.0693, 0.0391, 0.0371, 0.1251, 0.0791, 0.1432, 0.0833,
        0.1133], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:44,205][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ fun] are: tensor([0.0019, 0.1909, 0.0478, 0.1047, 0.0395, 0.1263, 0.1971, 0.0870, 0.1593,
        0.0454], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:44,206][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ fun] are: tensor([0.2307, 0.0649, 0.0346, 0.0372, 0.1052, 0.0686, 0.0571, 0.0980, 0.1735,
        0.1302], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:44,208][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ fun] are: tensor([0.0358, 0.0555, 0.0156, 0.1031, 0.0084, 0.0476, 0.0789, 0.0339, 0.5825,
        0.0387], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:44,209][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ fun] are: tensor([0.0164, 0.0612, 0.1445, 0.1197, 0.1564, 0.0519, 0.0831, 0.1257, 0.0673,
        0.1739], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:44,211][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ fun] are: tensor([0.0265, 0.0312, 0.0496, 0.0173, 0.0514, 0.0333, 0.0298, 0.1702, 0.1560,
        0.4347], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:44,211][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ fun] are: tensor([1.6242e-04, 2.1086e-03, 4.3832e-02, 1.5849e-01, 2.3206e-02, 2.7970e-02,
        4.1779e-01, 1.4081e-02, 2.0380e-01, 1.0856e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:44,213][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ fun] are: tensor([0.0060, 0.0544, 0.0605, 0.0949, 0.0814, 0.0780, 0.1689, 0.1272, 0.1798,
        0.1489], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:44,214][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ fun] are: tensor([0.0301, 0.0577, 0.0632, 0.0742, 0.0893, 0.1398, 0.0967, 0.1462, 0.1626,
        0.1402], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:44,216][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ fun] are: tensor([0.0186, 0.0095, 0.1463, 0.0564, 0.0970, 0.3053, 0.0640, 0.1597, 0.0661,
        0.0772], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:44,217][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ fun] are: tensor([1.7116e-03, 2.3162e-04, 3.0956e-05, 1.3874e-03, 1.7062e-04, 5.8281e-03,
        4.9976e-02, 2.2020e-02, 8.3454e-01, 8.4105e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:44,218][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ fun] are: tensor([0.0021, 0.0342, 0.0320, 0.1083, 0.0527, 0.0522, 0.2924, 0.1429, 0.1483,
        0.1346], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:44,220][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.1398, 0.0285, 0.0808, 0.0518, 0.0500, 0.1861, 0.0664, 0.1530, 0.0618,
        0.1183, 0.0635], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:44,221][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.0009, 0.1293, 0.0605, 0.0932, 0.0584, 0.0939, 0.2327, 0.1249, 0.1058,
        0.0374, 0.0631], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:44,222][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.2787, 0.0676, 0.0254, 0.0227, 0.0803, 0.0411, 0.0225, 0.0648, 0.1144,
        0.1137, 0.1688], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:44,224][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.1115, 0.1163, 0.0162, 0.0518, 0.0106, 0.0456, 0.0281, 0.0569, 0.3920,
        0.0618, 0.1092], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:44,225][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.0366, 0.0652, 0.0745, 0.1201, 0.1378, 0.0565, 0.0772, 0.1213, 0.0504,
        0.2206, 0.0397], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:44,227][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.0215, 0.0268, 0.0404, 0.0180, 0.0356, 0.0282, 0.0213, 0.1264, 0.1206,
        0.3308, 0.2304], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:44,228][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ at] are: tensor([1.5463e-04, 1.2570e-03, 3.1304e-02, 1.4795e-01, 2.2009e-02, 3.2041e-02,
        3.2312e-01, 1.4185e-02, 1.6809e-01, 9.0848e-02, 1.6905e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:44,229][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0060, 0.0502, 0.0535, 0.0812, 0.0726, 0.0693, 0.1473, 0.1065, 0.1593,
        0.1307, 0.1235], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:44,231][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.0598, 0.0374, 0.0599, 0.0541, 0.0759, 0.1375, 0.0863, 0.1579, 0.1441,
        0.1098, 0.0774], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:44,232][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.0121, 0.0174, 0.2079, 0.0640, 0.1291, 0.2390, 0.0568, 0.0994, 0.0756,
        0.0797, 0.0190], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:44,233][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ at] are: tensor([9.9789e-03, 9.3380e-04, 5.4519e-05, 1.4001e-03, 3.3577e-04, 7.2673e-03,
        2.5550e-02, 3.9705e-02, 4.7437e-01, 1.8350e-01, 2.5691e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:44,235][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.0017, 0.0302, 0.0230, 0.1180, 0.0417, 0.0537, 0.2924, 0.1126, 0.2242,
        0.0549, 0.0475], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:44,236][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.2183, 0.0254, 0.0771, 0.0360, 0.0452, 0.1321, 0.0512, 0.1164, 0.0587,
        0.0877, 0.0548, 0.0969], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:44,237][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0020, 0.1345, 0.0382, 0.0707, 0.0461, 0.0881, 0.1374, 0.1618, 0.1170,
        0.0501, 0.0706, 0.0834], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:44,238][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.1652, 0.0627, 0.0359, 0.0281, 0.1140, 0.0425, 0.0234, 0.0517, 0.1071,
        0.1239, 0.1546, 0.0909], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:44,238][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0331, 0.0647, 0.0110, 0.0576, 0.0076, 0.0252, 0.0296, 0.0271, 0.4986,
        0.0450, 0.1708, 0.0297], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:44,238][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0517, 0.0706, 0.0749, 0.0851, 0.1476, 0.0477, 0.0508, 0.2107, 0.0410,
        0.1465, 0.0345, 0.0391], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:44,239][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0077, 0.0148, 0.0256, 0.0137, 0.0362, 0.0197, 0.0144, 0.1012, 0.0977,
        0.4086, 0.1559, 0.1045], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:44,239][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ the] are: tensor([1.7483e-04, 1.1066e-03, 3.2503e-02, 1.3263e-01, 1.9416e-02, 2.1979e-02,
        2.7419e-01, 9.7121e-03, 1.5744e-01, 1.1945e-01, 1.7499e-01, 5.6414e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:44,240][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0060, 0.0448, 0.0478, 0.0739, 0.0629, 0.0627, 0.1316, 0.0894, 0.1461,
        0.1237, 0.1127, 0.0983], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:44,240][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0773, 0.0428, 0.0549, 0.0519, 0.0642, 0.1236, 0.0671, 0.1313, 0.1376,
        0.1081, 0.0759, 0.0653], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:44,241][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0132, 0.0094, 0.2535, 0.0491, 0.1141, 0.2184, 0.0538, 0.1064, 0.0544,
        0.0764, 0.0168, 0.0346], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:44,242][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ the] are: tensor([7.4740e-03, 6.3333e-04, 3.7804e-05, 1.5108e-03, 2.2300e-04, 6.0640e-03,
        1.7024e-02, 2.8262e-02, 4.0345e-01, 6.5067e-02, 2.1129e-01, 2.5897e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:44,244][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0010, 0.0274, 0.0269, 0.1082, 0.0290, 0.0420, 0.2243, 0.0797, 0.1831,
        0.1007, 0.0580, 0.1199], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:44,245][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ hospital] are: tensor([0.1260, 0.0455, 0.0850, 0.0329, 0.0388, 0.1594, 0.0521, 0.1445, 0.0425,
        0.0895, 0.0573, 0.0822, 0.0442], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:44,246][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ hospital] are: tensor([0.0024, 0.1569, 0.0382, 0.0695, 0.0348, 0.1028, 0.1351, 0.0905, 0.1159,
        0.0508, 0.0704, 0.1150, 0.0177], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:44,248][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ hospital] are: tensor([0.1591, 0.0550, 0.0201, 0.0234, 0.0709, 0.0460, 0.0238, 0.0456, 0.0789,
        0.0670, 0.1008, 0.0706, 0.2387], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:44,249][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ hospital] are: tensor([0.0723, 0.1262, 0.0240, 0.0819, 0.0098, 0.0321, 0.0265, 0.0316, 0.3461,
        0.0423, 0.0966, 0.0241, 0.0866], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:44,251][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ hospital] are: tensor([0.0267, 0.0732, 0.0828, 0.0658, 0.1425, 0.0358, 0.0484, 0.1339, 0.0376,
        0.0709, 0.0283, 0.0583, 0.1958], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:44,252][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ hospital] are: tensor([0.0090, 0.0115, 0.0182, 0.0063, 0.0212, 0.0120, 0.0085, 0.0454, 0.0399,
        0.1644, 0.0784, 0.0428, 0.5424], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:44,253][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ hospital] are: tensor([9.3186e-05, 1.0422e-03, 2.4288e-02, 1.1562e-01, 1.8017e-02, 2.1274e-02,
        2.9417e-01, 1.0853e-02, 1.9625e-01, 7.5957e-02, 1.7254e-01, 5.9374e-02,
        1.0514e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:44,255][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ hospital] are: tensor([0.0107, 0.0403, 0.0399, 0.0658, 0.0512, 0.0512, 0.1154, 0.0677, 0.1335,
        0.0968, 0.1042, 0.0905, 0.1328], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:44,256][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ hospital] are: tensor([0.0421, 0.0430, 0.0513, 0.0466, 0.0515, 0.1364, 0.0736, 0.1298, 0.1379,
        0.0766, 0.0674, 0.0974, 0.0463], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:44,258][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ hospital] are: tensor([0.0371, 0.0090, 0.1834, 0.0408, 0.0589, 0.1945, 0.0564, 0.1350, 0.0505,
        0.0924, 0.0175, 0.0320, 0.0926], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:44,259][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ hospital] are: tensor([5.7222e-03, 7.8887e-04, 3.4735e-05, 7.7412e-04, 9.0243e-05, 2.1619e-03,
        1.6520e-02, 8.1709e-03, 1.1961e-01, 2.5114e-02, 5.7542e-02, 1.8320e-01,
        5.8028e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:44,260][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ hospital] are: tensor([0.0030, 0.0173, 0.0177, 0.0877, 0.0203, 0.0375, 0.2996, 0.0869, 0.1693,
        0.0544, 0.0859, 0.0985, 0.0220], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:44,262][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.1786, 0.0270, 0.0563, 0.0330, 0.0435, 0.1261, 0.0564, 0.1119, 0.0561,
        0.0821, 0.0509, 0.1058, 0.0394, 0.0328], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:44,263][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.0008, 0.1111, 0.0334, 0.0777, 0.0266, 0.0781, 0.1568, 0.1094, 0.0891,
        0.0344, 0.0592, 0.1141, 0.0127, 0.0968], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:44,264][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.1000, 0.0516, 0.0252, 0.0140, 0.0862, 0.0302, 0.0136, 0.0298, 0.0689,
        0.0716, 0.0754, 0.0639, 0.2898, 0.0798], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:44,266][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0391, 0.1395, 0.0263, 0.0620, 0.0113, 0.0203, 0.0199, 0.0380, 0.2402,
        0.0529, 0.0753, 0.0200, 0.1156, 0.1397], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:44,267][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0498, 0.0663, 0.0674, 0.0752, 0.1518, 0.0416, 0.0501, 0.0761, 0.0313,
        0.1101, 0.0333, 0.0645, 0.1280, 0.0545], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:44,269][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.0062, 0.0078, 0.0145, 0.0073, 0.0194, 0.0153, 0.0076, 0.0546, 0.0493,
        0.1538, 0.0804, 0.0486, 0.5165, 0.0188], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:44,270][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [.] are: tensor([7.6151e-05, 9.5579e-04, 3.0752e-02, 1.0996e-01, 3.9381e-02, 1.9064e-02,
        2.2801e-01, 8.7030e-03, 1.5676e-01, 1.1158e-01, 1.6059e-01, 5.7974e-02,
        1.6053e-02, 6.0137e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:44,271][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0050, 0.0359, 0.0375, 0.0605, 0.0521, 0.0471, 0.1098, 0.0628, 0.1170,
        0.0840, 0.0919, 0.0817, 0.0983, 0.1164], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:44,273][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.0253, 0.0401, 0.0398, 0.0507, 0.0552, 0.1181, 0.0724, 0.1189, 0.1239,
        0.0880, 0.0664, 0.0708, 0.0514, 0.0790], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:44,274][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.0068, 0.0092, 0.2451, 0.0406, 0.1170, 0.1762, 0.0550, 0.0776, 0.0520,
        0.0776, 0.0150, 0.0230, 0.0801, 0.0248], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:44,275][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [.] are: tensor([1.7491e-02, 6.0188e-04, 2.2447e-05, 4.4218e-04, 5.9848e-05, 1.0785e-03,
        4.1022e-03, 3.3510e-03, 1.8842e-02, 1.0772e-02, 1.3100e-02, 4.0628e-02,
        2.2266e-01, 6.6685e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:44,277][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0014, 0.0147, 0.0217, 0.0768, 0.0366, 0.0280, 0.3274, 0.0819, 0.1010,
        0.1001, 0.0713, 0.0844, 0.0279, 0.0267], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:44,278][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Anthony] are: tensor([0.1320, 0.0314, 0.0727, 0.0370, 0.0355, 0.0994, 0.0438, 0.0901, 0.0613,
        0.0788, 0.0463, 0.0682, 0.0313, 0.0560, 0.1161], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:44,280][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Anthony] are: tensor([0.0017, 0.1178, 0.0316, 0.0753, 0.0253, 0.0668, 0.1330, 0.0811, 0.0960,
        0.0400, 0.0472, 0.0965, 0.0135, 0.1350, 0.0392], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:44,281][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Anthony] are: tensor([0.0879, 0.0407, 0.0233, 0.0122, 0.0384, 0.0205, 0.0133, 0.0291, 0.0531,
        0.0591, 0.0794, 0.0475, 0.2969, 0.0814, 0.1172], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:44,283][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Anthony] are: tensor([0.0297, 0.0287, 0.0055, 0.0062, 0.0025, 0.0067, 0.0056, 0.0122, 0.1115,
        0.0344, 0.0485, 0.0152, 0.2380, 0.2285, 0.2269], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:44,284][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Anthony] are: tensor([0.0236, 0.0724, 0.0746, 0.0633, 0.1470, 0.0240, 0.0308, 0.1435, 0.0287,
        0.0570, 0.0187, 0.0490, 0.0936, 0.0513, 0.1225], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:44,286][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Anthony] are: tensor([0.0065, 0.0089, 0.0200, 0.0041, 0.0267, 0.0085, 0.0060, 0.0368, 0.0360,
        0.1525, 0.0641, 0.0349, 0.4543, 0.0097, 0.1310], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:44,287][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Anthony] are: tensor([6.6555e-05, 8.8556e-04, 2.4423e-02, 1.1110e-01, 2.7856e-02, 1.7744e-02,
        1.7477e-01, 9.4381e-03, 1.2993e-01, 8.5920e-02, 1.1262e-01, 4.6777e-02,
        1.7235e-02, 4.9673e-02, 1.9156e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:44,288][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Anthony] are: tensor([0.0081, 0.0346, 0.0317, 0.0495, 0.0421, 0.0370, 0.0852, 0.0534, 0.0996,
        0.0715, 0.0815, 0.0715, 0.1007, 0.1101, 0.1235], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:44,290][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Anthony] are: tensor([0.0707, 0.0307, 0.0527, 0.0508, 0.0453, 0.0932, 0.0582, 0.1116, 0.1187,
        0.0830, 0.0455, 0.0554, 0.0529, 0.0725, 0.0587], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:44,291][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Anthony] are: tensor([0.0092, 0.0055, 0.1155, 0.0222, 0.0316, 0.1454, 0.0263, 0.0782, 0.0340,
        0.0471, 0.0115, 0.0259, 0.0592, 0.0215, 0.3669], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:44,292][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Anthony] are: tensor([1.7715e-03, 3.3721e-05, 1.0375e-06, 9.9182e-06, 4.1702e-06, 1.1217e-04,
        6.8911e-04, 8.6886e-04, 1.0461e-02, 3.4943e-03, 8.1515e-03, 2.3250e-02,
        2.2790e-01, 4.2687e-01, 2.9638e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:44,294][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Anthony] are: tensor([0.0025, 0.0370, 0.0284, 0.0724, 0.0233, 0.0581, 0.2216, 0.0948, 0.1123,
        0.1310, 0.0396, 0.0678, 0.0331, 0.0414, 0.0365], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:44,295][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.1859, 0.0174, 0.0479, 0.0203, 0.0287, 0.0863, 0.0315, 0.0850, 0.0513,
        0.0623, 0.0349, 0.0714, 0.0241, 0.0295, 0.0781, 0.1454],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:44,295][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0005, 0.0830, 0.0251, 0.0462, 0.0227, 0.0638, 0.1469, 0.0843, 0.1109,
        0.0253, 0.0552, 0.1170, 0.0093, 0.1414, 0.0328, 0.0355],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:44,296][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0216, 0.0202, 0.0146, 0.0178, 0.0567, 0.0252, 0.0194, 0.0259, 0.0602,
        0.0676, 0.0747, 0.0619, 0.2461, 0.0948, 0.0904, 0.1030],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:44,296][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.0078, 0.0252, 0.0075, 0.0132, 0.0041, 0.0075, 0.0103, 0.0190, 0.1570,
        0.0401, 0.0607, 0.0213, 0.1852, 0.1584, 0.2158, 0.0671],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:44,297][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.0036, 0.0233, 0.0672, 0.0529, 0.0668, 0.0259, 0.0517, 0.0472, 0.0425,
        0.0954, 0.0355, 0.0640, 0.0880, 0.0831, 0.1796, 0.0733],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:44,297][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.0024, 0.0076, 0.0117, 0.0069, 0.0159, 0.0106, 0.0068, 0.0462, 0.0447,
        0.1341, 0.0767, 0.0420, 0.4578, 0.0212, 0.0674, 0.0482],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:44,298][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([1.4203e-05, 3.1038e-04, 1.7200e-02, 6.0481e-02, 2.4697e-02, 1.2028e-02,
        2.0325e-01, 6.4130e-03, 1.1684e-01, 8.3976e-02, 1.3152e-01, 4.9287e-02,
        1.0876e-02, 4.2036e-02, 2.3091e-01, 1.0177e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:44,299][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0038, 0.0217, 0.0257, 0.0413, 0.0347, 0.0321, 0.0810, 0.0505, 0.0949,
        0.0683, 0.0798, 0.0716, 0.1097, 0.1006, 0.1213, 0.0631],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:44,300][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.0244, 0.0378, 0.0423, 0.0459, 0.0619, 0.1051, 0.0538, 0.1175, 0.0879,
        0.0917, 0.0624, 0.0644, 0.0427, 0.0663, 0.0421, 0.0539],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:44,302][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.0029, 0.0110, 0.1602, 0.0339, 0.0668, 0.1867, 0.0364, 0.0383, 0.0319,
        0.0477, 0.0110, 0.0171, 0.0470, 0.0164, 0.2627, 0.0301],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:44,303][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([4.0140e-04, 5.9660e-05, 3.7583e-06, 1.0783e-04, 2.1580e-05, 3.4757e-04,
        2.5512e-03, 1.7684e-03, 1.9450e-02, 4.6496e-03, 1.0549e-02, 2.0851e-02,
        1.2643e-01, 2.9660e-01, 3.2279e-01, 1.9341e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:44,304][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([1.7985e-04, 7.3956e-03, 1.6419e-02, 7.3411e-02, 1.9225e-02, 3.6212e-02,
        4.0026e-01, 7.1109e-02, 9.7659e-02, 3.5812e-02, 4.3606e-02, 6.1606e-02,
        1.3402e-02, 3.1817e-02, 4.0029e-02, 5.1852e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:44,305][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0995, 0.0164, 0.0452, 0.0213, 0.0270, 0.0828, 0.0401, 0.0787, 0.0357,
        0.0551, 0.0478, 0.0851, 0.0249, 0.0282, 0.0721, 0.1817, 0.0586],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:44,307][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0010, 0.1130, 0.0240, 0.0689, 0.0177, 0.0525, 0.1205, 0.0971, 0.0877,
        0.0274, 0.0503, 0.0627, 0.0122, 0.1156, 0.0238, 0.0295, 0.0962],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:44,308][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0857, 0.0252, 0.0115, 0.0088, 0.0362, 0.0189, 0.0090, 0.0214, 0.0480,
        0.0567, 0.0784, 0.0549, 0.2216, 0.0740, 0.0895, 0.1312, 0.0290],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:44,310][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0037, 0.0133, 0.0024, 0.0053, 0.0019, 0.0049, 0.0022, 0.0189, 0.0693,
        0.0297, 0.0352, 0.0080, 0.1593, 0.2783, 0.1866, 0.1701, 0.0111],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:44,311][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0276, 0.0271, 0.0531, 0.0421, 0.0603, 0.0272, 0.0215, 0.0844, 0.0301,
        0.0892, 0.0205, 0.0587, 0.1428, 0.0516, 0.0817, 0.1443, 0.0376],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:44,312][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0060, 0.0067, 0.0098, 0.0061, 0.0096, 0.0068, 0.0082, 0.0527, 0.0471,
        0.1610, 0.0803, 0.0468, 0.4237, 0.0205, 0.0547, 0.0347, 0.0251],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:44,314][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ a] are: tensor([9.7173e-05, 8.0398e-04, 1.7413e-02, 8.7670e-02, 1.8104e-02, 1.6373e-02,
        1.4610e-01, 1.1074e-02, 1.3019e-01, 8.2533e-02, 1.2814e-01, 5.0108e-02,
        1.2326e-02, 4.7589e-02, 1.4468e-01, 1.6784e-02, 9.0011e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:44,315][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0053, 0.0285, 0.0296, 0.0432, 0.0401, 0.0351, 0.0727, 0.0518, 0.0829,
        0.0685, 0.0663, 0.0624, 0.0860, 0.0908, 0.0983, 0.0588, 0.0799],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:44,316][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0874, 0.0333, 0.0372, 0.0431, 0.0405, 0.0991, 0.0536, 0.0878, 0.0964,
        0.0681, 0.0555, 0.0506, 0.0462, 0.0639, 0.0411, 0.0506, 0.0457],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:44,318][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0030, 0.0040, 0.0907, 0.0263, 0.0407, 0.1042, 0.0288, 0.0764, 0.0379,
        0.0460, 0.0156, 0.0218, 0.0658, 0.0210, 0.3538, 0.0447, 0.0193],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:44,319][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ a] are: tensor([2.4469e-03, 7.9262e-05, 1.3958e-06, 3.5844e-05, 5.0659e-06, 1.4648e-04,
        2.4258e-04, 8.6562e-04, 5.8920e-03, 2.1584e-03, 4.7449e-03, 7.4002e-03,
        1.1324e-01, 3.2047e-01, 1.4669e-01, 1.8382e-01, 2.1176e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:44,320][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0014, 0.0178, 0.0230, 0.0651, 0.0260, 0.0390, 0.1632, 0.0836, 0.1038,
        0.0759, 0.0347, 0.0706, 0.0347, 0.0270, 0.0453, 0.0699, 0.1193],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:44,322][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ drink] are: tensor([0.1538, 0.0169, 0.0275, 0.0170, 0.0187, 0.0726, 0.0388, 0.0835, 0.0416,
        0.0588, 0.0379, 0.0794, 0.0184, 0.0320, 0.0496, 0.1274, 0.0625, 0.0635],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:44,323][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ drink] are: tensor([0.0011, 0.1162, 0.0259, 0.0671, 0.0236, 0.0699, 0.1179, 0.0680, 0.0796,
        0.0206, 0.0416, 0.0813, 0.0078, 0.1016, 0.0260, 0.0397, 0.0956, 0.0166],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:44,325][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ drink] are: tensor([0.0345, 0.0214, 0.0127, 0.0107, 0.0357, 0.0154, 0.0129, 0.0219, 0.0501,
        0.0547, 0.0744, 0.0492, 0.2376, 0.0610, 0.0736, 0.0916, 0.0354, 0.1072],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:44,326][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ drink] are: tensor([0.0014, 0.0050, 0.0024, 0.0028, 0.0011, 0.0033, 0.0050, 0.0108, 0.0976,
        0.0279, 0.0312, 0.0212, 0.2427, 0.1696, 0.2270, 0.1162, 0.0292, 0.0054],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:44,328][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ drink] are: tensor([0.0061, 0.0312, 0.0493, 0.0628, 0.0942, 0.0234, 0.0447, 0.0644, 0.0390,
        0.0952, 0.0268, 0.0466, 0.0585, 0.0515, 0.0990, 0.0960, 0.0474, 0.0639],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:44,329][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ drink] are: tensor([0.0028, 0.0053, 0.0117, 0.0033, 0.0171, 0.0066, 0.0047, 0.0297, 0.0257,
        0.1106, 0.0418, 0.0295, 0.3718, 0.0100, 0.0918, 0.0425, 0.0149, 0.1803],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:44,330][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ drink] are: tensor([8.3067e-05, 9.8666e-04, 2.6106e-02, 7.8317e-02, 2.0731e-02, 1.3439e-02,
        2.0379e-01, 1.0151e-02, 1.2135e-01, 7.5310e-02, 1.0045e-01, 3.5280e-02,
        9.8663e-03, 3.3569e-02, 1.5932e-01, 1.0721e-02, 7.8054e-02, 2.2474e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:44,332][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ drink] are: tensor([0.0039, 0.0205, 0.0252, 0.0367, 0.0342, 0.0272, 0.0695, 0.0469, 0.0786,
        0.0561, 0.0622, 0.0576, 0.0754, 0.0799, 0.0954, 0.0507, 0.0740, 0.1061],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:44,333][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ drink] are: tensor([0.0531, 0.0289, 0.0337, 0.0323, 0.0397, 0.0935, 0.0501, 0.0950, 0.0781,
        0.0804, 0.0411, 0.0659, 0.0364, 0.0569, 0.0389, 0.0609, 0.0444, 0.0708],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:44,335][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ drink] are: tensor([0.0034, 0.0071, 0.0771, 0.0321, 0.0638, 0.1211, 0.0448, 0.0922, 0.0400,
        0.0491, 0.0138, 0.0195, 0.0715, 0.0283, 0.2425, 0.0481, 0.0242, 0.0215],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:44,336][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ drink] are: tensor([3.6028e-04, 2.2745e-05, 1.8082e-06, 3.0728e-05, 4.9425e-06, 9.3771e-05,
        8.5093e-04, 4.3997e-04, 7.6786e-03, 1.4595e-03, 4.4121e-03, 9.8247e-03,
        4.6049e-02, 1.6866e-01, 1.8936e-01, 6.2508e-02, 4.4703e-01, 6.1221e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:44,337][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ drink] are: tensor([0.0004, 0.0102, 0.0155, 0.0680, 0.0203, 0.0478, 0.2704, 0.0741, 0.0764,
        0.0506, 0.0495, 0.0579, 0.0110, 0.0288, 0.0373, 0.0561, 0.1029, 0.0227],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:44,339][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0747, 0.0165, 0.0434, 0.0228, 0.0407, 0.0970, 0.0412, 0.0744, 0.0330,
        0.0509, 0.0333, 0.0830, 0.0249, 0.0201, 0.0575, 0.1186, 0.0513, 0.0628,
        0.0537], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:44,341][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0007, 0.0789, 0.0280, 0.0561, 0.0224, 0.0581, 0.1391, 0.0823, 0.0584,
        0.0240, 0.0461, 0.0893, 0.0111, 0.0695, 0.0259, 0.0427, 0.0978, 0.0207,
        0.0490], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:44,342][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0921, 0.0277, 0.0100, 0.0056, 0.0376, 0.0163, 0.0068, 0.0172, 0.0393,
        0.0425, 0.0558, 0.0487, 0.2017, 0.0588, 0.0751, 0.1218, 0.0201, 0.0806,
        0.0423], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:44,344][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0066, 0.0238, 0.0039, 0.0027, 0.0015, 0.0034, 0.0022, 0.0158, 0.0504,
        0.0342, 0.0237, 0.0110, 0.1680, 0.2821, 0.1634, 0.1469, 0.0139, 0.0098,
        0.0363], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:44,345][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0423, 0.0478, 0.0543, 0.0586, 0.0701, 0.0314, 0.0297, 0.0502, 0.0201,
        0.0759, 0.0171, 0.0432, 0.0873, 0.0385, 0.0762, 0.1563, 0.0350, 0.0444,
        0.0215], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:44,347][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0100, 0.0103, 0.0095, 0.0048, 0.0111, 0.0067, 0.0059, 0.0381, 0.0367,
        0.1158, 0.0708, 0.0407, 0.3062, 0.0174, 0.0535, 0.0439, 0.0220, 0.1018,
        0.0949], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:44,348][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ to] are: tensor([8.0182e-05, 7.2826e-04, 2.0830e-02, 7.5932e-02, 1.8310e-02, 1.5405e-02,
        1.6452e-01, 7.9675e-03, 1.0195e-01, 6.4927e-02, 1.0944e-01, 4.0020e-02,
        9.5390e-03, 4.0323e-02, 1.3626e-01, 1.5356e-02, 8.6113e-02, 3.0800e-02,
        6.1500e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:44,349][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0040, 0.0216, 0.0235, 0.0337, 0.0320, 0.0274, 0.0624, 0.0403, 0.0696,
        0.0516, 0.0546, 0.0511, 0.0698, 0.0744, 0.0797, 0.0447, 0.0669, 0.1047,
        0.0880], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:44,351][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0304, 0.0324, 0.0324, 0.0430, 0.0498, 0.0880, 0.0531, 0.0873, 0.0872,
        0.0692, 0.0426, 0.0552, 0.0390, 0.0551, 0.0400, 0.0523, 0.0486, 0.0556,
        0.0390], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:44,352][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0096, 0.0051, 0.1021, 0.0198, 0.0599, 0.0892, 0.0262, 0.0602, 0.0333,
        0.0412, 0.0099, 0.0176, 0.0567, 0.0154, 0.3504, 0.0378, 0.0153, 0.0350,
        0.0153], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:44,353][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ to] are: tensor([8.0571e-03, 9.3951e-05, 1.2218e-06, 8.4152e-06, 4.1099e-06, 5.7912e-05,
        1.3503e-04, 5.0192e-04, 1.1325e-03, 1.2771e-03, 1.8239e-03, 5.1910e-03,
        1.0638e-01, 1.8743e-01, 1.1039e-01, 8.0379e-02, 1.0242e-01, 6.0818e-02,
        3.3390e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:44,353][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0006, 0.0103, 0.0164, 0.0679, 0.0127, 0.0292, 0.2294, 0.0520, 0.0722,
        0.0299, 0.0353, 0.0602, 0.0167, 0.0233, 0.0245, 0.0565, 0.1008, 0.0168,
        0.1453], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:44,400][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:21:44,401][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:44,402][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:44,403][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:44,405][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:44,406][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:44,407][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:44,408][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:44,409][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:44,410][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:44,411][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:44,412][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:44,412][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:44,412][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.7021, 0.2979], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:44,413][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0111, 0.9889], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:44,413][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.4650, 0.5350], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:44,413][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.8913, 0.1087], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:44,414][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0174, 0.9826], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:44,414][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.2249, 0.7751], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:44,415][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0164, 0.9836], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:44,416][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.2674, 0.7326], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:44,417][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.3056, 0.6944], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:44,419][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0088, 0.9912], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:44,420][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.2686, 0.7314], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:44,422][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0969, 0.9031], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:44,423][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Anthony] are: tensor([0.2417, 0.2363, 0.5220], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:44,424][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Anthony] are: tensor([8.8109e-04, 3.6981e-02, 9.6214e-01], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:44,425][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Anthony] are: tensor([0.2495, 0.2605, 0.4899], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:44,426][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Anthony] are: tensor([0.5922, 0.3208, 0.0869], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:44,428][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Anthony] are: tensor([0.0018, 0.0903, 0.9079], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:44,429][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Anthony] are: tensor([0.0935, 0.6884, 0.2182], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:44,431][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Anthony] are: tensor([0.0031, 0.0274, 0.9695], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:44,432][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Anthony] are: tensor([0.0930, 0.4855, 0.4214], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:44,433][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Anthony] are: tensor([0.1638, 0.7085, 0.1277], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:44,434][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Anthony] are: tensor([2.1656e-04, 2.9652e-03, 9.9682e-01], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:44,436][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Anthony] are: tensor([0.2153, 0.4214, 0.3633], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:44,437][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Anthony] are: tensor([0.0527, 0.5717, 0.3756], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:44,438][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.6222, 0.1894, 0.1321, 0.0563], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:44,440][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0014, 0.0457, 0.9008, 0.0522], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:44,441][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.2123, 0.4398, 0.2517, 0.0962], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:44,443][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.8877, 0.0438, 0.0028, 0.0658], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:44,444][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0235, 0.1397, 0.6897, 0.1470], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:44,445][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.4952, 0.4375, 0.0633, 0.0040], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:44,447][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0016, 0.0224, 0.7148, 0.2612], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:44,448][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0676, 0.2269, 0.3047, 0.4008], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:44,449][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.3319, 0.4495, 0.1135, 0.1051], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:44,450][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([5.2628e-04, 6.8844e-03, 8.6786e-01, 1.2473e-01], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:44,452][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0650, 0.0182, 0.0076, 0.9093], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:44,453][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0058, 0.1537, 0.1439, 0.6966], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:44,455][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Travis] are: tensor([0.4078, 0.1453, 0.1033, 0.0381, 0.3056], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:44,456][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Travis] are: tensor([0.0024, 0.1216, 0.5033, 0.0585, 0.3143], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:44,457][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Travis] are: tensor([0.1101, 0.2489, 0.1615, 0.0702, 0.4093], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:44,459][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Travis] are: tensor([0.3299, 0.0869, 0.0140, 0.5331, 0.0361], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:44,460][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Travis] are: tensor([0.0058, 0.1527, 0.4266, 0.1809, 0.2340], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:44,461][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Travis] are: tensor([0.1872, 0.5072, 0.1010, 0.0084, 0.1962], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:44,463][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Travis] are: tensor([0.0029, 0.0230, 0.4717, 0.2895, 0.2129], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:44,464][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Travis] are: tensor([0.0991, 0.1995, 0.1682, 0.3128, 0.2205], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:44,466][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Travis] are: tensor([0.1894, 0.4603, 0.0559, 0.1802, 0.1142], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:44,467][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Travis] are: tensor([0.0007, 0.0106, 0.4532, 0.3128, 0.2227], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:44,469][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Travis] are: tensor([0.0091, 0.0102, 0.0091, 0.8330, 0.1386], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:44,470][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Travis] are: tensor([0.0242, 0.1362, 0.1086, 0.6093, 0.1217], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:44,470][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.1947, 0.1402, 0.1741, 0.0564, 0.2606, 0.1739], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:44,470][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([3.2457e-04, 2.6231e-02, 5.1032e-01, 5.7630e-02, 3.8651e-01, 1.8987e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:44,471][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.0621, 0.1583, 0.2227, 0.0855, 0.3220, 0.1494], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:44,471][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.7336, 0.0522, 0.0027, 0.0391, 0.0148, 0.1577], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:44,472][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.0025, 0.0552, 0.5331, 0.1541, 0.2192, 0.0358], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:44,472][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.3073, 0.3928, 0.0467, 0.0059, 0.1173, 0.1300], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:44,472][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([1.4422e-04, 8.1982e-03, 3.8551e-01, 2.0318e-01, 1.8880e-01, 2.1416e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:44,473][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.0420, 0.1046, 0.1603, 0.1837, 0.3610, 0.1484], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:44,473][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.1436, 0.3589, 0.1112, 0.1469, 0.1014, 0.1379], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:44,474][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([4.0614e-05, 2.9007e-03, 4.3158e-01, 2.1594e-01, 1.1336e-01, 2.3618e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:44,476][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.0409, 0.0124, 0.0028, 0.2427, 0.0599, 0.6412], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:44,477][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.0027, 0.1069, 0.0979, 0.4455, 0.1473, 0.1997], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:44,478][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.5231, 0.1148, 0.0714, 0.0244, 0.1752, 0.0513, 0.0398],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:44,480][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0030, 0.0617, 0.5138, 0.0441, 0.2811, 0.0269, 0.0693],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:44,481][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.1616, 0.2542, 0.1489, 0.0498, 0.3168, 0.0497, 0.0190],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:44,482][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([9.4817e-01, 7.7193e-03, 1.2900e-04, 2.6667e-03, 1.3765e-03, 2.6835e-02,
        1.3108e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:44,483][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0312, 0.1347, 0.5577, 0.0993, 0.1194, 0.0293, 0.0284],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:44,485][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.5369, 0.3421, 0.0288, 0.0018, 0.0467, 0.0365, 0.0073],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:44,486][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0006, 0.0104, 0.2361, 0.1780, 0.1791, 0.1285, 0.2674],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:44,488][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0728, 0.1201, 0.0667, 0.0837, 0.2200, 0.0987, 0.3380],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:44,489][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.1391, 0.3929, 0.0685, 0.1149, 0.1133, 0.1492, 0.0220],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:44,490][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([8.4102e-05, 1.3827e-03, 4.5363e-01, 1.0602e-01, 1.0119e-01, 1.8139e-01,
        1.5630e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:44,491][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([1.2487e-01, 6.3707e-03, 4.0494e-04, 8.1868e-02, 1.0431e-02, 2.1296e-01,
        5.6310e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:44,492][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0050, 0.0854, 0.0640, 0.2718, 0.1327, 0.1157, 0.3255],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:44,494][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ lot] are: tensor([0.1456, 0.0365, 0.0442, 0.0347, 0.0726, 0.1114, 0.1085, 0.4465],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:44,495][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ lot] are: tensor([0.0019, 0.0590, 0.5012, 0.0399, 0.2176, 0.0319, 0.1473, 0.0012],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:44,497][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ lot] are: tensor([0.0505, 0.1026, 0.1227, 0.0504, 0.1941, 0.0513, 0.0744, 0.3540],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:44,498][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ lot] are: tensor([6.6392e-01, 1.5426e-02, 5.0881e-04, 8.9388e-03, 1.4583e-03, 5.5998e-02,
        1.6623e-01, 8.7522e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:44,499][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ lot] are: tensor([0.0030, 0.1288, 0.3570, 0.1988, 0.1561, 0.0358, 0.0750, 0.0454],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:44,501][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ lot] are: tensor([0.1622, 0.2684, 0.0990, 0.0101, 0.0865, 0.1378, 0.0446, 0.1913],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:44,502][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ lot] are: tensor([4.8974e-05, 3.4490e-03, 1.5372e-01, 1.5913e-01, 1.0701e-01, 9.8871e-02,
        4.5551e-01, 2.2253e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:44,503][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ lot] are: tensor([0.0091, 0.0256, 0.0370, 0.0574, 0.0792, 0.0645, 0.3294, 0.3979],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:44,504][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ lot] are: tensor([0.0435, 0.1143, 0.0863, 0.1118, 0.0872, 0.2234, 0.0426, 0.2908],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:44,505][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ lot] are: tensor([7.4760e-05, 3.4295e-03, 2.4402e-01, 1.5881e-01, 1.2537e-01, 1.8090e-01,
        2.7594e-01, 1.1462e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:44,506][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ lot] are: tensor([1.0756e-02, 2.3758e-03, 5.2083e-04, 3.1223e-02, 3.2346e-03, 6.4279e-02,
        8.2208e-01, 6.5526e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:44,508][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ lot] are: tensor([0.0004, 0.0175, 0.0442, 0.2882, 0.0860, 0.0759, 0.3181, 0.1698],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:44,509][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([0.3114, 0.1033, 0.1162, 0.0163, 0.1515, 0.0383, 0.0210, 0.1551, 0.0867],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:44,510][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([2.2797e-04, 1.3291e-02, 6.7599e-01, 1.2915e-02, 2.1947e-01, 8.5905e-03,
        4.6314e-02, 1.3511e-03, 2.1845e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:44,511][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([0.1250, 0.2084, 0.2096, 0.0196, 0.2895, 0.0266, 0.0086, 0.0810, 0.0318],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:44,512][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([8.5838e-01, 6.5512e-03, 8.0453e-05, 3.0062e-04, 1.8169e-04, 4.0518e-03,
        7.8175e-03, 4.4305e-02, 7.8334e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:44,514][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([0.0103, 0.1260, 0.4668, 0.1119, 0.2058, 0.0175, 0.0354, 0.0193, 0.0069],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:44,515][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([0.3780, 0.2952, 0.0435, 0.0037, 0.0555, 0.0356, 0.0092, 0.0795, 0.0998],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:44,516][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([1.2461e-04, 5.5575e-03, 3.1903e-01, 1.1083e-01, 1.7477e-01, 8.3329e-02,
        2.0716e-01, 2.9304e-02, 6.9895e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:44,518][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([0.0168, 0.0301, 0.0099, 0.0116, 0.0297, 0.0168, 0.1135, 0.1222, 0.6492],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:44,519][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([0.0848, 0.2724, 0.0572, 0.0630, 0.0608, 0.1473, 0.0149, 0.2272, 0.0726],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:44,520][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([4.1813e-05, 1.2168e-03, 5.6379e-01, 5.9412e-02, 8.1114e-02, 8.1515e-02,
        1.3135e-01, 1.7364e-02, 6.4193e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:44,521][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([2.6670e-02, 6.7186e-04, 3.7262e-05, 1.4175e-03, 4.1262e-04, 9.5286e-03,
        2.8783e-02, 3.3200e-02, 8.9928e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:44,522][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([0.0016, 0.0544, 0.0426, 0.1912, 0.0669, 0.0636, 0.2928, 0.1223, 0.1646],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:44,524][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ fun] are: tensor([0.1338, 0.0261, 0.0361, 0.0198, 0.0355, 0.0268, 0.0382, 0.2425, 0.1241,
        0.3171], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:44,525][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ fun] are: tensor([0.0016, 0.0350, 0.4044, 0.0322, 0.1875, 0.0350, 0.1903, 0.0043, 0.0500,
        0.0596], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:44,527][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ fun] are: tensor([0.1650, 0.0914, 0.1098, 0.0277, 0.2430, 0.0396, 0.0252, 0.1433, 0.0623,
        0.0928], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:44,528][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ fun] are: tensor([2.0660e-01, 7.8313e-03, 2.1837e-04, 1.8521e-03, 3.7742e-04, 2.1560e-02,
        4.5189e-02, 1.5728e-01, 4.4882e-01, 1.1027e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:44,528][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ fun] are: tensor([0.0015, 0.0459, 0.4512, 0.1823, 0.1467, 0.0260, 0.0623, 0.0330, 0.0110,
        0.0401], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:44,529][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ fun] are: tensor([0.0905, 0.1161, 0.0336, 0.0049, 0.0413, 0.0323, 0.0150, 0.0750, 0.0879,
        0.5035], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:44,529][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ fun] are: tensor([8.6029e-05, 2.2110e-03, 1.5720e-01, 1.1134e-01, 1.0063e-01, 7.9544e-02,
        4.0298e-01, 3.0094e-02, 5.5384e-02, 6.0531e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:44,529][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ fun] are: tensor([0.0030, 0.0131, 0.0096, 0.0180, 0.0181, 0.0171, 0.0945, 0.1635, 0.4363,
        0.2270], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:44,530][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ fun] are: tensor([0.0475, 0.0736, 0.0152, 0.0393, 0.0243, 0.0465, 0.0180, 0.1576, 0.0620,
        0.5161], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:44,530][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ fun] are: tensor([1.0217e-04, 1.1296e-03, 2.7670e-01, 1.1997e-01, 8.0760e-02, 2.1150e-01,
        1.5939e-01, 4.4373e-02, 7.7581e-02, 2.8508e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:44,531][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ fun] are: tensor([1.7116e-03, 2.3162e-04, 3.0956e-05, 1.3874e-03, 1.7062e-04, 5.8281e-03,
        4.9976e-02, 2.2020e-02, 8.3454e-01, 8.4105e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:44,532][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ fun] are: tensor([0.0021, 0.0342, 0.0320, 0.1083, 0.0527, 0.0522, 0.2924, 0.1429, 0.1483,
        0.1346], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:44,534][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.1629, 0.0266, 0.0338, 0.0087, 0.0492, 0.0190, 0.0131, 0.1450, 0.0665,
        0.3985, 0.0766], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:44,535][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.0006, 0.0385, 0.5138, 0.0280, 0.1486, 0.0217, 0.0807, 0.0035, 0.0525,
        0.0349, 0.0772], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:44,537][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.2241, 0.1746, 0.1065, 0.0253, 0.1630, 0.0269, 0.0095, 0.1092, 0.0331,
        0.0867, 0.0410], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:44,537][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([6.9656e-01, 8.0789e-03, 8.9170e-05, 2.1378e-04, 1.5948e-04, 3.9676e-03,
        3.2869e-03, 7.0919e-02, 5.6518e-02, 7.3686e-02, 8.6523e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:44,539][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.0052, 0.0829, 0.3123, 0.2143, 0.1452, 0.0414, 0.0781, 0.0276, 0.0134,
        0.0708, 0.0089], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:44,540][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.1678, 0.1255, 0.0345, 0.0032, 0.0297, 0.0241, 0.0071, 0.0485, 0.0533,
        0.3765, 0.1299], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:44,541][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([1.1053e-04, 3.2210e-03, 2.0779e-01, 1.0072e-01, 1.0638e-01, 1.2679e-01,
        2.4512e-01, 2.3260e-02, 4.7453e-02, 9.1288e-02, 4.7868e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:44,542][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.0074, 0.0194, 0.0118, 0.0163, 0.0235, 0.0181, 0.0900, 0.1481, 0.3396,
        0.1686, 0.1572], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:44,544][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.0350, 0.1025, 0.0175, 0.0244, 0.0264, 0.0420, 0.0099, 0.1349, 0.0282,
        0.5359, 0.0432], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:44,545][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([7.5367e-05, 1.8201e-03, 4.5630e-01, 9.7305e-02, 9.8443e-02, 1.3888e-01,
        8.6359e-02, 2.1735e-02, 6.8589e-02, 2.6571e-02, 3.9143e-03],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:44,546][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([9.9789e-03, 9.3380e-04, 5.4519e-05, 1.4001e-03, 3.3577e-04, 7.2673e-03,
        2.5550e-02, 3.9705e-02, 4.7437e-01, 1.8350e-01, 2.5691e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:44,547][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.0017, 0.0302, 0.0230, 0.1180, 0.0417, 0.0537, 0.2924, 0.1126, 0.2242,
        0.0549, 0.0475], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:44,549][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.1702, 0.0523, 0.0441, 0.0124, 0.0510, 0.0207, 0.0124, 0.0883, 0.0607,
        0.3699, 0.0930, 0.0249], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:44,550][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([2.9188e-04, 2.2325e-02, 6.6667e-01, 1.6195e-02, 1.3963e-01, 1.1213e-02,
        3.8394e-02, 8.8367e-04, 1.4980e-02, 3.1593e-02, 3.3171e-02, 2.4659e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:44,551][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.1052, 0.1974, 0.1916, 0.0336, 0.2285, 0.0263, 0.0076, 0.0477, 0.0264,
        0.0765, 0.0302, 0.0291], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:44,552][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([7.2922e-01, 7.4104e-03, 6.0818e-05, 3.4530e-04, 1.4398e-04, 3.3685e-03,
        4.7034e-03, 2.6962e-02, 5.7287e-02, 2.5431e-02, 9.7512e-02, 4.7558e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:44,553][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0045, 0.0921, 0.3327, 0.1777, 0.1575, 0.0349, 0.0582, 0.0768, 0.0093,
        0.0345, 0.0085, 0.0134], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:44,555][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.1483, 0.1284, 0.0185, 0.0023, 0.0232, 0.0191, 0.0051, 0.0297, 0.0438,
        0.3623, 0.1041, 0.1152], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:44,556][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([4.6832e-05, 3.1781e-03, 2.6131e-01, 1.1008e-01, 1.1174e-01, 9.4729e-02,
        1.6769e-01, 1.7788e-02, 3.4443e-02, 1.1776e-01, 4.6332e-02, 3.4903e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:44,557][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0074, 0.0208, 0.0099, 0.0152, 0.0150, 0.0174, 0.0617, 0.0809, 0.3033,
        0.2206, 0.1588, 0.0890], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:44,558][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0312, 0.1207, 0.0228, 0.0291, 0.0242, 0.0447, 0.0087, 0.1335, 0.0286,
        0.4843, 0.0467, 0.0255], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:44,559][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([4.5673e-05, 6.6577e-04, 5.5286e-01, 6.4424e-02, 7.0054e-02, 1.1792e-01,
        9.6661e-02, 1.9471e-02, 3.9773e-02, 2.1696e-02, 3.5935e-03, 1.2838e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:44,560][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([7.4740e-03, 6.3333e-04, 3.7804e-05, 1.5108e-03, 2.2300e-04, 6.0640e-03,
        1.7024e-02, 2.8262e-02, 4.0345e-01, 6.5067e-02, 2.1129e-01, 2.5897e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:44,562][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0010, 0.0274, 0.0269, 0.1082, 0.0290, 0.0420, 0.2243, 0.0797, 0.1831,
        0.1007, 0.0580, 0.1199], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:44,563][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ hospital] are: tensor([0.2676, 0.0436, 0.0319, 0.0074, 0.0192, 0.0123, 0.0056, 0.0306, 0.0212,
        0.0589, 0.0340, 0.0117, 0.4560], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:44,565][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ hospital] are: tensor([0.0009, 0.0313, 0.4144, 0.0405, 0.1437, 0.0259, 0.0817, 0.0022, 0.0266,
        0.0379, 0.0856, 0.0445, 0.0648], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:44,566][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ hospital] are: tensor([0.1604, 0.1219, 0.0754, 0.0271, 0.1228, 0.0393, 0.0120, 0.0642, 0.0415,
        0.0408, 0.0382, 0.0279, 0.2285], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:44,567][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ hospital] are: tensor([5.8342e-01, 9.1951e-03, 1.0732e-04, 4.1768e-04, 8.4950e-05, 2.8451e-03,
        4.4385e-03, 1.8714e-02, 3.3749e-02, 1.1962e-02, 4.3371e-02, 4.5447e-02,
        2.4625e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:44,569][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ hospital] are: tensor([0.0036, 0.1227, 0.2256, 0.1973, 0.2203, 0.0285, 0.0539, 0.0523, 0.0129,
        0.0230, 0.0101, 0.0200, 0.0297], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:44,570][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ hospital] are: tensor([0.0815, 0.0561, 0.0109, 0.0020, 0.0100, 0.0165, 0.0038, 0.0105, 0.0195,
        0.2302, 0.0559, 0.0557, 0.4475], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:44,571][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ hospital] are: tensor([1.3147e-04, 4.1856e-03, 2.2678e-01, 1.0943e-01, 1.0682e-01, 5.4979e-02,
        2.3075e-01, 2.0253e-02, 7.5423e-02, 4.4017e-02, 7.0874e-02, 4.3578e-02,
        1.2772e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:44,573][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ hospital] are: tensor([0.0447, 0.0208, 0.0053, 0.0066, 0.0077, 0.0099, 0.0274, 0.0292, 0.1130,
        0.0819, 0.0975, 0.0673, 0.4887], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:44,574][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ hospital] are: tensor([0.1111, 0.0859, 0.0215, 0.0287, 0.0208, 0.0193, 0.0188, 0.1200, 0.0385,
        0.2167, 0.0898, 0.0437, 0.1852], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:44,575][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ hospital] are: tensor([1.0558e-04, 1.1720e-03, 3.9292e-01, 8.6538e-02, 3.9857e-02, 1.2599e-01,
        1.7351e-01, 3.7543e-02, 6.0049e-02, 4.2468e-02, 7.7573e-03, 2.0678e-02,
        1.1416e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:44,576][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ hospital] are: tensor([5.7222e-03, 7.8887e-04, 3.4735e-05, 7.7412e-04, 9.0243e-05, 2.1619e-03,
        1.6520e-02, 8.1709e-03, 1.1961e-01, 2.5114e-02, 5.7542e-02, 1.8320e-01,
        5.8028e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:44,578][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ hospital] are: tensor([0.0030, 0.0173, 0.0177, 0.0877, 0.0203, 0.0375, 0.2996, 0.0869, 0.1693,
        0.0544, 0.0859, 0.0985, 0.0220], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:44,579][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.2858, 0.0432, 0.0307, 0.0033, 0.0448, 0.0078, 0.0025, 0.0246, 0.0113,
        0.1506, 0.0194, 0.0080, 0.3305, 0.0375], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:44,580][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([2.7518e-04, 1.5012e-02, 5.9300e-01, 1.1150e-02, 1.9062e-01, 1.4919e-02,
        4.4954e-02, 5.7150e-04, 1.0390e-02, 2.9242e-02, 3.3876e-02, 1.4478e-02,
        3.4280e-02, 7.2323e-03], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:44,582][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.0658, 0.1357, 0.1351, 0.0107, 0.1603, 0.0180, 0.0042, 0.0293, 0.0166,
        0.0442, 0.0135, 0.0191, 0.3165, 0.0310], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:44,583][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([8.6878e-01, 1.7257e-03, 8.5877e-06, 1.1581e-05, 6.4441e-06, 9.3894e-05,
        7.7417e-05, 1.2613e-03, 3.2055e-04, 6.1217e-04, 1.1726e-03, 7.6173e-04,
        1.5635e-02, 1.0953e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:44,584][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.0057, 0.1127, 0.2505, 0.1841, 0.2140, 0.0307, 0.0539, 0.0209, 0.0082,
        0.0311, 0.0088, 0.0241, 0.0289, 0.0265], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:44,585][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.1977, 0.1038, 0.0158, 0.0015, 0.0182, 0.0137, 0.0030, 0.0262, 0.0248,
        0.1661, 0.0548, 0.0495, 0.3051, 0.0199], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:44,586][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([1.0756e-04, 4.4387e-03, 2.6345e-01, 7.0444e-02, 2.0476e-01, 5.3990e-02,
        1.1539e-01, 1.2486e-02, 3.2377e-02, 1.1054e-01, 5.0461e-02, 3.7416e-02,
        1.9801e-02, 2.4342e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:44,586][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0069, 0.0103, 0.0054, 0.0061, 0.0106, 0.0058, 0.0425, 0.0252, 0.1586,
        0.0683, 0.0961, 0.0749, 0.2342, 0.2551], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:44,587][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.0876, 0.1040, 0.0288, 0.0267, 0.0233, 0.0312, 0.0077, 0.1060, 0.0171,
        0.2304, 0.0372, 0.0182, 0.1795, 0.1024], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:44,587][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([4.7747e-05, 7.1252e-04, 6.0841e-01, 4.8075e-02, 7.4605e-02, 8.7994e-02,
        9.0766e-02, 1.5489e-02, 3.2669e-02, 2.2141e-02, 3.0339e-03, 6.0885e-03,
        6.2051e-03, 3.7666e-03], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:44,588][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([1.7491e-02, 6.0188e-04, 2.2447e-05, 4.4218e-04, 5.9848e-05, 1.0785e-03,
        4.1022e-03, 3.3510e-03, 1.8842e-02, 1.0772e-02, 1.3100e-02, 4.0628e-02,
        2.2266e-01, 6.6685e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:44,588][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.0014, 0.0147, 0.0217, 0.0768, 0.0366, 0.0280, 0.3274, 0.0819, 0.1010,
        0.1001, 0.0713, 0.0844, 0.0279, 0.0267], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:44,588][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Anthony] are: tensor([0.1388, 0.0245, 0.0378, 0.0044, 0.0230, 0.0122, 0.0050, 0.0353, 0.0194,
        0.1157, 0.0359, 0.0164, 0.3127, 0.0500, 0.1689], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:44,590][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Anthony] are: tensor([0.0007, 0.0122, 0.2894, 0.0071, 0.0939, 0.0144, 0.0389, 0.0018, 0.0091,
        0.0576, 0.0344, 0.0200, 0.0487, 0.0086, 0.3631], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:44,591][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Anthony] are: tensor([0.0860, 0.0743, 0.0833, 0.0097, 0.0484, 0.0163, 0.0056, 0.0309, 0.0192,
        0.0355, 0.0263, 0.0232, 0.3466, 0.0499, 0.1447], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:44,592][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Anthony] are: tensor([8.5420e-02, 3.7132e-04, 2.0934e-06, 3.0317e-06, 2.2373e-06, 7.5233e-05,
        9.2284e-05, 6.4281e-04, 1.3693e-03, 1.2307e-03, 2.2767e-03, 2.3096e-03,
        1.1484e-01, 6.5590e-01, 1.3547e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:44,594][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Anthony] are: tensor([0.0024, 0.1160, 0.2584, 0.1758, 0.2016, 0.0134, 0.0405, 0.0565, 0.0072,
        0.0145, 0.0035, 0.0140, 0.0161, 0.0187, 0.0613], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:44,595][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Anthony] are: tensor([0.0977, 0.1160, 0.0227, 0.0015, 0.0206, 0.0141, 0.0034, 0.0126, 0.0214,
        0.2138, 0.0590, 0.0523, 0.2872, 0.0138, 0.0638], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:44,596][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Anthony] are: tensor([2.0084e-04, 2.2637e-03, 1.0535e-01, 4.4139e-02, 4.4263e-02, 4.6109e-02,
        8.0279e-02, 2.0933e-02, 2.6145e-02, 8.1338e-02, 3.2816e-02, 3.5029e-02,
        1.6935e-02, 1.9951e-02, 4.4425e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:44,597][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Anthony] are: tensor([0.0116, 0.0093, 0.0019, 0.0017, 0.0034, 0.0022, 0.0084, 0.0104, 0.0409,
        0.0258, 0.0327, 0.0258, 0.2498, 0.1541, 0.4218], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:44,599][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Anthony] are: tensor([0.1032, 0.0997, 0.0198, 0.0195, 0.0156, 0.0170, 0.0061, 0.0609, 0.0149,
        0.1857, 0.0239, 0.0177, 0.2224, 0.1315, 0.0621], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:44,600][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Anthony] are: tensor([6.3853e-05, 4.8736e-04, 2.0392e-01, 2.7060e-02, 1.4496e-02, 8.1015e-02,
        4.0048e-02, 1.7617e-02, 2.2997e-02, 1.3127e-02, 2.6375e-03, 1.2107e-02,
        5.7118e-03, 5.1221e-03, 5.5359e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:44,601][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Anthony] are: tensor([1.7715e-03, 3.3721e-05, 1.0375e-06, 9.9182e-06, 4.1702e-06, 1.1217e-04,
        6.8911e-04, 8.6886e-04, 1.0461e-02, 3.4943e-03, 8.1515e-03, 2.3250e-02,
        2.2790e-01, 4.2687e-01, 2.9638e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:44,602][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Anthony] are: tensor([0.0025, 0.0370, 0.0284, 0.0724, 0.0233, 0.0581, 0.2216, 0.0948, 0.1123,
        0.1310, 0.0396, 0.0678, 0.0331, 0.0414, 0.0365], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:44,604][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.0268, 0.0117, 0.0258, 0.0067, 0.0359, 0.0096, 0.0124, 0.0447, 0.0208,
        0.1695, 0.0256, 0.0188, 0.2320, 0.0584, 0.1897, 0.1118],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:44,605][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([1.6827e-04, 1.4047e-02, 2.4577e-01, 2.4760e-02, 5.8338e-02, 8.1008e-03,
        1.0795e-01, 8.6015e-04, 4.2316e-02, 2.1054e-02, 5.7819e-02, 3.1186e-02,
        3.6794e-02, 1.9421e-02, 3.0161e-01, 2.9804e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:44,607][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.0313, 0.0420, 0.0481, 0.0138, 0.0776, 0.0202, 0.0078, 0.0273, 0.0220,
        0.0436, 0.0216, 0.0276, 0.3045, 0.0505, 0.1111, 0.1508],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:44,608][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([7.6243e-02, 9.0052e-04, 8.6362e-06, 2.1785e-05, 1.1073e-05, 2.2399e-04,
        4.4528e-04, 2.1590e-03, 3.5957e-03, 2.0353e-03, 6.1971e-03, 5.6103e-03,
        8.9342e-02, 4.6339e-01, 2.0625e-01, 1.4357e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:44,609][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.0005, 0.0384, 0.2750, 0.1242, 0.0752, 0.0218, 0.0593, 0.0145, 0.0177,
        0.0315, 0.0095, 0.0266, 0.0249, 0.0471, 0.2020, 0.0320],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:44,611][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.0261, 0.0443, 0.0103, 0.0033, 0.0213, 0.0182, 0.0088, 0.0185, 0.0355,
        0.1494, 0.0783, 0.0750, 0.3428, 0.0467, 0.0603, 0.0611],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:44,612][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([8.6619e-06, 9.9038e-04, 1.4025e-01, 5.5042e-02, 8.9840e-02, 2.3937e-02,
        1.4447e-01, 5.0919e-03, 2.1302e-02, 3.3668e-02, 2.7318e-02, 2.2384e-02,
        4.2760e-03, 9.1222e-03, 4.1722e-01, 5.0789e-03], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:44,613][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0020, 0.0016, 0.0020, 0.0019, 0.0024, 0.0023, 0.0134, 0.0141, 0.0650,
        0.0323, 0.0503, 0.0379, 0.2353, 0.0955, 0.3936, 0.0503],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:44,615][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.0158, 0.0358, 0.0335, 0.0290, 0.0293, 0.0253, 0.0185, 0.0926, 0.0295,
        0.1890, 0.0463, 0.0368, 0.1051, 0.0756, 0.0753, 0.1624],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:44,616][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([1.6949e-05, 1.0654e-03, 2.2608e-01, 8.2624e-02, 4.1351e-02, 9.3585e-02,
        1.2326e-01, 6.8697e-03, 3.9608e-02, 1.5154e-02, 5.4926e-03, 1.1387e-02,
        4.5602e-03, 6.1063e-03, 3.4215e-01, 6.8706e-04], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:44,617][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([4.0140e-04, 5.9660e-05, 3.7583e-06, 1.0783e-04, 2.1580e-05, 3.4757e-04,
        2.5512e-03, 1.7684e-03, 1.9450e-02, 4.6496e-03, 1.0549e-02, 2.0851e-02,
        1.2643e-01, 2.9660e-01, 3.2279e-01, 1.9341e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:44,618][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([1.7985e-04, 7.3956e-03, 1.6419e-02, 7.3411e-02, 1.9225e-02, 3.6212e-02,
        4.0026e-01, 7.1109e-02, 9.7659e-02, 3.5812e-02, 4.3606e-02, 6.1606e-02,
        1.3402e-02, 3.1817e-02, 4.0029e-02, 5.1852e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:44,619][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.1534, 0.0121, 0.0132, 0.0018, 0.0155, 0.0040, 0.0016, 0.0263, 0.0065,
        0.1313, 0.0147, 0.0038, 0.3620, 0.0327, 0.0892, 0.1102, 0.0217],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:44,621][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0012, 0.0243, 0.2957, 0.0130, 0.0877, 0.0077, 0.0260, 0.0016, 0.0167,
        0.0278, 0.0345, 0.0241, 0.0419, 0.0102, 0.2691, 0.0717, 0.0469],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:44,622][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.1106, 0.0850, 0.0696, 0.0085, 0.0622, 0.0114, 0.0021, 0.0208, 0.0090,
        0.0280, 0.0144, 0.0148, 0.2867, 0.0284, 0.0773, 0.1643, 0.0070],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:44,623][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([2.0737e-01, 6.8060e-04, 1.6717e-06, 4.8843e-06, 3.3748e-06, 8.8619e-05,
        2.2588e-05, 1.4733e-03, 2.9955e-04, 5.8513e-04, 1.2072e-03, 6.8344e-04,
        3.7399e-02, 4.8419e-01, 5.9703e-02, 1.8985e-01, 1.6434e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:44,624][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0064, 0.0513, 0.2995, 0.1003, 0.0723, 0.0272, 0.0299, 0.0417, 0.0096,
        0.0291, 0.0070, 0.0370, 0.0499, 0.0258, 0.0780, 0.0900, 0.0450],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:44,626][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.1622, 0.0738, 0.0076, 0.0012, 0.0088, 0.0067, 0.0033, 0.0217, 0.0203,
        0.1628, 0.0647, 0.0565, 0.2794, 0.0246, 0.0272, 0.0349, 0.0444],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:44,627][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([9.2625e-05, 1.9514e-03, 8.3325e-02, 5.4137e-02, 4.6565e-02, 4.0506e-02,
        7.4770e-02, 1.9466e-02, 2.5593e-02, 6.1875e-02, 3.9298e-02, 4.1859e-02,
        1.0717e-02, 1.7679e-02, 3.7971e-01, 2.8364e-02, 7.4094e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:44,628][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0060, 0.0049, 0.0018, 0.0015, 0.0023, 0.0018, 0.0063, 0.0117, 0.0303,
        0.0358, 0.0268, 0.0234, 0.1891, 0.1359, 0.3003, 0.0595, 0.1624],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:44,630][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0529, 0.0414, 0.0135, 0.0105, 0.0128, 0.0225, 0.0029, 0.0941, 0.0075,
        0.1622, 0.0156, 0.0122, 0.1183, 0.0660, 0.0313, 0.3211, 0.0152],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:44,631][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([1.9227e-05, 2.1192e-04, 1.7888e-01, 2.9747e-02, 2.0597e-02, 5.2614e-02,
        4.2125e-02, 1.5534e-02, 2.7417e-02, 1.3044e-02, 4.0082e-03, 7.3169e-03,
        5.9583e-03, 4.3048e-03, 5.8684e-01, 9.1180e-04, 1.0466e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:44,632][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([2.4469e-03, 7.9262e-05, 1.3958e-06, 3.5844e-05, 5.0659e-06, 1.4648e-04,
        2.4258e-04, 8.6562e-04, 5.8920e-03, 2.1584e-03, 4.7449e-03, 7.4002e-03,
        1.1324e-01, 3.2047e-01, 1.4669e-01, 1.8382e-01, 2.1176e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:44,633][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0014, 0.0178, 0.0230, 0.0651, 0.0260, 0.0390, 0.1632, 0.0836, 0.1038,
        0.0759, 0.0347, 0.0706, 0.0347, 0.0270, 0.0453, 0.0699, 0.1193],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:44,635][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ drink] are: tensor([0.0397, 0.0071, 0.0170, 0.0037, 0.0148, 0.0043, 0.0050, 0.0375, 0.0118,
        0.0970, 0.0165, 0.0109, 0.1981, 0.0247, 0.0817, 0.0571, 0.0329, 0.3401],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:44,636][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ drink] are: tensor([0.0003, 0.0093, 0.2548, 0.0122, 0.0954, 0.0084, 0.0590, 0.0020, 0.0161,
        0.0174, 0.0469, 0.0224, 0.0323, 0.0095, 0.2261, 0.0308, 0.0732, 0.0839],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:44,638][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ drink] are: tensor([0.0257, 0.0392, 0.0501, 0.0095, 0.0480, 0.0081, 0.0043, 0.0254, 0.0148,
        0.0319, 0.0205, 0.0210, 0.3250, 0.0294, 0.0767, 0.0987, 0.0145, 0.1572],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:44,639][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ drink] are: tensor([2.4510e-02, 3.4361e-04, 3.8784e-06, 9.6490e-06, 3.1934e-06, 1.4459e-04,
        3.0412e-04, 1.3390e-03, 1.9003e-03, 8.3146e-04, 2.1906e-03, 3.6760e-03,
        5.9442e-02, 3.8140e-01, 1.5290e-01, 1.9158e-01, 1.4016e-01, 3.9257e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:44,640][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ drink] are: tensor([0.0011, 0.0509, 0.2483, 0.2087, 0.1452, 0.0169, 0.0611, 0.0256, 0.0112,
        0.0319, 0.0067, 0.0161, 0.0111, 0.0214, 0.0537, 0.0267, 0.0309, 0.0325],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:44,642][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ drink] are: tensor([0.0490, 0.0698, 0.0142, 0.0021, 0.0183, 0.0107, 0.0040, 0.0121, 0.0214,
        0.1773, 0.0554, 0.0540, 0.2501, 0.0226, 0.0477, 0.0286, 0.0325, 0.1303],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:44,643][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ drink] are: tensor([4.6517e-05, 1.5257e-03, 1.2246e-01, 4.3893e-02, 8.5355e-02, 1.7530e-02,
        1.5563e-01, 1.2924e-02, 2.0400e-02, 3.9446e-02, 2.1734e-02, 1.4556e-02,
        5.3174e-03, 6.7256e-03, 3.7625e-01, 7.8802e-03, 6.2737e-02, 5.5915e-03],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:44,644][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ drink] are: tensor([0.0010, 0.0014, 0.0018, 0.0015, 0.0024, 0.0013, 0.0109, 0.0128, 0.0485,
        0.0230, 0.0370, 0.0257, 0.1081, 0.0697, 0.3261, 0.0393, 0.1599, 0.1298],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:44,644][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ drink] are: tensor([0.0476, 0.0573, 0.0190, 0.0182, 0.0168, 0.0154, 0.0062, 0.0512, 0.0103,
        0.1173, 0.0197, 0.0139, 0.1239, 0.0533, 0.0316, 0.1563, 0.0197, 0.2222],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:44,644][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ drink] are: tensor([3.3736e-05, 8.8287e-04, 1.3140e-01, 8.0062e-02, 4.7087e-02, 7.9583e-02,
        1.5345e-01, 2.6187e-02, 4.8691e-02, 1.8403e-02, 6.0502e-03, 1.1949e-02,
        8.4558e-03, 1.1974e-02, 3.4173e-01, 1.4677e-03, 2.8775e-02, 3.8154e-03],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:44,645][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ drink] are: tensor([3.6028e-04, 2.2745e-05, 1.8082e-06, 3.0728e-05, 4.9425e-06, 9.3771e-05,
        8.5093e-04, 4.3997e-04, 7.6786e-03, 1.4595e-03, 4.4121e-03, 9.8247e-03,
        4.6049e-02, 1.6866e-01, 1.8936e-01, 6.2508e-02, 4.4703e-01, 6.1221e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:44,645][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ drink] are: tensor([0.0004, 0.0102, 0.0155, 0.0680, 0.0203, 0.0478, 0.2704, 0.0741, 0.0764,
        0.0506, 0.0495, 0.0579, 0.0110, 0.0288, 0.0373, 0.0561, 0.1029, 0.0227],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:44,646][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.1286, 0.0122, 0.0118, 0.0008, 0.0172, 0.0023, 0.0006, 0.0166, 0.0030,
        0.0805, 0.0061, 0.0024, 0.1356, 0.0155, 0.0538, 0.0603, 0.0085, 0.4193,
        0.0248], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:44,647][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([3.8795e-04, 1.4717e-02, 4.3609e-01, 6.8589e-03, 7.2194e-02, 5.5784e-03,
        1.8447e-02, 6.0829e-04, 7.3338e-03, 1.3962e-02, 1.9200e-02, 6.6397e-03,
        2.3255e-02, 3.5340e-03, 2.2692e-01, 3.2218e-02, 2.2822e-02, 7.8464e-02,
        1.0770e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:44,648][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1087, 0.1035, 0.0682, 0.0040, 0.0692, 0.0084, 0.0012, 0.0138, 0.0055,
        0.0204, 0.0076, 0.0119, 0.2545, 0.0179, 0.0618, 0.1451, 0.0038, 0.0885,
        0.0059], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:44,649][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([5.2126e-01, 7.1962e-04, 1.5553e-06, 8.6736e-07, 1.3750e-06, 3.0358e-05,
        1.2372e-05, 5.7592e-04, 7.9626e-05, 3.8079e-04, 3.7266e-04, 4.1474e-04,
        2.3574e-02, 1.6408e-01, 3.7665e-02, 1.0358e-01, 1.0883e-02, 4.0908e-02,
        9.5454e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:44,650][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0135, 0.1065, 0.2560, 0.1170, 0.0898, 0.0282, 0.0306, 0.0211, 0.0055,
        0.0249, 0.0043, 0.0168, 0.0262, 0.0164, 0.0604, 0.1078, 0.0267, 0.0374,
        0.0111], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:44,652][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.1901, 0.0645, 0.0086, 0.0007, 0.0110, 0.0061, 0.0016, 0.0174, 0.0140,
        0.1520, 0.0440, 0.0401, 0.2024, 0.0138, 0.0320, 0.0342, 0.0259, 0.1117,
        0.0298], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:44,653][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([1.1393e-04, 2.0855e-03, 1.5472e-01, 3.5965e-02, 6.5073e-02, 3.8552e-02,
        7.2281e-02, 9.6621e-03, 1.5013e-02, 4.0064e-02, 2.5537e-02, 2.1342e-02,
        8.4233e-03, 1.2141e-02, 3.6869e-01, 2.6210e-02, 6.8835e-02, 1.3909e-02,
        2.1382e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:44,654][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0041, 0.0027, 0.0011, 0.0006, 0.0016, 0.0009, 0.0051, 0.0058, 0.0202,
        0.0148, 0.0185, 0.0160, 0.1254, 0.0705, 0.1757, 0.0278, 0.1160, 0.1810,
        0.2123], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:44,656][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0740, 0.0380, 0.0110, 0.0047, 0.0070, 0.0140, 0.0021, 0.0618, 0.0062,
        0.1068, 0.0076, 0.0064, 0.1124, 0.0370, 0.0303, 0.2575, 0.0114, 0.1864,
        0.0253], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:44,657][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([6.9477e-05, 4.0311e-04, 2.3742e-01, 1.8411e-02, 3.5764e-02, 4.7812e-02,
        3.1458e-02, 1.4195e-02, 1.9473e-02, 1.1421e-02, 1.7196e-03, 4.9122e-03,
        4.9776e-03, 2.1270e-03, 5.5499e-01, 8.1641e-04, 5.4863e-03, 5.2198e-03,
        3.3247e-03], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:44,658][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([8.0571e-03, 9.3951e-05, 1.2218e-06, 8.4152e-06, 4.1099e-06, 5.7912e-05,
        1.3503e-04, 5.0192e-04, 1.1325e-03, 1.2771e-03, 1.8239e-03, 5.1910e-03,
        1.0638e-01, 1.8743e-01, 1.1039e-01, 8.0379e-02, 1.0242e-01, 6.0818e-02,
        3.3390e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:44,659][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0006, 0.0103, 0.0164, 0.0679, 0.0127, 0.0292, 0.2294, 0.0520, 0.0722,
        0.0299, 0.0353, 0.0602, 0.0167, 0.0233, 0.0245, 0.0565, 0.1008, 0.0168,
        0.1453], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:44,661][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:21:44,662][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[2505],
        [   8],
        [ 102],
        [  50],
        [4075],
        [ 715],
        [ 864],
        [ 286],
        [ 136],
        [ 254],
        [ 464],
        [ 433],
        [  67],
        [   9],
        [  74],
        [ 169],
        [ 261],
        [  18],
        [  20]], device='cuda:0')
[2024-07-24 10:21:44,664][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[1921],
        [  26],
        [ 239],
        [  82],
        [4625],
        [1130],
        [1387],
        [ 474],
        [ 226],
        [ 614],
        [ 940],
        [ 976],
        [ 148],
        [  26],
        [ 199],
        [ 431],
        [ 711],
        [  46],
        [  54]], device='cuda:0')
[2024-07-24 10:21:44,666][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[ 7628],
        [ 4762],
        [16245],
        [11960],
        [ 4007],
        [ 4785],
        [ 6833],
        [10774],
        [10154],
        [11634],
        [11460],
        [11972],
        [12191],
        [12036],
        [12890],
        [10989],
        [11879],
        [11887],
        [10701]], device='cuda:0')
[2024-07-24 10:21:44,667][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[4077],
        [9387],
        [6761],
        [3942],
        [2955],
        [3135],
        [2806],
        [2429],
        [2147],
        [2192],
        [2109],
        [2424],
        [2572],
        [2443],
        [2585],
        [2345],
        [2413],
        [2392],
        [2257]], device='cuda:0')
[2024-07-24 10:21:44,669][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 6096],
        [30579],
        [32530],
        [31533],
        [45410],
        [44006],
        [44043],
        [44692],
        [46152],
        [44793],
        [43795],
        [44439],
        [46486],
        [46969],
        [46872],
        [46870],
        [46778],
        [46064],
        [46186]], device='cuda:0')
[2024-07-24 10:21:44,670][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[19714],
        [23463],
        [25790],
        [24596],
        [25663],
        [27073],
        [27001],
        [28183],
        [28976],
        [30090],
        [30670],
        [30937],
        [30294],
        [30137],
        [30909],
        [31009],
        [29799],
        [30500],
        [29730]], device='cuda:0')
[2024-07-24 10:21:44,672][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[ 9238],
        [11859],
        [ 5595],
        [ 6716],
        [ 7026],
        [ 7806],
        [ 7275],
        [ 8130],
        [ 7637],
        [ 8534],
        [ 9190],
        [ 9161],
        [ 9556],
        [ 8982],
        [ 8201],
        [ 7921],
        [ 8929],
        [ 8465],
        [ 8761]], device='cuda:0')
[2024-07-24 10:21:44,673][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[14425],
        [ 3891],
        [ 6433],
        [ 7340],
        [ 4738],
        [ 5368],
        [ 4518],
        [ 9324],
        [ 6325],
        [ 6855],
        [ 5740],
        [ 5449],
        [ 6363],
        [ 6295],
        [ 5558],
        [ 5740],
        [ 5502],
        [ 5572],
        [ 4557]], device='cuda:0')
[2024-07-24 10:21:44,675][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[18458],
        [42695],
        [46847],
        [47006],
        [49867],
        [49843],
        [46987],
        [44458],
        [44972],
        [40314],
        [41362],
        [41176],
        [41049],
        [43365],
        [43251],
        [42480],
        [42025],
        [41542],
        [41701]], device='cuda:0')
[2024-07-24 10:21:44,676][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[ 3382],
        [14072],
        [19327],
        [16423],
        [ 7760],
        [ 8490],
        [ 9151],
        [10622],
        [ 9419],
        [ 9403],
        [ 9468],
        [ 9069],
        [ 9972],
        [ 9233],
        [10931],
        [12082],
        [11477],
        [11856],
        [11674]], device='cuda:0')
[2024-07-24 10:21:44,678][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[ 647],
        [1875],
        [3430],
        [4342],
        [ 593],
        [1160],
        [1407],
        [1720],
        [2102],
        [1490],
        [1479],
        [1420],
        [1811],
        [1750],
        [1922],
        [1557],
        [1882],
        [1711],
        [1882]], device='cuda:0')
[2024-07-24 10:21:44,679][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[22888],
        [ 7510],
        [  788],
        [  617],
        [44530],
        [14709],
        [15111],
        [18897],
        [10453],
        [ 5966],
        [ 8890],
        [ 6173],
        [ 1551],
        [ 4637],
        [  337],
        [  902],
        [  343],
        [  672],
        [  459]], device='cuda:0')
[2024-07-24 10:21:44,681][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[44855],
        [26000],
        [30316],
        [44523],
        [44741],
        [38874],
        [41930],
        [41195],
        [35997],
        [34210],
        [30218],
        [33190],
        [34654],
        [31626],
        [27961],
        [29789],
        [34575],
        [34036],
        [33808]], device='cuda:0')
[2024-07-24 10:21:44,683][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[16736],
        [28848],
        [40394],
        [24911],
        [33584],
        [33684],
        [37114],
        [32373],
        [33957],
        [32110],
        [33329],
        [33189],
        [33273],
        [34212],
        [32877],
        [34527],
        [35482],
        [34371],
        [34273]], device='cuda:0')
[2024-07-24 10:21:44,684][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[27534],
        [10513],
        [16377],
        [12492],
        [17210],
        [18867],
        [18518],
        [26476],
        [11139],
        [24011],
        [22885],
        [16868],
        [21886],
        [16363],
        [18825],
        [23184],
        [21465],
        [23099],
        [16979]], device='cuda:0')
[2024-07-24 10:21:44,685][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[38340],
        [21303],
        [ 8943],
        [12032],
        [ 7303],
        [ 7719],
        [ 7989],
        [31457],
        [14420],
        [25581],
        [24493],
        [21684],
        [13047],
        [15110],
        [12051],
        [13680],
        [15137],
        [15390],
        [15122]], device='cuda:0')
[2024-07-24 10:21:44,687][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[27213],
        [13320],
        [40818],
        [40092],
        [23178],
        [21756],
        [23687],
        [23894],
        [31930],
        [19168],
        [27061],
        [33332],
        [21116],
        [29314],
        [27520],
        [24152],
        [25901],
        [21768],
        [33047]], device='cuda:0')
[2024-07-24 10:21:44,689][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[12335],
        [ 5536],
        [ 4488],
        [ 7784],
        [ 8620],
        [ 8877],
        [ 8248],
        [ 5003],
        [ 6613],
        [ 6036],
        [ 6650],
        [ 7249],
        [ 8012],
        [ 8138],
        [ 9218],
        [12385],
        [11775],
        [13860],
        [13324]], device='cuda:0')
[2024-07-24 10:21:44,690][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[3348],
        [1136],
        [ 279],
        [1116],
        [ 313],
        [ 331],
        [1857],
        [ 211],
        [ 613],
        [ 639],
        [ 239],
        [ 314],
        [ 518],
        [1158],
        [1808],
        [1381],
        [ 701],
        [1180],
        [ 198]], device='cuda:0')
[2024-07-24 10:21:44,691][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[ 8784],
        [14652],
        [30815],
        [27778],
        [21257],
        [24057],
        [25442],
        [22667],
        [23601],
        [26303],
        [25170],
        [24379],
        [21658],
        [22557],
        [23364],
        [29521],
        [28312],
        [26684],
        [27582]], device='cuda:0')
[2024-07-24 10:21:44,693][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[ 2688],
        [17189],
        [17108],
        [14102],
        [20322],
        [19533],
        [15273],
        [20585],
        [16338],
        [25152],
        [23318],
        [23188],
        [16120],
        [15729],
        [17593],
        [15980],
        [16837],
        [17101],
        [16489]], device='cuda:0')
[2024-07-24 10:21:44,695][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[4403],
        [6149],
        [7125],
        [6633],
        [3955],
        [2334],
        [3406],
        [5727],
        [3611],
        [4858],
        [3197],
        [2955],
        [3915],
        [2705],
        [6891],
        [7135],
        [6278],
        [7015],
        [6015]], device='cuda:0')
[2024-07-24 10:21:44,696][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[ 1167],
        [26649],
        [34302],
        [28118],
        [26193],
        [26903],
        [33032],
        [31059],
        [29761],
        [36383],
        [34572],
        [36135],
        [47130],
        [41540],
        [42635],
        [43012],
        [44209],
        [44402],
        [44812]], device='cuda:0')
[2024-07-24 10:21:44,697][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[14476],
        [ 5469],
        [ 4347],
        [ 3770],
        [ 2966],
        [ 1688],
        [ 1733],
        [  752],
        [ 1901],
        [ 1768],
        [ 1667],
        [ 1687],
        [ 1492],
        [ 1476],
        [ 1419],
        [  885],
        [  926],
        [  974],
        [  992]], device='cuda:0')
[2024-07-24 10:21:44,699][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[23403],
        [39419],
        [35659],
        [34344],
        [30929],
        [35818],
        [42747],
        [47351],
        [38872],
        [43050],
        [37259],
        [37557],
        [40930],
        [36987],
        [41585],
        [43525],
        [41764],
        [45651],
        [40659]], device='cuda:0')
[2024-07-24 10:21:44,701][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[ 2441],
        [ 5520],
        [14193],
        [10917],
        [ 9867],
        [19793],
        [23031],
        [25580],
        [ 9609],
        [11277],
        [16861],
        [16984],
        [29974],
        [23835],
        [25580],
        [31971],
        [34528],
        [33571],
        [31724]], device='cuda:0')
[2024-07-24 10:21:44,702][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[13030],
        [34148],
        [10886],
        [25809],
        [24274],
        [23073],
        [19449],
        [17366],
        [18094],
        [18191],
        [19056],
        [19917],
        [19172],
        [18776],
        [18654],
        [16426],
        [16069],
        [15996],
        [17047]], device='cuda:0')
[2024-07-24 10:21:44,703][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[48537],
        [44981],
        [47900],
        [45669],
        [47442],
        [47675],
        [46466],
        [44496],
        [47704],
        [43907],
        [45349],
        [44837],
        [45048],
        [45191],
        [43193],
        [41553],
        [42104],
        [40264],
        [43337]], device='cuda:0')
[2024-07-24 10:21:44,705][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[21240],
        [38323],
        [18801],
        [21474],
        [28579],
        [25650],
        [23071],
        [18305],
        [29278],
        [21834],
        [21402],
        [24992],
        [19430],
        [25440],
        [20024],
        [19527],
        [19881],
        [19631],
        [20814]], device='cuda:0')
[2024-07-24 10:21:44,707][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[28930],
        [28930],
        [28930],
        [28930],
        [28930],
        [28930],
        [28930],
        [28930],
        [28930],
        [28930],
        [28930],
        [28930],
        [28930],
        [28930],
        [28930],
        [28930],
        [28930],
        [28930],
        [28930]], device='cuda:0')
[2024-07-24 10:21:44,767][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:21:44,768][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:44,769][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:44,770][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:44,771][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:44,772][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:44,772][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:44,772][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:44,773][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:44,773][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:44,773][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:44,774][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:44,774][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:44,774][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.5481, 0.4519], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:44,775][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0300, 0.9700], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:44,775][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.3932, 0.6068], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:44,775][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.1885, 0.8115], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:44,776][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.1369, 0.8631], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:44,777][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.4745, 0.5255], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:44,778][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0249, 0.9751], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:44,780][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0247, 0.9753], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:44,781][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.2324, 0.7676], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:44,781][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.9600, 0.0400], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:44,782][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0931, 0.9069], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:44,782][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.7382, 0.2618], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:44,782][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Anthony] are: tensor([0.3381, 0.2962, 0.3657], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:44,783][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Anthony] are: tensor([2.2986e-04, 1.6069e-03, 9.9816e-01], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:44,783][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Anthony] are: tensor([0.5163, 0.2343, 0.2494], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:44,783][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Anthony] are: tensor([0.0625, 0.6930, 0.2445], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:44,784][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Anthony] are: tensor([0.0727, 0.5611, 0.3662], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:44,784][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Anthony] are: tensor([0.0683, 0.8311, 0.1006], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:44,785][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Anthony] are: tensor([0.0039, 0.1322, 0.8639], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:44,787][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Anthony] are: tensor([0.0015, 0.2985, 0.7000], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:44,788][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Anthony] are: tensor([0.0710, 0.5238, 0.4052], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:44,789][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Anthony] are: tensor([0.4366, 0.3013, 0.2621], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:44,791][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Anthony] are: tensor([0.0155, 0.0522, 0.9323], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:44,792][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Anthony] are: tensor([0.0195, 0.0449, 0.9356], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:44,793][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.3445, 0.1765, 0.3342, 0.1447], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:44,794][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ and] are: tensor([7.0451e-04, 2.8794e-03, 9.8233e-01, 1.4090e-02], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:44,796][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.4301, 0.2767, 0.2004, 0.0929], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:44,797][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0862, 0.6726, 0.1778, 0.0634], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:44,798][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0668, 0.4606, 0.0452, 0.4274], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:44,800][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.2632, 0.3150, 0.0483, 0.3735], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:44,801][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0040, 0.1182, 0.4617, 0.4161], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:44,803][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0321, 0.6104, 0.3273, 0.0302], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:44,804][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.1097, 0.5739, 0.3067, 0.0097], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:44,805][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.9443, 0.0039, 0.0030, 0.0487], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:44,806][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ and] are: tensor([8.4454e-02, 1.5419e-01, 7.6094e-01, 4.1275e-04], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:44,808][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.6890, 0.0427, 0.2641, 0.0042], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:44,809][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Travis] are: tensor([0.6447, 0.0878, 0.1258, 0.0470, 0.0947], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:44,810][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Travis] are: tensor([1.7624e-04, 2.9340e-03, 3.3498e-01, 1.7951e-02, 6.4396e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:44,811][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Travis] are: tensor([0.4760, 0.2303, 0.1527, 0.1094, 0.0316], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:44,813][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Travis] are: tensor([0.0515, 0.3773, 0.1282, 0.0843, 0.3588], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:44,814][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Travis] are: tensor([0.2004, 0.4713, 0.0864, 0.1731, 0.0688], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:44,816][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Travis] are: tensor([0.0915, 0.3322, 0.0257, 0.4004, 0.1502], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:44,817][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Travis] are: tensor([0.0016, 0.0756, 0.2866, 0.3363, 0.2999], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:44,818][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Travis] are: tensor([0.0028, 0.2638, 0.0619, 0.0172, 0.6544], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:44,820][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Travis] are: tensor([0.1043, 0.4290, 0.1808, 0.0136, 0.2723], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:44,821][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Travis] are: tensor([0.0849, 0.0061, 0.0078, 0.4388, 0.4624], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:44,822][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Travis] are: tensor([0.1027, 0.1230, 0.7553, 0.0010, 0.0180], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:44,824][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Travis] are: tensor([0.0153, 0.0395, 0.5729, 0.1484, 0.2240], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:44,825][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.2908, 0.0842, 0.2185, 0.0823, 0.1546, 0.1695], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:44,826][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ had] are: tensor([4.1122e-05, 6.8754e-04, 9.2454e-02, 4.3537e-03, 8.7331e-01, 2.9155e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:44,827][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.1838, 0.2439, 0.1704, 0.2059, 0.0541, 0.1420], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:44,829][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.0275, 0.2935, 0.1230, 0.0338, 0.4193, 0.1029], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:44,830][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.1132, 0.2635, 0.0585, 0.2236, 0.0620, 0.2792], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:44,832][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.2615, 0.1304, 0.0118, 0.1192, 0.0268, 0.4502], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:44,833][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.0013, 0.0388, 0.1949, 0.1828, 0.1897, 0.3926], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:44,834][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.0154, 0.3079, 0.2541, 0.0189, 0.3598, 0.0439], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:44,836][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.0519, 0.6166, 0.1109, 0.0102, 0.1183, 0.0920], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:44,837][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.0820, 0.0053, 0.0022, 0.0156, 0.0368, 0.8581], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:44,838][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ had] are: tensor([1.4927e-02, 1.1180e-01, 8.4331e-01, 6.5123e-04, 2.8524e-02, 7.8284e-04],
       device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:44,839][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0739, 0.0286, 0.4446, 0.0349, 0.1735, 0.2446], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:44,839][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.1863, 0.0933, 0.1947, 0.0770, 0.1355, 0.1113, 0.2019],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:44,839][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ a] are: tensor([4.7965e-05, 5.6917e-04, 2.0899e-01, 3.3262e-03, 7.0331e-01, 9.5744e-03,
        7.4175e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:44,840][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.2313, 0.3155, 0.1220, 0.1262, 0.0558, 0.0416, 0.1077],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:44,840][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0781, 0.5476, 0.0600, 0.0268, 0.1967, 0.0466, 0.0442],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:44,840][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.1729, 0.2036, 0.0138, 0.1265, 0.0076, 0.1251, 0.3504],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:44,841][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.1617, 0.1018, 0.0148, 0.0928, 0.0313, 0.3321, 0.2655],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:44,841][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0009, 0.0337, 0.1306, 0.1104, 0.1178, 0.1941, 0.4125],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:44,842][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0294, 0.4787, 0.1321, 0.0176, 0.2951, 0.0190, 0.0280],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:44,842][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0496, 0.2571, 0.1447, 0.0066, 0.4892, 0.0385, 0.0144],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:44,843][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ a] are: tensor([8.6512e-01, 1.4734e-03, 9.7453e-05, 8.0149e-04, 1.9591e-03, 5.1572e-02,
        7.8979e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:44,844][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ a] are: tensor([2.0202e-02, 2.0539e-01, 7.3673e-01, 6.2879e-04, 3.6316e-02, 3.9547e-04,
        3.4401e-04], device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:44,845][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.3384, 0.0187, 0.3090, 0.0116, 0.2754, 0.0370, 0.0098],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:44,847][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ lot] are: tensor([0.1204, 0.0411, 0.1307, 0.0655, 0.1591, 0.1039, 0.1530, 0.2262],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:44,848][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ lot] are: tensor([1.8554e-05, 1.0337e-03, 1.0665e-01, 8.9426e-03, 5.7461e-01, 7.9086e-03,
        2.9087e-01, 9.9570e-03], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:44,848][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ lot] are: tensor([0.0486, 0.1226, 0.0700, 0.2051, 0.0295, 0.1022, 0.3030, 0.1189],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:44,850][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ lot] are: tensor([0.0066, 0.0708, 0.0897, 0.0383, 0.3046, 0.1113, 0.0611, 0.3176],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:44,851][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ lot] are: tensor([0.2045, 0.0963, 0.0121, 0.0882, 0.0119, 0.1061, 0.4451, 0.0359],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:44,853][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ lot] are: tensor([0.0875, 0.0851, 0.0062, 0.0646, 0.0179, 0.2481, 0.2487, 0.2419],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:44,854][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ lot] are: tensor([0.0004, 0.0124, 0.0993, 0.0714, 0.0931, 0.1522, 0.2869, 0.2843],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:44,855][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ lot] are: tensor([0.0020, 0.1227, 0.1139, 0.0277, 0.6140, 0.0184, 0.0323, 0.0688],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:44,857][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ lot] are: tensor([0.0105, 0.0920, 0.1032, 0.0132, 0.3161, 0.1104, 0.0394, 0.3151],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:44,858][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ lot] are: tensor([2.6646e-02, 1.0546e-03, 9.3071e-05, 1.0765e-03, 1.0925e-03, 5.1709e-02,
        8.0101e-01, 1.1732e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:44,859][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ lot] are: tensor([0.0095, 0.1121, 0.8237, 0.0014, 0.0485, 0.0015, 0.0010, 0.0023],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:44,861][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ lot] are: tensor([0.0120, 0.0181, 0.1888, 0.0383, 0.1112, 0.2870, 0.1791, 0.1655],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:44,862][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ of] are: tensor([0.0873, 0.0561, 0.1682, 0.0518, 0.1165, 0.0863, 0.1484, 0.1262, 0.1593],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:44,863][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ of] are: tensor([1.6979e-05, 3.0563e-04, 2.4286e-01, 2.5729e-03, 6.9678e-01, 5.6832e-03,
        3.1145e-02, 1.5732e-02, 4.9004e-03], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:44,864][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ of] are: tensor([0.1788, 0.2767, 0.1425, 0.0739, 0.0268, 0.0439, 0.0691, 0.1560, 0.0324],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:44,866][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ of] are: tensor([0.0229, 0.2346, 0.1304, 0.0145, 0.2318, 0.0346, 0.0235, 0.2944, 0.0132],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:44,867][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ of] are: tensor([0.1059, 0.1455, 0.0170, 0.0717, 0.0131, 0.0656, 0.0906, 0.0481, 0.4425],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:44,869][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ of] are: tensor([0.2068, 0.0301, 0.0022, 0.0148, 0.0047, 0.0508, 0.0658, 0.0405, 0.5845],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:44,870][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ of] are: tensor([0.0005, 0.0146, 0.0905, 0.0555, 0.0720, 0.1117, 0.2280, 0.1992, 0.2280],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:44,872][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ of] are: tensor([0.0151, 0.3593, 0.1905, 0.0078, 0.3650, 0.0121, 0.0122, 0.0144, 0.0235],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:44,873][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ of] are: tensor([0.0157, 0.1660, 0.1018, 0.0040, 0.3806, 0.0276, 0.0067, 0.2767, 0.0210],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:44,874][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ of] are: tensor([8.0350e-01, 4.5776e-04, 1.2403e-05, 3.4000e-05, 1.0059e-04, 1.0644e-02,
        1.8707e-02, 2.2135e-02, 1.4441e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:44,875][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ of] are: tensor([9.9071e-03, 7.4020e-02, 8.9920e-01, 3.0331e-04, 1.5169e-02, 2.8288e-04,
        1.6393e-04, 9.4453e-04, 1.3421e-05], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:44,876][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ of] are: tensor([0.3359, 0.0214, 0.3315, 0.0056, 0.2108, 0.0128, 0.0011, 0.0725, 0.0084],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:44,878][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ fun] are: tensor([0.2196, 0.0311, 0.0816, 0.0392, 0.0639, 0.0793, 0.1207, 0.1342, 0.1377,
        0.0928], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:44,879][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ fun] are: tensor([1.5509e-05, 1.3104e-04, 7.1158e-02, 6.9265e-03, 8.0385e-01, 1.0070e-02,
        8.1959e-02, 8.7210e-03, 6.4548e-03, 1.0715e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:44,880][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ fun] are: tensor([0.0225, 0.0529, 0.0574, 0.1094, 0.0105, 0.0602, 0.2495, 0.1139, 0.0888,
        0.2349], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:44,882][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ fun] are: tensor([0.0082, 0.0971, 0.0739, 0.0267, 0.2359, 0.0750, 0.0597, 0.3968, 0.0110,
        0.0156], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:44,883][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ fun] are: tensor([0.1136, 0.1309, 0.0126, 0.0487, 0.0109, 0.0729, 0.2105, 0.0337, 0.3559,
        0.0104], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:44,885][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ fun] are: tensor([0.0355, 0.0247, 0.0021, 0.0187, 0.0053, 0.0683, 0.0778, 0.0892, 0.6500,
        0.0285], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:44,886][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ fun] are: tensor([0.0006, 0.0095, 0.0580, 0.0640, 0.0574, 0.1040, 0.1993, 0.2146, 0.1955,
        0.0972], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:44,887][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ fun] are: tensor([0.0051, 0.1158, 0.1637, 0.0268, 0.4311, 0.0374, 0.0367, 0.0232, 0.0138,
        0.1464], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:44,889][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ fun] are: tensor([0.0263, 0.0807, 0.0232, 0.0044, 0.0429, 0.0319, 0.0108, 0.0475, 0.0236,
        0.7088], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:44,890][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ fun] are: tensor([5.9422e-03, 1.9137e-04, 2.1001e-05, 1.4264e-04, 8.6836e-05, 8.0713e-03,
        8.5243e-02, 2.4015e-01, 5.0571e-01, 1.5444e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:44,891][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ fun] are: tensor([9.3770e-03, 4.0267e-02, 7.0803e-01, 1.8083e-03, 3.1161e-02, 1.3479e-03,
        1.0191e-03, 2.7305e-03, 7.7150e-05, 2.0418e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:44,892][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ fun] are: tensor([0.0080, 0.0029, 0.3473, 0.0186, 0.2246, 0.0685, 0.0567, 0.0954, 0.1566,
        0.0214], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:44,893][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.1236, 0.0380, 0.1085, 0.0319, 0.0900, 0.0801, 0.0994, 0.1371, 0.1207,
        0.1115, 0.0593], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:44,894][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ at] are: tensor([8.5250e-06, 2.7014e-04, 7.4301e-02, 3.3097e-03, 8.1563e-01, 1.2182e-02,
        5.0815e-02, 1.5234e-02, 3.1257e-03, 2.0229e-02, 4.8916e-03],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:44,896][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.0693, 0.1447, 0.0650, 0.0694, 0.0265, 0.0712, 0.0829, 0.1713, 0.0225,
        0.1707, 0.1067], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:44,896][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.0232, 0.2180, 0.0751, 0.0202, 0.2546, 0.0415, 0.0386, 0.2822, 0.0160,
        0.0222, 0.0085], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:44,897][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.1551, 0.1551, 0.0124, 0.0585, 0.0121, 0.0606, 0.0773, 0.0387, 0.2539,
        0.0134, 0.1631], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:44,897][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.0587, 0.0380, 0.0032, 0.0192, 0.0063, 0.0602, 0.0689, 0.0608, 0.5368,
        0.0349, 0.1130], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:44,898][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.0006, 0.0103, 0.0551, 0.0457, 0.0478, 0.0868, 0.1918, 0.1832, 0.1976,
        0.1018, 0.0795], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:44,898][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0055, 0.2000, 0.0885, 0.0124, 0.5687, 0.0160, 0.0189, 0.0094, 0.0185,
        0.0365, 0.0255], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:44,899][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.0082, 0.2414, 0.0482, 0.0046, 0.1139, 0.0277, 0.0126, 0.1671, 0.0192,
        0.3358, 0.0213], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:44,899][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ at] are: tensor([2.3225e-01, 1.0352e-03, 5.9279e-05, 5.0079e-05, 2.9678e-04, 9.9482e-03,
        3.5938e-02, 1.3770e-01, 1.1211e-01, 2.9667e-01, 1.7393e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:44,900][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ at] are: tensor([1.7833e-02, 1.1210e-01, 5.9776e-01, 7.2159e-04, 2.5927e-02, 9.3407e-04,
        3.3851e-04, 2.7342e-03, 3.2182e-05, 2.4142e-01, 1.9712e-04],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:44,901][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.1980, 0.0182, 0.2064, 0.0053, 0.3777, 0.0113, 0.0010, 0.1034, 0.0034,
        0.0357, 0.0395], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:44,902][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0867, 0.0449, 0.1473, 0.0358, 0.0778, 0.0706, 0.0932, 0.0987, 0.1035,
        0.1257, 0.0522, 0.0636], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:44,903][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ the] are: tensor([3.2522e-06, 2.1361e-04, 2.2443e-01, 3.4045e-03, 6.6417e-01, 4.0976e-03,
        4.3983e-02, 1.1830e-02, 3.3719e-03, 2.4101e-02, 5.5617e-03, 1.4838e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:44,905][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0356, 0.1057, 0.0905, 0.0856, 0.0172, 0.0377, 0.0807, 0.1771, 0.0262,
        0.2206, 0.0652, 0.0578], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:44,906][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0147, 0.1386, 0.0767, 0.0227, 0.1668, 0.0335, 0.0425, 0.4155, 0.0126,
        0.0296, 0.0085, 0.0384], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:44,907][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0584, 0.0548, 0.0071, 0.0475, 0.0028, 0.0247, 0.0780, 0.0301, 0.2460,
        0.0120, 0.1909, 0.2479], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:44,909][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0519, 0.0307, 0.0032, 0.0180, 0.0059, 0.0483, 0.0536, 0.0506, 0.5296,
        0.0315, 0.1128, 0.0639], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:44,910][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0003, 0.0093, 0.0732, 0.0402, 0.0462, 0.0845, 0.1777, 0.1434, 0.1636,
        0.0951, 0.0695, 0.0970], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:44,912][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0101, 0.2335, 0.1583, 0.0138, 0.3788, 0.0140, 0.0168, 0.0115, 0.0129,
        0.0539, 0.0174, 0.0790], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:44,913][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0022, 0.0589, 0.0197, 0.0024, 0.0685, 0.0104, 0.0058, 0.1524, 0.0138,
        0.6081, 0.0333, 0.0244], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:44,914][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ the] are: tensor([4.1708e-01, 1.7568e-03, 3.9174e-05, 9.3946e-05, 1.8350e-04, 7.4485e-03,
        1.8210e-02, 8.0937e-02, 1.3281e-01, 8.1980e-02, 1.4964e-01, 1.0982e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:44,915][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ the] are: tensor([2.5857e-03, 3.9240e-02, 8.3845e-01, 2.3506e-04, 1.5180e-02, 1.2575e-04,
        9.3990e-05, 5.5899e-04, 6.2803e-06, 1.0326e-01, 3.8400e-05, 2.2737e-04],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:44,916][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.1071, 0.0047, 0.2886, 0.0080, 0.2712, 0.0333, 0.0030, 0.1491, 0.0229,
        0.0144, 0.0886, 0.0090], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:44,918][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ hospital] are: tensor([0.1608, 0.0318, 0.0862, 0.0269, 0.0681, 0.0580, 0.0656, 0.1081, 0.0737,
        0.0705, 0.0556, 0.0463, 0.1486], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:44,919][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ hospital] are: tensor([3.8061e-05, 8.2805e-04, 1.7906e-01, 1.3610e-02, 3.9557e-01, 1.3907e-02,
        8.5448e-02, 5.6696e-03, 6.5996e-03, 1.5391e-02, 1.9685e-02, 9.5230e-03,
        2.5468e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:44,920][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ hospital] are: tensor([0.0435, 0.1871, 0.0715, 0.1134, 0.0126, 0.0758, 0.1233, 0.0782, 0.0218,
        0.1058, 0.0693, 0.0330, 0.0645], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:44,922][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ hospital] are: tensor([0.0386, 0.2783, 0.0918, 0.0256, 0.1352, 0.0487, 0.0401, 0.2303, 0.0116,
        0.0194, 0.0326, 0.0263, 0.0214], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:44,923][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ hospital] are: tensor([0.2097, 0.1344, 0.0100, 0.0321, 0.0062, 0.0496, 0.0911, 0.0109, 0.1475,
        0.0071, 0.0797, 0.1548, 0.0669], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:44,925][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ hospital] are: tensor([0.0688, 0.0187, 0.0008, 0.0112, 0.0023, 0.0475, 0.0469, 0.0390, 0.4993,
        0.0168, 0.1171, 0.0543, 0.0771], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:44,926][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ hospital] are: tensor([0.0006, 0.0117, 0.0709, 0.0485, 0.0423, 0.0773, 0.1761, 0.1313, 0.1512,
        0.0655, 0.0567, 0.0703, 0.0976], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:44,928][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ hospital] are: tensor([0.0053, 0.1624, 0.1610, 0.0137, 0.3245, 0.0164, 0.0151, 0.0048, 0.0061,
        0.0234, 0.0179, 0.0367, 0.2127], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:44,929][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ hospital] are: tensor([0.0580, 0.1947, 0.0300, 0.0060, 0.0291, 0.0313, 0.0113, 0.0317, 0.0215,
        0.2658, 0.0487, 0.0301, 0.2417], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:44,930][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ hospital] are: tensor([7.5496e-02, 1.2222e-04, 1.9199e-06, 1.5216e-05, 6.3851e-06, 3.0113e-04,
        2.9332e-03, 5.2662e-03, 6.7114e-03, 4.4486e-03, 1.1896e-02, 1.9911e-02,
        8.7289e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:44,931][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ hospital] are: tensor([1.9707e-02, 9.6511e-02, 6.8764e-01, 2.0923e-03, 2.5509e-02, 8.5928e-04,
        1.0992e-03, 1.4438e-03, 3.7616e-05, 1.2801e-01, 2.6195e-04, 6.3616e-04,
        3.6194e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:44,932][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ hospital] are: tensor([0.0170, 0.0183, 0.2687, 0.0609, 0.1729, 0.0485, 0.0274, 0.0741, 0.0902,
        0.0186, 0.1551, 0.0213, 0.0269], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:44,934][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.0880, 0.0259, 0.0910, 0.0234, 0.0611, 0.0627, 0.0736, 0.0746, 0.0710,
        0.0810, 0.0455, 0.0499, 0.2007, 0.0516], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:44,935][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [.] are: tensor([8.7787e-06, 2.1015e-04, 1.2464e-01, 2.4682e-03, 3.9457e-01, 4.4363e-03,
        3.2387e-02, 7.2747e-03, 2.8704e-03, 1.8577e-02, 7.3499e-03, 5.9716e-03,
        3.9670e-01, 2.5344e-03], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:44,936][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.1051, 0.1229, 0.0959, 0.0612, 0.0119, 0.0510, 0.0855, 0.0812, 0.0165,
        0.1120, 0.0658, 0.0329, 0.0758, 0.0822], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:44,938][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0330, 0.1919, 0.0957, 0.0154, 0.2933, 0.0525, 0.0172, 0.1902, 0.0080,
        0.0310, 0.0095, 0.0133, 0.0155, 0.0336], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:44,939][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.2772, 0.1965, 0.0131, 0.0169, 0.0059, 0.0320, 0.0515, 0.0285, 0.0898,
        0.0106, 0.0656, 0.0993, 0.0796, 0.0335], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:44,941][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.0880, 0.0243, 0.0022, 0.0132, 0.0040, 0.0357, 0.0340, 0.0267, 0.2384,
        0.0187, 0.0533, 0.0426, 0.0531, 0.3658], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:44,942][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0003, 0.0109, 0.0503, 0.0401, 0.0477, 0.0789, 0.1573, 0.1409, 0.1380,
        0.0768, 0.0639, 0.0753, 0.0912, 0.0285], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:44,944][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0229, 0.2325, 0.1027, 0.0067, 0.2472, 0.0153, 0.0137, 0.0071, 0.0074,
        0.0293, 0.0157, 0.0300, 0.1840, 0.0853], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:44,945][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.0138, 0.0475, 0.0296, 0.0015, 0.0679, 0.0156, 0.0054, 0.0447, 0.0085,
        0.2962, 0.0233, 0.0177, 0.3635, 0.0649], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:44,946][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [.] are: tensor([5.9387e-01, 6.7283e-05, 2.3358e-06, 1.8126e-06, 1.1177e-05, 1.7107e-04,
        3.7109e-04, 6.2551e-04, 2.9172e-04, 9.5296e-04, 8.2292e-04, 7.9183e-04,
        2.2969e-01, 1.7233e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:44,947][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [.] are: tensor([8.3292e-03, 8.6871e-02, 7.3692e-01, 4.8693e-04, 2.0137e-02, 4.6902e-04,
        2.8252e-04, 8.5730e-04, 1.2809e-05, 1.0297e-01, 7.6823e-05, 2.7341e-04,
        3.7354e-02, 4.9566e-03], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:44,949][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.2893, 0.0156, 0.2528, 0.0028, 0.2877, 0.0107, 0.0003, 0.0778, 0.0014,
        0.0088, 0.0051, 0.0007, 0.0386, 0.0085], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:44,950][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Anthony] are: tensor([0.1703, 0.0353, 0.0714, 0.0175, 0.0409, 0.0465, 0.0390, 0.0612, 0.0466,
        0.0537, 0.0293, 0.0384, 0.1600, 0.0426, 0.1474], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:44,951][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Anthony] are: tensor([2.9390e-05, 1.6165e-04, 7.9451e-02, 2.4343e-03, 1.6766e-01, 3.8693e-03,
        2.0753e-02, 5.8642e-03, 3.2873e-03, 1.7097e-02, 1.1401e-02, 6.7454e-03,
        2.5337e-01, 3.2047e-03, 4.2468e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:44,952][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Anthony] are: tensor([0.1764, 0.0916, 0.0719, 0.0540, 0.0076, 0.0428, 0.0713, 0.0727, 0.0174,
        0.1438, 0.0331, 0.0356, 0.0786, 0.0765, 0.0268], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:44,954][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Anthony] are: tensor([0.0415, 0.2623, 0.1124, 0.0162, 0.0745, 0.0365, 0.0127, 0.2218, 0.0177,
        0.0325, 0.0143, 0.0281, 0.0247, 0.0339, 0.0709], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:44,955][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Anthony] are: tensor([0.2124, 0.1796, 0.0254, 0.0176, 0.0108, 0.0393, 0.0433, 0.0351, 0.1224,
        0.0093, 0.0538, 0.0618, 0.0914, 0.0425, 0.0552], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:44,955][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Anthony] are: tensor([0.0100, 0.0109, 0.0006, 0.0056, 0.0024, 0.0334, 0.0317, 0.0327, 0.3198,
        0.0174, 0.0753, 0.0434, 0.0453, 0.3469, 0.0247], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:44,955][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Anthony] are: tensor([0.0004, 0.0081, 0.0454, 0.0349, 0.0292, 0.0642, 0.1246, 0.1064, 0.1544,
        0.0634, 0.0586, 0.0680, 0.0787, 0.0223, 0.1413], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:44,956][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Anthony] are: tensor([0.0049, 0.1990, 0.1581, 0.0060, 0.1363, 0.0083, 0.0047, 0.0020, 0.0050,
        0.0214, 0.0080, 0.0195, 0.3019, 0.0385, 0.0864], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:44,956][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Anthony] are: tensor([0.0118, 0.0531, 0.0245, 0.0027, 0.0608, 0.0185, 0.0049, 0.0398, 0.0131,
        0.3808, 0.0267, 0.0253, 0.1828, 0.0705, 0.0846], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:44,957][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Anthony] are: tensor([5.3927e-02, 2.0949e-05, 2.4884e-07, 2.0504e-07, 9.8021e-07, 2.0470e-05,
        7.4404e-05, 4.5252e-04, 6.8939e-04, 9.1582e-04, 1.1257e-03, 2.3051e-03,
        2.2690e-01, 4.5090e-01, 2.6267e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:44,957][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Anthony] are: tensor([3.5806e-02, 6.9282e-02, 6.7972e-01, 6.8689e-04, 1.1380e-02, 7.3088e-04,
        3.2945e-04, 7.3835e-04, 2.2393e-05, 1.2185e-01, 1.2774e-04, 4.5246e-04,
        3.4657e-02, 9.4901e-03, 3.4731e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:44,959][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Anthony] are: tensor([0.0579, 0.0198, 0.3106, 0.0144, 0.1012, 0.0160, 0.0057, 0.0473, 0.0138,
        0.0227, 0.0177, 0.0116, 0.0500, 0.0154, 0.2958], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:44,960][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.0501, 0.0175, 0.0680, 0.0195, 0.0690, 0.0549, 0.0493, 0.0524, 0.0516,
        0.0845, 0.0338, 0.0376, 0.0927, 0.0392, 0.1742, 0.1057],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:44,961][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([1.0504e-06, 1.9565e-04, 4.1414e-02, 3.1341e-03, 3.1879e-01, 3.4135e-03,
        2.5535e-02, 6.9591e-03, 7.1350e-03, 1.6281e-02, 1.8018e-02, 6.1810e-03,
        1.4929e-01, 2.8671e-03, 3.9659e-01, 4.1949e-03], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:44,963][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0288, 0.0532, 0.0973, 0.0754, 0.0074, 0.0463, 0.1045, 0.0808, 0.0217,
        0.1481, 0.0879, 0.0309, 0.0448, 0.0543, 0.0516, 0.0670],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:44,964][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.0055, 0.0665, 0.1659, 0.0227, 0.2546, 0.0493, 0.0638, 0.1272, 0.0136,
        0.0210, 0.0202, 0.0175, 0.0077, 0.0129, 0.1076, 0.0441],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:44,965][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.0739, 0.0606, 0.0129, 0.0452, 0.0129, 0.0482, 0.0533, 0.0281, 0.1692,
        0.0075, 0.1032, 0.0721, 0.0821, 0.0864, 0.0893, 0.0551],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:44,967][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.0264, 0.0185, 0.0008, 0.0074, 0.0014, 0.0236, 0.0290, 0.0281, 0.2476,
        0.0119, 0.0659, 0.0420, 0.0542, 0.3562, 0.0304, 0.0566],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:44,968][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0002, 0.0060, 0.0511, 0.0285, 0.0401, 0.0655, 0.1232, 0.1337, 0.1084,
        0.0704, 0.0606, 0.0548, 0.0599, 0.0164, 0.1726, 0.0085],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:44,970][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0008, 0.0436, 0.0712, 0.0066, 0.2571, 0.0095, 0.0102, 0.0047, 0.0042,
        0.0311, 0.0117, 0.0145, 0.0679, 0.0233, 0.0379, 0.4057],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:44,971][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.0011, 0.0153, 0.0274, 0.0025, 0.0264, 0.0090, 0.0078, 0.0172, 0.0397,
        0.1456, 0.0476, 0.0253, 0.1156, 0.0550, 0.1999, 0.2645],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:44,972][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([3.2108e-03, 6.2479e-06, 2.0153e-07, 6.9430e-07, 9.5730e-07, 1.9449e-05,
        2.7129e-04, 3.5064e-04, 6.1886e-04, 7.1668e-04, 1.0286e-03, 1.6088e-03,
        1.1887e-01, 1.5836e-01, 5.1961e-01, 1.9532e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:44,973][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([1.0917e-03, 2.2126e-02, 7.4056e-01, 8.4049e-04, 1.7596e-02, 6.9922e-04,
        4.8627e-04, 6.7585e-04, 4.0418e-05, 7.8433e-02, 2.0926e-04, 4.6917e-04,
        2.1198e-02, 4.0214e-03, 6.1344e-02, 5.0206e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:44,975][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.1157, 0.0072, 0.2949, 0.0048, 0.1708, 0.0346, 0.0013, 0.0676, 0.0093,
        0.0175, 0.0459, 0.0025, 0.0143, 0.0054, 0.1436, 0.0645],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:44,976][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.1781, 0.0235, 0.0526, 0.0143, 0.0316, 0.0335, 0.0322, 0.0492, 0.0368,
        0.0573, 0.0278, 0.0292, 0.1308, 0.0368, 0.1023, 0.1183, 0.0455],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:44,977][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ a] are: tensor([9.3145e-06, 1.5821e-04, 7.5115e-02, 1.8096e-03, 2.1915e-01, 3.4934e-03,
        3.0700e-02, 8.3593e-03, 4.0928e-03, 8.4915e-03, 7.4076e-03, 1.0187e-02,
        2.8374e-01, 1.9682e-03, 2.6228e-01, 5.6493e-03, 7.7388e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:44,979][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0646, 0.0771, 0.0628, 0.0541, 0.0118, 0.0210, 0.0451, 0.0861, 0.0129,
        0.1484, 0.0403, 0.0347, 0.0685, 0.0800, 0.0308, 0.1167, 0.0450],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:44,980][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0338, 0.1157, 0.0381, 0.0154, 0.0588, 0.0243, 0.0279, 0.2694, 0.0167,
        0.0273, 0.0121, 0.0281, 0.0277, 0.0337, 0.0435, 0.1527, 0.0748],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:44,981][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.1359, 0.0667, 0.0038, 0.0180, 0.0011, 0.0232, 0.0339, 0.0549, 0.1611,
        0.0089, 0.1370, 0.1331, 0.0546, 0.0278, 0.0077, 0.0739, 0.0583],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:44,983][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0424, 0.0227, 0.0030, 0.0112, 0.0035, 0.0264, 0.0250, 0.0293, 0.1845,
        0.0201, 0.0612, 0.0387, 0.0836, 0.2559, 0.0433, 0.0684, 0.0808],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:44,984][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0004, 0.0069, 0.0488, 0.0294, 0.0319, 0.0635, 0.1120, 0.1022, 0.1119,
        0.0673, 0.0588, 0.0700, 0.0721, 0.0202, 0.1290, 0.0122, 0.0633],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:44,986][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0112, 0.1044, 0.0623, 0.0053, 0.1190, 0.0063, 0.0075, 0.0105, 0.0059,
        0.0387, 0.0099, 0.0299, 0.1898, 0.0457, 0.0462, 0.2528, 0.0545],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:44,987][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0038, 0.0176, 0.0134, 0.0014, 0.0403, 0.0042, 0.0020, 0.0771, 0.0060,
        0.2295, 0.0108, 0.0153, 0.1432, 0.0468, 0.0542, 0.3115, 0.0228],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:44,988][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ a] are: tensor([6.4281e-02, 6.0024e-05, 8.6646e-07, 5.5803e-07, 1.5132e-06, 3.1593e-05,
        2.7633e-05, 5.4959e-04, 2.4464e-04, 2.5236e-04, 4.9709e-04, 3.1559e-04,
        1.0870e-01, 1.3274e-01, 1.6039e-01, 5.0416e-01, 2.7747e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:44,989][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ a] are: tensor([6.9951e-03, 7.5978e-02, 5.4309e-01, 5.8056e-04, 1.7067e-02, 3.2588e-04,
        1.9338e-04, 9.1284e-04, 1.4002e-05, 1.1622e-01, 8.6988e-05, 4.3008e-04,
        3.6462e-02, 7.1579e-03, 2.7026e-02, 1.5372e-01, 1.3730e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:44,991][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.1767, 0.0032, 0.1611, 0.0025, 0.1541, 0.0095, 0.0015, 0.1232, 0.0036,
        0.0106, 0.0136, 0.0020, 0.0344, 0.0067, 0.2355, 0.0503, 0.0115],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:44,992][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ drink] are: tensor([0.1426, 0.0177, 0.0656, 0.0110, 0.0359, 0.0312, 0.0385, 0.0689, 0.0410,
        0.0509, 0.0275, 0.0209, 0.0838, 0.0230, 0.1287, 0.1104, 0.0430, 0.0592],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:44,993][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ drink] are: tensor([6.3427e-06, 2.6631e-04, 1.1075e-01, 5.5278e-03, 2.9562e-01, 2.3206e-03,
        2.7628e-02, 6.0683e-03, 6.8149e-03, 6.4636e-03, 1.3052e-02, 7.5697e-03,
        9.5089e-02, 1.7816e-03, 3.5899e-01, 1.7037e-03, 3.2389e-02, 2.7964e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:44,995][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ drink] are: tensor([0.0263, 0.0307, 0.1157, 0.0939, 0.0070, 0.0275, 0.1374, 0.0705, 0.0169,
        0.1682, 0.0558, 0.0333, 0.0281, 0.0382, 0.0359, 0.0377, 0.0590, 0.0179],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:44,996][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ drink] are: tensor([0.0142, 0.0553, 0.1434, 0.0154, 0.2176, 0.0252, 0.0333, 0.1594, 0.0089,
        0.0232, 0.0254, 0.0114, 0.0078, 0.0164, 0.0770, 0.0605, 0.0654, 0.0404],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:44,998][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ drink] are: tensor([0.0821, 0.0687, 0.0134, 0.0132, 0.0036, 0.0213, 0.0351, 0.0501, 0.1731,
        0.0121, 0.0472, 0.0629, 0.0858, 0.0701, 0.0688, 0.0593, 0.0753, 0.0579],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:44,999][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ drink] are: tensor([0.0172, 0.0101, 0.0007, 0.0055, 0.0016, 0.0219, 0.0239, 0.0265, 0.2365,
        0.0103, 0.0484, 0.0343, 0.0507, 0.3102, 0.0260, 0.0517, 0.0834, 0.0410],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:45,001][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ drink] are: tensor([0.0003, 0.0064, 0.0491, 0.0311, 0.0331, 0.0540, 0.1032, 0.1357, 0.1131,
        0.0604, 0.0425, 0.0433, 0.0664, 0.0146, 0.1221, 0.0067, 0.0481, 0.0697],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:45,002][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ drink] are: tensor([0.0019, 0.0522, 0.0837, 0.0061, 0.1229, 0.0089, 0.0066, 0.0103, 0.0031,
        0.0485, 0.0165, 0.0123, 0.1355, 0.0255, 0.0407, 0.1908, 0.0301, 0.2044],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:45,004][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ drink] are: tensor([0.0036, 0.0274, 0.0263, 0.0038, 0.0284, 0.0126, 0.0060, 0.0189, 0.0095,
        0.1471, 0.0384, 0.0192, 0.0625, 0.0412, 0.0615, 0.1977, 0.0364, 0.2596],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:45,005][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ drink] are: tensor([3.0505e-03, 8.7099e-06, 1.9738e-07, 6.7725e-07, 5.3127e-07, 1.1135e-05,
        1.7483e-04, 4.4918e-04, 7.0177e-04, 5.1850e-04, 1.1185e-03, 2.1704e-03,
        7.5616e-02, 2.5808e-01, 1.3388e-01, 1.5104e-01, 2.2613e-01, 1.4705e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:45,006][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ drink] are: tensor([4.8455e-03, 3.3866e-02, 4.2410e-01, 9.4936e-04, 1.6501e-02, 2.6474e-04,
        4.6840e-04, 1.2588e-03, 2.2989e-05, 7.7327e-02, 1.8543e-04, 2.8245e-04,
        1.4648e-02, 2.8570e-03, 1.8704e-02, 6.1828e-02, 1.1020e-02, 3.3088e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:45,007][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ drink] are: tensor([0.0110, 0.0043, 0.4224, 0.0123, 0.0851, 0.0080, 0.0060, 0.0356, 0.0110,
        0.0159, 0.0200, 0.0048, 0.0101, 0.0060, 0.2117, 0.0164, 0.0183, 0.1011],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:45,009][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.1431, 0.0222, 0.0480, 0.0126, 0.0316, 0.0363, 0.0381, 0.0496, 0.0403,
        0.0477, 0.0226, 0.0283, 0.1012, 0.0321, 0.1053, 0.0983, 0.0500, 0.0550,
        0.0376], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:45,010][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ to] are: tensor([2.2021e-05, 1.6811e-04, 8.6268e-02, 1.1887e-03, 1.9981e-01, 3.8161e-03,
        2.4080e-02, 7.5297e-03, 3.5474e-03, 1.0326e-02, 6.2786e-03, 5.6629e-03,
        2.5653e-01, 1.9950e-03, 2.8568e-01, 5.7059e-03, 3.5001e-02, 6.3117e-02,
        3.2766e-03], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:45,012][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1667, 0.0543, 0.0573, 0.0224, 0.0072, 0.0314, 0.0473, 0.0634, 0.0095,
        0.1189, 0.0436, 0.0254, 0.0569, 0.0383, 0.0264, 0.1250, 0.0456, 0.0305,
        0.0299], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:45,012][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0344, 0.0721, 0.0875, 0.0094, 0.0799, 0.0267, 0.0228, 0.1817, 0.0108,
        0.0299, 0.0105, 0.0154, 0.0167, 0.0252, 0.0737, 0.1619, 0.0666, 0.0665,
        0.0084], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:45,013][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.1900, 0.1279, 0.0161, 0.0251, 0.0042, 0.0339, 0.0349, 0.0341, 0.1043,
        0.0053, 0.0509, 0.0744, 0.0708, 0.0278, 0.0189, 0.0700, 0.0437, 0.0257,
        0.0420], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:45,013][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0792, 0.0221, 0.0033, 0.0082, 0.0028, 0.0201, 0.0199, 0.0213, 0.1218,
        0.0158, 0.0457, 0.0296, 0.0533, 0.1805, 0.0314, 0.0435, 0.0648, 0.0550,
        0.1817], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:45,014][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0003, 0.0066, 0.0415, 0.0251, 0.0279, 0.0576, 0.1138, 0.1046, 0.1094,
        0.0548, 0.0528, 0.0577, 0.0601, 0.0172, 0.1140, 0.0081, 0.0579, 0.0628,
        0.0278], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:45,014][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0219, 0.1401, 0.0658, 0.0040, 0.1225, 0.0079, 0.0064, 0.0054, 0.0065,
        0.0236, 0.0147, 0.0185, 0.1254, 0.0528, 0.0625, 0.2070, 0.0442, 0.0157,
        0.0551], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:45,015][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0052, 0.0240, 0.0192, 0.0014, 0.0321, 0.0065, 0.0025, 0.0318, 0.0052,
        0.0851, 0.0086, 0.0117, 0.0968, 0.0355, 0.0664, 0.1670, 0.0168, 0.3461,
        0.0380], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:45,016][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ to] are: tensor([2.4400e-01, 8.3969e-05, 4.0622e-07, 1.5275e-07, 1.1036e-06, 1.9755e-05,
        2.8385e-05, 1.3936e-04, 4.9971e-05, 2.2339e-04, 1.6919e-04, 2.4463e-04,
        9.5808e-02, 9.5429e-02, 1.4735e-01, 2.0993e-01, 2.9297e-02, 6.7031e-02,
        1.1020e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:45,016][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ to] are: tensor([1.2331e-02, 3.4046e-02, 3.4209e-01, 2.2199e-04, 1.0006e-02, 3.6704e-04,
        2.4868e-04, 6.6145e-04, 1.3255e-05, 9.4784e-02, 7.4321e-05, 2.2976e-04,
        2.3308e-02, 3.0869e-03, 2.2664e-02, 9.2992e-02, 9.4230e-03, 3.5095e-01,
        2.5106e-03], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:45,017][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ to] are: tensor([6.2465e-01, 5.6501e-03, 1.0902e-01, 3.2955e-04, 4.7436e-02, 1.0569e-03,
        7.4377e-05, 4.3428e-02, 1.7884e-04, 3.2702e-03, 9.8203e-04, 2.0508e-04,
        2.5643e-02, 1.5520e-03, 5.3020e-02, 1.0677e-02, 9.3302e-04, 7.0815e-02,
        1.0836e-03], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:45,079][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:21:45,082][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:45,084][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:45,085][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:45,086][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:45,087][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:45,087][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:45,088][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:45,090][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:45,091][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:45,092][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:45,093][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:45,094][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:45,096][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.3172, 0.6828], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:45,102][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0300, 0.9700], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:45,103][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.4384, 0.5616], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:45,104][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.1885, 0.8115], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:45,106][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0799, 0.9201], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:45,107][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.9572, 0.0428], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:45,108][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0956, 0.9044], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:45,110][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0247, 0.9753], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:45,111][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.2324, 0.7676], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:45,112][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.9600, 0.0400], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:45,114][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0931, 0.9069], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:45,115][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.7382, 0.2618], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:45,116][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Anthony] are: tensor([0.0033, 0.0441, 0.9525], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:45,117][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Anthony] are: tensor([2.2986e-04, 1.6069e-03, 9.9816e-01], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:45,119][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Anthony] are: tensor([0.5986, 0.1905, 0.2109], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:45,120][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Anthony] are: tensor([0.0625, 0.6930, 0.2445], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:45,122][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Anthony] are: tensor([0.0131, 0.2354, 0.7515], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:45,123][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Anthony] are: tensor([0.7566, 0.1251, 0.1183], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:45,124][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Anthony] are: tensor([0.0047, 0.0420, 0.9532], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:45,126][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Anthony] are: tensor([0.0015, 0.2985, 0.7000], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:45,127][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Anthony] are: tensor([0.0710, 0.5238, 0.4052], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:45,129][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Anthony] are: tensor([0.4366, 0.3013, 0.2621], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:45,129][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Anthony] are: tensor([0.0155, 0.0522, 0.9323], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:45,129][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Anthony] are: tensor([0.0195, 0.0449, 0.9356], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:45,130][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0053, 0.0203, 0.8536, 0.1208], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:45,130][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([7.0451e-04, 2.8794e-03, 9.8233e-01, 1.4090e-02], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:45,130][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.5377, 0.2397, 0.1789, 0.0437], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:45,131][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0862, 0.6726, 0.1778, 0.0634], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:45,131][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0277, 0.2613, 0.1433, 0.5677], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:45,131][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.9166, 0.0042, 0.0022, 0.0769], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:45,132][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0113, 0.1235, 0.6412, 0.2240], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:45,132][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0321, 0.6104, 0.3273, 0.0302], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:45,134][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.1097, 0.5739, 0.3067, 0.0097], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:45,135][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.9443, 0.0039, 0.0030, 0.0487], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:45,136][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([8.4454e-02, 1.5419e-01, 7.6094e-01, 4.1275e-04], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:45,137][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.6890, 0.0427, 0.2641, 0.0042], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:45,138][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Travis] are: tensor([0.0115, 0.0306, 0.6329, 0.1117, 0.2133], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:45,139][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Travis] are: tensor([1.7624e-04, 2.9340e-03, 3.3498e-01, 1.7951e-02, 6.4396e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:45,141][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Travis] are: tensor([0.5957, 0.2005, 0.1239, 0.0615, 0.0184], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:45,142][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Travis] are: tensor([0.0515, 0.3773, 0.1282, 0.0843, 0.3588], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:45,144][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Travis] are: tensor([0.0711, 0.2229, 0.1343, 0.2869, 0.2848], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:45,145][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Travis] are: tensor([0.4357, 0.0101, 0.0034, 0.3180, 0.2328], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:45,146][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Travis] are: tensor([0.0064, 0.0963, 0.4253, 0.3306, 0.1415], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:45,148][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Travis] are: tensor([0.0028, 0.2638, 0.0619, 0.0172, 0.6544], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:45,149][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Travis] are: tensor([0.1043, 0.4290, 0.1808, 0.0136, 0.2723], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:45,151][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Travis] are: tensor([0.0849, 0.0061, 0.0078, 0.4388, 0.4624], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:45,152][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Travis] are: tensor([0.1027, 0.1230, 0.7553, 0.0010, 0.0180], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:45,153][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Travis] are: tensor([0.0153, 0.0395, 0.5729, 0.1484, 0.2240], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:45,155][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.0020, 0.0074, 0.4929, 0.0883, 0.2384, 0.1711], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:45,156][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([4.1122e-05, 6.8754e-04, 9.2454e-02, 4.3537e-03, 8.7331e-01, 2.9155e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:45,157][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.2994, 0.2618, 0.1618, 0.1441, 0.0359, 0.0970], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:45,158][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.0275, 0.2935, 0.1230, 0.0338, 0.4193, 0.1029], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:45,160][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.0313, 0.0840, 0.0767, 0.2117, 0.1743, 0.4219], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:45,161][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([9.6032e-02, 2.8063e-03, 3.0051e-04, 1.2582e-02, 1.9792e-02, 8.6849e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:45,162][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.0021, 0.0269, 0.3049, 0.0809, 0.0977, 0.4874], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:45,164][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.0154, 0.3079, 0.2541, 0.0189, 0.3598, 0.0439], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:45,165][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.0519, 0.6166, 0.1109, 0.0102, 0.1183, 0.0920], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:45,167][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.0820, 0.0053, 0.0022, 0.0156, 0.0368, 0.8581], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:45,167][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([1.4927e-02, 1.1180e-01, 8.4331e-01, 6.5123e-04, 2.8524e-02, 7.8284e-04],
       device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:45,169][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.0739, 0.0286, 0.4446, 0.0349, 0.1735, 0.2446], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:45,170][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0011, 0.0083, 0.3358, 0.0514, 0.0900, 0.0731, 0.4403],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:45,171][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([4.7965e-05, 5.6917e-04, 2.0899e-01, 3.3262e-03, 7.0331e-01, 9.5744e-03,
        7.4175e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:45,173][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.2596, 0.3688, 0.1330, 0.0954, 0.0411, 0.0257, 0.0765],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:45,174][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0781, 0.5476, 0.0600, 0.0268, 0.1967, 0.0466, 0.0442],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:45,176][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0247, 0.0373, 0.0124, 0.0818, 0.0125, 0.0656, 0.7657],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:45,177][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([7.6184e-01, 3.0158e-04, 3.9998e-05, 1.4871e-03, 1.0283e-03, 1.7602e-01,
        5.9283e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:45,178][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0013, 0.0388, 0.1977, 0.0396, 0.0606, 0.1329, 0.5293],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:45,179][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0294, 0.4787, 0.1321, 0.0176, 0.2951, 0.0190, 0.0280],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:45,181][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0496, 0.2571, 0.1447, 0.0066, 0.4892, 0.0385, 0.0144],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:45,182][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([8.6512e-01, 1.4734e-03, 9.7453e-05, 8.0149e-04, 1.9591e-03, 5.1572e-02,
        7.8979e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:45,183][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([2.0202e-02, 2.0539e-01, 7.3673e-01, 6.2879e-04, 3.6316e-02, 3.9547e-04,
        3.4401e-04], device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:45,184][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.3384, 0.0187, 0.3090, 0.0116, 0.2754, 0.0370, 0.0098],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:45,186][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ lot] are: tensor([0.0016, 0.0016, 0.1232, 0.0491, 0.1247, 0.0495, 0.1780, 0.4724],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:45,187][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ lot] are: tensor([1.8554e-05, 1.0337e-03, 1.0665e-01, 8.9426e-03, 5.7461e-01, 7.9086e-03,
        2.9087e-01, 9.9570e-03], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:45,187][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ lot] are: tensor([0.0699, 0.1589, 0.0780, 0.1858, 0.0244, 0.0906, 0.3008, 0.0916],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:45,187][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ lot] are: tensor([0.0066, 0.0708, 0.0897, 0.0383, 0.3046, 0.1113, 0.0611, 0.3176],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:45,188][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ lot] are: tensor([0.0387, 0.0149, 0.0039, 0.0420, 0.0118, 0.0726, 0.8099, 0.0061],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:45,188][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ lot] are: tensor([3.8573e-02, 1.3324e-03, 1.9813e-04, 5.2677e-03, 1.6862e-03, 1.4778e-01,
        5.6991e-01, 2.3525e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:45,189][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ lot] are: tensor([2.3922e-04, 3.1633e-03, 1.0111e-01, 2.3621e-02, 4.6126e-02, 8.9373e-02,
        2.8509e-01, 4.5128e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:45,189][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ lot] are: tensor([0.0020, 0.1227, 0.1139, 0.0277, 0.6140, 0.0184, 0.0323, 0.0688],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:45,189][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ lot] are: tensor([0.0105, 0.0920, 0.1032, 0.0132, 0.3161, 0.1104, 0.0394, 0.3151],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:45,190][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ lot] are: tensor([2.6646e-02, 1.0546e-03, 9.3071e-05, 1.0765e-03, 1.0925e-03, 5.1709e-02,
        8.0101e-01, 1.1732e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:45,191][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ lot] are: tensor([0.0095, 0.1121, 0.8237, 0.0014, 0.0485, 0.0015, 0.0010, 0.0023],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:45,193][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ lot] are: tensor([0.0120, 0.0181, 0.1888, 0.0383, 0.1112, 0.2870, 0.1791, 0.1655],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:45,194][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([0.0005, 0.0019, 0.2732, 0.0239, 0.0527, 0.0397, 0.2303, 0.1858, 0.1920],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:45,195][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([1.6979e-05, 3.0563e-04, 2.4286e-01, 2.5729e-03, 6.9678e-01, 5.6832e-03,
        3.1145e-02, 1.5732e-02, 4.9004e-03], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:45,196][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([0.2296, 0.3284, 0.1476, 0.0535, 0.0182, 0.0315, 0.0507, 0.1179, 0.0228],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:45,198][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([0.0229, 0.2346, 0.1304, 0.0145, 0.2318, 0.0346, 0.0235, 0.2944, 0.0132],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:45,199][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([0.0139, 0.0446, 0.0174, 0.0823, 0.0203, 0.0592, 0.2036, 0.0160, 0.5428],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:45,200][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([8.8232e-01, 6.2811e-05, 4.5520e-06, 2.4859e-05, 4.4167e-05, 1.9808e-02,
        2.9278e-03, 4.4126e-02, 5.0686e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:45,201][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([0.0003, 0.0055, 0.1536, 0.0089, 0.0260, 0.0474, 0.1971, 0.2575, 0.3036],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:45,203][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([0.0151, 0.3593, 0.1905, 0.0078, 0.3650, 0.0121, 0.0122, 0.0144, 0.0235],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:45,204][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([0.0157, 0.1660, 0.1018, 0.0040, 0.3806, 0.0276, 0.0067, 0.2767, 0.0210],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:45,205][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([8.0350e-01, 4.5776e-04, 1.2403e-05, 3.4000e-05, 1.0059e-04, 1.0644e-02,
        1.8707e-02, 2.2135e-02, 1.4441e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:45,206][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([9.9071e-03, 7.4020e-02, 8.9920e-01, 3.0331e-04, 1.5169e-02, 2.8288e-04,
        1.6393e-04, 9.4453e-04, 1.3421e-05], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:45,208][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([0.3359, 0.0214, 0.3315, 0.0056, 0.2108, 0.0128, 0.0011, 0.0725, 0.0084],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:45,209][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ fun] are: tensor([0.0012, 0.0009, 0.1022, 0.0240, 0.0517, 0.0613, 0.2228, 0.3333, 0.1509,
        0.0517], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:45,210][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ fun] are: tensor([1.5509e-05, 1.3104e-04, 7.1158e-02, 6.9265e-03, 8.0385e-01, 1.0070e-02,
        8.1959e-02, 8.7210e-03, 6.4548e-03, 1.0715e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:45,211][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ fun] are: tensor([0.0349, 0.0608, 0.0625, 0.0978, 0.0081, 0.0592, 0.2548, 0.1021, 0.0832,
        0.2367], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:45,213][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ fun] are: tensor([0.0082, 0.0971, 0.0739, 0.0267, 0.2359, 0.0750, 0.0597, 0.3968, 0.0110,
        0.0156], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:45,214][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ fun] are: tensor([0.0086, 0.0173, 0.0056, 0.0423, 0.0172, 0.0457, 0.3661, 0.0107, 0.4794,
        0.0072], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:45,215][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ fun] are: tensor([2.4776e-02, 4.2491e-04, 2.1873e-05, 6.0810e-04, 2.9308e-04, 4.4589e-02,
        6.7513e-02, 1.1181e-01, 6.3026e-01, 1.1970e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:45,217][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ fun] are: tensor([0.0006, 0.0025, 0.0325, 0.0209, 0.0151, 0.0446, 0.1840, 0.4060, 0.2171,
        0.0768], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:45,218][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ fun] are: tensor([0.0051, 0.1158, 0.1637, 0.0268, 0.4311, 0.0374, 0.0367, 0.0232, 0.0138,
        0.1464], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:45,220][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ fun] are: tensor([0.0263, 0.0807, 0.0232, 0.0044, 0.0429, 0.0319, 0.0108, 0.0475, 0.0236,
        0.7088], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:45,220][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ fun] are: tensor([5.9422e-03, 1.9137e-04, 2.1001e-05, 1.4264e-04, 8.6836e-05, 8.0713e-03,
        8.5243e-02, 2.4015e-01, 5.0571e-01, 1.5444e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:45,221][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ fun] are: tensor([9.3770e-03, 4.0267e-02, 7.0803e-01, 1.8083e-03, 3.1161e-02, 1.3479e-03,
        1.0191e-03, 2.7305e-03, 7.7150e-05, 2.0418e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:45,223][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ fun] are: tensor([0.0080, 0.0029, 0.3473, 0.0186, 0.2246, 0.0685, 0.0567, 0.0954, 0.1566,
        0.0214], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:45,224][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.0011, 0.0017, 0.2072, 0.0172, 0.0913, 0.0537, 0.1385, 0.2816, 0.1354,
        0.0627, 0.0096], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:45,225][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([8.5250e-06, 2.7014e-04, 7.4301e-02, 3.3097e-03, 8.1563e-01, 1.2182e-02,
        5.0815e-02, 1.5234e-02, 3.1257e-03, 2.0229e-02, 4.8916e-03],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:45,227][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.1162, 0.1918, 0.0721, 0.0569, 0.0228, 0.0660, 0.0716, 0.1585, 0.0185,
        0.1445, 0.0809], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:45,228][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.0232, 0.2180, 0.0751, 0.0202, 0.2546, 0.0415, 0.0386, 0.2822, 0.0160,
        0.0222, 0.0085], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:45,229][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.0213, 0.0497, 0.0111, 0.0562, 0.0212, 0.0475, 0.1795, 0.0144, 0.3812,
        0.0130, 0.2049], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:45,230][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([2.2078e-01, 6.2215e-04, 4.9914e-05, 2.2208e-04, 4.1832e-04, 3.8110e-02,
        2.2318e-02, 1.1671e-01, 1.8605e-01, 2.0342e-01, 2.1130e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:45,232][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.0005, 0.0044, 0.0394, 0.0112, 0.0129, 0.0419, 0.2039, 0.3153, 0.2727,
        0.0830, 0.0147], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:45,233][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.0055, 0.2000, 0.0885, 0.0124, 0.5687, 0.0160, 0.0189, 0.0094, 0.0185,
        0.0365, 0.0255], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:45,235][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.0082, 0.2414, 0.0482, 0.0046, 0.1139, 0.0277, 0.0126, 0.1671, 0.0192,
        0.3358, 0.0213], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:45,236][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([2.3225e-01, 1.0352e-03, 5.9279e-05, 5.0079e-05, 2.9678e-04, 9.9482e-03,
        3.5938e-02, 1.3770e-01, 1.1211e-01, 2.9667e-01, 1.7393e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:45,237][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([1.7833e-02, 1.1210e-01, 5.9776e-01, 7.2159e-04, 2.5927e-02, 9.3407e-04,
        3.3851e-04, 2.7342e-03, 3.2182e-05, 2.4142e-01, 1.9712e-04],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:45,238][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.1980, 0.0182, 0.2064, 0.0053, 0.3777, 0.0113, 0.0010, 0.1034, 0.0034,
        0.0357, 0.0395], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:45,239][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0005, 0.0024, 0.4726, 0.0211, 0.0644, 0.0487, 0.0995, 0.1065, 0.0793,
        0.0725, 0.0064, 0.0260], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:45,240][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([3.2522e-06, 2.1361e-04, 2.2443e-01, 3.4045e-03, 6.6417e-01, 4.0976e-03,
        4.3983e-02, 1.1830e-02, 3.3719e-03, 2.4101e-02, 5.5617e-03, 1.4838e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:45,242][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0644, 0.1368, 0.1052, 0.0751, 0.0135, 0.0320, 0.0702, 0.1693, 0.0201,
        0.2087, 0.0480, 0.0569], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:45,243][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0147, 0.1386, 0.0767, 0.0227, 0.1668, 0.0335, 0.0425, 0.4155, 0.0126,
        0.0296, 0.0085, 0.0384], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:45,244][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0127, 0.0117, 0.0054, 0.0451, 0.0042, 0.0168, 0.1563, 0.0084, 0.2802,
        0.0080, 0.1859, 0.2654], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:45,245][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([5.3030e-01, 4.9182e-04, 1.3663e-05, 1.9686e-04, 1.5335e-04, 4.0341e-02,
        6.8053e-03, 4.8730e-02, 7.7364e-02, 4.2673e-02, 7.0802e-02, 1.8213e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:45,245][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([2.2866e-04, 4.8150e-03, 1.6918e-01, 1.0150e-02, 2.1892e-02, 5.1125e-02,
        2.1662e-01, 1.5953e-01, 2.3588e-01, 9.3187e-02, 1.1761e-02, 2.5624e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:45,246][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0101, 0.2335, 0.1583, 0.0138, 0.3788, 0.0140, 0.0168, 0.0115, 0.0129,
        0.0539, 0.0174, 0.0790], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:45,246][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0022, 0.0589, 0.0197, 0.0024, 0.0685, 0.0104, 0.0058, 0.1524, 0.0138,
        0.6081, 0.0333, 0.0244], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:45,246][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([4.1708e-01, 1.7568e-03, 3.9174e-05, 9.3946e-05, 1.8350e-04, 7.4485e-03,
        1.8210e-02, 8.0937e-02, 1.3281e-01, 8.1980e-02, 1.4964e-01, 1.0982e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:45,247][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([2.5857e-03, 3.9240e-02, 8.3845e-01, 2.3506e-04, 1.5180e-02, 1.2575e-04,
        9.3990e-05, 5.5899e-04, 6.2803e-06, 1.0326e-01, 3.8400e-05, 2.2737e-04],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:45,248][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.1071, 0.0047, 0.2886, 0.0080, 0.2712, 0.0333, 0.0030, 0.1491, 0.0229,
        0.0144, 0.0886, 0.0090], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:45,250][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ hospital] are: tensor([0.0026, 0.0050, 0.3078, 0.0395, 0.0924, 0.0478, 0.0913, 0.1437, 0.0553,
        0.0213, 0.0135, 0.0199, 0.1600], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:45,250][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ hospital] are: tensor([3.8061e-05, 8.2805e-04, 1.7906e-01, 1.3610e-02, 3.9557e-01, 1.3907e-02,
        8.5448e-02, 5.6696e-03, 6.5996e-03, 1.5391e-02, 1.9685e-02, 9.5230e-03,
        2.5468e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:45,252][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ hospital] are: tensor([0.0862, 0.2620, 0.0704, 0.0987, 0.0080, 0.0691, 0.1036, 0.0532, 0.0182,
        0.0871, 0.0535, 0.0276, 0.0622], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:45,253][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ hospital] are: tensor([0.0386, 0.2783, 0.0918, 0.0256, 0.1352, 0.0487, 0.0401, 0.2303, 0.0116,
        0.0194, 0.0326, 0.0263, 0.0214], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:45,255][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ hospital] are: tensor([0.0400, 0.0474, 0.0078, 0.0397, 0.0125, 0.0444, 0.2205, 0.0030, 0.2380,
        0.0059, 0.0811, 0.1845, 0.0752], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:45,256][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ hospital] are: tensor([3.2987e-02, 2.4077e-04, 2.9810e-06, 5.9457e-05, 1.9805e-05, 2.4812e-03,
        1.0361e-02, 3.9335e-03, 2.1967e-02, 5.6084e-03, 2.4934e-02, 1.0830e-01,
        7.8910e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:45,257][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ hospital] are: tensor([0.0012, 0.0078, 0.1640, 0.0194, 0.0189, 0.0471, 0.2192, 0.1639, 0.1424,
        0.0471, 0.0137, 0.0211, 0.1343], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:45,259][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ hospital] are: tensor([0.0053, 0.1624, 0.1610, 0.0137, 0.3245, 0.0164, 0.0151, 0.0048, 0.0061,
        0.0234, 0.0179, 0.0367, 0.2127], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:45,260][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ hospital] are: tensor([0.0580, 0.1947, 0.0300, 0.0060, 0.0291, 0.0313, 0.0113, 0.0317, 0.0215,
        0.2658, 0.0487, 0.0301, 0.2417], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:45,261][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ hospital] are: tensor([7.5496e-02, 1.2222e-04, 1.9199e-06, 1.5216e-05, 6.3851e-06, 3.0113e-04,
        2.9332e-03, 5.2662e-03, 6.7114e-03, 4.4486e-03, 1.1896e-02, 1.9911e-02,
        8.7289e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:45,262][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ hospital] are: tensor([1.9707e-02, 9.6511e-02, 6.8764e-01, 2.0923e-03, 2.5509e-02, 8.5928e-04,
        1.0992e-03, 1.4438e-03, 3.7616e-05, 1.2801e-01, 2.6195e-04, 6.3616e-04,
        3.6194e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:45,264][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ hospital] are: tensor([0.0170, 0.0183, 0.2687, 0.0609, 0.1729, 0.0485, 0.0274, 0.0741, 0.0902,
        0.0186, 0.1551, 0.0213, 0.0269], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:45,265][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.0017, 0.0020, 0.1956, 0.0208, 0.0448, 0.0515, 0.1322, 0.1024, 0.0629,
        0.0401, 0.0096, 0.0238, 0.2913, 0.0213], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:45,266][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([8.7787e-06, 2.1015e-04, 1.2464e-01, 2.4682e-03, 3.9457e-01, 4.4363e-03,
        3.2387e-02, 7.2747e-03, 2.8704e-03, 1.8577e-02, 7.3499e-03, 5.9716e-03,
        3.9670e-01, 2.5344e-03], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:45,268][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.2001, 0.1344, 0.0957, 0.0450, 0.0082, 0.0392, 0.0687, 0.0629, 0.0136,
        0.0926, 0.0511, 0.0296, 0.0783, 0.0806], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:45,269][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.0330, 0.1919, 0.0957, 0.0154, 0.2933, 0.0525, 0.0172, 0.1902, 0.0080,
        0.0310, 0.0095, 0.0133, 0.0155, 0.0336], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:45,271][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.0555, 0.0849, 0.0148, 0.0286, 0.0143, 0.0308, 0.1760, 0.0114, 0.1649,
        0.0129, 0.0909, 0.1486, 0.1253, 0.0411], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:45,272][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([1.5082e-01, 3.0356e-04, 8.4720e-06, 6.9701e-05, 5.3362e-05, 4.6591e-03,
        3.3524e-03, 3.9257e-03, 6.0902e-03, 8.6090e-03, 8.9499e-03, 3.3467e-02,
        4.8849e-01, 2.9120e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:45,273][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.0005, 0.0114, 0.0902, 0.0101, 0.0305, 0.0537, 0.1546, 0.3199, 0.1281,
        0.0808, 0.0135, 0.0159, 0.0840, 0.0068], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:45,275][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0229, 0.2325, 0.1027, 0.0067, 0.2472, 0.0153, 0.0137, 0.0071, 0.0074,
        0.0293, 0.0157, 0.0300, 0.1840, 0.0853], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:45,276][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.0138, 0.0475, 0.0296, 0.0015, 0.0679, 0.0156, 0.0054, 0.0447, 0.0085,
        0.2962, 0.0233, 0.0177, 0.3635, 0.0649], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:45,277][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([5.9387e-01, 6.7283e-05, 2.3358e-06, 1.8126e-06, 1.1177e-05, 1.7107e-04,
        3.7109e-04, 6.2551e-04, 2.9172e-04, 9.5296e-04, 8.2292e-04, 7.9183e-04,
        2.2969e-01, 1.7233e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:45,278][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([8.3292e-03, 8.6871e-02, 7.3692e-01, 4.8693e-04, 2.0137e-02, 4.6902e-04,
        2.8252e-04, 8.5730e-04, 1.2809e-05, 1.0297e-01, 7.6823e-05, 2.7341e-04,
        3.7354e-02, 4.9566e-03], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:45,279][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.2893, 0.0156, 0.2528, 0.0028, 0.2877, 0.0107, 0.0003, 0.0778, 0.0014,
        0.0088, 0.0051, 0.0007, 0.0386, 0.0085], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:45,281][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Anthony] are: tensor([0.0019, 0.0036, 0.1376, 0.0138, 0.0176, 0.0217, 0.0282, 0.0503, 0.0246,
        0.0168, 0.0039, 0.0136, 0.1940, 0.0150, 0.4574], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:45,282][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Anthony] are: tensor([2.9390e-05, 1.6165e-04, 7.9451e-02, 2.4343e-03, 1.6766e-01, 3.8693e-03,
        2.0753e-02, 5.8642e-03, 3.2873e-03, 1.7097e-02, 1.1401e-02, 6.7454e-03,
        2.5337e-01, 3.2047e-03, 4.2468e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:45,283][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Anthony] are: tensor([0.2951, 0.0942, 0.0647, 0.0387, 0.0051, 0.0293, 0.0566, 0.0511, 0.0150,
        0.1209, 0.0228, 0.0306, 0.0769, 0.0745, 0.0246], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:45,285][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Anthony] are: tensor([0.0415, 0.2623, 0.1124, 0.0162, 0.0745, 0.0365, 0.0127, 0.2218, 0.0177,
        0.0325, 0.0143, 0.0281, 0.0247, 0.0339, 0.0709], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:45,286][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Anthony] are: tensor([0.0518, 0.0422, 0.0211, 0.0267, 0.0200, 0.0327, 0.1261, 0.0148, 0.2360,
        0.0118, 0.0875, 0.1179, 0.0918, 0.0487, 0.0709], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:45,287][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Anthony] are: tensor([1.1228e-02, 2.3658e-05, 4.1345e-07, 2.1230e-06, 2.4903e-06, 2.4134e-04,
        2.3710e-04, 7.2590e-04, 1.9219e-03, 1.6561e-03, 3.8795e-03, 1.4253e-02,
        2.2914e-01, 1.6490e-01, 5.7178e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:45,289][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Anthony] are: tensor([0.0005, 0.0037, 0.0657, 0.0075, 0.0052, 0.0307, 0.0807, 0.1258, 0.2525,
        0.0476, 0.0150, 0.0183, 0.0855, 0.0038, 0.2576], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:45,290][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Anthony] are: tensor([0.0049, 0.1990, 0.1581, 0.0060, 0.1363, 0.0083, 0.0047, 0.0020, 0.0050,
        0.0214, 0.0080, 0.0195, 0.3019, 0.0385, 0.0864], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:45,292][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Anthony] are: tensor([0.0118, 0.0531, 0.0245, 0.0027, 0.0608, 0.0185, 0.0049, 0.0398, 0.0131,
        0.3808, 0.0267, 0.0253, 0.1828, 0.0705, 0.0846], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:45,292][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Anthony] are: tensor([5.3927e-02, 2.0949e-05, 2.4884e-07, 2.0504e-07, 9.8021e-07, 2.0470e-05,
        7.4404e-05, 4.5252e-04, 6.8939e-04, 9.1582e-04, 1.1257e-03, 2.3051e-03,
        2.2690e-01, 4.5090e-01, 2.6267e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:45,293][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Anthony] are: tensor([3.5806e-02, 6.9282e-02, 6.7972e-01, 6.8689e-04, 1.1380e-02, 7.3088e-04,
        3.2945e-04, 7.3835e-04, 2.2393e-05, 1.2185e-01, 1.2774e-04, 4.5246e-04,
        3.4657e-02, 9.4901e-03, 3.4731e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:45,295][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Anthony] are: tensor([0.0579, 0.0198, 0.3106, 0.0144, 0.1012, 0.0160, 0.0057, 0.0473, 0.0138,
        0.0227, 0.0177, 0.0116, 0.0500, 0.0154, 0.2958], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:45,296][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([2.2154e-04, 1.1203e-03, 1.4178e-01, 1.2543e-02, 6.6729e-02, 3.0130e-02,
        4.6333e-02, 3.4943e-02, 2.1084e-02, 3.4292e-02, 3.2298e-03, 9.3703e-03,
        3.9109e-02, 1.0928e-02, 5.3284e-01, 1.5354e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:45,297][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([1.0504e-06, 1.9565e-04, 4.1414e-02, 3.1341e-03, 3.1879e-01, 3.4135e-03,
        2.5535e-02, 6.9591e-03, 7.1350e-03, 1.6281e-02, 1.8018e-02, 6.1810e-03,
        1.4929e-01, 2.8671e-03, 3.9659e-01, 4.1949e-03], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:45,298][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.0484, 0.0596, 0.1144, 0.0623, 0.0060, 0.0380, 0.0890, 0.0702, 0.0190,
        0.1538, 0.0709, 0.0282, 0.0479, 0.0572, 0.0621, 0.0731],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:45,300][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.0055, 0.0665, 0.1659, 0.0227, 0.2546, 0.0493, 0.0638, 0.1272, 0.0136,
        0.0210, 0.0202, 0.0175, 0.0077, 0.0129, 0.1076, 0.0441],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:45,301][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.0153, 0.0169, 0.0099, 0.0463, 0.0203, 0.0375, 0.1157, 0.0070, 0.2515,
        0.0059, 0.1019, 0.0855, 0.0904, 0.0659, 0.1062, 0.0238],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:45,302][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([2.3023e-03, 2.8545e-05, 1.1652e-06, 6.9700e-06, 3.8544e-06, 5.9212e-04,
        1.6149e-03, 9.6135e-04, 4.6044e-03, 3.2458e-03, 3.6582e-03, 2.0182e-02,
        2.3202e-01, 1.0568e-01, 5.6500e-01, 6.0103e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:45,302][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([1.5625e-04, 2.2576e-03, 8.7347e-02, 6.3412e-03, 1.9433e-02, 2.9402e-02,
        8.3380e-02, 1.7929e-01, 7.1172e-02, 7.2003e-02, 1.2232e-02, 8.0869e-03,
        2.5768e-02, 2.1303e-03, 3.9992e-01, 1.0765e-03], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:45,302][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0008, 0.0436, 0.0712, 0.0066, 0.2571, 0.0095, 0.0102, 0.0047, 0.0042,
        0.0311, 0.0117, 0.0145, 0.0679, 0.0233, 0.0379, 0.4057],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:45,303][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.0011, 0.0153, 0.0274, 0.0025, 0.0264, 0.0090, 0.0078, 0.0172, 0.0397,
        0.1456, 0.0476, 0.0253, 0.1156, 0.0550, 0.1999, 0.2645],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:45,303][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([3.2108e-03, 6.2479e-06, 2.0153e-07, 6.9430e-07, 9.5730e-07, 1.9449e-05,
        2.7129e-04, 3.5064e-04, 6.1886e-04, 7.1668e-04, 1.0286e-03, 1.6088e-03,
        1.1887e-01, 1.5836e-01, 5.1961e-01, 1.9532e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:45,304][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([1.0917e-03, 2.2126e-02, 7.4056e-01, 8.4049e-04, 1.7596e-02, 6.9922e-04,
        4.8627e-04, 6.7585e-04, 4.0418e-05, 7.8433e-02, 2.0926e-04, 4.6917e-04,
        2.1198e-02, 4.0214e-03, 6.1344e-02, 5.0206e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:45,304][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.1157, 0.0072, 0.2949, 0.0048, 0.1708, 0.0346, 0.0013, 0.0676, 0.0093,
        0.0175, 0.0459, 0.0025, 0.0143, 0.0054, 0.1436, 0.0645],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:45,304][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0010, 0.0023, 0.1772, 0.0153, 0.0247, 0.0252, 0.0403, 0.0651, 0.0270,
        0.0332, 0.0052, 0.0137, 0.1497, 0.0162, 0.3375, 0.0380, 0.0283],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:45,305][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([9.3145e-06, 1.5821e-04, 7.5115e-02, 1.8096e-03, 2.1915e-01, 3.4934e-03,
        3.0700e-02, 8.3593e-03, 4.0928e-03, 8.4915e-03, 7.4076e-03, 1.0187e-02,
        2.8374e-01, 1.9682e-03, 2.6228e-01, 5.6493e-03, 7.7388e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:45,306][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.1028, 0.0879, 0.0735, 0.0473, 0.0099, 0.0163, 0.0393, 0.0694, 0.0104,
        0.1337, 0.0298, 0.0315, 0.0744, 0.0846, 0.0323, 0.1144, 0.0424],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:45,307][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0338, 0.1157, 0.0381, 0.0154, 0.0588, 0.0243, 0.0279, 0.2694, 0.0167,
        0.0273, 0.0121, 0.0281, 0.0277, 0.0337, 0.0435, 0.1527, 0.0748],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:45,308][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0333, 0.0196, 0.0044, 0.0234, 0.0029, 0.0166, 0.0891, 0.0154, 0.2745,
        0.0087, 0.1472, 0.1642, 0.0655, 0.0343, 0.0142, 0.0296, 0.0570],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:45,309][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([1.3791e-01, 6.9932e-05, 1.4379e-06, 1.3297e-05, 4.4695e-06, 7.3040e-04,
        2.2762e-04, 1.6221e-03, 2.5216e-03, 1.7979e-03, 3.2385e-03, 6.9365e-03,
        1.8519e-01, 1.2437e-01, 1.8083e-01, 1.8936e-01, 1.6519e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:45,311][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0010, 0.0048, 0.1198, 0.0054, 0.0114, 0.0353, 0.0815, 0.1781, 0.1299,
        0.0855, 0.0142, 0.0214, 0.0603, 0.0023, 0.2184, 0.0028, 0.0281],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:45,312][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0112, 0.1044, 0.0623, 0.0053, 0.1190, 0.0063, 0.0075, 0.0105, 0.0059,
        0.0387, 0.0099, 0.0299, 0.1898, 0.0457, 0.0462, 0.2528, 0.0545],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:45,313][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0038, 0.0176, 0.0134, 0.0014, 0.0403, 0.0042, 0.0020, 0.0771, 0.0060,
        0.2295, 0.0108, 0.0153, 0.1432, 0.0468, 0.0542, 0.3115, 0.0228],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:45,314][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([6.4281e-02, 6.0024e-05, 8.6646e-07, 5.5803e-07, 1.5132e-06, 3.1593e-05,
        2.7633e-05, 5.4959e-04, 2.4464e-04, 2.5236e-04, 4.9709e-04, 3.1559e-04,
        1.0870e-01, 1.3274e-01, 1.6039e-01, 5.0416e-01, 2.7747e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:45,315][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([6.9951e-03, 7.5978e-02, 5.4309e-01, 5.8056e-04, 1.7067e-02, 3.2588e-04,
        1.9338e-04, 9.1284e-04, 1.4002e-05, 1.1622e-01, 8.6988e-05, 4.3008e-04,
        3.6462e-02, 7.1579e-03, 2.7026e-02, 1.5372e-01, 1.3730e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:45,317][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.1767, 0.0032, 0.1611, 0.0025, 0.1541, 0.0095, 0.0015, 0.1232, 0.0036,
        0.0106, 0.0136, 0.0020, 0.0344, 0.0067, 0.2355, 0.0503, 0.0115],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:45,318][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ drink] are: tensor([0.0008, 0.0010, 0.2223, 0.0052, 0.0240, 0.0079, 0.0282, 0.0772, 0.0169,
        0.0186, 0.0032, 0.0044, 0.0634, 0.0043, 0.4609, 0.0216, 0.0198, 0.0203],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:45,319][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ drink] are: tensor([6.3427e-06, 2.6631e-04, 1.1075e-01, 5.5278e-03, 2.9562e-01, 2.3206e-03,
        2.7628e-02, 6.0683e-03, 6.8149e-03, 6.4636e-03, 1.3052e-02, 7.5697e-03,
        9.5089e-02, 1.7816e-03, 3.5899e-01, 1.7037e-03, 3.2389e-02, 2.7964e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:45,320][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ drink] are: tensor([0.0424, 0.0321, 0.1377, 0.0878, 0.0058, 0.0225, 0.1356, 0.0602, 0.0154,
        0.1644, 0.0434, 0.0313, 0.0270, 0.0403, 0.0399, 0.0333, 0.0623, 0.0184],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:45,322][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ drink] are: tensor([0.0142, 0.0553, 0.1434, 0.0154, 0.2176, 0.0252, 0.0333, 0.1594, 0.0089,
        0.0232, 0.0254, 0.0114, 0.0078, 0.0164, 0.0770, 0.0605, 0.0654, 0.0404],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:45,323][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ drink] are: tensor([0.0179, 0.0109, 0.0056, 0.0116, 0.0038, 0.0115, 0.0731, 0.0162, 0.2836,
        0.0092, 0.0691, 0.0828, 0.0883, 0.0611, 0.0650, 0.0299, 0.0892, 0.0713],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:45,324][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ drink] are: tensor([3.8664e-03, 2.3199e-05, 7.7503e-07, 6.0085e-06, 3.8950e-06, 2.8291e-04,
        6.9958e-04, 6.7073e-04, 2.3658e-03, 1.1389e-03, 3.3496e-03, 1.5488e-02,
        8.7301e-02, 6.5181e-02, 3.1237e-01, 6.2113e-02, 3.0635e-01, 1.3879e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:45,325][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ drink] are: tensor([3.0328e-04, 2.8886e-03, 9.0318e-02, 8.8436e-03, 1.3102e-02, 1.6828e-02,
        6.1339e-02, 3.1454e-01, 1.0618e-01, 5.2977e-02, 4.9415e-03, 4.2832e-03,
        4.3368e-02, 1.3084e-03, 2.3348e-01, 6.5615e-04, 1.3655e-02, 3.0975e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:45,327][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ drink] are: tensor([0.0019, 0.0522, 0.0837, 0.0061, 0.1229, 0.0089, 0.0066, 0.0103, 0.0031,
        0.0485, 0.0165, 0.0123, 0.1355, 0.0255, 0.0407, 0.1908, 0.0301, 0.2044],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:45,328][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ drink] are: tensor([0.0036, 0.0274, 0.0263, 0.0038, 0.0284, 0.0126, 0.0060, 0.0189, 0.0095,
        0.1471, 0.0384, 0.0192, 0.0625, 0.0412, 0.0615, 0.1977, 0.0364, 0.2596],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:45,329][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ drink] are: tensor([3.0505e-03, 8.7099e-06, 1.9738e-07, 6.7725e-07, 5.3127e-07, 1.1135e-05,
        1.7483e-04, 4.4918e-04, 7.0177e-04, 5.1850e-04, 1.1185e-03, 2.1704e-03,
        7.5616e-02, 2.5808e-01, 1.3388e-01, 1.5104e-01, 2.2613e-01, 1.4705e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:45,330][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ drink] are: tensor([4.8455e-03, 3.3866e-02, 4.2410e-01, 9.4936e-04, 1.6501e-02, 2.6474e-04,
        4.6840e-04, 1.2588e-03, 2.2989e-05, 7.7327e-02, 1.8543e-04, 2.8245e-04,
        1.4648e-02, 2.8570e-03, 1.8704e-02, 6.1828e-02, 1.1020e-02, 3.3088e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:45,332][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ drink] are: tensor([0.0110, 0.0043, 0.4224, 0.0123, 0.0851, 0.0080, 0.0060, 0.0356, 0.0110,
        0.0159, 0.0200, 0.0048, 0.0101, 0.0060, 0.2117, 0.0164, 0.0183, 0.1011],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:45,333][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0013, 0.0013, 0.1176, 0.0107, 0.0207, 0.0213, 0.0749, 0.0588, 0.0317,
        0.0206, 0.0036, 0.0134, 0.1093, 0.0127, 0.4113, 0.0211, 0.0356, 0.0137,
        0.0203], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:45,334][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([2.2021e-05, 1.6811e-04, 8.6268e-02, 1.1887e-03, 1.9981e-01, 3.8161e-03,
        2.4080e-02, 7.5297e-03, 3.5474e-03, 1.0326e-02, 6.2786e-03, 5.6629e-03,
        2.5653e-01, 1.9950e-03, 2.8568e-01, 5.7059e-03, 3.5001e-02, 6.3117e-02,
        3.2766e-03], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:45,335][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.2344, 0.0523, 0.0566, 0.0165, 0.0054, 0.0244, 0.0404, 0.0469, 0.0081,
        0.0982, 0.0320, 0.0234, 0.0572, 0.0373, 0.0285, 0.1316, 0.0450, 0.0325,
        0.0292], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:45,337][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0344, 0.0721, 0.0875, 0.0094, 0.0799, 0.0267, 0.0228, 0.1817, 0.0108,
        0.0299, 0.0105, 0.0154, 0.0167, 0.0252, 0.0737, 0.1619, 0.0666, 0.0665,
        0.0084], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:45,338][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0327, 0.0488, 0.0159, 0.0367, 0.0090, 0.0201, 0.0858, 0.0099, 0.1915,
        0.0060, 0.0738, 0.1092, 0.0987, 0.0440, 0.0360, 0.0406, 0.0568, 0.0482,
        0.0365], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:45,339][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([8.8059e-02, 6.8059e-05, 2.5219e-06, 2.3417e-06, 4.9332e-06, 4.4093e-04,
        1.9779e-04, 1.0945e-03, 7.8317e-04, 1.8306e-03, 8.6286e-04, 5.4640e-03,
        1.6934e-01, 5.7445e-02, 2.9594e-01, 5.2730e-02, 9.5066e-02, 1.6444e-01,
        6.6231e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:45,341][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0011, 0.0044, 0.0871, 0.0041, 0.0073, 0.0363, 0.1055, 0.2420, 0.1405,
        0.0517, 0.0143, 0.0135, 0.0416, 0.0021, 0.1919, 0.0015, 0.0281, 0.0252,
        0.0018], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:45,342][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0219, 0.1401, 0.0658, 0.0040, 0.1225, 0.0079, 0.0064, 0.0054, 0.0065,
        0.0236, 0.0147, 0.0185, 0.1254, 0.0528, 0.0625, 0.2070, 0.0442, 0.0157,
        0.0551], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:45,344][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0052, 0.0240, 0.0192, 0.0014, 0.0321, 0.0065, 0.0025, 0.0318, 0.0052,
        0.0851, 0.0086, 0.0117, 0.0968, 0.0355, 0.0664, 0.1670, 0.0168, 0.3461,
        0.0380], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:45,345][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([2.4400e-01, 8.3969e-05, 4.0622e-07, 1.5275e-07, 1.1036e-06, 1.9755e-05,
        2.8385e-05, 1.3936e-04, 4.9971e-05, 2.2339e-04, 1.6919e-04, 2.4463e-04,
        9.5808e-02, 9.5429e-02, 1.4735e-01, 2.0993e-01, 2.9297e-02, 6.7031e-02,
        1.1020e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:45,346][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([1.2331e-02, 3.4046e-02, 3.4209e-01, 2.2199e-04, 1.0006e-02, 3.6704e-04,
        2.4868e-04, 6.6145e-04, 1.3255e-05, 9.4784e-02, 7.4321e-05, 2.2976e-04,
        2.3308e-02, 3.0869e-03, 2.2664e-02, 9.2992e-02, 9.4230e-03, 3.5095e-01,
        2.5106e-03], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:45,347][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([6.2465e-01, 5.6501e-03, 1.0902e-01, 3.2955e-04, 4.7436e-02, 1.0569e-03,
        7.4377e-05, 4.3428e-02, 1.7884e-04, 3.2702e-03, 9.8203e-04, 2.0508e-04,
        2.5643e-02, 1.5520e-03, 5.3020e-02, 1.0677e-02, 9.3302e-04, 7.0815e-02,
        1.0836e-03], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:45,348][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:21:45,350][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[1664],
        [   5],
        [  68],
        [  19],
        [ 169],
        [  27],
        [ 154],
        [  53],
        [  26],
        [ 120],
        [  86],
        [  66],
        [  35],
        [  46],
        [ 133],
        [ 187],
        [ 154],
        [  69],
        [   9]], device='cuda:0')
[2024-07-24 10:21:45,351][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[1215],
        [   5],
        [  44],
        [  18],
        [ 208],
        [  21],
        [ 121],
        [  54],
        [  23],
        [ 128],
        [  98],
        [  59],
        [  26],
        [  42],
        [  93],
        [ 131],
        [ 135],
        [  44],
        [   8]], device='cuda:0')
[2024-07-24 10:21:45,353][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[22649],
        [44560],
        [46723],
        [48165],
        [50248],
        [50246],
        [50226],
        [50245],
        [50182],
        [50099],
        [50128],
        [49984],
        [49730],
        [49552],
        [49418],
        [49996],
        [49587],
        [49851],
        [49705]], device='cuda:0')
[2024-07-24 10:21:45,355][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[23309],
        [ 5510],
        [27993],
        [27623],
        [21191],
        [19361],
        [18778],
        [13491],
        [19908],
        [17472],
        [17940],
        [18830],
        [11802],
        [10401],
        [10217],
        [11746],
        [ 9038],
        [12602],
        [ 8993]], device='cuda:0')
[2024-07-24 10:21:45,356][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[41557],
        [17783],
        [31600],
        [27792],
        [34315],
        [34574],
        [28158],
        [15704],
        [21544],
        [14297],
        [23137],
        [20091],
        [18633],
        [20886],
        [19149],
        [20657],
        [18102],
        [17768],
        [17362]], device='cuda:0')
[2024-07-24 10:21:45,357][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[ 5467],
        [38688],
        [40980],
        [40284],
        [47765],
        [47866],
        [45027],
        [44969],
        [45249],
        [43475],
        [45190],
        [41767],
        [41892],
        [45920],
        [40850],
        [44706],
        [35283],
        [43136],
        [36571]], device='cuda:0')
[2024-07-24 10:21:45,359][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[22459],
        [39026],
        [42686],
        [44393],
        [44508],
        [47655],
        [45623],
        [46001],
        [46887],
        [46609],
        [46568],
        [47349],
        [47554],
        [47702],
        [48276],
        [48357],
        [47704],
        [48735],
        [47908]], device='cuda:0')
[2024-07-24 10:21:45,360][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[23706],
        [14299],
        [13881],
        [12777],
        [11970],
        [16993],
        [15746],
        [13597],
        [12937],
        [12673],
        [13129],
        [13564],
        [13631],
        [17195],
        [16664],
        [17525],
        [17792],
        [18599],
        [18666]], device='cuda:0')
[2024-07-24 10:21:45,362][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[6341],
        [9871],
        [2791],
        [ 737],
        [4499],
        [2369],
        [ 912],
        [ 455],
        [ 318],
        [ 200],
        [ 163],
        [ 171],
        [ 144],
        [ 146],
        [ 167],
        [ 192],
        [ 174],
        [ 150],
        [ 149]], device='cuda:0')
[2024-07-24 10:21:45,363][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[23873],
        [ 1380],
        [ 4667],
        [ 1700],
        [    1],
        [    6],
        [   12],
        [    1],
        [    6],
        [    8],
        [    1],
        [    8],
        [   73],
        [  153],
        [ 2575],
        [  470],
        [ 5048],
        [ 6567],
        [ 2693]], device='cuda:0')
[2024-07-24 10:21:45,364][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[ 5181],
        [19808],
        [15203],
        [16087],
        [10572],
        [14315],
        [ 7226],
        [ 7551],
        [ 7506],
        [ 8745],
        [ 9217],
        [ 7614],
        [ 9230],
        [ 8639],
        [ 7683],
        [ 4290],
        [ 4736],
        [ 5057],
        [ 5941]], device='cuda:0')
[2024-07-24 10:21:45,365][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[32481],
        [36421],
        [46027],
        [33560],
        [27769],
        [34702],
        [36039],
        [36947],
        [38436],
        [36942],
        [35681],
        [39452],
        [44927],
        [41662],
        [35329],
        [30388],
        [26450],
        [27396],
        [29789]], device='cuda:0')
[2024-07-24 10:21:45,366][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[ 7693],
        [44381],
        [28282],
        [30299],
        [32049],
        [32863],
        [35919],
        [35319],
        [30418],
        [30284],
        [30766],
        [29030],
        [31052],
        [30267],
        [27962],
        [28230],
        [30610],
        [18851],
        [16584]], device='cuda:0')
[2024-07-24 10:21:45,368][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[18960],
        [37497],
        [45003],
        [43454],
        [45468],
        [44443],
        [45845],
        [40810],
        [45536],
        [44060],
        [44704],
        [44242],
        [43338],
        [45723],
        [44205],
        [44093],
        [43434],
        [44245],
        [42573]], device='cuda:0')
[2024-07-24 10:21:45,370][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[20508],
        [34685],
        [28884],
        [23478],
        [33684],
        [29579],
        [33983],
        [37440],
        [24206],
        [28266],
        [22054],
        [28003],
        [26882],
        [16333],
        [24287],
        [35127],
        [31686],
        [30468],
        [24382]], device='cuda:0')
[2024-07-24 10:21:45,371][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[ 6421],
        [22464],
        [30818],
        [30292],
        [32780],
        [33856],
        [30649],
        [34308],
        [32233],
        [32257],
        [33738],
        [32570],
        [36033],
        [35946],
        [34945],
        [32344],
        [34198],
        [33495],
        [32895]], device='cuda:0')
[2024-07-24 10:21:45,372][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[46461],
        [37494],
        [45129],
        [45114],
        [46517],
        [45756],
        [46025],
        [44938],
        [46159],
        [45331],
        [45382],
        [46006],
        [45892],
        [45938],
        [46845],
        [46694],
        [46559],
        [46736],
        [46760]], device='cuda:0')
[2024-07-24 10:21:45,374][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[42764],
        [31251],
        [30923],
        [30426],
        [29905],
        [22312],
        [26888],
        [26423],
        [30183],
        [30903],
        [30497],
        [32075],
        [28862],
        [31343],
        [32713],
        [32017],
        [33787],
        [31964],
        [34831]], device='cuda:0')
[2024-07-24 10:21:45,376][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[42515],
        [18053],
        [24039],
        [22509],
        [28710],
        [29102],
        [25351],
        [27600],
        [26358],
        [25336],
        [25843],
        [23695],
        [23874],
        [26722],
        [22268],
        [27662],
        [21021],
        [27689],
        [24294]], device='cuda:0')
[2024-07-24 10:21:45,377][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[17031],
        [31680],
        [25971],
        [28677],
        [27165],
        [27673],
        [30527],
        [30490],
        [29404],
        [29935],
        [30687],
        [29495],
        [30427],
        [31653],
        [30428],
        [30105],
        [30503],
        [30336],
        [30820]], device='cuda:0')
[2024-07-24 10:21:45,378][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[34615],
        [38611],
        [39386],
        [37616],
        [40410],
        [19952],
        [21330],
        [14878],
        [30205],
        [15690],
        [22958],
        [19211],
        [32477],
        [29779],
        [22451],
        [22641],
        [22487],
        [17038],
        [21165]], device='cuda:0')
[2024-07-24 10:21:45,380][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[ 8062],
        [22487],
        [23583],
        [24250],
        [25819],
        [22218],
        [21643],
        [12860],
        [16477],
        [12642],
        [14295],
        [17784],
        [16567],
        [13039],
        [22016],
        [23635],
        [20474],
        [17275],
        [18834]], device='cuda:0')
[2024-07-24 10:21:45,382][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[28499],
        [44350],
        [48565],
        [48396],
        [47379],
        [48594],
        [48253],
        [47583],
        [48513],
        [48100],
        [47783],
        [48513],
        [48487],
        [48145],
        [47945],
        [46179],
        [47715],
        [48109],
        [48055]], device='cuda:0')
[2024-07-24 10:21:45,383][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[27840],
        [24783],
        [17175],
        [18841],
        [17953],
        [19772],
        [15870],
        [10131],
        [11261],
        [15252],
        [12854],
        [14040],
        [10533],
        [ 9320],
        [10718],
        [ 8432],
        [ 8583],
        [10477],
        [10492]], device='cuda:0')
[2024-07-24 10:21:45,385][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[34984],
        [33099],
        [11037],
        [33517],
        [ 3671],
        [16511],
        [35524],
        [28530],
        [32053],
        [18645],
        [20898],
        [19537],
        [ 4964],
        [13461],
        [ 9276],
        [ 8480],
        [ 7463],
        [11953],
        [ 8936]], device='cuda:0')
[2024-07-24 10:21:45,386][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[40743],
        [47336],
        [38277],
        [39806],
        [39876],
        [39628],
        [41079],
        [40092],
        [38850],
        [40505],
        [41834],
        [39153],
        [40966],
        [40443],
        [40455],
        [39145],
        [40897],
        [45512],
        [45873]], device='cuda:0')
[2024-07-24 10:21:45,388][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[33712],
        [10161],
        [ 7656],
        [15814],
        [ 7934],
        [ 7840],
        [ 9615],
        [ 8991],
        [ 9686],
        [ 8204],
        [ 8788],
        [ 8272],
        [ 8188],
        [ 8701],
        [ 9261],
        [ 8422],
        [ 8623],
        [ 9193],
        [15401]], device='cuda:0')
[2024-07-24 10:21:45,389][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[2940],
        [4306],
        [4249],
        [1979],
        [4757],
        [4988],
        [3723],
        [7145],
        [4139],
        [7810],
        [5784],
        [5830],
        [5576],
        [4503],
        [4954],
        [6409],
        [6018],
        [6252],
        [3996]], device='cuda:0')
[2024-07-24 10:21:45,391][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[17302],
        [  809],
        [11812],
        [ 5684],
        [ 7281],
        [ 8719],
        [ 4401],
        [ 4707],
        [ 4954],
        [ 6149],
        [ 8453],
        [ 6239],
        [ 9652],
        [16572],
        [11754],
        [ 7773],
        [ 6754],
        [ 7095],
        [ 7806]], device='cuda:0')
[2024-07-24 10:21:45,392][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[14113],
        [14113],
        [14113],
        [14113],
        [14113],
        [14113],
        [14113],
        [14113],
        [14113],
        [14113],
        [14113],
        [14113],
        [14113],
        [14113],
        [14113],
        [14113],
        [14113],
        [14113],
        [14113]], device='cuda:0')
[2024-07-24 10:21:45,436][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:21:45,437][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:45,438][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:45,439][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:45,440][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:45,441][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:45,442][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:45,442][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:45,442][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:45,443][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:45,443][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:45,443][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:45,444][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:45,444][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0179, 0.9821], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:45,444][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.1085, 0.8915], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:45,445][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.1331, 0.8669], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:45,445][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.2280, 0.7720], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:45,445][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0051, 0.9949], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:45,446][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0612, 0.9388], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:45,446][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.7594, 0.2406], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:45,446][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0028, 0.9972], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:45,446][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.6335, 0.3665], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:45,447][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.9900, 0.0100], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:45,447][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.9134, 0.0866], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:45,447][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0029, 0.9971], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:45,448][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Anthony] are: tensor([0.0949, 0.8550, 0.0501], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:45,448][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Anthony] are: tensor([0.0072, 0.0102, 0.9826], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:45,448][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Anthony] are: tensor([0.0234, 0.3402, 0.6364], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:45,449][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Anthony] are: tensor([0.0540, 0.4228, 0.5232], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:45,449][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Anthony] are: tensor([0.0016, 0.1474, 0.8510], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:45,449][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Anthony] are: tensor([0.0145, 0.1862, 0.7993], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:45,450][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Anthony] are: tensor([0.4950, 0.0788, 0.4262], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:45,450][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Anthony] are: tensor([0.0022, 0.0256, 0.9722], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:45,450][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Anthony] are: tensor([0.3517, 0.3978, 0.2505], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:45,452][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Anthony] are: tensor([0.5437, 0.0146, 0.4416], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:45,452][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Anthony] are: tensor([0.5915, 0.2893, 0.1193], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:45,453][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Anthony] are: tensor([0.0072, 0.0928, 0.8999], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:45,453][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.2666, 0.6576, 0.0227, 0.0531], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:45,453][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0391, 0.0259, 0.9305, 0.0045], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:45,454][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0073, 0.1021, 0.1924, 0.6982], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:45,454][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0797, 0.2093, 0.3247, 0.3864], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:45,454][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0039, 0.1519, 0.3854, 0.4588], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:45,455][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.2053, 0.4103, 0.3531, 0.0313], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:45,456][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.4910, 0.2120, 0.2943, 0.0027], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:45,457][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0238, 0.3531, 0.6101, 0.0129], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:45,459][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.4877, 0.3175, 0.1047, 0.0902], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:45,460][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ and] are: tensor([9.7760e-01, 2.9524e-03, 1.9432e-02, 1.5226e-05], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:45,460][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ and] are: tensor([9.9612e-01, 3.2646e-03, 1.3339e-04, 4.8095e-04], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:45,462][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.1463, 0.2051, 0.5006, 0.1480], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:45,463][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Travis] are: tensor([0.5413, 0.4357, 0.0095, 0.0079, 0.0056], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:45,465][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Travis] are: tensor([0.0980, 0.0492, 0.7529, 0.0152, 0.0846], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:45,466][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Travis] are: tensor([0.0065, 0.1048, 0.1705, 0.5928, 0.1254], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:45,467][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Travis] are: tensor([0.0316, 0.1240, 0.1938, 0.2518, 0.3988], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:45,469][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Travis] are: tensor([0.0011, 0.1173, 0.2106, 0.5118, 0.1592], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:45,470][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Travis] are: tensor([0.0387, 0.2067, 0.3638, 0.1064, 0.2844], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:45,471][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Travis] are: tensor([0.4720, 0.3781, 0.1365, 0.0036, 0.0099], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:45,473][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Travis] are: tensor([0.0055, 0.1825, 0.6618, 0.0381, 0.1121], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:45,474][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Travis] are: tensor([0.3339, 0.3436, 0.1309, 0.0976, 0.0941], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:45,476][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Travis] are: tensor([0.8672, 0.0217, 0.0989, 0.0011, 0.0111], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:45,477][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Travis] are: tensor([0.8958, 0.0196, 0.0045, 0.0120, 0.0681], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:45,478][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Travis] are: tensor([0.0136, 0.0600, 0.1592, 0.5381, 0.2291], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:45,480][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.3802, 0.5853, 0.0104, 0.0056, 0.0021, 0.0164], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:45,481][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.0224, 0.0403, 0.7049, 0.0118, 0.1012, 0.1195], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:45,482][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.0038, 0.0698, 0.1185, 0.4658, 0.1454, 0.1966], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:45,484][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.0704, 0.1006, 0.1374, 0.1820, 0.2760, 0.2337], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:45,485][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.0018, 0.0504, 0.2087, 0.4497, 0.1503, 0.1391], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:45,487][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.0275, 0.3261, 0.2676, 0.0675, 0.2248, 0.0865], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:45,488][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.1799, 0.3978, 0.1808, 0.0061, 0.0542, 0.1812], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:45,489][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.0122, 0.4779, 0.3043, 0.0236, 0.1055, 0.0764], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:45,491][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.3022, 0.3025, 0.1328, 0.0836, 0.0924, 0.0865], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:45,492][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ had] are: tensor([7.3716e-01, 2.3160e-02, 1.1003e-01, 1.3466e-04, 2.1672e-02, 1.0784e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:45,493][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.9183, 0.0185, 0.0023, 0.0019, 0.0194, 0.0396], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:45,494][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.1175, 0.1074, 0.1702, 0.1495, 0.2915, 0.1638], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:45,496][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.5557, 0.3965, 0.0043, 0.0067, 0.0007, 0.0080, 0.0281],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:45,496][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0266, 0.0340, 0.8754, 0.0024, 0.0303, 0.0145, 0.0167],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:45,497][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0034, 0.0501, 0.1110, 0.3335, 0.1199, 0.1531, 0.2291],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:45,497][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0517, 0.0832, 0.1255, 0.1490, 0.2146, 0.1860, 0.1901],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:45,497][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0065, 0.0380, 0.2933, 0.3276, 0.1678, 0.0815, 0.0854],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:45,498][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.1200, 0.1521, 0.2211, 0.0452, 0.3921, 0.0421, 0.0275],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:45,498][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.2690, 0.3500, 0.2268, 0.0026, 0.0410, 0.1085, 0.0021],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:45,498][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0305, 0.2810, 0.4617, 0.0245, 0.1264, 0.0245, 0.0514],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:45,499][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.6733, 0.0971, 0.0485, 0.0328, 0.0316, 0.0494, 0.0673],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:45,499][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ a] are: tensor([9.6817e-01, 1.8269e-03, 2.0961e-02, 1.5685e-05, 5.4370e-03, 3.5258e-03,
        6.6112e-05], device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:45,499][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ a] are: tensor([9.9707e-01, 9.0931e-04, 5.6169e-05, 7.0143e-05, 5.2357e-04, 8.1396e-04,
        5.5700e-04], device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:45,501][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.1793, 0.0408, 0.1660, 0.1167, 0.1254, 0.0647, 0.3072],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:45,502][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ lot] are: tensor([0.6723, 0.3078, 0.0055, 0.0028, 0.0011, 0.0044, 0.0048, 0.0013],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:45,503][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ lot] are: tensor([0.0094, 0.0138, 0.2228, 0.0085, 0.1343, 0.2222, 0.1861, 0.2028],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:45,505][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ lot] are: tensor([0.0019, 0.0309, 0.0636, 0.2399, 0.0785, 0.0957, 0.1616, 0.3279],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:45,506][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ lot] are: tensor([0.0254, 0.0749, 0.0903, 0.1470, 0.1820, 0.1824, 0.1909, 0.1072],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:45,507][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ lot] are: tensor([0.0023, 0.0358, 0.1691, 0.2648, 0.1337, 0.0572, 0.2475, 0.0896],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:45,509][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ lot] are: tensor([0.0066, 0.0357, 0.1587, 0.0827, 0.1802, 0.0548, 0.2123, 0.2690],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:45,510][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ lot] are: tensor([0.0968, 0.0478, 0.0387, 0.0088, 0.0826, 0.4617, 0.0195, 0.2441],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:45,512][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ lot] are: tensor([0.0011, 0.0453, 0.2693, 0.0924, 0.1998, 0.1547, 0.2292, 0.0083],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:45,513][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ lot] are: tensor([0.2571, 0.1700, 0.1056, 0.0859, 0.0646, 0.0825, 0.1327, 0.1017],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:45,514][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ lot] are: tensor([0.0332, 0.0274, 0.1147, 0.0030, 0.1380, 0.2684, 0.0250, 0.3904],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:45,516][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ lot] are: tensor([0.1721, 0.0347, 0.0042, 0.0141, 0.2065, 0.2613, 0.2063, 0.1008],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:45,517][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ lot] are: tensor([0.0165, 0.0123, 0.0287, 0.0365, 0.0192, 0.0733, 0.8087, 0.0048],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:45,518][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ of] are: tensor([0.7067, 0.2023, 0.0039, 0.0028, 0.0009, 0.0036, 0.0099, 0.0044, 0.0653],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:45,520][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ of] are: tensor([0.1092, 0.0680, 0.7290, 0.0027, 0.0165, 0.0180, 0.0058, 0.0471, 0.0038],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:45,521][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ of] are: tensor([0.0016, 0.0316, 0.0640, 0.1896, 0.0699, 0.0887, 0.1263, 0.2369, 0.1915],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:45,522][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ of] are: tensor([0.0537, 0.0678, 0.0873, 0.1090, 0.1657, 0.1442, 0.1483, 0.0806, 0.1433],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:45,524][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ of] are: tensor([0.0033, 0.0669, 0.1882, 0.2248, 0.0726, 0.0490, 0.0878, 0.0558, 0.2515],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:45,525][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ of] are: tensor([0.0265, 0.2015, 0.1182, 0.0171, 0.0768, 0.0204, 0.0154, 0.2898, 0.2343],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:45,526][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ of] are: tensor([0.3484, 0.4033, 0.0787, 0.0019, 0.0196, 0.1047, 0.0009, 0.0397, 0.0029],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:45,528][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ of] are: tensor([0.0051, 0.3624, 0.3798, 0.0281, 0.1325, 0.0315, 0.0335, 0.0067, 0.0204],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:45,529][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ of] are: tensor([0.1278, 0.1692, 0.0878, 0.0805, 0.0667, 0.0825, 0.1603, 0.0758, 0.1494],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:45,530][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ of] are: tensor([8.1220e-01, 6.7246e-03, 1.1592e-01, 5.8254e-05, 1.9616e-02, 4.7028e-03,
        5.9656e-05, 4.0286e-02, 4.3567e-04], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:45,531][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ of] are: tensor([9.9373e-01, 1.8898e-03, 4.1179e-05, 3.0223e-05, 6.9752e-04, 5.2115e-04,
        5.5401e-05, 2.3933e-03, 6.4199e-04], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:45,532][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ of] are: tensor([0.1664, 0.1309, 0.3259, 0.0259, 0.0798, 0.0583, 0.0717, 0.0206, 0.1204],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:45,534][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ fun] are: tensor([0.4080, 0.4411, 0.0063, 0.0076, 0.0012, 0.0077, 0.0125, 0.0085, 0.1050,
        0.0020], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:45,535][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ fun] are: tensor([0.0035, 0.0205, 0.1705, 0.0193, 0.0365, 0.1127, 0.1603, 0.3626, 0.0259,
        0.0883], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:45,537][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ fun] are: tensor([0.0018, 0.0350, 0.0678, 0.1842, 0.0665, 0.0794, 0.1109, 0.2342, 0.1748,
        0.0455], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:45,538][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ fun] are: tensor([0.0269, 0.0656, 0.0747, 0.1076, 0.1329, 0.1217, 0.1376, 0.0853, 0.1282,
        0.1196], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:45,539][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ fun] are: tensor([0.0004, 0.0547, 0.1568, 0.2044, 0.0966, 0.0700, 0.1013, 0.0187, 0.1935,
        0.1036], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:45,541][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ fun] are: tensor([0.0023, 0.0128, 0.1550, 0.0239, 0.1149, 0.0190, 0.0761, 0.1766, 0.2870,
        0.1323], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:45,542][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ fun] are: tensor([0.1206, 0.1028, 0.1666, 0.0151, 0.0428, 0.3158, 0.0124, 0.1326, 0.0082,
        0.0831], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:45,544][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ fun] are: tensor([0.0004, 0.0076, 0.1825, 0.0239, 0.2605, 0.0957, 0.2461, 0.0261, 0.0365,
        0.1207], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:45,545][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ fun] are: tensor([0.1978, 0.1483, 0.0769, 0.0604, 0.0627, 0.0959, 0.0969, 0.0674, 0.0861,
        0.1075], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:45,546][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ fun] are: tensor([0.0414, 0.0062, 0.2652, 0.0009, 0.0873, 0.0820, 0.0093, 0.4795, 0.0071,
        0.0210], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:45,548][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ fun] are: tensor([0.4526, 0.0191, 0.0023, 0.0099, 0.0851, 0.1231, 0.0712, 0.1214, 0.1018,
        0.0135], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:45,549][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ fun] are: tensor([0.0061, 0.0156, 0.0759, 0.1187, 0.0410, 0.0229, 0.3260, 0.0136, 0.3594,
        0.0208], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:45,550][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.3454, 0.5426, 0.0060, 0.0048, 0.0006, 0.0042, 0.0067, 0.0069, 0.0621,
        0.0022, 0.0183], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:45,552][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.0903, 0.0259, 0.3629, 0.0033, 0.0403, 0.0468, 0.0220, 0.1950, 0.0074,
        0.1930, 0.0133], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:45,553][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.0022, 0.0290, 0.0544, 0.1594, 0.0623, 0.0785, 0.1105, 0.2204, 0.1745,
        0.0438, 0.0649], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:45,555][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.0199, 0.0641, 0.0710, 0.0941, 0.1178, 0.1247, 0.1153, 0.0716, 0.1185,
        0.1172, 0.0858], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:45,555][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.0018, 0.0641, 0.1184, 0.1428, 0.0501, 0.0430, 0.0694, 0.0258, 0.1626,
        0.1443, 0.1776], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:45,555][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.0022, 0.1057, 0.0825, 0.0153, 0.0988, 0.0140, 0.0146, 0.1656, 0.1491,
        0.3284, 0.0239], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:45,556][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.1507, 0.4532, 0.0936, 0.0015, 0.0287, 0.1531, 0.0014, 0.0368, 0.0016,
        0.0705, 0.0088], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:45,556][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0052, 0.1471, 0.2493, 0.0170, 0.2384, 0.0623, 0.0495, 0.0057, 0.0131,
        0.1571, 0.0554], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:45,556][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.2518, 0.1512, 0.0704, 0.0517, 0.0475, 0.0649, 0.0716, 0.0542, 0.0541,
        0.0948, 0.0878], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:45,557][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ at] are: tensor([3.8552e-01, 1.5815e-02, 2.6711e-01, 1.9668e-04, 1.1027e-01, 3.2221e-02,
        6.8358e-04, 1.4135e-01, 1.5555e-03, 4.4540e-02, 7.4356e-04],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:45,557][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ at] are: tensor([9.4261e-01, 8.2294e-03, 4.3284e-04, 3.6005e-04, 9.5465e-03, 2.8009e-03,
        4.4002e-04, 8.8341e-03, 2.7441e-03, 2.8992e-03, 2.1105e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:45,557][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.1156, 0.0775, 0.0869, 0.0528, 0.0804, 0.0233, 0.0850, 0.0318, 0.0740,
        0.1048, 0.2679], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:45,558][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ the] are: tensor([2.4685e-01, 3.8994e-01, 1.9223e-03, 3.7815e-03, 2.0746e-04, 4.0362e-03,
        1.0062e-02, 2.0727e-03, 1.3779e-01, 9.5764e-04, 1.7928e-02, 1.8446e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:45,558][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ the] are: tensor([6.5448e-03, 4.0927e-02, 9.1428e-01, 6.3502e-04, 5.2221e-03, 3.6420e-03,
        3.0357e-03, 8.3455e-03, 7.4738e-04, 8.8982e-03, 7.3358e-04, 6.9898e-03],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:45,560][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0014, 0.0260, 0.0599, 0.1505, 0.0649, 0.0728, 0.1030, 0.2289, 0.1569,
        0.0389, 0.0546, 0.0420], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:45,561][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0214, 0.0527, 0.0746, 0.0855, 0.1189, 0.1058, 0.1012, 0.0618, 0.1121,
        0.1053, 0.0793, 0.0815], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:45,562][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0017, 0.0132, 0.1244, 0.0977, 0.0273, 0.0196, 0.0358, 0.0238, 0.1285,
        0.0513, 0.0841, 0.3925], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:45,564][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0062, 0.0915, 0.1387, 0.0178, 0.0575, 0.0077, 0.0232, 0.1248, 0.1247,
        0.2946, 0.0190, 0.0942], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:45,565][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.2328, 0.3571, 0.2689, 0.0009, 0.0192, 0.0580, 0.0008, 0.0281, 0.0007,
        0.0236, 0.0026, 0.0072], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:45,566][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0018, 0.2070, 0.5990, 0.0148, 0.0506, 0.0080, 0.0186, 0.0022, 0.0073,
        0.0579, 0.0192, 0.0137], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:45,568][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.5563, 0.0848, 0.0408, 0.0264, 0.0215, 0.0329, 0.0356, 0.0278, 0.0322,
        0.0390, 0.0423, 0.0604], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:45,569][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ the] are: tensor([4.9530e-01, 6.4501e-03, 2.3158e-01, 9.6158e-05, 4.1002e-02, 1.8451e-02,
        4.6662e-04, 1.5217e-01, 7.3344e-04, 5.1568e-02, 1.0580e-03, 1.1244e-03],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:45,570][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ the] are: tensor([9.8262e-01, 1.6928e-03, 1.2121e-04, 7.2701e-05, 1.3296e-03, 1.0080e-03,
        3.0614e-04, 2.8576e-03, 8.0617e-04, 4.2415e-04, 2.7680e-03, 5.9910e-03],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:45,571][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.1477, 0.0539, 0.0492, 0.0162, 0.0177, 0.0111, 0.0332, 0.0057, 0.0222,
        0.0223, 0.0316, 0.5892], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:45,572][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ hospital] are: tensor([0.7354, 0.1591, 0.0011, 0.0019, 0.0009, 0.0015, 0.0024, 0.0008, 0.0399,
        0.0009, 0.0174, 0.0287, 0.0097], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:45,574][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ hospital] are: tensor([0.0414, 0.2467, 0.2821, 0.0192, 0.0221, 0.0797, 0.0465, 0.1470, 0.0094,
        0.0201, 0.0053, 0.0416, 0.0389], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:45,575][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ hospital] are: tensor([0.0027, 0.0325, 0.0622, 0.1785, 0.0600, 0.0766, 0.1019, 0.2048, 0.1545,
        0.0335, 0.0457, 0.0324, 0.0147], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:45,577][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ hospital] are: tensor([0.0220, 0.0513, 0.0485, 0.0864, 0.0932, 0.0941, 0.1173, 0.0504, 0.0956,
        0.0901, 0.0716, 0.0807, 0.0986], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:45,578][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ hospital] are: tensor([0.0011, 0.0447, 0.0777, 0.1307, 0.0470, 0.0191, 0.0410, 0.0137, 0.1236,
        0.0614, 0.1088, 0.2464, 0.0848], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:45,580][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ hospital] are: tensor([0.0037, 0.0584, 0.0302, 0.0226, 0.0131, 0.0162, 0.0607, 0.0397, 0.1672,
        0.0866, 0.0307, 0.0588, 0.4120], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:45,581][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ hospital] are: tensor([0.4335, 0.2135, 0.0602, 0.0032, 0.0070, 0.0990, 0.0020, 0.0205, 0.0026,
        0.0249, 0.0151, 0.0111, 0.1075], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:45,582][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ hospital] are: tensor([0.0085, 0.0938, 0.3033, 0.0315, 0.0456, 0.1195, 0.1460, 0.0050, 0.0174,
        0.0727, 0.0657, 0.0172, 0.0740], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:45,584][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ hospital] are: tensor([0.2063, 0.1779, 0.0689, 0.0399, 0.0384, 0.0547, 0.0493, 0.0386, 0.0366,
        0.0443, 0.0561, 0.0641, 0.1249], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:45,585][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ hospital] are: tensor([0.0905, 0.0600, 0.3054, 0.0015, 0.0372, 0.0342, 0.0024, 0.1752, 0.0033,
        0.0242, 0.0043, 0.0013, 0.2605], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:45,586][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ hospital] are: tensor([8.2300e-01, 2.1997e-02, 7.2020e-04, 1.5754e-03, 1.8761e-02, 7.1979e-03,
        3.7976e-03, 3.6419e-03, 8.5909e-03, 8.1494e-04, 2.2993e-02, 4.1465e-02,
        4.5447e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:45,588][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ hospital] are: tensor([0.0197, 0.0320, 0.0279, 0.1676, 0.0267, 0.0108, 0.1029, 0.0026, 0.0626,
        0.0044, 0.0385, 0.4762, 0.0282], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:45,589][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.1631, 0.4959, 0.0013, 0.0058, 0.0007, 0.0039, 0.0048, 0.0036, 0.0797,
        0.0009, 0.0294, 0.0514, 0.0043, 0.1551], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:45,591][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.0620, 0.0948, 0.5319, 0.0041, 0.0192, 0.0319, 0.0205, 0.0954, 0.0029,
        0.0368, 0.0050, 0.0240, 0.0598, 0.0118], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:45,592][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.0010, 0.0211, 0.0579, 0.1582, 0.0526, 0.0734, 0.1020, 0.2159, 0.1507,
        0.0307, 0.0466, 0.0334, 0.0183, 0.0382], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:45,593][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0341, 0.0486, 0.0625, 0.0669, 0.1075, 0.0823, 0.0834, 0.0480, 0.0872,
        0.0850, 0.0654, 0.0653, 0.1121, 0.0517], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:45,595][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0009, 0.0214, 0.0534, 0.0594, 0.0374, 0.0239, 0.0570, 0.0198, 0.0716,
        0.0591, 0.0861, 0.3231, 0.0808, 0.1061], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:45,596][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.0091, 0.0256, 0.0297, 0.0114, 0.0347, 0.0065, 0.0180, 0.1010, 0.1281,
        0.1320, 0.0305, 0.0295, 0.3059, 0.1380], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:45,598][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.2198, 0.5233, 0.0454, 0.0017, 0.0067, 0.0817, 0.0008, 0.0233, 0.0009,
        0.0217, 0.0026, 0.0027, 0.0528, 0.0168], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:45,599][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0030, 0.3205, 0.1824, 0.0195, 0.1093, 0.0618, 0.0554, 0.0032, 0.0112,
        0.0708, 0.0431, 0.0208, 0.0562, 0.0427], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:45,601][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.1345, 0.1403, 0.0618, 0.0460, 0.0416, 0.0392, 0.0415, 0.0433, 0.0293,
        0.0544, 0.0392, 0.0486, 0.1325, 0.1479], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:45,602][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [.] are: tensor([4.0448e-01, 7.9561e-03, 6.5715e-02, 1.4062e-04, 2.8376e-02, 1.0489e-02,
        3.1059e-04, 8.9060e-02, 6.4199e-04, 3.4519e-02, 7.5966e-04, 1.7166e-04,
        3.5526e-01, 2.1217e-03], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:45,603][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [.] are: tensor([9.8639e-01, 4.2294e-04, 9.8825e-06, 6.8243e-06, 1.7006e-04, 5.5180e-05,
        8.4742e-06, 1.2018e-04, 2.2161e-05, 2.0495e-05, 1.0900e-04, 6.7839e-05,
        5.7759e-04, 1.2017e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:45,604][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0597, 0.1745, 0.0442, 0.0284, 0.0286, 0.0034, 0.0080, 0.0011, 0.0039,
        0.0087, 0.0103, 0.0509, 0.1924, 0.3861], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:45,605][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Anthony] are: tensor([0.3704, 0.3521, 0.0043, 0.0030, 0.0006, 0.0030, 0.0052, 0.0032, 0.0859,
        0.0022, 0.0249, 0.0607, 0.0118, 0.0658, 0.0071], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:45,607][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Anthony] are: tensor([0.1223, 0.0620, 0.4867, 0.0046, 0.0129, 0.0318, 0.0084, 0.0768, 0.0060,
        0.0398, 0.0039, 0.0186, 0.0618, 0.0139, 0.0505], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:45,608][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Anthony] are: tensor([0.0015, 0.0243, 0.0499, 0.1524, 0.0472, 0.0739, 0.0922, 0.2212, 0.1323,
        0.0339, 0.0428, 0.0334, 0.0168, 0.0430, 0.0352], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:45,610][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Anthony] are: tensor([0.0154, 0.0420, 0.0431, 0.0586, 0.0946, 0.0820, 0.0840, 0.0502, 0.0862,
        0.0858, 0.0642, 0.0632, 0.1219, 0.0552, 0.0538], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:45,611][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Anthony] are: tensor([0.0007, 0.0154, 0.0941, 0.0765, 0.0290, 0.0252, 0.0198, 0.0128, 0.0935,
        0.0341, 0.0897, 0.3241, 0.0491, 0.0418, 0.0941], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:45,613][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Anthony] are: tensor([0.0072, 0.0230, 0.0240, 0.0118, 0.0163, 0.0090, 0.0132, 0.0772, 0.2039,
        0.1000, 0.0459, 0.0539, 0.2687, 0.0909, 0.0551], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:45,613][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Anthony] are: tensor([5.5763e-01, 2.2595e-01, 2.9170e-02, 1.0494e-03, 2.1300e-03, 5.1859e-02,
        3.4596e-04, 1.2955e-02, 8.0141e-04, 1.2755e-02, 2.1801e-03, 2.5418e-03,
        7.3931e-02, 1.4914e-02, 1.1790e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:45,614][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Anthony] are: tensor([0.0119, 0.1536, 0.4224, 0.0210, 0.0530, 0.0318, 0.0228, 0.0052, 0.0108,
        0.0672, 0.0164, 0.0189, 0.0740, 0.0340, 0.0570], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:45,614][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Anthony] are: tensor([0.0850, 0.1381, 0.0588, 0.0317, 0.0377, 0.0395, 0.0398, 0.0253, 0.0339,
        0.0412, 0.0394, 0.0644, 0.1211, 0.1537, 0.0904], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:45,614][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Anthony] are: tensor([4.5406e-01, 1.1695e-02, 6.4388e-02, 2.0384e-04, 4.9960e-03, 1.6132e-02,
        2.9307e-04, 3.3981e-02, 8.6974e-04, 2.2613e-02, 7.0000e-04, 5.6002e-04,
        3.6371e-01, 3.0238e-03, 2.2777e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:45,615][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Anthony] are: tensor([8.9331e-01, 3.7480e-03, 1.3228e-04, 9.9294e-05, 2.1333e-03, 8.6651e-04,
        1.5740e-04, 4.9094e-04, 7.0768e-04, 2.9816e-04, 1.4314e-03, 1.8546e-03,
        1.4665e-02, 5.9763e-02, 2.0339e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:45,615][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Anthony] are: tensor([0.0874, 0.0184, 0.0323, 0.0172, 0.0099, 0.0044, 0.0123, 0.0041, 0.0122,
        0.0058, 0.0084, 0.1046, 0.1319, 0.3305, 0.2204], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:45,615][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([1.3913e-01, 2.3043e-01, 1.1333e-03, 9.0927e-04, 4.6831e-04, 9.9786e-04,
        3.8114e-04, 5.3424e-04, 1.3706e-02, 6.0494e-04, 1.0572e-02, 1.1070e-02,
        3.3662e-03, 6.8006e-02, 2.5976e-03, 5.1609e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:45,616][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0103, 0.0838, 0.4270, 0.0065, 0.0192, 0.0408, 0.0246, 0.0844, 0.0045,
        0.0541, 0.0042, 0.0233, 0.0491, 0.0152, 0.0864, 0.0665],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:45,617][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0015, 0.0287, 0.0664, 0.1635, 0.0557, 0.0666, 0.0767, 0.2009, 0.1141,
        0.0337, 0.0452, 0.0335, 0.0192, 0.0425, 0.0407, 0.0111],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:45,618][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.0252, 0.0334, 0.0455, 0.0570, 0.0767, 0.0689, 0.0776, 0.0486, 0.0876,
        0.0893, 0.0541, 0.0594, 0.1052, 0.0557, 0.0633, 0.0525],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:45,619][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([3.5762e-04, 1.5754e-02, 8.4801e-02, 1.1111e-01, 2.6674e-02, 1.8872e-02,
        4.1537e-02, 1.1271e-02, 6.3495e-02, 2.8367e-02, 7.9862e-02, 3.6368e-01,
        3.7669e-02, 2.2236e-02, 7.5752e-02, 1.8557e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:45,620][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.0014, 0.0160, 0.0302, 0.0176, 0.0147, 0.0174, 0.0393, 0.0482, 0.1809,
        0.1086, 0.0610, 0.0704, 0.1159, 0.0891, 0.1637, 0.0255],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:45,622][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0966, 0.3202, 0.1310, 0.0029, 0.0110, 0.0806, 0.0024, 0.0239, 0.0023,
        0.0355, 0.0075, 0.0120, 0.0703, 0.0261, 0.0284, 0.1494],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:45,623][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0004, 0.0713, 0.1099, 0.0265, 0.1711, 0.0671, 0.0975, 0.0022, 0.0153,
        0.0345, 0.0680, 0.0573, 0.0551, 0.0454, 0.0346, 0.1438],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:45,624][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.1664, 0.1307, 0.0505, 0.0277, 0.0243, 0.0296, 0.0271, 0.0306, 0.0237,
        0.0531, 0.0433, 0.0506, 0.1149, 0.0972, 0.0538, 0.0767],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:45,625][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([1.1078e-02, 1.4800e-03, 9.9130e-02, 1.3421e-04, 1.9445e-02, 2.0487e-02,
        1.3706e-03, 9.7574e-02, 2.6385e-03, 5.0038e-02, 4.7120e-03, 1.2462e-03,
        4.8296e-01, 2.8518e-03, 1.8740e-01, 1.7449e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:45,627][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.4048, 0.0166, 0.0007, 0.0005, 0.0344, 0.0055, 0.0006, 0.0006, 0.0009,
        0.0006, 0.0028, 0.0072, 0.0195, 0.3218, 0.1004, 0.0831],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:45,628][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.1318, 0.0383, 0.0142, 0.0106, 0.0256, 0.0096, 0.0212, 0.0018, 0.0243,
        0.0126, 0.0286, 0.1454, 0.1120, 0.1179, 0.2279, 0.0781],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:45,629][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ a] are: tensor([2.7986e-01, 1.2379e-01, 8.7155e-04, 1.9133e-03, 1.7179e-04, 2.4189e-03,
        5.9749e-03, 2.0657e-03, 7.0630e-02, 8.8608e-04, 1.7355e-02, 9.6728e-02,
        5.4567e-03, 7.9453e-02, 1.7012e-03, 2.4164e-01, 6.9080e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:45,630][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0347, 0.0477, 0.5920, 0.0028, 0.0128, 0.0107, 0.0097, 0.0323, 0.0030,
        0.0418, 0.0030, 0.0198, 0.0516, 0.0064, 0.0301, 0.0862, 0.0155],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:45,632][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0012, 0.0210, 0.0534, 0.1379, 0.0498, 0.0673, 0.0860, 0.1940, 0.1231,
        0.0333, 0.0461, 0.0367, 0.0213, 0.0419, 0.0447, 0.0149, 0.0274],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:45,633][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0203, 0.0356, 0.0576, 0.0597, 0.0857, 0.0676, 0.0633, 0.0426, 0.0742,
        0.0735, 0.0511, 0.0515, 0.1083, 0.0462, 0.0614, 0.0568, 0.0446],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:45,635][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0006, 0.0056, 0.0602, 0.0443, 0.0312, 0.0120, 0.0159, 0.0284, 0.0683,
        0.0606, 0.0649, 0.3296, 0.1077, 0.0428, 0.0939, 0.0099, 0.0241],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:45,636][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0138, 0.0097, 0.0513, 0.0107, 0.0412, 0.0068, 0.0078, 0.1461, 0.0980,
        0.1358, 0.0197, 0.0415, 0.2197, 0.0559, 0.0486, 0.0389, 0.0546],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:45,638][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.1898, 0.2026, 0.1296, 0.0015, 0.0065, 0.0445, 0.0008, 0.0155, 0.0008,
        0.0213, 0.0021, 0.0056, 0.0721, 0.0124, 0.0094, 0.2798, 0.0056],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:45,639][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0044, 0.0488, 0.3443, 0.0078, 0.0661, 0.0138, 0.0197, 0.0016, 0.0083,
        0.0631, 0.0220, 0.0270, 0.0570, 0.0067, 0.0125, 0.1140, 0.1829],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:45,640][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.3269, 0.0751, 0.0518, 0.0223, 0.0255, 0.0315, 0.0309, 0.0212, 0.0217,
        0.0295, 0.0297, 0.0539, 0.0781, 0.0659, 0.0458, 0.0435, 0.0466],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:45,641][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ a] are: tensor([3.1046e-01, 9.9953e-04, 6.5079e-02, 3.4039e-05, 5.0790e-03, 3.4788e-03,
        1.0468e-04, 3.2569e-02, 6.5311e-04, 1.5445e-02, 4.3169e-04, 3.0335e-04,
        5.1162e-01, 1.5628e-03, 2.0091e-02, 3.0797e-02, 1.2876e-03],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:45,642][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ a] are: tensor([9.0378e-01, 6.1097e-04, 8.8023e-05, 5.9535e-05, 9.9647e-04, 6.1719e-04,
        3.6882e-04, 1.2913e-03, 6.4611e-04, 1.4288e-04, 1.0885e-03, 4.5363e-03,
        8.7895e-03, 3.7822e-02, 1.2781e-02, 3.9242e-03, 2.2459e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:45,644][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0413, 0.0155, 0.0292, 0.0116, 0.0096, 0.0013, 0.0089, 0.0016, 0.0046,
        0.0068, 0.0054, 0.1311, 0.0675, 0.1456, 0.0934, 0.0046, 0.4219],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:45,645][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ drink] are: tensor([0.2500, 0.2301, 0.0016, 0.0013, 0.0006, 0.0023, 0.0017, 0.0013, 0.0415,
        0.0015, 0.0164, 0.0237, 0.0054, 0.0529, 0.0033, 0.3111, 0.0363, 0.0191],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:45,647][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ drink] are: tensor([0.0216, 0.0373, 0.5044, 0.0096, 0.0284, 0.0440, 0.0281, 0.0575, 0.0081,
        0.0304, 0.0043, 0.0260, 0.0331, 0.0100, 0.0414, 0.0594, 0.0157, 0.0407],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:45,648][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ drink] are: tensor([0.0020, 0.0226, 0.0505, 0.1620, 0.0492, 0.0625, 0.0836, 0.1840, 0.1378,
        0.0333, 0.0423, 0.0317, 0.0140, 0.0413, 0.0351, 0.0131, 0.0270, 0.0080],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:45,650][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ drink] are: tensor([0.0153, 0.0306, 0.0411, 0.0466, 0.0713, 0.0656, 0.0674, 0.0451, 0.0711,
        0.0824, 0.0497, 0.0515, 0.0819, 0.0441, 0.0531, 0.0510, 0.0523, 0.0797],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:45,651][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ drink] are: tensor([0.0003, 0.0232, 0.0634, 0.1179, 0.0232, 0.0112, 0.0327, 0.0095, 0.1015,
        0.0725, 0.0834, 0.2112, 0.0355, 0.0467, 0.0781, 0.0179, 0.0326, 0.0392],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:45,652][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ drink] are: tensor([0.0027, 0.0145, 0.1118, 0.0160, 0.0284, 0.0085, 0.0153, 0.2076, 0.1141,
        0.0562, 0.0495, 0.0433, 0.0716, 0.0366, 0.0676, 0.0197, 0.0387, 0.0981],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:45,654][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ drink] are: tensor([0.2848, 0.2870, 0.0458, 0.0047, 0.0047, 0.0552, 0.0011, 0.0126, 0.0019,
        0.0330, 0.0056, 0.0054, 0.0401, 0.0148, 0.0041, 0.1508, 0.0062, 0.0422],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:45,655][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ drink] are: tensor([0.0057, 0.0250, 0.2287, 0.0262, 0.0652, 0.0498, 0.0289, 0.0044, 0.0112,
        0.0537, 0.0205, 0.0399, 0.0454, 0.0156, 0.0249, 0.0700, 0.1886, 0.0963],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:45,657][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ drink] are: tensor([0.0889, 0.0890, 0.0439, 0.0205, 0.0271, 0.0323, 0.0343, 0.0219, 0.0267,
        0.0413, 0.0439, 0.0466, 0.0871, 0.0945, 0.0603, 0.0552, 0.0587, 0.1277],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:45,658][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ drink] are: tensor([7.9753e-02, 5.5017e-03, 3.0586e-01, 2.5425e-04, 1.7957e-02, 9.7815e-03,
        9.2879e-04, 1.8883e-01, 1.5292e-03, 3.4981e-02, 2.7837e-03, 4.3645e-04,
        2.5967e-01, 1.0361e-03, 4.2021e-02, 1.7636e-02, 1.6812e-03, 2.9362e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:45,659][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ drink] are: tensor([6.7240e-01, 3.0407e-03, 4.3352e-04, 3.9518e-04, 2.6186e-03, 1.2773e-03,
        1.0015e-03, 4.5043e-04, 2.5383e-03, 2.9560e-04, 3.3843e-03, 5.1060e-03,
        8.5802e-03, 1.1659e-01, 4.8233e-02, 7.4752e-03, 4.0504e-02, 8.5673e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:45,660][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ drink] are: tensor([0.0456, 0.0038, 0.0233, 0.0164, 0.0037, 0.0009, 0.0161, 0.0019, 0.0109,
        0.0024, 0.0117, 0.0400, 0.0113, 0.0501, 0.0460, 0.0038, 0.7018, 0.0102],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:45,662][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.1547, 0.0916, 0.0011, 0.0024, 0.0003, 0.0017, 0.0042, 0.0023, 0.0636,
        0.0011, 0.0212, 0.0752, 0.0038, 0.1013, 0.0026, 0.2771, 0.0910, 0.0130,
        0.0919], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:45,663][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0597, 0.0370, 0.4197, 0.0031, 0.0176, 0.0342, 0.0157, 0.0716, 0.0032,
        0.0411, 0.0053, 0.0228, 0.0464, 0.0068, 0.0571, 0.0984, 0.0160, 0.0427,
        0.0016], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:45,665][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0011, 0.0164, 0.0412, 0.1293, 0.0430, 0.0620, 0.0904, 0.2013, 0.1261,
        0.0304, 0.0483, 0.0359, 0.0178, 0.0383, 0.0383, 0.0128, 0.0267, 0.0071,
        0.0336], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:45,666][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0201, 0.0321, 0.0535, 0.0515, 0.0917, 0.0594, 0.0599, 0.0379, 0.0622,
        0.0677, 0.0437, 0.0424, 0.0931, 0.0348, 0.0482, 0.0450, 0.0379, 0.0743,
        0.0447], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:45,668][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0007, 0.0195, 0.0575, 0.0427, 0.0264, 0.0185, 0.0342, 0.0140, 0.0532,
        0.0443, 0.0650, 0.2558, 0.0659, 0.0825, 0.0895, 0.0093, 0.0371, 0.0329,
        0.0510], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:45,669][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0238, 0.0248, 0.0831, 0.0103, 0.0233, 0.0085, 0.0181, 0.0712, 0.1408,
        0.0815, 0.0406, 0.0302, 0.2055, 0.0378, 0.0724, 0.0234, 0.0415, 0.0499,
        0.0133], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:45,671][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.2839, 0.3048, 0.0665, 0.0017, 0.0040, 0.0734, 0.0011, 0.0176, 0.0011,
        0.0210, 0.0026, 0.0029, 0.0627, 0.0079, 0.0087, 0.1129, 0.0023, 0.0229,
        0.0019], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:45,671][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0090, 0.0986, 0.1636, 0.0082, 0.0536, 0.0473, 0.0284, 0.0020, 0.0106,
        0.0530, 0.0340, 0.0242, 0.0628, 0.0150, 0.0188, 0.1412, 0.1784, 0.0377,
        0.0134], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:45,672][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.1173, 0.0761, 0.0395, 0.0249, 0.0223, 0.0244, 0.0270, 0.0246, 0.0203,
        0.0418, 0.0268, 0.0417, 0.0966, 0.1048, 0.0512, 0.0388, 0.0436, 0.1102,
        0.0681], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:45,672][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ to] are: tensor([4.0561e-01, 1.4313e-03, 7.7955e-02, 5.0577e-05, 6.3707e-03, 6.4068e-03,
        2.6745e-04, 2.5796e-02, 5.3395e-04, 1.3807e-02, 6.4620e-04, 1.3417e-04,
        3.7411e-01, 5.5669e-04, 2.6556e-02, 1.7725e-02, 7.6518e-04, 4.0932e-02,
        3.4177e-04], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:45,672][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ to] are: tensor([9.7084e-01, 6.5023e-04, 3.4945e-05, 1.5281e-05, 2.2140e-04, 1.5283e-04,
        3.4231e-05, 1.5448e-04, 6.4518e-05, 4.3464e-05, 2.3738e-04, 2.1924e-04,
        1.3847e-03, 1.2213e-02, 4.7037e-03, 9.3652e-04, 1.8750e-03, 3.1701e-03,
        3.0525e-03], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:45,673][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0146, 0.0213, 0.0327, 0.0089, 0.0084, 0.0011, 0.0056, 0.0011, 0.0020,
        0.0082, 0.0069, 0.0300, 0.1382, 0.0954, 0.1697, 0.0060, 0.2850, 0.0702,
        0.0947], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:45,722][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:21:45,722][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:45,723][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:45,723][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:45,723][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:45,724][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:45,724][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:45,724][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:45,724][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:45,725][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:45,725][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:45,725][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:45,726][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:21:45,726][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0289, 0.9711], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:45,726][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.1085, 0.8915], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:45,727][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0051, 0.9949], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:45,728][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.1429, 0.8571], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:45,729][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0038, 0.9962], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:45,731][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0612, 0.9388], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:45,732][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.7594, 0.2406], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:45,734][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0028, 0.9972], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:45,735][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0226, 0.9774], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:45,736][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.9900, 0.0100], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:45,738][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.9134, 0.0866], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:45,739][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0029, 0.9971], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:21:45,740][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Anthony] are: tensor([0.3413, 0.5770, 0.0817], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:45,742][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Anthony] are: tensor([0.0072, 0.0102, 0.9826], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:45,743][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Anthony] are: tensor([0.0078, 0.1015, 0.8907], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:45,744][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Anthony] are: tensor([4.6868e-04, 2.0916e-01, 7.9037e-01], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:45,745][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Anthony] are: tensor([5.1046e-04, 1.0526e-01, 8.9423e-01], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:45,746][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Anthony] are: tensor([0.0145, 0.1862, 0.7993], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:45,748][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Anthony] are: tensor([0.4950, 0.0788, 0.4262], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:45,748][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Anthony] are: tensor([0.0022, 0.0256, 0.9722], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:45,748][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Anthony] are: tensor([0.0025, 0.9626, 0.0348], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:45,749][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Anthony] are: tensor([0.5437, 0.0146, 0.4416], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:45,749][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Anthony] are: tensor([0.5915, 0.2893, 0.1193], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:45,749][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Anthony] are: tensor([0.0072, 0.0928, 0.8999], device='cuda:0') for source tokens [Then, Anthony]
[2024-07-24 10:21:45,750][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.3708, 0.5747, 0.0388, 0.0156], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:45,750][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0391, 0.0259, 0.9305, 0.0045], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:45,750][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0053, 0.1815, 0.7954, 0.0179], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:45,750][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0243, 0.1004, 0.6318, 0.2435], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:45,751][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0056, 0.2121, 0.7069, 0.0755], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:45,751][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.2053, 0.4103, 0.3531, 0.0313], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:45,751][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.4910, 0.2120, 0.2943, 0.0027], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:45,753][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0238, 0.3531, 0.6101, 0.0129], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:45,754][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0198, 0.9315, 0.0032, 0.0454], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:45,755][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([9.7760e-01, 2.9524e-03, 1.9432e-02, 1.5226e-05], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:45,756][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([9.9612e-01, 3.2646e-03, 1.3339e-04, 4.8095e-04], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:45,757][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.1463, 0.2051, 0.5006, 0.1480], device='cuda:0') for source tokens [Then, Anthony and]
[2024-07-24 10:21:45,758][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Travis] are: tensor([0.8470, 0.1433, 0.0074, 0.0010, 0.0013], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:45,759][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Travis] are: tensor([0.0980, 0.0492, 0.7529, 0.0152, 0.0846], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:45,761][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Travis] are: tensor([0.0178, 0.1228, 0.6724, 0.1277, 0.0593], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:45,762][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Travis] are: tensor([0.0079, 0.0250, 0.2267, 0.4307, 0.3097], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:45,763][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Travis] are: tensor([0.0061, 0.4492, 0.3391, 0.1389, 0.0666], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:45,765][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Travis] are: tensor([0.0387, 0.2067, 0.3638, 0.1064, 0.2844], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:45,766][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Travis] are: tensor([0.4720, 0.3781, 0.1365, 0.0036, 0.0099], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:45,768][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Travis] are: tensor([0.0055, 0.1825, 0.6618, 0.0381, 0.1121], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:45,769][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Travis] are: tensor([0.0044, 0.8540, 0.0083, 0.0870, 0.0463], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:45,770][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Travis] are: tensor([0.8672, 0.0217, 0.0989, 0.0011, 0.0111], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:45,772][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Travis] are: tensor([0.8958, 0.0196, 0.0045, 0.0120, 0.0681], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:45,773][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Travis] are: tensor([0.0136, 0.0600, 0.1592, 0.5381, 0.2291], device='cuda:0') for source tokens [Then, Anthony and Travis]
[2024-07-24 10:21:45,774][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.5617, 0.4160, 0.0138, 0.0013, 0.0011, 0.0059], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:45,776][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.0224, 0.0403, 0.7049, 0.0118, 0.1012, 0.1195], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:45,777][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.0052, 0.1436, 0.2226, 0.0391, 0.2587, 0.3309], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:45,779][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.0467, 0.0135, 0.0231, 0.0171, 0.0732, 0.8264], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:45,780][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.0046, 0.1577, 0.2561, 0.1509, 0.1050, 0.3258], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:45,781][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.0275, 0.3261, 0.2676, 0.0675, 0.2248, 0.0865], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:45,783][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.1799, 0.3978, 0.1808, 0.0061, 0.0542, 0.1812], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:45,784][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.0122, 0.4779, 0.3043, 0.0236, 0.1055, 0.0764], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:45,785][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.0016, 0.8442, 0.0109, 0.0632, 0.0751, 0.0050], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:45,786][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([7.3716e-01, 2.3160e-02, 1.1003e-01, 1.3466e-04, 2.1672e-02, 1.0784e-01],
       device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:45,788][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.9183, 0.0185, 0.0023, 0.0019, 0.0194, 0.0396], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:45,789][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.1175, 0.1074, 0.1702, 0.1495, 0.2915, 0.1638], device='cuda:0') for source tokens [Then, Anthony and Travis had]
[2024-07-24 10:21:45,790][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([6.6748e-01, 3.1420e-01, 6.2123e-03, 1.9224e-03, 4.1404e-04, 3.1946e-03,
        6.5786e-03], device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:45,791][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0266, 0.0340, 0.8754, 0.0024, 0.0303, 0.0145, 0.0167],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:45,793][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0020, 0.2301, 0.4044, 0.0130, 0.1549, 0.1329, 0.0628],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:45,794][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0226, 0.0141, 0.0250, 0.0326, 0.0222, 0.5292, 0.3544],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:45,796][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0040, 0.1602, 0.3207, 0.0594, 0.1054, 0.1791, 0.1713],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:45,797][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.1200, 0.1521, 0.2211, 0.0452, 0.3921, 0.0421, 0.0275],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:45,798][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.2690, 0.3500, 0.2268, 0.0026, 0.0410, 0.1085, 0.0021],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:45,800][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0305, 0.2810, 0.4617, 0.0245, 0.1264, 0.0245, 0.0514],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:45,801][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.4278, 0.2669, 0.0058, 0.0578, 0.0364, 0.0195, 0.1857],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:45,802][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([9.6817e-01, 1.8269e-03, 2.0961e-02, 1.5685e-05, 5.4370e-03, 3.5258e-03,
        6.6112e-05], device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:45,803][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([9.9707e-01, 9.0931e-04, 5.6169e-05, 7.0143e-05, 5.2357e-04, 8.1396e-04,
        5.5700e-04], device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:45,804][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.1793, 0.0408, 0.1660, 0.1167, 0.1254, 0.0647, 0.3072],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a]
[2024-07-24 10:21:45,805][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ lot] are: tensor([8.8196e-01, 1.1111e-01, 4.7922e-03, 3.2416e-04, 2.5180e-04, 9.6452e-04,
        4.0467e-04, 1.9265e-04], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:45,807][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ lot] are: tensor([0.0094, 0.0138, 0.2228, 0.0085, 0.1343, 0.2222, 0.1861, 0.2028],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:45,807][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ lot] are: tensor([3.7090e-04, 3.7905e-03, 1.1938e-02, 4.1524e-03, 4.6855e-02, 1.8474e-02,
        3.0396e-02, 8.8402e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:45,807][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ lot] are: tensor([0.0239, 0.0014, 0.0014, 0.0060, 0.0130, 0.3229, 0.6273, 0.0042],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:45,808][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ lot] are: tensor([0.0069, 0.0517, 0.2012, 0.0612, 0.0735, 0.1226, 0.2777, 0.2053],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:45,808][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ lot] are: tensor([0.0066, 0.0357, 0.1587, 0.0827, 0.1802, 0.0548, 0.2123, 0.2690],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:45,808][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ lot] are: tensor([0.0968, 0.0478, 0.0387, 0.0088, 0.0826, 0.4617, 0.0195, 0.2441],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:45,809][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ lot] are: tensor([0.0011, 0.0453, 0.2693, 0.0924, 0.1998, 0.1547, 0.2292, 0.0083],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:45,809][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ lot] are: tensor([0.0105, 0.2946, 0.0236, 0.2182, 0.0460, 0.0187, 0.2870, 0.1014],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:45,809][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ lot] are: tensor([0.0332, 0.0274, 0.1147, 0.0030, 0.1380, 0.2684, 0.0250, 0.3904],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:45,810][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ lot] are: tensor([0.1721, 0.0347, 0.0042, 0.0141, 0.2065, 0.2613, 0.2063, 0.1008],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:45,810][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ lot] are: tensor([0.0165, 0.0123, 0.0287, 0.0365, 0.0192, 0.0733, 0.8087, 0.0048],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot]
[2024-07-24 10:21:45,810][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([8.7263e-01, 1.0959e-01, 3.0010e-03, 6.3708e-04, 3.3098e-04, 1.2922e-03,
        2.0426e-03, 1.6328e-03, 8.8444e-03], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:45,812][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([0.1092, 0.0680, 0.7290, 0.0027, 0.0165, 0.0180, 0.0058, 0.0471, 0.0038],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:45,813][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([0.0007, 0.0332, 0.0824, 0.0018, 0.0263, 0.0260, 0.0123, 0.6562, 0.1612],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:45,814][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([0.0370, 0.0192, 0.0265, 0.0052, 0.0186, 0.3132, 0.1193, 0.0174, 0.4438],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:45,816][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([0.0053, 0.3000, 0.2264, 0.0299, 0.0305, 0.0904, 0.0731, 0.0730, 0.1714],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:45,817][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([0.0265, 0.2015, 0.1182, 0.0171, 0.0768, 0.0204, 0.0154, 0.2898, 0.2343],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:45,818][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([0.3484, 0.4033, 0.0787, 0.0019, 0.0196, 0.1047, 0.0009, 0.0397, 0.0029],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:45,820][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([0.0051, 0.3624, 0.3798, 0.0281, 0.1325, 0.0315, 0.0335, 0.0067, 0.0204],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:45,821][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([0.0030, 0.1779, 0.0096, 0.1312, 0.0462, 0.0133, 0.2809, 0.0231, 0.3147],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:45,822][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([8.1220e-01, 6.7246e-03, 1.1592e-01, 5.8254e-05, 1.9616e-02, 4.7028e-03,
        5.9656e-05, 4.0286e-02, 4.3567e-04], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:45,823][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([9.9373e-01, 1.8898e-03, 4.1179e-05, 3.0223e-05, 6.9752e-04, 5.2115e-04,
        5.5401e-05, 2.3933e-03, 6.4199e-04], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:45,824][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([0.1664, 0.1309, 0.3259, 0.0259, 0.0798, 0.0583, 0.0717, 0.0206, 0.1204],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of]
[2024-07-24 10:21:45,825][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ fun] are: tensor([7.3199e-01, 2.4425e-01, 8.3412e-03, 1.7637e-03, 2.7548e-04, 2.6560e-03,
        1.8753e-03, 2.3881e-03, 6.0053e-03, 4.5452e-04], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:45,827][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ fun] are: tensor([0.0035, 0.0205, 0.1705, 0.0193, 0.0365, 0.1127, 0.1603, 0.3626, 0.0259,
        0.0883], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:45,828][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ fun] are: tensor([5.3102e-05, 4.9182e-03, 4.5034e-02, 1.3414e-02, 4.2556e-02, 3.7996e-02,
        7.0987e-02, 6.4145e-01, 1.3296e-01, 1.0636e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:45,829][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ fun] are: tensor([0.0012, 0.0015, 0.0022, 0.0050, 0.0069, 0.2548, 0.0948, 0.0142, 0.5727,
        0.0467], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:45,830][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ fun] are: tensor([3.7684e-04, 1.0609e-01, 1.5865e-01, 2.6563e-02, 3.0267e-02, 4.6871e-02,
        1.0715e-01, 1.8512e-02, 1.1347e-01, 3.9204e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:45,831][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ fun] are: tensor([0.0023, 0.0128, 0.1550, 0.0239, 0.1149, 0.0190, 0.0761, 0.1766, 0.2870,
        0.1323], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:45,833][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ fun] are: tensor([0.1206, 0.1028, 0.1666, 0.0151, 0.0428, 0.3158, 0.0124, 0.1326, 0.0082,
        0.0831], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:45,834][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ fun] are: tensor([0.0004, 0.0076, 0.1825, 0.0239, 0.2605, 0.0957, 0.2461, 0.0261, 0.0365,
        0.1207], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:45,835][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ fun] are: tensor([0.0015, 0.1480, 0.0072, 0.0780, 0.0655, 0.0403, 0.0956, 0.0305, 0.2661,
        0.2673], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:45,837][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ fun] are: tensor([0.0414, 0.0062, 0.2652, 0.0009, 0.0873, 0.0820, 0.0093, 0.4795, 0.0071,
        0.0210], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:45,838][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ fun] are: tensor([0.4526, 0.0191, 0.0023, 0.0099, 0.0851, 0.1231, 0.0712, 0.1214, 0.1018,
        0.0135], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:45,840][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ fun] are: tensor([0.0061, 0.0156, 0.0759, 0.1187, 0.0410, 0.0229, 0.3260, 0.0136, 0.3594,
        0.0208], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun]
[2024-07-24 10:21:45,840][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([4.9670e-01, 4.6998e-01, 7.4649e-03, 1.6418e-03, 3.1485e-04, 2.0494e-03,
        1.9250e-03, 3.7727e-03, 1.1148e-02, 1.3526e-03, 3.6499e-03],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:45,842][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.0903, 0.0259, 0.3629, 0.0033, 0.0403, 0.0468, 0.0220, 0.1950, 0.0074,
        0.1930, 0.0133], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:45,843][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.0011, 0.0307, 0.0286, 0.0034, 0.0252, 0.0391, 0.0164, 0.6656, 0.1375,
        0.0364, 0.0162], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:45,845][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.0055, 0.0121, 0.0128, 0.0030, 0.0089, 0.3190, 0.0268, 0.0566, 0.1768,
        0.2536, 0.1249], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:45,846][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.0012, 0.2337, 0.1256, 0.0127, 0.0250, 0.0636, 0.0463, 0.0197, 0.0520,
        0.2940, 0.1262], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:45,848][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.0022, 0.1057, 0.0825, 0.0153, 0.0988, 0.0140, 0.0146, 0.1656, 0.1491,
        0.3284, 0.0239], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:45,849][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.1507, 0.4532, 0.0936, 0.0015, 0.0287, 0.1531, 0.0014, 0.0368, 0.0016,
        0.0705, 0.0088], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:45,850][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.0052, 0.1471, 0.2493, 0.0170, 0.2384, 0.0623, 0.0495, 0.0057, 0.0131,
        0.1571, 0.0554], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:45,852][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.0133, 0.2253, 0.0066, 0.0960, 0.0447, 0.0141, 0.0559, 0.0248, 0.0858,
        0.3422, 0.0913], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:45,853][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([3.8552e-01, 1.5815e-02, 2.6711e-01, 1.9668e-04, 1.1027e-01, 3.2221e-02,
        6.8358e-04, 1.4135e-01, 1.5555e-03, 4.4540e-02, 7.4356e-04],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:45,854][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([9.4261e-01, 8.2294e-03, 4.3284e-04, 3.6005e-04, 9.5465e-03, 2.8009e-03,
        4.4002e-04, 8.8341e-03, 2.7441e-03, 2.8992e-03, 2.1105e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:45,855][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.1156, 0.0775, 0.0869, 0.0528, 0.0804, 0.0233, 0.0850, 0.0318, 0.0740,
        0.1048, 0.2679], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at]
[2024-07-24 10:21:45,856][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([3.5606e-01, 5.3278e-01, 3.3843e-03, 1.6879e-03, 1.5050e-04, 2.4418e-03,
        3.3847e-03, 1.4998e-03, 2.9257e-02, 7.2629e-04, 3.6468e-03, 6.4984e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:45,857][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([6.5448e-03, 4.0927e-02, 9.1428e-01, 6.3502e-04, 5.2221e-03, 3.6420e-03,
        3.0357e-03, 8.3455e-03, 7.4738e-04, 8.8982e-03, 7.3358e-04, 6.9898e-03],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:45,858][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0004, 0.0985, 0.1506, 0.0030, 0.0213, 0.0228, 0.0123, 0.2631, 0.1808,
        0.0162, 0.0101, 0.2211], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:45,860][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0217, 0.0089, 0.0066, 0.0028, 0.0047, 0.0731, 0.0175, 0.0125, 0.1299,
        0.0593, 0.0460, 0.6170], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:45,861][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0011, 0.0609, 0.2077, 0.0133, 0.0166, 0.0401, 0.0429, 0.0283, 0.0709,
        0.1930, 0.0721, 0.2530], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:45,863][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.0062, 0.0915, 0.1387, 0.0178, 0.0575, 0.0077, 0.0232, 0.1248, 0.1247,
        0.2946, 0.0190, 0.0942], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:45,864][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.2328, 0.3571, 0.2689, 0.0009, 0.0192, 0.0580, 0.0008, 0.0281, 0.0007,
        0.0236, 0.0026, 0.0072], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:45,865][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0018, 0.2070, 0.5990, 0.0148, 0.0506, 0.0080, 0.0186, 0.0022, 0.0073,
        0.0579, 0.0192, 0.0137], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:45,865][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.4904, 0.2134, 0.0040, 0.0293, 0.0105, 0.0048, 0.0181, 0.0107, 0.0693,
        0.0533, 0.0333, 0.0627], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:45,866][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([4.9530e-01, 6.4501e-03, 2.3158e-01, 9.6158e-05, 4.1002e-02, 1.8451e-02,
        4.6662e-04, 1.5217e-01, 7.3344e-04, 5.1568e-02, 1.0580e-03, 1.1244e-03],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:45,866][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([9.8262e-01, 1.6928e-03, 1.2121e-04, 7.2701e-05, 1.3296e-03, 1.0080e-03,
        3.0614e-04, 2.8576e-03, 8.0617e-04, 4.2415e-04, 2.7680e-03, 5.9910e-03],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:45,866][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.1477, 0.0539, 0.0492, 0.0162, 0.0177, 0.0111, 0.0332, 0.0057, 0.0222,
        0.0223, 0.0316, 0.5892], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the]
[2024-07-24 10:21:45,867][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ hospital] are: tensor([8.9228e-01, 8.8004e-02, 1.2283e-03, 4.3849e-04, 2.5933e-04, 6.1715e-04,
        3.7632e-04, 2.8043e-04, 2.6522e-03, 3.2915e-04, 1.3157e-03, 5.7236e-03,
        6.4999e-03], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:45,867][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ hospital] are: tensor([0.0414, 0.2467, 0.2821, 0.0192, 0.0221, 0.0797, 0.0465, 0.1470, 0.0094,
        0.0201, 0.0053, 0.0416, 0.0389], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:45,868][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ hospital] are: tensor([0.0043, 0.1591, 0.0745, 0.0362, 0.0631, 0.0944, 0.0718, 0.2397, 0.1264,
        0.0209, 0.0132, 0.0501, 0.0463], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:45,868][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ hospital] are: tensor([0.0313, 0.0029, 0.0004, 0.0043, 0.0017, 0.0647, 0.0262, 0.0048, 0.3504,
        0.0125, 0.0439, 0.1803, 0.2766], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:45,870][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ hospital] are: tensor([0.0017, 0.2280, 0.0431, 0.0264, 0.0099, 0.0304, 0.0315, 0.0167, 0.0561,
        0.2191, 0.0593, 0.1136, 0.1641], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:45,871][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ hospital] are: tensor([0.0037, 0.0584, 0.0302, 0.0226, 0.0131, 0.0162, 0.0607, 0.0397, 0.1672,
        0.0866, 0.0307, 0.0588, 0.4120], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:45,872][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ hospital] are: tensor([0.4335, 0.2135, 0.0602, 0.0032, 0.0070, 0.0990, 0.0020, 0.0205, 0.0026,
        0.0249, 0.0151, 0.0111, 0.1075], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:45,874][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ hospital] are: tensor([0.0085, 0.0938, 0.3033, 0.0315, 0.0456, 0.1195, 0.1460, 0.0050, 0.0174,
        0.0727, 0.0657, 0.0172, 0.0740], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:45,875][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ hospital] are: tensor([0.0045, 0.6264, 0.0097, 0.0364, 0.0225, 0.0083, 0.0160, 0.0071, 0.0314,
        0.0286, 0.0216, 0.0175, 0.1700], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:45,877][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ hospital] are: tensor([0.0905, 0.0600, 0.3054, 0.0015, 0.0372, 0.0342, 0.0024, 0.1752, 0.0033,
        0.0242, 0.0043, 0.0013, 0.2605], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:45,878][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ hospital] are: tensor([8.2300e-01, 2.1997e-02, 7.2020e-04, 1.5754e-03, 1.8761e-02, 7.1979e-03,
        3.7976e-03, 3.6419e-03, 8.5909e-03, 8.1494e-04, 2.2993e-02, 4.1465e-02,
        4.5447e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:45,879][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ hospital] are: tensor([0.0197, 0.0320, 0.0279, 0.1676, 0.0267, 0.0108, 0.1029, 0.0026, 0.0626,
        0.0044, 0.0385, 0.4762, 0.0282], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital]
[2024-07-24 10:21:45,880][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([2.7427e-01, 6.0509e-01, 1.8356e-03, 2.3632e-03, 4.2499e-04, 2.3194e-03,
        1.2906e-03, 2.3319e-03, 1.3393e-02, 7.5764e-04, 5.6484e-03, 1.4654e-02,
        2.8574e-03, 7.2766e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:45,881][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.0620, 0.0948, 0.5319, 0.0041, 0.0192, 0.0319, 0.0205, 0.0954, 0.0029,
        0.0368, 0.0050, 0.0240, 0.0598, 0.0118], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:45,882][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([3.7960e-04, 2.4914e-02, 4.0748e-02, 2.8857e-03, 1.0421e-02, 3.2867e-02,
        1.5863e-02, 6.7512e-01, 6.7803e-02, 1.6867e-02, 1.1169e-02, 3.4113e-02,
        5.9813e-02, 7.0353e-03], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:45,883][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([1.3605e-01, 4.7882e-03, 1.2491e-03, 2.5403e-04, 9.0756e-04, 1.0379e-02,
        4.3103e-04, 1.9141e-03, 7.0378e-03, 7.3166e-03, 3.0589e-03, 1.1949e-02,
        7.8840e-01, 2.6264e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:45,884][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.0024, 0.1083, 0.0671, 0.0116, 0.0111, 0.0359, 0.0325, 0.0134, 0.0366,
        0.0799, 0.0404, 0.0618, 0.1935, 0.3054], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:45,886][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.0091, 0.0256, 0.0297, 0.0114, 0.0347, 0.0065, 0.0180, 0.1010, 0.1281,
        0.1320, 0.0305, 0.0295, 0.3059, 0.1380], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:45,887][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.2198, 0.5233, 0.0454, 0.0017, 0.0067, 0.0817, 0.0008, 0.0233, 0.0009,
        0.0217, 0.0026, 0.0027, 0.0528, 0.0168], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:45,889][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0030, 0.3205, 0.1824, 0.0195, 0.1093, 0.0618, 0.0554, 0.0032, 0.0112,
        0.0708, 0.0431, 0.0208, 0.0562, 0.0427], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:45,890][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.0025, 0.2746, 0.0047, 0.0301, 0.0140, 0.0014, 0.0042, 0.0058, 0.0055,
        0.0201, 0.0036, 0.0032, 0.0878, 0.5426], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:45,891][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([4.0448e-01, 7.9561e-03, 6.5715e-02, 1.4062e-04, 2.8376e-02, 1.0489e-02,
        3.1059e-04, 8.9060e-02, 6.4199e-04, 3.4519e-02, 7.5966e-04, 1.7166e-04,
        3.5526e-01, 2.1217e-03], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:45,892][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([9.8639e-01, 4.2294e-04, 9.8825e-06, 6.8243e-06, 1.7006e-04, 5.5180e-05,
        8.4742e-06, 1.2018e-04, 2.2161e-05, 2.0495e-05, 1.0900e-04, 6.7839e-05,
        5.7759e-04, 1.2017e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:45,894][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.0597, 0.1745, 0.0442, 0.0284, 0.0286, 0.0034, 0.0080, 0.0011, 0.0039,
        0.0087, 0.0103, 0.0509, 0.1924, 0.3861], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital.]
[2024-07-24 10:21:45,895][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Anthony] are: tensor([6.9959e-01, 2.3689e-01, 4.9700e-03, 6.9858e-04, 1.5356e-04, 1.5243e-03,
        1.1591e-03, 1.2686e-03, 9.2332e-03, 6.6976e-04, 2.8826e-03, 1.5668e-02,
        5.1554e-03, 1.6317e-02, 3.8120e-03], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:45,896][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Anthony] are: tensor([0.1223, 0.0620, 0.4867, 0.0046, 0.0129, 0.0318, 0.0084, 0.0768, 0.0060,
        0.0398, 0.0039, 0.0186, 0.0618, 0.0139, 0.0505], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:45,897][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Anthony] are: tensor([0.0029, 0.0277, 0.0655, 0.0047, 0.0110, 0.0344, 0.0098, 0.5345, 0.0880,
        0.0205, 0.0063, 0.0346, 0.0576, 0.0105, 0.0921], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:45,898][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Anthony] are: tensor([1.1795e-02, 2.6171e-03, 1.3825e-03, 4.3663e-04, 9.3834e-04, 1.0241e-02,
        1.8488e-03, 2.5018e-04, 3.0563e-02, 3.4853e-03, 8.5435e-03, 3.7302e-02,
        6.1877e-01, 7.2224e-02, 1.9961e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:45,900][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Anthony] are: tensor([0.0017, 0.0638, 0.0574, 0.0108, 0.0055, 0.0220, 0.0143, 0.0152, 0.0369,
        0.1346, 0.0446, 0.1250, 0.0815, 0.2924, 0.0942], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:45,901][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Anthony] are: tensor([0.0072, 0.0230, 0.0240, 0.0118, 0.0163, 0.0090, 0.0132, 0.0772, 0.2039,
        0.1000, 0.0459, 0.0539, 0.2687, 0.0909, 0.0551], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:45,902][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Anthony] are: tensor([5.5763e-01, 2.2595e-01, 2.9170e-02, 1.0494e-03, 2.1300e-03, 5.1859e-02,
        3.4596e-04, 1.2955e-02, 8.0141e-04, 1.2755e-02, 2.1801e-03, 2.5418e-03,
        7.3931e-02, 1.4914e-02, 1.1790e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:45,903][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Anthony] are: tensor([0.0119, 0.1536, 0.4224, 0.0210, 0.0530, 0.0318, 0.0228, 0.0052, 0.0108,
        0.0672, 0.0164, 0.0189, 0.0740, 0.0340, 0.0570], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:45,905][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Anthony] are: tensor([0.0007, 0.2243, 0.0053, 0.0103, 0.0126, 0.0022, 0.0051, 0.0012, 0.0118,
        0.0118, 0.0052, 0.0145, 0.0579, 0.5338, 0.1032], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:45,906][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Anthony] are: tensor([4.5406e-01, 1.1695e-02, 6.4388e-02, 2.0384e-04, 4.9960e-03, 1.6132e-02,
        2.9307e-04, 3.3981e-02, 8.6974e-04, 2.2613e-02, 7.0000e-04, 5.6002e-04,
        3.6371e-01, 3.0238e-03, 2.2777e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:45,907][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Anthony] are: tensor([8.9331e-01, 3.7480e-03, 1.3228e-04, 9.9294e-05, 2.1333e-03, 8.6651e-04,
        1.5740e-04, 4.9094e-04, 7.0768e-04, 2.9816e-04, 1.4314e-03, 1.8546e-03,
        1.4665e-02, 5.9763e-02, 2.0339e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:45,908][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Anthony] are: tensor([0.0874, 0.0184, 0.0323, 0.0172, 0.0099, 0.0044, 0.0123, 0.0041, 0.0122,
        0.0058, 0.0084, 0.1046, 0.1319, 0.3305, 0.2204], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony]
[2024-07-24 10:21:45,909][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([2.4357e-01, 2.2546e-01, 1.7883e-03, 3.4141e-04, 2.9376e-04, 5.8343e-04,
        9.7136e-05, 2.7465e-04, 2.1824e-03, 5.1275e-04, 2.4277e-03, 3.3218e-03,
        2.6648e-03, 3.2839e-02, 3.0695e-03, 4.8058e-01], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:45,910][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0103, 0.0838, 0.4270, 0.0065, 0.0192, 0.0408, 0.0246, 0.0844, 0.0045,
        0.0541, 0.0042, 0.0233, 0.0491, 0.0152, 0.0864, 0.0665],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:45,911][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([3.0649e-04, 5.3638e-02, 4.1950e-01, 7.7005e-03, 4.9761e-02, 1.5570e-02,
        5.5028e-03, 1.6332e-01, 2.0761e-02, 6.9486e-03, 7.1566e-03, 3.0806e-02,
        3.4933e-02, 1.7990e-02, 1.6551e-01, 5.9667e-04], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:45,912][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([1.4791e-02, 5.5209e-04, 2.5206e-04, 1.1190e-04, 2.4393e-04, 1.0121e-02,
        3.8067e-03, 4.7546e-04, 1.9744e-02, 6.8899e-03, 6.8692e-03, 3.8001e-02,
        5.2040e-01, 9.6064e-02, 2.4491e-01, 3.6770e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:45,913][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.0010, 0.0396, 0.1116, 0.0244, 0.0077, 0.0309, 0.0435, 0.0121, 0.0346,
        0.1287, 0.0865, 0.1852, 0.0760, 0.1221, 0.0777, 0.0183],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:45,915][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.0014, 0.0160, 0.0302, 0.0176, 0.0147, 0.0174, 0.0393, 0.0482, 0.1809,
        0.1086, 0.0610, 0.0704, 0.1159, 0.0891, 0.1637, 0.0255],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:45,916][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.0966, 0.3202, 0.1310, 0.0029, 0.0110, 0.0806, 0.0024, 0.0239, 0.0023,
        0.0355, 0.0075, 0.0120, 0.0703, 0.0261, 0.0284, 0.1494],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:45,918][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0004, 0.0713, 0.1099, 0.0265, 0.1711, 0.0671, 0.0975, 0.0022, 0.0153,
        0.0345, 0.0680, 0.0573, 0.0551, 0.0454, 0.0346, 0.1438],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:45,919][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.0006, 0.2010, 0.0029, 0.0090, 0.0038, 0.0008, 0.0018, 0.0031, 0.0073,
        0.0461, 0.0094, 0.0074, 0.1386, 0.4835, 0.0551, 0.0297],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:45,920][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([1.1078e-02, 1.4800e-03, 9.9130e-02, 1.3421e-04, 1.9445e-02, 2.0487e-02,
        1.3706e-03, 9.7574e-02, 2.6385e-03, 5.0038e-02, 4.7120e-03, 1.2462e-03,
        4.8296e-01, 2.8518e-03, 1.8740e-01, 1.7449e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:45,922][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.4048, 0.0166, 0.0007, 0.0005, 0.0344, 0.0055, 0.0006, 0.0006, 0.0009,
        0.0006, 0.0028, 0.0072, 0.0195, 0.3218, 0.1004, 0.0831],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:45,923][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.1318, 0.0383, 0.0142, 0.0106, 0.0256, 0.0096, 0.0212, 0.0018, 0.0243,
        0.0126, 0.0286, 0.1454, 0.1120, 0.1179, 0.2279, 0.0781],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave]
[2024-07-24 10:21:45,924][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([4.6756e-01, 1.5751e-01, 1.4681e-03, 1.0050e-03, 1.2991e-04, 1.7169e-03,
        2.4494e-03, 1.7989e-03, 1.9757e-02, 8.0028e-04, 4.8295e-03, 4.3096e-02,
        5.0942e-03, 4.9627e-02, 1.9605e-03, 1.9864e-01, 4.2550e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:45,925][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0347, 0.0477, 0.5920, 0.0028, 0.0128, 0.0107, 0.0097, 0.0323, 0.0030,
        0.0418, 0.0030, 0.0198, 0.0516, 0.0064, 0.0301, 0.0862, 0.0155],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:45,926][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([3.7696e-04, 1.3855e-02, 8.5439e-02, 3.6450e-03, 1.2664e-02, 1.6194e-02,
        8.1221e-03, 5.1423e-01, 7.3244e-02, 1.3283e-02, 6.4709e-03, 6.8718e-02,
        7.1964e-02, 7.3729e-03, 9.7735e-02, 2.8359e-03, 3.8517e-03],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:45,927][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([3.8144e-02, 1.7225e-03, 1.5078e-03, 5.6480e-04, 4.7175e-04, 6.1175e-03,
        1.1134e-03, 4.3161e-03, 1.2001e-02, 8.3826e-03, 4.1893e-03, 3.6882e-02,
        7.0831e-01, 3.4380e-02, 9.7938e-02, 2.1712e-02, 2.2249e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:45,928][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0007, 0.0181, 0.0679, 0.0056, 0.0111, 0.0130, 0.0105, 0.0264, 0.0224,
        0.1448, 0.0332, 0.1187, 0.1250, 0.2024, 0.1234, 0.0059, 0.0708],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:45,929][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0138, 0.0097, 0.0513, 0.0107, 0.0412, 0.0068, 0.0078, 0.1461, 0.0980,
        0.1358, 0.0197, 0.0415, 0.2197, 0.0559, 0.0486, 0.0389, 0.0546],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:45,929][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.1898, 0.2026, 0.1296, 0.0015, 0.0065, 0.0445, 0.0008, 0.0155, 0.0008,
        0.0213, 0.0021, 0.0056, 0.0721, 0.0124, 0.0094, 0.2798, 0.0056],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:45,930][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0044, 0.0488, 0.3443, 0.0078, 0.0661, 0.0138, 0.0197, 0.0016, 0.0083,
        0.0631, 0.0220, 0.0270, 0.0570, 0.0067, 0.0125, 0.1140, 0.1829],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:45,930][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0788, 0.1292, 0.0137, 0.0233, 0.0218, 0.0049, 0.0099, 0.0047, 0.0242,
        0.0200, 0.0097, 0.0369, 0.0987, 0.3380, 0.1054, 0.0134, 0.0672],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:45,930][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([3.1046e-01, 9.9953e-04, 6.5079e-02, 3.4039e-05, 5.0790e-03, 3.4788e-03,
        1.0468e-04, 3.2569e-02, 6.5311e-04, 1.5445e-02, 4.3169e-04, 3.0335e-04,
        5.1162e-01, 1.5628e-03, 2.0091e-02, 3.0797e-02, 1.2876e-03],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:45,931][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([9.0378e-01, 6.1097e-04, 8.8023e-05, 5.9535e-05, 9.9647e-04, 6.1719e-04,
        3.6882e-04, 1.2913e-03, 6.4611e-04, 1.4288e-04, 1.0885e-03, 4.5363e-03,
        8.7895e-03, 3.7822e-02, 1.2781e-02, 3.9242e-03, 2.2459e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:45,931][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0413, 0.0155, 0.0292, 0.0116, 0.0096, 0.0013, 0.0089, 0.0016, 0.0046,
        0.0068, 0.0054, 0.1311, 0.0675, 0.1456, 0.0934, 0.0046, 0.4219],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a]
[2024-07-24 10:21:45,931][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ drink] are: tensor([6.1692e-01, 1.6593e-01, 2.3591e-03, 3.5899e-04, 1.5697e-04, 1.2320e-03,
        3.2555e-04, 5.4738e-04, 3.8500e-03, 6.0582e-04, 1.6900e-03, 5.7013e-03,
        2.7735e-03, 1.7068e-02, 2.4037e-03, 1.5488e-01, 1.4263e-02, 8.9380e-03],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:45,932][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ drink] are: tensor([0.0216, 0.0373, 0.5044, 0.0096, 0.0284, 0.0440, 0.0281, 0.0575, 0.0081,
        0.0304, 0.0043, 0.0260, 0.0331, 0.0100, 0.0414, 0.0594, 0.0157, 0.0407],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:45,934][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ drink] are: tensor([0.0015, 0.0340, 0.2529, 0.0148, 0.0309, 0.0127, 0.0084, 0.4042, 0.0538,
        0.0149, 0.0061, 0.0140, 0.0133, 0.0082, 0.1246, 0.0012, 0.0030, 0.0016],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:45,935][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ drink] are: tensor([0.0385, 0.0025, 0.0010, 0.0007, 0.0008, 0.0104, 0.0077, 0.0011, 0.0695,
        0.0048, 0.0118, 0.0495, 0.1644, 0.1447, 0.1745, 0.0475, 0.2087, 0.0621],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:45,936][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ drink] are: tensor([0.0009, 0.0576, 0.0777, 0.0152, 0.0079, 0.0107, 0.0166, 0.0080, 0.0310,
        0.1812, 0.0429, 0.0847, 0.0670, 0.1810, 0.0965, 0.0129, 0.0575, 0.0506],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:45,938][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ drink] are: tensor([0.0027, 0.0145, 0.1118, 0.0160, 0.0284, 0.0085, 0.0153, 0.2076, 0.1141,
        0.0562, 0.0495, 0.0433, 0.0716, 0.0366, 0.0676, 0.0197, 0.0387, 0.0981],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:45,939][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ drink] are: tensor([0.2848, 0.2870, 0.0458, 0.0047, 0.0047, 0.0552, 0.0011, 0.0126, 0.0019,
        0.0330, 0.0056, 0.0054, 0.0401, 0.0148, 0.0041, 0.1508, 0.0062, 0.0422],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:45,941][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ drink] are: tensor([0.0057, 0.0250, 0.2287, 0.0262, 0.0652, 0.0498, 0.0289, 0.0044, 0.0112,
        0.0537, 0.0205, 0.0399, 0.0454, 0.0156, 0.0249, 0.0700, 0.1886, 0.0963],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:45,942][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ drink] are: tensor([0.0010, 0.0429, 0.0019, 0.0032, 0.0048, 0.0012, 0.0033, 0.0011, 0.0098,
        0.0158, 0.0096, 0.0056, 0.0299, 0.3052, 0.0662, 0.0096, 0.0437, 0.4450],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:45,943][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ drink] are: tensor([7.9753e-02, 5.5017e-03, 3.0586e-01, 2.5425e-04, 1.7957e-02, 9.7815e-03,
        9.2879e-04, 1.8883e-01, 1.5292e-03, 3.4981e-02, 2.7837e-03, 4.3645e-04,
        2.5967e-01, 1.0361e-03, 4.2021e-02, 1.7636e-02, 1.6812e-03, 2.9362e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:45,944][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ drink] are: tensor([6.7240e-01, 3.0407e-03, 4.3352e-04, 3.9518e-04, 2.6186e-03, 1.2773e-03,
        1.0015e-03, 4.5043e-04, 2.5383e-03, 2.9560e-04, 3.3843e-03, 5.1060e-03,
        8.5802e-03, 1.1659e-01, 4.8233e-02, 7.4752e-03, 4.0504e-02, 8.5673e-02],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:45,945][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ drink] are: tensor([0.0456, 0.0038, 0.0233, 0.0164, 0.0037, 0.0009, 0.0161, 0.0019, 0.0109,
        0.0024, 0.0117, 0.0400, 0.0113, 0.0501, 0.0460, 0.0038, 0.7018, 0.0102],
       device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink]
[2024-07-24 10:21:45,946][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([3.1332e-01, 1.3014e-01, 2.0122e-03, 1.3713e-03, 2.3558e-04, 1.3065e-03,
        1.6896e-03, 2.0448e-03, 1.9273e-02, 9.8909e-04, 7.0002e-03, 3.5008e-02,
        3.1469e-03, 6.9322e-02, 2.9551e-03, 2.9034e-01, 6.2573e-02, 1.2242e-02,
        4.5023e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:45,948][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0597, 0.0370, 0.4197, 0.0031, 0.0176, 0.0342, 0.0157, 0.0716, 0.0032,
        0.0411, 0.0053, 0.0228, 0.0464, 0.0068, 0.0571, 0.0984, 0.0160, 0.0427,
        0.0016], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:45,949][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([3.5694e-04, 1.8025e-03, 1.8783e-02, 1.3898e-03, 7.7387e-03, 1.4590e-02,
        1.1174e-02, 7.6012e-01, 4.8308e-02, 1.3867e-02, 7.4915e-03, 1.6052e-02,
        2.5761e-02, 2.6322e-03, 6.3700e-02, 1.7364e-03, 2.3572e-03, 1.3676e-03,
        7.7017e-04], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:45,950][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([7.5712e-02, 2.7309e-03, 4.1115e-03, 1.7664e-04, 9.5643e-04, 1.0069e-02,
        7.6666e-04, 9.8685e-04, 6.2152e-03, 9.7479e-03, 2.9969e-03, 1.2299e-02,
        5.6451e-01, 1.6690e-02, 1.6177e-01, 1.3807e-02, 1.3762e-02, 6.0804e-02,
        4.1890e-02], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:45,951][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0016, 0.0506, 0.0808, 0.0054, 0.0090, 0.0232, 0.0263, 0.0110, 0.0223,
        0.0780, 0.0348, 0.0701, 0.1497, 0.2008, 0.1317, 0.0047, 0.0500, 0.0208,
        0.0292], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:45,953][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0238, 0.0248, 0.0831, 0.0103, 0.0233, 0.0085, 0.0181, 0.0712, 0.1408,
        0.0815, 0.0406, 0.0302, 0.2055, 0.0378, 0.0724, 0.0234, 0.0415, 0.0499,
        0.0133], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:45,954][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.2839, 0.3048, 0.0665, 0.0017, 0.0040, 0.0734, 0.0011, 0.0176, 0.0011,
        0.0210, 0.0026, 0.0029, 0.0627, 0.0079, 0.0087, 0.1129, 0.0023, 0.0229,
        0.0019], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:45,956][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0090, 0.0986, 0.1636, 0.0082, 0.0536, 0.0473, 0.0284, 0.0020, 0.0106,
        0.0530, 0.0340, 0.0242, 0.0628, 0.0150, 0.0188, 0.1412, 0.1784, 0.0377,
        0.0134], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:45,957][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0040, 0.0578, 0.0028, 0.0097, 0.0041, 0.0008, 0.0029, 0.0027, 0.0055,
        0.0172, 0.0038, 0.0057, 0.0647, 0.3302, 0.0422, 0.0051, 0.0215, 0.2911,
        0.1282], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:45,958][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([4.0561e-01, 1.4313e-03, 7.7955e-02, 5.0577e-05, 6.3707e-03, 6.4068e-03,
        2.6745e-04, 2.5796e-02, 5.3395e-04, 1.3807e-02, 6.4620e-04, 1.3417e-04,
        3.7411e-01, 5.5669e-04, 2.6556e-02, 1.7725e-02, 7.6518e-04, 4.0932e-02,
        3.4177e-04], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:45,959][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([9.7084e-01, 6.5023e-04, 3.4945e-05, 1.5281e-05, 2.2140e-04, 1.5283e-04,
        3.4231e-05, 1.5448e-04, 6.4518e-05, 4.3464e-05, 2.3738e-04, 2.1924e-04,
        1.3847e-03, 1.2213e-02, 4.7037e-03, 9.3652e-04, 1.8750e-03, 3.1701e-03,
        3.0525e-03], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:45,961][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0146, 0.0213, 0.0327, 0.0089, 0.0084, 0.0011, 0.0056, 0.0011, 0.0020,
        0.0082, 0.0069, 0.0300, 0.1382, 0.0954, 0.1697, 0.0060, 0.2850, 0.0702,
        0.0947], device='cuda:0') for source tokens [Then, Anthony and Travis had a lot of fun at the hospital. Anthony gave a drink to]
[2024-07-24 10:21:45,962][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:21:45,963][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[895],
        [  6],
        [ 22],
        [ 36],
        [103],
        [ 12],
        [119],
        [  2],
        [  5],
        [  4],
        [ 33],
        [ 42],
        [  1],
        [ 12],
        [ 21],
        [ 26],
        [ 39],
        [  2],
        [  1]], device='cuda:0')
[2024-07-24 10:21:45,965][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[1112],
        [   1],
        [   3],
        [   1],
        [  50],
        [   2],
        [  25],
        [   2],
        [   1],
        [   3],
        [  18],
        [  12],
        [   3],
        [  12],
        [  25],
        [  22],
        [  20],
        [   5],
        [   2]], device='cuda:0')
[2024-07-24 10:21:45,966][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[ 8573],
        [24704],
        [24438],
        [22876],
        [20371],
        [22422],
        [19685],
        [17678],
        [13506],
        [18828],
        [21241],
        [15926],
        [12220],
        [18348],
        [16323],
        [23218],
        [15431],
        [19600],
        [16362]], device='cuda:0')
[2024-07-24 10:21:45,968][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[ 5057],
        [28892],
        [49697],
        [49667],
        [49744],
        [49660],
        [49694],
        [47685],
        [49564],
        [44862],
        [47968],
        [49653],
        [46915],
        [49169],
        [49199],
        [48886],
        [49307],
        [49347],
        [49073]], device='cuda:0')
[2024-07-24 10:21:45,969][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[  112],
        [ 3206],
        [ 1660],
        [ 2756],
        [11782],
        [14604],
        [12033],
        [ 3457],
        [ 3803],
        [ 3583],
        [ 3394],
        [ 3251],
        [ 3141],
        [ 2912],
        [ 2765],
        [ 3240],
        [ 3205],
        [ 3289],
        [ 2874]], device='cuda:0')
[2024-07-24 10:21:45,971][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[31504],
        [17214],
        [15148],
        [12495],
        [ 2432],
        [ 3842],
        [ 4745],
        [ 5474],
        [ 6022],
        [ 8348],
        [ 8865],
        [ 9144],
        [10262],
        [10214],
        [10882],
        [11870],
        [11280],
        [12312],
        [11173]], device='cuda:0')
[2024-07-24 10:21:45,972][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[6351],
        [4307],
        [ 705],
        [ 897],
        [1003],
        [1000],
        [ 800],
        [1143],
        [ 760],
        [ 811],
        [ 902],
        [2609],
        [2099],
        [2619],
        [1777],
        [2220],
        [1979],
        [1436],
        [1596]], device='cuda:0')
[2024-07-24 10:21:45,974][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[27230],
        [ 6623],
        [ 1306],
        [ 1769],
        [ 1069],
        [ 1083],
        [ 1046],
        [ 1910],
        [ 2928],
        [ 2121],
        [ 2940],
        [ 2704],
        [ 2996],
        [ 3240],
        [ 2966],
        [ 2360],
        [ 2926],
        [ 2992],
        [ 2492]], device='cuda:0')
[2024-07-24 10:21:45,975][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[27310],
        [31170],
        [49625],
        [48608],
        [43582],
        [45608],
        [46780],
        [40379],
        [40390],
        [45267],
        [41232],
        [46809],
        [40516],
        [36040],
        [37718],
        [40328],
        [37539],
        [32756],
        [36312]], device='cuda:0')
[2024-07-24 10:21:45,977][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[49555],
        [46906],
        [49215],
        [49332],
        [49234],
        [48796],
        [49072],
        [47864],
        [48943],
        [47532],
        [48295],
        [49189],
        [48437],
        [48314],
        [49143],
        [47575],
        [48595],
        [47992],
        [48034]], device='cuda:0')
[2024-07-24 10:21:45,978][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[10698],
        [10684],
        [10520],
        [10617],
        [10524],
        [10525],
        [10646],
        [10163],
        [ 9002],
        [10590],
        [10315],
        [10595],
        [10789],
        [11424],
        [ 7761],
        [10523],
        [10363],
        [ 8438],
        [10127]], device='cuda:0')
[2024-07-24 10:21:45,980][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[13473],
        [12629],
        [ 8167],
        [11518],
        [ 9822],
        [13319],
        [12494],
        [16578],
        [10375],
        [12147],
        [13060],
        [10153],
        [ 7822],
        [ 7134],
        [ 6421],
        [ 6929],
        [ 6019],
        [ 6920],
        [ 5861]], device='cuda:0')
[2024-07-24 10:21:45,981][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[47945],
        [41969],
        [10690],
        [47818],
        [ 1762],
        [25455],
        [47760],
        [  431],
        [47698],
        [ 3497],
        [41796],
        [47329],
        [34024],
        [47625],
        [42067],
        [ 8686],
        [44445],
        [37721],
        [47456]], device='cuda:0')
[2024-07-24 10:21:45,983][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[41338],
        [48043],
        [49952],
        [50010],
        [50181],
        [50200],
        [50110],
        [49245],
        [50116],
        [49960],
        [50130],
        [49202],
        [49705],
        [50138],
        [50152],
        [50099],
        [49807],
        [49222],
        [50016]], device='cuda:0')
[2024-07-24 10:21:45,984][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[13523],
        [ 2104],
        [ 2936],
        [ 9592],
        [ 9112],
        [ 8818],
        [ 6507],
        [ 7043],
        [ 6561],
        [ 6118],
        [ 6100],
        [ 5573],
        [ 8245],
        [ 3361],
        [ 1225],
        [ 5061],
        [ 6399],
        [ 3463],
        [ 5491]], device='cuda:0')
[2024-07-24 10:21:45,986][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[20697],
        [25671],
        [26192],
        [26142],
        [22918],
        [25580],
        [24867],
        [22400],
        [22675],
        [24348],
        [25962],
        [27066],
        [22569],
        [28178],
        [25853],
        [33637],
        [32993],
        [30912],
        [34682]], device='cuda:0')
[2024-07-24 10:21:45,987][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[14589],
        [ 8330],
        [ 9031],
        [ 8990],
        [10660],
        [12265],
        [ 9758],
        [21319],
        [ 9846],
        [21061],
        [15985],
        [ 9289],
        [13467],
        [11953],
        [12405],
        [13418],
        [11313],
        [12369],
        [12624]], device='cuda:0')
[2024-07-24 10:21:45,989][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[37622],
        [15834],
        [25696],
        [24311],
        [24552],
        [26810],
        [24505],
        [33852],
        [32073],
        [32176],
        [32230],
        [27435],
        [27338],
        [32583],
        [30899],
        [26704],
        [30796],
        [28740],
        [33006]], device='cuda:0')
[2024-07-24 10:21:45,990][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[ 7561],
        [10204],
        [18397],
        [20746],
        [22966],
        [22411],
        [22518],
        [22765],
        [20251],
        [19571],
        [20896],
        [19659],
        [18274],
        [18271],
        [20562],
        [21104],
        [19377],
        [19571],
        [20404]], device='cuda:0')
[2024-07-24 10:21:45,991][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[23014],
        [ 3649],
        [18256],
        [14992],
        [ 9350],
        [ 9608],
        [10809],
        [ 9842],
        [10077],
        [11685],
        [10734],
        [12508],
        [ 9631],
        [ 9250],
        [10262],
        [11782],
        [11559],
        [11617],
        [11577]], device='cuda:0')
[2024-07-24 10:21:45,992][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[ 7626],
        [13297],
        [19655],
        [18773],
        [17208],
        [17243],
        [15856],
        [12720],
        [ 9621],
        [12026],
        [12717],
        [14558],
        [18760],
        [17128],
        [16559],
        [16404],
        [16421],
        [14178],
        [17641]], device='cuda:0')
[2024-07-24 10:21:45,993][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[7827],
        [3956],
        [3785],
        [3902],
        [4371],
        [4384],
        [4194],
        [6900],
        [4872],
        [5722],
        [5051],
        [4703],
        [4229],
        [4911],
        [3877],
        [4821],
        [5141],
        [5054],
        [4763]], device='cuda:0')
[2024-07-24 10:21:45,994][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[22469],
        [24952],
        [29149],
        [29795],
        [30483],
        [29783],
        [30799],
        [31393],
        [30085],
        [28472],
        [27417],
        [29375],
        [28612],
        [26939],
        [28162],
        [28394],
        [30008],
        [28230],
        [28524]], device='cuda:0')
[2024-07-24 10:21:45,996][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[20527],
        [25668],
        [24631],
        [24687],
        [23155],
        [22965],
        [17709],
        [19712],
        [19462],
        [18849],
        [18657],
        [18751],
        [21092],
        [19384],
        [19151],
        [18936],
        [17898],
        [18801],
        [18860]], device='cuda:0')
[2024-07-24 10:21:45,997][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[17415],
        [19993],
        [18632],
        [19402],
        [18863],
        [15163],
        [19894],
        [16116],
        [17209],
        [21318],
        [18100],
        [20207],
        [20996],
        [22503],
        [22620],
        [22862],
        [23192],
        [22821],
        [24336]], device='cuda:0')
[2024-07-24 10:21:45,999][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[ 3851],
        [ 6003],
        [19268],
        [ 3873],
        [ 5825],
        [ 4551],
        [ 3845],
        [12502],
        [ 3772],
        [ 7498],
        [ 3579],
        [ 3646],
        [ 4003],
        [ 3708],
        [ 3499],
        [10187],
        [ 3404],
        [ 6709],
        [ 3488]], device='cuda:0')
[2024-07-24 10:21:46,000][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 5549],
        [30786],
        [21373],
        [22198],
        [22477],
        [22244],
        [22393],
        [24648],
        [21011],
        [19245],
        [18264],
        [25951],
        [25051],
        [16704],
        [13795],
        [16704],
        [20521],
        [23292],
        [18381]], device='cuda:0')
[2024-07-24 10:21:46,002][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[32711],
        [31965],
        [19981],
        [28014],
        [24629],
        [25895],
        [28149],
        [17487],
        [29863],
        [21823],
        [28337],
        [28817],
        [26359],
        [27763],
        [26753],
        [19912],
        [25425],
        [22858],
        [25563]], device='cuda:0')
[2024-07-24 10:21:46,003][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[34189],
        [36749],
        [34662],
        [28344],
        [31987],
        [33046],
        [36231],
        [35281],
        [35854],
        [36479],
        [35424],
        [36323],
        [32883],
        [35437],
        [40949],
        [33461],
        [33763],
        [35956],
        [32946]], device='cuda:0')
[2024-07-24 10:21:46,005][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[20058],
        [20058],
        [20058],
        [20058],
        [20058],
        [20058],
        [20058],
        [20058],
        [20058],
        [20058],
        [20058],
        [20058],
        [20058],
        [20058],
        [20058],
        [20058],
        [20058],
        [20058],
        [20058]], device='cuda:0')
