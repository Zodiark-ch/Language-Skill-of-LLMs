[2024-07-24 10:28:59,483][explain_satisfiability.py][line:287][INFO] ############ CASE TEXT isAfter Amanda and John went to the station, John gave a ring to
[2024-07-24 10:28:59,483][explain_satisfiability.py][line:288][INFO] ############ CASE Prediction is  Amanda
[2024-07-24 10:28:59,484][explain_satisfiability.py][line:289][INFO] ############ Refined Forward Graph
[2024-07-24 10:28:59,484][explain_satisfiability.py][line:290][INFO] ****** Layer 1
[2024-07-24 10:28:59,484][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 0
[2024-07-24 10:28:59,484][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,485][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 1
[2024-07-24 10:28:59,485][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,485][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 2
[2024-07-24 10:28:59,485][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,486][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 3
[2024-07-24 10:28:59,486][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:28:59,486][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 4
[2024-07-24 10:28:59,487][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit26']
[2024-07-24 10:28:59,487][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 5
[2024-07-24 10:28:59,487][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:28:59,487][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 6
[2024-07-24 10:28:59,488][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:28:59,488][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 7
[2024-07-24 10:28:59,488][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:28:59,488][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 8
[2024-07-24 10:28:59,488][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:28:59,489][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 9
[2024-07-24 10:28:59,489][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:28:59,489][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 10
[2024-07-24 10:28:59,489][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit26', 'circuit27']
[2024-07-24 10:28:59,489][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 11
[2024-07-24 10:28:59,489][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:28:59,490][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 12
[2024-07-24 10:28:59,490][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,490][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 13
[2024-07-24 10:28:59,490][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,490][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 14
[2024-07-24 10:28:59,490][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit4', 'circuit5', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit22']
[2024-07-24 10:28:59,491][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 15
[2024-07-24 10:28:59,491][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:28:59,491][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 16
[2024-07-24 10:28:59,491][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit5', 'circuit7', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:28:59,491][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 17
[2024-07-24 10:28:59,492][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit27']
[2024-07-24 10:28:59,492][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 18
[2024-07-24 10:28:59,492][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:28:59,493][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 19
[2024-07-24 10:28:59,493][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:28:59,493][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 20
[2024-07-24 10:28:59,493][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit26']
[2024-07-24 10:28:59,494][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 21
[2024-07-24 10:28:59,494][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:28:59,494][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 22
[2024-07-24 10:28:59,494][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:28:59,494][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 23
[2024-07-24 10:28:59,494][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit15', 'circuit17', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:28:59,495][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 24
[2024-07-24 10:28:59,495][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,495][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 25
[2024-07-24 10:28:59,495][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:28:59,495][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 26
[2024-07-24 10:28:59,495][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,495][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 27
[2024-07-24 10:28:59,496][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,496][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 28
[2024-07-24 10:28:59,496][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,496][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 0
[2024-07-24 10:28:59,496][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,496][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,497][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 1
[2024-07-24 10:28:59,497][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:28:59,497][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit10', 'circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:28:59,497][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 2
[2024-07-24 10:28:59,497][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit7', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:28:59,497][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit20']
[2024-07-24 10:28:59,498][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 3
[2024-07-24 10:28:59,498][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:28:59,498][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit23']
[2024-07-24 10:28:59,498][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 4
[2024-07-24 10:28:59,498][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit26', 'circuit27']
[2024-07-24 10:28:59,498][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:28:59,498][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 5
[2024-07-24 10:28:59,499][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit24']
[2024-07-24 10:28:59,499][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,499][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 6
[2024-07-24 10:28:59,499][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:28:59,499][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:28:59,499][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 7
[2024-07-24 10:28:59,500][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,500][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit13', 'circuit15', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:28:59,500][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 8
[2024-07-24 10:28:59,500][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:28:59,500][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,500][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 9
[2024-07-24 10:28:59,500][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:28:59,501][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,501][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 10
[2024-07-24 10:28:59,501][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit18', 'circuit20', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:28:59,501][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:28:59,501][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 11
[2024-07-24 10:28:59,501][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit23', 'circuit26']
[2024-07-24 10:28:59,502][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit23']
[2024-07-24 10:28:59,502][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 12
[2024-07-24 10:28:59,502][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit21', 'circuit27']
[2024-07-24 10:28:59,502][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit7', 'circuit11', 'circuit16', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:28:59,502][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 13
[2024-07-24 10:28:59,502][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,502][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,503][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 14
[2024-07-24 10:28:59,503][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:28:59,503][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit23', 'circuit24']
[2024-07-24 10:28:59,503][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 15
[2024-07-24 10:28:59,503][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:28:59,503][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit9', 'circuit13', 'circuit16', 'circuit20', 'circuit25', 'circuit26']
[2024-07-24 10:28:59,503][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 16
[2024-07-24 10:28:59,504][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit4', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:28:59,504][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit5', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:28:59,504][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 17
[2024-07-24 10:28:59,504][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:28:59,504][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:28:59,504][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 18
[2024-07-24 10:28:59,505][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit18', 'circuit19', 'circuit24']
[2024-07-24 10:28:59,505][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,505][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 19
[2024-07-24 10:28:59,505][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit22', 'circuit24', 'circuit27']
[2024-07-24 10:28:59,505][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit23']
[2024-07-24 10:28:59,505][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 20
[2024-07-24 10:28:59,505][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:28:59,506][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,506][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 21
[2024-07-24 10:28:59,506][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:28:59,506][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit24']
[2024-07-24 10:28:59,506][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 22
[2024-07-24 10:28:59,506][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:28:59,507][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit23', 'circuit24']
[2024-07-24 10:28:59,507][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 23
[2024-07-24 10:28:59,507][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:28:59,507][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit23']
[2024-07-24 10:28:59,507][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 24
[2024-07-24 10:28:59,507][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,507][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit3', 'circuit5', 'circuit8', 'circuit11', 'circuit14', 'circuit15', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit27']
[2024-07-24 10:28:59,508][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 25
[2024-07-24 10:28:59,508][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit22', 'circuit26']
[2024-07-24 10:28:59,508][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit24', 'circuit25']
[2024-07-24 10:28:59,508][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 26
[2024-07-24 10:28:59,508][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,508][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,509][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 27
[2024-07-24 10:28:59,509][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,509][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,509][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 28
[2024-07-24 10:28:59,509][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,509][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,509][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 0
[2024-07-24 10:28:59,510][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit6', 'circuit7', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,510][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,510][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit6', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:28:59,510][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 1
[2024-07-24 10:28:59,510][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,510][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit3', 'circuit5', 'circuit6', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:28:59,511][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:28:59,511][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 2
[2024-07-24 10:28:59,511][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:28:59,511][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit19', 'circuit20', 'circuit23', 'circuit24']
[2024-07-24 10:28:59,511][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit26']
[2024-07-24 10:28:59,511][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 3
[2024-07-24 10:28:59,512][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit16', 'circuit17', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,512][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:28:59,512][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:28:59,512][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 4
[2024-07-24 10:28:59,512][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:28:59,512][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit16', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:28:59,512][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit26']
[2024-07-24 10:28:59,513][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 5
[2024-07-24 10:28:59,513][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,513][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:28:59,513][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit6', 'circuit12', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:28:59,513][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 6
[2024-07-24 10:28:59,513][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:28:59,514][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit5', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20']
[2024-07-24 10:28:59,514][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:28:59,514][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 7
[2024-07-24 10:28:59,514][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,514][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,514][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit26']
[2024-07-24 10:28:59,514][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 8
[2024-07-24 10:28:59,515][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit17']
[2024-07-24 10:28:59,515][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,515][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit23']
[2024-07-24 10:28:59,515][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 9
[2024-07-24 10:28:59,515][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,515][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit23']
[2024-07-24 10:28:59,516][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit22']
[2024-07-24 10:28:59,516][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 10
[2024-07-24 10:28:59,516][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:28:59,516][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,516][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13']
[2024-07-24 10:28:59,516][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 11
[2024-07-24 10:28:59,516][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:28:59,517][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit7', 'circuit9', 'circuit18', 'circuit23', 'circuit26']
[2024-07-24 10:28:59,517][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:28:59,517][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 12
[2024-07-24 10:28:59,517][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit20', 'circuit25']
[2024-07-24 10:28:59,517][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,517][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,518][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 13
[2024-07-24 10:28:59,518][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,518][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,518][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,518][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 14
[2024-07-24 10:28:59,518][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:28:59,518][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:28:59,519][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:28:59,519][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 15
[2024-07-24 10:28:59,519][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit24']
[2024-07-24 10:28:59,519][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit19', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:28:59,519][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit20', 'circuit23']
[2024-07-24 10:28:59,519][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 16
[2024-07-24 10:28:59,520][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,520][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit19', 'circuit20']
[2024-07-24 10:28:59,520][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,520][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 17
[2024-07-24 10:28:59,520][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,520][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,521][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,521][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 18
[2024-07-24 10:28:59,521][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,521][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit7', 'circuit16', 'circuit23', 'circuit25']
[2024-07-24 10:28:59,521][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,521][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 19
[2024-07-24 10:28:59,521][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit23', 'circuit24']
[2024-07-24 10:28:59,522][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,522][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,522][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 20
[2024-07-24 10:28:59,522][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,522][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,522][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,522][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 21
[2024-07-24 10:28:59,523][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,523][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,523][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,523][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 22
[2024-07-24 10:28:59,523][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:28:59,523][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,524][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,524][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 23
[2024-07-24 10:28:59,524][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,524][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,524][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,524][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 24
[2024-07-24 10:28:59,524][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,525][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,525][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,525][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 25
[2024-07-24 10:28:59,525][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,525][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,525][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,525][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 26
[2024-07-24 10:28:59,526][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,526][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,526][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,526][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 27
[2024-07-24 10:28:59,526][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,526][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,527][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,527][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 28
[2024-07-24 10:28:59,527][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,527][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,527][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,527][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 0
[2024-07-24 10:28:59,528][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit5', 'circuit6', 'circuit7', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,528][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:28:59,528][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit3', 'circuit5', 'circuit7', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,528][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,528][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 1
[2024-07-24 10:28:59,528][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit3', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit23', 'circuit26']
[2024-07-24 10:28:59,528][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,529][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,529][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,529][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 2
[2024-07-24 10:28:59,529][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:28:59,529][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit21']
[2024-07-24 10:28:59,529][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23']
[2024-07-24 10:28:59,530][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,530][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 3
[2024-07-24 10:28:59,530][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:28:59,530][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit13', 'circuit14', 'circuit18']
[2024-07-24 10:28:59,530][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit20']
[2024-07-24 10:28:59,530][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,530][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 4
[2024-07-24 10:28:59,531][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,531][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16']
[2024-07-24 10:28:59,531][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14']
[2024-07-24 10:28:59,531][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,531][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 5
[2024-07-24 10:28:59,531][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:28:59,532][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit7', 'circuit15', 'circuit16', 'circuit18', 'circuit20', 'circuit26']
[2024-07-24 10:28:59,532][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:28:59,532][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:28:59,532][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 6
[2024-07-24 10:28:59,532][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:28:59,532][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,533][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit17', 'circuit20', 'circuit22', 'circuit23']
[2024-07-24 10:28:59,533][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,533][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 7
[2024-07-24 10:28:59,533][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:28:59,533][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:28:59,533][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:28:59,533][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:28:59,534][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 8
[2024-07-24 10:28:59,534][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,534][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,534][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,534][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,534][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 9
[2024-07-24 10:28:59,535][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit16']
[2024-07-24 10:28:59,535][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit4', 'circuit13']
[2024-07-24 10:28:59,535][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14']
[2024-07-24 10:28:59,535][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:28:59,535][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 10
[2024-07-24 10:28:59,535][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:28:59,535][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,536][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,536][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,536][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 11
[2024-07-24 10:28:59,536][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:28:59,536][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:28:59,536][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:28:59,537][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit20']
[2024-07-24 10:28:59,537][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 12
[2024-07-24 10:28:59,537][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit27']
[2024-07-24 10:28:59,537][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,537][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17']
[2024-07-24 10:28:59,537][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,537][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 13
[2024-07-24 10:28:59,538][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,538][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit4', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,538][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:28:59,538][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit3', 'circuit5', 'circuit6', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,538][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 14
[2024-07-24 10:28:59,538][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:28:59,539][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,539][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:28:59,539][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,539][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 15
[2024-07-24 10:28:59,539][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit20', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:28:59,539][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16']
[2024-07-24 10:28:59,540][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,540][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,540][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 16
[2024-07-24 10:28:59,540][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit12', 'circuit15', 'circuit16', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,540][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit5', 'circuit7', 'circuit8', 'circuit14', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:28:59,540][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,540][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit21', 'circuit23', 'circuit25']
[2024-07-24 10:28:59,541][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 17
[2024-07-24 10:28:59,541][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,541][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,541][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,541][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,541][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 18
[2024-07-24 10:28:59,542][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:28:59,542][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit26']
[2024-07-24 10:28:59,542][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:28:59,542][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit12', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:28:59,542][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 19
[2024-07-24 10:28:59,542][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,542][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,543][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,543][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,543][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 20
[2024-07-24 10:28:59,543][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:28:59,543][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit19', 'circuit20', 'circuit21']
[2024-07-24 10:28:59,543][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:28:59,544][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit19', 'circuit23', 'circuit25']
[2024-07-24 10:28:59,544][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 21
[2024-07-24 10:28:59,544][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit27']
[2024-07-24 10:28:59,544][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit24']
[2024-07-24 10:28:59,544][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit23', 'circuit27']
[2024-07-24 10:28:59,544][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,544][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 22
[2024-07-24 10:28:59,545][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:28:59,545][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:28:59,545][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:28:59,545][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit8', 'circuit11', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:28:59,545][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 23
[2024-07-24 10:28:59,545][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:28:59,546][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:28:59,546][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:28:59,546][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit25']
[2024-07-24 10:28:59,546][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 24
[2024-07-24 10:28:59,546][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit15', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:28:59,546][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14']
[2024-07-24 10:28:59,546][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit17']
[2024-07-24 10:28:59,547][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,547][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 25
[2024-07-24 10:28:59,547][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit11', 'circuit27']
[2024-07-24 10:28:59,547][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,547][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,547][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,548][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 26
[2024-07-24 10:28:59,548][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,548][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,548][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,548][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,548][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 27
[2024-07-24 10:28:59,549][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,549][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,549][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,549][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,549][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 28
[2024-07-24 10:28:59,549][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,549][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,550][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,550][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,550][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 0
[2024-07-24 10:28:59,550][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,550][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit3', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,550][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit5', 'circuit7', 'circuit8', 'circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:28:59,551][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit5', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,551][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,551][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 1
[2024-07-24 10:28:59,551][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,551][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit6', 'circuit7', 'circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit25']
[2024-07-24 10:28:59,551][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:28:59,552][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,552][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit23']
[2024-07-24 10:28:59,552][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 2
[2024-07-24 10:28:59,552][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:28:59,552][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit17']
[2024-07-24 10:28:59,552][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13']
[2024-07-24 10:28:59,552][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit15', 'circuit16']
[2024-07-24 10:28:59,553][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,553][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 3
[2024-07-24 10:28:59,553][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,553][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit8']
[2024-07-24 10:28:59,553][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,553][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,554][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,554][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 4
[2024-07-24 10:28:59,554][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit27']
[2024-07-24 10:28:59,554][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit3', 'circuit5', 'circuit13', 'circuit16', 'circuit19', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:28:59,554][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,554][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,554][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:28:59,555][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 5
[2024-07-24 10:28:59,555][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:28:59,555][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,555][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,555][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,555][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,556][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 6
[2024-07-24 10:28:59,556][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit28']
[2024-07-24 10:28:59,556][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21']
[2024-07-24 10:28:59,556][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,556][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:28:59,556][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:28:59,556][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 7
[2024-07-24 10:28:59,557][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:28:59,557][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21']
[2024-07-24 10:28:59,557][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit25']
[2024-07-24 10:28:59,557][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit17', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:28:59,557][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:28:59,557][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 8
[2024-07-24 10:28:59,558][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,558][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit6', 'circuit9', 'circuit10', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:28:59,558][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,558][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,558][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,558][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 9
[2024-07-24 10:28:59,559][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:28:59,559][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,559][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,559][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,559][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,559][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 10
[2024-07-24 10:28:59,559][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,560][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:28:59,560][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:28:59,560][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:28:59,560][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,560][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 11
[2024-07-24 10:28:59,560][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,561][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit9', 'circuit13', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:28:59,561][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:28:59,561][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit23']
[2024-07-24 10:28:59,561][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit22', 'circuit24']
[2024-07-24 10:28:59,561][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 12
[2024-07-24 10:28:59,561][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10']
[2024-07-24 10:28:59,561][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit18', 'circuit19']
[2024-07-24 10:28:59,562][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit2', 'circuit13', 'circuit26']
[2024-07-24 10:28:59,562][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,562][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit22', 'circuit24']
[2024-07-24 10:28:59,562][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 13
[2024-07-24 10:28:59,562][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,562][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,563][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit6', 'circuit7', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:28:59,563][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit5', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,563][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,563][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 14
[2024-07-24 10:28:59,563][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,563][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:28:59,564][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:28:59,564][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit5', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:28:59,564][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit3', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:28:59,564][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 15
[2024-07-24 10:28:59,564][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:28:59,564][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,564][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,565][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,565][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,565][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 16
[2024-07-24 10:28:59,565][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,565][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,565][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,566][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,566][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,566][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 17
[2024-07-24 10:28:59,566][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,566][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,566][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,566][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,567][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,567][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 18
[2024-07-24 10:28:59,567][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit22']
[2024-07-24 10:28:59,567][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,567][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,567][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,568][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,568][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 19
[2024-07-24 10:28:59,568][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:28:59,568][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,568][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24']
[2024-07-24 10:28:59,568][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,568][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,569][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 20
[2024-07-24 10:28:59,569][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,569][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,569][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,569][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,569][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,570][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 21
[2024-07-24 10:28:59,570][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,570][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,570][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,570][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,570][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,570][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 22
[2024-07-24 10:28:59,571][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit27']
[2024-07-24 10:28:59,571][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,571][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,571][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,571][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,571][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 23
[2024-07-24 10:28:59,572][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:28:59,572][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:28:59,572][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:28:59,572][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit25']
[2024-07-24 10:28:59,572][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,572][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 24
[2024-07-24 10:28:59,572][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:28:59,573][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:28:59,573][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:28:59,573][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:28:59,573][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:28:59,573][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 25
[2024-07-24 10:28:59,573][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit9', 'circuit10', 'circuit27']
[2024-07-24 10:28:59,574][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,574][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,574][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,574][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,574][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 26
[2024-07-24 10:28:59,574][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,575][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,575][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,575][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,575][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,575][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 27
[2024-07-24 10:28:59,575][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,576][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,576][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,576][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,576][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,576][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 28
[2024-07-24 10:28:59,576][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,577][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,577][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,577][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,577][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,577][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 0
[2024-07-24 10:28:59,577][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit5', 'circuit6', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,578][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit4', 'circuit5', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,578][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit6', 'circuit7', 'circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:28:59,578][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit5', 'circuit6', 'circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,578][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:28:59,578][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:28:59,578][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 1
[2024-07-24 10:28:59,579][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,579][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit9', 'circuit26']
[2024-07-24 10:28:59,579][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,579][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,579][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,579][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,579][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 2
[2024-07-24 10:28:59,580][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,580][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,580][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,580][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit27']
[2024-07-24 10:28:59,580][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit4', 'circuit7']
[2024-07-24 10:28:59,580][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,581][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 3
[2024-07-24 10:28:59,581][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit26', 'circuit27']
[2024-07-24 10:28:59,581][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit8', 'circuit14', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23']
[2024-07-24 10:28:59,581][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,581][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,581][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit15', 'circuit16', 'circuit22']
[2024-07-24 10:28:59,582][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,582][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 4
[2024-07-24 10:28:59,582][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,582][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21']
[2024-07-24 10:28:59,582][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit23']
[2024-07-24 10:28:59,582][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit24', 'circuit25']
[2024-07-24 10:28:59,582][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit20', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:28:59,583][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit24', 'circuit25']
[2024-07-24 10:28:59,583][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 5
[2024-07-24 10:28:59,583][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit23', 'circuit24']
[2024-07-24 10:28:59,583][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,583][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,583][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,584][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,584][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,584][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 6
[2024-07-24 10:28:59,584][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,584][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,584][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,584][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,585][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,585][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,585][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 7
[2024-07-24 10:28:59,585][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,585][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit4', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21']
[2024-07-24 10:28:59,585][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:28:59,586][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:28:59,586][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit22', 'circuit24']
[2024-07-24 10:28:59,586][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,586][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 8
[2024-07-24 10:28:59,586][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit24']
[2024-07-24 10:28:59,586][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit16']
[2024-07-24 10:28:59,586][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14']
[2024-07-24 10:28:59,587][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit21', 'circuit25']
[2024-07-24 10:28:59,587][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,587][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,587][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 9
[2024-07-24 10:28:59,587][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,587][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,588][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,588][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,588][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,588][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,588][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 10
[2024-07-24 10:28:59,588][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,588][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,589][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,589][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,589][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,589][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,589][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 11
[2024-07-24 10:28:59,589][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:28:59,590][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13', 'circuit21', 'circuit22', 'circuit26']
[2024-07-24 10:28:59,590][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit24', 'circuit26']
[2024-07-24 10:28:59,590][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:28:59,590][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit22']
[2024-07-24 10:28:59,590][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit6', 'circuit10', 'circuit11', 'circuit26']
[2024-07-24 10:28:59,590][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 12
[2024-07-24 10:28:59,591][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20']
[2024-07-24 10:28:59,591][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,591][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:28:59,591][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit25']
[2024-07-24 10:28:59,591][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit23']
[2024-07-24 10:28:59,591][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,591][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 13
[2024-07-24 10:28:59,592][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit5', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,592][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:28:59,592][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:28:59,592][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit4', 'circuit5', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:28:59,592][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit2', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,592][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit6', 'circuit7', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,593][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 14
[2024-07-24 10:28:59,593][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,593][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit9', 'circuit13', 'circuit17', 'circuit19']
[2024-07-24 10:28:59,593][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,593][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14']
[2024-07-24 10:28:59,593][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14']
[2024-07-24 10:28:59,594][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,594][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 15
[2024-07-24 10:28:59,594][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,594][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,594][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,594][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,594][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,595][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,595][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 16
[2024-07-24 10:28:59,595][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,595][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit7', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit24', 'circuit26']
[2024-07-24 10:28:59,595][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:28:59,595][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:28:59,596][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:28:59,596][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit15', 'circuit16', 'circuit17', 'circuit22', 'circuit23']
[2024-07-24 10:28:59,596][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 17
[2024-07-24 10:28:59,596][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit28']
[2024-07-24 10:28:59,596][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit24']
[2024-07-24 10:28:59,596][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:28:59,597][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:28:59,597][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit17', 'circuit22', 'circuit24']
[2024-07-24 10:28:59,597][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit24']
[2024-07-24 10:28:59,597][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 18
[2024-07-24 10:28:59,597][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit20']
[2024-07-24 10:28:59,597][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit18', 'circuit19', 'circuit20', 'circuit21']
[2024-07-24 10:28:59,597][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17']
[2024-07-24 10:28:59,598][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,598][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,598][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit9', 'circuit11', 'circuit12', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:28:59,598][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 19
[2024-07-24 10:28:59,598][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit24', 'circuit26']
[2024-07-24 10:28:59,598][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit3', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit21']
[2024-07-24 10:28:59,599][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,599][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,599][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,599][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,599][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 20
[2024-07-24 10:28:59,599][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:28:59,599][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit7', 'circuit14', 'circuit15', 'circuit16', 'circuit18']
[2024-07-24 10:28:59,600][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit2', 'circuit3', 'circuit13', 'circuit14', 'circuit22']
[2024-07-24 10:28:59,600][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:28:59,600][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:28:59,600][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit15', 'circuit20', 'circuit21', 'circuit23', 'circuit26']
[2024-07-24 10:28:59,600][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 21
[2024-07-24 10:28:59,600][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit27']
[2024-07-24 10:28:59,601][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,601][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,601][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,601][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,601][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,601][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 22
[2024-07-24 10:28:59,602][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit24']
[2024-07-24 10:28:59,602][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,602][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,602][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,602][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,602][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,602][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 23
[2024-07-24 10:28:59,603][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,603][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13', 'circuit26']
[2024-07-24 10:28:59,603][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,603][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,603][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,603][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,604][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 24
[2024-07-24 10:28:59,604][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit24']
[2024-07-24 10:28:59,604][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20']
[2024-07-24 10:28:59,604][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:28:59,604][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,604][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,604][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,605][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 25
[2024-07-24 10:28:59,605][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,605][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit26']
[2024-07-24 10:28:59,605][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,605][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,605][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,606][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,606][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 26
[2024-07-24 10:28:59,606][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,606][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,606][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,606][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,607][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,607][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,607][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 27
[2024-07-24 10:28:59,607][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,607][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,607][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,608][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,608][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,608][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,608][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 28
[2024-07-24 10:28:59,608][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,608][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,608][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,609][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,609][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,609][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,609][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 0
[2024-07-24 10:28:59,609][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,609][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:28:59,610][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:28:59,610][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,610][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:28:59,610][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:28:59,610][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:28:59,610][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 1
[2024-07-24 10:28:59,611][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,611][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13']
[2024-07-24 10:28:59,611][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit27']
[2024-07-24 10:28:59,611][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,611][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,611][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15']
[2024-07-24 10:28:59,612][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit3']
[2024-07-24 10:28:59,612][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 2
[2024-07-24 10:28:59,612][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:28:59,612][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,612][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,612][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,612][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:28:59,613][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit21', 'circuit24', 'circuit25']
[2024-07-24 10:28:59,613][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,613][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 3
[2024-07-24 10:28:59,613][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:28:59,613][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,613][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,614][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,614][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,614][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,614][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,614][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 4
[2024-07-24 10:28:59,614][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,614][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit19', 'circuit20']
[2024-07-24 10:28:59,615][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14']
[2024-07-24 10:28:59,615][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit16']
[2024-07-24 10:28:59,615][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14']
[2024-07-24 10:28:59,615][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,615][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,615][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 5
[2024-07-24 10:28:59,616][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit20']
[2024-07-24 10:28:59,616][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15']
[2024-07-24 10:28:59,616][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,616][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,616][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,616][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,616][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,617][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 6
[2024-07-24 10:28:59,617][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,617][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,617][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,617][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,617][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,618][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,618][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,618][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 7
[2024-07-24 10:28:59,618][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,618][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,618][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit28']
[2024-07-24 10:28:59,618][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit25']
[2024-07-24 10:28:59,619][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit19', 'circuit20', 'circuit22', 'circuit23']
[2024-07-24 10:28:59,619][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit19', 'circuit23']
[2024-07-24 10:28:59,619][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,619][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 8
[2024-07-24 10:28:59,619][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,619][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,620][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,620][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,620][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,620][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,620][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,620][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 9
[2024-07-24 10:28:59,620][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,621][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,621][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,621][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,621][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,621][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,621][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,622][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 10
[2024-07-24 10:28:59,622][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,622][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,622][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,622][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,622][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,623][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,623][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,623][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 11
[2024-07-24 10:28:59,623][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,623][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,623][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,623][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,624][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,624][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,624][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,624][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 12
[2024-07-24 10:28:59,624][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,624][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,625][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,625][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,625][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,625][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,625][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,625][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 13
[2024-07-24 10:28:59,625][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,626][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:28:59,626][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit19', 'circuit20', 'circuit26']
[2024-07-24 10:28:59,626][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,626][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit14', 'circuit16', 'circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:28:59,626][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:28:59,626][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:28:59,627][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 14
[2024-07-24 10:28:59,627][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,627][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,627][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,627][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,627][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,627][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,628][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,628][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 15
[2024-07-24 10:28:59,628][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,628][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,628][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,628][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,629][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,629][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,629][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,629][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 16
[2024-07-24 10:28:59,629][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,629][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,629][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,630][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,630][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,630][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,630][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,630][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 17
[2024-07-24 10:28:59,630][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,631][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,631][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,631][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,631][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,631][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,631][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,631][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 18
[2024-07-24 10:28:59,632][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,632][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,632][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,632][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,632][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,632][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,633][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,633][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 19
[2024-07-24 10:28:59,633][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,633][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,633][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,633][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,634][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,634][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,634][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,634][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 20
[2024-07-24 10:28:59,634][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,634][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,634][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,635][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,635][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,635][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,635][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,635][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 21
[2024-07-24 10:28:59,635][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,636][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,636][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,636][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,636][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,636][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,636][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,636][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 22
[2024-07-24 10:28:59,637][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,637][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,637][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,637][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,637][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,637][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,638][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,638][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 23
[2024-07-24 10:28:59,638][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,638][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,638][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,638][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,639][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,639][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,639][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,639][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 24
[2024-07-24 10:28:59,639][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,639][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,639][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,640][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,640][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,640][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,640][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,640][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 25
[2024-07-24 10:28:59,640][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,641][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,641][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,641][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,641][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,641][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,641][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,641][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 26
[2024-07-24 10:28:59,642][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,642][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,642][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,642][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,642][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,642][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,643][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,643][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 27
[2024-07-24 10:28:59,643][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,643][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,643][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,643][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,644][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,644][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,644][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,644][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 28
[2024-07-24 10:28:59,644][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,644][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,645][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,645][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,645][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,645][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,645][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,645][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 0
[2024-07-24 10:28:59,645][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit4', 'circuit6', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,646][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:28:59,646][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:28:59,646][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit5', 'circuit12', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:28:59,646][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:28:59,646][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:28:59,646][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit5', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:28:59,647][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit5', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit23', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:28:59,647][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 1
[2024-07-24 10:28:59,647][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,647][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,647][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,647][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,648][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,648][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,648][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,648][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0']
[2024-07-24 10:28:59,648][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 2
[2024-07-24 10:28:59,648][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,648][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,649][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,649][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,649][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,649][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,649][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,649][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,650][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 3
[2024-07-24 10:28:59,650][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit20', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:28:59,650][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit19', 'circuit20', 'circuit23', 'circuit24']
[2024-07-24 10:28:59,650][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:28:59,650][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:28:59,650][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit22', 'circuit23']
[2024-07-24 10:28:59,651][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,651][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit23', 'circuit24']
[2024-07-24 10:28:59,651][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit17']
[2024-07-24 10:28:59,651][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 4
[2024-07-24 10:28:59,651][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:28:59,651][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:28:59,651][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:28:59,652][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit15', 'circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:28:59,652][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit15', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:28:59,652][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:28:59,652][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit23']
[2024-07-24 10:28:59,652][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:28:59,652][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 5
[2024-07-24 10:28:59,653][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit17', 'circuit18']
[2024-07-24 10:28:59,653][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14']
[2024-07-24 10:28:59,653][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,653][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,653][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit18']
[2024-07-24 10:28:59,653][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,653][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,654][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,654][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 6
[2024-07-24 10:28:59,654][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:28:59,654][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit7', 'circuit11', 'circuit13', 'circuit14', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:28:59,654][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:28:59,654][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit11', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:28:59,655][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:28:59,655][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit24']
[2024-07-24 10:28:59,655][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit14']
[2024-07-24 10:28:59,655][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit25', 'circuit27']
[2024-07-24 10:28:59,655][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 7
[2024-07-24 10:28:59,655][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit20']
[2024-07-24 10:28:59,656][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,656][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,656][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,656][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,656][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,656][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,656][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,657][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 8
[2024-07-24 10:28:59,657][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:28:59,657][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit5', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:28:59,657][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:28:59,657][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:28:59,657][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:28:59,658][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:28:59,658][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:28:59,658][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit4', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:28:59,658][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 9
[2024-07-24 10:28:59,658][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit5', 'circuit7', 'circuit8', 'circuit9', 'circuit20']
[2024-07-24 10:28:59,658][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,658][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit16', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:28:59,659][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,659][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,659][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,659][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,659][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit15', 'circuit21']
[2024-07-24 10:28:59,659][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 10
[2024-07-24 10:28:59,660][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,660][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,660][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,660][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,660][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,660][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,661][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,661][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,661][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 11
[2024-07-24 10:28:59,661][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,661][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,661][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,661][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,662][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,662][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,662][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,662][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,662][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 12
[2024-07-24 10:28:59,662][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,663][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,663][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,663][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,663][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,663][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,663][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,663][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,664][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 13
[2024-07-24 10:28:59,664][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:28:59,664][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit6', 'circuit12', 'circuit13', 'circuit14', 'circuit16', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:28:59,664][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit26']
[2024-07-24 10:28:59,664][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,664][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,665][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,665][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,665][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,665][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 14
[2024-07-24 10:28:59,665][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,665][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,666][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,666][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,666][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,666][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,666][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,666][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,666][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 15
[2024-07-24 10:28:59,667][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,667][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,667][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,667][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,667][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,667][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,668][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,668][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,668][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 16
[2024-07-24 10:28:59,668][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,668][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,668][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,668][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,669][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,669][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,669][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,669][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,669][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 17
[2024-07-24 10:28:59,669][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,670][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,670][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,670][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,670][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,670][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,670][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,670][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,671][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 18
[2024-07-24 10:28:59,671][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,671][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,671][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,671][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,671][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,672][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,672][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,672][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,672][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 19
[2024-07-24 10:28:59,672][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,672][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,672][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,673][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,673][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,673][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,673][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,673][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,673][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 20
[2024-07-24 10:28:59,674][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,674][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,674][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,674][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,674][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,674][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,674][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,675][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,675][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 21
[2024-07-24 10:28:59,675][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,675][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,675][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,675][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,676][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,676][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,676][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,676][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,676][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 22
[2024-07-24 10:28:59,676][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,676][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,677][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,677][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,677][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,677][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,677][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,677][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,678][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 23
[2024-07-24 10:28:59,678][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,678][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,678][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,678][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,678][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,678][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,679][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,679][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,679][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 24
[2024-07-24 10:28:59,679][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,679][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,679][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,680][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,680][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,680][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,680][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,680][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,680][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 25
[2024-07-24 10:28:59,681][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,681][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,681][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,681][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,681][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,681][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,681][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,682][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,682][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 26
[2024-07-24 10:28:59,682][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,682][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,682][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,682][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,683][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,683][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,683][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,683][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,683][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 27
[2024-07-24 10:28:59,683][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,684][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,684][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,684][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,684][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,684][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,684][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,685][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,685][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 28
[2024-07-24 10:28:59,685][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,685][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,685][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,685][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,686][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,686][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,686][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,686][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,686][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 0
[2024-07-24 10:28:59,686][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit5', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:28:59,686][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit7', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:28:59,687][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:28:59,687][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:28:59,687][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:28:59,687][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:28:59,687][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:28:59,687][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit7', 'circuit25']
[2024-07-24 10:28:59,688][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit13', 'circuit15', 'circuit16', 'circuit27']
[2024-07-24 10:28:59,688][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 1
[2024-07-24 10:28:59,688][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,688][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,688][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,688][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,689][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,689][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,689][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,689][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,689][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:28:59,689][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 2
[2024-07-24 10:28:59,689][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,690][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,690][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,690][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,690][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,690][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,690][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,691][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,691][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:28:59,691][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 3
[2024-07-24 10:28:59,691][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,691][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,691][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,691][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,692][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,692][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,692][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,692][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,692][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:28:59,692][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 4
[2024-07-24 10:28:59,693][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,693][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,693][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,693][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,693][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,693][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,694][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,694][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,694][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:28:59,694][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 5
[2024-07-24 10:28:59,694][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,694][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,695][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,695][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,695][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,695][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,695][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,695][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,695][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:28:59,696][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 6
[2024-07-24 10:28:59,696][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,696][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,696][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,696][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,696][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,697][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,697][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,697][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,697][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:28:59,697][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 7
[2024-07-24 10:28:59,697][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,697][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,698][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,698][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,698][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,698][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,698][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,698][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,699][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:28:59,699][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 8
[2024-07-24 10:28:59,699][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,699][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,699][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,699][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,700][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,700][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,700][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,700][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,700][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:28:59,700][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 9
[2024-07-24 10:28:59,700][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,701][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,701][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,701][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,701][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,701][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,701][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,702][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,702][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:28:59,702][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 10
[2024-07-24 10:28:59,702][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,702][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,702][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,702][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,703][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,703][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,703][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,703][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,703][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:28:59,703][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 11
[2024-07-24 10:28:59,704][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,704][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,704][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,704][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,704][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,704][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,704][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,705][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,705][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:28:59,705][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 12
[2024-07-24 10:28:59,705][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,705][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,705][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,706][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,706][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,706][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,706][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,706][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,706][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:28:59,706][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 13
[2024-07-24 10:28:59,707][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,707][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:28:59,707][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,707][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,707][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,707][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,708][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,708][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit17']
[2024-07-24 10:28:59,708][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit13', 'circuit25']
[2024-07-24 10:28:59,708][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 14
[2024-07-24 10:28:59,708][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,708][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,709][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,709][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,709][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,709][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,709][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,709][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,709][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:28:59,710][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 15
[2024-07-24 10:28:59,710][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,710][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,710][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,710][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,710][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,711][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,711][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,711][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,711][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:28:59,711][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 16
[2024-07-24 10:28:59,711][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,711][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,712][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,712][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,712][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,712][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,712][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,712][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,713][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:28:59,713][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 17
[2024-07-24 10:28:59,713][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,713][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,713][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,713][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,713][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,714][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,714][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,714][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,714][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:28:59,714][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 18
[2024-07-24 10:28:59,714][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,715][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,715][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,715][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,715][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,715][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,715][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,716][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,716][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:28:59,716][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 19
[2024-07-24 10:28:59,716][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,716][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,716][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,716][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,717][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,717][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,717][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,717][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,717][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:28:59,717][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 20
[2024-07-24 10:28:59,718][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,718][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,718][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,718][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,718][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,718][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,718][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,719][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,719][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:28:59,719][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 21
[2024-07-24 10:28:59,719][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,719][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,719][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,720][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,720][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,720][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,720][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,720][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,720][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:28:59,720][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 22
[2024-07-24 10:28:59,721][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,721][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,721][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,721][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,721][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,721][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,722][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,722][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,722][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:28:59,722][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 23
[2024-07-24 10:28:59,722][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,722][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,723][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,723][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,723][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,723][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,723][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,723][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,723][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:28:59,724][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 24
[2024-07-24 10:28:59,724][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,724][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,724][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,724][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,724][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,725][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,725][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,725][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,725][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:28:59,725][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 25
[2024-07-24 10:28:59,725][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,725][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,726][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,726][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,726][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,726][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,726][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,726][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,727][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:28:59,727][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 26
[2024-07-24 10:28:59,727][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,727][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,727][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,727][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,728][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,728][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,728][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,728][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,728][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,728][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 27
[2024-07-24 10:28:59,728][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,729][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,729][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,729][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,729][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,729][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,729][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,730][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,730][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,730][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 28
[2024-07-24 10:28:59,730][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,730][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,730][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,731][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,731][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,731][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,731][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,731][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,731][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,732][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 0
[2024-07-24 10:28:59,732][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,732][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:28:59,732][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:28:59,732][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit16', 'circuit17', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:28:59,732][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:28:59,733][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit21', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:28:59,733][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit5', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit24']
[2024-07-24 10:28:59,733][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit13', 'circuit18', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:28:59,733][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit6', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit20', 'circuit27']
[2024-07-24 10:28:59,733][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit13', 'circuit17', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:28:59,733][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 1
[2024-07-24 10:28:59,733][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:28:59,734][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,734][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:28:59,734][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,734][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,734][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,734][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,735][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,735][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit16', 'circuit17', 'circuit18']
[2024-07-24 10:28:59,735][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-24 10:28:59,735][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 2
[2024-07-24 10:28:59,735][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:28:59,735][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit20', 'circuit23', 'circuit26']
[2024-07-24 10:28:59,736][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:28:59,736][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:28:59,736][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit22']
[2024-07-24 10:28:59,736][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,736][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,736][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,736][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit23', 'circuit24']
[2024-07-24 10:28:59,737][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-24 10:28:59,737][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 3
[2024-07-24 10:28:59,737][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:28:59,737][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:28:59,737][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:28:59,737][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:28:59,738][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:28:59,738][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:28:59,738][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit18', 'circuit23', 'circuit25']
[2024-07-24 10:28:59,738][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:28:59,738][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit13', 'circuit27']
[2024-07-24 10:28:59,738][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit19', 'circuit20', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:28:59,739][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 4
[2024-07-24 10:28:59,739][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:28:59,739][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit18', 'circuit19', 'circuit20']
[2024-07-24 10:28:59,739][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,739][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,739][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:28:59,739][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,740][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,740][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit25']
[2024-07-24 10:28:59,740][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit16', 'circuit18', 'circuit21', 'circuit23', 'circuit25']
[2024-07-24 10:28:59,740][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-24 10:28:59,740][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 5
[2024-07-24 10:28:59,740][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:28:59,741][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,741][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:28:59,741][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,741][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,741][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,741][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,742][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,742][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:28:59,742][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-24 10:28:59,742][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 6
[2024-07-24 10:28:59,742][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:28:59,742][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,742][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,743][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,743][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,743][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,743][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,743][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,743][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:28:59,744][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit19', 'circuit24']
[2024-07-24 10:28:59,744][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 7
[2024-07-24 10:28:59,744][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:28:59,744][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:28:59,744][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:28:59,744][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit1', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:28:59,744][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:28:59,745][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,745][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit13', 'circuit17']
[2024-07-24 10:28:59,745][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit7', 'circuit13', 'circuit27']
[2024-07-24 10:28:59,745][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit13', 'circuit16']
[2024-07-24 10:28:59,745][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit5']
[2024-07-24 10:28:59,745][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 8
[2024-07-24 10:28:59,746][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10']
[2024-07-24 10:28:59,746][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit6', 'circuit9']
[2024-07-24 10:28:59,746][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,746][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,746][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,746][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,747][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,747][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,747][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:28:59,747][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:28:59,747][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 9
[2024-07-24 10:28:59,747][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,747][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,748][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,748][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,748][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,748][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,748][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,748][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,749][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:28:59,749][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:28:59,749][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 10
[2024-07-24 10:28:59,749][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,749][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,749][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,749][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,750][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,750][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,750][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,750][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,750][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:28:59,750][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:28:59,751][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 11
[2024-07-24 10:28:59,751][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit20', 'circuit22', 'circuit23']
[2024-07-24 10:28:59,751][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,751][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,751][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,751][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,752][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,752][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,752][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,752][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:28:59,752][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:28:59,752][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 12
[2024-07-24 10:28:59,752][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit15', 'circuit22', 'circuit23']
[2024-07-24 10:28:59,753][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,753][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,753][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,753][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,753][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,753][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,754][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,754][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit23']
[2024-07-24 10:28:59,754][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit19']
[2024-07-24 10:28:59,754][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 13
[2024-07-24 10:28:59,754][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:28:59,754][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:28:59,755][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,755][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,755][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit23', 'circuit24']
[2024-07-24 10:28:59,755][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,755][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,755][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,755][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:28:59,756][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:28:59,756][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 14
[2024-07-24 10:28:59,756][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,756][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,756][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,756][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,757][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,757][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,757][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,757][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,757][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:28:59,757][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:28:59,757][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 15
[2024-07-24 10:28:59,758][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,758][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,758][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,758][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,758][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,758][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,759][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,759][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,759][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:28:59,759][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:28:59,759][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 16
[2024-07-24 10:28:59,759][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,759][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,760][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,760][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,760][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,760][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,760][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,760][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,761][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:28:59,761][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:28:59,761][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 17
[2024-07-24 10:28:59,761][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,761][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,761][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,762][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,762][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,762][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,762][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,762][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,762][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:28:59,762][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:28:59,763][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 18
[2024-07-24 10:28:59,763][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,763][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,763][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,763][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,763][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,764][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,764][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,764][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,764][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:28:59,764][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:28:59,764][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 19
[2024-07-24 10:28:59,764][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,765][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,765][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,765][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,765][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,765][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,765][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,766][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,766][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:28:59,766][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:28:59,766][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 20
[2024-07-24 10:28:59,766][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,766][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,767][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,767][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,767][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,767][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,767][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,767][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,767][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:28:59,768][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:28:59,768][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 21
[2024-07-24 10:28:59,768][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,768][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,768][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,768][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,769][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,769][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,769][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,769][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,769][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:28:59,769][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:28:59,769][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 22
[2024-07-24 10:28:59,770][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,770][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,770][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,770][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,770][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,770][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,771][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,771][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,771][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:28:59,771][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:28:59,771][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 23
[2024-07-24 10:28:59,771][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,771][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,772][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,772][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,772][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,772][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,772][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,772][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,773][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:28:59,773][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:28:59,773][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 24
[2024-07-24 10:28:59,773][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,773][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,773][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,774][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,774][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,774][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,774][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,774][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,774][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:28:59,774][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:28:59,775][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 25
[2024-07-24 10:28:59,775][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,775][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,775][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,775][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,775][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,776][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,776][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,776][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,776][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:28:59,776][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:28:59,776][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 26
[2024-07-24 10:28:59,776][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,777][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,777][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,777][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,777][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,777][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,777][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,778][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,778][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,778][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,778][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 27
[2024-07-24 10:28:59,778][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,778][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,779][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,779][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,779][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,779][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,779][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,779][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,780][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,780][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,780][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 28
[2024-07-24 10:28:59,780][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,780][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,780][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,781][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,781][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,781][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,781][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,781][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,781][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,782][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,782][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 0
[2024-07-24 10:28:59,782][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit22', 'circuit23', 'circuit27']
[2024-07-24 10:28:59,782][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,782][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:28:59,782][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:28:59,783][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,783][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,783][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,783][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0']
[2024-07-24 10:28:59,783][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit19', 'circuit27']
[2024-07-24 10:28:59,783][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit13', 'circuit17', 'circuit19', 'circuit25']
[2024-07-24 10:28:59,784][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit3', 'circuit5', 'circuit6', 'circuit7', 'circuit9', 'circuit11', 'circuit25', 'circuit26']
[2024-07-24 10:28:59,784][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 1
[2024-07-24 10:28:59,784][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,784][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,784][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,784][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,785][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,785][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,785][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,785][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,785][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:28:59,785][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:28:59,785][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:28:59,786][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 2
[2024-07-24 10:28:59,786][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,786][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,786][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,786][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,786][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,787][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,787][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,787][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,787][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:28:59,787][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:28:59,787][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:28:59,787][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 3
[2024-07-24 10:28:59,788][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:28:59,788][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,788][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,788][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,788][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,788][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,789][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,789][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,789][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:28:59,789][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:28:59,789][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0']
[2024-07-24 10:28:59,789][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 4
[2024-07-24 10:28:59,789][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,790][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,790][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,790][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,790][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,790][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,790][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,791][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,791][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:28:59,791][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:28:59,791][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit1', 'circuit3', 'circuit4', 'circuit5', 'circuit7', 'circuit8', 'circuit10', 'circuit11']
[2024-07-24 10:28:59,791][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 5
[2024-07-24 10:28:59,791][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,791][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,792][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,792][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,792][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,792][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,792][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,792][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,793][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit13']
[2024-07-24 10:28:59,793][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:28:59,793][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:28:59,793][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 6
[2024-07-24 10:28:59,793][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,793][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,794][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,794][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,794][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,794][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,794][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,794][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,794][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit4', 'circuit10', 'circuit11', 'circuit13', 'circuit17', 'circuit24', 'circuit25']
[2024-07-24 10:28:59,795][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:28:59,795][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0']
[2024-07-24 10:28:59,795][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 7
[2024-07-24 10:28:59,795][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit22']
[2024-07-24 10:28:59,795][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:28:59,795][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:28:59,796][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:28:59,796][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit24']
[2024-07-24 10:28:59,796][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,796][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,796][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,796][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit13', 'circuit23']
[2024-07-24 10:28:59,797][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-24 10:28:59,797][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:28:59,797][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 8
[2024-07-24 10:28:59,797][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,797][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,797][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,797][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,798][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,798][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,798][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,798][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,798][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:28:59,798][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:28:59,799][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:28:59,799][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 9
[2024-07-24 10:28:59,799][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,799][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit22', 'circuit24']
[2024-07-24 10:28:59,799][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,799][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,799][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,800][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,800][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,800][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,800][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit13']
[2024-07-24 10:28:59,800][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit25']
[2024-07-24 10:28:59,800][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0']
[2024-07-24 10:28:59,801][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 10
[2024-07-24 10:28:59,801][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:28:59,801][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,801][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,801][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,801][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,802][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,802][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,802][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,802][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:28:59,802][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:28:59,802][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:28:59,802][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 11
[2024-07-24 10:28:59,803][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,803][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,803][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,803][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,803][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,803][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,804][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,804][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,804][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:28:59,804][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:28:59,804][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:28:59,804][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 12
[2024-07-24 10:28:59,804][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit16', 'circuit18', 'circuit20', 'circuit22']
[2024-07-24 10:28:59,805][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,805][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit25']
[2024-07-24 10:28:59,805][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,805][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,805][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,805][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,806][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,806][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:28:59,806][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit13', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:28:59,806][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24']
[2024-07-24 10:28:59,806][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 13
[2024-07-24 10:28:59,806][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit23', 'circuit24']
[2024-07-24 10:28:59,807][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,807][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:28:59,807][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:28:59,807][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit21']
[2024-07-24 10:28:59,807][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,807][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,807][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:28:59,808][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:28:59,808][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:28:59,808][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:28:59,808][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 14
[2024-07-24 10:28:59,808][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,808][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,809][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,809][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,809][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,809][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,809][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,809][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,810][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:28:59,810][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:28:59,810][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:28:59,810][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 15
[2024-07-24 10:28:59,810][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,810][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,810][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,811][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,811][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,811][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,811][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,811][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,811][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:28:59,812][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:28:59,812][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:28:59,812][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 16
[2024-07-24 10:28:59,812][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,812][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,812][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,812][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,813][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,813][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,813][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,813][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,813][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:28:59,813][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:28:59,814][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:28:59,814][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 17
[2024-07-24 10:28:59,814][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,814][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,814][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,814][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,814][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,815][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,815][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,815][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,815][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:28:59,815][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:28:59,815][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:28:59,816][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 18
[2024-07-24 10:28:59,816][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,816][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,816][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,816][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,816][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,817][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,817][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,817][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,817][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:28:59,817][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:28:59,817][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:28:59,817][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 19
[2024-07-24 10:28:59,818][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,818][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,818][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,818][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,818][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,818][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,819][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,819][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,819][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:28:59,819][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:28:59,819][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:28:59,819][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 20
[2024-07-24 10:28:59,819][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,820][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,820][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,820][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,820][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,820][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,820][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,821][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,821][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:28:59,821][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:28:59,821][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:28:59,821][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 21
[2024-07-24 10:28:59,821][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,821][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,822][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,822][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,822][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,822][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,822][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,822][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,823][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:28:59,823][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:28:59,823][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:28:59,823][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 22
[2024-07-24 10:28:59,823][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,823][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,823][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,824][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,824][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,824][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,824][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,824][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,824][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:28:59,825][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:28:59,825][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:28:59,825][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 23
[2024-07-24 10:28:59,825][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,825][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,825][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,825][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,826][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,826][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,826][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,826][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,826][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:28:59,826][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:28:59,827][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:28:59,827][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 24
[2024-07-24 10:28:59,827][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,827][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,827][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,827][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,828][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,828][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,828][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,828][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,828][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:28:59,828][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:28:59,828][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:28:59,829][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 25
[2024-07-24 10:28:59,829][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:28:59,829][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:28:59,829][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:28:59,829][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:28:59,829][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:28:59,830][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:28:59,830][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:28:59,830][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:28:59,830][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:28:59,830][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:28:59,830][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:28:59,830][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 26
[2024-07-24 10:28:59,831][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,831][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,831][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,831][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,831][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,831][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,832][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,832][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,832][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,832][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,832][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,832][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 27
[2024-07-24 10:28:59,833][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,833][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,833][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,833][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,833][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,833][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,834][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,834][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,834][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,834][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,834][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,834][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 28
[2024-07-24 10:28:59,835][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,835][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,835][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,835][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,835][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,835][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,835][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,836][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,836][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,836][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:28:59,836][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:29:01,440][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:29:01,441][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:01,442][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:01,443][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:01,444][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:01,445][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:01,446][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:01,448][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:01,450][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:01,450][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:01,451][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:01,452][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:01,452][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:01,454][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Amanda] are: tensor([0.7423, 0.2577], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:01,455][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Amanda] are: tensor([3.1639e-04, 9.9968e-01], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:01,456][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Amanda] are: tensor([0.8436, 0.1564], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:01,456][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Amanda] are: tensor([0.0355, 0.9645], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:01,457][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Amanda] are: tensor([0.1067, 0.8933], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:01,458][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Amanda] are: tensor([0.0048, 0.9952], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:01,459][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Amanda] are: tensor([0.6518, 0.3482], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:01,460][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Amanda] are: tensor([0.9715, 0.0285], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:01,462][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Amanda] are: tensor([0.8405, 0.1595], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:01,463][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Amanda] are: tensor([0.9453, 0.0547], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:01,465][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Amanda] are: tensor([0.6894, 0.3106], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:01,466][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Amanda] are: tensor([0.7239, 0.2761], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:01,468][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.6827, 0.2594, 0.0579], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:01,469][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ and] are: tensor([4.4087e-03, 7.4961e-04, 9.9484e-01], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:01,471][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.4064, 0.0688, 0.5248], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:01,472][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.2290, 0.0997, 0.6712], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:01,474][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.6062, 0.2164, 0.1774], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:01,476][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1820, 0.0177, 0.8003], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:01,477][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.6438, 0.3328, 0.0234], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:01,479][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.4191, 0.3655, 0.2154], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:01,481][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.2536, 0.0403, 0.7061], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:01,482][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.6158, 0.1302, 0.2539], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:01,484][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.6628, 0.1054, 0.2317], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:01,485][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.5518, 0.1019, 0.3463], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:01,487][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ John] are: tensor([0.3340, 0.3917, 0.1185, 0.1558], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:01,488][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ John] are: tensor([2.0011e-03, 7.1557e-04, 2.1659e-03, 9.9512e-01], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:01,489][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ John] are: tensor([0.6462, 0.1167, 0.1043, 0.1328], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:01,489][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ John] are: tensor([0.0323, 0.0053, 0.0016, 0.9607], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:01,490][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ John] are: tensor([0.1066, 0.1850, 0.0220, 0.6865], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:01,491][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ John] are: tensor([2.4545e-02, 2.3773e-05, 3.3886e-05, 9.7540e-01], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:01,493][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ John] are: tensor([0.3549, 0.4104, 0.0599, 0.1748], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:01,494][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ John] are: tensor([0.3594, 0.1316, 0.3600, 0.1491], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:01,496][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ John] are: tensor([0.2896, 0.1961, 0.1935, 0.3209], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:01,497][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ John] are: tensor([0.5558, 0.1413, 0.2271, 0.0758], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:01,499][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ John] are: tensor([0.4261, 0.0995, 0.1634, 0.3111], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:01,500][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ John] are: tensor([0.4384, 0.1817, 0.2244, 0.1555], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:01,502][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ went] are: tensor([0.4519, 0.1372, 0.0799, 0.0817, 0.2493], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:01,504][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ went] are: tensor([0.0012, 0.0010, 0.0018, 0.0010, 0.9950], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:01,505][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ went] are: tensor([0.6081, 0.0602, 0.1923, 0.0522, 0.0872], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:01,507][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ went] are: tensor([0.0308, 0.0010, 0.0020, 0.0015, 0.9647], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:01,509][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ went] are: tensor([0.4045, 0.0504, 0.0593, 0.0826, 0.4033], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:01,510][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ went] are: tensor([2.6716e-02, 4.4419e-05, 6.5624e-05, 1.3193e-04, 9.7304e-01],
       device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:01,511][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ went] are: tensor([0.2726, 0.2975, 0.0414, 0.3480, 0.0405], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:01,513][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ went] are: tensor([0.2438, 0.1140, 0.2593, 0.1671, 0.2159], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:01,515][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.3699, 0.0708, 0.3602, 0.1388, 0.0602], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:01,516][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ went] are: tensor([0.4249, 0.1476, 0.2077, 0.1056, 0.1141], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:01,518][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ went] are: tensor([0.4038, 0.0889, 0.1818, 0.0714, 0.2541], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:01,519][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ went] are: tensor([0.4761, 0.0768, 0.2370, 0.0902, 0.1199], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:01,521][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.4314, 0.1564, 0.0581, 0.0897, 0.2334, 0.0309], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:01,521][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ to] are: tensor([5.9629e-03, 2.0484e-04, 6.7586e-02, 3.6603e-04, 8.4855e-04, 9.2503e-01],
       device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:01,522][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.3912, 0.0579, 0.1762, 0.0438, 0.0794, 0.2516], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:01,523][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0321, 0.0035, 0.0209, 0.0243, 0.4547, 0.4645], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:01,524][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.1548, 0.0488, 0.0261, 0.0211, 0.6183, 0.1309], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:01,525][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0841, 0.0061, 0.1464, 0.0078, 0.0156, 0.7399], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:01,527][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.2825, 0.2097, 0.0155, 0.0730, 0.0736, 0.3456], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:01,529][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.1403, 0.0756, 0.1195, 0.1104, 0.3048, 0.2494], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:01,530][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0595, 0.0157, 0.3439, 0.0300, 0.0643, 0.4866], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:01,532][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.3527, 0.0963, 0.1888, 0.0890, 0.0886, 0.1846], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:01,533][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.3399, 0.0790, 0.2344, 0.0684, 0.0878, 0.1906], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:01,535][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.3432, 0.0853, 0.1823, 0.0761, 0.1260, 0.1870], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:01,537][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.4717, 0.1698, 0.0415, 0.1354, 0.1265, 0.0218, 0.0334],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:01,538][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ the] are: tensor([9.0572e-03, 4.3506e-04, 6.6368e-02, 6.9753e-03, 1.9016e-04, 8.6814e-02,
        8.3016e-01], device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:01,539][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.3361, 0.0470, 0.1432, 0.0472, 0.1106, 0.2756, 0.0403],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:01,541][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0493, 0.0104, 0.0227, 0.0356, 0.0832, 0.1779, 0.6209],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:01,543][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.2931, 0.0528, 0.0408, 0.0699, 0.2828, 0.1213, 0.1395],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:01,544][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.1731, 0.0231, 0.1467, 0.0398, 0.0397, 0.1305, 0.4471],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:01,546][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.3132, 0.3626, 0.0073, 0.2136, 0.0876, 0.0116, 0.0043],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:01,548][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.1216, 0.0356, 0.0846, 0.0615, 0.1502, 0.2350, 0.3116],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:01,550][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0302, 0.0087, 0.1935, 0.0254, 0.0518, 0.2073, 0.4832],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:01,551][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.3211, 0.0902, 0.1565, 0.0756, 0.0785, 0.1521, 0.1260],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:01,553][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.3429, 0.0799, 0.1646, 0.0794, 0.0435, 0.1118, 0.1777],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:01,554][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.2776, 0.0874, 0.1453, 0.0848, 0.1057, 0.1411, 0.1582],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:01,555][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ station] are: tensor([0.2966, 0.1166, 0.1320, 0.1184, 0.0752, 0.0639, 0.1008, 0.0965],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:01,556][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ station] are: tensor([5.8283e-04, 3.4998e-03, 4.0157e-03, 3.4884e-04, 1.0904e-03, 1.8392e-03,
        4.8303e-04, 9.8814e-01], device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:01,557][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ station] are: tensor([0.2717, 0.0605, 0.0797, 0.2035, 0.0697, 0.0839, 0.0676, 0.1634],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:01,558][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ station] are: tensor([1.2267e-02, 2.7548e-03, 1.7934e-04, 7.4200e-04, 6.2710e-03, 1.4358e-03,
        9.7010e-04, 9.7538e-01], device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:01,559][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ station] are: tensor([0.0582, 0.0365, 0.0055, 0.0479, 0.0308, 0.0102, 0.0167, 0.7941],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:01,560][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ station] are: tensor([1.2808e-02, 2.2023e-03, 1.8575e-05, 5.3677e-05, 5.4231e-05, 3.4071e-06,
        4.1063e-06, 9.8486e-01], device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:01,562][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ station] are: tensor([0.2325, 0.2446, 0.0394, 0.1916, 0.0247, 0.0261, 0.0330, 0.2082],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:01,564][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ station] are: tensor([0.0636, 0.1218, 0.0477, 0.0256, 0.1006, 0.1824, 0.3079, 0.1503],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:01,565][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ station] are: tensor([0.2279, 0.0577, 0.1546, 0.0955, 0.0594, 0.1382, 0.1080, 0.1587],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:01,567][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ station] are: tensor([0.2744, 0.1237, 0.1400, 0.1200, 0.0821, 0.1183, 0.1247, 0.0167],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:01,569][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ station] are: tensor([0.1585, 0.0841, 0.1450, 0.0673, 0.0584, 0.1086, 0.1007, 0.2773],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:01,570][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ station] are: tensor([0.2450, 0.0616, 0.1116, 0.0552, 0.0985, 0.1725, 0.0502, 0.2053],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:01,572][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.4482, 0.1218, 0.0206, 0.0856, 0.1211, 0.0189, 0.0599, 0.1100, 0.0139],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:01,573][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [,] are: tensor([3.4318e-03, 5.3800e-04, 2.5580e-02, 6.3632e-05, 5.2707e-04, 9.1309e-03,
        1.2520e-03, 1.1306e-04, 9.5936e-01], device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:01,575][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.2774, 0.0329, 0.1213, 0.0148, 0.0478, 0.0613, 0.0139, 0.0117, 0.4190],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:01,577][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0513, 0.0031, 0.0080, 0.0045, 0.0733, 0.0443, 0.1170, 0.0659, 0.6327],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:01,578][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.5167, 0.0436, 0.0153, 0.0225, 0.0717, 0.0517, 0.0283, 0.0752, 0.1749],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:01,580][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.1381, 0.0207, 0.1986, 0.0259, 0.0596, 0.0987, 0.1473, 0.0196, 0.2915],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:01,582][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.2980, 0.2368, 0.0104, 0.2019, 0.0641, 0.0205, 0.0068, 0.1553, 0.0064],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:01,583][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0528, 0.0250, 0.0335, 0.0536, 0.0682, 0.0898, 0.1768, 0.1559, 0.3443],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:01,585][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0338, 0.0080, 0.1761, 0.0166, 0.0213, 0.1564, 0.2288, 0.0121, 0.3469],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:01,587][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.2685, 0.0760, 0.1362, 0.0710, 0.0728, 0.1262, 0.1001, 0.0465, 0.1028],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:01,588][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.2294, 0.0864, 0.1650, 0.0641, 0.0702, 0.1368, 0.0996, 0.0371, 0.1113],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:01,589][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.2495, 0.0621, 0.1227, 0.0644, 0.0924, 0.1122, 0.0638, 0.0962, 0.1367],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:01,590][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ John] are: tensor([0.1759, 0.2278, 0.0582, 0.1035, 0.0170, 0.0437, 0.0457, 0.1679, 0.0530,
        0.1074], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:01,590][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ John] are: tensor([6.8058e-04, 1.3159e-04, 5.4025e-04, 5.4031e-01, 1.0901e-03, 2.4013e-04,
        8.8710e-04, 1.7020e-04, 4.1411e-05, 4.5590e-01], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:01,591][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ John] are: tensor([0.3292, 0.0799, 0.0662, 0.1090, 0.0478, 0.0700, 0.0841, 0.0323, 0.0843,
        0.0971], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:01,593][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ John] are: tensor([3.3841e-03, 7.0777e-05, 1.3784e-05, 1.0297e-02, 2.9064e-05, 9.5899e-05,
        4.5938e-04, 8.8485e-04, 5.8687e-04, 9.8418e-01], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:01,594][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ John] are: tensor([0.0249, 0.0258, 0.0039, 0.0972, 0.0069, 0.0080, 0.0094, 0.0077, 0.0204,
        0.7957], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:01,595][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ John] are: tensor([4.7452e-03, 5.2135e-06, 6.1960e-06, 5.7922e-01, 2.3079e-05, 1.0129e-06,
        1.9598e-05, 3.1250e-06, 2.2300e-06, 4.1597e-01], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:01,597][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ John] are: tensor([0.1767, 0.3001, 0.0340, 0.1465, 0.0360, 0.0165, 0.0276, 0.1041, 0.0281,
        0.1306], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:01,599][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ John] are: tensor([0.0923, 0.0208, 0.0394, 0.0231, 0.0276, 0.1018, 0.1422, 0.0674, 0.2504,
        0.2352], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:01,601][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ John] are: tensor([0.1061, 0.1030, 0.0880, 0.1615, 0.0256, 0.0728, 0.0990, 0.0460, 0.1129,
        0.1850], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:01,602][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ John] are: tensor([0.2588, 0.0889, 0.1235, 0.0442, 0.0628, 0.0988, 0.1038, 0.0743, 0.1039,
        0.0412], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:01,604][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ John] are: tensor([0.1368, 0.0545, 0.0843, 0.2573, 0.0352, 0.0661, 0.0706, 0.0226, 0.0583,
        0.2144], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:01,606][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ John] are: tensor([0.1778, 0.0966, 0.0806, 0.0733, 0.1546, 0.0780, 0.0517, 0.1092, 0.0931,
        0.0849], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:01,607][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.2748, 0.0797, 0.0331, 0.0349, 0.2224, 0.0216, 0.0204, 0.0489, 0.0237,
        0.0393, 0.2011], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:01,609][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([9.4592e-04, 1.2764e-03, 2.3565e-03, 7.4877e-04, 8.8363e-03, 1.1968e-03,
        3.2186e-04, 1.6744e-04, 3.6735e-04, 4.2558e-04, 9.8336e-01],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:01,610][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.3276, 0.0563, 0.0794, 0.0469, 0.0917, 0.1211, 0.0783, 0.0168, 0.0492,
        0.0408, 0.0918], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:01,612][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([2.3800e-03, 5.0589e-05, 2.9723e-05, 4.5886e-05, 1.0924e-03, 1.2993e-04,
        1.9825e-04, 5.5457e-04, 1.7775e-03, 3.2065e-03, 9.9053e-01],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:01,613][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.1317, 0.0412, 0.0137, 0.0191, 0.0377, 0.0310, 0.0204, 0.0231, 0.0443,
        0.1005, 0.5373], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:01,615][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([4.7273e-02, 1.4555e-04, 3.9483e-05, 6.3572e-04, 1.0246e-02, 4.1275e-06,
        1.4019e-05, 2.1761e-06, 1.8999e-06, 2.5451e-04, 9.4138e-01],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:01,616][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.1337, 0.1390, 0.0186, 0.2109, 0.0294, 0.0134, 0.0177, 0.1228, 0.0149,
        0.2679, 0.0317], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:01,618][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0488, 0.0115, 0.0217, 0.0187, 0.0247, 0.0494, 0.0827, 0.0485, 0.2030,
        0.2338, 0.2572], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:01,620][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.1292, 0.0343, 0.1405, 0.0407, 0.0471, 0.1336, 0.1828, 0.0367, 0.1636,
        0.0458, 0.0457], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:01,621][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.1989, 0.0702, 0.1055, 0.0588, 0.0863, 0.1028, 0.0842, 0.0623, 0.0932,
        0.0618, 0.0759], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:01,622][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.1659, 0.0600, 0.0982, 0.0553, 0.1046, 0.0935, 0.0659, 0.0254, 0.0714,
        0.0454, 0.2143], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:01,623][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.3052, 0.0425, 0.1285, 0.0405, 0.0516, 0.1090, 0.0483, 0.0514, 0.1059,
        0.0388, 0.0783], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:01,624][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.3018, 0.1329, 0.0284, 0.0591, 0.0742, 0.0183, 0.0339, 0.0741, 0.0292,
        0.0742, 0.1465, 0.0273], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:01,625][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ a] are: tensor([3.0256e-03, 2.6163e-03, 3.7189e-03, 1.9346e-03, 1.0791e-04, 9.8090e-03,
        3.0884e-02, 5.2244e-05, 1.0062e-03, 1.2490e-03, 2.1821e-04, 9.4538e-01],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:01,627][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.1958, 0.0371, 0.1276, 0.0368, 0.0882, 0.2068, 0.0292, 0.0189, 0.0842,
        0.0358, 0.1126, 0.0271], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:01,629][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0118, 0.0011, 0.0009, 0.0010, 0.0019, 0.0040, 0.0158, 0.0071, 0.0484,
        0.0494, 0.1316, 0.7269], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:01,630][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0622, 0.0120, 0.0063, 0.0067, 0.0637, 0.0165, 0.0178, 0.0174, 0.0321,
        0.0410, 0.5405, 0.1839], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:01,632][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0645, 0.0183, 0.1028, 0.0067, 0.0109, 0.0911, 0.2212, 0.0021, 0.0309,
        0.0029, 0.0074, 0.4415], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:01,634][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.1789, 0.2090, 0.0051, 0.1134, 0.0740, 0.0095, 0.0039, 0.1467, 0.0035,
        0.1543, 0.0952, 0.0064], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:01,636][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0371, 0.0072, 0.0120, 0.0068, 0.0251, 0.0242, 0.0422, 0.0347, 0.1244,
        0.0770, 0.3068, 0.3025], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:01,637][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0156, 0.0046, 0.0787, 0.0100, 0.0216, 0.0951, 0.2233, 0.0123, 0.1508,
        0.0149, 0.0275, 0.3456], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:01,639][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.1876, 0.0669, 0.1071, 0.0556, 0.0537, 0.1024, 0.0872, 0.0419, 0.0842,
        0.0558, 0.0699, 0.0877], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:01,641][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.1716, 0.0682, 0.1098, 0.0572, 0.0380, 0.1021, 0.1093, 0.0278, 0.0718,
        0.0456, 0.0397, 0.1590], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:01,642][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.2012, 0.0538, 0.0881, 0.0468, 0.0693, 0.0976, 0.0530, 0.0728, 0.1006,
        0.0475, 0.0968, 0.0726], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:01,644][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ ring] are: tensor([0.1477, 0.1740, 0.0458, 0.0516, 0.0457, 0.0329, 0.0439, 0.1199, 0.0412,
        0.0525, 0.0600, 0.0349, 0.1500], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:01,645][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ ring] are: tensor([1.0931e-04, 8.0768e-04, 3.3282e-04, 5.2779e-04, 3.0970e-04, 5.0213e-05,
        1.6594e-04, 1.0224e-04, 3.3548e-05, 3.0239e-04, 1.2654e-04, 1.3994e-05,
        9.9712e-01], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:01,647][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ ring] are: tensor([0.1498, 0.1178, 0.0750, 0.1432, 0.0323, 0.0801, 0.0521, 0.0551, 0.0274,
        0.1354, 0.0467, 0.0525, 0.0326], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:01,648][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ ring] are: tensor([1.4424e-03, 3.2627e-05, 5.0767e-06, 4.2676e-05, 8.3940e-05, 3.4188e-05,
        1.1712e-04, 2.5223e-03, 3.1494e-04, 2.8621e-03, 2.9323e-03, 3.2055e-03,
        9.8640e-01], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:01,650][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ ring] are: tensor([0.0297, 0.0190, 0.0028, 0.0125, 0.0208, 0.0037, 0.0092, 0.0117, 0.0112,
        0.0424, 0.0307, 0.0287, 0.7774], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:01,651][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ ring] are: tensor([1.1052e-03, 2.1990e-04, 4.3503e-06, 2.6818e-05, 1.3047e-05, 4.5886e-07,
        1.0776e-06, 9.5013e-05, 3.4200e-07, 7.8924e-06, 3.4336e-07, 6.7231e-07,
        9.9852e-01], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:01,653][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ ring] are: tensor([0.1561, 0.2660, 0.0377, 0.1159, 0.0350, 0.0192, 0.0173, 0.0744, 0.0308,
        0.1080, 0.0314, 0.0197, 0.0884], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:01,654][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ ring] are: tensor([0.0537, 0.0137, 0.0148, 0.0079, 0.0183, 0.0446, 0.0452, 0.0127, 0.1140,
        0.0449, 0.2561, 0.2862, 0.0878], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:01,655][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ ring] are: tensor([0.1769, 0.0264, 0.1052, 0.0333, 0.0578, 0.0893, 0.0744, 0.0667, 0.0809,
        0.0319, 0.0701, 0.1101, 0.0771], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:01,656][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ ring] are: tensor([0.1490, 0.0816, 0.1005, 0.0590, 0.0531, 0.0922, 0.0820, 0.0892, 0.0811,
        0.0578, 0.0586, 0.0902, 0.0056], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:01,657][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ ring] are: tensor([0.1010, 0.0554, 0.0809, 0.0520, 0.0603, 0.0820, 0.0669, 0.0440, 0.0665,
        0.0473, 0.0364, 0.0621, 0.2451], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:01,659][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ ring] are: tensor([0.1676, 0.0664, 0.0626, 0.0610, 0.0704, 0.0630, 0.0332, 0.1025, 0.0755,
        0.0617, 0.0925, 0.0469, 0.0969], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:01,660][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.2215, 0.0691, 0.0233, 0.0433, 0.1303, 0.0126, 0.0283, 0.0556, 0.0247,
        0.0560, 0.1398, 0.0283, 0.1507, 0.0167], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:01,662][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ to] are: tensor([2.8452e-03, 4.3141e-05, 2.1799e-02, 1.2193e-04, 2.6965e-04, 4.6072e-01,
        1.1718e-03, 1.1463e-04, 4.8518e-03, 7.3040e-05, 3.8288e-04, 7.0094e-04,
        1.0586e-05, 5.0689e-01], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:01,663][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.2042, 0.0332, 0.1009, 0.0289, 0.0564, 0.1531, 0.0299, 0.0158, 0.0603,
        0.0265, 0.0694, 0.0268, 0.0187, 0.1760], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:01,665][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ to] are: tensor([3.8842e-03, 4.6065e-05, 1.8600e-04, 1.3862e-04, 2.7054e-03, 1.9078e-03,
        2.3768e-03, 5.6341e-04, 6.3308e-03, 4.9664e-03, 2.3953e-01, 6.6723e-02,
        1.2350e-01, 5.4714e-01], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:01,666][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0425, 0.0058, 0.0037, 0.0017, 0.0708, 0.0139, 0.0084, 0.0195, 0.0122,
        0.0098, 0.3928, 0.0880, 0.0601, 0.2707], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:01,668][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0220, 0.0023, 0.0621, 0.0037, 0.0088, 0.3835, 0.1423, 0.0015, 0.0139,
        0.0016, 0.0044, 0.0967, 0.0024, 0.2546], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:01,670][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1205, 0.1032, 0.0054, 0.0366, 0.0357, 0.1598, 0.0034, 0.0718, 0.0041,
        0.0526, 0.0546, 0.0058, 0.0544, 0.2921], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:01,671][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0295, 0.0057, 0.0070, 0.0054, 0.0140, 0.0097, 0.0217, 0.0164, 0.0556,
        0.0483, 0.1351, 0.1837, 0.1431, 0.3247], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:01,673][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0131, 0.0038, 0.0865, 0.0071, 0.0192, 0.1179, 0.1594, 0.0095, 0.1361,
        0.0099, 0.0185, 0.1870, 0.0160, 0.2161], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:01,675][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.1576, 0.0519, 0.0902, 0.0474, 0.0481, 0.0862, 0.0770, 0.0368, 0.0721,
        0.0480, 0.0636, 0.0818, 0.0374, 0.1019], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:01,677][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.1247, 0.0387, 0.1073, 0.0428, 0.0663, 0.1201, 0.0835, 0.0280, 0.0766,
        0.0356, 0.0589, 0.0821, 0.0238, 0.1115], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:01,679][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.1796, 0.0494, 0.0817, 0.0399, 0.0672, 0.0810, 0.0394, 0.0643, 0.0852,
        0.0384, 0.0902, 0.0527, 0.0474, 0.0836], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:01,691][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:29:01,692][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:01,694][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:01,695][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:01,697][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:01,698][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:01,700][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:01,701][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:01,702][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:01,703][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:01,704][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:01,704][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:01,705][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:01,707][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Amanda] are: tensor([0.7423, 0.2577], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:01,708][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Amanda] are: tensor([3.1639e-04, 9.9968e-01], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:01,709][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Amanda] are: tensor([0.8436, 0.1564], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:01,711][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Amanda] are: tensor([0.0355, 0.9645], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:01,712][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Amanda] are: tensor([0.1067, 0.8933], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:01,714][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Amanda] are: tensor([0.0048, 0.9952], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:01,715][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Amanda] are: tensor([0.6518, 0.3482], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:01,717][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Amanda] are: tensor([0.9715, 0.0285], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:01,718][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Amanda] are: tensor([0.8405, 0.1595], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:01,720][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Amanda] are: tensor([0.9453, 0.0547], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:01,722][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Amanda] are: tensor([0.6894, 0.3106], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:01,723][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Amanda] are: tensor([0.7239, 0.2761], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:01,725][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.6827, 0.2594, 0.0579], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:01,726][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([4.4087e-03, 7.4961e-04, 9.9484e-01], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:01,728][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.4064, 0.0688, 0.5248], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:01,729][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.2290, 0.0997, 0.6712], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:01,731][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.6062, 0.2164, 0.1774], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:01,732][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.1820, 0.0177, 0.8003], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:01,734][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.6438, 0.3328, 0.0234], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:01,736][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.4191, 0.3655, 0.2154], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:01,737][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.2536, 0.0403, 0.7061], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:01,737][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.6158, 0.1302, 0.2539], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:01,738][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.6628, 0.1054, 0.2317], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:01,739][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.5518, 0.1019, 0.3463], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:01,740][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ John] are: tensor([0.3340, 0.3917, 0.1185, 0.1558], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:01,741][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ John] are: tensor([2.0011e-03, 7.1557e-04, 2.1659e-03, 9.9512e-01], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:01,742][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ John] are: tensor([0.6462, 0.1167, 0.1043, 0.1328], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:01,744][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ John] are: tensor([0.0323, 0.0053, 0.0016, 0.9607], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:01,746][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ John] are: tensor([0.1066, 0.1850, 0.0220, 0.6865], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:01,747][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ John] are: tensor([2.4545e-02, 2.3773e-05, 3.3886e-05, 9.7540e-01], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:01,748][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ John] are: tensor([0.3549, 0.4104, 0.0599, 0.1748], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:01,750][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ John] are: tensor([0.3594, 0.1316, 0.3600, 0.1491], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:01,752][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ John] are: tensor([0.2896, 0.1961, 0.1935, 0.3209], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:01,753][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ John] are: tensor([0.5558, 0.1413, 0.2271, 0.0758], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:01,755][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ John] are: tensor([0.4261, 0.0995, 0.1634, 0.3111], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:01,757][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ John] are: tensor([0.4384, 0.1817, 0.2244, 0.1555], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:01,758][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([0.4519, 0.1372, 0.0799, 0.0817, 0.2493], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:01,760][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([0.0012, 0.0010, 0.0018, 0.0010, 0.9950], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:01,762][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([0.6081, 0.0602, 0.1923, 0.0522, 0.0872], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:01,763][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([0.0308, 0.0010, 0.0020, 0.0015, 0.9647], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:01,765][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([0.4045, 0.0504, 0.0593, 0.0826, 0.4033], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:01,766][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([2.6716e-02, 4.4419e-05, 6.5624e-05, 1.3193e-04, 9.7304e-01],
       device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:01,768][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([0.2726, 0.2975, 0.0414, 0.3480, 0.0405], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:01,769][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([0.2438, 0.1140, 0.2593, 0.1671, 0.2159], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:01,770][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([0.3699, 0.0708, 0.3602, 0.1388, 0.0602], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:01,771][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([0.4249, 0.1476, 0.2077, 0.1056, 0.1141], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:01,771][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([0.4038, 0.0889, 0.1818, 0.0714, 0.2541], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:01,772][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([0.4761, 0.0768, 0.2370, 0.0902, 0.1199], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:01,773][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.4314, 0.1564, 0.0581, 0.0897, 0.2334, 0.0309], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:01,775][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([5.9629e-03, 2.0484e-04, 6.7586e-02, 3.6603e-04, 8.4855e-04, 9.2503e-01],
       device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:01,776][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.3912, 0.0579, 0.1762, 0.0438, 0.0794, 0.2516], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:01,778][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0321, 0.0035, 0.0209, 0.0243, 0.4547, 0.4645], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:01,779][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.1548, 0.0488, 0.0261, 0.0211, 0.6183, 0.1309], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:01,781][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0841, 0.0061, 0.1464, 0.0078, 0.0156, 0.7399], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:01,783][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.2825, 0.2097, 0.0155, 0.0730, 0.0736, 0.3456], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:01,784][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.1403, 0.0756, 0.1195, 0.1104, 0.3048, 0.2494], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:01,786][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0595, 0.0157, 0.3439, 0.0300, 0.0643, 0.4866], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:01,787][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.3527, 0.0963, 0.1888, 0.0890, 0.0886, 0.1846], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:01,789][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.3399, 0.0790, 0.2344, 0.0684, 0.0878, 0.1906], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:01,791][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.3432, 0.0853, 0.1823, 0.0761, 0.1260, 0.1870], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:01,793][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.4717, 0.1698, 0.0415, 0.1354, 0.1265, 0.0218, 0.0334],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:01,794][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([9.0572e-03, 4.3506e-04, 6.6368e-02, 6.9753e-03, 1.9016e-04, 8.6814e-02,
        8.3016e-01], device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:01,796][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.3361, 0.0470, 0.1432, 0.0472, 0.1106, 0.2756, 0.0403],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:01,797][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0493, 0.0104, 0.0227, 0.0356, 0.0832, 0.1779, 0.6209],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:01,799][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.2931, 0.0528, 0.0408, 0.0699, 0.2828, 0.1213, 0.1395],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:01,800][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.1731, 0.0231, 0.1467, 0.0398, 0.0397, 0.1305, 0.4471],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:01,802][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.3132, 0.3626, 0.0073, 0.2136, 0.0876, 0.0116, 0.0043],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:01,804][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.1216, 0.0356, 0.0846, 0.0615, 0.1502, 0.2350, 0.3116],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:01,805][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0302, 0.0087, 0.1935, 0.0254, 0.0518, 0.2073, 0.4832],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:01,805][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.3211, 0.0902, 0.1565, 0.0756, 0.0785, 0.1521, 0.1260],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:01,806][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.3429, 0.0799, 0.1646, 0.0794, 0.0435, 0.1118, 0.1777],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:01,807][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.2776, 0.0874, 0.1453, 0.0848, 0.1057, 0.1411, 0.1582],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:01,809][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ station] are: tensor([0.2966, 0.1166, 0.1320, 0.1184, 0.0752, 0.0639, 0.1008, 0.0965],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:01,810][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ station] are: tensor([5.8283e-04, 3.4998e-03, 4.0157e-03, 3.4884e-04, 1.0904e-03, 1.8392e-03,
        4.8303e-04, 9.8814e-01], device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:01,811][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ station] are: tensor([0.2717, 0.0605, 0.0797, 0.2035, 0.0697, 0.0839, 0.0676, 0.1634],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:01,813][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ station] are: tensor([1.2267e-02, 2.7548e-03, 1.7934e-04, 7.4200e-04, 6.2710e-03, 1.4358e-03,
        9.7010e-04, 9.7538e-01], device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:01,814][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ station] are: tensor([0.0582, 0.0365, 0.0055, 0.0479, 0.0308, 0.0102, 0.0167, 0.7941],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:01,815][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ station] are: tensor([1.2808e-02, 2.2023e-03, 1.8575e-05, 5.3677e-05, 5.4231e-05, 3.4071e-06,
        4.1063e-06, 9.8486e-01], device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:01,817][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ station] are: tensor([0.2325, 0.2446, 0.0394, 0.1916, 0.0247, 0.0261, 0.0330, 0.2082],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:01,819][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ station] are: tensor([0.0636, 0.1218, 0.0477, 0.0256, 0.1006, 0.1824, 0.3079, 0.1503],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:01,820][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ station] are: tensor([0.2279, 0.0577, 0.1546, 0.0955, 0.0594, 0.1382, 0.1080, 0.1587],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:01,822][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ station] are: tensor([0.2744, 0.1237, 0.1400, 0.1200, 0.0821, 0.1183, 0.1247, 0.0167],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:01,823][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ station] are: tensor([0.1585, 0.0841, 0.1450, 0.0673, 0.0584, 0.1086, 0.1007, 0.2773],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:01,825][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ station] are: tensor([0.2450, 0.0616, 0.1116, 0.0552, 0.0985, 0.1725, 0.0502, 0.2053],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:01,827][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.4482, 0.1218, 0.0206, 0.0856, 0.1211, 0.0189, 0.0599, 0.1100, 0.0139],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:01,828][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([3.4318e-03, 5.3800e-04, 2.5580e-02, 6.3632e-05, 5.2707e-04, 9.1309e-03,
        1.2520e-03, 1.1306e-04, 9.5936e-01], device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:01,830][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.2774, 0.0329, 0.1213, 0.0148, 0.0478, 0.0613, 0.0139, 0.0117, 0.4190],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:01,832][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0513, 0.0031, 0.0080, 0.0045, 0.0733, 0.0443, 0.1170, 0.0659, 0.6327],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:01,833][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.5167, 0.0436, 0.0153, 0.0225, 0.0717, 0.0517, 0.0283, 0.0752, 0.1749],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:01,835][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.1381, 0.0207, 0.1986, 0.0259, 0.0596, 0.0987, 0.1473, 0.0196, 0.2915],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:01,837][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.2980, 0.2368, 0.0104, 0.2019, 0.0641, 0.0205, 0.0068, 0.1553, 0.0064],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:01,838][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0528, 0.0250, 0.0335, 0.0536, 0.0682, 0.0898, 0.1768, 0.1559, 0.3443],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:01,838][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0338, 0.0080, 0.1761, 0.0166, 0.0213, 0.1564, 0.2288, 0.0121, 0.3469],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:01,839][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.2685, 0.0760, 0.1362, 0.0710, 0.0728, 0.1262, 0.1001, 0.0465, 0.1028],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:01,840][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.2294, 0.0864, 0.1650, 0.0641, 0.0702, 0.1368, 0.0996, 0.0371, 0.1113],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:01,842][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.2495, 0.0621, 0.1227, 0.0644, 0.0924, 0.1122, 0.0638, 0.0962, 0.1367],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:01,844][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ John] are: tensor([0.1759, 0.2278, 0.0582, 0.1035, 0.0170, 0.0437, 0.0457, 0.1679, 0.0530,
        0.1074], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:01,845][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ John] are: tensor([6.8058e-04, 1.3159e-04, 5.4025e-04, 5.4031e-01, 1.0901e-03, 2.4013e-04,
        8.8710e-04, 1.7020e-04, 4.1411e-05, 4.5590e-01], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:01,846][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ John] are: tensor([0.3292, 0.0799, 0.0662, 0.1090, 0.0478, 0.0700, 0.0841, 0.0323, 0.0843,
        0.0971], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:01,848][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ John] are: tensor([3.3841e-03, 7.0777e-05, 1.3784e-05, 1.0297e-02, 2.9064e-05, 9.5899e-05,
        4.5938e-04, 8.8485e-04, 5.8687e-04, 9.8418e-01], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:01,849][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ John] are: tensor([0.0249, 0.0258, 0.0039, 0.0972, 0.0069, 0.0080, 0.0094, 0.0077, 0.0204,
        0.7957], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:01,850][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ John] are: tensor([4.7452e-03, 5.2135e-06, 6.1960e-06, 5.7922e-01, 2.3079e-05, 1.0129e-06,
        1.9598e-05, 3.1250e-06, 2.2300e-06, 4.1597e-01], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:01,852][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ John] are: tensor([0.1767, 0.3001, 0.0340, 0.1465, 0.0360, 0.0165, 0.0276, 0.1041, 0.0281,
        0.1306], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:01,854][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ John] are: tensor([0.0923, 0.0208, 0.0394, 0.0231, 0.0276, 0.1018, 0.1422, 0.0674, 0.2504,
        0.2352], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:01,855][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ John] are: tensor([0.1061, 0.1030, 0.0880, 0.1615, 0.0256, 0.0728, 0.0990, 0.0460, 0.1129,
        0.1850], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:01,857][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ John] are: tensor([0.2588, 0.0889, 0.1235, 0.0442, 0.0628, 0.0988, 0.1038, 0.0743, 0.1039,
        0.0412], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:01,859][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ John] are: tensor([0.1368, 0.0545, 0.0843, 0.2573, 0.0352, 0.0661, 0.0706, 0.0226, 0.0583,
        0.2144], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:01,860][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ John] are: tensor([0.1778, 0.0966, 0.0806, 0.0733, 0.1546, 0.0780, 0.0517, 0.1092, 0.0931,
        0.0849], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:01,862][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.2748, 0.0797, 0.0331, 0.0349, 0.2224, 0.0216, 0.0204, 0.0489, 0.0237,
        0.0393, 0.2011], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:01,864][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([9.4592e-04, 1.2764e-03, 2.3565e-03, 7.4877e-04, 8.8363e-03, 1.1968e-03,
        3.2186e-04, 1.6744e-04, 3.6735e-04, 4.2558e-04, 9.8336e-01],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:01,865][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.3276, 0.0563, 0.0794, 0.0469, 0.0917, 0.1211, 0.0783, 0.0168, 0.0492,
        0.0408, 0.0918], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:01,866][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([2.3800e-03, 5.0589e-05, 2.9723e-05, 4.5886e-05, 1.0924e-03, 1.2993e-04,
        1.9825e-04, 5.5457e-04, 1.7775e-03, 3.2065e-03, 9.9053e-01],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:01,868][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.1317, 0.0412, 0.0137, 0.0191, 0.0377, 0.0310, 0.0204, 0.0231, 0.0443,
        0.1005, 0.5373], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:01,870][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([4.7273e-02, 1.4555e-04, 3.9483e-05, 6.3572e-04, 1.0246e-02, 4.1275e-06,
        1.4019e-05, 2.1761e-06, 1.8999e-06, 2.5451e-04, 9.4138e-01],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:01,871][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.1337, 0.1390, 0.0186, 0.2109, 0.0294, 0.0134, 0.0177, 0.1228, 0.0149,
        0.2679, 0.0317], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:01,872][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0488, 0.0115, 0.0217, 0.0187, 0.0247, 0.0494, 0.0827, 0.0485, 0.2030,
        0.2338, 0.2572], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:01,872][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.1292, 0.0343, 0.1405, 0.0407, 0.0471, 0.1336, 0.1828, 0.0367, 0.1636,
        0.0458, 0.0457], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:01,873][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.1989, 0.0702, 0.1055, 0.0588, 0.0863, 0.1028, 0.0842, 0.0623, 0.0932,
        0.0618, 0.0759], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:01,874][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.1659, 0.0600, 0.0982, 0.0553, 0.1046, 0.0935, 0.0659, 0.0254, 0.0714,
        0.0454, 0.2143], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:01,876][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.3052, 0.0425, 0.1285, 0.0405, 0.0516, 0.1090, 0.0483, 0.0514, 0.1059,
        0.0388, 0.0783], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:01,878][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.3018, 0.1329, 0.0284, 0.0591, 0.0742, 0.0183, 0.0339, 0.0741, 0.0292,
        0.0742, 0.1465, 0.0273], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:01,879][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([3.0256e-03, 2.6163e-03, 3.7189e-03, 1.9346e-03, 1.0791e-04, 9.8090e-03,
        3.0884e-02, 5.2244e-05, 1.0062e-03, 1.2490e-03, 2.1821e-04, 9.4538e-01],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:01,881][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.1958, 0.0371, 0.1276, 0.0368, 0.0882, 0.2068, 0.0292, 0.0189, 0.0842,
        0.0358, 0.1126, 0.0271], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:01,882][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0118, 0.0011, 0.0009, 0.0010, 0.0019, 0.0040, 0.0158, 0.0071, 0.0484,
        0.0494, 0.1316, 0.7269], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:01,884][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0622, 0.0120, 0.0063, 0.0067, 0.0637, 0.0165, 0.0178, 0.0174, 0.0321,
        0.0410, 0.5405, 0.1839], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:01,886][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0645, 0.0183, 0.1028, 0.0067, 0.0109, 0.0911, 0.2212, 0.0021, 0.0309,
        0.0029, 0.0074, 0.4415], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:01,887][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.1789, 0.2090, 0.0051, 0.1134, 0.0740, 0.0095, 0.0039, 0.1467, 0.0035,
        0.1543, 0.0952, 0.0064], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:01,889][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0371, 0.0072, 0.0120, 0.0068, 0.0251, 0.0242, 0.0422, 0.0347, 0.1244,
        0.0770, 0.3068, 0.3025], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:01,891][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0156, 0.0046, 0.0787, 0.0100, 0.0216, 0.0951, 0.2233, 0.0123, 0.1508,
        0.0149, 0.0275, 0.3456], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:01,893][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.1876, 0.0669, 0.1071, 0.0556, 0.0537, 0.1024, 0.0872, 0.0419, 0.0842,
        0.0558, 0.0699, 0.0877], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:01,894][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.1716, 0.0682, 0.1098, 0.0572, 0.0380, 0.1021, 0.1093, 0.0278, 0.0718,
        0.0456, 0.0397, 0.1590], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:01,896][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.2012, 0.0538, 0.0881, 0.0468, 0.0693, 0.0976, 0.0530, 0.0728, 0.1006,
        0.0475, 0.0968, 0.0726], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:01,898][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ ring] are: tensor([0.1477, 0.1740, 0.0458, 0.0516, 0.0457, 0.0329, 0.0439, 0.1199, 0.0412,
        0.0525, 0.0600, 0.0349, 0.1500], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:01,899][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ ring] are: tensor([1.0931e-04, 8.0768e-04, 3.3282e-04, 5.2779e-04, 3.0970e-04, 5.0213e-05,
        1.6594e-04, 1.0224e-04, 3.3548e-05, 3.0239e-04, 1.2654e-04, 1.3994e-05,
        9.9712e-01], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:01,901][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ ring] are: tensor([0.1498, 0.1178, 0.0750, 0.1432, 0.0323, 0.0801, 0.0521, 0.0551, 0.0274,
        0.1354, 0.0467, 0.0525, 0.0326], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:01,902][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ ring] are: tensor([1.4424e-03, 3.2627e-05, 5.0767e-06, 4.2676e-05, 8.3940e-05, 3.4188e-05,
        1.1712e-04, 2.5223e-03, 3.1494e-04, 2.8621e-03, 2.9323e-03, 3.2055e-03,
        9.8640e-01], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:01,904][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ ring] are: tensor([0.0297, 0.0190, 0.0028, 0.0125, 0.0208, 0.0037, 0.0092, 0.0117, 0.0112,
        0.0424, 0.0307, 0.0287, 0.7774], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:01,905][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ ring] are: tensor([1.1052e-03, 2.1990e-04, 4.3503e-06, 2.6818e-05, 1.3047e-05, 4.5886e-07,
        1.0776e-06, 9.5013e-05, 3.4200e-07, 7.8924e-06, 3.4336e-07, 6.7231e-07,
        9.9852e-01], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:01,906][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ ring] are: tensor([0.1561, 0.2660, 0.0377, 0.1159, 0.0350, 0.0192, 0.0173, 0.0744, 0.0308,
        0.1080, 0.0314, 0.0197, 0.0884], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:01,906][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ ring] are: tensor([0.0537, 0.0137, 0.0148, 0.0079, 0.0183, 0.0446, 0.0452, 0.0127, 0.1140,
        0.0449, 0.2561, 0.2862, 0.0878], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:01,907][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ ring] are: tensor([0.1769, 0.0264, 0.1052, 0.0333, 0.0578, 0.0893, 0.0744, 0.0667, 0.0809,
        0.0319, 0.0701, 0.1101, 0.0771], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:01,909][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ ring] are: tensor([0.1490, 0.0816, 0.1005, 0.0590, 0.0531, 0.0922, 0.0820, 0.0892, 0.0811,
        0.0578, 0.0586, 0.0902, 0.0056], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:01,911][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ ring] are: tensor([0.1010, 0.0554, 0.0809, 0.0520, 0.0603, 0.0820, 0.0669, 0.0440, 0.0665,
        0.0473, 0.0364, 0.0621, 0.2451], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:01,912][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ ring] are: tensor([0.1676, 0.0664, 0.0626, 0.0610, 0.0704, 0.0630, 0.0332, 0.1025, 0.0755,
        0.0617, 0.0925, 0.0469, 0.0969], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:01,914][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.2215, 0.0691, 0.0233, 0.0433, 0.1303, 0.0126, 0.0283, 0.0556, 0.0247,
        0.0560, 0.1398, 0.0283, 0.1507, 0.0167], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:01,915][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([2.8452e-03, 4.3141e-05, 2.1799e-02, 1.2193e-04, 2.6965e-04, 4.6072e-01,
        1.1718e-03, 1.1463e-04, 4.8518e-03, 7.3040e-05, 3.8288e-04, 7.0094e-04,
        1.0586e-05, 5.0689e-01], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:01,917][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.2042, 0.0332, 0.1009, 0.0289, 0.0564, 0.1531, 0.0299, 0.0158, 0.0603,
        0.0265, 0.0694, 0.0268, 0.0187, 0.1760], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:01,918][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([3.8842e-03, 4.6065e-05, 1.8600e-04, 1.3862e-04, 2.7054e-03, 1.9078e-03,
        2.3768e-03, 5.6341e-04, 6.3308e-03, 4.9664e-03, 2.3953e-01, 6.6723e-02,
        1.2350e-01, 5.4714e-01], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:01,920][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0425, 0.0058, 0.0037, 0.0017, 0.0708, 0.0139, 0.0084, 0.0195, 0.0122,
        0.0098, 0.3928, 0.0880, 0.0601, 0.2707], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:01,922][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0220, 0.0023, 0.0621, 0.0037, 0.0088, 0.3835, 0.1423, 0.0015, 0.0139,
        0.0016, 0.0044, 0.0967, 0.0024, 0.2546], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:01,924][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.1205, 0.1032, 0.0054, 0.0366, 0.0357, 0.1598, 0.0034, 0.0718, 0.0041,
        0.0526, 0.0546, 0.0058, 0.0544, 0.2921], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:01,925][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0295, 0.0057, 0.0070, 0.0054, 0.0140, 0.0097, 0.0217, 0.0164, 0.0556,
        0.0483, 0.1351, 0.1837, 0.1431, 0.3247], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:01,927][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0131, 0.0038, 0.0865, 0.0071, 0.0192, 0.1179, 0.1594, 0.0095, 0.1361,
        0.0099, 0.0185, 0.1870, 0.0160, 0.2161], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:01,929][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.1576, 0.0519, 0.0902, 0.0474, 0.0481, 0.0862, 0.0770, 0.0368, 0.0721,
        0.0480, 0.0636, 0.0818, 0.0374, 0.1019], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:01,931][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.1247, 0.0387, 0.1073, 0.0428, 0.0663, 0.1201, 0.0835, 0.0280, 0.0766,
        0.0356, 0.0589, 0.0821, 0.0238, 0.1115], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:01,933][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.1796, 0.0494, 0.0817, 0.0399, 0.0672, 0.0810, 0.0394, 0.0643, 0.0852,
        0.0384, 0.0902, 0.0527, 0.0474, 0.0836], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:01,936][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:29:01,938][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[10554],
        [    1],
        [20786],
        [11129],
        [ 6102],
        [22320],
        [28904],
        [ 4002],
        [10773],
        [17220],
        [ 6973],
        [37126],
        [35007],
        [28166]], device='cuda:0')
[2024-07-24 10:29:01,940][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[37613],
        [    1],
        [33866],
        [ 2154],
        [35930],
        [34627],
        [24823],
        [29192],
        [32008],
        [ 1017],
        [30419],
        [17077],
        [23995],
        [25734]], device='cuda:0')
[2024-07-24 10:29:01,941][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[5430],
        [2333],
        [1976],
        [1494],
        [2130],
        [2249],
        [1798],
        [3582],
        [2576],
        [2976],
        [4551],
        [2671],
        [4256],
        [5129]], device='cuda:0')
[2024-07-24 10:29:01,943][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[44929],
        [ 6029],
        [24510],
        [12156],
        [ 3386],
        [36362],
        [48220],
        [ 6921],
        [ 9193],
        [12373],
        [ 6867],
        [48167],
        [10113],
        [36748]], device='cuda:0')
[2024-07-24 10:29:01,944][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 6839],
        [ 6958],
        [15810],
        [ 7023],
        [10753],
        [14613],
        [13972],
        [11279],
        [14801],
        [ 7300],
        [11334],
        [15158],
        [ 8028],
        [14999]], device='cuda:0')
[2024-07-24 10:29:01,946][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[41825],
        [ 6816],
        [30909],
        [24682],
        [12012],
        [19606],
        [16851],
        [44728],
        [31348],
        [23505],
        [ 4396],
        [ 6536],
        [ 4954],
        [13308]], device='cuda:0')
[2024-07-24 10:29:01,948][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[ 3676],
        [ 1113],
        [ 1549],
        [12088],
        [ 5838],
        [ 7770],
        [ 3444],
        [46999],
        [ 3819],
        [20549],
        [ 9556],
        [ 7210],
        [19585],
        [ 5470]], device='cuda:0')
[2024-07-24 10:29:01,949][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[38251],
        [ 1651],
        [41344],
        [39081],
        [39086],
        [41566],
        [42036],
        [38529],
        [42115],
        [38614],
        [42869],
        [38575],
        [28188],
        [40980]], device='cuda:0')
[2024-07-24 10:29:01,951][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[33662],
        [ 1157],
        [ 1495],
        [  267],
        [  820],
        [ 8837],
        [  351],
        [ 5368],
        [ 3924],
        [ 1568],
        [ 6695],
        [ 3948],
        [ 3174],
        [15569]], device='cuda:0')
[2024-07-24 10:29:01,953][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[16834],
        [16243],
        [12402],
        [18856],
        [21968],
        [28600],
        [31183],
        [30420],
        [23395],
        [21610],
        [27524],
        [34906],
        [37764],
        [42562]], device='cuda:0')
[2024-07-24 10:29:01,954][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[ 8955],
        [ 7008],
        [22230],
        [ 3923],
        [10776],
        [24311],
        [26686],
        [14369],
        [31238],
        [ 8339],
        [23213],
        [32490],
        [28537],
        [30990]], device='cuda:0')
[2024-07-24 10:29:01,956][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[24398],
        [22643],
        [24804],
        [21757],
        [20221],
        [27140],
        [25794],
        [21597],
        [26578],
        [24043],
        [24256],
        [24541],
        [21604],
        [27181]], device='cuda:0')
[2024-07-24 10:29:01,957][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[21312],
        [30789],
        [10251],
        [38760],
        [ 9023],
        [ 4464],
        [19191],
        [15695],
        [ 7001],
        [44501],
        [ 6169],
        [22067],
        [12150],
        [ 7658]], device='cuda:0')
[2024-07-24 10:29:01,959][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[38715],
        [35841],
        [35289],
        [36505],
        [36851],
        [32606],
        [38750],
        [34499],
        [36032],
        [34740],
        [38249],
        [38192],
        [36571],
        [36361]], device='cuda:0')
[2024-07-24 10:29:01,961][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[23076],
        [    6],
        [41716],
        [31843],
        [34530],
        [35907],
        [48925],
        [25825],
        [20882],
        [33262],
        [43244],
        [48936],
        [49215],
        [35773]], device='cuda:0')
[2024-07-24 10:29:01,962][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[43415],
        [32214],
        [30204],
        [23177],
        [24181],
        [24917],
        [25521],
        [23858],
        [20847],
        [18180],
        [19828],
        [20334],
        [22403],
        [23875]], device='cuda:0')
[2024-07-24 10:29:01,964][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[10734],
        [29666],
        [18056],
        [40189],
        [40354],
        [16156],
        [ 8136],
        [31930],
        [25050],
        [40352],
        [38833],
        [ 9751],
        [38612],
        [15619]], device='cuda:0')
[2024-07-24 10:29:01,966][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[48431],
        [48475],
        [48445],
        [48237],
        [48150],
        [44120],
        [43643],
        [48347],
        [40555],
        [46924],
        [46704],
        [43905],
        [48074],
        [40375]], device='cuda:0')
[2024-07-24 10:29:01,967][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[31203],
        [16279],
        [18476],
        [ 7120],
        [10558],
        [12875],
        [14125],
        [ 8259],
        [15406],
        [ 7794],
        [17759],
        [15187],
        [25375],
        [19467]], device='cuda:0')
[2024-07-24 10:29:01,969][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[19698],
        [29301],
        [24915],
        [20233],
        [17844],
        [18197],
        [21164],
        [47025],
        [27362],
        [19488],
        [24256],
        [26287],
        [45281],
        [31400]], device='cuda:0')
[2024-07-24 10:29:01,970][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[33726],
        [33769],
        [34311],
        [28555],
        [23729],
        [35164],
        [31020],
        [11299],
        [34057],
        [28765],
        [18308],
        [34647],
        [24449],
        [35984]], device='cuda:0')
[2024-07-24 10:29:01,972][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[49702],
        [38659],
        [38496],
        [23081],
        [19351],
        [41746],
        [25103],
        [15237],
        [21220],
        [16070],
        [20270],
        [22926],
        [16986],
        [46532]], device='cuda:0')
[2024-07-24 10:29:01,974][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[39576],
        [39550],
        [34343],
        [29635],
        [29106],
        [17684],
        [10128],
        [ 9040],
        [ 8343],
        [16030],
        [21559],
        [16167],
        [15094],
        [ 9393]], device='cuda:0')
[2024-07-24 10:29:01,975][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[34592],
        [34545],
        [33866],
        [34000],
        [34363],
        [23903],
        [25058],
        [28535],
        [19102],
        [29176],
        [25261],
        [16938],
        [28010],
        [16284]], device='cuda:0')
[2024-07-24 10:29:01,976][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[35525],
        [34943],
        [32536],
        [30914],
        [29251],
        [29311],
        [30221],
        [29384],
        [28567],
        [28497],
        [28672],
        [29863],
        [29352],
        [28623]], device='cuda:0')
[2024-07-24 10:29:01,978][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[50046],
        [49407],
        [50144],
        [49751],
        [50083],
        [50145],
        [49912],
        [48922],
        [49968],
        [49244],
        [50110],
        [49551],
        [49406],
        [49868]], device='cuda:0')
[2024-07-24 10:29:01,979][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 9092],
        [ 7289],
        [ 6166],
        [28725],
        [14528],
        [25367],
        [26242],
        [14704],
        [28674],
        [42258],
        [28686],
        [38176],
        [42224],
        [38205]], device='cuda:0')
[2024-07-24 10:29:01,981][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[ 111],
        [1119],
        [1133],
        [2170],
        [1981],
        [2158],
        [4581],
        [4378],
        [4925],
        [4695],
        [2581],
        [5820],
        [3169],
        [3860]], device='cuda:0')
[2024-07-24 10:29:01,983][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[19444],
        [50232],
        [ 5638],
        [13672],
        [11843],
        [10613],
        [  812],
        [18649],
        [23308],
        [12613],
        [ 4908],
        [  723],
        [  689],
        [10758]], device='cuda:0')
[2024-07-24 10:29:01,984][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[28503],
        [28503],
        [28503],
        [28503],
        [28503],
        [28503],
        [28503],
        [28503],
        [28503],
        [28503],
        [28503],
        [28503],
        [28503],
        [28503]], device='cuda:0')
[2024-07-24 10:29:02,016][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:29:02,017][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:02,019][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:02,020][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:02,021][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:02,023][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:02,024][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:02,026][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:02,027][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:02,028][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:02,030][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:02,031][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:02,033][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:02,034][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Amanda] are: tensor([0.5001, 0.4999], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:02,036][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Amanda] are: tensor([0.5001, 0.4999], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:02,038][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Amanda] are: tensor([0.6838, 0.3162], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:02,039][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Amanda] are: tensor([0.4188, 0.5812], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:02,040][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Amanda] are: tensor([0.7224, 0.2776], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:02,041][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Amanda] are: tensor([0.3215, 0.6785], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:02,042][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Amanda] are: tensor([0.9813, 0.0187], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:02,042][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Amanda] are: tensor([0.0607, 0.9393], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:02,044][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Amanda] are: tensor([0.8625, 0.1375], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:02,045][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Amanda] are: tensor([0.0430, 0.9570], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:02,047][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Amanda] are: tensor([0.1727, 0.8273], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:02,049][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Amanda] are: tensor([0.0935, 0.9065], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:02,050][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.3333, 0.3332, 0.3335], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:02,051][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.3333, 0.3332, 0.3335], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:02,053][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.4919, 0.2324, 0.2757], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:02,054][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.2496, 0.7010, 0.0494], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:02,056][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.4805, 0.2314, 0.2882], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:02,057][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.4363, 0.0908, 0.4729], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:02,059][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.7825, 0.1720, 0.0455], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:02,061][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0342, 0.9204, 0.0454], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:02,062][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.7635, 0.1677, 0.0687], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:02,064][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0485, 0.7609, 0.1906], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:02,065][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.1008, 0.5086, 0.3907], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:02,067][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.3003, 0.0026, 0.6971], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:02,068][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ John] are: tensor([0.2500, 0.2499, 0.2501, 0.2501], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:02,070][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ John] are: tensor([0.2500, 0.2499, 0.2502, 0.2499], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:02,072][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ John] are: tensor([0.3724, 0.1868, 0.2215, 0.2193], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:02,073][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ John] are: tensor([0.2920, 0.5002, 0.0832, 0.1246], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:02,074][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ John] are: tensor([0.3061, 0.1586, 0.3350, 0.2003], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:02,074][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ John] are: tensor([0.0449, 0.7968, 0.0092, 0.1491], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:02,075][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ John] are: tensor([0.8106, 0.0221, 0.1490, 0.0182], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:02,076][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ John] are: tensor([0.0080, 0.8956, 0.0277, 0.0687], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:02,078][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ John] are: tensor([0.7930, 0.1298, 0.0424, 0.0348], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:02,079][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ John] are: tensor([0.0372, 0.6361, 0.1969, 0.1297], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:02,081][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ John] are: tensor([0.0759, 0.3423, 0.2700, 0.3118], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:02,082][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ John] are: tensor([2.0646e-03, 1.2482e-04, 4.2545e-03, 9.9356e-01], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:02,083][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ went] are: tensor([0.2000, 0.1999, 0.2001, 0.2001, 0.1999], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:02,085][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ went] are: tensor([0.2000, 0.2000, 0.2001, 0.1999, 0.2000], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:02,086][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ went] are: tensor([0.3231, 0.1481, 0.1750, 0.1776, 0.1762], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:02,088][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ went] are: tensor([0.2377, 0.4777, 0.0547, 0.1072, 0.1228], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:02,090][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ went] are: tensor([0.2328, 0.1196, 0.2299, 0.2014, 0.2164], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:02,091][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ went] are: tensor([0.4831, 0.0613, 0.1313, 0.0300, 0.2944], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:02,093][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ went] are: tensor([9.8414e-01, 2.8750e-04, 1.3223e-02, 6.4969e-04, 1.6997e-03],
       device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:02,094][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ went] are: tensor([0.0127, 0.5918, 0.0397, 0.1781, 0.1778], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:02,096][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.7423, 0.1058, 0.0446, 0.0435, 0.0638], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:02,098][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ went] are: tensor([0.0340, 0.5519, 0.1394, 0.0977, 0.1769], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:02,099][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ went] are: tensor([0.0523, 0.2482, 0.1948, 0.2343, 0.2704], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:02,100][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ went] are: tensor([2.2277e-03, 2.6009e-05, 1.0724e-02, 9.3551e-04, 9.8609e-01],
       device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:02,102][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.1667, 0.1666, 0.1668, 0.1667, 0.1666, 0.1666], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:02,104][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.1667, 0.1666, 0.1668, 0.1666, 0.1667, 0.1666], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:02,105][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.2627, 0.1299, 0.1463, 0.1578, 0.1547, 0.1486], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:02,106][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.2078, 0.5106, 0.0342, 0.0945, 0.1077, 0.0451], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:02,107][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.1269, 0.1012, 0.1316, 0.1466, 0.1606, 0.3331], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:02,108][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0093, 0.0158, 0.0017, 0.0033, 0.0012, 0.9687], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:02,109][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.4007, 0.0192, 0.0128, 0.0054, 0.5512, 0.0107], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:02,110][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0316, 0.4657, 0.0460, 0.1076, 0.3158, 0.0333], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:02,111][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.6063, 0.1413, 0.0613, 0.0551, 0.0811, 0.0548], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:02,113][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0537, 0.5857, 0.1108, 0.0824, 0.1220, 0.0455], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:02,114][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0438, 0.2127, 0.1604, 0.1965, 0.2277, 0.1589], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:02,116][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ to] are: tensor([9.0554e-02, 4.3559e-04, 1.8800e-01, 2.0101e-03, 9.4242e-04, 7.1806e-01],
       device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:02,117][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.1428, 0.1428, 0.1429, 0.1429, 0.1428, 0.1428, 0.1430],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:02,119][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.1429, 0.1428, 0.1429, 0.1428, 0.1428, 0.1428, 0.1430],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:02,121][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.2277, 0.1127, 0.1319, 0.1400, 0.1378, 0.1274, 0.1225],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:02,122][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.1925, 0.4407, 0.0373, 0.1044, 0.1045, 0.0439, 0.0766],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:02,124][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0994, 0.0778, 0.1172, 0.1050, 0.1252, 0.2271, 0.2484],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:02,126][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.1746, 0.3532, 0.0270, 0.1006, 0.0406, 0.2344, 0.0695],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:02,127][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.6972, 0.0323, 0.0292, 0.0479, 0.0323, 0.0188, 0.1424],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:02,129][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0120, 0.5825, 0.0113, 0.1177, 0.2302, 0.0071, 0.0391],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:02,131][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.5527, 0.1065, 0.0562, 0.0384, 0.0623, 0.0454, 0.1385],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:02,132][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0463, 0.5388, 0.1044, 0.0720, 0.1136, 0.0430, 0.0819],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:02,134][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0383, 0.1838, 0.1406, 0.1722, 0.1961, 0.1349, 0.1342],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:02,135][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ the] are: tensor([2.0142e-02, 6.5279e-04, 4.2372e-02, 2.5680e-03, 2.2801e-03, 1.8790e-02,
        9.1319e-01], device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:02,137][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ station] are: tensor([0.1249, 0.1249, 0.1250, 0.1250, 0.1249, 0.1249, 0.1251, 0.1252],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:02,138][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ station] are: tensor([0.1250, 0.1249, 0.1250, 0.1249, 0.1249, 0.1249, 0.1251, 0.1253],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:02,140][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ station] are: tensor([0.2261, 0.0963, 0.1170, 0.1175, 0.1140, 0.1119, 0.1012, 0.1160],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:02,141][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ station] are: tensor([0.2204, 0.4059, 0.0410, 0.0803, 0.0885, 0.0422, 0.0495, 0.0723],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:02,142][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ station] are: tensor([0.1810, 0.0628, 0.1229, 0.0879, 0.1064, 0.1944, 0.1753, 0.0693],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:02,142][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ station] are: tensor([0.0903, 0.0295, 0.0461, 0.0114, 0.3004, 0.1590, 0.1236, 0.2396],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:02,143][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ station] are: tensor([0.1680, 0.0239, 0.2545, 0.0425, 0.1307, 0.1330, 0.1098, 0.1375],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:02,145][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ station] are: tensor([0.0023, 0.6560, 0.0105, 0.1242, 0.1722, 0.0047, 0.0140, 0.0160],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:02,146][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ station] are: tensor([0.6344, 0.0692, 0.0355, 0.0300, 0.0453, 0.0314, 0.1485, 0.0058],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:02,148][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ station] are: tensor([0.0255, 0.3879, 0.1074, 0.0796, 0.1286, 0.0507, 0.0904, 0.1299],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:02,150][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ station] are: tensor([0.0326, 0.1550, 0.1251, 0.1469, 0.1644, 0.1168, 0.1116, 0.1476],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:02,151][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ station] are: tensor([1.2849e-03, 1.0749e-04, 7.0903e-03, 1.6609e-04, 4.2558e-04, 2.8972e-03,
        3.8271e-04, 9.8765e-01], device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:02,153][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.1111, 0.1110, 0.1112, 0.1111, 0.1110, 0.1111, 0.1112, 0.1113, 0.1109],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:02,155][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.1111, 0.1111, 0.1112, 0.1110, 0.1111, 0.1111, 0.1112, 0.1114, 0.1109],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:02,156][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.1818, 0.0891, 0.1008, 0.1079, 0.1074, 0.0989, 0.0923, 0.1078, 0.1139],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:02,158][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.1748, 0.3055, 0.0397, 0.0819, 0.1011, 0.0501, 0.0601, 0.1030, 0.0839],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:02,160][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0765, 0.0666, 0.0884, 0.0841, 0.1047, 0.1375, 0.1347, 0.0746, 0.2330],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:02,161][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0412, 0.0451, 0.0050, 0.0181, 0.0174, 0.0303, 0.0740, 0.0251, 0.7438],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:02,163][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.3530, 0.0446, 0.0150, 0.0128, 0.0854, 0.0205, 0.2380, 0.1799, 0.0508],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:02,165][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0156, 0.4933, 0.0285, 0.0934, 0.1596, 0.0210, 0.0508, 0.1039, 0.0339],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:02,166][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.4968, 0.1155, 0.0570, 0.0403, 0.0646, 0.0490, 0.1432, 0.0066, 0.0268],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:02,168][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0474, 0.4798, 0.0875, 0.0626, 0.0880, 0.0350, 0.0625, 0.0490, 0.0882],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:02,170][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0286, 0.1397, 0.1084, 0.1314, 0.1542, 0.1045, 0.1004, 0.1392, 0.0935],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:02,172][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.2053, 0.0691, 0.1879, 0.0470, 0.0321, 0.0843, 0.0657, 0.0973, 0.2113],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:02,173][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ John] are: tensor([0.1000, 0.0999, 0.1000, 0.1000, 0.0999, 0.1000, 0.1001, 0.1002, 0.0998,
        0.1000], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:02,174][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ John] are: tensor([0.1000, 0.1000, 0.1001, 0.0999, 0.1000, 0.1000, 0.1001, 0.1002, 0.0998,
        0.1000], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:02,175][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ John] are: tensor([0.1630, 0.0812, 0.0943, 0.0946, 0.0948, 0.0889, 0.0813, 0.0996, 0.1023,
        0.1000], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:02,176][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ John] are: tensor([0.1673, 0.2528, 0.0443, 0.0680, 0.0971, 0.0489, 0.0581, 0.1000, 0.0945,
        0.0688], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:02,177][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ John] are: tensor([0.0639, 0.0448, 0.1131, 0.0482, 0.0796, 0.1574, 0.1263, 0.0478, 0.2636,
        0.0555], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:02,178][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ John] are: tensor([0.0040, 0.5571, 0.0010, 0.1024, 0.0017, 0.0824, 0.0060, 0.0027, 0.0457,
        0.1968], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:02,180][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ John] are: tensor([0.5401, 0.0120, 0.1010, 0.0108, 0.0052, 0.0587, 0.2060, 0.0034, 0.0527,
        0.0101], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:02,182][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ John] are: tensor([0.0048, 0.6124, 0.0190, 0.0488, 0.0879, 0.0167, 0.0340, 0.1141, 0.0131,
        0.0492], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:02,183][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ John] are: tensor([0.6164, 0.0735, 0.0322, 0.0250, 0.0429, 0.0288, 0.1440, 0.0057, 0.0290,
        0.0025], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:02,185][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ John] are: tensor([0.0245, 0.3370, 0.0865, 0.0577, 0.0979, 0.0398, 0.0718, 0.0849, 0.1421,
        0.0577], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:02,186][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ John] are: tensor([0.0290, 0.1251, 0.0984, 0.1149, 0.1326, 0.0934, 0.0889, 0.1218, 0.0844,
        0.1117], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:02,188][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ John] are: tensor([2.9620e-05, 6.4044e-05, 1.3714e-04, 3.5219e-01, 1.2049e-04, 8.0208e-05,
        2.5155e-05, 1.3042e-05, 8.5880e-03, 6.3875e-01], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:02,189][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.0909, 0.0909, 0.0910, 0.0909, 0.0908, 0.0909, 0.0910, 0.0911, 0.0908,
        0.0909, 0.0908], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:02,191][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0909, 0.0909, 0.0910, 0.0908, 0.0909, 0.0909, 0.0910, 0.0911, 0.0908,
        0.0909, 0.0908], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:02,193][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.1512, 0.0720, 0.0835, 0.0852, 0.0858, 0.0815, 0.0728, 0.0881, 0.0935,
        0.0906, 0.0961], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:02,194][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.1595, 0.1996, 0.0379, 0.0563, 0.0815, 0.0468, 0.0498, 0.0792, 0.0835,
        0.0582, 0.1478], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:02,196][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.0742, 0.0413, 0.0863, 0.0665, 0.0732, 0.1395, 0.1042, 0.0385, 0.2081,
        0.0877, 0.0805], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:02,198][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.1172, 0.0218, 0.0184, 0.0087, 0.2340, 0.1343, 0.0933, 0.0191, 0.2045,
        0.0077, 0.1410], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:02,200][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.7235, 0.0029, 0.1197, 0.0037, 0.0326, 0.0208, 0.0091, 0.0038, 0.0140,
        0.0042, 0.0657], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:02,202][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0037, 0.3444, 0.0135, 0.0891, 0.1932, 0.0080, 0.0137, 0.1678, 0.0088,
        0.1081, 0.0497], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:02,203][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.5438, 0.0849, 0.0414, 0.0345, 0.0539, 0.0368, 0.1506, 0.0066, 0.0294,
        0.0026, 0.0154], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:02,205][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.0324, 0.3909, 0.0760, 0.0555, 0.0836, 0.0326, 0.0597, 0.0580, 0.0982,
        0.0475, 0.0656], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:02,206][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0233, 0.1104, 0.0854, 0.1031, 0.1223, 0.0837, 0.0796, 0.1104, 0.0747,
        0.1005, 0.1066], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:02,207][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([2.8109e-03, 4.5440e-04, 3.7200e-03, 1.5943e-03, 6.9623e-04, 1.3760e-03,
        9.1521e-05, 4.3505e-04, 1.1064e-02, 5.6929e-04, 9.7719e-01],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:02,208][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0833, 0.0833, 0.0834, 0.0834, 0.0833, 0.0833, 0.0834, 0.0835, 0.0832,
        0.0833, 0.0833, 0.0834], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:02,209][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0833, 0.0833, 0.0834, 0.0833, 0.0833, 0.0833, 0.0834, 0.0835, 0.0832,
        0.0833, 0.0833, 0.0834], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:02,210][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.1355, 0.0653, 0.0773, 0.0799, 0.0774, 0.0749, 0.0704, 0.0818, 0.0865,
        0.0856, 0.0874, 0.0778], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:02,212][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.1296, 0.1986, 0.0286, 0.0621, 0.0680, 0.0368, 0.0573, 0.0766, 0.0684,
        0.0653, 0.1387, 0.0700], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:02,213][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0487, 0.0321, 0.0645, 0.0411, 0.0530, 0.1193, 0.1293, 0.0533, 0.1909,
        0.0605, 0.0779, 0.1292], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:02,215][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0618, 0.2737, 0.0118, 0.0116, 0.0582, 0.0994, 0.0595, 0.0761, 0.2034,
        0.0054, 0.1222, 0.0168], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:02,217][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.3804, 0.0263, 0.0274, 0.0097, 0.0371, 0.0286, 0.2600, 0.0091, 0.0353,
        0.0104, 0.0439, 0.1319], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:02,218][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0101, 0.4537, 0.0121, 0.0794, 0.1537, 0.0089, 0.0262, 0.0545, 0.0124,
        0.0898, 0.0712, 0.0280], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:02,220][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.5740, 0.0821, 0.0431, 0.0291, 0.0495, 0.0354, 0.1293, 0.0054, 0.0253,
        0.0020, 0.0125, 0.0121], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:02,222][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0385, 0.4075, 0.0740, 0.0520, 0.0759, 0.0296, 0.0546, 0.0429, 0.0786,
        0.0412, 0.0539, 0.0513], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:02,224][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0219, 0.1029, 0.0792, 0.0962, 0.1106, 0.0761, 0.0743, 0.1022, 0.0687,
        0.0943, 0.1001, 0.0734], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:02,225][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ a] are: tensor([3.0772e-03, 1.1545e-03, 3.2108e-03, 1.1558e-04, 1.1408e-03, 5.8938e-03,
        1.1501e-03, 7.7544e-05, 1.4415e-02, 7.0627e-05, 1.3119e-04, 9.6956e-01],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:02,227][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ ring] are: tensor([0.0769, 0.0769, 0.0770, 0.0769, 0.0769, 0.0769, 0.0770, 0.0771, 0.0768,
        0.0769, 0.0769, 0.0769, 0.0769], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:02,228][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ ring] are: tensor([0.0769, 0.0769, 0.0770, 0.0769, 0.0769, 0.0769, 0.0770, 0.0771, 0.0768,
        0.0769, 0.0769, 0.0770, 0.0769], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:02,230][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ ring] are: tensor([0.1406, 0.0596, 0.0718, 0.0731, 0.0700, 0.0688, 0.0609, 0.0723, 0.0779,
        0.0766, 0.0799, 0.0665, 0.0819], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:02,232][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ ring] are: tensor([0.1312, 0.3033, 0.0248, 0.0564, 0.0590, 0.0269, 0.0317, 0.0505, 0.0590,
        0.0488, 0.1332, 0.0458, 0.0294], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:02,234][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ ring] are: tensor([0.0577, 0.0387, 0.0869, 0.0429, 0.0459, 0.1188, 0.0973, 0.0330, 0.2000,
        0.0581, 0.0683, 0.0851, 0.0673], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:02,235][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ ring] are: tensor([0.0383, 0.1094, 0.0090, 0.0114, 0.3480, 0.2418, 0.0284, 0.0162, 0.0326,
        0.0086, 0.1131, 0.0300, 0.0133], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:02,236][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ ring] are: tensor([1.2749e-03, 8.8965e-03, 1.4927e-03, 2.2732e-03, 6.0533e-04, 1.3685e-03,
        9.6264e-04, 1.7538e-05, 2.2443e-03, 2.0523e-03, 7.0751e-04, 1.5500e-03,
        9.7655e-01], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:02,238][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ ring] are: tensor([0.0047, 0.2509, 0.0128, 0.1268, 0.1343, 0.0083, 0.0346, 0.1530, 0.0098,
        0.1355, 0.0887, 0.0334, 0.0072], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:02,240][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ ring] are: tensor([0.6572, 0.0502, 0.0273, 0.0231, 0.0351, 0.0235, 0.1220, 0.0048, 0.0257,
        0.0023, 0.0113, 0.0150, 0.0026], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:02,241][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ ring] are: tensor([0.0177, 0.2545, 0.0683, 0.0483, 0.0797, 0.0317, 0.0552, 0.0753, 0.1160,
        0.0493, 0.0721, 0.0587, 0.0732], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:02,241][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ ring] are: tensor([0.0198, 0.0942, 0.0743, 0.0884, 0.0995, 0.0704, 0.0675, 0.0914, 0.0628,
        0.0853, 0.0897, 0.0659, 0.0908], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:02,242][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ ring] are: tensor([3.0616e-03, 7.4619e-04, 8.6719e-03, 4.7458e-04, 4.6224e-03, 3.1640e-03,
        2.1107e-04, 4.0760e-03, 7.1243e-03, 4.4900e-05, 1.9787e-03, 3.3251e-04,
        9.6549e-01], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:02,244][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0714, 0.0714, 0.0715, 0.0714, 0.0714, 0.0714, 0.0715, 0.0716, 0.0713,
        0.0714, 0.0714, 0.0714, 0.0714, 0.0715], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:02,245][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0714, 0.0714, 0.0715, 0.0714, 0.0714, 0.0714, 0.0715, 0.0716, 0.0713,
        0.0714, 0.0714, 0.0715, 0.0714, 0.0715], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:02,247][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1130, 0.0571, 0.0633, 0.0689, 0.0672, 0.0643, 0.0595, 0.0695, 0.0729,
        0.0744, 0.0784, 0.0658, 0.0803, 0.0653], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:02,249][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.1234, 0.2430, 0.0214, 0.0509, 0.0661, 0.0297, 0.0368, 0.0618, 0.0545,
        0.0506, 0.1423, 0.0483, 0.0383, 0.0329], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:02,250][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0347, 0.0287, 0.0503, 0.0378, 0.0421, 0.1128, 0.0851, 0.0352, 0.1272,
        0.0457, 0.0642, 0.0852, 0.0756, 0.1754], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:02,251][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ to] are: tensor([5.7337e-04, 3.4661e-03, 1.3299e-04, 1.0668e-03, 9.2360e-04, 2.1562e-01,
        2.8289e-03, 6.0826e-04, 6.9092e-04, 1.5252e-03, 4.2511e-04, 5.9974e-03,
        1.7521e-04, 7.6597e-01], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:02,253][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.2379, 0.0075, 0.0062, 0.0021, 0.2666, 0.0047, 0.0364, 0.0113, 0.0043,
        0.0025, 0.3020, 0.0618, 0.0530, 0.0038], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:02,255][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0147, 0.1975, 0.0230, 0.0503, 0.1379, 0.0164, 0.0210, 0.0969, 0.0387,
        0.0504, 0.1176, 0.0263, 0.1916, 0.0176], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:02,257][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.5654, 0.0872, 0.0443, 0.0312, 0.0514, 0.0359, 0.1239, 0.0054, 0.0237,
        0.0020, 0.0122, 0.0111, 0.0026, 0.0037], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:02,258][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0431, 0.4215, 0.0677, 0.0482, 0.0665, 0.0256, 0.0468, 0.0327, 0.0607,
        0.0347, 0.0437, 0.0423, 0.0400, 0.0263], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:02,260][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0187, 0.0882, 0.0663, 0.0814, 0.0939, 0.0657, 0.0625, 0.0865, 0.0585,
        0.0801, 0.0854, 0.0617, 0.0884, 0.0626], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:02,261][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ to] are: tensor([1.7646e-02, 1.0241e-04, 5.7559e-02, 6.7000e-04, 3.9450e-04, 3.1659e-01,
        1.0477e-03, 5.8693e-04, 7.1817e-02, 4.5030e-04, 3.9838e-04, 3.5487e-03,
        1.1331e-03, 5.2806e-01], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:02,281][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:29:02,282][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:02,284][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:02,284][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:02,284][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:02,285][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:02,285][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:02,285][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:02,286][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:02,286][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:02,286][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:02,287][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:02,287][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:02,287][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Amanda] are: tensor([0.1892, 0.8108], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:02,288][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Amanda] are: tensor([0.9753, 0.0247], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:02,289][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Amanda] are: tensor([0.9966, 0.0034], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:02,289][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Amanda] are: tensor([0.6449, 0.3551], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:02,289][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Amanda] are: tensor([0.1590, 0.8410], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:02,290][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Amanda] are: tensor([0.6077, 0.3923], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:02,290][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Amanda] are: tensor([0.0387, 0.9613], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:02,290][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Amanda] are: tensor([0.3024, 0.6976], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:02,291][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Amanda] are: tensor([0.7262, 0.2738], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:02,291][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Amanda] are: tensor([0.7929, 0.2071], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:02,291][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Amanda] are: tensor([2.9441e-04, 9.9971e-01], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:02,292][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Amanda] are: tensor([3.6757e-04, 9.9963e-01], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:02,293][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0418, 0.8584, 0.0998], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:02,294][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.7778, 0.1619, 0.0603], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:02,296][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.6816, 0.0075, 0.3109], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:02,297][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.3452, 0.1964, 0.4584], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:02,298][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.1105, 0.5775, 0.3120], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:02,300][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.2170, 0.0583, 0.7247], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:02,301][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([2.1894e-05, 9.9988e-01, 1.0155e-04], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:02,302][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2303, 0.5277, 0.2420], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:02,304][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.3570, 0.1186, 0.5244], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:02,305][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.3618, 0.3828, 0.2554], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:02,306][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0010, 0.5238, 0.4752], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:02,307][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([3.0882e-03, 1.8146e-07, 9.9691e-01], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:02,309][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ John] are: tensor([0.0329, 0.5241, 0.0642, 0.3787], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:02,310][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ John] are: tensor([0.6665, 0.0854, 0.1913, 0.0569], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:02,311][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ John] are: tensor([0.6080, 0.0099, 0.3208, 0.0613], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:02,313][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ John] are: tensor([0.2665, 0.1385, 0.3476, 0.2474], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:02,314][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ John] are: tensor([0.0684, 0.4240, 0.2322, 0.2753], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:02,315][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ John] are: tensor([0.1909, 0.1796, 0.5443, 0.0852], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:02,317][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ John] are: tensor([0.0023, 0.1423, 0.1194, 0.7360], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:02,318][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ John] are: tensor([0.1028, 0.5363, 0.1567, 0.2042], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:02,319][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ John] are: tensor([0.3275, 0.1066, 0.4428, 0.1232], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:02,319][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ John] are: tensor([0.4527, 0.2611, 0.1626, 0.1236], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:02,320][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ John] are: tensor([0.0009, 0.3533, 0.3755, 0.2703], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:02,320][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ John] are: tensor([4.8512e-04, 4.9494e-06, 3.5270e-01, 6.4681e-01], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:02,320][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([0.0550, 0.2162, 0.0804, 0.4178, 0.2305], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:02,321][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([0.6000, 0.0851, 0.1769, 0.0877, 0.0503], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:02,321][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([0.5147, 0.0093, 0.2738, 0.0563, 0.1457], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:02,321][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([0.2217, 0.1173, 0.2822, 0.2140, 0.1648], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:02,322][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([0.0550, 0.3107, 0.1763, 0.2069, 0.2511], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:02,322][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([0.2694, 0.0985, 0.4551, 0.0268, 0.1502], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:02,322][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([0.0721, 0.0256, 0.2828, 0.2494, 0.3702], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:02,323][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([0.0839, 0.3178, 0.1238, 0.1926, 0.2819], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:02,324][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([0.3005, 0.1164, 0.3867, 0.1080, 0.0884], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:02,325][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([0.3229, 0.2507, 0.1063, 0.1180, 0.2021], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:02,326][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([0.0009, 0.2541, 0.2367, 0.2080, 0.3003], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:02,327][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([6.1733e-05, 8.1757e-07, 2.6188e-02, 7.5914e-07, 9.7375e-01],
       device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:02,329][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0191, 0.0933, 0.0241, 0.1131, 0.7404, 0.0101], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:02,330][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.4123, 0.1020, 0.1790, 0.0992, 0.1253, 0.0821], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:02,331][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.4019, 0.0075, 0.1983, 0.0426, 0.1093, 0.2404], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:02,333][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.1674, 0.0928, 0.1959, 0.1702, 0.1309, 0.2429], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:02,334][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0562, 0.2582, 0.1460, 0.1825, 0.2103, 0.1468], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:02,336][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.2585, 0.0673, 0.4374, 0.0337, 0.0709, 0.1322], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:02,336][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([9.9770e-05, 4.6888e-02, 6.3292e-04, 1.5913e-02, 9.3226e-01, 4.2067e-03],
       device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:02,338][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.1100, 0.2174, 0.1054, 0.1468, 0.2095, 0.2109], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:02,339][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.1709, 0.0614, 0.2526, 0.0681, 0.0523, 0.3947], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:02,341][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.1696, 0.2449, 0.1164, 0.0737, 0.1288, 0.2665], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:02,342][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0016, 0.1952, 0.1747, 0.1524, 0.2365, 0.2395], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:02,343][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([8.9765e-05, 2.9007e-09, 8.8965e-03, 6.5697e-09, 2.8051e-08, 9.9101e-01],
       device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:02,345][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0457, 0.1552, 0.0753, 0.2366, 0.1698, 0.1641, 0.1533],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:02,346][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.3690, 0.0693, 0.1082, 0.0888, 0.1541, 0.1374, 0.0733],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:02,347][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.2885, 0.0079, 0.1858, 0.0371, 0.1039, 0.1990, 0.1778],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:02,349][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.1305, 0.0736, 0.1644, 0.1477, 0.0985, 0.1725, 0.2129],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:02,350][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0472, 0.2253, 0.1298, 0.1643, 0.1841, 0.1244, 0.1250],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:02,351][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.0713, 0.0252, 0.2066, 0.0269, 0.0247, 0.0227, 0.6227],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:02,352][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([2.8203e-05, 1.3183e-01, 1.6285e-03, 7.5825e-01, 9.7386e-02, 1.0882e-02,
        3.3165e-07], device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:02,352][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0950, 0.2014, 0.0782, 0.1305, 0.1616, 0.1435, 0.1898],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:02,352][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.1160, 0.0431, 0.1733, 0.0469, 0.0389, 0.2578, 0.3240],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:02,353][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.1204, 0.2346, 0.1073, 0.0689, 0.1332, 0.1984, 0.1371],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:02,353][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0016, 0.1465, 0.1392, 0.1281, 0.1926, 0.1953, 0.1967],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:02,353][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([3.0063e-04, 7.8091e-07, 1.3296e-01, 1.1225e-05, 1.7101e-06, 1.3496e-03,
        8.6538e-01], device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:02,354][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ station] are: tensor([0.0055, 0.1586, 0.0304, 0.2711, 0.2807, 0.0923, 0.1509, 0.0105],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:02,354][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ station] are: tensor([0.2781, 0.0728, 0.1229, 0.0641, 0.0898, 0.0874, 0.2622, 0.0228],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:02,354][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ station] are: tensor([0.1960, 0.0065, 0.1543, 0.0339, 0.0933, 0.2033, 0.1943, 0.1184],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:02,355][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ station] are: tensor([0.1490, 0.0579, 0.1755, 0.1134, 0.0908, 0.1940, 0.1755, 0.0439],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:02,356][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ station] are: tensor([0.0358, 0.1923, 0.1202, 0.1342, 0.1600, 0.1087, 0.1094, 0.1394],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:02,357][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ station] are: tensor([0.0555, 0.0257, 0.1689, 0.0084, 0.0353, 0.0128, 0.6909, 0.0025],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:02,358][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ station] are: tensor([2.5959e-04, 4.9840e-02, 5.2477e-02, 2.3559e-01, 1.9731e-01, 1.8819e-01,
        6.7475e-05, 2.7627e-01], device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:02,360][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ station] are: tensor([0.0515, 0.2564, 0.0666, 0.1230, 0.1891, 0.0989, 0.1478, 0.0669],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:02,361][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ station] are: tensor([0.1053, 0.0367, 0.1512, 0.0441, 0.0312, 0.2620, 0.3163, 0.0533],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:02,362][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ station] are: tensor([0.1839, 0.1220, 0.0534, 0.0654, 0.0994, 0.2756, 0.1832, 0.0170],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:02,364][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ station] are: tensor([0.0007, 0.1273, 0.1318, 0.1118, 0.1631, 0.1786, 0.1625, 0.1241],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:02,365][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ station] are: tensor([7.8073e-05, 1.9964e-05, 3.1039e-01, 1.2676e-06, 5.1298e-06, 4.6380e-02,
        1.1734e-06, 6.4313e-01], device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:02,366][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0404, 0.2079, 0.0547, 0.2062, 0.1044, 0.0821, 0.1984, 0.0379, 0.0678],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:02,368][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.3108, 0.0778, 0.0872, 0.1141, 0.1034, 0.0686, 0.1124, 0.0520, 0.0737],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:02,369][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.1659, 0.0058, 0.1157, 0.0237, 0.0676, 0.1206, 0.1107, 0.0932, 0.2968],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:02,370][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.1198, 0.0597, 0.1451, 0.1171, 0.0854, 0.1598, 0.1544, 0.0481, 0.1107],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:02,372][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0385, 0.1766, 0.0998, 0.1262, 0.1459, 0.0947, 0.0926, 0.1311, 0.0946],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:02,373][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0631, 0.0228, 0.1777, 0.0131, 0.0194, 0.0149, 0.4466, 0.0046, 0.2378],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:02,374][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([1.1441e-05, 6.5574e-02, 2.0553e-04, 2.4453e-02, 1.0696e-01, 5.1676e-03,
        5.3327e-07, 7.9713e-01, 4.9962e-04], device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:02,376][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0709, 0.1455, 0.0677, 0.0972, 0.1107, 0.1327, 0.1532, 0.0904, 0.1317],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:02,377][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0818, 0.0367, 0.1226, 0.0342, 0.0272, 0.1660, 0.2302, 0.0525, 0.2487],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:02,379][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0820, 0.1658, 0.0768, 0.0386, 0.0769, 0.1439, 0.0704, 0.0270, 0.3185],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:02,380][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0016, 0.0990, 0.0941, 0.0932, 0.1431, 0.1402, 0.1320, 0.1062, 0.1907],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:02,381][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([2.7553e-02, 1.2789e-04, 7.5891e-01, 4.8082e-05, 2.6788e-05, 7.7770e-02,
        7.1223e-04, 7.4766e-06, 1.3485e-01], device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:02,382][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ John] are: tensor([0.0138, 0.2397, 0.0313, 0.1708, 0.0818, 0.0328, 0.1512, 0.0210, 0.1033,
        0.1542], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:02,383][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ John] are: tensor([0.1528, 0.0238, 0.0446, 0.0197, 0.0762, 0.0769, 0.1146, 0.0652, 0.3474,
        0.0789], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:02,383][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ John] are: tensor([0.1376, 0.0068, 0.1112, 0.0245, 0.0650, 0.1098, 0.1122, 0.1092, 0.2698,
        0.0538], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:02,384][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ John] are: tensor([0.1076, 0.0525, 0.1347, 0.0960, 0.0794, 0.1378, 0.1347, 0.0463, 0.1084,
        0.1026], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:02,384][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ John] are: tensor([0.0283, 0.1685, 0.0914, 0.1112, 0.1286, 0.0821, 0.0814, 0.1192, 0.0861,
        0.1031], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:02,384][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ John] are: tensor([0.0512, 0.0401, 0.1455, 0.0216, 0.0148, 0.0143, 0.5080, 0.0019, 0.1642,
        0.0384], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:02,385][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ John] are: tensor([5.8037e-04, 5.9782e-02, 4.7345e-02, 3.2106e-01, 1.6876e-02, 1.6910e-01,
        1.4689e-04, 1.0412e-01, 7.3235e-03, 2.7366e-01], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:02,385][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ John] are: tensor([0.0434, 0.1958, 0.0594, 0.0761, 0.1100, 0.0936, 0.1369, 0.0780, 0.1030,
        0.1037], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:02,385][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ John] are: tensor([0.0755, 0.0270, 0.1120, 0.0292, 0.0263, 0.2003, 0.2144, 0.0444, 0.2310,
        0.0400], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:02,386][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ John] are: tensor([0.0996, 0.1083, 0.0452, 0.0413, 0.0548, 0.1597, 0.1072, 0.0136, 0.3254,
        0.0449], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:02,386][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ John] are: tensor([0.0018, 0.0818, 0.0862, 0.0769, 0.1187, 0.1300, 0.1145, 0.0887, 0.1706,
        0.1307], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:02,387][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ John] are: tensor([1.2177e-04, 2.2657e-06, 9.9155e-02, 4.4849e-01, 5.2551e-06, 5.0980e-03,
        3.4710e-06, 2.5398e-08, 1.3936e-01, 3.0776e-01], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:02,388][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.0091, 0.1240, 0.0368, 0.1195, 0.2437, 0.0525, 0.1090, 0.0234, 0.0724,
        0.1016, 0.1079], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:02,389][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.1803, 0.0354, 0.0459, 0.0421, 0.0248, 0.0599, 0.0856, 0.0253, 0.2680,
        0.1615, 0.0714], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:02,391][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.1524, 0.0065, 0.1015, 0.0251, 0.0593, 0.1012, 0.0900, 0.1044, 0.2439,
        0.0514, 0.0642], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:02,392][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.1049, 0.0468, 0.1237, 0.0878, 0.0712, 0.1460, 0.1279, 0.0400, 0.1044,
        0.0950, 0.0523], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:02,394][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.0269, 0.1387, 0.0804, 0.0980, 0.1183, 0.0772, 0.0739, 0.1028, 0.0782,
        0.0922, 0.1134], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:02,395][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.0807, 0.0375, 0.1452, 0.0090, 0.0363, 0.0187, 0.4367, 0.0015, 0.1665,
        0.0158, 0.0520], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:02,396][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([3.0668e-04, 9.0830e-04, 1.1767e-01, 2.1989e-02, 1.0554e-01, 8.8335e-02,
        4.4668e-06, 3.2706e-01, 3.9989e-03, 4.2519e-02, 2.9167e-01],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:02,397][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0452, 0.1412, 0.0541, 0.0817, 0.1313, 0.0906, 0.1134, 0.0757, 0.0873,
        0.1129, 0.0667], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:02,399][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.0784, 0.0273, 0.1178, 0.0300, 0.0257, 0.1713, 0.2298, 0.0429, 0.2169,
        0.0401, 0.0199], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:02,400][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.0793, 0.0859, 0.0399, 0.0394, 0.0687, 0.1431, 0.1306, 0.0152, 0.2996,
        0.0410, 0.0572], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:02,402][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0012, 0.0742, 0.0723, 0.0669, 0.1096, 0.1052, 0.0948, 0.0769, 0.1377,
        0.1065, 0.1547], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:02,403][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([3.7596e-04, 1.5512e-04, 5.8888e-02, 1.2181e-06, 9.6958e-06, 1.8375e-02,
        1.0875e-07, 1.3173e-07, 3.8109e-02, 5.8462e-07, 8.8408e-01],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:02,404][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0095, 0.0655, 0.0318, 0.1446, 0.1428, 0.0436, 0.1209, 0.0082, 0.0708,
        0.1294, 0.1642, 0.0688], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:02,406][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.1035, 0.0200, 0.0286, 0.0303, 0.0277, 0.0495, 0.0837, 0.0389, 0.2287,
        0.1460, 0.1961, 0.0472], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:02,407][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.1357, 0.0058, 0.0894, 0.0224, 0.0531, 0.0903, 0.0922, 0.0956, 0.2215,
        0.0485, 0.0604, 0.0852], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:02,409][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0842, 0.0435, 0.0984, 0.0883, 0.0585, 0.1100, 0.1287, 0.0361, 0.0842,
        0.0954, 0.0453, 0.1275], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:02,410][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0283, 0.1241, 0.0763, 0.0912, 0.1008, 0.0726, 0.0728, 0.1040, 0.0734,
        0.0863, 0.1041, 0.0661], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:02,411][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0428, 0.0169, 0.1348, 0.0079, 0.0120, 0.0150, 0.3569, 0.0020, 0.1596,
        0.0137, 0.0208, 0.2174], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:02,412][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([1.5955e-05, 9.4435e-02, 2.3126e-03, 5.0035e-02, 9.6572e-02, 1.2281e-02,
        2.7053e-06, 3.8538e-01, 7.0648e-04, 1.0842e-01, 2.4982e-01, 1.6233e-05],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:02,414][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0608, 0.1162, 0.0475, 0.0733, 0.0938, 0.0948, 0.1101, 0.0544, 0.0873,
        0.0957, 0.0607, 0.1053], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:02,415][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0659, 0.0248, 0.1046, 0.0249, 0.0221, 0.1406, 0.1925, 0.0390, 0.1963,
        0.0327, 0.0191, 0.1377], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:02,415][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0623, 0.1093, 0.0495, 0.0349, 0.0789, 0.1152, 0.0736, 0.0204, 0.2510,
        0.0336, 0.0507, 0.1205], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:02,415][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0017, 0.0593, 0.0575, 0.0566, 0.0865, 0.0905, 0.0870, 0.0639, 0.1253,
        0.0973, 0.1470, 0.1274], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:02,416][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([2.1324e-05, 5.2245e-06, 2.4409e-03, 2.9411e-08, 3.7280e-07, 1.0313e-03,
        1.9725e-05, 1.0165e-10, 1.2470e-03, 1.3584e-08, 4.3667e-07, 9.9523e-01],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:02,416][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ ring] are: tensor([0.0017, 0.0917, 0.0113, 0.0839, 0.2818, 0.0176, 0.0874, 0.0064, 0.0360,
        0.0751, 0.2059, 0.0843, 0.0169], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:02,417][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ ring] are: tensor([0.0658, 0.0196, 0.0188, 0.0134, 0.0323, 0.0307, 0.0578, 0.0119, 0.1720,
        0.0751, 0.1988, 0.2149, 0.0890], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:02,417][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ ring] are: tensor([0.1008, 0.0054, 0.0797, 0.0225, 0.0497, 0.0826, 0.0848, 0.0913, 0.2074,
        0.0552, 0.0679, 0.0884, 0.0645], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:02,417][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ ring] are: tensor([0.0865, 0.0415, 0.1073, 0.0780, 0.0604, 0.1210, 0.1063, 0.0328, 0.0874,
        0.0829, 0.0439, 0.1070, 0.0449], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:02,418][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ ring] are: tensor([0.0227, 0.1240, 0.0734, 0.0842, 0.0949, 0.0673, 0.0653, 0.0857, 0.0682,
        0.0783, 0.0970, 0.0555, 0.0835], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:02,419][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ ring] are: tensor([0.0491, 0.0194, 0.1248, 0.0059, 0.0256, 0.0096, 0.4151, 0.0014, 0.1274,
        0.0106, 0.0201, 0.1843, 0.0064], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:02,419][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ ring] are: tensor([8.6696e-05, 5.3591e-01, 1.9410e-03, 1.0734e-01, 8.4697e-03, 1.6914e-02,
        1.6173e-06, 4.7497e-03, 1.2039e-03, 9.1513e-02, 2.3971e-02, 7.8983e-05,
        2.0782e-01], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:02,421][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ ring] are: tensor([0.0339, 0.1159, 0.0393, 0.0694, 0.1106, 0.0688, 0.1106, 0.0628, 0.0790,
        0.0978, 0.0668, 0.0965, 0.0486], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:02,422][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ ring] are: tensor([0.0647, 0.0228, 0.0959, 0.0270, 0.0193, 0.1482, 0.1913, 0.0364, 0.1824,
        0.0367, 0.0145, 0.1172, 0.0436], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:02,424][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ ring] are: tensor([0.0665, 0.0699, 0.0277, 0.0281, 0.0501, 0.1059, 0.0751, 0.0103, 0.2443,
        0.0295, 0.0495, 0.2072, 0.0359], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:02,425][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ ring] are: tensor([0.0013, 0.0511, 0.0522, 0.0488, 0.0712, 0.0824, 0.0709, 0.0553, 0.1128,
        0.0873, 0.1260, 0.1072, 0.1334], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:02,426][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ ring] are: tensor([1.9953e-05, 9.6429e-06, 5.2095e-02, 3.8422e-06, 4.9686e-05, 9.7731e-03,
        4.3255e-07, 1.1238e-05, 2.1240e-02, 1.4850e-06, 6.6758e-06, 1.3022e-05,
        9.1678e-01], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:02,427][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0086, 0.0468, 0.0124, 0.0587, 0.3599, 0.0044, 0.0464, 0.0056, 0.0275,
        0.0538, 0.2850, 0.0596, 0.0287, 0.0028], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:02,429][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0801, 0.0149, 0.0210, 0.0173, 0.0222, 0.0137, 0.0464, 0.0189, 0.1253,
        0.0745, 0.1039, 0.1240, 0.2446, 0.0932], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:02,430][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0932, 0.0065, 0.0790, 0.0188, 0.0474, 0.0736, 0.0754, 0.0806, 0.1765,
        0.0369, 0.0530, 0.0632, 0.0501, 0.1457], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:02,431][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0738, 0.0389, 0.0819, 0.0712, 0.0557, 0.1027, 0.0987, 0.0314, 0.0714,
        0.0768, 0.0411, 0.0981, 0.0450, 0.1133], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:02,433][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0257, 0.1099, 0.0624, 0.0782, 0.0879, 0.0627, 0.0618, 0.0846, 0.0617,
        0.0750, 0.0934, 0.0572, 0.0843, 0.0552], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:02,434][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0680, 0.0175, 0.1269, 0.0095, 0.0156, 0.0382, 0.3380, 0.0034, 0.1100,
        0.0168, 0.0229, 0.1883, 0.0059, 0.0389], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:02,435][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([2.4773e-05, 1.0941e-02, 4.5651e-04, 4.4645e-03, 3.5429e-01, 1.3489e-03,
        1.0579e-06, 2.2275e-02, 1.4585e-04, 1.0014e-02, 5.4653e-01, 1.8736e-05,
        4.6252e-02, 3.2411e-03], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:02,437][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0479, 0.0789, 0.0413, 0.0577, 0.0738, 0.0888, 0.0928, 0.0537, 0.0874,
        0.0731, 0.0557, 0.0913, 0.0790, 0.0786], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:02,438][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0519, 0.0203, 0.0806, 0.0219, 0.0177, 0.1247, 0.1451, 0.0308, 0.1597,
        0.0288, 0.0151, 0.1106, 0.0351, 0.1577], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:02,440][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0618, 0.1089, 0.0460, 0.0317, 0.0560, 0.0909, 0.0594, 0.0185, 0.1960,
        0.0312, 0.0389, 0.1051, 0.0675, 0.0881], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:02,441][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0027, 0.0433, 0.0401, 0.0406, 0.0653, 0.0666, 0.0609, 0.0462, 0.0900,
        0.0724, 0.1145, 0.0893, 0.1166, 0.1514], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:02,442][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([2.1920e-05, 8.3132e-10, 2.6433e-03, 1.8052e-09, 8.0313e-09, 3.8646e-01,
        2.1800e-08, 2.3720e-10, 3.8981e-04, 9.3168e-10, 4.7100e-09, 2.8742e-07,
        2.5522e-10, 6.1049e-01], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:02,443][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:29:02,444][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[14989],
        [   60],
        [14463],
        [14172],
        [ 9768],
        [22237],
        [18224],
        [ 3484],
        [ 8053],
        [16335],
        [ 9795],
        [20015],
        [36961],
        [32150]], device='cuda:0')
[2024-07-24 10:29:02,446][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 7710],
        [    2],
        [29556],
        [22827],
        [12773],
        [28196],
        [28305],
        [ 1007],
        [15657],
        [28652],
        [10136],
        [36895],
        [44692],
        [30973]], device='cuda:0')
[2024-07-24 10:29:02,447][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[18202],
        [18202],
        [18179],
        [18196],
        [18197],
        [18202],
        [18192],
        [18185],
        [18180],
        [18177],
        [18178],
        [18186],
        [18183],
        [18185]], device='cuda:0')
[2024-07-24 10:29:02,448][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[35874],
        [35864],
        [35856],
        [35865],
        [35867],
        [35871],
        [35872],
        [35875],
        [35876],
        [35879],
        [35880],
        [35878],
        [35873],
        [35875]], device='cuda:0')
[2024-07-24 10:29:02,449][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[47639],
        [48002],
        [48009],
        [48489],
        [48314],
        [48384],
        [48367],
        [48266],
        [48306],
        [48434],
        [48268],
        [48301],
        [48349],
        [48371]], device='cuda:0')
[2024-07-24 10:29:02,450][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[11878],
        [20850],
        [22497],
        [19015],
        [17477],
        [18455],
        [15801],
        [15621],
        [15369],
        [14857],
        [14652],
        [12871],
        [14798],
        [13661]], device='cuda:0')
[2024-07-24 10:29:02,451][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[15799],
        [18238],
        [22047],
        [30903],
        [32967],
        [34533],
        [34333],
        [33478],
        [34711],
        [34974],
        [36995],
        [34729],
        [35121],
        [34552]], device='cuda:0')
[2024-07-24 10:29:02,452][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[43814],
        [38643],
        [10376],
        [33525],
        [15703],
        [36143],
        [31096],
        [15337],
        [ 6796],
        [28111],
        [ 2326],
        [15100],
        [ 7817],
        [37440]], device='cuda:0')
[2024-07-24 10:29:02,453][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[ 3094],
        [ 2809],
        [ 1080],
        [ 3134],
        [ 3101],
        [  113],
        [ 1876],
        [ 1422],
        [  545],
        [ 2435],
        [ 2358],
        [  945],
        [13099],
        [  131]], device='cuda:0')
[2024-07-24 10:29:02,455][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[42113],
        [   57],
        [   73],
        [   64],
        [  199],
        [  411],
        [  207],
        [  117],
        [  433],
        [  202],
        [  683],
        [  432],
        [ 1825],
        [ 4697]], device='cuda:0')
[2024-07-24 10:29:02,456][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[20334],
        [21945],
        [21626],
        [21242],
        [20780],
        [20680],
        [20375],
        [20232],
        [20338],
        [20230],
        [20151],
        [20194],
        [20095],
        [20207]], device='cuda:0')
[2024-07-24 10:29:02,457][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[17218],
        [19372],
        [17826],
        [16807],
        [16241],
        [16583],
        [16093],
        [14400],
        [15307],
        [13618],
        [14223],
        [14426],
        [12957],
        [14625]], device='cuda:0')
[2024-07-24 10:29:02,458][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[14976],
        [23386],
        [20677],
        [20194],
        [19190],
        [18785],
        [18378],
        [17595],
        [17669],
        [18008],
        [18110],
        [17926],
        [17470],
        [17488]], device='cuda:0')
[2024-07-24 10:29:02,460][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[ 8867],
        [43429],
        [14362],
        [40196],
        [41075],
        [21477],
        [41957],
        [37999],
        [19399],
        [30657],
        [20820],
        [40021],
        [44319],
        [19736]], device='cuda:0')
[2024-07-24 10:29:02,461][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 9576],
        [ 8028],
        [14428],
        [35684],
        [26229],
        [24574],
        [23386],
        [38461],
        [15336],
        [39016],
        [37878],
        [17870],
        [28826],
        [18485]], device='cuda:0')
[2024-07-24 10:29:02,462][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[22304],
        [18715],
        [17407],
        [24688],
        [34376],
        [36174],
        [29315],
        [32427],
        [27072],
        [28425],
        [30926],
        [27630],
        [28183],
        [30469]], device='cuda:0')
[2024-07-24 10:29:02,464][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[10541],
        [11008],
        [17372],
        [20110],
        [21268],
        [21887],
        [22322],
        [25040],
        [24368],
        [28314],
        [27270],
        [23994],
        [25492],
        [24719]], device='cuda:0')
[2024-07-24 10:29:02,465][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[14571],
        [14502],
        [13236],
        [12241],
        [11835],
        [10164],
        [10163],
        [ 9961],
        [11094],
        [10646],
        [10666],
        [10789],
        [10704],
        [10705]], device='cuda:0')
[2024-07-24 10:29:02,466][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[42553],
        [32623],
        [37711],
        [32701],
        [28414],
        [31427],
        [31965],
        [32915],
        [34064],
        [32509],
        [31983],
        [30622],
        [30148],
        [30584]], device='cuda:0')
[2024-07-24 10:29:02,468][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[40778],
        [37636],
        [37475],
        [36122],
        [35344],
        [35325],
        [35624],
        [36076],
        [36368],
        [35976],
        [35589],
        [35829],
        [35823],
        [35845]], device='cuda:0')
[2024-07-24 10:29:02,469][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[38248],
        [41028],
        [37405],
        [38712],
        [38876],
        [38224],
        [38986],
        [38998],
        [37971],
        [38483],
        [38370],
        [38435],
        [38591],
        [38363]], device='cuda:0')
[2024-07-24 10:29:02,471][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[40376],
        [38193],
        [40309],
        [28884],
        [34373],
        [31126],
        [27513],
        [30431],
        [38315],
        [28981],
        [32962],
        [35010],
        [34491],
        [28268]], device='cuda:0')
[2024-07-24 10:29:02,472][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[27195],
        [49503],
        [48243],
        [49021],
        [47604],
        [44852],
        [46270],
        [47485],
        [45390],
        [46956],
        [46668],
        [46220],
        [46742],
        [44617]], device='cuda:0')
[2024-07-24 10:29:02,473][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[26406],
        [23434],
        [25757],
        [24058],
        [22359],
        [21699],
        [23028],
        [22131],
        [22540],
        [22244],
        [22159],
        [22424],
        [21876],
        [21469]], device='cuda:0')
[2024-07-24 10:29:02,475][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[12781],
        [12748],
        [14285],
        [13736],
        [14102],
        [15483],
        [14534],
        [14413],
        [17719],
        [17245],
        [16976],
        [15793],
        [14976],
        [15955]], device='cuda:0')
[2024-07-24 10:29:02,476][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[11911],
        [11457],
        [ 9862],
        [10984],
        [ 9133],
        [ 9017],
        [ 8987],
        [ 9185],
        [ 9199],
        [ 9669],
        [ 8314],
        [ 7860],
        [ 8229],
        [ 8063]], device='cuda:0')
[2024-07-24 10:29:02,477][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 1897],
        [14045],
        [ 3157],
        [  653],
        [16238],
        [ 2312],
        [ 3018],
        [ 2251],
        [ 3166],
        [  800],
        [10699],
        [ 9882],
        [24209],
        [ 2050]], device='cuda:0')
[2024-07-24 10:29:02,479][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[ 6611],
        [ 9698],
        [16719],
        [10716],
        [ 8804],
        [11384],
        [ 9848],
        [ 9095],
        [12477],
        [ 8711],
        [ 8108],
        [ 9008],
        [ 8686],
        [11946]], device='cuda:0')
[2024-07-24 10:29:02,480][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[18184],
        [19863],
        [17119],
        [ 3763],
        [ 4982],
        [15855],
        [12574],
        [ 8583],
        [23080],
        [ 3607],
        [ 4110],
        [16065],
        [ 8268],
        [21364]], device='cuda:0')
[2024-07-24 10:29:02,481][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[33444],
        [33444],
        [33444],
        [33444],
        [33444],
        [33444],
        [33444],
        [33444],
        [33444],
        [33444],
        [33444],
        [33444],
        [33444],
        [33444]], device='cuda:0')
[2024-07-24 10:29:02,508][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:29:02,509][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:02,509][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:02,509][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:02,510][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:02,510][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:02,510][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:02,511][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:02,511][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:02,511][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:02,512][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:02,512][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:02,512][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:02,513][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Amanda] are: tensor([0.8953, 0.1047], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:02,513][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Amanda] are: tensor([0.0732, 0.9268], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:02,513][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Amanda] are: tensor([0.7652, 0.2348], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:02,514][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Amanda] are: tensor([0.7529, 0.2471], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:02,514][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Amanda] are: tensor([0.8489, 0.1511], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:02,514][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Amanda] are: tensor([0.4980, 0.5020], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:02,515][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Amanda] are: tensor([0.5142, 0.4858], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:02,516][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Amanda] are: tensor([0.3007, 0.6993], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:02,517][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Amanda] are: tensor([0.9096, 0.0904], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:02,519][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Amanda] are: tensor([0.6259, 0.3741], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:02,520][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Amanda] are: tensor([0.6661, 0.3339], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:02,522][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Amanda] are: tensor([0.4635, 0.5365], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:02,523][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.4835, 0.2958, 0.2208], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:02,524][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.1603, 0.7563, 0.0834], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:02,526][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.1400, 0.8148, 0.0452], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:02,527][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.7897, 0.1649, 0.0454], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:02,529][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.1172, 0.6828, 0.2000], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:02,530][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.2891, 0.3007, 0.4102], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:02,531][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.3188, 0.3077, 0.3735], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:02,531][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.1439, 0.7381, 0.1180], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:02,532][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.6486, 0.3047, 0.0467], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:02,532][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.2333, 0.5469, 0.2199], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:02,532][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.5582, 0.1832, 0.2585], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:02,533][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.3077, 0.3444, 0.3479], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:02,533][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ John] are: tensor([0.1263, 0.3414, 0.4345, 0.0979], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:02,533][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ John] are: tensor([0.1676, 0.4239, 0.1459, 0.2625], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:02,534][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ John] are: tensor([0.1434, 0.6072, 0.2287, 0.0207], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:02,534][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ John] are: tensor([0.7017, 0.1676, 0.0523, 0.0784], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:02,535][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ John] are: tensor([0.4210, 0.2450, 0.2676, 0.0665], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:02,536][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ John] are: tensor([0.2246, 0.2275, 0.3779, 0.1699], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:02,538][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ John] are: tensor([0.2373, 0.2263, 0.2846, 0.2518], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:02,539][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ John] are: tensor([0.1374, 0.4294, 0.2055, 0.2278], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:02,540][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ John] are: tensor([0.4013, 0.3942, 0.1946, 0.0099], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:02,542][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ John] are: tensor([0.1675, 0.3544, 0.2622, 0.2159], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:02,543][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ John] are: tensor([0.3648, 0.1883, 0.2626, 0.1843], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:02,545][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ John] are: tensor([0.2283, 0.2579, 0.2604, 0.2534], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:02,546][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ went] are: tensor([0.0858, 0.0997, 0.5908, 0.2188, 0.0048], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:02,547][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ went] are: tensor([0.5202, 0.0406, 0.3792, 0.0379, 0.0220], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:02,549][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ went] are: tensor([0.1981, 0.1973, 0.5243, 0.0774, 0.0028], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:02,550][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ went] are: tensor([0.7048, 0.1473, 0.0434, 0.0677, 0.0369], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:02,551][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ went] are: tensor([0.3983, 0.0873, 0.3828, 0.0650, 0.0666], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:02,553][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ went] are: tensor([0.1866, 0.1951, 0.3357, 0.1449, 0.1377], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:02,554][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ went] are: tensor([0.1973, 0.1795, 0.2301, 0.2003, 0.1927], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:02,556][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ went] are: tensor([0.1434, 0.3291, 0.1688, 0.1830, 0.1757], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:02,557][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.5310, 0.3151, 0.1008, 0.0354, 0.0177], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:02,558][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ went] are: tensor([0.1157, 0.2854, 0.2187, 0.2608, 0.1195], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:02,560][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ went] are: tensor([0.3328, 0.1527, 0.2087, 0.1507, 0.1551], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:02,561][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ went] are: tensor([0.1844, 0.2037, 0.2058, 0.1986, 0.2074], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:02,563][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.1753, 0.0144, 0.6869, 0.0827, 0.0074, 0.0333], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:02,563][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.1754, 0.2426, 0.2203, 0.1063, 0.0532, 0.2022], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:02,563][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1698, 0.0870, 0.1380, 0.0537, 0.5493, 0.0022], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:02,564][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.7344, 0.1275, 0.0347, 0.0584, 0.0281, 0.0169], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:02,564][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0982, 0.1736, 0.2396, 0.0592, 0.2328, 0.1965], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:02,564][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.1727, 0.1839, 0.3243, 0.1271, 0.1195, 0.0724], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:02,565][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1515, 0.1414, 0.1852, 0.1626, 0.1672, 0.1921], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:02,565][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0872, 0.3366, 0.0659, 0.2014, 0.2461, 0.0629], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:02,566][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ to] are: tensor([9.1952e-03, 1.7837e-02, 7.3706e-03, 6.3743e-03, 9.5913e-01, 9.5634e-05],
       device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:02,566][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.1078, 0.2481, 0.1586, 0.2454, 0.1596, 0.0805], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:02,568][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.2983, 0.1222, 0.1922, 0.1101, 0.1220, 0.1552], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:02,569][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.1562, 0.1694, 0.1694, 0.1614, 0.1708, 0.1727], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:02,570][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0565, 0.0385, 0.4967, 0.1039, 0.0153, 0.2672, 0.0218],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:02,572][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0441, 0.1645, 0.0774, 0.3289, 0.2170, 0.0427, 0.1254],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:02,573][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.1060, 0.1150, 0.1643, 0.0526, 0.4037, 0.1554, 0.0030],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:02,575][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.7395, 0.1200, 0.0301, 0.0517, 0.0250, 0.0151, 0.0186],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:02,576][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.1488, 0.1077, 0.1775, 0.1903, 0.0396, 0.2067, 0.1294],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:02,577][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.1582, 0.1681, 0.2972, 0.1187, 0.1138, 0.0704, 0.0736],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:02,579][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.1321, 0.1206, 0.1582, 0.1354, 0.1398, 0.1588, 0.1551],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:02,580][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0954, 0.2442, 0.0837, 0.1936, 0.1884, 0.0718, 0.1229],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:02,582][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.1585, 0.1189, 0.1653, 0.0167, 0.3807, 0.1579, 0.0020],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:02,583][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.1128, 0.1951, 0.1337, 0.1660, 0.1248, 0.1204, 0.1471],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:02,585][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.2850, 0.1007, 0.1745, 0.0960, 0.1012, 0.1427, 0.0998],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:02,586][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.1324, 0.1433, 0.1451, 0.1379, 0.1464, 0.1487, 0.1461],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:02,588][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ station] are: tensor([0.1009, 0.1096, 0.3116, 0.2787, 0.0398, 0.0894, 0.0511, 0.0189],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:02,589][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ station] are: tensor([0.0828, 0.1362, 0.2137, 0.1553, 0.0492, 0.0437, 0.2459, 0.0732],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:02,590][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ station] are: tensor([0.0592, 0.1133, 0.1203, 0.2847, 0.2970, 0.0473, 0.0703, 0.0080],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:02,592][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ station] are: tensor([0.7417, 0.1191, 0.0282, 0.0473, 0.0235, 0.0136, 0.0168, 0.0099],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:02,593][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ station] are: tensor([0.0988, 0.0865, 0.1590, 0.0708, 0.1141, 0.1599, 0.2631, 0.0478],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:02,594][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ station] are: tensor([0.1549, 0.1556, 0.2573, 0.1117, 0.1073, 0.0663, 0.0685, 0.0784],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:02,595][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ station] are: tensor([0.1149, 0.1094, 0.1411, 0.1214, 0.1218, 0.1372, 0.1345, 0.1197],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:02,595][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ station] are: tensor([0.1011, 0.2232, 0.0798, 0.1099, 0.1509, 0.0629, 0.0697, 0.2024],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:02,595][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ station] are: tensor([0.6836, 0.0083, 0.0729, 0.0056, 0.1465, 0.0521, 0.0275, 0.0036],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:02,596][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ station] are: tensor([0.0449, 0.1676, 0.0960, 0.1726, 0.1498, 0.0675, 0.2291, 0.0724],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:02,596][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ station] are: tensor([0.2314, 0.1044, 0.1378, 0.1132, 0.1048, 0.1166, 0.0972, 0.0947],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:02,597][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ station] are: tensor([0.1130, 0.1256, 0.1275, 0.1220, 0.1290, 0.1312, 0.1301, 0.1215],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:02,597][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.1069, 0.0572, 0.2877, 0.0916, 0.0280, 0.2456, 0.0619, 0.0125, 0.1087],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:02,597][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.1060, 0.0905, 0.0759, 0.1441, 0.1252, 0.0466, 0.2686, 0.0583, 0.0848],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:02,599][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0658, 0.1993, 0.0758, 0.0805, 0.3516, 0.0594, 0.0523, 0.1134, 0.0019],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:02,600][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.7301, 0.1119, 0.0270, 0.0497, 0.0230, 0.0135, 0.0169, 0.0102, 0.0177],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:02,602][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0568, 0.1580, 0.0961, 0.0907, 0.0275, 0.1023, 0.2235, 0.1384, 0.1068],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:02,603][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.1319, 0.1373, 0.1923, 0.1059, 0.1034, 0.0658, 0.0663, 0.0749, 0.1222],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:02,604][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0895, 0.0864, 0.1130, 0.1008, 0.1059, 0.1203, 0.1215, 0.1056, 0.1570],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:02,606][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0726, 0.2164, 0.0655, 0.1370, 0.1832, 0.0509, 0.0842, 0.1671, 0.0230],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:02,607][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.3346, 0.0596, 0.0894, 0.0079, 0.3616, 0.0827, 0.0414, 0.0103, 0.0125],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:02,608][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0752, 0.1341, 0.0890, 0.1073, 0.0997, 0.0650, 0.1687, 0.1194, 0.1416],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:02,610][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.2462, 0.0906, 0.1327, 0.0840, 0.0901, 0.0942, 0.0826, 0.0724, 0.1071],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:02,611][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.1040, 0.1147, 0.1139, 0.1081, 0.1149, 0.1155, 0.1143, 0.1057, 0.1088],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:02,613][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ John] are: tensor([0.0555, 0.1351, 0.2015, 0.0333, 0.0340, 0.1880, 0.0281, 0.0213, 0.2653,
        0.0379], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:02,614][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ John] are: tensor([0.0516, 0.0945, 0.0474, 0.0510, 0.0933, 0.0204, 0.1264, 0.3733, 0.1006,
        0.0414], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:02,616][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ John] are: tensor([0.0547, 0.2237, 0.0948, 0.0054, 0.1307, 0.0417, 0.1014, 0.3108, 0.0328,
        0.0040], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:02,617][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ John] are: tensor([0.6963, 0.1190, 0.0284, 0.0492, 0.0253, 0.0140, 0.0173, 0.0120, 0.0185,
        0.0199], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:02,619][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ John] are: tensor([0.1707, 0.0826, 0.1121, 0.0199, 0.0342, 0.1145, 0.1479, 0.1273, 0.1771,
        0.0136], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:02,620][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ John] are: tensor([0.1314, 0.1281, 0.2124, 0.0887, 0.0853, 0.0509, 0.0525, 0.0618, 0.1272,
        0.0617], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:02,622][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ John] are: tensor([0.0966, 0.0865, 0.1074, 0.0941, 0.0937, 0.1037, 0.1008, 0.0907, 0.1241,
        0.1024], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:02,623][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ John] are: tensor([0.0576, 0.1969, 0.0963, 0.0948, 0.1406, 0.0684, 0.0760, 0.1544, 0.0338,
        0.0811], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:02,624][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ John] are: tensor([0.2006, 0.1798, 0.0922, 0.0045, 0.0358, 0.1652, 0.0597, 0.2041, 0.0551,
        0.0032], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:02,626][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ John] are: tensor([0.0566, 0.1082, 0.0779, 0.0536, 0.0957, 0.0617, 0.1330, 0.1229, 0.1706,
        0.1199], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:02,626][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ John] are: tensor([0.1749, 0.0867, 0.1195, 0.0865, 0.0862, 0.0888, 0.0741, 0.0995, 0.0979,
        0.0860], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:02,627][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ John] are: tensor([0.0946, 0.1038, 0.1031, 0.0978, 0.1041, 0.1045, 0.1033, 0.0953, 0.0980,
        0.0956], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:02,627][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.0234, 0.0494, 0.1889, 0.1247, 0.0529, 0.1389, 0.0505, 0.0244, 0.2038,
        0.1399, 0.0031], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:02,628][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0404, 0.0468, 0.1491, 0.0825, 0.1372, 0.0406, 0.1243, 0.0828, 0.0775,
        0.0784, 0.1406], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:02,628][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0416, 0.1271, 0.2122, 0.1128, 0.0221, 0.0513, 0.1061, 0.1106, 0.0997,
        0.1126, 0.0039], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:02,629][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.6916, 0.1133, 0.0277, 0.0503, 0.0235, 0.0138, 0.0174, 0.0115, 0.0184,
        0.0198, 0.0126], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:02,629][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.0997, 0.0703, 0.1252, 0.0410, 0.0309, 0.1330, 0.1595, 0.0703, 0.2334,
        0.0293, 0.0074], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:02,629][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.1153, 0.1206, 0.2226, 0.0826, 0.0787, 0.0464, 0.0489, 0.0533, 0.1269,
        0.0537, 0.0510], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:02,630][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0903, 0.0786, 0.1007, 0.0841, 0.0820, 0.0940, 0.0913, 0.0814, 0.1160,
        0.0911, 0.0905], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:02,631][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0651, 0.1659, 0.0653, 0.0851, 0.1246, 0.0701, 0.0826, 0.1400, 0.0388,
        0.0847, 0.0778], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:02,633][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.2603, 0.1036, 0.0941, 0.0065, 0.0183, 0.3012, 0.0777, 0.0153, 0.1118,
        0.0046, 0.0066], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:02,634][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.0452, 0.0878, 0.0600, 0.0846, 0.0640, 0.0454, 0.1240, 0.0780, 0.1642,
        0.1993, 0.0475], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:02,636][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.1843, 0.0786, 0.0914, 0.0783, 0.0876, 0.0775, 0.0664, 0.0715, 0.0939,
        0.0819, 0.0887], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:02,637][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0869, 0.0939, 0.0939, 0.0887, 0.0949, 0.0956, 0.0939, 0.0866, 0.0887,
        0.0864, 0.0906], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:02,638][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0266, 0.0105, 0.3852, 0.0612, 0.0054, 0.1077, 0.0361, 0.0158, 0.2607,
        0.0706, 0.0117, 0.0087], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:02,639][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0615, 0.0800, 0.0749, 0.1173, 0.1150, 0.0527, 0.0804, 0.0778, 0.0517,
        0.1298, 0.0996, 0.0591], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:02,641][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0649, 0.0793, 0.1771, 0.0200, 0.1382, 0.0528, 0.0261, 0.2040, 0.0351,
        0.0227, 0.1786, 0.0013], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:02,642][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.7113, 0.1044, 0.0238, 0.0442, 0.0201, 0.0117, 0.0147, 0.0092, 0.0155,
        0.0165, 0.0107, 0.0177], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:02,644][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0952, 0.0379, 0.1518, 0.0589, 0.0293, 0.1503, 0.1279, 0.0668, 0.1799,
        0.0372, 0.0182, 0.0466], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:02,645][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.1162, 0.1169, 0.2055, 0.0795, 0.0755, 0.0443, 0.0467, 0.0524, 0.1191,
        0.0528, 0.0494, 0.0416], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:02,647][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0827, 0.0687, 0.0875, 0.0755, 0.0772, 0.0854, 0.0830, 0.0761, 0.1070,
        0.0858, 0.0858, 0.0854], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:02,648][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0448, 0.1526, 0.0464, 0.1102, 0.1090, 0.0413, 0.0786, 0.1489, 0.0198,
        0.1165, 0.0735, 0.0585], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:02,649][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ a] are: tensor([2.9920e-02, 8.9603e-02, 1.6591e-02, 1.4677e-03, 5.5341e-02, 9.2909e-03,
        3.1850e-03, 5.3008e-02, 5.7813e-03, 1.1117e-03, 7.3423e-01, 4.6928e-04],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:02,651][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0526, 0.0873, 0.0603, 0.0651, 0.0588, 0.0449, 0.0679, 0.0788, 0.1335,
        0.1351, 0.1124, 0.1035], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:02,652][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.2013, 0.0661, 0.0990, 0.0648, 0.0665, 0.0835, 0.0631, 0.0539, 0.0838,
        0.0585, 0.0728, 0.0866], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:02,654][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0820, 0.0866, 0.0862, 0.0809, 0.0867, 0.0871, 0.0851, 0.0787, 0.0799,
        0.0776, 0.0813, 0.0878], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:02,655][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ ring] are: tensor([0.0405, 0.0475, 0.1884, 0.1320, 0.0237, 0.1056, 0.0230, 0.0867, 0.1431,
        0.1431, 0.0449, 0.0101, 0.0115], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:02,657][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ ring] are: tensor([0.0129, 0.2868, 0.0593, 0.1090, 0.0341, 0.0135, 0.0697, 0.0706, 0.0505,
        0.0898, 0.0531, 0.0374, 0.1133], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:02,658][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ ring] are: tensor([0.0202, 0.0674, 0.1409, 0.0953, 0.0731, 0.0930, 0.0441, 0.1060, 0.0675,
        0.0956, 0.1510, 0.0353, 0.0106], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:02,659][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ ring] are: tensor([0.7148, 0.1041, 0.0225, 0.0404, 0.0192, 0.0108, 0.0138, 0.0088, 0.0144,
        0.0153, 0.0102, 0.0164, 0.0092], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:02,659][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ ring] are: tensor([0.0502, 0.0631, 0.0999, 0.0371, 0.0230, 0.1155, 0.1559, 0.0533, 0.2219,
        0.0252, 0.0138, 0.0864, 0.0547], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:02,660][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ ring] are: tensor([0.1177, 0.1143, 0.1963, 0.0772, 0.0724, 0.0420, 0.0437, 0.0508, 0.1110,
        0.0503, 0.0452, 0.0391, 0.0400], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:02,660][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ ring] are: tensor([0.0820, 0.0679, 0.0844, 0.0721, 0.0727, 0.0794, 0.0769, 0.0700, 0.0946,
        0.0775, 0.0764, 0.0772, 0.0689], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:02,661][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ ring] are: tensor([0.0438, 0.1648, 0.0581, 0.0801, 0.1031, 0.0450, 0.0486, 0.1467, 0.0198,
        0.0709, 0.0697, 0.0468, 0.1026], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:02,661][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ ring] are: tensor([0.4501, 0.0504, 0.0692, 0.0025, 0.0999, 0.0351, 0.0123, 0.0248, 0.0317,
        0.0016, 0.2156, 0.0038, 0.0030], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:02,662][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ ring] are: tensor([0.0283, 0.0776, 0.0471, 0.0639, 0.0557, 0.0338, 0.0863, 0.0487, 0.0897,
        0.1338, 0.1175, 0.1444, 0.0730], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:02,662][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ ring] are: tensor([0.1619, 0.0740, 0.0861, 0.0782, 0.0671, 0.0709, 0.0603, 0.0575, 0.0744,
        0.0686, 0.0597, 0.0863, 0.0550], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:02,663][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ ring] are: tensor([0.0748, 0.0792, 0.0787, 0.0743, 0.0793, 0.0797, 0.0783, 0.0727, 0.0737,
        0.0717, 0.0751, 0.0810, 0.0815], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:02,665][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0690, 0.0065, 0.3753, 0.0331, 0.0034, 0.0131, 0.0209, 0.0112, 0.3304,
        0.0408, 0.0132, 0.0195, 0.0553, 0.0086], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:02,666][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0623, 0.0751, 0.0658, 0.0319, 0.0147, 0.0594, 0.1967, 0.0272, 0.0784,
        0.0229, 0.0354, 0.1808, 0.1024, 0.0471], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:02,668][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0827, 0.0323, 0.0625, 0.0212, 0.2388, 0.0007, 0.0646, 0.0581, 0.0223,
        0.0194, 0.2149, 0.0841, 0.0977, 0.0006], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:02,669][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.6876, 0.1020, 0.0238, 0.0447, 0.0195, 0.0112, 0.0148, 0.0094, 0.0154,
        0.0174, 0.0106, 0.0176, 0.0098, 0.0163], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:02,670][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0371, 0.0494, 0.0935, 0.0201, 0.0909, 0.0773, 0.0907, 0.0867, 0.1540,
        0.0149, 0.0691, 0.0714, 0.0999, 0.0448], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:02,672][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.1100, 0.1107, 0.1838, 0.0761, 0.0719, 0.0414, 0.0436, 0.0488, 0.1031,
        0.0491, 0.0457, 0.0389, 0.0394, 0.0373], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:02,674][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0675, 0.0589, 0.0732, 0.0643, 0.0658, 0.0731, 0.0724, 0.0655, 0.0911,
        0.0718, 0.0736, 0.0751, 0.0658, 0.0820], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:02,675][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0387, 0.1445, 0.0316, 0.0919, 0.1239, 0.0331, 0.0599, 0.1083, 0.0219,
        0.0952, 0.0863, 0.0499, 0.0911, 0.0236], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:02,676][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ to] are: tensor([2.7559e-03, 5.7616e-03, 2.5590e-03, 2.3782e-03, 3.1622e-01, 2.4231e-05,
        8.5295e-04, 8.0904e-04, 1.9992e-03, 1.7381e-03, 6.6306e-01, 1.0145e-03,
        8.0513e-04, 1.4585e-05], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:02,677][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0336, 0.0638, 0.0407, 0.0560, 0.0424, 0.0165, 0.0744, 0.0522, 0.0830,
        0.1122, 0.0916, 0.1584, 0.1439, 0.0314], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:02,679][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.1594, 0.0571, 0.0907, 0.0510, 0.0608, 0.0743, 0.0562, 0.0444, 0.0793,
        0.0458, 0.0637, 0.0770, 0.0446, 0.0957], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:02,680][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0714, 0.0745, 0.0734, 0.0691, 0.0739, 0.0737, 0.0721, 0.0666, 0.0676,
        0.0656, 0.0687, 0.0740, 0.0745, 0.0751], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:02,707][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:29:02,708][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:02,709][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:02,710][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:02,711][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:02,712][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:02,713][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:02,713][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:02,713][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:02,714][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:02,714][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:02,714][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:02,715][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:02,715][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Amanda] are: tensor([0.7014, 0.2986], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:02,715][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Amanda] are: tensor([0.6596, 0.3404], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:02,716][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Amanda] are: tensor([9.9921e-01, 7.8596e-04], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:02,716][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Amanda] are: tensor([0.5621, 0.4379], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:02,716][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Amanda] are: tensor([0.9284, 0.0716], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:02,717][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Amanda] are: tensor([0.6629, 0.3371], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:02,717][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Amanda] are: tensor([0.5011, 0.4989], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:02,717][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Amanda] are: tensor([0.5535, 0.4465], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:02,718][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Amanda] are: tensor([0.7002, 0.2998], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:02,718][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Amanda] are: tensor([0.4835, 0.5165], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:02,718][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Amanda] are: tensor([0.4903, 0.5097], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:02,719][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Amanda] are: tensor([0.5528, 0.4472], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:02,719][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.3750, 0.3154, 0.3096], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:02,719][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.4475, 0.2440, 0.3085], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:02,720][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([9.9831e-01, 9.0674e-04, 7.8472e-04], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:02,720][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.2977, 0.5261, 0.1762], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:02,720][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0480, 0.8777, 0.0743], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:02,721][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.3406, 0.1287, 0.5307], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:02,721][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.1646, 0.0942, 0.7412], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:02,721][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.4001, 0.3649, 0.2350], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:02,722][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.3997, 0.2913, 0.3090], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:02,722][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.1373, 0.5405, 0.3222], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:02,722][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.3207, 0.3401, 0.3392], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:02,723][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.3750, 0.5237, 0.1013], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:02,724][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ John] are: tensor([0.2360, 0.2566, 0.2558, 0.2515], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:02,725][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ John] are: tensor([0.3633, 0.1987, 0.2436, 0.1943], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:02,726][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ John] are: tensor([9.8587e-01, 6.5280e-04, 2.4841e-03, 1.0991e-02], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:02,728][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ John] are: tensor([0.1934, 0.3480, 0.2089, 0.2496], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:02,729][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ John] are: tensor([0.5601, 0.2096, 0.1994, 0.0309], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:02,730][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ John] are: tensor([0.1811, 0.0706, 0.3579, 0.3904], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:02,732][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ John] are: tensor([0.0823, 0.0618, 0.5666, 0.2893], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:02,733][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ John] are: tensor([0.3305, 0.2762, 0.1955, 0.1978], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:02,734][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ John] are: tensor([0.2956, 0.2640, 0.3379, 0.1026], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:02,736][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ John] are: tensor([0.0947, 0.3323, 0.2964, 0.2766], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:02,737][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ John] are: tensor([0.2244, 0.2614, 0.2564, 0.2578], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:02,738][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ John] are: tensor([0.3514, 0.4382, 0.0679, 0.1424], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:02,740][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([0.2021, 0.1643, 0.2397, 0.2606, 0.1333], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:02,741][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([0.2882, 0.1621, 0.1975, 0.1599, 0.1924], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:02,742][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([9.5469e-01, 2.9598e-03, 8.9823e-03, 3.2694e-02, 6.7468e-04],
       device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:02,743][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([0.2308, 0.2328, 0.1953, 0.2598, 0.0813], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:02,744][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([0.5269, 0.0363, 0.3607, 0.0304, 0.0458], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:02,744][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([0.1320, 0.0451, 0.2365, 0.2784, 0.3081], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:02,745][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([0.1270, 0.0812, 0.3271, 0.2459, 0.2188], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:02,745][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([0.2782, 0.2234, 0.1641, 0.1603, 0.1740], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:02,746][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([0.2865, 0.2073, 0.2175, 0.1146, 0.1740], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:02,746][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([0.0521, 0.2356, 0.2260, 0.3008, 0.1855], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:02,746][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([0.1835, 0.2096, 0.2045, 0.2047, 0.1977], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:02,747][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([0.2394, 0.3573, 0.0454, 0.1887, 0.1692], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:02,747][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.2069, 0.1065, 0.1787, 0.1710, 0.1324, 0.2044], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:02,748][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.2410, 0.1238, 0.1529, 0.1208, 0.1521, 0.2094], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:02,749][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.9105, 0.0023, 0.0080, 0.0711, 0.0019, 0.0063], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:02,751][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.1640, 0.2480, 0.1469, 0.2438, 0.1123, 0.0850], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:02,752][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0762, 0.1746, 0.1719, 0.0396, 0.3894, 0.1483], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:02,753][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.1301, 0.0308, 0.1627, 0.2058, 0.2082, 0.2624], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:02,754][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0777, 0.0302, 0.3589, 0.0536, 0.1144, 0.3652], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:02,756][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.2300, 0.1993, 0.1388, 0.1465, 0.1601, 0.1253], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:02,757][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.1040, 0.1256, 0.1325, 0.0996, 0.4424, 0.0959], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:02,758][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0513, 0.1898, 0.1741, 0.2761, 0.2298, 0.0789], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:02,759][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.1664, 0.1699, 0.1671, 0.1683, 0.1646, 0.1637], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:02,761][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.2133, 0.3023, 0.0316, 0.1482, 0.2096, 0.0951], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:02,762][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.1570, 0.1087, 0.1474, 0.1461, 0.1282, 0.1994, 0.1132],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:02,764][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.1836, 0.1027, 0.1253, 0.1013, 0.1244, 0.1662, 0.1966],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:02,765][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.8985, 0.0010, 0.0037, 0.0533, 0.0015, 0.0086, 0.0334],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:02,767][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.1571, 0.1886, 0.1283, 0.1664, 0.1120, 0.1364, 0.1111],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:02,768][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.1332, 0.1190, 0.1732, 0.2738, 0.0305, 0.1962, 0.0742],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:02,770][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.1048, 0.0238, 0.1250, 0.1527, 0.1594, 0.2040, 0.2302],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:02,771][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0344, 0.0144, 0.1802, 0.0503, 0.1565, 0.4167, 0.1476],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:02,772][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.2034, 0.1727, 0.1222, 0.1299, 0.1375, 0.1096, 0.1247],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:02,774][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.1264, 0.1213, 0.1476, 0.0761, 0.2289, 0.2076, 0.0922],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:02,775][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0527, 0.1593, 0.1545, 0.2020, 0.1795, 0.1198, 0.1323],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:02,776][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.1377, 0.1481, 0.1451, 0.1447, 0.1396, 0.1403, 0.1445],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:02,776][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.2700, 0.2658, 0.0372, 0.1021, 0.1674, 0.1006, 0.0569],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:02,777][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ station] are: tensor([0.1162, 0.0997, 0.1175, 0.1401, 0.1129, 0.1543, 0.1055, 0.1538],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:02,777][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ station] are: tensor([0.1590, 0.0892, 0.1061, 0.0892, 0.1075, 0.1422, 0.1697, 0.1372],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:02,777][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ station] are: tensor([5.8152e-01, 3.3040e-04, 1.7911e-03, 6.3258e-02, 1.1428e-03, 6.3095e-03,
        5.8071e-02, 2.8758e-01], device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:02,778][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ station] are: tensor([0.0958, 0.2354, 0.0868, 0.2297, 0.1193, 0.0536, 0.1445, 0.0349],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:02,778][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ station] are: tensor([0.1012, 0.0815, 0.1515, 0.0560, 0.1547, 0.1435, 0.2976, 0.0140],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:02,779][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ station] are: tensor([0.0471, 0.0147, 0.0882, 0.0884, 0.1091, 0.1748, 0.1690, 0.3088],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:02,780][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ station] are: tensor([0.0130, 0.0127, 0.1026, 0.0751, 0.0796, 0.2894, 0.2429, 0.1847],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:02,781][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ station] are: tensor([0.1905, 0.1481, 0.1089, 0.1110, 0.1255, 0.0986, 0.1119, 0.1055],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:02,783][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ station] are: tensor([0.1110, 0.0521, 0.1122, 0.0445, 0.2018, 0.1711, 0.1230, 0.1842],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:02,784][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ station] are: tensor([0.0209, 0.1312, 0.1054, 0.1923, 0.1907, 0.0676, 0.1942, 0.0978],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:02,785][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ station] are: tensor([0.1160, 0.1320, 0.1279, 0.1270, 0.1223, 0.1232, 0.1243, 0.1274],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:02,787][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ station] are: tensor([0.2368, 0.3027, 0.0234, 0.1550, 0.1219, 0.0457, 0.0566, 0.0578],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:02,788][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.1062, 0.0918, 0.1025, 0.1132, 0.1005, 0.1369, 0.0939, 0.1486, 0.1064],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:02,790][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.1300, 0.0733, 0.0888, 0.0735, 0.0893, 0.1196, 0.1417, 0.1145, 0.1694],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:02,791][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.5180, 0.0007, 0.0029, 0.0554, 0.0030, 0.0100, 0.0497, 0.2942, 0.0661],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:02,792][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.1378, 0.1557, 0.0848, 0.1566, 0.0905, 0.1084, 0.1306, 0.0500, 0.0856],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:02,794][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0504, 0.2809, 0.0683, 0.0844, 0.0166, 0.0963, 0.2607, 0.0871, 0.0553],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:02,795][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0630, 0.0124, 0.0640, 0.0778, 0.0779, 0.0949, 0.1105, 0.2940, 0.2055],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:02,797][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0357, 0.0167, 0.1226, 0.0560, 0.1259, 0.1816, 0.2602, 0.1455, 0.0559],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:02,798][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.1656, 0.1425, 0.0982, 0.1066, 0.1137, 0.0869, 0.1000, 0.0945, 0.0919],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:02,800][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.1071, 0.0773, 0.0935, 0.0464, 0.1767, 0.1253, 0.0934, 0.1726, 0.1077],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:02,801][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0311, 0.0991, 0.1046, 0.1270, 0.1390, 0.0725, 0.1450, 0.1588, 0.1230],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:02,803][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.1075, 0.1145, 0.1125, 0.1114, 0.1074, 0.1086, 0.1118, 0.1134, 0.1128],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:02,804][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.2135, 0.1856, 0.0382, 0.0932, 0.1477, 0.0781, 0.0737, 0.0385, 0.1316],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:02,805][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ John] are: tensor([0.0799, 0.0841, 0.0840, 0.0820, 0.0934, 0.1282, 0.0800, 0.1362, 0.1091,
        0.1231], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:02,807][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ John] are: tensor([0.1018, 0.0657, 0.0800, 0.0672, 0.0839, 0.1097, 0.1298, 0.1060, 0.1579,
        0.0981], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:02,807][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ John] are: tensor([3.8484e-01, 4.1766e-04, 2.1130e-03, 2.6601e-02, 1.6834e-03, 8.3635e-03,
        2.5029e-02, 8.7018e-02, 4.4354e-02, 4.1958e-01], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:02,808][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ John] are: tensor([0.0732, 0.1276, 0.0663, 0.0747, 0.0750, 0.0837, 0.1955, 0.0932, 0.1159,
        0.0949], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:02,808][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ John] are: tensor([0.2682, 0.0723, 0.0999, 0.0097, 0.0357, 0.1279, 0.1369, 0.1003, 0.1416,
        0.0074], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:02,809][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ John] are: tensor([0.0339, 0.0081, 0.0521, 0.0523, 0.0638, 0.0976, 0.0999, 0.2095, 0.1937,
        0.1892], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:02,809][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ John] are: tensor([0.0156, 0.0118, 0.0948, 0.0495, 0.1108, 0.1515, 0.1137, 0.2351, 0.0848,
        0.1324], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:02,809][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ John] are: tensor([0.1535, 0.1254, 0.0918, 0.0929, 0.1042, 0.0823, 0.0928, 0.0865, 0.0898,
        0.0806], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:02,810][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ John] are: tensor([0.0803, 0.0724, 0.0869, 0.0258, 0.0922, 0.1341, 0.1037, 0.2129, 0.1435,
        0.0481], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:02,810][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ John] are: tensor([0.0232, 0.0816, 0.0814, 0.0660, 0.1260, 0.0607, 0.1160, 0.1573, 0.1406,
        0.1471], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:02,811][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ John] are: tensor([0.0922, 0.1056, 0.1021, 0.1016, 0.0978, 0.1001, 0.1007, 0.1021, 0.1008,
        0.0969], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:02,813][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ John] are: tensor([0.2378, 0.2344, 0.0258, 0.0637, 0.1115, 0.0484, 0.0505, 0.0684, 0.0735,
        0.0861], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:02,814][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.0686, 0.0624, 0.0822, 0.0943, 0.0944, 0.1278, 0.0794, 0.1149, 0.0943,
        0.1331, 0.0487], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:02,815][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0936, 0.0588, 0.0707, 0.0598, 0.0736, 0.0955, 0.1138, 0.0931, 0.1362,
        0.0873, 0.1176], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:02,816][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([7.3631e-02, 3.7264e-04, 3.1721e-03, 3.3467e-02, 1.6361e-03, 7.8157e-03,
        3.4145e-02, 9.3938e-02, 6.1836e-02, 6.3442e-01, 5.5569e-02],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:02,818][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.0912, 0.1255, 0.0611, 0.1064, 0.0458, 0.0783, 0.1611, 0.0849, 0.0957,
        0.1266, 0.0233], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:02,819][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.1579, 0.0615, 0.1269, 0.0240, 0.0255, 0.1609, 0.1661, 0.0351, 0.2209,
        0.0166, 0.0047], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:02,821][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.0341, 0.0073, 0.0426, 0.0478, 0.0512, 0.0719, 0.0784, 0.1872, 0.1492,
        0.1671, 0.1634], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:02,822][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.0235, 0.0261, 0.0614, 0.0384, 0.1121, 0.1088, 0.1191, 0.2727, 0.0905,
        0.0992, 0.0480], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:02,824][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.1438, 0.1195, 0.0850, 0.0860, 0.0970, 0.0785, 0.0852, 0.0801, 0.0829,
        0.0743, 0.0678], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:02,825][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.0961, 0.0717, 0.0841, 0.0300, 0.0809, 0.1484, 0.1012, 0.1370, 0.1352,
        0.0469, 0.0685], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:02,827][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.0190, 0.0686, 0.0654, 0.1000, 0.0892, 0.0459, 0.1098, 0.1036, 0.1367,
        0.2115, 0.0503], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:02,828][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0855, 0.0952, 0.0927, 0.0919, 0.0888, 0.0914, 0.0921, 0.0928, 0.0926,
        0.0881, 0.0890], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:02,829][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.1702, 0.1913, 0.0151, 0.0693, 0.0787, 0.0438, 0.0584, 0.0544, 0.0788,
        0.1005, 0.1395], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:02,831][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0805, 0.0491, 0.0857, 0.0814, 0.0651, 0.1113, 0.0725, 0.1167, 0.0945,
        0.1124, 0.0599, 0.0709], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:02,832][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0886, 0.0534, 0.0658, 0.0540, 0.0670, 0.0877, 0.1002, 0.0817, 0.1175,
        0.0744, 0.1040, 0.1058], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:02,833][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([8.5002e-02, 5.2273e-04, 4.0064e-03, 3.6303e-02, 2.9276e-03, 1.4402e-02,
        3.8272e-02, 1.1998e-01, 3.3795e-02, 5.8171e-01, 5.3031e-02, 3.0042e-02],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:02,835][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0817, 0.0987, 0.0597, 0.1020, 0.0548, 0.0646, 0.1142, 0.0599, 0.0792,
        0.1316, 0.0797, 0.0738], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:02,836][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0899, 0.0366, 0.1802, 0.0616, 0.0331, 0.1518, 0.1322, 0.0338, 0.1833,
        0.0378, 0.0206, 0.0391], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:02,838][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0404, 0.0070, 0.0386, 0.0448, 0.0460, 0.0581, 0.0658, 0.1781, 0.1260,
        0.1519, 0.1441, 0.0992], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:02,839][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0146, 0.0131, 0.0626, 0.0262, 0.1157, 0.1166, 0.1170, 0.2307, 0.1046,
        0.0736, 0.0741, 0.0510], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:02,839][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.1307, 0.1137, 0.0793, 0.0841, 0.0880, 0.0705, 0.0810, 0.0765, 0.0730,
        0.0717, 0.0622, 0.0694], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:02,840][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0542, 0.0730, 0.0611, 0.0259, 0.1012, 0.0742, 0.0524, 0.1616, 0.0894,
        0.0433, 0.2136, 0.0500], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:02,840][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0206, 0.0706, 0.0696, 0.0819, 0.0840, 0.0480, 0.0645, 0.1123, 0.1184,
        0.1550, 0.1041, 0.0710], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:02,841][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0808, 0.0861, 0.0842, 0.0836, 0.0810, 0.0828, 0.0846, 0.0855, 0.0846,
        0.0812, 0.0811, 0.0844], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:02,841][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.1671, 0.1330, 0.0136, 0.0603, 0.0806, 0.0415, 0.0352, 0.0292, 0.0734,
        0.0944, 0.1922, 0.0796], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:02,842][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ ring] are: tensor([0.0579, 0.0466, 0.0663, 0.0751, 0.0645, 0.0955, 0.0556, 0.1171, 0.0762,
        0.1096, 0.0675, 0.0546, 0.1137], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:02,843][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ ring] are: tensor([0.0757, 0.0501, 0.0619, 0.0510, 0.0640, 0.0835, 0.0939, 0.0753, 0.1054,
        0.0660, 0.0954, 0.0964, 0.0814], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:02,844][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ ring] are: tensor([2.9035e-02, 1.6686e-04, 1.9975e-03, 1.8938e-02, 1.1544e-03, 6.6499e-03,
        2.0836e-02, 7.8107e-02, 4.1720e-02, 4.4110e-01, 3.2454e-02, 2.0018e-02,
        3.0782e-01], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:02,845][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ ring] are: tensor([0.0640, 0.1115, 0.0467, 0.0903, 0.0741, 0.0291, 0.1011, 0.0442, 0.0705,
        0.1041, 0.0691, 0.1511, 0.0443], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:02,847][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ ring] are: tensor([0.0302, 0.0666, 0.1011, 0.0326, 0.0243, 0.1346, 0.1871, 0.0290, 0.2287,
        0.0192, 0.0129, 0.0939, 0.0397], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:02,848][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ ring] are: tensor([0.0197, 0.0052, 0.0330, 0.0327, 0.0395, 0.0624, 0.0599, 0.1196, 0.1145,
        0.1179, 0.1305, 0.0892, 0.1759], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:02,849][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ ring] are: tensor([0.0060, 0.0050, 0.0544, 0.0489, 0.0485, 0.1924, 0.1547, 0.1458, 0.0516,
        0.1083, 0.0390, 0.0862, 0.0593], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:02,851][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ ring] are: tensor([0.1245, 0.0986, 0.0729, 0.0739, 0.0830, 0.0670, 0.0750, 0.0697, 0.0723,
        0.0645, 0.0589, 0.0648, 0.0750], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:02,852][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ ring] are: tensor([0.0607, 0.0420, 0.0647, 0.0180, 0.1010, 0.0866, 0.0544, 0.1181, 0.0939,
        0.0297, 0.1541, 0.0621, 0.1148], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:02,854][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ ring] are: tensor([0.0100, 0.0590, 0.0498, 0.0747, 0.0742, 0.0348, 0.0801, 0.0670, 0.0814,
        0.1570, 0.1104, 0.1066, 0.0951], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:02,855][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ ring] are: tensor([0.0720, 0.0793, 0.0777, 0.0780, 0.0756, 0.0757, 0.0773, 0.0791, 0.0772,
        0.0759, 0.0756, 0.0773, 0.0791], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:02,857][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ ring] are: tensor([0.1141, 0.2166, 0.0111, 0.0784, 0.0854, 0.0261, 0.0296, 0.0496, 0.0422,
        0.1007, 0.1387, 0.0735, 0.0340], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:02,858][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0780, 0.0400, 0.0641, 0.0620, 0.0493, 0.0689, 0.0513, 0.0904, 0.0742,
        0.0870, 0.0518, 0.0638, 0.1402, 0.0788], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:02,860][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0714, 0.0431, 0.0538, 0.0433, 0.0551, 0.0738, 0.0866, 0.0683, 0.1013,
        0.0613, 0.0882, 0.0909, 0.0766, 0.0863], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:02,861][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0354, 0.0007, 0.0038, 0.0309, 0.0035, 0.0074, 0.0298, 0.0681, 0.0243,
        0.3170, 0.0374, 0.0253, 0.3231, 0.0933], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:02,863][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0733, 0.0888, 0.0553, 0.0779, 0.0352, 0.0267, 0.0862, 0.0422, 0.0799,
        0.0801, 0.0962, 0.1530, 0.0665, 0.0388], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:02,864][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0306, 0.0532, 0.0789, 0.0137, 0.1683, 0.0630, 0.0962, 0.0505, 0.1237,
        0.0096, 0.1058, 0.0625, 0.1009, 0.0432], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:02,866][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0301, 0.0053, 0.0288, 0.0339, 0.0342, 0.0419, 0.0477, 0.1335, 0.0905,
        0.1136, 0.1051, 0.0706, 0.1814, 0.0834], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:02,867][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0343, 0.0148, 0.0987, 0.0178, 0.0518, 0.0856, 0.1422, 0.0598, 0.1363,
        0.0394, 0.0414, 0.0769, 0.0582, 0.1427], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:02,869][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.1121, 0.0998, 0.0702, 0.0740, 0.0793, 0.0632, 0.0706, 0.0675, 0.0655,
        0.0631, 0.0563, 0.0608, 0.0735, 0.0442], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:02,870][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0347, 0.0456, 0.0462, 0.0355, 0.1621, 0.0281, 0.0402, 0.0899, 0.0694,
        0.0520, 0.1776, 0.0599, 0.1280, 0.0309], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:02,871][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0144, 0.0525, 0.0491, 0.0706, 0.0627, 0.0198, 0.0677, 0.0802, 0.0754,
        0.1302, 0.0854, 0.1040, 0.1691, 0.0190], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:02,871][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0727, 0.0728, 0.0708, 0.0710, 0.0689, 0.0703, 0.0725, 0.0732, 0.0720,
        0.0695, 0.0694, 0.0723, 0.0747, 0.0699], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:02,871][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.1422, 0.1278, 0.0113, 0.0535, 0.0877, 0.0310, 0.0357, 0.0179, 0.0704,
        0.0748, 0.1413, 0.0808, 0.0224, 0.1032], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:02,873][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:29:02,874][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[12253],
        [    9],
        [ 3247],
        [11172],
        [23652],
        [16928],
        [13601],
        [10786],
        [14306],
        [20041],
        [ 8678],
        [15006],
        [22512],
        [27953]], device='cuda:0')
[2024-07-24 10:29:02,875][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[12991],
        [   32],
        [ 7852],
        [ 9829],
        [ 5636],
        [14592],
        [11529],
        [ 1456],
        [ 3289],
        [11017],
        [ 5141],
        [13286],
        [33211],
        [24252]], device='cuda:0')
[2024-07-24 10:29:02,877][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[38707],
        [39853],
        [36385],
        [28989],
        [25178],
        [20100],
        [14213],
        [30382],
        [13588],
        [ 9232],
        [16213],
        [10579],
        [19776],
        [10276]], device='cuda:0')
[2024-07-24 10:29:02,878][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[38972],
        [    4],
        [    6],
        [   17],
        [27094],
        [  254],
        [  229],
        [ 1772],
        [ 3207],
        [ 6201],
        [ 3373],
        [ 1467],
        [   41],
        [11747]], device='cuda:0')
[2024-07-24 10:29:02,879][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[28851],
        [26087],
        [18694],
        [22851],
        [32951],
        [29147],
        [28811],
        [33198],
        [25185],
        [19196],
        [31580],
        [19843],
        [26519],
        [24245]], device='cuda:0')
[2024-07-24 10:29:02,881][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[4973],
        [5318],
        [5233],
        [5312],
        [5297],
        [5246],
        [5231],
        [5285],
        [5316],
        [5402],
        [5399],
        [5382],
        [5422],
        [5463]], device='cuda:0')
[2024-07-24 10:29:02,882][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[28095],
        [24494],
        [11969],
        [23106],
        [27173],
        [19573],
        [24657],
        [24020],
        [23270],
        [26260],
        [27443],
        [27464],
        [25480],
        [22127]], device='cuda:0')
[2024-07-24 10:29:02,884][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[32440],
        [31691],
        [32340],
        [32202],
        [31969],
        [31819],
        [31608],
        [31416],
        [31442],
        [31598],
        [31619],
        [31483],
        [31391],
        [31272]], device='cuda:0')
[2024-07-24 10:29:02,885][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[14489],
        [ 7274],
        [ 8858],
        [ 5976],
        [ 4680],
        [ 4940],
        [ 4850],
        [ 4189],
        [ 4839],
        [ 4551],
        [ 4129],
        [ 4013],
        [ 3876],
        [ 3927]], device='cuda:0')
[2024-07-24 10:29:02,886][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[36206],
        [49654],
        [49569],
        [48364],
        [48374],
        [49183],
        [48688],
        [47080],
        [47675],
        [47192],
        [47192],
        [47700],
        [46815],
        [47475]], device='cuda:0')
[2024-07-24 10:29:02,888][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[40840],
        [40001],
        [37517],
        [37914],
        [37260],
        [10556],
        [32710],
        [40553],
        [33846],
        [41217],
        [44485],
        [12976],
        [35567],
        [ 9964]], device='cuda:0')
[2024-07-24 10:29:02,889][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[17543],
        [14578],
        [14370],
        [13809],
        [14959],
        [15988],
        [19645],
        [21808],
        [22128],
        [20891],
        [18850],
        [19959],
        [20924],
        [21606]], device='cuda:0')
[2024-07-24 10:29:02,891][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[14230],
        [15699],
        [27034],
        [32768],
        [30922],
        [34500],
        [33669],
        [35045],
        [39714],
        [40719],
        [38874],
        [37682],
        [37535],
        [38709]], device='cuda:0')
[2024-07-24 10:29:02,892][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[11816],
        [12692],
        [12161],
        [11919],
        [11985],
        [12587],
        [13221],
        [13564],
        [13737],
        [13845],
        [14067],
        [14226],
        [14480],
        [14558]], device='cuda:0')
[2024-07-24 10:29:02,893][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[11251],
        [ 8151],
        [ 7270],
        [15997],
        [12844],
        [21725],
        [15724],
        [34310],
        [23500],
        [21680],
        [13018],
        [29610],
        [36791],
        [24759]], device='cuda:0')
[2024-07-24 10:29:02,895][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[19837],
        [20758],
        [21583],
        [22398],
        [23747],
        [23925],
        [23539],
        [23840],
        [24809],
        [25044],
        [25252],
        [24676],
        [25367],
        [24957]], device='cuda:0')
[2024-07-24 10:29:02,896][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[37963],
        [34002],
        [28144],
        [24027],
        [21110],
        [19584],
        [17207],
        [17077],
        [15527],
        [14922],
        [15248],
        [15341],
        [15624],
        [16061]], device='cuda:0')
[2024-07-24 10:29:02,898][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[18787],
        [18821],
        [18857],
        [19073],
        [20015],
        [21699],
        [23306],
        [ 5587],
        [ 6078],
        [10771],
        [ 9678],
        [ 9296],
        [ 8197],
        [ 8177]], device='cuda:0')
[2024-07-24 10:29:02,899][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[21357],
        [25945],
        [27000],
        [27123],
        [26984],
        [27220],
        [26101],
        [27109],
        [25191],
        [24815],
        [25200],
        [24843],
        [24302],
        [23301]], device='cuda:0')
[2024-07-24 10:29:02,900][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[17786],
        [18335],
        [27969],
        [19733],
        [17437],
        [23838],
        [22754],
        [25202],
        [29483],
        [22809],
        [22119],
        [22035],
        [24062],
        [23644]], device='cuda:0')
[2024-07-24 10:29:02,902][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[3969],
        [3773],
        [3612],
        [3378],
        [3245],
        [3148],
        [3162],
        [2910],
        [2923],
        [2872],
        [2802],
        [2836],
        [2750],
        [2754]], device='cuda:0')
[2024-07-24 10:29:02,903][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[27736],
        [22717],
        [21774],
        [22401],
        [27443],
        [28648],
        [26541],
        [19294],
        [18537],
        [20743],
        [20166],
        [20004],
        [18397],
        [19868]], device='cuda:0')
[2024-07-24 10:29:02,904][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[9853],
        [7368],
        [8018],
        [8097],
        [8204],
        [8627],
        [8574],
        [8799],
        [9024],
        [9233],
        [9222],
        [9202],
        [9020],
        [9138]], device='cuda:0')
[2024-07-24 10:29:02,905][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[33105],
        [33443],
        [33942],
        [34041],
        [33327],
        [31854],
        [32864],
        [32574],
        [32772],
        [32849],
        [33407],
        [34185],
        [33842],
        [33802]], device='cuda:0')
[2024-07-24 10:29:02,906][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[24525],
        [24307],
        [23353],
        [22616],
        [21945],
        [21708],
        [21925],
        [21559],
        [21410],
        [21233],
        [21242],
        [21155],
        [21166],
        [21063]], device='cuda:0')
[2024-07-24 10:29:02,907][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[27212],
        [26311],
        [26378],
        [26098],
        [26295],
        [25604],
        [25404],
        [25318],
        [25037],
        [24791],
        [24321],
        [23759],
        [23567],
        [23524]], device='cuda:0')
[2024-07-24 10:29:02,909][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[16204],
        [11946],
        [12476],
        [11229],
        [11446],
        [12838],
        [13733],
        [11926],
        [14548],
        [12830],
        [12119],
        [12595],
        [11602],
        [13747]], device='cuda:0')
[2024-07-24 10:29:02,910][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[10206],
        [11000],
        [10525],
        [11905],
        [12529],
        [11998],
        [12344],
        [15305],
        [15813],
        [15094],
        [15154],
        [15318],
        [15684],
        [15932]], device='cuda:0')
[2024-07-24 10:29:02,912][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[12913],
        [39385],
        [39898],
        [32267],
        [32216],
        [24830],
        [27210],
        [22750],
        [24377],
        [24339],
        [29071],
        [20280],
        [10683],
        [23668]], device='cuda:0')
[2024-07-24 10:29:02,913][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[48380],
        [48380],
        [48380],
        [48380],
        [48380],
        [48380],
        [48380],
        [48380],
        [48380],
        [48380],
        [48380],
        [48380],
        [48380],
        [48380]], device='cuda:0')
[2024-07-24 10:29:02,934][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:29:02,935][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:02,936][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:02,936][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:02,937][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:02,938][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:02,938][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:02,939][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:02,940][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:02,941][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:02,942][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:02,942][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:02,943][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:02,944][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Amanda] are: tensor([0.5610, 0.4390], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:02,944][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Amanda] are: tensor([0.4358, 0.5642], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:02,946][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Amanda] are: tensor([0.9057, 0.0943], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:02,948][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Amanda] are: tensor([0.5560, 0.4440], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:02,949][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Amanda] are: tensor([0.5334, 0.4666], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:02,951][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Amanda] are: tensor([0.6137, 0.3863], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:02,953][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Amanda] are: tensor([0.5289, 0.4711], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:02,954][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Amanda] are: tensor([0.2092, 0.7908], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:02,955][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Amanda] are: tensor([0.0383, 0.9617], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:02,956][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Amanda] are: tensor([0.6142, 0.3858], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:02,956][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Amanda] are: tensor([0.6773, 0.3227], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:02,957][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Amanda] are: tensor([0.3690, 0.6310], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:02,958][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.3858, 0.3085, 0.3057], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:02,960][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.2228, 0.4486, 0.3287], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:02,961][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.6651, 0.2631, 0.0718], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:02,963][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.4453, 0.3209, 0.2338], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:02,964][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.2644, 0.4591, 0.2764], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:02,966][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.4444, 0.2803, 0.2753], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:02,967][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.3545, 0.3174, 0.3281], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:02,969][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0967, 0.3902, 0.5131], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:02,971][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0083, 0.4450, 0.5467], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:02,972][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.3974, 0.3095, 0.2931], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:02,974][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.3838, 0.2199, 0.3963], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:02,976][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.1490, 0.5215, 0.3295], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:02,977][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ John] are: tensor([0.2960, 0.2339, 0.2315, 0.2386], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:02,979][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ John] are: tensor([0.1594, 0.3131, 0.3196, 0.2079], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:02,980][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ John] are: tensor([0.6951, 0.1134, 0.1194, 0.0721], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:02,982][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ John] are: tensor([0.3309, 0.2576, 0.1866, 0.2249], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:02,984][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ John] are: tensor([0.2412, 0.2852, 0.2134, 0.2603], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:02,985][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ John] are: tensor([0.3478, 0.2181, 0.2150, 0.2191], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:02,987][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ John] are: tensor([0.2690, 0.2404, 0.2484, 0.2422], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:02,988][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ John] are: tensor([0.0586, 0.2647, 0.3618, 0.3149], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:02,989][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ John] are: tensor([0.0064, 0.2829, 0.3547, 0.3560], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:02,990][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ John] are: tensor([0.4047, 0.2970, 0.2432, 0.0551], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:02,991][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ John] are: tensor([0.3362, 0.1465, 0.2987, 0.2185], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:02,992][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ John] are: tensor([0.0575, 0.1378, 0.0827, 0.7221], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:02,993][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ went] are: tensor([0.2360, 0.1880, 0.1871, 0.1926, 0.1963], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:02,995][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ went] are: tensor([0.1283, 0.2153, 0.2832, 0.1687, 0.2045], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:02,996][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ went] are: tensor([0.4778, 0.1635, 0.1010, 0.2034, 0.0542], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:02,998][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ went] are: tensor([0.2640, 0.1958, 0.1447, 0.1763, 0.2192], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:02,999][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ went] are: tensor([0.2375, 0.1943, 0.2041, 0.1282, 0.2359], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:03,001][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ went] are: tensor([0.3019, 0.1809, 0.1770, 0.1810, 0.1592], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:03,003][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ went] are: tensor([0.2176, 0.1929, 0.1997, 0.1944, 0.1954], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:03,005][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ went] are: tensor([0.0416, 0.1899, 0.2762, 0.2489, 0.2433], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:03,006][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.0021, 0.1899, 0.2863, 0.2891, 0.2327], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:03,008][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ went] are: tensor([0.3994, 0.1685, 0.1980, 0.0517, 0.1824], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:03,009][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ went] are: tensor([0.2577, 0.1214, 0.2357, 0.1785, 0.2067], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:03,011][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ went] are: tensor([0.0232, 0.1040, 0.0734, 0.6450, 0.1544], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:03,012][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.2019, 0.1602, 0.1591, 0.1635, 0.1664, 0.1489], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:03,014][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.1122, 0.2318, 0.1770, 0.1779, 0.1680, 0.1330], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:03,016][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.3835, 0.1763, 0.0953, 0.1579, 0.1487, 0.0383], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:03,018][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.1891, 0.1655, 0.1234, 0.1464, 0.1789, 0.1967], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:03,019][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0882, 0.2472, 0.1685, 0.1632, 0.2624, 0.0705], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:03,021][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.2637, 0.1566, 0.1527, 0.1561, 0.1373, 0.1336], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:03,022][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1819, 0.1620, 0.1675, 0.1633, 0.1643, 0.1611], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:03,022][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0363, 0.1536, 0.2102, 0.1923, 0.2032, 0.2044], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:03,023][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0017, 0.1584, 0.2273, 0.2140, 0.1666, 0.2320], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:03,024][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.3074, 0.1456, 0.1555, 0.0396, 0.2754, 0.0765], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:03,025][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.2347, 0.0968, 0.1761, 0.1351, 0.1578, 0.1995], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:03,027][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0066, 0.0647, 0.0295, 0.4658, 0.1788, 0.2546], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:03,028][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.1748, 0.1399, 0.1391, 0.1427, 0.1450, 0.1305, 0.1281],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:03,030][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0800, 0.1781, 0.1391, 0.1369, 0.1392, 0.1023, 0.2245],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:03,032][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.4420, 0.1051, 0.0694, 0.0781, 0.1362, 0.0987, 0.0705],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:03,033][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.1721, 0.1394, 0.1003, 0.1241, 0.1509, 0.1653, 0.1481],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:03,035][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.1008, 0.1502, 0.1221, 0.1372, 0.2761, 0.0980, 0.1156],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:03,036][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.2286, 0.1383, 0.1350, 0.1380, 0.1218, 0.1190, 0.1192],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:03,038][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.1558, 0.1387, 0.1434, 0.1397, 0.1406, 0.1380, 0.1438],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:03,040][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0296, 0.1269, 0.1723, 0.1564, 0.1708, 0.1717, 0.1724],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:03,042][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0019, 0.1309, 0.1764, 0.1750, 0.1379, 0.1970, 0.1808],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:03,043][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.2244, 0.2077, 0.1272, 0.0436, 0.1764, 0.1519, 0.0687],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:03,045][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.2021, 0.0831, 0.1497, 0.1109, 0.1272, 0.1640, 0.1630],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:03,046][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0142, 0.0833, 0.0347, 0.3850, 0.1175, 0.2975, 0.0679],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:03,048][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ station] are: tensor([0.1548, 0.1237, 0.1233, 0.1264, 0.1287, 0.1157, 0.1136, 0.1138],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:03,050][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ station] are: tensor([0.0522, 0.1057, 0.1234, 0.0867, 0.1218, 0.1019, 0.2529, 0.1555],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:03,051][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ station] are: tensor([0.2147, 0.0752, 0.0697, 0.1629, 0.0657, 0.0960, 0.2616, 0.0542],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:03,053][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ station] are: tensor([0.1618, 0.1166, 0.0836, 0.1033, 0.1282, 0.1398, 0.1246, 0.1420],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:03,055][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ station] are: tensor([0.0993, 0.1071, 0.1122, 0.0990, 0.2025, 0.0839, 0.0955, 0.2005],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:03,056][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ station] are: tensor([0.1973, 0.1244, 0.1212, 0.1234, 0.1087, 0.1073, 0.1075, 0.1102],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:03,056][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ station] are: tensor([0.1362, 0.1215, 0.1255, 0.1225, 0.1228, 0.1207, 0.1261, 0.1247],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:03,057][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ station] are: tensor([0.0184, 0.1132, 0.1618, 0.1490, 0.1537, 0.1723, 0.1723, 0.0594],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:03,058][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ station] are: tensor([0.0014, 0.1052, 0.1422, 0.1450, 0.1119, 0.1694, 0.1545, 0.1703],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:03,059][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ station] are: tensor([0.1383, 0.1254, 0.0965, 0.0460, 0.1223, 0.1545, 0.0732, 0.2439],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:03,061][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ station] are: tensor([0.1631, 0.0738, 0.1294, 0.0986, 0.1106, 0.1480, 0.1455, 0.1310],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:03,063][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ station] are: tensor([0.0071, 0.0691, 0.0313, 0.3422, 0.0869, 0.2562, 0.0820, 0.1252],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:03,064][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.1407, 0.1125, 0.1119, 0.1145, 0.1161, 0.1048, 0.1024, 0.1028, 0.0943],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:03,066][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0601, 0.1191, 0.0956, 0.0846, 0.0801, 0.0741, 0.1737, 0.1069, 0.2058],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:03,068][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.2768, 0.0928, 0.0633, 0.1099, 0.0856, 0.0706, 0.2000, 0.0670, 0.0339],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:03,069][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.1396, 0.1049, 0.0765, 0.0951, 0.1149, 0.1245, 0.1136, 0.1295, 0.1014],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:03,071][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0282, 0.0858, 0.0933, 0.0902, 0.2108, 0.0582, 0.0888, 0.2692, 0.0756],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:03,073][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.1853, 0.1124, 0.1095, 0.1117, 0.0982, 0.0966, 0.0965, 0.0989, 0.0910],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:03,074][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.1209, 0.1077, 0.1112, 0.1085, 0.1087, 0.1069, 0.1117, 0.1107, 0.1137],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:03,076][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0259, 0.1059, 0.1408, 0.1303, 0.1407, 0.1419, 0.1463, 0.0597, 0.1085],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:03,078][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0007, 0.0832, 0.1169, 0.1086, 0.0837, 0.1197, 0.1142, 0.1253, 0.2476],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:03,080][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.1406, 0.1363, 0.1063, 0.0301, 0.1126, 0.0888, 0.0946, 0.2299, 0.0609],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:03,081][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.1323, 0.0662, 0.1108, 0.0900, 0.0996, 0.1277, 0.1266, 0.1138, 0.1330],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:03,083][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0042, 0.0562, 0.0266, 0.2871, 0.1041, 0.2064, 0.0758, 0.1818, 0.0578],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:03,085][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ John] are: tensor([0.1278, 0.1023, 0.1015, 0.1043, 0.1056, 0.0953, 0.0933, 0.0936, 0.0860,
        0.0903], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:03,087][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ John] are: tensor([0.0386, 0.0852, 0.0764, 0.0541, 0.0892, 0.0742, 0.1459, 0.1460, 0.2035,
        0.0869], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:03,088][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ John] are: tensor([0.3221, 0.0620, 0.0595, 0.0466, 0.0518, 0.0758, 0.1687, 0.0774, 0.0495,
        0.0865], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:03,089][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ John] are: tensor([0.1230, 0.0961, 0.0662, 0.0812, 0.0992, 0.1099, 0.0989, 0.1090, 0.0883,
        0.1282], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:03,090][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ John] are: tensor([0.0923, 0.0817, 0.0727, 0.0797, 0.2187, 0.0675, 0.0714, 0.1787, 0.0486,
        0.0888], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:03,091][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ John] are: tensor([0.1653, 0.1021, 0.0999, 0.1015, 0.0898, 0.0890, 0.0887, 0.0908, 0.0842,
        0.0887], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:03,092][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ John] are: tensor([0.1091, 0.0969, 0.1000, 0.0975, 0.0977, 0.0961, 0.1004, 0.0996, 0.1023,
        0.1007], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:03,093][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ John] are: tensor([0.0191, 0.0941, 0.1279, 0.1141, 0.1280, 0.1324, 0.1328, 0.0557, 0.1025,
        0.0934], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:03,095][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ John] are: tensor([0.0005, 0.0668, 0.0883, 0.0794, 0.0593, 0.0836, 0.0781, 0.0941, 0.1814,
        0.2685], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:03,097][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ John] are: tensor([0.1987, 0.1475, 0.1102, 0.0258, 0.0761, 0.1260, 0.0781, 0.1082, 0.1016,
        0.0278], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:03,098][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ John] are: tensor([0.1310, 0.0562, 0.1018, 0.0762, 0.0849, 0.1150, 0.1144, 0.1004, 0.1255,
        0.0946], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:03,100][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ John] are: tensor([0.0071, 0.0350, 0.0187, 0.1849, 0.0757, 0.1367, 0.0596, 0.0956, 0.0578,
        0.3288], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:03,102][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.1170, 0.0936, 0.0933, 0.0956, 0.0972, 0.0876, 0.0860, 0.0862, 0.0794,
        0.0831, 0.0810], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:03,103][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0394, 0.0682, 0.0771, 0.0576, 0.0817, 0.0628, 0.1643, 0.0873, 0.1901,
        0.0853, 0.0863], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:03,105][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.1908, 0.0704, 0.0420, 0.1107, 0.0335, 0.0670, 0.2256, 0.0405, 0.0450,
        0.1610, 0.0136], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:03,107][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.1127, 0.0864, 0.0607, 0.0744, 0.0923, 0.1004, 0.0911, 0.1030, 0.0809,
        0.1155, 0.0826], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:03,109][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.0554, 0.0950, 0.1007, 0.0768, 0.1275, 0.0478, 0.0747, 0.1850, 0.0533,
        0.0788, 0.1049], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:03,110][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.1552, 0.0947, 0.0922, 0.0939, 0.0823, 0.0809, 0.0811, 0.0830, 0.0766,
        0.0810, 0.0788], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:03,112][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0988, 0.0879, 0.0907, 0.0884, 0.0887, 0.0871, 0.0912, 0.0904, 0.0929,
        0.0914, 0.0925], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:03,114][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0175, 0.0808, 0.1158, 0.1065, 0.1092, 0.1190, 0.1210, 0.0492, 0.0997,
        0.0892, 0.0919], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:03,115][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.0003, 0.0480, 0.0696, 0.0633, 0.0477, 0.0731, 0.0678, 0.0766, 0.1639,
        0.2351, 0.1546], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:03,117][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.1504, 0.0884, 0.1004, 0.0216, 0.1129, 0.1383, 0.0970, 0.1091, 0.0965,
        0.0232, 0.0621], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:03,119][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.1201, 0.0525, 0.0926, 0.0703, 0.0768, 0.1055, 0.1061, 0.0931, 0.1159,
        0.0869, 0.0802], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:03,121][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0060, 0.0358, 0.0219, 0.1870, 0.0499, 0.1134, 0.0411, 0.0788, 0.0580,
        0.3273, 0.0808], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:03,122][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.1087, 0.0871, 0.0865, 0.0886, 0.0899, 0.0813, 0.0795, 0.0798, 0.0732,
        0.0768, 0.0749, 0.0736], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:03,123][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0373, 0.0797, 0.0669, 0.0566, 0.0655, 0.0533, 0.0992, 0.0891, 0.1477,
        0.0851, 0.1094, 0.1103], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:03,124][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.2567, 0.0894, 0.0477, 0.0616, 0.0553, 0.0559, 0.1071, 0.1135, 0.0429,
        0.1034, 0.0383, 0.0282], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:03,124][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.1015, 0.0774, 0.0545, 0.0677, 0.0828, 0.0908, 0.0822, 0.0914, 0.0726,
        0.1049, 0.0742, 0.1000], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:03,126][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0268, 0.0821, 0.0870, 0.0809, 0.1261, 0.0461, 0.0781, 0.1856, 0.0566,
        0.0772, 0.1000, 0.0534], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:03,128][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.1449, 0.0876, 0.0853, 0.0870, 0.0763, 0.0750, 0.0751, 0.0772, 0.0709,
        0.0752, 0.0733, 0.0723], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:03,129][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0899, 0.0800, 0.0826, 0.0806, 0.0809, 0.0795, 0.0831, 0.0826, 0.0848,
        0.0836, 0.0846, 0.0877], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:03,131][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0186, 0.0752, 0.1029, 0.0948, 0.1007, 0.1053, 0.1067, 0.0437, 0.0839,
        0.0775, 0.0876, 0.1030], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:03,133][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0005, 0.0468, 0.0634, 0.0589, 0.0451, 0.0636, 0.0581, 0.0673, 0.1345,
        0.2004, 0.1377, 0.1237], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:03,134][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.1583, 0.1030, 0.0865, 0.0228, 0.1133, 0.0838, 0.0424, 0.1576, 0.0522,
        0.0247, 0.1246, 0.0307], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:03,136][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.1208, 0.0494, 0.0844, 0.0642, 0.0720, 0.0944, 0.0950, 0.0834, 0.1028,
        0.0784, 0.0723, 0.0827], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:03,138][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0051, 0.0305, 0.0154, 0.1556, 0.0486, 0.0909, 0.0438, 0.0736, 0.0496,
        0.2835, 0.0947, 0.1088], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:03,140][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ ring] are: tensor([0.1011, 0.0811, 0.0804, 0.0823, 0.0835, 0.0756, 0.0739, 0.0743, 0.0682,
        0.0716, 0.0699, 0.0687, 0.0695], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:03,142][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ ring] are: tensor([0.0294, 0.0575, 0.0668, 0.0404, 0.0606, 0.0468, 0.0892, 0.0762, 0.1361,
        0.0632, 0.0960, 0.0939, 0.1440], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:03,143][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ ring] are: tensor([0.1075, 0.0566, 0.0393, 0.0851, 0.0523, 0.0646, 0.1320, 0.0671, 0.0531,
        0.1394, 0.0353, 0.0780, 0.0896], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:03,145][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ ring] are: tensor([0.0935, 0.0694, 0.0477, 0.0596, 0.0738, 0.0815, 0.0729, 0.0798, 0.0641,
        0.0949, 0.0657, 0.0904, 0.1067], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:03,147][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ ring] are: tensor([0.0404, 0.0699, 0.0587, 0.0832, 0.1486, 0.0554, 0.0726, 0.1414, 0.0336,
        0.0779, 0.0925, 0.0430, 0.0829], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:03,148][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ ring] are: tensor([0.1314, 0.0807, 0.0788, 0.0801, 0.0707, 0.0702, 0.0700, 0.0715, 0.0660,
        0.0697, 0.0680, 0.0673, 0.0757], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:03,150][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ ring] are: tensor([0.0825, 0.0737, 0.0761, 0.0743, 0.0746, 0.0733, 0.0766, 0.0760, 0.0781,
        0.0770, 0.0779, 0.0808, 0.0793], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:03,152][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ ring] are: tensor([0.0134, 0.0702, 0.0974, 0.0913, 0.0928, 0.1030, 0.1049, 0.0392, 0.0814,
        0.0719, 0.0766, 0.0992, 0.0586], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:03,154][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ ring] are: tensor([0.0003, 0.0367, 0.0536, 0.0502, 0.0386, 0.0570, 0.0516, 0.0590, 0.1199,
        0.1803, 0.1276, 0.1121, 0.1131], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:03,155][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ ring] are: tensor([0.0830, 0.1202, 0.0558, 0.0210, 0.1343, 0.1038, 0.0446, 0.1231, 0.0444,
        0.0204, 0.0771, 0.0352, 0.1371], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:03,156][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ ring] are: tensor([0.1110, 0.0453, 0.0779, 0.0584, 0.0664, 0.0879, 0.0868, 0.0772, 0.0948,
        0.0719, 0.0670, 0.0753, 0.0800], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:03,156][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ ring] are: tensor([0.0032, 0.0194, 0.0110, 0.1202, 0.0419, 0.0571, 0.0403, 0.0664, 0.0504,
        0.2414, 0.0882, 0.1346, 0.1257], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:03,157][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0943, 0.0756, 0.0752, 0.0770, 0.0783, 0.0706, 0.0692, 0.0694, 0.0638,
        0.0670, 0.0654, 0.0642, 0.0649, 0.0652], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:03,159][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0330, 0.0728, 0.0510, 0.0515, 0.0485, 0.0384, 0.0811, 0.0567, 0.1116,
        0.0772, 0.0845, 0.0960, 0.1545, 0.0431], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:03,161][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1395, 0.0786, 0.0378, 0.0857, 0.0513, 0.0169, 0.1544, 0.0634, 0.0357,
        0.1127, 0.0346, 0.0702, 0.0967, 0.0227], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:03,162][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0843, 0.0624, 0.0440, 0.0543, 0.0661, 0.0731, 0.0660, 0.0719, 0.0579,
        0.0855, 0.0595, 0.0812, 0.0954, 0.0983], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:03,164][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0372, 0.0989, 0.0792, 0.0840, 0.0949, 0.0331, 0.0644, 0.1446, 0.0304,
        0.0784, 0.0764, 0.0373, 0.0830, 0.0581], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:03,166][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.1248, 0.0757, 0.0736, 0.0750, 0.0658, 0.0649, 0.0649, 0.0666, 0.0614,
        0.0649, 0.0632, 0.0625, 0.0707, 0.0660], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:03,168][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0766, 0.0682, 0.0704, 0.0687, 0.0689, 0.0677, 0.0708, 0.0704, 0.0722,
        0.0712, 0.0720, 0.0747, 0.0734, 0.0747], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:03,169][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0177, 0.0649, 0.0861, 0.0801, 0.0848, 0.0853, 0.0899, 0.0384, 0.0699,
        0.0667, 0.0768, 0.0908, 0.0602, 0.0883], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:03,171][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0005, 0.0415, 0.0522, 0.0481, 0.0363, 0.0480, 0.0487, 0.0547, 0.1051,
        0.1459, 0.1048, 0.0971, 0.1095, 0.1075], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:03,173][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.1491, 0.0705, 0.0777, 0.0184, 0.1270, 0.0338, 0.0511, 0.1242, 0.0390,
        0.0202, 0.0904, 0.0417, 0.1325, 0.0244], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:03,175][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.1013, 0.0422, 0.0700, 0.0546, 0.0618, 0.0806, 0.0790, 0.0703, 0.0845,
        0.0667, 0.0623, 0.0692, 0.0734, 0.0841], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:03,177][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0012, 0.0088, 0.0043, 0.0668, 0.0282, 0.0286, 0.0338, 0.0591, 0.0464,
        0.1953, 0.0907, 0.1283, 0.1614, 0.1472], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:03,216][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:29:03,217][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:03,217][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:03,218][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:03,219][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:03,219][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:03,220][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:03,221][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:03,222][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:03,223][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:03,223][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:03,224][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:03,225][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:03,226][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Amanda] are: tensor([0.4869, 0.5131], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:03,226][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Amanda] are: tensor([0.4289, 0.5711], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:03,227][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Amanda] are: tensor([0.0222, 0.9778], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:03,228][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Amanda] are: tensor([0.4399, 0.5601], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:03,228][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Amanda] are: tensor([0.5827, 0.4173], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:03,229][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Amanda] are: tensor([0.6313, 0.3687], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:03,230][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Amanda] are: tensor([0.8391, 0.1609], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:03,231][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Amanda] are: tensor([0.8749, 0.1251], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:03,232][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Amanda] are: tensor([0.9773, 0.0227], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:03,234][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Amanda] are: tensor([0.6248, 0.3752], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:03,235][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Amanda] are: tensor([0.9769, 0.0231], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:03,237][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Amanda] are: tensor([0.7842, 0.2158], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:03,239][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.3678, 0.3926, 0.2396], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:03,240][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.2475, 0.3155, 0.4370], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:03,241][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0097, 0.5719, 0.4184], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:03,242][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0935, 0.3530, 0.5534], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:03,243][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.6175, 0.1813, 0.2012], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:03,243][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.3881, 0.2889, 0.3230], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:03,244][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.6373, 0.1430, 0.2197], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:03,246][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.4361, 0.1653, 0.3986], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:03,247][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0566, 0.9402, 0.0032], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:03,249][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.6062, 0.2027, 0.1911], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:03,250][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.9699, 0.0169, 0.0132], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:03,252][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.7217, 0.0669, 0.2114], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:03,253][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ John] are: tensor([0.2841, 0.3008, 0.1853, 0.2298], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:03,255][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ John] are: tensor([0.1622, 0.2084, 0.3067, 0.3227], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:03,257][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ John] are: tensor([0.0041, 0.1716, 0.2541, 0.5702], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:03,258][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ John] are: tensor([0.0414, 0.0590, 0.3308, 0.5689], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:03,260][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ John] are: tensor([0.3099, 0.2240, 0.2503, 0.2158], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:03,262][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ John] are: tensor([0.2694, 0.1252, 0.2561, 0.3493], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:03,263][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ John] are: tensor([0.3093, 0.0731, 0.3985, 0.2191], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:03,265][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ John] are: tensor([0.2530, 0.0572, 0.3959, 0.2939], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:03,267][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ John] are: tensor([0.1504, 0.4890, 0.3370, 0.0236], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:03,268][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ John] are: tensor([0.1905, 0.0967, 0.2518, 0.4609], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:03,270][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ John] are: tensor([0.8538, 0.0430, 0.0335, 0.0698], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:03,271][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ John] are: tensor([0.4664, 0.0803, 0.2238, 0.2296], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:03,273][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([0.2355, 0.2459, 0.1522, 0.1846, 0.1818], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:03,275][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([0.1198, 0.1533, 0.2311, 0.2393, 0.2565], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:03,275][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([0.0137, 0.2118, 0.2216, 0.4236, 0.1293], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:03,276][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([0.0169, 0.0065, 0.2197, 0.2945, 0.4623], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:03,277][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([0.2589, 0.1776, 0.2109, 0.1798, 0.1728], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:03,278][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([0.2292, 0.1059, 0.1404, 0.2539, 0.2705], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:03,280][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([0.1198, 0.0345, 0.2226, 0.4073, 0.2158], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:03,281][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([0.0265, 0.0152, 0.0849, 0.4975, 0.3760], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:03,283][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([0.3744, 0.3585, 0.1979, 0.0661, 0.0031], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:03,284][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([0.4084, 0.0458, 0.2252, 0.1706, 0.1500], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:03,286][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([0.8844, 0.0182, 0.0184, 0.0234, 0.0556], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:03,287][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([0.5186, 0.0144, 0.1829, 0.0566, 0.2275], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:03,289][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.1945, 0.2101, 0.1350, 0.1633, 0.1584, 0.1387], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:03,291][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.1001, 0.1180, 0.1695, 0.1721, 0.1859, 0.2544], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:03,292][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0018, 0.1492, 0.1946, 0.4633, 0.1036, 0.0875], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:03,294][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0289, 0.0024, 0.0232, 0.0588, 0.5231, 0.3635], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:03,296][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.2517, 0.1371, 0.1736, 0.1348, 0.1356, 0.1672], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:03,297][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.1482, 0.0702, 0.0743, 0.1674, 0.1582, 0.3817], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:03,299][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.3344, 0.0294, 0.0941, 0.1417, 0.1956, 0.2048], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:03,301][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0771, 0.0125, 0.0344, 0.1221, 0.2774, 0.4764], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:03,302][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0338, 0.7562, 0.1329, 0.0615, 0.0118, 0.0038], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:03,304][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.3391, 0.0396, 0.0816, 0.1664, 0.2715, 0.1018], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:03,306][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.9288, 0.0068, 0.0062, 0.0115, 0.0158, 0.0310], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:03,307][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.3891, 0.0203, 0.1071, 0.0926, 0.2287, 0.1623], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:03,308][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.1758, 0.1849, 0.1165, 0.1434, 0.1396, 0.1183, 0.1214],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:03,309][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0807, 0.0953, 0.1380, 0.1446, 0.1582, 0.2119, 0.1713],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:03,310][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0041, 0.1516, 0.1554, 0.3263, 0.1418, 0.1221, 0.0987],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:03,310][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0122, 0.0032, 0.0155, 0.1391, 0.1379, 0.5687, 0.1235],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:03,312][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.1714, 0.1312, 0.1540, 0.1298, 0.1261, 0.1488, 0.1388],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:03,313][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.0923, 0.0484, 0.0590, 0.1173, 0.1188, 0.3316, 0.2327],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:03,315][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.3291, 0.0213, 0.0559, 0.0867, 0.1114, 0.3168, 0.0788],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:03,317][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0541, 0.0041, 0.0161, 0.0454, 0.1929, 0.5043, 0.1832],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:03,318][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0364, 0.7753, 0.0539, 0.0422, 0.0311, 0.0597, 0.0015],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:03,320][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.1937, 0.0450, 0.0720, 0.1310, 0.1424, 0.2962, 0.1197],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:03,322][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.8797, 0.0086, 0.0060, 0.0122, 0.0238, 0.0239, 0.0458],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:03,323][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.3542, 0.0164, 0.0556, 0.0714, 0.1314, 0.2702, 0.1008],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:03,325][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ station] are: tensor([0.1606, 0.1708, 0.1013, 0.1290, 0.1288, 0.1082, 0.1111, 0.0903],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:03,327][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ station] are: tensor([0.0728, 0.0799, 0.1147, 0.1200, 0.1253, 0.1678, 0.1421, 0.1774],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:03,328][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ station] are: tensor([0.0110, 0.1423, 0.1505, 0.2425, 0.0950, 0.1273, 0.1166, 0.1146],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:03,330][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ station] are: tensor([4.5418e-04, 2.8700e-04, 1.0950e-02, 4.4280e-02, 6.4848e-02, 6.8034e-01,
        1.9626e-01, 2.5749e-03], device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:03,331][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ station] are: tensor([0.1559, 0.1093, 0.1430, 0.1078, 0.1146, 0.1379, 0.1256, 0.1060],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:03,333][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ station] are: tensor([0.0841, 0.0361, 0.0602, 0.0843, 0.0907, 0.2178, 0.1915, 0.2353],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:03,335][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ station] are: tensor([0.0288, 0.0061, 0.0695, 0.1270, 0.1400, 0.4244, 0.1854, 0.0187],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:03,336][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ station] are: tensor([0.0007, 0.0007, 0.0084, 0.0275, 0.1409, 0.4778, 0.3427, 0.0013],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:03,338][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ station] are: tensor([0.2536, 0.0668, 0.1597, 0.3189, 0.0170, 0.1684, 0.0147, 0.0009],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:03,340][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ station] are: tensor([0.0210, 0.0135, 0.0463, 0.1733, 0.0919, 0.4029, 0.2073, 0.0438],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:03,341][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ station] are: tensor([0.6742, 0.0109, 0.0198, 0.0285, 0.0629, 0.0784, 0.0879, 0.0373],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:03,341][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ station] are: tensor([0.0325, 0.0092, 0.0480, 0.0940, 0.1368, 0.3634, 0.2930, 0.0231],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:03,342][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.1449, 0.1554, 0.0917, 0.1204, 0.1200, 0.0990, 0.1061, 0.0861, 0.0765],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:03,343][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0663, 0.0714, 0.0971, 0.1010, 0.1055, 0.1396, 0.1177, 0.1500, 0.1513],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:03,344][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0013, 0.1763, 0.1631, 0.2979, 0.1096, 0.0881, 0.0756, 0.0685, 0.0196],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:03,346][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0063, 0.0018, 0.0089, 0.0364, 0.0786, 0.4001, 0.3801, 0.0117, 0.0761],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:03,347][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.3231, 0.0784, 0.0948, 0.0738, 0.0793, 0.0957, 0.0875, 0.0701, 0.0973],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:03,349][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0609, 0.0289, 0.0308, 0.0601, 0.0621, 0.1570, 0.1129, 0.2784, 0.2090],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:03,351][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0531, 0.0193, 0.0662, 0.1108, 0.0892, 0.2919, 0.2386, 0.0549, 0.0759],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:03,352][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0062, 0.0021, 0.0079, 0.0266, 0.1351, 0.3116, 0.3827, 0.0373, 0.0907],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:03,354][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0672, 0.6374, 0.0346, 0.0406, 0.0841, 0.0253, 0.0417, 0.0483, 0.0208],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:03,356][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.1651, 0.0491, 0.0513, 0.1858, 0.0587, 0.2842, 0.1250, 0.0398, 0.0410],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:03,357][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.7853, 0.0103, 0.0122, 0.0131, 0.0245, 0.0348, 0.0710, 0.0099, 0.0389],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:03,359][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0825, 0.0102, 0.0691, 0.0460, 0.1498, 0.2263, 0.1986, 0.1223, 0.0951],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:03,361][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ John] are: tensor([0.1351, 0.1448, 0.0867, 0.1098, 0.1080, 0.0890, 0.0919, 0.0769, 0.0681,
        0.0897], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:03,362][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ John] are: tensor([0.0511, 0.0562, 0.0826, 0.0865, 0.0918, 0.1242, 0.1034, 0.1360, 0.1352,
        0.1330], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:03,364][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ John] are: tensor([0.0088, 0.1162, 0.1283, 0.1751, 0.1075, 0.1026, 0.0947, 0.1208, 0.0436,
        0.1023], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:03,366][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ John] are: tensor([0.0099, 0.0016, 0.0047, 0.0099, 0.0598, 0.1443, 0.0458, 0.0016, 0.0710,
        0.6513], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:03,367][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ John] are: tensor([0.1270, 0.0961, 0.1121, 0.0892, 0.0888, 0.1023, 0.0954, 0.0824, 0.1153,
        0.0912], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:03,369][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ John] are: tensor([0.0425, 0.0173, 0.0328, 0.0415, 0.0531, 0.1663, 0.1260, 0.1813, 0.2550,
        0.0841], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:03,371][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ John] are: tensor([0.1677, 0.0155, 0.0517, 0.0309, 0.0421, 0.1846, 0.0622, 0.0213, 0.1824,
        0.2416], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:03,373][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ John] are: tensor([0.0329, 0.0012, 0.0053, 0.0041, 0.1418, 0.2344, 0.2627, 0.0196, 0.1638,
        0.1342], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:03,374][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ John] are: tensor([0.0773, 0.2601, 0.1937, 0.0151, 0.0408, 0.1774, 0.0216, 0.0900, 0.1060,
        0.0179], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:03,375][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ John] are: tensor([0.1091, 0.0179, 0.0373, 0.0559, 0.0245, 0.1436, 0.1027, 0.0122, 0.0940,
        0.4028], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:03,376][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ John] are: tensor([0.6543, 0.0262, 0.0127, 0.0338, 0.0195, 0.0298, 0.0507, 0.0071, 0.0370,
        0.1288], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:03,376][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ John] are: tensor([0.2298, 0.0097, 0.0265, 0.0254, 0.0906, 0.2053, 0.1410, 0.0684, 0.0757,
        0.1276], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:03,378][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.1227, 0.1304, 0.0812, 0.0984, 0.1004, 0.0805, 0.0836, 0.0719, 0.0624,
        0.0807, 0.0878], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:03,379][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0494, 0.0513, 0.0728, 0.0739, 0.0762, 0.1056, 0.0891, 0.1135, 0.1175,
        0.1131, 0.1376], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:03,381][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.0063, 0.1252, 0.1237, 0.2022, 0.0766, 0.0878, 0.0847, 0.0925, 0.0413,
        0.1097, 0.0500], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:03,382][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([1.9064e-03, 1.3668e-04, 5.8497e-03, 5.9686e-03, 1.7895e-02, 2.0612e-01,
        8.6912e-02, 1.7548e-03, 2.6951e-01, 3.5806e-01, 4.5898e-02],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:03,384][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.1192, 0.0807, 0.1021, 0.0770, 0.0785, 0.0945, 0.0862, 0.0810, 0.1150,
        0.0830, 0.0828], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:03,385][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.0582, 0.0225, 0.0269, 0.0459, 0.0466, 0.1231, 0.0919, 0.1798, 0.1712,
        0.0867, 0.1473], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:03,387][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.0216, 0.0036, 0.0243, 0.0304, 0.0315, 0.1404, 0.0924, 0.0223, 0.1621,
        0.4177, 0.0539], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:03,388][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([5.1744e-03, 3.6427e-04, 3.0613e-03, 9.9715e-03, 3.5245e-02, 1.0839e-01,
        1.0686e-01, 8.6123e-03, 2.4597e-01, 4.0457e-01, 7.1775e-02],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:03,390][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.0667, 0.0711, 0.1623, 0.0275, 0.1257, 0.0958, 0.0148, 0.1984, 0.2030,
        0.0307, 0.0040], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:03,392][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.1087, 0.0097, 0.0467, 0.0324, 0.0410, 0.2043, 0.1290, 0.0125, 0.1727,
        0.1812, 0.0620], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:03,393][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.5760, 0.0115, 0.0136, 0.0193, 0.0604, 0.0437, 0.0846, 0.0124, 0.0420,
        0.0872, 0.0492], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:03,395][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.1394, 0.0026, 0.0379, 0.0130, 0.0613, 0.2540, 0.1067, 0.0277, 0.1901,
        0.0634, 0.1038], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:03,397][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.1128, 0.1202, 0.0745, 0.0911, 0.0914, 0.0740, 0.0778, 0.0657, 0.0581,
        0.0749, 0.0810, 0.0785], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:03,399][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0456, 0.0475, 0.0649, 0.0677, 0.0714, 0.0930, 0.0781, 0.1026, 0.1008,
        0.0988, 0.1208, 0.1088], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:03,400][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0042, 0.1194, 0.1132, 0.1697, 0.1098, 0.0843, 0.0725, 0.1023, 0.0330,
        0.0881, 0.0528, 0.0507], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:03,402][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([6.6391e-03, 4.5098e-05, 3.0393e-04, 8.1393e-04, 3.8810e-03, 1.4529e-02,
        4.3735e-03, 3.9297e-04, 1.4316e-02, 5.8181e-02, 3.8218e-02, 8.5831e-01],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:03,403][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.1087, 0.0780, 0.0892, 0.0755, 0.0734, 0.0850, 0.0797, 0.0753, 0.0947,
        0.0792, 0.0777, 0.0835], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:03,405][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0351, 0.0143, 0.0182, 0.0336, 0.0355, 0.1082, 0.0770, 0.1736, 0.1530,
        0.0734, 0.1445, 0.1335], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:03,407][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.2932, 0.0036, 0.0106, 0.0123, 0.0153, 0.0523, 0.0147, 0.0100, 0.0385,
        0.1323, 0.0417, 0.3756], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:03,408][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([3.0229e-02, 2.0379e-04, 5.8134e-04, 1.7301e-03, 7.3630e-03, 2.0607e-02,
        1.3739e-02, 1.4904e-03, 1.9389e-02, 8.3932e-02, 5.4701e-02, 7.6603e-01],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:03,409][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0404, 0.2165, 0.1205, 0.0765, 0.0522, 0.0894, 0.0030, 0.0726, 0.1942,
        0.1043, 0.0298, 0.0007], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:03,410][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.1680, 0.0076, 0.0116, 0.0162, 0.0263, 0.0695, 0.0232, 0.0155, 0.0205,
        0.1087, 0.2910, 0.2419], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:03,412][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.8377, 0.0047, 0.0034, 0.0049, 0.0088, 0.0104, 0.0161, 0.0039, 0.0080,
        0.0215, 0.0092, 0.0713], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:03,413][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.3182, 0.0027, 0.0116, 0.0117, 0.0316, 0.0536, 0.0407, 0.0105, 0.0358,
        0.0616, 0.0903, 0.3317], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:03,415][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ ring] are: tensor([0.1093, 0.1159, 0.0699, 0.0849, 0.0861, 0.0701, 0.0718, 0.0602, 0.0528,
        0.0677, 0.0741, 0.0709, 0.0664], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:03,417][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ ring] are: tensor([0.0369, 0.0392, 0.0560, 0.0603, 0.0614, 0.0826, 0.0692, 0.0906, 0.0902,
        0.0915, 0.1091, 0.0989, 0.1142], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:03,418][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ ring] are: tensor([0.0071, 0.0847, 0.0843, 0.1532, 0.1013, 0.0869, 0.0756, 0.0893, 0.0331,
        0.0845, 0.0561, 0.0602, 0.0838], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:03,420][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ ring] are: tensor([6.9167e-05, 4.0029e-06, 1.1642e-04, 1.7295e-04, 1.2680e-03, 6.7819e-03,
        1.8717e-03, 1.0188e-04, 3.6535e-03, 1.2011e-02, 2.0419e-02, 9.5012e-01,
        3.4075e-03], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:03,421][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ ring] are: tensor([0.0971, 0.0682, 0.0930, 0.0684, 0.0640, 0.0831, 0.0736, 0.0709, 0.1027,
        0.0746, 0.0698, 0.0762, 0.0584], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:03,423][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ ring] are: tensor([0.0369, 0.0131, 0.0235, 0.0316, 0.0340, 0.0893, 0.0792, 0.0959, 0.1448,
        0.0590, 0.1036, 0.1275, 0.1615], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:03,424][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ ring] are: tensor([6.5040e-03, 7.3085e-04, 3.7221e-03, 6.0373e-03, 7.9858e-03, 2.3771e-02,
        1.8268e-02, 1.9073e-03, 2.2410e-02, 7.4121e-02, 3.5107e-02, 7.9011e-01,
        9.3313e-03], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:03,426][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ ring] are: tensor([9.0609e-05, 1.6673e-05, 9.3084e-05, 4.2739e-04, 1.7678e-03, 3.7363e-03,
        3.0366e-03, 1.0195e-04, 3.5383e-03, 1.7495e-02, 1.2111e-02, 9.5544e-01,
        2.1487e-03], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:03,427][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ ring] are: tensor([2.2450e-01, 1.7387e-02, 1.5349e-01, 3.2792e-02, 4.7147e-02, 2.3615e-01,
        4.9217e-03, 6.1638e-03, 6.9213e-02, 3.3331e-02, 1.6646e-01, 8.3853e-03,
        6.1461e-05], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:03,429][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ ring] are: tensor([0.0419, 0.0014, 0.0069, 0.0036, 0.0686, 0.1060, 0.0354, 0.0092, 0.0244,
        0.0309, 0.1893, 0.4370, 0.0455], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:03,430][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ ring] are: tensor([0.5960, 0.0058, 0.0091, 0.0089, 0.0216, 0.0258, 0.0318, 0.0143, 0.0329,
        0.0393, 0.0437, 0.1293, 0.0415], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:03,432][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ ring] are: tensor([0.0156, 0.0010, 0.0071, 0.0076, 0.0143, 0.0335, 0.0292, 0.0072, 0.0226,
        0.0461, 0.1107, 0.6449, 0.0603], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:03,434][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0993, 0.1045, 0.0677, 0.0803, 0.0800, 0.0660, 0.0677, 0.0579, 0.0521,
        0.0648, 0.0696, 0.0679, 0.0632, 0.0589], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:03,435][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0385, 0.0390, 0.0528, 0.0549, 0.0573, 0.0745, 0.0628, 0.0814, 0.0805,
        0.0788, 0.0970, 0.0879, 0.1007, 0.0939], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:03,437][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0035, 0.0971, 0.1105, 0.1792, 0.0748, 0.0521, 0.0666, 0.0742, 0.0372,
        0.0824, 0.0437, 0.0504, 0.0888, 0.0395], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:03,439][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([9.8162e-03, 3.0106e-06, 1.8222e-05, 3.2385e-05, 2.4525e-04, 2.0866e-04,
        4.5892e-04, 2.2926e-05, 3.2457e-04, 1.9665e-03, 1.5774e-03, 9.4953e-02,
        1.0534e-03, 8.8932e-01], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:03,440][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.1214, 0.0636, 0.0770, 0.0615, 0.0612, 0.0739, 0.0673, 0.0602, 0.0804,
        0.0633, 0.0647, 0.0697, 0.0628, 0.0732], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:03,441][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0291, 0.0110, 0.0125, 0.0243, 0.0232, 0.0629, 0.0482, 0.1096, 0.0852,
        0.0481, 0.0806, 0.0785, 0.2141, 0.1728], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:03,442][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.2643, 0.0016, 0.0026, 0.0043, 0.0036, 0.0047, 0.0069, 0.0015, 0.0089,
        0.0389, 0.0038, 0.1785, 0.0134, 0.4670], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:03,443][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([1.7655e-02, 3.0749e-05, 4.6383e-05, 1.5379e-04, 2.0471e-04, 4.2116e-04,
        1.2216e-03, 1.0403e-04, 1.1336e-03, 4.4584e-03, 3.4873e-03, 1.2920e-01,
        7.7387e-03, 8.3414e-01], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:03,445][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0219, 0.4165, 0.1101, 0.0450, 0.0083, 0.0023, 0.0512, 0.0520, 0.2114,
        0.0481, 0.0201, 0.0055, 0.0057, 0.0019], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:03,446][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.3663, 0.0029, 0.0050, 0.0069, 0.0146, 0.0047, 0.0132, 0.0041, 0.0143,
        0.0539, 0.0967, 0.1451, 0.0205, 0.2516], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:03,448][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.8679, 0.0018, 0.0012, 0.0020, 0.0021, 0.0059, 0.0050, 0.0010, 0.0047,
        0.0076, 0.0049, 0.0132, 0.0028, 0.0800], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:03,450][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.3635, 0.0012, 0.0048, 0.0041, 0.0071, 0.0055, 0.0172, 0.0018, 0.0143,
        0.0167, 0.0359, 0.2176, 0.0331, 0.2772], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:03,454][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:29:03,456][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[11956],
        [  264],
        [ 1706],
        [ 6609],
        [ 8761],
        [ 7474],
        [ 6249],
        [ 1549],
        [ 7615],
        [15219],
        [ 4288],
        [10748],
        [16364],
        [15300]], device='cuda:0')
[2024-07-24 10:29:03,457][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[12049],
        [  291],
        [ 2453],
        [11317],
        [21054],
        [12804],
        [11173],
        [ 5281],
        [11829],
        [21674],
        [ 7811],
        [13925],
        [21698],
        [24988]], device='cuda:0')
[2024-07-24 10:29:03,459][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[6478],
        [6252],
        [6224],
        [6159],
        [6198],
        [6277],
        [6185],
        [6237],
        [6280],
        [6270],
        [6330],
        [6350],
        [6345],
        [6354]], device='cuda:0')
[2024-07-24 10:29:03,461][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[30250],
        [14528],
        [16745],
        [17298],
        [17556],
        [17217],
        [18332],
        [17961],
        [18386],
        [17289],
        [17346],
        [15291],
        [14667],
        [14271]], device='cuda:0')
[2024-07-24 10:29:03,462][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[26709],
        [30440],
        [36484],
        [33140],
        [37340],
        [36866],
        [35401],
        [39015],
        [38268],
        [37370],
        [39141],
        [37576],
        [37626],
        [38316]], device='cuda:0')
[2024-07-24 10:29:03,464][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[23293],
        [19792],
        [19872],
        [19050],
        [19352],
        [18838],
        [18571],
        [18502],
        [18477],
        [18195],
        [18416],
        [18247],
        [17942],
        [17551]], device='cuda:0')
[2024-07-24 10:29:03,465][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[34487],
        [24308],
        [16114],
        [13312],
        [16161],
        [13931],
        [13798],
        [14489],
        [14571],
        [15252],
        [14475],
        [14225],
        [14002],
        [13281]], device='cuda:0')
[2024-07-24 10:29:03,467][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[15597],
        [13807],
        [13646],
        [13474],
        [13825],
        [14187],
        [14495],
        [14709],
        [14657],
        [14789],
        [14925],
        [15082],
        [15287],
        [15263]], device='cuda:0')
[2024-07-24 10:29:03,469][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[12532],
        [12789],
        [12136],
        [11956],
        [12292],
        [12357],
        [12520],
        [12780],
        [13012],
        [13205],
        [13500],
        [13718],
        [13947],
        [14092]], device='cuda:0')
[2024-07-24 10:29:03,470][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[10664],
        [11110],
        [11168],
        [10414],
        [ 9985],
        [10345],
        [ 9721],
        [ 9706],
        [ 9843],
        [ 9777],
        [ 9603],
        [ 9339],
        [ 9344],
        [ 9456]], device='cuda:0')
[2024-07-24 10:29:03,472][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[24644],
        [26020],
        [25962],
        [27098],
        [26193],
        [25378],
        [24696],
        [25088],
        [25775],
        [26974],
        [27242],
        [26882],
        [26629],
        [26396]], device='cuda:0')
[2024-07-24 10:29:03,473][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[40689],
        [40054],
        [39642],
        [40172],
        [39443],
        [39236],
        [40649],
        [41940],
        [41803],
        [42060],
        [42538],
        [42825],
        [43792],
        [43878]], device='cuda:0')
[2024-07-24 10:29:03,475][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[ 9492],
        [ 9320],
        [10602],
        [11540],
        [11587],
        [11460],
        [11500],
        [11444],
        [11591],
        [11674],
        [11586],
        [11705],
        [11751],
        [11649]], device='cuda:0')
[2024-07-24 10:29:03,476][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[13215],
        [ 3409],
        [ 2398],
        [ 4738],
        [ 4468],
        [ 5673],
        [ 6238],
        [ 5953],
        [ 5427],
        [ 6217],
        [ 6345],
        [ 5844],
        [ 5281],
        [ 6194]], device='cuda:0')
[2024-07-24 10:29:03,478][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[28726],
        [26989],
        [ 6489],
        [15877],
        [ 8259],
        [17430],
        [13826],
        [ 1584],
        [17471],
        [18504],
        [21485],
        [25432],
        [19998],
        [21037]], device='cuda:0')
[2024-07-24 10:29:03,479][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[40460],
        [40128],
        [41062],
        [41973],
        [42493],
        [42712],
        [43074],
        [43515],
        [43835],
        [44135],
        [44347],
        [44520],
        [44625],
        [44668]], device='cuda:0')
[2024-07-24 10:29:03,481][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[10652],
        [ 9491],
        [11282],
        [11648],
        [11505],
        [12310],
        [12467],
        [11890],
        [11939],
        [11844],
        [11690],
        [11648],
        [11389],
        [11367]], device='cuda:0')
[2024-07-24 10:29:03,482][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[15178],
        [22052],
        [23433],
        [15145],
        [15901],
        [14450],
        [14778],
        [15583],
        [15720],
        [15618],
        [15343],
        [15939],
        [16299],
        [16690]], device='cuda:0')
[2024-07-24 10:29:03,484][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[15826],
        [ 3849],
        [ 8541],
        [ 5569],
        [ 5866],
        [ 5261],
        [ 7841],
        [ 9023],
        [ 7836],
        [12925],
        [ 8142],
        [ 3834],
        [ 3998],
        [20049]], device='cuda:0')
[2024-07-24 10:29:03,486][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[25995],
        [26373],
        [25629],
        [27152],
        [27037],
        [25048],
        [25217],
        [25124],
        [23083],
        [23767],
        [22318],
        [21615],
        [21902],
        [21511]], device='cuda:0')
[2024-07-24 10:29:03,487][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[16501],
        [11230],
        [13406],
        [11920],
        [11290],
        [13009],
        [14285],
        [14052],
        [14752],
        [15121],
        [14180],
        [14745],
        [14563],
        [14563]], device='cuda:0')
[2024-07-24 10:29:03,489][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[33769],
        [32727],
        [29864],
        [22847],
        [14640],
        [21676],
        [23218],
        [19481],
        [21512],
        [21609],
        [19030],
        [22166],
        [17940],
        [18602]], device='cuda:0')
[2024-07-24 10:29:03,491][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[10228],
        [10476],
        [ 9195],
        [ 8088],
        [ 3869],
        [ 7010],
        [10916],
        [13862],
        [14846],
        [10813],
        [ 5821],
        [18602],
        [22413],
        [ 9479]], device='cuda:0')
[2024-07-24 10:29:03,492][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[21605],
        [21494],
        [ 3725],
        [11714],
        [11764],
        [ 5207],
        [ 4741],
        [12574],
        [ 6209],
        [15651],
        [18633],
        [14538],
        [16874],
        [12059]], device='cuda:0')
[2024-07-24 10:29:03,494][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[ 8822],
        [ 8125],
        [ 2744],
        [ 4842],
        [ 3400],
        [ 7552],
        [ 7801],
        [ 9155],
        [ 8759],
        [11634],
        [ 7100],
        [ 3380],
        [ 7278],
        [ 7223]], device='cuda:0')
[2024-07-24 10:29:03,495][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[21252],
        [24338],
        [24966],
        [36798],
        [33002],
        [27251],
        [30510],
        [34669],
        [31649],
        [35329],
        [33162],
        [29726],
        [29700],
        [25397]], device='cuda:0')
[2024-07-24 10:29:03,497][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 4934],
        [ 7092],
        [ 6594],
        [ 7192],
        [ 7736],
        [ 9166],
        [ 7859],
        [ 8495],
        [ 8614],
        [ 7739],
        [ 7998],
        [11253],
        [16872],
        [ 8801]], device='cuda:0')
[2024-07-24 10:29:03,499][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[26457],
        [28651],
        [31858],
        [30467],
        [35467],
        [32230],
        [30544],
        [27996],
        [29549],
        [25262],
        [30477],
        [29682],
        [26447],
        [27535]], device='cuda:0')
[2024-07-24 10:29:03,500][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[13691],
        [29079],
        [45665],
        [33213],
        [30482],
        [36469],
        [37095],
        [36899],
        [32257],
        [26997],
        [21323],
        [25349],
        [21792],
        [25680]], device='cuda:0')
[2024-07-24 10:29:03,502][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[30895],
        [30895],
        [30895],
        [30895],
        [30895],
        [30895],
        [30895],
        [30895],
        [30895],
        [30895],
        [30895],
        [30895],
        [30895],
        [30895]], device='cuda:0')
[2024-07-24 10:29:03,547][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:29:03,549][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:03,550][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:03,551][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:03,552][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:03,553][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:03,554][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:03,554][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:03,555][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:03,556][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:03,557][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:03,559][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:03,560][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:03,561][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Amanda] are: tensor([0.2455, 0.7545], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:03,563][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Amanda] are: tensor([0.4899, 0.5101], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:03,564][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Amanda] are: tensor([0.3299, 0.6701], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:03,566][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Amanda] are: tensor([0.3844, 0.6156], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:03,568][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Amanda] are: tensor([0.6571, 0.3429], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:03,569][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Amanda] are: tensor([0.0745, 0.9255], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:03,571][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Amanda] are: tensor([0.6362, 0.3638], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:03,572][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Amanda] are: tensor([0.3754, 0.6246], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:03,574][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Amanda] are: tensor([0.7006, 0.2994], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:03,576][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Amanda] are: tensor([0.3543, 0.6457], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:03,577][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Amanda] are: tensor([0.4946, 0.5054], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:03,578][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Amanda] are: tensor([3.1021e-06, 1.0000e+00], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:03,580][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.1324, 0.4653, 0.4023], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:03,581][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.2986, 0.3271, 0.3743], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:03,583][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.2728, 0.4097, 0.3176], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:03,584][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0598, 0.7325, 0.2077], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:03,585][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.4351, 0.2518, 0.3131], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:03,586][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0356, 0.4798, 0.4846], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:03,587][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.5077, 0.2621, 0.2302], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:03,588][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0388, 0.2666, 0.6946], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:03,589][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.3326, 0.4759, 0.1916], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:03,591][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.2782, 0.6005, 0.1213], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:03,592][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.3288, 0.3364, 0.3348], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:03,593][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ and] are: tensor([2.0112e-11, 9.9586e-01, 4.1359e-03], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:03,595][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ John] are: tensor([0.0523, 0.2556, 0.2783, 0.4137], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:03,596][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ John] are: tensor([0.2244, 0.2439, 0.2927, 0.2390], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:03,598][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ John] are: tensor([0.1766, 0.3588, 0.2599, 0.2047], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:03,600][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ John] are: tensor([0.0514, 0.4460, 0.1773, 0.3252], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:03,601][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ John] are: tensor([0.3393, 0.1859, 0.2381, 0.2367], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:03,603][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ John] are: tensor([0.0215, 0.3244, 0.3626, 0.2916], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:03,604][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ John] are: tensor([0.4145, 0.2098, 0.1943, 0.1814], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:03,606][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ John] are: tensor([0.0281, 0.1756, 0.4085, 0.3878], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:03,608][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ John] are: tensor([0.3624, 0.2068, 0.1275, 0.3033], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:03,609][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ John] are: tensor([0.1532, 0.6141, 0.1011, 0.1316], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:03,611][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ John] are: tensor([0.2480, 0.2539, 0.2539, 0.2443], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:03,612][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ John] are: tensor([2.4996e-10, 1.1444e-01, 8.8554e-01, 1.2448e-05], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:03,614][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ went] are: tensor([0.0455, 0.2118, 0.2241, 0.3240, 0.1947], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:03,615][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ went] are: tensor([0.1921, 0.1915, 0.2362, 0.1988, 0.1815], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:03,616][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ went] are: tensor([0.1448, 0.2710, 0.2466, 0.1769, 0.1606], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:03,617][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ went] are: tensor([0.0084, 0.3664, 0.0976, 0.2539, 0.2737], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:03,618][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ went] are: tensor([0.2853, 0.1507, 0.1958, 0.1924, 0.1757], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:03,618][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ went] are: tensor([0.0274, 0.2655, 0.2814, 0.2481, 0.1777], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:03,620][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ went] are: tensor([0.3723, 0.1749, 0.1603, 0.1483, 0.1442], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:03,622][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ went] are: tensor([0.0102, 0.0749, 0.2227, 0.1034, 0.5888], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:03,623][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.0873, 0.1633, 0.0934, 0.2478, 0.4082], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:03,625][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ went] are: tensor([0.1302, 0.3773, 0.0909, 0.1005, 0.3011], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:03,627][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ went] are: tensor([0.2006, 0.2046, 0.2058, 0.1960, 0.1930], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:03,628][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ went] are: tensor([4.5132e-10, 1.7354e-01, 7.6018e-01, 1.1165e-02, 5.5117e-02],
       device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:03,629][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0688, 0.1565, 0.1626, 0.2191, 0.1454, 0.2476], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:03,631][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.1434, 0.1576, 0.1850, 0.1720, 0.1597, 0.1823], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:03,632][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1207, 0.2160, 0.1898, 0.1635, 0.1578, 0.1523], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:03,634][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0097, 0.2617, 0.0616, 0.2049, 0.3530, 0.1091], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:03,636][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.2384, 0.1248, 0.1650, 0.1616, 0.1471, 0.1631], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:03,637][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0139, 0.2223, 0.2442, 0.2085, 0.1578, 0.1534], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:03,639][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.3231, 0.1486, 0.1350, 0.1276, 0.1329, 0.1328], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:03,641][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0070, 0.0504, 0.1369, 0.0487, 0.3298, 0.4273], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:03,642][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.2190, 0.1422, 0.0534, 0.1731, 0.2407, 0.1716], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:03,644][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.1218, 0.2325, 0.0423, 0.0975, 0.4546, 0.0512], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:03,646][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.1680, 0.1729, 0.1739, 0.1653, 0.1625, 0.1574], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:03,647][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ to] are: tensor([1.9759e-12, 2.0046e-01, 3.0761e-03, 1.1884e-02, 7.8447e-01, 1.1803e-04],
       device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:03,648][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0452, 0.1411, 0.1399, 0.1988, 0.1211, 0.2086, 0.1452],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:03,648][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.1232, 0.1345, 0.1592, 0.1391, 0.1375, 0.1601, 0.1464],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:03,649][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.1126, 0.1913, 0.1519, 0.1423, 0.1317, 0.1216, 0.1485],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:03,651][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0078, 0.2256, 0.0638, 0.1854, 0.2999, 0.1082, 0.1093],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:03,652][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.2079, 0.1092, 0.1424, 0.1402, 0.1266, 0.1394, 0.1343],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:03,654][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0089, 0.1865, 0.1939, 0.1579, 0.1325, 0.1407, 0.1796],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:03,655][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.2868, 0.1330, 0.1233, 0.1127, 0.1160, 0.1186, 0.1096],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:03,657][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0056, 0.0378, 0.1014, 0.0541, 0.3092, 0.3150, 0.1768],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:03,659][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.2051, 0.1428, 0.0557, 0.1565, 0.1649, 0.1414, 0.1337],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:03,660][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.1082, 0.2587, 0.0508, 0.0969, 0.3455, 0.0728, 0.0671],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:03,662][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.1449, 0.1491, 0.1497, 0.1429, 0.1401, 0.1358, 0.1375],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:03,663][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ the] are: tensor([1.8186e-10, 1.6319e-01, 3.0103e-02, 5.4301e-04, 7.9347e-01, 1.0956e-02,
        1.7469e-03], device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:03,665][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ station] are: tensor([0.0287, 0.1087, 0.1338, 0.1726, 0.1071, 0.2011, 0.1341, 0.1139],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:03,667][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ station] are: tensor([0.1138, 0.1128, 0.1408, 0.1176, 0.1174, 0.1429, 0.1367, 0.1179],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:03,668][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ station] are: tensor([0.0848, 0.1617, 0.1429, 0.1405, 0.1283, 0.1045, 0.1373, 0.1001],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:03,670][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ station] are: tensor([0.0208, 0.2115, 0.0481, 0.1705, 0.2121, 0.0772, 0.1092, 0.1507],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:03,672][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ station] are: tensor([0.1764, 0.0963, 0.1252, 0.1224, 0.1124, 0.1239, 0.1185, 0.1248],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:03,673][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ station] are: tensor([0.0130, 0.1584, 0.1574, 0.1408, 0.1144, 0.1159, 0.1446, 0.1555],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:03,675][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ station] are: tensor([0.2451, 0.1172, 0.1117, 0.1036, 0.1032, 0.1102, 0.1038, 0.1052],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:03,677][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ station] are: tensor([0.0024, 0.0320, 0.0900, 0.0772, 0.1979, 0.3897, 0.1469, 0.0638],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:03,678][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ station] are: tensor([0.1827, 0.0715, 0.0441, 0.1027, 0.1048, 0.1010, 0.1350, 0.2582],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:03,679][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ station] are: tensor([0.1091, 0.2371, 0.0398, 0.0950, 0.3384, 0.0468, 0.0765, 0.0573],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:03,680][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ station] are: tensor([0.1273, 0.1302, 0.1297, 0.1254, 0.1238, 0.1191, 0.1213, 0.1232],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:03,680][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ station] are: tensor([1.5277e-09, 8.9275e-02, 1.0272e-01, 3.8388e-03, 4.9641e-01, 3.7345e-02,
        2.5342e-01, 1.6993e-02], device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:03,681][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0445, 0.1053, 0.1050, 0.1498, 0.0908, 0.1451, 0.1120, 0.0914, 0.1561],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:03,683][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0981, 0.1027, 0.1203, 0.1082, 0.1046, 0.1221, 0.1189, 0.1078, 0.1174],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:03,684][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0975, 0.1467, 0.1212, 0.1156, 0.1164, 0.0908, 0.1103, 0.0991, 0.1024],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:03,686][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0037, 0.1327, 0.0373, 0.1262, 0.2370, 0.0785, 0.1100, 0.2297, 0.0449],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:03,688][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.1496, 0.0860, 0.1073, 0.1077, 0.1016, 0.1098, 0.1038, 0.1089, 0.1253],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:03,689][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0094, 0.1288, 0.1411, 0.1156, 0.0993, 0.1012, 0.1307, 0.1380, 0.1360],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:03,691][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.2262, 0.1058, 0.0960, 0.0914, 0.0970, 0.0997, 0.0944, 0.0960, 0.0936],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:03,693][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0023, 0.0286, 0.1011, 0.0355, 0.2794, 0.2613, 0.1260, 0.0435, 0.1223],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:03,695][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.1219, 0.0864, 0.0398, 0.0892, 0.1126, 0.1000, 0.0908, 0.2193, 0.1401],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:03,696][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.1451, 0.2260, 0.0337, 0.0561, 0.3334, 0.0456, 0.0616, 0.0744, 0.0242],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:03,698][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.1125, 0.1153, 0.1147, 0.1113, 0.1101, 0.1066, 0.1083, 0.1093, 0.1119],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:03,699][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [,] are: tensor([1.9433e-14, 4.0793e-02, 1.4559e-04, 1.1068e-03, 3.5014e-01, 3.0322e-04,
        1.9770e-02, 5.8773e-01, 1.5698e-05], device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:03,701][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ John] are: tensor([0.0210, 0.0655, 0.0841, 0.1156, 0.0740, 0.1332, 0.0928, 0.0929, 0.1451,
        0.1759], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:03,703][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ John] are: tensor([0.0860, 0.0930, 0.1136, 0.0918, 0.0929, 0.1139, 0.1079, 0.1029, 0.1096,
        0.0883], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:03,704][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ John] are: tensor([0.0750, 0.1537, 0.1140, 0.0895, 0.0985, 0.0887, 0.1007, 0.1066, 0.0957,
        0.0776], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:03,706][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ John] are: tensor([0.0119, 0.1452, 0.0447, 0.1077, 0.1932, 0.0791, 0.0801, 0.1578, 0.0424,
        0.1379], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:03,708][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ John] are: tensor([0.1430, 0.0750, 0.0994, 0.0966, 0.0873, 0.0970, 0.0921, 0.0969, 0.1167,
        0.0961], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:03,709][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ John] are: tensor([0.0064, 0.1124, 0.1244, 0.1008, 0.0873, 0.0921, 0.1214, 0.1333, 0.1274,
        0.0945], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:03,711][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ John] are: tensor([0.2043, 0.0962, 0.0901, 0.0825, 0.0850, 0.0884, 0.0825, 0.0862, 0.0858,
        0.0988], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:03,713][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ John] are: tensor([0.0066, 0.0346, 0.0768, 0.0628, 0.1627, 0.2443, 0.1638, 0.0392, 0.1081,
        0.1009], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:03,714][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ John] are: tensor([0.2136, 0.0648, 0.0318, 0.0820, 0.0793, 0.0724, 0.0794, 0.1535, 0.0920,
        0.1314], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:03,715][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ John] are: tensor([0.0817, 0.3229, 0.0488, 0.0733, 0.1907, 0.0476, 0.0786, 0.0759, 0.0366,
        0.0439], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:03,716][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ John] are: tensor([0.1018, 0.1045, 0.1045, 0.1007, 0.0989, 0.0953, 0.0971, 0.0984, 0.1009,
        0.0978], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:03,716][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ John] are: tensor([6.7522e-11, 5.4404e-02, 1.8597e-01, 5.2481e-06, 2.2191e-01, 2.7142e-02,
        1.0535e-01, 3.9296e-01, 1.2161e-02, 9.9923e-05], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:03,718][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.0193, 0.0652, 0.0826, 0.1066, 0.0692, 0.1264, 0.0886, 0.0787, 0.1287,
        0.1499, 0.0848], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:03,719][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0836, 0.0851, 0.1060, 0.0895, 0.0804, 0.1057, 0.0987, 0.0881, 0.1043,
        0.0860, 0.0727], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:03,721][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0784, 0.1087, 0.1077, 0.0919, 0.0711, 0.0937, 0.1182, 0.0913, 0.1011,
        0.0829, 0.0550], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:03,722][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.0018, 0.1236, 0.0348, 0.1182, 0.1501, 0.0619, 0.0544, 0.1349, 0.0313,
        0.1829, 0.1060], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:03,724][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.1333, 0.0686, 0.0910, 0.0881, 0.0805, 0.0893, 0.0851, 0.0898, 0.1072,
        0.0878, 0.0794], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:03,725][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.0098, 0.1117, 0.1174, 0.1005, 0.0704, 0.0831, 0.1117, 0.1145, 0.1159,
        0.0939, 0.0711], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:03,727][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.1972, 0.0892, 0.0841, 0.0761, 0.0761, 0.0799, 0.0747, 0.0757, 0.0767,
        0.0887, 0.0815], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:03,729][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0025, 0.0171, 0.1016, 0.0261, 0.2500, 0.1717, 0.0918, 0.0235, 0.1061,
        0.0420, 0.1676], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:03,730][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.0575, 0.0439, 0.0198, 0.0686, 0.0832, 0.0638, 0.0685, 0.2258, 0.1165,
        0.1340, 0.1185], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:03,732][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.0933, 0.1692, 0.0659, 0.0598, 0.2832, 0.0674, 0.0883, 0.0513, 0.0436,
        0.0370, 0.0410], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:03,734][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0930, 0.0954, 0.0956, 0.0918, 0.0900, 0.0866, 0.0881, 0.0894, 0.0919,
        0.0888, 0.0895], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:03,735][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([5.9589e-11, 5.7972e-02, 4.1728e-02, 1.6586e-03, 2.8011e-01, 2.8967e-02,
        1.0186e-01, 3.4442e-01, 6.9919e-03, 2.0911e-02, 1.1538e-01],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:03,737][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0197, 0.0588, 0.0683, 0.1007, 0.0632, 0.1131, 0.0767, 0.0692, 0.1184,
        0.1413, 0.0788, 0.0919], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:03,739][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0738, 0.0786, 0.0939, 0.0812, 0.0788, 0.0955, 0.0877, 0.0818, 0.0960,
        0.0785, 0.0713, 0.0830], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:03,740][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0735, 0.1149, 0.0970, 0.0919, 0.0744, 0.0773, 0.0964, 0.0751, 0.0851,
        0.0808, 0.0582, 0.0755], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:03,742][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0036, 0.1033, 0.0314, 0.0819, 0.1698, 0.0574, 0.0574, 0.1239, 0.0334,
        0.1157, 0.1500, 0.0721], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:03,744][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.1224, 0.0632, 0.0836, 0.0811, 0.0737, 0.0815, 0.0783, 0.0822, 0.0984,
        0.0809, 0.0725, 0.0822], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:03,746][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0064, 0.0963, 0.1002, 0.0897, 0.0686, 0.0756, 0.0977, 0.1123, 0.1050,
        0.0849, 0.0701, 0.0933], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:03,746][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.1773, 0.0823, 0.0762, 0.0702, 0.0722, 0.0734, 0.0691, 0.0719, 0.0705,
        0.0829, 0.0766, 0.0775], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:03,747][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0030, 0.0162, 0.0610, 0.0188, 0.1869, 0.1388, 0.0760, 0.0199, 0.0854,
        0.0331, 0.1143, 0.2467], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:03,748][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0995, 0.0622, 0.0251, 0.0770, 0.0822, 0.0701, 0.0670, 0.1669, 0.0876,
        0.1152, 0.0776, 0.0697], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:03,749][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0794, 0.2353, 0.0376, 0.0623, 0.2779, 0.0490, 0.0440, 0.0629, 0.0271,
        0.0391, 0.0645, 0.0211], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:03,751][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0850, 0.0872, 0.0874, 0.0841, 0.0825, 0.0797, 0.0809, 0.0821, 0.0843,
        0.0816, 0.0819, 0.0832], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:03,752][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ a] are: tensor([7.6002e-12, 1.9478e-02, 6.9714e-03, 8.1293e-05, 1.6837e-01, 3.5600e-03,
        8.3903e-04, 1.1952e-01, 8.9133e-04, 7.7546e-04, 6.7931e-01, 2.0486e-04],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:03,754][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ ring] are: tensor([0.0133, 0.0466, 0.0664, 0.0848, 0.0580, 0.1025, 0.0665, 0.0642, 0.1051,
        0.1228, 0.0711, 0.0780, 0.1208], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:03,755][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ ring] are: tensor([0.0675, 0.0724, 0.0887, 0.0735, 0.0733, 0.0906, 0.0866, 0.0740, 0.0896,
        0.0706, 0.0646, 0.0817, 0.0670], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:03,757][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ ring] are: tensor([0.0470, 0.1067, 0.0890, 0.0725, 0.0828, 0.0754, 0.0884, 0.0835, 0.0815,
        0.0671, 0.0673, 0.0798, 0.0589], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:03,759][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ ring] are: tensor([0.0116, 0.1326, 0.0352, 0.0902, 0.1397, 0.0452, 0.0532, 0.0987, 0.0276,
        0.1053, 0.1070, 0.0747, 0.0789], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:03,761][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ ring] are: tensor([0.1109, 0.0583, 0.0771, 0.0750, 0.0683, 0.0754, 0.0721, 0.0760, 0.0908,
        0.0748, 0.0670, 0.0752, 0.0790], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:03,762][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ ring] are: tensor([0.0111, 0.0843, 0.0965, 0.0782, 0.0644, 0.0696, 0.0881, 0.0927, 0.0944,
        0.0725, 0.0613, 0.0908, 0.0961], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:03,764][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ ring] are: tensor([0.1557, 0.0750, 0.0714, 0.0648, 0.0655, 0.0682, 0.0642, 0.0673, 0.0676,
        0.0767, 0.0701, 0.0722, 0.0813], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:03,766][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ ring] are: tensor([0.0019, 0.0162, 0.0511, 0.0285, 0.1192, 0.1317, 0.0613, 0.0278, 0.0860,
        0.0436, 0.1113, 0.1918, 0.1297], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:03,768][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ ring] are: tensor([0.1018, 0.0278, 0.0137, 0.0395, 0.0601, 0.0335, 0.0389, 0.1495, 0.0737,
        0.0822, 0.0870, 0.0540, 0.2383], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:03,769][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ ring] are: tensor([0.0614, 0.2183, 0.0290, 0.0524, 0.3292, 0.0322, 0.0540, 0.0500, 0.0205,
        0.0291, 0.0493, 0.0362, 0.0385], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:03,771][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ ring] are: tensor([0.0782, 0.0801, 0.0801, 0.0776, 0.0763, 0.0736, 0.0749, 0.0760, 0.0779,
        0.0754, 0.0757, 0.0768, 0.0775], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:03,773][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ ring] are: tensor([1.2252e-09, 1.7516e-02, 3.8242e-02, 8.7281e-04, 9.0751e-02, 1.7613e-02,
        9.0099e-02, 1.4683e-02, 2.9082e-03, 4.8547e-03, 6.4492e-01, 4.3845e-02,
        3.3693e-02], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:03,774][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0301, 0.0437, 0.0522, 0.0696, 0.0472, 0.0827, 0.0599, 0.0460, 0.0941,
        0.1031, 0.0579, 0.0709, 0.0935, 0.1492], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:03,776][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0606, 0.0663, 0.0789, 0.0735, 0.0673, 0.0778, 0.0781, 0.0705, 0.0800,
        0.0710, 0.0565, 0.0767, 0.0661, 0.0767], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:03,778][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0612, 0.0930, 0.0866, 0.0756, 0.0744, 0.0683, 0.0823, 0.0686, 0.0787,
        0.0671, 0.0566, 0.0693, 0.0546, 0.0635], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:03,778][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0041, 0.0830, 0.0209, 0.0616, 0.1221, 0.0392, 0.0503, 0.0985, 0.0293,
        0.1051, 0.1193, 0.0833, 0.1071, 0.0763], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:03,779][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.1037, 0.0529, 0.0710, 0.0687, 0.0628, 0.0702, 0.0665, 0.0697, 0.0844,
        0.0687, 0.0613, 0.0692, 0.0725, 0.0785], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:03,780][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0054, 0.0809, 0.0897, 0.0760, 0.0586, 0.0558, 0.0848, 0.0915, 0.0880,
        0.0706, 0.0582, 0.0885, 0.0985, 0.0535], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:03,782][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1386, 0.0675, 0.0651, 0.0609, 0.0635, 0.0653, 0.0630, 0.0634, 0.0641,
        0.0719, 0.0691, 0.0692, 0.0757, 0.0627], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:03,783][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0045, 0.0158, 0.0392, 0.0137, 0.0819, 0.1004, 0.0501, 0.0158, 0.0511,
        0.0234, 0.0733, 0.1768, 0.0771, 0.2769], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:03,785][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.1323, 0.0443, 0.0165, 0.0572, 0.0745, 0.0532, 0.0432, 0.1126, 0.0460,
        0.0808, 0.0589, 0.0486, 0.1668, 0.0650], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:03,787][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0677, 0.1612, 0.0245, 0.0627, 0.2769, 0.0300, 0.0442, 0.0840, 0.0198,
        0.0438, 0.0484, 0.0331, 0.0883, 0.0156], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:03,788][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0721, 0.0742, 0.0742, 0.0720, 0.0709, 0.0684, 0.0695, 0.0704, 0.0721,
        0.0700, 0.0703, 0.0714, 0.0718, 0.0727], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:03,790][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ to] are: tensor([5.1611e-13, 1.6459e-02, 3.0164e-04, 5.5846e-04, 5.7000e-02, 2.0772e-05,
        5.0401e-03, 4.3803e-02, 1.6592e-04, 5.5409e-03, 1.0810e-01, 3.5632e-03,
        7.5894e-01, 5.1023e-04], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:03,843][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:29:03,845][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:03,846][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:03,846][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:03,847][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:03,848][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:03,848][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:03,850][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:03,851][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:03,852][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:03,854][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:03,855][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:03,856][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:03,858][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Amanda] are: tensor([0.0642, 0.9358], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:03,859][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Amanda] are: tensor([0.8799, 0.1201], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:03,861][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Amanda] are: tensor([0.7675, 0.2325], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:03,862][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Amanda] are: tensor([0.5376, 0.4624], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:03,864][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Amanda] are: tensor([0.2311, 0.7689], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:03,866][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Amanda] are: tensor([0.7312, 0.2688], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:03,867][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Amanda] are: tensor([0.3302, 0.6698], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:03,869][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Amanda] are: tensor([0.6612, 0.3388], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:03,871][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Amanda] are: tensor([0.5124, 0.4876], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:03,872][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Amanda] are: tensor([0.2936, 0.7064], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:03,874][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Amanda] are: tensor([0.1903, 0.8097], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:03,875][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Amanda] are: tensor([1.0000e+00, 2.7291e-09], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:03,876][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0246, 0.5640, 0.4114], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:03,877][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0827, 0.8664, 0.0510], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:03,877][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.6104, 0.2466, 0.1430], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:03,878][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.1328, 0.6748, 0.1924], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:03,879][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.1106, 0.6016, 0.2878], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:03,881][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.4263, 0.3350, 0.2387], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:03,882][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.1999, 0.4016, 0.3985], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:03,884][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0163, 0.0035, 0.9802], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:03,885][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.3485, 0.3718, 0.2797], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:03,886][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.1904, 0.4205, 0.3890], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:03,887][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.1027, 0.3962, 0.5011], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:03,888][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([2.0117e-01, 7.9883e-01, 1.8699e-10], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:03,888][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ John] are: tensor([0.0257, 0.3740, 0.3119, 0.2885], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:03,889][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ John] are: tensor([0.5654, 0.2759, 0.0993, 0.0594], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:03,891][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ John] are: tensor([0.4370, 0.2612, 0.1259, 0.1758], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:03,893][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ John] are: tensor([0.2332, 0.3142, 0.2555, 0.1971], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:03,894][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ John] are: tensor([0.0977, 0.3958, 0.2038, 0.3027], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:03,896][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ John] are: tensor([0.2669, 0.2407, 0.4004, 0.0921], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:03,897][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ John] are: tensor([0.1378, 0.2936, 0.2913, 0.2773], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:03,899][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ John] are: tensor([0.0747, 0.0601, 0.7493, 0.1159], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:03,901][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ John] are: tensor([0.2586, 0.2594, 0.2195, 0.2625], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:03,902][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ John] are: tensor([0.1286, 0.3049, 0.2863, 0.2802], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:03,904][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ John] are: tensor([0.0749, 0.2821, 0.3647, 0.2784], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:03,905][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ John] are: tensor([4.9698e-01, 1.5764e-03, 5.0144e-01, 2.6836e-11], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:03,907][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([0.0181, 0.2728, 0.2472, 0.2142, 0.2477], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:03,908][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([0.5253, 0.1236, 0.1832, 0.1552, 0.0127], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:03,910][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([0.5049, 0.1321, 0.0934, 0.1216, 0.1480], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:03,911][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([0.0186, 0.3491, 0.1613, 0.2419, 0.2291], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:03,911][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([0.0807, 0.3144, 0.1576, 0.2263, 0.2210], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:03,912][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([0.1288, 0.2834, 0.3587, 0.1789, 0.0501], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:03,913][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([0.1042, 0.2316, 0.2293, 0.2181, 0.2169], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:03,915][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([0.0146, 0.0065, 0.3231, 0.0163, 0.6395], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:03,916][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([0.1975, 0.2056, 0.1754, 0.2086, 0.2129], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:03,918][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([0.1053, 0.2368, 0.2279, 0.2224, 0.2075], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:03,919][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([0.0581, 0.1946, 0.2555, 0.1821, 0.3097], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:03,921][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([7.6793e-01, 2.2088e-03, 2.2752e-01, 2.2855e-03, 5.5134e-05],
       device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:03,922][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0088, 0.2442, 0.1721, 0.1782, 0.2265, 0.1702], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:03,924][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0913, 0.1966, 0.0187, 0.6213, 0.0601, 0.0121], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:03,926][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.3209, 0.1078, 0.0818, 0.1359, 0.2083, 0.1453], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:03,927][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0517, 0.2756, 0.0947, 0.1527, 0.3493, 0.0760], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:03,929][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0609, 0.2605, 0.1285, 0.1881, 0.1827, 0.1794], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:03,930][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.1955, 0.2330, 0.1989, 0.1077, 0.1319, 0.1330], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:03,932][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0844, 0.1896, 0.1879, 0.1796, 0.1797, 0.1789], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:03,934][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0076, 0.0014, 0.2561, 0.0007, 0.0784, 0.6558], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:03,935][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.1620, 0.1712, 0.1452, 0.1727, 0.1761, 0.1728], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:03,937][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0778, 0.1923, 0.1833, 0.1802, 0.1726, 0.1937], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:03,939][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0417, 0.1408, 0.1784, 0.1375, 0.2131, 0.2885], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:03,940][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([3.3792e-04, 7.7786e-03, 2.8825e-10, 6.8223e-03, 9.8506e-01, 2.1755e-14],
       device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:03,941][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0079, 0.2025, 0.1515, 0.1436, 0.1786, 0.1625, 0.1535],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:03,942][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.1514, 0.2163, 0.0745, 0.1962, 0.1925, 0.1641, 0.0050],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:03,943][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.2841, 0.1296, 0.0676, 0.1353, 0.1900, 0.1147, 0.0787],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:03,944][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0481, 0.2464, 0.1140, 0.1562, 0.2690, 0.0842, 0.0821],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:03,945][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0525, 0.2077, 0.1103, 0.1568, 0.1476, 0.1499, 0.1751],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:03,946][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.1551, 0.1410, 0.1884, 0.0698, 0.0649, 0.2904, 0.0903],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:03,947][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0730, 0.1613, 0.1598, 0.1525, 0.1528, 0.1525, 0.1482],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:03,949][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0035, 0.0034, 0.0434, 0.0060, 0.1375, 0.2472, 0.5590],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:03,951][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.1413, 0.1448, 0.1244, 0.1466, 0.1488, 0.1467, 0.1474],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:03,952][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0656, 0.1608, 0.1548, 0.1519, 0.1424, 0.1633, 0.1612],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:03,954][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0378, 0.1226, 0.1433, 0.1057, 0.1703, 0.2205, 0.1998],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:03,955][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([2.6911e-02, 4.6505e-03, 2.5569e-05, 2.8772e-07, 9.6799e-01, 4.2453e-04,
        2.3718e-10], device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:03,957][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ station] are: tensor([0.0100, 0.1620, 0.1292, 0.1282, 0.1430, 0.1367, 0.1319, 0.1589],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:03,958][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ station] are: tensor([0.0458, 0.0484, 0.1874, 0.0439, 0.0743, 0.3220, 0.2588, 0.0194],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:03,960][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ station] are: tensor([0.1941, 0.0988, 0.0654, 0.1457, 0.1843, 0.0910, 0.0749, 0.1458],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:03,962][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ station] are: tensor([0.0301, 0.2574, 0.0652, 0.1937, 0.2156, 0.0609, 0.1368, 0.0402],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:03,964][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ station] are: tensor([0.0477, 0.1770, 0.0953, 0.1307, 0.1219, 0.1258, 0.1452, 0.1564],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:03,965][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ station] are: tensor([0.0850, 0.1229, 0.1179, 0.0616, 0.0475, 0.3665, 0.1678, 0.0308],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:03,967][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ station] are: tensor([0.0665, 0.1386, 0.1377, 0.1315, 0.1319, 0.1322, 0.1286, 0.1329],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:03,969][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ station] are: tensor([0.0028, 0.0014, 0.1905, 0.0026, 0.0574, 0.4243, 0.2897, 0.0313],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:03,971][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ station] are: tensor([0.1230, 0.1238, 0.1076, 0.1273, 0.1288, 0.1282, 0.1294, 0.1319],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:03,972][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ station] are: tensor([0.0579, 0.1393, 0.1308, 0.1305, 0.1240, 0.1394, 0.1432, 0.1349],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:03,973][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ station] are: tensor([0.0296, 0.0942, 0.1236, 0.0943, 0.1377, 0.1853, 0.1680, 0.1672],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:03,974][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ station] are: tensor([8.3144e-02, 4.2217e-04, 9.3143e-03, 2.0466e-04, 4.0675e-01, 6.5185e-03,
        4.9365e-01, 9.0129e-09], device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:03,975][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0066, 0.1478, 0.1053, 0.1104, 0.1315, 0.1102, 0.1189, 0.1503, 0.1190],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:03,976][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.2411, 0.0714, 0.0168, 0.1998, 0.1059, 0.0873, 0.1625, 0.0982, 0.0170],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:03,977][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.1814, 0.0930, 0.0584, 0.1088, 0.1757, 0.0933, 0.0583, 0.1473, 0.0837],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:03,978][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0113, 0.1442, 0.0474, 0.1059, 0.3307, 0.0533, 0.1074, 0.1508, 0.0491],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:03,980][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0304, 0.1777, 0.0810, 0.1218, 0.1178, 0.1087, 0.1304, 0.1467, 0.0856],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:03,982][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0600, 0.0865, 0.1913, 0.0543, 0.0799, 0.2627, 0.1502, 0.0651, 0.0500],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:03,983][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0571, 0.1238, 0.1226, 0.1171, 0.1174, 0.1169, 0.1138, 0.1182, 0.1130],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:03,985][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0030, 0.0010, 0.3220, 0.0005, 0.0332, 0.3080, 0.0744, 0.0081, 0.2498],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:03,986][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.1175, 0.1282, 0.0943, 0.1186, 0.1193, 0.1117, 0.1116, 0.1127, 0.0860],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:03,988][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0531, 0.1227, 0.1145, 0.1118, 0.1078, 0.1220, 0.1223, 0.1174, 0.1284],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:03,990][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0285, 0.0928, 0.1049, 0.0792, 0.1208, 0.1523, 0.1410, 0.1298, 0.1507],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:03,991][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([5.0205e-06, 9.1069e-05, 1.7238e-13, 4.0935e-05, 6.6286e-02, 3.0773e-11,
        1.4198e-05, 9.3356e-01, 2.8959e-15], device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:03,993][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ John] are: tensor([0.0076, 0.1241, 0.1003, 0.0964, 0.1057, 0.1064, 0.1071, 0.1368, 0.1149,
        0.1007], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:03,994][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ John] are: tensor([0.1720, 0.0665, 0.0733, 0.0172, 0.0545, 0.2328, 0.0573, 0.2515, 0.0568,
        0.0181], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:03,996][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ John] are: tensor([0.2042, 0.1216, 0.0559, 0.0725, 0.1315, 0.0669, 0.0494, 0.1670, 0.0640,
        0.0669], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:03,998][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ John] are: tensor([0.1379, 0.1167, 0.0734, 0.0672, 0.1954, 0.0835, 0.0780, 0.0651, 0.0615,
        0.1213], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:03,999][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ John] are: tensor([0.0362, 0.1467, 0.0743, 0.1113, 0.1019, 0.1004, 0.1173, 0.1259, 0.0793,
        0.1066], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:04,001][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ John] are: tensor([0.1496, 0.0733, 0.1500, 0.0287, 0.0339, 0.2414, 0.1450, 0.0594, 0.0588,
        0.0599], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:04,003][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ John] are: tensor([0.0510, 0.1109, 0.1104, 0.1049, 0.1050, 0.1053, 0.1025, 0.1064, 0.1021,
        0.1014], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:04,005][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ John] are: tensor([0.0050, 0.0041, 0.0341, 0.0075, 0.0379, 0.1945, 0.6378, 0.0348, 0.0308,
        0.0137], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:04,006][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ John] are: tensor([0.1011, 0.1024, 0.0857, 0.1029, 0.1048, 0.1022, 0.1032, 0.1054, 0.0859,
        0.1064], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:04,006][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ John] are: tensor([0.0451, 0.1097, 0.1047, 0.1014, 0.0928, 0.1079, 0.1113, 0.1057, 0.1177,
        0.1036], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:04,007][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ John] are: tensor([0.0248, 0.0812, 0.1005, 0.0737, 0.1062, 0.1370, 0.1261, 0.1104, 0.1323,
        0.1077], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:04,008][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ John] are: tensor([3.9831e-01, 6.9241e-04, 2.7590e-01, 7.6413e-12, 4.4174e-02, 2.2108e-02,
        5.3992e-02, 2.0242e-01, 2.4024e-03, 1.1302e-09], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:04,010][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.0055, 0.1120, 0.0933, 0.0871, 0.1020, 0.0971, 0.0986, 0.1243, 0.1060,
        0.0901, 0.0837], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:04,011][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.1115, 0.0422, 0.1642, 0.0907, 0.0046, 0.1210, 0.0404, 0.0204, 0.2748,
        0.0727, 0.0572], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:04,013][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.2386, 0.0638, 0.0442, 0.0745, 0.0750, 0.0807, 0.0690, 0.1388, 0.0705,
        0.0917, 0.0531], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:04,014][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.0091, 0.1366, 0.0493, 0.1112, 0.1001, 0.0481, 0.0394, 0.0692, 0.0447,
        0.3137, 0.0787], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:04,016][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.0317, 0.1303, 0.0698, 0.0972, 0.0906, 0.0873, 0.1053, 0.1120, 0.0732,
        0.0943, 0.1084], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:04,018][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.0613, 0.0686, 0.1408, 0.0592, 0.0203, 0.1576, 0.1186, 0.0349, 0.1192,
        0.1855, 0.0341], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:04,019][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.0454, 0.1003, 0.0997, 0.0952, 0.0949, 0.0953, 0.0930, 0.0964, 0.0924,
        0.0920, 0.0953], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:04,021][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0074, 0.0013, 0.1874, 0.0018, 0.0863, 0.2323, 0.1024, 0.0162, 0.1958,
        0.0033, 0.1659], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:04,023][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.0914, 0.0913, 0.0786, 0.0921, 0.0942, 0.0918, 0.0934, 0.0963, 0.0805,
        0.0967, 0.0938], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:04,025][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.0437, 0.0950, 0.0959, 0.0900, 0.0856, 0.0993, 0.1013, 0.0918, 0.1069,
        0.0920, 0.0986], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:04,026][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0203, 0.0667, 0.0815, 0.0613, 0.0988, 0.1308, 0.1071, 0.1084, 0.1220,
        0.0945, 0.1086], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:04,028][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([3.9279e-02, 9.3534e-04, 3.0273e-03, 3.5029e-04, 1.2581e-01, 6.8929e-02,
        1.3071e-01, 5.5727e-01, 7.9371e-04, 7.2855e-02, 3.5490e-05],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:04,029][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0053, 0.1099, 0.0812, 0.0780, 0.0935, 0.0858, 0.0856, 0.1138, 0.0940,
        0.0810, 0.0878, 0.0839], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:04,031][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0614, 0.0384, 0.0190, 0.0609, 0.0316, 0.0703, 0.0055, 0.0259, 0.2072,
        0.0596, 0.4163, 0.0039], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:04,033][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.1559, 0.0790, 0.0437, 0.0830, 0.0893, 0.0646, 0.0513, 0.1299, 0.0692,
        0.1035, 0.0862, 0.0444], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:04,035][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0308, 0.0839, 0.0492, 0.0474, 0.1551, 0.0470, 0.0384, 0.0392, 0.0516,
        0.1008, 0.1640, 0.1927], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:04,036][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0313, 0.1202, 0.0633, 0.0853, 0.0803, 0.0812, 0.0928, 0.1006, 0.0649,
        0.0796, 0.0899, 0.1106], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:04,037][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.2024, 0.0608, 0.0854, 0.0336, 0.0167, 0.1264, 0.0806, 0.0400, 0.0714,
        0.1072, 0.0366, 0.1388], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:04,038][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0417, 0.0914, 0.0909, 0.0869, 0.0869, 0.0867, 0.0847, 0.0879, 0.0842,
        0.0841, 0.0871, 0.0876], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:04,039][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0026, 0.0013, 0.0701, 0.0014, 0.0584, 0.1372, 0.3356, 0.0218, 0.1421,
        0.0028, 0.1067, 0.1199], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:04,040][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0825, 0.0824, 0.0730, 0.0841, 0.0853, 0.0844, 0.0856, 0.0873, 0.0742,
        0.0876, 0.0844, 0.0893], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:04,041][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0376, 0.0896, 0.0860, 0.0835, 0.0780, 0.0897, 0.0892, 0.0855, 0.0960,
        0.0849, 0.0924, 0.0875], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:04,043][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0201, 0.0672, 0.0737, 0.0565, 0.0866, 0.1106, 0.1001, 0.0951, 0.1082,
        0.0856, 0.0937, 0.1025], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:04,044][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([4.1274e-04, 3.3009e-05, 5.0431e-06, 2.3159e-08, 4.3662e-02, 5.7487e-05,
        2.4236e-09, 7.3085e-01, 6.0550e-06, 1.2031e-05, 2.2496e-01, 1.5565e-11],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:04,046][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ ring] are: tensor([0.0071, 0.0960, 0.0745, 0.0725, 0.0849, 0.0792, 0.0779, 0.0978, 0.0836,
        0.0749, 0.0757, 0.0803, 0.0958], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:04,048][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ ring] are: tensor([0.0096, 0.0327, 0.0956, 0.0128, 0.0167, 0.1902, 0.1004, 0.0066, 0.3769,
        0.0090, 0.1275, 0.0209, 0.0012], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:04,049][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ ring] are: tensor([0.1991, 0.0952, 0.0397, 0.0541, 0.1060, 0.0541, 0.0389, 0.1008, 0.0454,
        0.0529, 0.0950, 0.0329, 0.0858], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:04,051][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ ring] are: tensor([0.0175, 0.1026, 0.0495, 0.0545, 0.1059, 0.0328, 0.0379, 0.0274, 0.0395,
        0.1106, 0.1066, 0.2871, 0.0281], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:04,053][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ ring] are: tensor([0.0314, 0.1066, 0.0568, 0.0778, 0.0724, 0.0745, 0.0841, 0.0919, 0.0589,
        0.0723, 0.0801, 0.0986, 0.0945], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:04,054][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ ring] are: tensor([0.0340, 0.0576, 0.0760, 0.0287, 0.0196, 0.0835, 0.0661, 0.0173, 0.0388,
        0.0612, 0.0402, 0.4285, 0.0485], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:04,056][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ ring] are: tensor([0.0387, 0.0839, 0.0836, 0.0799, 0.0801, 0.0801, 0.0781, 0.0809, 0.0776,
        0.0774, 0.0802, 0.0808, 0.0788], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:04,058][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ ring] are: tensor([0.0028, 0.0016, 0.0720, 0.0020, 0.0659, 0.3405, 0.1136, 0.0473, 0.2097,
        0.0033, 0.0711, 0.0455, 0.0246], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:04,060][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ ring] are: tensor([0.0744, 0.0719, 0.0659, 0.0751, 0.0764, 0.0776, 0.0785, 0.0814, 0.0709,
        0.0818, 0.0789, 0.0829, 0.0842], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:04,062][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ ring] are: tensor([0.0347, 0.0821, 0.0774, 0.0747, 0.0726, 0.0816, 0.0833, 0.0784, 0.0877,
        0.0766, 0.0844, 0.0831, 0.0833], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:04,063][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ ring] are: tensor([0.0166, 0.0551, 0.0674, 0.0520, 0.0762, 0.1003, 0.0863, 0.0891, 0.0970,
        0.0813, 0.0815, 0.0911, 0.1061], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:04,064][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ ring] are: tensor([2.1908e-03, 7.0195e-06, 9.1985e-03, 1.0013e-05, 5.0944e-03, 8.7521e-02,
        6.4509e-01, 3.3403e-06, 2.5126e-05, 6.7847e-04, 2.2961e-01, 2.0572e-02,
        1.6254e-08], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:04,066][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0034, 0.0921, 0.0636, 0.0685, 0.0842, 0.0619, 0.0754, 0.0948, 0.0752,
        0.0722, 0.0736, 0.0782, 0.0947, 0.0622], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:04,068][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0391, 0.0376, 0.0150, 0.3150, 0.0303, 0.0101, 0.0381, 0.0253, 0.0969,
        0.2100, 0.0730, 0.0821, 0.0079, 0.0198], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:04,069][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1596, 0.0543, 0.0374, 0.0624, 0.0994, 0.0722, 0.0358, 0.0956, 0.0549,
        0.0695, 0.0642, 0.0351, 0.1104, 0.0491], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:04,070][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0794, 0.0645, 0.0246, 0.0255, 0.0682, 0.0194, 0.0289, 0.0177, 0.0362,
        0.0659, 0.0831, 0.2387, 0.0461, 0.2018], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:04,071][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0249, 0.0930, 0.0507, 0.0709, 0.0672, 0.0677, 0.0788, 0.0858, 0.0545,
        0.0677, 0.0754, 0.0887, 0.0847, 0.0900], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:04,073][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.2577, 0.0472, 0.0535, 0.0167, 0.0150, 0.0165, 0.0358, 0.0099, 0.0486,
        0.0501, 0.0286, 0.1750, 0.0741, 0.1714], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:04,074][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0354, 0.0777, 0.0773, 0.0741, 0.0741, 0.0739, 0.0721, 0.0751, 0.0718,
        0.0717, 0.0745, 0.0747, 0.0734, 0.0741], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:04,075][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([4.0947e-03, 8.3336e-04, 8.3315e-02, 3.5373e-04, 3.5514e-02, 2.0922e-01,
        4.0429e-02, 5.0557e-03, 3.8518e-02, 6.3228e-04, 5.5118e-02, 2.5715e-02,
        1.5054e-02, 4.8615e-01], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:04,077][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0709, 0.0720, 0.0629, 0.0724, 0.0731, 0.0722, 0.0723, 0.0732, 0.0611,
        0.0730, 0.0703, 0.0746, 0.0761, 0.0758], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:04,079][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0310, 0.0750, 0.0723, 0.0705, 0.0660, 0.0751, 0.0759, 0.0728, 0.0805,
        0.0715, 0.0772, 0.0758, 0.0774, 0.0790], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:04,081][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0166, 0.0513, 0.0568, 0.0449, 0.0695, 0.0901, 0.0770, 0.0772, 0.0851,
        0.0671, 0.0751, 0.0790, 0.0859, 0.1244], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:04,082][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([1.0722e-07, 2.3042e-06, 1.3124e-13, 1.8641e-06, 1.9889e-04, 6.1592e-18,
        9.4831e-08, 8.6075e-04, 5.1065e-12, 7.4062e-04, 5.1075e-06, 1.0125e-08,
        9.9819e-01, 1.0169e-15], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:04,085][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:29:04,087][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[10597],
        [21028],
        [ 8327],
        [19906],
        [ 7141],
        [13505],
        [17335],
        [ 2067],
        [ 9753],
        [19110],
        [ 6659],
        [18045],
        [27450],
        [14826]], device='cuda:0')
[2024-07-24 10:29:04,089][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[11311],
        [20689],
        [ 9704],
        [21187],
        [ 6447],
        [16005],
        [15110],
        [ 1160],
        [10215],
        [24690],
        [ 5710],
        [20885],
        [31298],
        [21500]], device='cuda:0')
[2024-07-24 10:29:04,091][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[16389],
        [23203],
        [20266],
        [22011],
        [21878],
        [20582],
        [20362],
        [20942],
        [20726],
        [22079],
        [21997],
        [22057],
        [21976],
        [21306]], device='cuda:0')
[2024-07-24 10:29:04,093][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[32198],
        [28122],
        [28396],
        [28346],
        [25638],
        [26128],
        [25838],
        [26265],
        [26564],
        [26707],
        [27194],
        [26943],
        [26829],
        [27005]], device='cuda:0')
[2024-07-24 10:29:04,094][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[16177],
        [ 3835],
        [ 7969],
        [ 4577],
        [ 6245],
        [ 6980],
        [ 9982],
        [10231],
        [11205],
        [ 9365],
        [10720],
        [10174],
        [10209],
        [10162]], device='cuda:0')
[2024-07-24 10:29:04,096][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[ 8175],
        [33618],
        [29137],
        [19603],
        [15943],
        [12566],
        [11126],
        [11869],
        [10073],
        [10813],
        [11332],
        [10607],
        [11102],
        [ 9914]], device='cuda:0')
[2024-07-24 10:29:04,097][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[29949],
        [27905],
        [28957],
        [28921],
        [28117],
        [26189],
        [25437],
        [24998],
        [24616],
        [24349],
        [23977],
        [23814],
        [23850],
        [23243]], device='cuda:0')
[2024-07-24 10:29:04,099][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[21852],
        [16707],
        [21351],
        [22919],
        [23992],
        [24063],
        [21834],
        [22177],
        [22250],
        [22475],
        [22454],
        [23055],
        [24280],
        [24348]], device='cuda:0')
[2024-07-24 10:29:04,101][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[28976],
        [35273],
        [37898],
        [38507],
        [38468],
        [38172],
        [38442],
        [38419],
        [38886],
        [39134],
        [39446],
        [39712],
        [40009],
        [39911]], device='cuda:0')
[2024-07-24 10:29:04,102][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[453],
        [242],
        [305],
        [337],
        [534],
        [687],
        [714],
        [744],
        [746],
        [762],
        [750],
        [747],
        [731],
        [872]], device='cuda:0')
[2024-07-24 10:29:04,103][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[22854],
        [23304],
        [26188],
        [27584],
        [35224],
        [34389],
        [34395],
        [36342],
        [36116],
        [33573],
        [35748],
        [35647],
        [38096],
        [37826]], device='cuda:0')
[2024-07-24 10:29:04,105][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[13013],
        [ 7520],
        [ 8838],
        [ 8982],
        [ 9991],
        [10778],
        [10844],
        [10513],
        [10384],
        [ 9985],
        [10645],
        [ 9351],
        [ 9506],
        [ 9660]], device='cuda:0')
[2024-07-24 10:29:04,106][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[14648],
        [13959],
        [13666],
        [13755],
        [14082],
        [13737],
        [13689],
        [13990],
        [14012],
        [14054],
        [14156],
        [14209],
        [14325],
        [14200]], device='cuda:0')
[2024-07-24 10:29:04,108][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[ 8204],
        [23673],
        [23593],
        [ 6324],
        [ 6984],
        [ 5583],
        [ 5032],
        [ 3884],
        [ 7701],
        [ 6544],
        [ 7273],
        [10536],
        [ 9375],
        [10665]], device='cuda:0')
[2024-07-24 10:29:04,109][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[22587],
        [48394],
        [43558],
        [47308],
        [41021],
        [36047],
        [40139],
        [36898],
        [37956],
        [43833],
        [39645],
        [26471],
        [32508],
        [25692]], device='cuda:0')
[2024-07-24 10:29:04,111][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[32449],
        [33686],
        [32169],
        [32113],
        [30850],
        [31511],
        [31181],
        [31089],
        [30952],
        [31057],
        [30748],
        [30769],
        [31210],
        [31372]], device='cuda:0')
[2024-07-24 10:29:04,112][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[22679],
        [16013],
        [ 8805],
        [ 7662],
        [17894],
        [ 8172],
        [22232],
        [27891],
        [21225],
        [30169],
        [25397],
        [18317],
        [23085],
        [16496]], device='cuda:0')
[2024-07-24 10:29:04,114][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[5189],
        [4141],
        [3706],
        [3749],
        [5953],
        [6481],
        [6615],
        [8026],
        [7519],
        [7162],
        [6585],
        [6690],
        [6952],
        [6849]], device='cuda:0')
[2024-07-24 10:29:04,116][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[1906],
        [3633],
        [4044],
        [4416],
        [3125],
        [2455],
        [2557],
        [2346],
        [1135],
        [1698],
        [2433],
        [1577],
        [1775],
        [1612]], device='cuda:0')
[2024-07-24 10:29:04,117][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[45003],
        [47035],
        [45936],
        [44722],
        [44729],
        [44154],
        [43524],
        [43584],
        [42880],
        [42255],
        [41982],
        [41139],
        [40460],
        [40298]], device='cuda:0')
[2024-07-24 10:29:04,119][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[ 8584],
        [10328],
        [ 9443],
        [ 9835],
        [10502],
        [11579],
        [11603],
        [12223],
        [10844],
        [ 9926],
        [ 9821],
        [15648],
        [33813],
        [19001]], device='cuda:0')
[2024-07-24 10:29:04,121][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[24442],
        [23305],
        [22507],
        [21831],
        [21386],
        [20835],
        [20651],
        [20458],
        [20336],
        [20249],
        [20015],
        [20029],
        [20006],
        [19928]], device='cuda:0')
[2024-07-24 10:29:04,123][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[33677],
        [ 7796],
        [ 1089],
        [  670],
        [  482],
        [ 1201],
        [  650],
        [  895],
        [  624],
        [  698],
        [  391],
        [  383],
        [  489],
        [ 1190]], device='cuda:0')
[2024-07-24 10:29:04,124][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[22219],
        [22870],
        [22725],
        [22486],
        [22593],
        [22918],
        [23107],
        [22783],
        [23063],
        [22813],
        [22478],
        [22564],
        [22229],
        [22332]], device='cuda:0')
[2024-07-24 10:29:04,125][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[37102],
        [28551],
        [25259],
        [25780],
        [28067],
        [28704],
        [29000],
        [29423],
        [28878],
        [28918],
        [30026],
        [29650],
        [29304],
        [29535]], device='cuda:0')
[2024-07-24 10:29:04,127][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[10437],
        [ 6886],
        [ 9164],
        [11092],
        [11393],
        [12161],
        [12054],
        [14176],
        [14127],
        [14950],
        [15205],
        [15062],
        [16048],
        [15736]], device='cuda:0')
[2024-07-24 10:29:04,129][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[35374],
        [35374],
        [23676],
        [33633],
        [35738],
        [27870],
        [28229],
        [44868],
        [26160],
        [31008],
        [27641],
        [31371],
        [45351],
        [24267]], device='cuda:0')
[2024-07-24 10:29:04,131][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[20419],
        [22436],
        [29506],
        [29066],
        [28905],
        [29588],
        [26102],
        [22821],
        [27979],
        [25906],
        [27225],
        [26594],
        [19458],
        [27380]], device='cuda:0')
[2024-07-24 10:29:04,132][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[23840],
        [12586],
        [28879],
        [25402],
        [28167],
        [30273],
        [29499],
        [29097],
        [27431],
        [16951],
        [27759],
        [35950],
        [30283],
        [26156]], device='cuda:0')
[2024-07-24 10:29:04,134][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[19668],
        [19668],
        [19668],
        [19668],
        [19668],
        [19668],
        [19668],
        [19668],
        [19668],
        [19668],
        [19668],
        [19668],
        [19668],
        [19668]], device='cuda:0')
[2024-07-24 10:29:04,195][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:29:04,196][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:04,197][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:04,198][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:04,199][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:04,199][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:04,200][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:04,202][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:04,203][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:04,204][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:04,205][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:04,207][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:04,208][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:04,209][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Amanda] are: tensor([0.0061, 0.9939], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:04,211][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Amanda] are: tensor([0.1994, 0.8006], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:04,212][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Amanda] are: tensor([0.5155, 0.4845], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:04,214][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Amanda] are: tensor([0.4312, 0.5688], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:04,215][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Amanda] are: tensor([0.9278, 0.0722], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:04,217][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Amanda] are: tensor([0.0294, 0.9706], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:04,219][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Amanda] are: tensor([0.1028, 0.8972], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:04,220][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Amanda] are: tensor([0.2618, 0.7382], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:04,222][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Amanda] are: tensor([0.9730, 0.0270], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:04,224][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Amanda] are: tensor([0.3959, 0.6041], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:04,225][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Amanda] are: tensor([0.0793, 0.9207], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:04,227][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Amanda] are: tensor([0.5406, 0.4594], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:04,229][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0037, 0.4890, 0.5073], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:04,229][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0022, 0.9882, 0.0096], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:04,230][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.2327, 0.7113, 0.0560], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:04,231][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.2770, 0.4450, 0.2780], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:04,231][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.6935, 0.2955, 0.0110], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:04,233][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0160, 0.4722, 0.5118], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:04,235][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0273, 0.6155, 0.3572], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:04,236][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.1220, 0.4089, 0.4691], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:04,238][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.3411, 0.6574, 0.0015], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:04,239][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.2480, 0.3903, 0.3617], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:04,241][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0453, 0.4644, 0.4903], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:04,243][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.3666, 0.3106, 0.3229], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:04,244][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ John] are: tensor([0.0016, 0.3362, 0.3518, 0.3103], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:04,246][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ John] are: tensor([0.0025, 0.8456, 0.1190, 0.0330], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:04,247][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ John] are: tensor([0.2852, 0.4843, 0.0634, 0.1672], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:04,249][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ John] are: tensor([0.1996, 0.3071, 0.2002, 0.2931], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:04,251][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ John] are: tensor([0.6071, 0.0989, 0.2285, 0.0656], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:04,252][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ John] are: tensor([0.0234, 0.1907, 0.5230, 0.2629], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:04,254][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ John] are: tensor([0.0311, 0.3702, 0.3676, 0.2311], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:04,255][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ John] are: tensor([0.0754, 0.2876, 0.3308, 0.3061], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:04,257][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ John] are: tensor([0.5590, 0.2681, 0.1705, 0.0025], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:04,259][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ John] are: tensor([0.1817, 0.2858, 0.2646, 0.2678], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:04,260][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ John] are: tensor([0.0265, 0.3205, 0.3433, 0.3097], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:04,261][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ John] are: tensor([0.2806, 0.2380, 0.2479, 0.2335], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:04,262][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ went] are: tensor([0.0008, 0.2743, 0.2848, 0.2503, 0.1897], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:04,263][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ went] are: tensor([0.0207, 0.4134, 0.3454, 0.1740, 0.0465], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:04,263][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ went] are: tensor([0.0848, 0.5634, 0.0578, 0.2416, 0.0523], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:04,265][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ went] are: tensor([0.1563, 0.2404, 0.1546, 0.2262, 0.2225], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:04,267][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ went] are: tensor([0.4354, 0.0813, 0.2762, 0.2023, 0.0047], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:04,268][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ went] are: tensor([0.0025, 0.0532, 0.3756, 0.1756, 0.3932], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:04,270][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ went] are: tensor([0.0208, 0.2957, 0.2829, 0.2179, 0.1827], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:04,271][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ went] are: tensor([0.0513, 0.2150, 0.2512, 0.2309, 0.2517], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:04,273][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.2777, 0.1804, 0.4279, 0.1114, 0.0025], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:04,275][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ went] are: tensor([0.1428, 0.2284, 0.2110, 0.2137, 0.2041], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:04,276][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ went] are: tensor([0.0185, 0.2499, 0.2701, 0.2398, 0.2217], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:04,278][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ went] are: tensor([0.2327, 0.1925, 0.2011, 0.1887, 0.1850], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:04,280][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0007, 0.2325, 0.2409, 0.2115, 0.1603, 0.1543], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:04,281][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0026, 0.3372, 0.0061, 0.2386, 0.4097, 0.0058], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:04,283][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1369, 0.4178, 0.0382, 0.2855, 0.0772, 0.0444], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:04,285][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.1204, 0.2172, 0.1366, 0.2050, 0.2015, 0.1194], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:04,286][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.4075, 0.2829, 0.0813, 0.1979, 0.0264, 0.0039], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:04,288][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0018, 0.0606, 0.2547, 0.1140, 0.2899, 0.2791], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:04,290][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0118, 0.3068, 0.1844, 0.2049, 0.1870, 0.1051], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:04,291][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0267, 0.1738, 0.2086, 0.1901, 0.2139, 0.1868], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:04,292][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.3643, 0.1781, 0.0259, 0.2870, 0.1444, 0.0004], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:04,293][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.1179, 0.1903, 0.1755, 0.1778, 0.1698, 0.1686], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:04,294][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0147, 0.2033, 0.2185, 0.1965, 0.1817, 0.1851], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:04,294][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.1939, 0.1610, 0.1681, 0.1582, 0.1546, 0.1643], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:04,295][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0006, 0.1977, 0.2064, 0.1809, 0.1384, 0.1334, 0.1426],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:04,297][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0020, 0.2490, 0.0969, 0.0875, 0.3132, 0.2480, 0.0033],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:04,298][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0992, 0.4308, 0.0284, 0.3216, 0.0449, 0.0522, 0.0229],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:04,300][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.1109, 0.1814, 0.1165, 0.1735, 0.1711, 0.1059, 0.1407],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:04,302][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.6483, 0.1709, 0.0147, 0.1126, 0.0431, 0.0078, 0.0024],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:04,303][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0026, 0.0521, 0.2342, 0.1336, 0.2825, 0.2122, 0.0827],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:04,305][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0095, 0.2516, 0.1775, 0.1767, 0.1806, 0.1093, 0.0949],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:04,306][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0224, 0.1379, 0.1618, 0.1566, 0.1860, 0.1604, 0.1749],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:04,308][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.2670, 0.1052, 0.0604, 0.1273, 0.2775, 0.1616, 0.0010],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:04,310][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.1000, 0.1627, 0.1503, 0.1523, 0.1457, 0.1445, 0.1445],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:04,311][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0125, 0.1702, 0.1833, 0.1649, 0.1524, 0.1557, 0.1611],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:04,313][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.1683, 0.1390, 0.1448, 0.1360, 0.1326, 0.1406, 0.1387],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:04,315][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ station] are: tensor([0.0008, 0.1677, 0.1732, 0.1535, 0.1187, 0.1147, 0.1218, 0.1496],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:04,317][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ station] are: tensor([0.0006, 0.0402, 0.2286, 0.2109, 0.2201, 0.1669, 0.0813, 0.0513],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:04,318][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ station] are: tensor([0.0982, 0.4181, 0.0355, 0.2942, 0.0796, 0.0294, 0.0330, 0.0120],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:04,320][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ station] are: tensor([0.0924, 0.1507, 0.0977, 0.1433, 0.1430, 0.0900, 0.1206, 0.1624],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:04,321][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ station] are: tensor([0.3863, 0.0914, 0.1168, 0.0841, 0.0126, 0.0815, 0.2251, 0.0021],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:04,323][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ station] are: tensor([0.0027, 0.0379, 0.2434, 0.1213, 0.2185, 0.2109, 0.0771, 0.0882],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:04,324][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ station] are: tensor([0.0130, 0.1871, 0.1582, 0.1306, 0.1320, 0.0964, 0.1080, 0.1747],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:04,325][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ station] are: tensor([0.0246, 0.1143, 0.1388, 0.1263, 0.1491, 0.1358, 0.1476, 0.1635],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:04,325][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ station] are: tensor([0.0973, 0.0111, 0.0219, 0.1910, 0.1699, 0.1878, 0.3204, 0.0006],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:04,326][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ station] are: tensor([0.0883, 0.1409, 0.1306, 0.1321, 0.1264, 0.1257, 0.1256, 0.1304],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:04,327][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ station] are: tensor([0.0118, 0.1465, 0.1577, 0.1417, 0.1313, 0.1341, 0.1385, 0.1384],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:04,329][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ station] are: tensor([0.1474, 0.1221, 0.1270, 0.1198, 0.1171, 0.1240, 0.1228, 0.1197],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:04,330][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0008, 0.1441, 0.1496, 0.1329, 0.1038, 0.1003, 0.1067, 0.1302, 0.1316],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:04,332][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0013, 0.1597, 0.0116, 0.1096, 0.1463, 0.0199, 0.0116, 0.5365, 0.0034],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:04,333][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0719, 0.3586, 0.0253, 0.3679, 0.0632, 0.0398, 0.0359, 0.0274, 0.0101],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:04,335][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0881, 0.1380, 0.0842, 0.1291, 0.1258, 0.0761, 0.1044, 0.1441, 0.1101],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:04,336][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [,] are: tensor([5.8058e-01, 1.3253e-01, 5.5827e-03, 1.2580e-01, 3.8759e-02, 2.5169e-03,
        9.9096e-02, 1.5006e-02, 1.3039e-04], device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:04,338][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0036, 0.0514, 0.2634, 0.1199, 0.1885, 0.1508, 0.0724, 0.0824, 0.0675],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:04,340][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0077, 0.1970, 0.1127, 0.1306, 0.1262, 0.0735, 0.0820, 0.1863, 0.0840],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:04,341][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0118, 0.1049, 0.1275, 0.1147, 0.1346, 0.1213, 0.1305, 0.1486, 0.1063],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:04,343][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.1086, 0.1537, 0.0138, 0.1441, 0.3060, 0.0259, 0.2304, 0.0168, 0.0005],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:04,345][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0775, 0.1252, 0.1158, 0.1171, 0.1121, 0.1114, 0.1113, 0.1159, 0.1137],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:04,346][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0114, 0.1272, 0.1351, 0.1243, 0.1156, 0.1179, 0.1216, 0.1210, 0.1259],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:04,348][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.1306, 0.1087, 0.1133, 0.1067, 0.1042, 0.1101, 0.1088, 0.1067, 0.1110],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:04,350][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ John] are: tensor([0.0005, 0.1292, 0.1355, 0.1191, 0.0913, 0.0885, 0.0943, 0.1164, 0.1180,
        0.1072], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:04,351][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ John] are: tensor([0.0008, 0.4048, 0.0580, 0.0134, 0.1942, 0.0706, 0.0099, 0.1893, 0.0532,
        0.0058], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:04,353][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ John] are: tensor([0.2117, 0.2906, 0.0400, 0.1387, 0.0530, 0.0613, 0.0299, 0.0229, 0.0183,
        0.1336], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:04,355][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ John] are: tensor([0.0788, 0.1182, 0.0745, 0.1117, 0.1099, 0.0668, 0.0925, 0.1310, 0.0968,
        0.1198], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:04,356][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ John] are: tensor([0.5324, 0.0623, 0.1484, 0.0640, 0.0175, 0.0381, 0.0689, 0.0085, 0.0036,
        0.0562], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:04,356][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ John] are: tensor([0.0037, 0.0382, 0.1667, 0.0777, 0.1724, 0.1818, 0.0932, 0.1159, 0.0979,
        0.0525], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:04,357][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ John] are: tensor([0.0114, 0.1535, 0.1405, 0.0915, 0.1000, 0.0824, 0.0869, 0.1464, 0.1065,
        0.0811], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:04,358][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ John] are: tensor([0.0147, 0.0973, 0.1112, 0.0993, 0.1166, 0.1042, 0.1131, 0.1252, 0.0914,
        0.1270], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:04,360][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ John] are: tensor([0.2631, 0.0990, 0.0552, 0.0009, 0.1495, 0.1085, 0.0648, 0.0875, 0.1694,
        0.0020], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:04,361][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ John] are: tensor([0.0699, 0.1120, 0.1037, 0.1048, 0.1004, 0.0999, 0.0999, 0.1040, 0.1020,
        0.1035], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:04,363][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ John] are: tensor([0.0089, 0.1133, 0.1220, 0.1105, 0.1023, 0.1041, 0.1076, 0.1080, 0.1134,
        0.1098], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:04,365][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ John] are: tensor([0.1183, 0.0984, 0.1025, 0.0963, 0.0943, 0.0996, 0.0987, 0.0962, 0.1003,
        0.0952], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:04,366][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.0004, 0.1190, 0.1233, 0.1088, 0.0831, 0.0806, 0.0858, 0.1067, 0.1075,
        0.0975, 0.0873], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:04,368][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0052, 0.0863, 0.0785, 0.1375, 0.0694, 0.0614, 0.0278, 0.3084, 0.0755,
        0.1343, 0.0157], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:04,370][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0653, 0.3386, 0.0301, 0.1988, 0.0564, 0.0493, 0.0374, 0.0201, 0.0111,
        0.1702, 0.0227], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:04,372][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.0739, 0.1074, 0.0675, 0.1001, 0.0985, 0.0608, 0.0844, 0.1165, 0.0892,
        0.1088, 0.0930], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:04,373][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.3592, 0.0437, 0.1376, 0.1309, 0.0140, 0.0219, 0.1668, 0.0154, 0.0065,
        0.1009, 0.0030], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:04,375][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.0010, 0.0182, 0.2297, 0.1281, 0.2835, 0.1374, 0.0411, 0.0472, 0.0457,
        0.0303, 0.0379], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:04,377][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0077, 0.1296, 0.1227, 0.0928, 0.0881, 0.0764, 0.0719, 0.1510, 0.1000,
        0.0824, 0.0774], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:04,378][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0159, 0.0875, 0.1027, 0.0905, 0.1010, 0.0911, 0.1003, 0.1152, 0.0800,
        0.1139, 0.1018], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:04,380][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.2574, 0.0728, 0.0232, 0.1007, 0.0652, 0.0728, 0.1263, 0.0861, 0.0522,
        0.1427, 0.0006], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:04,382][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.0634, 0.1013, 0.0939, 0.0949, 0.0910, 0.0904, 0.0905, 0.0941, 0.0924,
        0.0937, 0.0945], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:04,384][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0082, 0.1032, 0.1108, 0.0997, 0.0923, 0.0940, 0.0971, 0.0975, 0.1026,
        0.0990, 0.0956], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:04,385][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.1083, 0.0901, 0.0934, 0.0877, 0.0861, 0.0908, 0.0898, 0.0878, 0.0914,
        0.0867, 0.0879], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:04,387][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0004, 0.1090, 0.1135, 0.0999, 0.0766, 0.0738, 0.0790, 0.0983, 0.0985,
        0.0895, 0.0803, 0.0814], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:04,388][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0020, 0.0876, 0.0746, 0.0767, 0.0928, 0.1096, 0.0056, 0.2972, 0.0882,
        0.0778, 0.0816, 0.0064], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:04,388][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0663, 0.3042, 0.0140, 0.2439, 0.0207, 0.0194, 0.0123, 0.0111, 0.0052,
        0.2552, 0.0226, 0.0251], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:04,389][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0601, 0.0948, 0.0615, 0.0920, 0.0898, 0.0571, 0.0761, 0.1058, 0.0803,
        0.0995, 0.0853, 0.0977], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:04,390][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ a] are: tensor([6.1080e-01, 6.2792e-02, 3.2209e-02, 1.0216e-01, 3.6518e-02, 1.1491e-02,
        1.8906e-02, 7.6937e-03, 3.3113e-03, 1.0622e-01, 7.3722e-03, 5.2298e-04],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:04,392][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0015, 0.0168, 0.2328, 0.0895, 0.1987, 0.1463, 0.0455, 0.0701, 0.0599,
        0.0309, 0.0581, 0.0500], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:04,394][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0055, 0.1347, 0.0973, 0.1017, 0.0917, 0.0607, 0.0518, 0.1539, 0.0759,
        0.0928, 0.0798, 0.0542], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:04,395][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0113, 0.0755, 0.0873, 0.0814, 0.0965, 0.0839, 0.0907, 0.1031, 0.0738,
        0.1035, 0.1021, 0.0907], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:04,396][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ a] are: tensor([8.3874e-02, 4.9023e-02, 5.6733e-02, 2.7648e-02, 7.7462e-02, 4.7515e-02,
        8.6967e-03, 8.2333e-02, 3.3240e-01, 8.6402e-02, 1.4770e-01, 2.1138e-04],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:04,398][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0576, 0.0923, 0.0856, 0.0865, 0.0831, 0.0826, 0.0826, 0.0859, 0.0844,
        0.0856, 0.0865, 0.0873], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:04,400][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0076, 0.0930, 0.0997, 0.0903, 0.0837, 0.0854, 0.0882, 0.0886, 0.0928,
        0.0900, 0.0872, 0.0934], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:04,401][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0996, 0.0826, 0.0859, 0.0807, 0.0790, 0.0832, 0.0825, 0.0805, 0.0837,
        0.0795, 0.0803, 0.0824], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:04,403][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ ring] are: tensor([0.0004, 0.1012, 0.1050, 0.0926, 0.0708, 0.0681, 0.0725, 0.0898, 0.0904,
        0.0823, 0.0734, 0.0743, 0.0793], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:04,405][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ ring] are: tensor([0.0005, 0.0664, 0.0856, 0.0565, 0.0290, 0.2233, 0.0211, 0.1183, 0.1537,
        0.0435, 0.1007, 0.0877, 0.0138], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:04,407][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ ring] are: tensor([0.0278, 0.3311, 0.0245, 0.2999, 0.0380, 0.0180, 0.0258, 0.0122, 0.0079,
        0.1503, 0.0190, 0.0412, 0.0044], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:04,409][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ ring] are: tensor([0.0610, 0.0842, 0.0541, 0.0814, 0.0791, 0.0499, 0.0676, 0.0935, 0.0707,
        0.0877, 0.0751, 0.0891, 0.1065], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:04,410][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ ring] are: tensor([0.3990, 0.0825, 0.0690, 0.0712, 0.0265, 0.0329, 0.1688, 0.0041, 0.0111,
        0.0576, 0.0146, 0.0464, 0.0164], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:04,412][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ ring] are: tensor([0.0016, 0.0167, 0.1335, 0.0726, 0.1222, 0.1881, 0.0536, 0.0546, 0.0665,
        0.0355, 0.0505, 0.0761, 0.1284], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:04,414][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ ring] are: tensor([0.0083, 0.1139, 0.1018, 0.0794, 0.0770, 0.0580, 0.0610, 0.1189, 0.0818,
        0.0716, 0.0765, 0.0659, 0.0859], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:04,415][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ ring] are: tensor([0.0137, 0.0685, 0.0801, 0.0706, 0.0840, 0.0739, 0.0827, 0.0968, 0.0687,
        0.0902, 0.0882, 0.0852, 0.0974], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:04,417][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ ring] are: tensor([0.0789, 0.0193, 0.0160, 0.0702, 0.0120, 0.2339, 0.0813, 0.0085, 0.2536,
        0.1336, 0.0329, 0.0596, 0.0003], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:04,419][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ ring] are: tensor([0.0536, 0.0845, 0.0785, 0.0793, 0.0762, 0.0757, 0.0757, 0.0788, 0.0774,
        0.0785, 0.0791, 0.0799, 0.0829], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:04,419][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ ring] are: tensor([0.0075, 0.0848, 0.0907, 0.0822, 0.0761, 0.0778, 0.0803, 0.0804, 0.0844,
        0.0819, 0.0793, 0.0847, 0.0898], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:04,420][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ ring] are: tensor([0.0914, 0.0765, 0.0791, 0.0747, 0.0728, 0.0768, 0.0759, 0.0745, 0.0773,
        0.0734, 0.0741, 0.0759, 0.0776], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:04,421][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0003, 0.0942, 0.0976, 0.0861, 0.0657, 0.0633, 0.0676, 0.0842, 0.0845,
        0.0767, 0.0684, 0.0693, 0.0742, 0.0677], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:04,422][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0007, 0.0900, 0.0014, 0.0851, 0.1113, 0.0012, 0.0123, 0.1777, 0.0023,
        0.0987, 0.0736, 0.0798, 0.2643, 0.0016], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:04,424][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1544, 0.1992, 0.0173, 0.1396, 0.0231, 0.0173, 0.0239, 0.0149, 0.0149,
        0.2185, 0.0316, 0.0693, 0.0278, 0.0481], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:04,426][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0508, 0.0816, 0.0520, 0.0787, 0.0758, 0.0474, 0.0635, 0.0880, 0.0667,
        0.0837, 0.0707, 0.0825, 0.0990, 0.0597], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:04,427][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.2079, 0.1057, 0.0471, 0.1214, 0.0172, 0.0023, 0.1193, 0.0080, 0.0046,
        0.1344, 0.0202, 0.0505, 0.1598, 0.0014], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:04,429][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0007, 0.0183, 0.1989, 0.0804, 0.1926, 0.1455, 0.0429, 0.0578, 0.0493,
        0.0224, 0.0409, 0.0466, 0.0624, 0.0414], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:04,431][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0049, 0.1247, 0.0768, 0.0876, 0.0799, 0.0453, 0.0571, 0.1203, 0.0638,
        0.0785, 0.0681, 0.0605, 0.0852, 0.0471], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:04,433][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0087, 0.0630, 0.0729, 0.0696, 0.0801, 0.0682, 0.0775, 0.0896, 0.0628,
        0.0903, 0.0858, 0.0767, 0.0877, 0.0672], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:04,434][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ to] are: tensor([2.2745e-01, 8.3448e-02, 8.3368e-03, 9.7699e-02, 3.5451e-02, 7.2290e-05,
        1.0591e-01, 8.4840e-03, 2.6170e-02, 2.3899e-01, 4.4730e-02, 1.1235e-01,
        1.0646e-02, 2.5582e-04], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:04,436][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0492, 0.0786, 0.0728, 0.0736, 0.0705, 0.0701, 0.0700, 0.0728, 0.0716,
        0.0726, 0.0732, 0.0739, 0.0768, 0.0742], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:04,437][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0064, 0.0780, 0.0838, 0.0762, 0.0707, 0.0720, 0.0744, 0.0744, 0.0781,
        0.0757, 0.0734, 0.0786, 0.0828, 0.0754], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:04,439][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0850, 0.0707, 0.0734, 0.0690, 0.0677, 0.0716, 0.0705, 0.0689, 0.0718,
        0.0680, 0.0688, 0.0704, 0.0717, 0.0727], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:04,501][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:29:04,503][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:04,504][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:04,506][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:04,507][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:04,508][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:04,509][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:04,511][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:04,512][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:04,513][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:04,513][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:04,514][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:04,515][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:04,515][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Amanda] are: tensor([0.0591, 0.9409], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:04,516][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Amanda] are: tensor([0.4772, 0.5228], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:04,517][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Amanda] are: tensor([0.4795, 0.5205], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:04,518][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Amanda] are: tensor([0.4940, 0.5060], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:04,519][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Amanda] are: tensor([0.8121, 0.1879], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:04,519][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Amanda] are: tensor([0.1471, 0.8529], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:04,520][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Amanda] are: tensor([0.7085, 0.2915], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:04,521][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Amanda] are: tensor([0.6097, 0.3903], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:04,522][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Amanda] are: tensor([0.9223, 0.0777], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:04,522][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Amanda] are: tensor([0.1094, 0.8906], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:04,524][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Amanda] are: tensor([0.6127, 0.3873], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:04,525][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Amanda] are: tensor([0.2760, 0.7240], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:04,527][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.2338, 0.3862, 0.3800], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:04,528][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([7.9162e-04, 9.9766e-01, 1.5435e-03], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:04,529][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.2374, 0.6860, 0.0766], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:04,531][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.3416, 0.4896, 0.1687], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:04,533][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.6482, 0.2895, 0.0623], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:04,534][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0841, 0.5633, 0.3526], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:04,536][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.1871, 0.4995, 0.3134], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:04,537][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.5460, 0.3504, 0.1036], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:04,539][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.2607, 0.7249, 0.0144], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:04,541][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0555, 0.4850, 0.4594], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:04,542][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.5078, 0.2138, 0.2784], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:04,544][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.1139, 0.1314, 0.7546], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:04,545][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ John] are: tensor([0.0026, 0.0249, 0.1306, 0.8419], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:04,547][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ John] are: tensor([0.0015, 0.7617, 0.2318, 0.0050], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:04,549][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ John] are: tensor([0.2790, 0.4119, 0.0891, 0.2199], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:04,550][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ John] are: tensor([0.3055, 0.3296, 0.1368, 0.2281], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:04,551][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ John] are: tensor([0.4993, 0.3581, 0.1088, 0.0338], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:04,552][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ John] are: tensor([0.0456, 0.3758, 0.2585, 0.3202], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:04,553][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ John] are: tensor([0.2355, 0.3891, 0.3126, 0.0628], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:04,553][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ John] are: tensor([0.4970, 0.3249, 0.0634, 0.1147], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:04,555][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ John] are: tensor([0.2287, 0.3349, 0.4215, 0.0149], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:04,557][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ John] are: tensor([0.0347, 0.3458, 0.3236, 0.2959], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:04,558][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ John] are: tensor([0.2569, 0.2128, 0.3100, 0.2204], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:04,560][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ John] are: tensor([0.1652, 0.3248, 0.2086, 0.3014], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:04,561][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([0.0031, 0.0359, 0.0357, 0.5751, 0.3501], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:04,563][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([0.0056, 0.0920, 0.8845, 0.0164, 0.0015], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:04,565][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([0.0906, 0.4313, 0.0811, 0.3150, 0.0819], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:04,566][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([0.2156, 0.3019, 0.0995, 0.2185, 0.1645], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:04,568][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([0.5131, 0.2424, 0.0652, 0.0306, 0.1487], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:04,569][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([0.0381, 0.2952, 0.1951, 0.2825, 0.1891], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:04,571][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([0.0706, 0.2060, 0.3562, 0.1307, 0.2365], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:04,573][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([0.2523, 0.2251, 0.1549, 0.0901, 0.2775], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:04,574][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([0.1927, 0.2393, 0.4415, 0.1225, 0.0040], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:04,576][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([0.0230, 0.2650, 0.2403, 0.2418, 0.2300], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:04,578][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([0.1628, 0.1969, 0.3020, 0.1721, 0.1662], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:04,579][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([0.0516, 0.0232, 0.1009, 0.0294, 0.7949], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:04,580][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([5.2537e-04, 1.1341e-02, 4.4032e-02, 2.1626e-01, 3.9413e-02, 6.8843e-01],
       device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:04,582][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0046, 0.4552, 0.0034, 0.1490, 0.3871, 0.0007], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:04,583][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.2177, 0.3053, 0.0430, 0.2746, 0.0812, 0.0781], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:04,584][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.2868, 0.2073, 0.0896, 0.1972, 0.1346, 0.0845], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:04,584][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.3217, 0.2224, 0.0771, 0.0330, 0.2466, 0.0993], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:04,585][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0295, 0.2263, 0.1614, 0.2419, 0.2134, 0.1277], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:04,586][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0724, 0.0896, 0.0887, 0.0367, 0.4965, 0.2161], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:04,588][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.2432, 0.1389, 0.0584, 0.0452, 0.3079, 0.2063], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:04,589][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.1430, 0.2217, 0.1565, 0.3537, 0.1207, 0.0044], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:04,591][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0186, 0.2139, 0.2023, 0.1984, 0.1907, 0.1761], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:04,592][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.2046, 0.1403, 0.2061, 0.1334, 0.1573, 0.1584], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:04,594][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0540, 0.0277, 0.1670, 0.0305, 0.0931, 0.6277], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:04,595][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([3.0867e-04, 1.0842e-02, 3.1247e-02, 8.5123e-02, 3.5965e-02, 3.1750e-01,
        5.1901e-01], device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:04,597][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0032, 0.0991, 0.1152, 0.0178, 0.1430, 0.6208, 0.0009],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:04,598][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.1465, 0.3134, 0.0349, 0.3042, 0.0498, 0.1029, 0.0482],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:04,600][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.2481, 0.2142, 0.0681, 0.1820, 0.1062, 0.0943, 0.0872],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:04,602][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0617, 0.2972, 0.0815, 0.0371, 0.2402, 0.2403, 0.0421],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:04,603][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.0331, 0.1939, 0.1483, 0.2036, 0.1710, 0.1299, 0.1202],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:04,605][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0585, 0.0605, 0.0781, 0.0331, 0.2103, 0.3823, 0.1772],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:04,607][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.2974, 0.1456, 0.0478, 0.0427, 0.1780, 0.2213, 0.0673],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:04,609][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.1657, 0.1418, 0.1659, 0.1529, 0.1508, 0.2185, 0.0043],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:04,610][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0166, 0.1856, 0.1714, 0.1708, 0.1646, 0.1503, 0.1408],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:04,612][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.1439, 0.1226, 0.1951, 0.1315, 0.1377, 0.1319, 0.1373],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:04,613][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0609, 0.0484, 0.1063, 0.1659, 0.1169, 0.0421, 0.4595],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:04,614][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ station] are: tensor([3.6803e-04, 9.3728e-03, 4.3253e-03, 1.2609e-01, 1.1540e-01, 9.4972e-02,
        4.7363e-01, 1.7585e-01], device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:04,615][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ station] are: tensor([1.2396e-05, 1.5117e-03, 1.8615e-01, 1.9333e-02, 1.3744e-02, 1.8881e-01,
        5.8996e-01, 4.8295e-04], device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:04,616][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ station] are: tensor([0.0841, 0.3155, 0.0394, 0.3018, 0.0992, 0.0625, 0.0776, 0.0199],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:04,617][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ station] are: tensor([0.1643, 0.2453, 0.0656, 0.1584, 0.1127, 0.0781, 0.1035, 0.0722],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:04,618][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ station] are: tensor([0.3553, 0.1680, 0.0473, 0.0286, 0.1829, 0.1444, 0.0617, 0.0118],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:04,619][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ station] are: tensor([0.0256, 0.1372, 0.1317, 0.1735, 0.1401, 0.1211, 0.1235, 0.1472],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:04,621][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ station] are: tensor([0.0182, 0.0304, 0.0489, 0.0434, 0.1333, 0.3091, 0.4055, 0.0112],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:04,622][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ station] are: tensor([0.3191, 0.1480, 0.0471, 0.0363, 0.1837, 0.1825, 0.0526, 0.0308],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:04,624][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ station] are: tensor([0.0498, 0.0261, 0.1055, 0.3389, 0.1164, 0.1692, 0.1889, 0.0052],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:04,625][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ station] are: tensor([0.0144, 0.1600, 0.1475, 0.1442, 0.1415, 0.1298, 0.1202, 0.1422],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:04,627][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ station] are: tensor([0.1301, 0.1069, 0.1660, 0.1072, 0.1162, 0.1073, 0.1116, 0.1548],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:04,629][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ station] are: tensor([0.0879, 0.0456, 0.0895, 0.1886, 0.3606, 0.0513, 0.0833, 0.0932],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:04,630][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0130, 0.0106, 0.0249, 0.0557, 0.0186, 0.1133, 0.6403, 0.1013, 0.0222],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:04,631][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([7.6704e-05, 1.1819e-01, 6.7943e-03, 7.3747e-02, 4.9569e-02, 1.9541e-02,
        2.1352e-01, 5.1810e-01, 4.5824e-04], device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:04,633][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0967, 0.2629, 0.0301, 0.3284, 0.0629, 0.0811, 0.0793, 0.0396, 0.0190],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:04,635][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.1718, 0.1774, 0.0594, 0.1513, 0.0965, 0.0688, 0.0676, 0.1388, 0.0683],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:04,636][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0294, 0.1999, 0.0775, 0.0218, 0.2720, 0.2595, 0.0768, 0.0226, 0.0405],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:04,638][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0234, 0.1391, 0.1085, 0.1503, 0.1375, 0.0939, 0.0995, 0.1553, 0.0925],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:04,640][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0495, 0.0326, 0.0651, 0.0181, 0.1768, 0.2174, 0.2842, 0.0872, 0.0692],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:04,642][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.2559, 0.1274, 0.0503, 0.0367, 0.1985, 0.1769, 0.0529, 0.0631, 0.0382],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:04,643][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0581, 0.1809, 0.0609, 0.1725, 0.1593, 0.0537, 0.1285, 0.1847, 0.0014],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:04,645][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0129, 0.1376, 0.1298, 0.1266, 0.1224, 0.1141, 0.1074, 0.1272, 0.1221],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:04,647][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.1912, 0.0842, 0.1202, 0.0974, 0.1058, 0.0914, 0.0822, 0.1215, 0.1061],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:04,648][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0884, 0.0556, 0.3140, 0.0658, 0.0800, 0.1339, 0.0579, 0.0439, 0.1605],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:04,650][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ John] are: tensor([0.0011, 0.0046, 0.0241, 0.0625, 0.0669, 0.1459, 0.2836, 0.0894, 0.0954,
        0.2265], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:04,651][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ John] are: tensor([1.3820e-04, 2.3941e-01, 7.1067e-02, 1.1658e-03, 7.6275e-02, 3.4860e-01,
        3.9030e-02, 4.8869e-02, 1.7508e-01, 3.6593e-04], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:04,652][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ John] are: tensor([0.2264, 0.1572, 0.0342, 0.1104, 0.0467, 0.0839, 0.0537, 0.0250, 0.0270,
        0.2355], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:04,653][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ John] are: tensor([0.1685, 0.1590, 0.0605, 0.1176, 0.0810, 0.0560, 0.0687, 0.0877, 0.0644,
        0.1367], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:04,653][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ John] are: tensor([0.1942, 0.1885, 0.0659, 0.0170, 0.2189, 0.1779, 0.0580, 0.0292, 0.0430,
        0.0074], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:04,655][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ John] are: tensor([0.0147, 0.1327, 0.0929, 0.1122, 0.1268, 0.0744, 0.0822, 0.1640, 0.0858,
        0.1143], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:04,657][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ John] are: tensor([0.0982, 0.0543, 0.0783, 0.0109, 0.1288, 0.1437, 0.3271, 0.0364, 0.1068,
        0.0156], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:04,658][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ John] are: tensor([0.3751, 0.1545, 0.0308, 0.0506, 0.1151, 0.0978, 0.0459, 0.0256, 0.0260,
        0.0787], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:04,660][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ John] are: tensor([0.0712, 0.1010, 0.1212, 0.0043, 0.1013, 0.1142, 0.0564, 0.3637, 0.0613,
        0.0052], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:04,662][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ John] are: tensor([0.0099, 0.1258, 0.1175, 0.1079, 0.1100, 0.1024, 0.1009, 0.1182, 0.1099,
        0.0974], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:04,663][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ John] are: tensor([0.0679, 0.0789, 0.1254, 0.0832, 0.0843, 0.0733, 0.0788, 0.1214, 0.1610,
        0.1258], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:04,665][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ John] are: tensor([0.0773, 0.1025, 0.0787, 0.1172, 0.1370, 0.0569, 0.1669, 0.0561, 0.0926,
        0.1148], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:04,667][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.0005, 0.0051, 0.0064, 0.0817, 0.0876, 0.0646, 0.2493, 0.0541, 0.0216,
        0.1792, 0.2499], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:04,668][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0009, 0.0340, 0.2456, 0.0580, 0.0112, 0.1117, 0.2304, 0.0699, 0.1832,
        0.0532, 0.0019], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:04,670][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.0614, 0.1828, 0.0271, 0.1489, 0.0494, 0.0834, 0.0727, 0.0282, 0.0198,
        0.2905, 0.0359], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:04,672][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.1211, 0.1423, 0.0553, 0.0955, 0.0892, 0.0550, 0.1022, 0.0963, 0.0438,
        0.1171, 0.0820], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:04,674][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.1776, 0.3065, 0.0731, 0.0269, 0.2053, 0.1087, 0.0369, 0.0172, 0.0205,
        0.0095, 0.0176], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:04,675][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.0185, 0.1115, 0.0874, 0.1144, 0.0962, 0.0733, 0.0803, 0.1304, 0.0791,
        0.1195, 0.0893], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:04,677][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.0397, 0.0548, 0.0742, 0.0344, 0.0885, 0.1906, 0.2686, 0.0327, 0.0761,
        0.0477, 0.0928], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:04,679][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.3199, 0.1358, 0.0587, 0.0308, 0.0837, 0.2007, 0.0403, 0.0214, 0.0289,
        0.0323, 0.0477], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:04,681][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.0904, 0.0729, 0.0724, 0.0864, 0.0489, 0.1166, 0.0971, 0.2665, 0.0391,
        0.1082, 0.0016], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:04,682][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.0099, 0.1131, 0.1021, 0.1064, 0.1000, 0.0933, 0.0870, 0.1050, 0.0988,
        0.0958, 0.0886], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:04,683][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0562, 0.0818, 0.1228, 0.0722, 0.0694, 0.0623, 0.0680, 0.1052, 0.1679,
        0.1027, 0.0915], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:04,684][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.0227, 0.0953, 0.1681, 0.0418, 0.0794, 0.0493, 0.0821, 0.0172, 0.0603,
        0.0447, 0.3392], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:04,685][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0006, 0.0055, 0.0326, 0.0337, 0.0199, 0.1630, 0.3052, 0.0447, 0.0565,
        0.0664, 0.1032, 0.1685], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:04,687][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0006, 0.0180, 0.1603, 0.0155, 0.0152, 0.2307, 0.0087, 0.0753, 0.4310,
        0.0191, 0.0246, 0.0010], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:04,688][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.1069, 0.1706, 0.0136, 0.1726, 0.0171, 0.0325, 0.0230, 0.0124, 0.0085,
        0.3619, 0.0309, 0.0501], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:04,690][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.1815, 0.0983, 0.0367, 0.0879, 0.0477, 0.0448, 0.0490, 0.0580, 0.0482,
        0.1420, 0.1233, 0.0826], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:04,692][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0661, 0.3808, 0.0402, 0.0384, 0.1654, 0.0853, 0.0293, 0.0163, 0.0305,
        0.0209, 0.0533, 0.0735], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:04,693][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0195, 0.0982, 0.0833, 0.1065, 0.0877, 0.0713, 0.0692, 0.1069, 0.0746,
        0.1068, 0.0994, 0.0764], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:04,695][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0400, 0.0153, 0.0299, 0.0089, 0.1086, 0.1215, 0.0788, 0.0268, 0.0539,
        0.0164, 0.3244, 0.1755], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:04,697][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.2847, 0.0752, 0.0261, 0.0199, 0.1051, 0.1093, 0.0358, 0.0289, 0.0330,
        0.0319, 0.1788, 0.0714], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:04,698][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0558, 0.0829, 0.1289, 0.0475, 0.0579, 0.0700, 0.0143, 0.2694, 0.0987,
        0.0826, 0.0913, 0.0007], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:04,700][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0097, 0.1010, 0.0960, 0.0950, 0.0916, 0.0852, 0.0801, 0.0942, 0.0917,
        0.0862, 0.0860, 0.0834], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:04,702][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0767, 0.0724, 0.1114, 0.0726, 0.0703, 0.0650, 0.0647, 0.0964, 0.1194,
        0.0964, 0.0854, 0.0691], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:04,704][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0580, 0.0570, 0.0788, 0.0832, 0.1140, 0.0344, 0.1099, 0.0618, 0.0262,
        0.0864, 0.0615, 0.2287], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:04,705][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ ring] are: tensor([0.0011, 0.0063, 0.0162, 0.0308, 0.0581, 0.1286, 0.1681, 0.0431, 0.0581,
        0.0769, 0.1627, 0.1375, 0.1127], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:04,707][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ ring] are: tensor([7.2995e-06, 4.4088e-03, 7.8305e-02, 2.9624e-03, 8.2913e-04, 3.2066e-01,
        1.0372e-01, 2.2896e-03, 4.2972e-01, 1.8603e-03, 8.1231e-03, 4.6868e-02,
        2.4219e-04], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:04,708][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ ring] are: tensor([0.0313, 0.1985, 0.0225, 0.2087, 0.0331, 0.0330, 0.0521, 0.0143, 0.0132,
        0.2465, 0.0321, 0.1066, 0.0081], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:04,710][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ ring] are: tensor([0.0565, 0.1555, 0.0531, 0.0936, 0.0666, 0.0382, 0.0575, 0.0591, 0.0574,
        0.0919, 0.1150, 0.1143, 0.0411], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:04,712][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ ring] are: tensor([0.0750, 0.1536, 0.0590, 0.0240, 0.1797, 0.0941, 0.0512, 0.0096, 0.0483,
        0.0069, 0.0749, 0.2138, 0.0099], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:04,713][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ ring] are: tensor([0.0135, 0.0957, 0.0699, 0.0965, 0.0817, 0.0643, 0.0621, 0.1039, 0.0650,
        0.0973, 0.0895, 0.0705, 0.0901], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:04,714][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ ring] are: tensor([0.0231, 0.0066, 0.0254, 0.0061, 0.0639, 0.1164, 0.1350, 0.0061, 0.0496,
        0.0114, 0.2297, 0.3177, 0.0092], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:04,715][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ ring] are: tensor([0.1463, 0.0977, 0.0502, 0.0206, 0.0871, 0.1210, 0.0649, 0.0434, 0.0391,
        0.0317, 0.0811, 0.1673, 0.0495], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:04,716][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ ring] are: tensor([0.0433, 0.0457, 0.0831, 0.1141, 0.0105, 0.2542, 0.0540, 0.1019, 0.0884,
        0.1509, 0.0213, 0.0260, 0.0067], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:04,717][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ ring] are: tensor([0.0085, 0.0930, 0.0892, 0.0878, 0.0870, 0.0800, 0.0735, 0.0890, 0.0836,
        0.0784, 0.0778, 0.0762, 0.0761], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:04,719][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ ring] are: tensor([0.0713, 0.0747, 0.1021, 0.0651, 0.0600, 0.0609, 0.0622, 0.0847, 0.1154,
        0.0844, 0.0747, 0.0657, 0.0787], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:04,720][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ ring] are: tensor([0.0483, 0.1725, 0.0398, 0.0976, 0.0202, 0.0349, 0.0595, 0.0545, 0.0274,
        0.1084, 0.0557, 0.0540, 0.2270], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:04,722][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([1.2204e-04, 1.0529e-03, 1.8869e-02, 1.5354e-02, 4.5457e-03, 9.9932e-02,
        2.0387e-01, 2.5921e-02, 2.1385e-02, 4.3283e-02, 3.8503e-02, 8.0510e-02,
        1.1824e-02, 4.3483e-01], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:04,723][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([2.3793e-04, 2.4763e-02, 2.0420e-04, 1.2402e-02, 2.0415e-02, 3.1347e-05,
        1.5958e-01, 2.9165e-02, 5.1967e-04, 1.6250e-02, 3.1197e-02, 6.2332e-01,
        8.1867e-02, 4.4931e-05], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:04,725][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.2691, 0.1016, 0.0121, 0.0834, 0.0137, 0.0179, 0.0289, 0.0108, 0.0144,
        0.2154, 0.0258, 0.0935, 0.0230, 0.0906], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:04,726][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.2073, 0.0827, 0.0322, 0.0682, 0.0374, 0.0280, 0.0397, 0.0427, 0.0503,
        0.1039, 0.0896, 0.0670, 0.0852, 0.0660], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:04,728][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.2254, 0.1755, 0.0378, 0.0160, 0.0685, 0.0275, 0.0234, 0.0102, 0.0267,
        0.0068, 0.0432, 0.1551, 0.0150, 0.1689], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:04,730][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0115, 0.0847, 0.0633, 0.0942, 0.0825, 0.0505, 0.0621, 0.0949, 0.0585,
        0.0947, 0.0858, 0.0724, 0.0942, 0.0507], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:04,732][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.1625, 0.0147, 0.0184, 0.0045, 0.1002, 0.0272, 0.0844, 0.0138, 0.0498,
        0.0075, 0.2121, 0.1955, 0.0315, 0.0781], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:04,733][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.3733, 0.0448, 0.0171, 0.0166, 0.0799, 0.0520, 0.0241, 0.0176, 0.0207,
        0.0312, 0.1407, 0.0438, 0.0190, 0.1193], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:04,735][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0520, 0.0800, 0.0517, 0.1057, 0.0358, 0.0013, 0.1186, 0.0916, 0.0273,
        0.1549, 0.0431, 0.0795, 0.1571, 0.0013], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:04,737][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0070, 0.0880, 0.0825, 0.0815, 0.0774, 0.0717, 0.0673, 0.0811, 0.0777,
        0.0727, 0.0731, 0.0709, 0.0789, 0.0702], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:04,739][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0686, 0.0597, 0.0896, 0.0550, 0.0608, 0.0570, 0.0554, 0.0853, 0.1116,
        0.0786, 0.0770, 0.0635, 0.0764, 0.0614], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:04,741][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0287, 0.0111, 0.0773, 0.0147, 0.0495, 0.2794, 0.0244, 0.0134, 0.0406,
        0.0154, 0.0557, 0.0255, 0.0108, 0.3537], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:04,744][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:29:04,746][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[10541],
        [ 7008],
        [ 3550],
        [ 9830],
        [ 3854],
        [ 8341],
        [18407],
        [ 1633],
        [ 8083],
        [15892],
        [ 7121],
        [19044],
        [23463],
        [13947]], device='cuda:0')
[2024-07-24 10:29:04,747][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[10801],
        [25164],
        [10375],
        [23207],
        [ 9147],
        [16700],
        [22103],
        [ 1829],
        [12597],
        [22325],
        [ 8179],
        [22453],
        [29961],
        [19423]], device='cuda:0')
[2024-07-24 10:29:04,748][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[35012],
        [29360],
        [29557],
        [29388],
        [28593],
        [28626],
        [28300],
        [27670],
        [27776],
        [27881],
        [27582],
        [27317],
        [26968],
        [26917]], device='cuda:0')
[2024-07-24 10:29:04,750][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[11797],
        [    3],
        [    2],
        [    4],
        [  278],
        [  636],
        [ 1876],
        [10461],
        [ 6540],
        [  357],
        [10571],
        [ 9232],
        [ 8800],
        [10353]], device='cuda:0')
[2024-07-24 10:29:04,752][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 4253],
        [24415],
        [28039],
        [24333],
        [24309],
        [21005],
        [21563],
        [20274],
        [19259],
        [14973],
        [15947],
        [16012],
        [17167],
        [12529]], device='cuda:0')
[2024-07-24 10:29:04,753][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[2261],
        [2973],
        [2759],
        [2485],
        [2510],
        [2529],
        [2445],
        [2382],
        [2316],
        [2285],
        [2342],
        [2340],
        [2299],
        [2296]], device='cuda:0')
[2024-07-24 10:29:04,755][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[ 7643],
        [ 6647],
        [ 8124],
        [ 6661],
        [ 8894],
        [10843],
        [ 9652],
        [ 9532],
        [ 9787],
        [ 8375],
        [10356],
        [10387],
        [10913],
        [11601]], device='cuda:0')
[2024-07-24 10:29:04,756][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[48512],
        [49773],
        [49499],
        [49310],
        [48337],
        [47727],
        [47693],
        [47378],
        [47671],
        [47256],
        [47685],
        [47597],
        [47468],
        [47577]], device='cuda:0')
[2024-07-24 10:29:04,758][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[31479],
        [36478],
        [40329],
        [40217],
        [40567],
        [39979],
        [40913],
        [41273],
        [41170],
        [41108],
        [41020],
        [41003],
        [41473],
        [41172]], device='cuda:0')
[2024-07-24 10:29:04,760][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[17658],
        [40994],
        [38353],
        [33691],
        [32123],
        [31423],
        [31408],
        [32427],
        [32276],
        [31400],
        [31588],
        [31902],
        [32177],
        [31645]], device='cuda:0')
[2024-07-24 10:29:04,761][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[31646],
        [31303],
        [19673],
        [23102],
        [18985],
        [21937],
        [23636],
        [23745],
        [25420],
        [20421],
        [21792],
        [12923],
        [14393],
        [21766]], device='cuda:0')
[2024-07-24 10:29:04,763][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[32748],
        [35024],
        [35053],
        [35160],
        [34962],
        [34725],
        [34499],
        [34825],
        [35078],
        [35269],
        [35455],
        [35568],
        [35800],
        [35898]], device='cuda:0')
[2024-07-24 10:29:04,765][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[4084],
        [4338],
        [3828],
        [3656],
        [3609],
        [3470],
        [3353],
        [3296],
        [3219],
        [3182],
        [3186],
        [3140],
        [3018],
        [2930]], device='cuda:0')
[2024-07-24 10:29:04,767][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[26898],
        [21002],
        [20729],
        [21197],
        [20908],
        [20609],
        [20598],
        [19747],
        [19383],
        [19365],
        [19004],
        [18893],
        [18705],
        [18516]], device='cuda:0')
[2024-07-24 10:29:04,768][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[19022],
        [ 6614],
        [25077],
        [28127],
        [30163],
        [19136],
        [34301],
        [16098],
        [26378],
        [30187],
        [22697],
        [31099],
        [16985],
        [23639]], device='cuda:0')
[2024-07-24 10:29:04,769][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[30728],
        [18043],
        [26575],
        [34032],
        [30767],
        [38299],
        [36289],
        [31421],
        [33282],
        [31233],
        [29485],
        [34404],
        [32883],
        [34975]], device='cuda:0')
[2024-07-24 10:29:04,771][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[21502],
        [32563],
        [36362],
        [35277],
        [34541],
        [34632],
        [48015],
        [44439],
        [14396],
        [44272],
        [38404],
        [41469],
        [45363],
        [26961]], device='cuda:0')
[2024-07-24 10:29:04,773][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[10823],
        [ 5889],
        [ 6340],
        [ 6810],
        [ 7965],
        [ 8212],
        [ 8868],
        [ 9906],
        [10623],
        [14404],
        [14998],
        [14709],
        [14093],
        [15832]], device='cuda:0')
[2024-07-24 10:29:04,775][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[ 5256],
        [32169],
        [30199],
        [22913],
        [22158],
        [16882],
        [15853],
        [18458],
        [16992],
        [15368],
        [17020],
        [16000],
        [18026],
        [14090]], device='cuda:0')
[2024-07-24 10:29:04,776][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[15056],
        [18046],
        [22599],
        [25774],
        [26072],
        [22495],
        [20906],
        [20163],
        [18086],
        [19262],
        [22402],
        [20794],
        [11977],
        [15503]], device='cuda:0')
[2024-07-24 10:29:04,778][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[13387],
        [37013],
        [38118],
        [38808],
        [38771],
        [38787],
        [39274],
        [39220],
        [39396],
        [39417],
        [39594],
        [39828],
        [39565],
        [39602]], device='cuda:0')
[2024-07-24 10:29:04,779][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[44060],
        [30863],
        [20446],
        [21332],
        [27554],
        [30347],
        [27028],
        [27000],
        [26555],
        [27327],
        [27550],
        [33489],
        [33092],
        [34277]], device='cuda:0')
[2024-07-24 10:29:04,781][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[36713],
        [ 8140],
        [10628],
        [11660],
        [15236],
        [19218],
        [19585],
        [18252],
        [18659],
        [17881],
        [18437],
        [19606],
        [19170],
        [19813]], device='cuda:0')
[2024-07-24 10:29:04,782][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[42283],
        [41226],
        [23333],
        [32315],
        [31966],
        [23063],
        [27515],
        [25765],
        [22882],
        [29366],
        [27643],
        [29130],
        [29783],
        [23120]], device='cuda:0')
[2024-07-24 10:29:04,784][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[35215],
        [32896],
        [34172],
        [34412],
        [35080],
        [35092],
        [34744],
        [34720],
        [34767],
        [34762],
        [34755],
        [34634],
        [34657],
        [34646]], device='cuda:0')
[2024-07-24 10:29:04,785][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[22548],
        [30242],
        [32780],
        [34891],
        [36202],
        [36829],
        [36434],
        [36169],
        [35643],
        [35712],
        [35750],
        [35777],
        [35739],
        [35709]], device='cuda:0')
[2024-07-24 10:29:04,787][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 1680],
        [12452],
        [37044],
        [22879],
        [34870],
        [37408],
        [34456],
        [29258],
        [39229],
        [30788],
        [31891],
        [33411],
        [10757],
        [38012]], device='cuda:0')
[2024-07-24 10:29:04,788][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[12845],
        [12984],
        [13055],
        [12559],
        [10897],
        [10211],
        [ 9806],
        [11544],
        [12929],
        [10856],
        [11676],
        [ 9650],
        [12142],
        [10719]], device='cuda:0')
[2024-07-24 10:29:04,790][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[6334],
        [5854],
        [4177],
        [3074],
        [ 557],
        [3066],
        [1117],
        [2894],
        [3622],
        [1966],
        [1022],
        [ 782],
        [3990],
        [2544]], device='cuda:0')
[2024-07-24 10:29:04,791][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[31166],
        [31166],
        [31166],
        [31166],
        [31166],
        [31166],
        [31166],
        [31166],
        [31166],
        [31166],
        [31166],
        [31166],
        [31166],
        [31166]], device='cuda:0')
[2024-07-24 10:29:04,855][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:29:04,857][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:04,857][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:04,858][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:04,859][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:04,859][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:04,860][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:04,861][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:04,862][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:04,863][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:04,865][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:04,866][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:04,867][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:04,869][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Amanda] are: tensor([0.1131, 0.8869], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:04,870][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Amanda] are: tensor([0.6734, 0.3266], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:04,872][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Amanda] are: tensor([0.8452, 0.1548], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:04,873][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Amanda] are: tensor([0.1466, 0.8534], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:04,875][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Amanda] are: tensor([0.7737, 0.2263], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:04,876][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Amanda] are: tensor([0.5668, 0.4332], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:04,877][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Amanda] are: tensor([0.0257, 0.9743], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:04,878][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Amanda] are: tensor([0.3801, 0.6199], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:04,880][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Amanda] are: tensor([0.8837, 0.1163], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:04,881][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Amanda] are: tensor([0.4399, 0.5601], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:04,883][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Amanda] are: tensor([0.5008, 0.4992], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:04,883][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Amanda] are: tensor([0.1845, 0.8155], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:04,884][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0870, 0.4351, 0.4779], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:04,885][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.2968, 0.4187, 0.2845], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:04,886][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.6702, 0.1601, 0.1696], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:04,887][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0807, 0.4490, 0.4703], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:04,889][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.8467, 0.1212, 0.0321], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:04,890][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.2884, 0.4467, 0.2649], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:04,892][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0128, 0.5042, 0.4829], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:04,894][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.2223, 0.4376, 0.3401], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:04,895][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.5394, 0.3374, 0.1232], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:04,897][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0310, 0.5602, 0.4088], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:04,898][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.2923, 0.3335, 0.3742], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:04,900][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.1461, 0.6397, 0.2142], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:04,902][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ John] are: tensor([0.0583, 0.2520, 0.3090, 0.3807], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:04,903][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ John] are: tensor([0.3734, 0.2990, 0.2251, 0.1025], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:04,905][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ John] are: tensor([0.5213, 0.1383, 0.1467, 0.1937], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:04,906][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ John] are: tensor([0.0513, 0.3079, 0.3255, 0.3153], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:04,908][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ John] are: tensor([0.7151, 0.1213, 0.0195, 0.1441], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:04,910][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ John] are: tensor([0.4142, 0.2774, 0.1945, 0.1139], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:04,911][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ John] are: tensor([0.0082, 0.3416, 0.3260, 0.3242], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:04,913][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ John] are: tensor([0.1812, 0.3179, 0.2493, 0.2516], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:04,914][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ John] are: tensor([0.8066, 0.1051, 0.0601, 0.0283], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:04,915][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ John] are: tensor([0.5272, 0.2801, 0.1843, 0.0084], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:04,915][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ John] are: tensor([0.2382, 0.2306, 0.2632, 0.2681], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:04,916][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ John] are: tensor([0.0924, 0.4618, 0.2106, 0.2352], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:04,918][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ went] are: tensor([0.0452, 0.1961, 0.2296, 0.2882, 0.2410], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:04,919][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ went] are: tensor([0.1288, 0.2268, 0.1760, 0.0815, 0.3869], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:04,921][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ went] are: tensor([0.3498, 0.1232, 0.1270, 0.1624, 0.2375], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:04,923][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ went] are: tensor([0.0357, 0.2369, 0.2517, 0.2429, 0.2328], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:04,924][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ went] are: tensor([0.8350, 0.0681, 0.0139, 0.0561, 0.0269], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:04,926][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ went] are: tensor([0.1835, 0.2378, 0.1533, 0.1286, 0.2967], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:04,927][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ went] are: tensor([0.0057, 0.2572, 0.2449, 0.2428, 0.2494], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:04,929][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ went] are: tensor([0.1134, 0.2604, 0.1985, 0.2072, 0.2205], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:04,930][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.4687, 0.2207, 0.0940, 0.0915, 0.1251], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:04,932][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ went] are: tensor([0.0525, 0.1990, 0.2972, 0.2297, 0.2216], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:04,934][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ went] are: tensor([0.1899, 0.1817, 0.2171, 0.2109, 0.2005], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:04,935][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ went] are: tensor([0.0598, 0.3775, 0.1724, 0.2196, 0.1707], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:04,937][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0700, 0.1494, 0.1725, 0.2023, 0.1735, 0.2323], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:04,939][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.1871, 0.1971, 0.1487, 0.0650, 0.2347, 0.1674], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:04,940][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.3238, 0.1138, 0.1142, 0.1321, 0.1855, 0.1305], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:04,942][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0295, 0.1933, 0.2037, 0.1991, 0.1902, 0.1843], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:04,944][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.6901, 0.1093, 0.0320, 0.0844, 0.0561, 0.0280], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:04,945][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.2409, 0.1772, 0.0995, 0.0960, 0.1586, 0.2277], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:04,946][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0042, 0.2076, 0.1979, 0.1959, 0.2010, 0.1934], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:04,947][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0971, 0.2245, 0.1621, 0.1841, 0.1869, 0.1453], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:04,948][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.5680, 0.1311, 0.0516, 0.0642, 0.0933, 0.0918], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:04,949][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0017, 0.1519, 0.1967, 0.0686, 0.3089, 0.2721], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:04,951][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.1590, 0.1534, 0.1778, 0.1744, 0.1605, 0.1748], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:04,952][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0490, 0.3630, 0.1194, 0.1975, 0.1663, 0.1047], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:04,954][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0631, 0.1243, 0.1490, 0.1650, 0.1400, 0.1839, 0.1747],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:04,956][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.1772, 0.1446, 0.1186, 0.0471, 0.2024, 0.2014, 0.1088],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:04,957][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.2785, 0.0937, 0.0927, 0.1107, 0.1520, 0.1154, 0.1570],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:04,959][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0257, 0.1628, 0.1709, 0.1672, 0.1597, 0.1549, 0.1589],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:04,961][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.6742, 0.1011, 0.0260, 0.0965, 0.0521, 0.0238, 0.0264],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:04,962][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.2118, 0.1471, 0.0934, 0.0691, 0.1549, 0.2260, 0.0977],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:04,964][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0038, 0.1732, 0.1656, 0.1642, 0.1687, 0.1621, 0.1623],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:04,966][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0894, 0.1914, 0.1423, 0.1563, 0.1636, 0.1310, 0.1260],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:04,967][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.5117, 0.1143, 0.0575, 0.0507, 0.0606, 0.1521, 0.0532],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:04,969][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0106, 0.1190, 0.1247, 0.0705, 0.2712, 0.3434, 0.0607],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:04,971][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.1326, 0.1304, 0.1523, 0.1499, 0.1355, 0.1535, 0.1458],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:04,972][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0628, 0.3069, 0.1141, 0.1695, 0.1429, 0.1143, 0.0896],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:04,974][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ station] are: tensor([0.0310, 0.0986, 0.1247, 0.1480, 0.1257, 0.1693, 0.1674, 0.1352],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:04,976][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ station] are: tensor([0.1142, 0.1268, 0.0953, 0.0399, 0.2829, 0.1555, 0.0971, 0.0883],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:04,976][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ station] are: tensor([0.2014, 0.0796, 0.0819, 0.1054, 0.1673, 0.1033, 0.1360, 0.1250],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:04,977][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ station] are: tensor([0.0248, 0.1370, 0.1446, 0.1402, 0.1349, 0.1316, 0.1352, 0.1515],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:04,978][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ station] are: tensor([0.8535, 0.0408, 0.0067, 0.0367, 0.0177, 0.0048, 0.0051, 0.0348],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:04,979][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ station] are: tensor([0.2640, 0.1029, 0.0748, 0.0695, 0.1419, 0.1969, 0.0841, 0.0657],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:04,980][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ station] are: tensor([0.0036, 0.1475, 0.1410, 0.1402, 0.1447, 0.1393, 0.1393, 0.1442],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:04,981][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ station] are: tensor([0.1141, 0.1704, 0.1212, 0.1286, 0.1378, 0.1182, 0.1138, 0.0960],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:04,983][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ station] are: tensor([0.6711, 0.0894, 0.0241, 0.0428, 0.0504, 0.0511, 0.0475, 0.0236],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:04,985][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ station] are: tensor([0.0791, 0.1150, 0.1139, 0.1673, 0.1688, 0.1546, 0.1106, 0.0906],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:04,986][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ station] are: tensor([0.1210, 0.1142, 0.1363, 0.1297, 0.1175, 0.1322, 0.1301, 0.1189],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:04,988][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ station] are: tensor([0.0432, 0.2399, 0.1118, 0.1306, 0.1150, 0.1055, 0.0890, 0.1650],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:04,989][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0424, 0.0954, 0.1130, 0.1272, 0.1091, 0.1378, 0.1350, 0.1169, 0.1232],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:04,991][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.1301, 0.1260, 0.0763, 0.0475, 0.2087, 0.1271, 0.1013, 0.1213, 0.0616],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:04,993][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.2022, 0.0801, 0.0786, 0.0901, 0.1229, 0.0920, 0.1234, 0.1046, 0.1060],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:04,994][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0203, 0.1203, 0.1261, 0.1236, 0.1180, 0.1144, 0.1180, 0.1334, 0.1259],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:04,996][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.5853, 0.0686, 0.0261, 0.0920, 0.0420, 0.0190, 0.0263, 0.0932, 0.0474],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:04,998][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.1221, 0.1268, 0.0837, 0.0644, 0.1493, 0.1670, 0.0822, 0.1508, 0.0536],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:05,000][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0027, 0.1300, 0.1242, 0.1233, 0.1272, 0.1219, 0.1220, 0.1262, 0.1225],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:05,001][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0724, 0.1534, 0.1141, 0.1268, 0.1344, 0.1034, 0.1014, 0.1025, 0.0917],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:05,003][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.3509, 0.1490, 0.0567, 0.0751, 0.0805, 0.1236, 0.0928, 0.0487, 0.0227],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:05,005][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0054, 0.1006, 0.0693, 0.0681, 0.1680, 0.2217, 0.0943, 0.1795, 0.0930],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:05,007][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0967, 0.1023, 0.1171, 0.1159, 0.1068, 0.1205, 0.1186, 0.1118, 0.1104],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:05,008][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0593, 0.2125, 0.0766, 0.1387, 0.1061, 0.0774, 0.0752, 0.1771, 0.0771],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:05,009][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ John] are: tensor([0.0352, 0.0787, 0.1000, 0.1116, 0.0916, 0.1276, 0.1245, 0.1053, 0.1145,
        0.1110], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:05,009][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ John] are: tensor([0.2346, 0.1072, 0.0720, 0.0290, 0.1493, 0.1054, 0.0866, 0.0777, 0.0712,
        0.0670], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:05,010][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ John] are: tensor([0.2016, 0.0659, 0.0625, 0.0864, 0.1237, 0.0765, 0.1065, 0.1020, 0.0941,
        0.0810], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:05,012][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ John] are: tensor([0.0189, 0.1063, 0.1125, 0.1093, 0.1044, 0.1019, 0.1045, 0.1183, 0.1121,
        0.1118], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:05,013][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ John] are: tensor([0.4797, 0.0817, 0.0137, 0.1029, 0.0386, 0.0155, 0.0179, 0.1093, 0.0398,
        0.1009], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:05,015][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ John] are: tensor([0.2289, 0.1166, 0.0782, 0.0508, 0.1079, 0.1492, 0.0613, 0.0954, 0.0462,
        0.0655], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:05,016][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ John] are: tensor([0.0026, 0.1157, 0.1103, 0.1101, 0.1129, 0.1084, 0.1086, 0.1120, 0.1089,
        0.1106], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:05,018][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ John] are: tensor([0.0690, 0.1345, 0.1018, 0.1077, 0.1186, 0.0983, 0.0938, 0.0909, 0.0846,
        0.1007], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:05,020][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ John] are: tensor([0.7037, 0.0524, 0.0301, 0.0181, 0.0296, 0.0474, 0.0333, 0.0296, 0.0134,
        0.0425], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:05,021][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ John] are: tensor([0.0309, 0.0794, 0.0645, 0.0039, 0.1357, 0.1420, 0.0668, 0.3144, 0.1535,
        0.0089], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:05,023][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ John] are: tensor([0.1013, 0.0919, 0.1049, 0.1031, 0.0919, 0.1034, 0.1019, 0.1002, 0.1001,
        0.1013], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:05,025][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ John] are: tensor([0.0378, 0.1952, 0.0936, 0.1017, 0.0852, 0.0901, 0.0793, 0.1441, 0.0838,
        0.0892], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:05,027][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.0279, 0.0710, 0.0859, 0.1021, 0.0895, 0.1216, 0.1176, 0.0982, 0.1014,
        0.1038, 0.0810], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:05,028][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0826, 0.0817, 0.0744, 0.0299, 0.1901, 0.1193, 0.0864, 0.0683, 0.0705,
        0.0597, 0.1371], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:05,030][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.1383, 0.0682, 0.0644, 0.0743, 0.1173, 0.0735, 0.0968, 0.0893, 0.0889,
        0.0675, 0.1214], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:05,032][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.0165, 0.0960, 0.1015, 0.0981, 0.0939, 0.0916, 0.0941, 0.1060, 0.1005,
        0.1002, 0.1015], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:05,034][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.6332, 0.0525, 0.0081, 0.0550, 0.0328, 0.0090, 0.0137, 0.0533, 0.0234,
        0.0553, 0.0636], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:05,035][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.1114, 0.1087, 0.0632, 0.0666, 0.1116, 0.1412, 0.0733, 0.0833, 0.0455,
        0.1117, 0.0836], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:05,037][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0024, 0.1035, 0.0989, 0.0984, 0.1015, 0.0973, 0.0973, 0.1006, 0.0978,
        0.0990, 0.1034], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:05,039][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0517, 0.1241, 0.0937, 0.1019, 0.1038, 0.0878, 0.0853, 0.0820, 0.0773,
        0.0964, 0.0960], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:05,039][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.3304, 0.1156, 0.0327, 0.0555, 0.0570, 0.0714, 0.0719, 0.0336, 0.0259,
        0.1524, 0.0533], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:05,040][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.0028, 0.0253, 0.0290, 0.0334, 0.2095, 0.1370, 0.1246, 0.2062, 0.1103,
        0.0788, 0.0431], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:05,041][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.1006, 0.0843, 0.1028, 0.0952, 0.0840, 0.0933, 0.0937, 0.0871, 0.0918,
        0.0912, 0.0760], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:05,042][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0283, 0.1736, 0.0823, 0.0965, 0.0875, 0.0770, 0.0724, 0.1360, 0.0815,
        0.0853, 0.0796], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:05,044][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0360, 0.0689, 0.0846, 0.0931, 0.0780, 0.1040, 0.0999, 0.0850, 0.0932,
        0.0909, 0.0730, 0.0935], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:05,045][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.1392, 0.0735, 0.0557, 0.0298, 0.0975, 0.0840, 0.0613, 0.0814, 0.0638,
        0.0775, 0.1083, 0.1282], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:05,047][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.1503, 0.0614, 0.0595, 0.0672, 0.0958, 0.0699, 0.0930, 0.0795, 0.0833,
        0.0611, 0.1061, 0.0729], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:05,048][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0143, 0.0868, 0.0917, 0.0894, 0.0852, 0.0829, 0.0855, 0.0970, 0.0916,
        0.0919, 0.0929, 0.0908], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:05,050][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.5486, 0.0590, 0.0196, 0.0649, 0.0344, 0.0147, 0.0158, 0.0547, 0.0347,
        0.0605, 0.0716, 0.0216], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:05,052][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.1620, 0.0739, 0.0487, 0.0472, 0.0788, 0.1108, 0.0534, 0.0736, 0.0479,
        0.0935, 0.0988, 0.1114], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:05,053][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0021, 0.0941, 0.0897, 0.0894, 0.0921, 0.0881, 0.0883, 0.0914, 0.0886,
        0.0900, 0.0938, 0.0924], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:05,055][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0476, 0.1135, 0.0856, 0.0954, 0.1005, 0.0794, 0.0753, 0.0768, 0.0696,
        0.0893, 0.0907, 0.0763], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:05,057][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.3767, 0.0660, 0.0298, 0.0380, 0.0309, 0.0619, 0.0314, 0.0243, 0.0241,
        0.1315, 0.0689, 0.1167], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:05,059][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0049, 0.0470, 0.0784, 0.0406, 0.1133, 0.1874, 0.0541, 0.1360, 0.1451,
        0.0649, 0.0906, 0.0378], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:05,060][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0795, 0.0783, 0.0910, 0.0892, 0.0779, 0.0864, 0.0862, 0.0834, 0.0846,
        0.0874, 0.0728, 0.0833], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:05,062][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0395, 0.1612, 0.0664, 0.0945, 0.0835, 0.0697, 0.0572, 0.1388, 0.0689,
        0.0866, 0.0834, 0.0503], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:05,064][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ ring] are: tensor([0.0249, 0.0588, 0.0777, 0.0850, 0.0702, 0.0962, 0.0954, 0.0779, 0.0922,
        0.0836, 0.0667, 0.0903, 0.0813], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:05,066][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ ring] are: tensor([0.1550, 0.0883, 0.0507, 0.0296, 0.0846, 0.0648, 0.0488, 0.0464, 0.0577,
        0.0617, 0.1170, 0.1175, 0.0779], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:05,067][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ ring] are: tensor([0.1434, 0.0518, 0.0554, 0.0638, 0.1012, 0.0639, 0.0831, 0.0746, 0.0712,
        0.0557, 0.0983, 0.0623, 0.0753], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:05,069][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ ring] are: tensor([0.0127, 0.0799, 0.0849, 0.0819, 0.0780, 0.0763, 0.0787, 0.0885, 0.0842,
        0.0840, 0.0849, 0.0830, 0.0829], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:05,070][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ ring] are: tensor([0.6331, 0.0720, 0.0101, 0.0537, 0.0259, 0.0068, 0.0087, 0.0490, 0.0200,
        0.0451, 0.0350, 0.0155, 0.0252], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:05,071][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ ring] are: tensor([0.1152, 0.0844, 0.0639, 0.0577, 0.1009, 0.0876, 0.0477, 0.0753, 0.0407,
        0.0679, 0.0986, 0.0988, 0.0612], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:05,072][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ ring] are: tensor([0.0021, 0.0863, 0.0820, 0.0819, 0.0842, 0.0806, 0.0807, 0.0835, 0.0810,
        0.0822, 0.0856, 0.0843, 0.0856], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:05,073][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ ring] are: tensor([0.0636, 0.1097, 0.0799, 0.0834, 0.0898, 0.0767, 0.0730, 0.0655, 0.0655,
        0.0774, 0.0843, 0.0753, 0.0559], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:05,075][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ ring] are: tensor([0.3209, 0.0958, 0.0211, 0.0509, 0.0352, 0.0307, 0.0323, 0.0214, 0.0108,
        0.1002, 0.0714, 0.1701, 0.0393], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:05,076][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ ring] are: tensor([0.1012, 0.0579, 0.0764, 0.0388, 0.0674, 0.1178, 0.0450, 0.0452, 0.0804,
        0.0420, 0.0559, 0.0615, 0.2103], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:05,078][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ ring] are: tensor([0.0807, 0.0704, 0.0834, 0.0798, 0.0711, 0.0804, 0.0819, 0.0764, 0.0790,
        0.0797, 0.0671, 0.0799, 0.0702], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:05,080][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ ring] are: tensor([0.0292, 0.1463, 0.0661, 0.0901, 0.0759, 0.0661, 0.0571, 0.1105, 0.0634,
        0.0790, 0.0744, 0.0559, 0.0859], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:05,081][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0322, 0.0563, 0.0671, 0.0749, 0.0629, 0.0839, 0.0848, 0.0688, 0.0786,
        0.0782, 0.0605, 0.0821, 0.0793, 0.0904], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:05,083][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.1493, 0.0655, 0.0522, 0.0221, 0.0555, 0.0586, 0.0547, 0.0555, 0.0504,
        0.0547, 0.0844, 0.1378, 0.0646, 0.0947], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:05,085][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1353, 0.0496, 0.0512, 0.0568, 0.0830, 0.0596, 0.0816, 0.0687, 0.0690,
        0.0506, 0.0937, 0.0635, 0.0713, 0.0660], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:05,086][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0121, 0.0736, 0.0774, 0.0759, 0.0722, 0.0701, 0.0724, 0.0822, 0.0780,
        0.0780, 0.0792, 0.0772, 0.0775, 0.0744], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:05,088][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.4227, 0.0740, 0.0242, 0.0549, 0.0396, 0.0196, 0.0208, 0.0896, 0.0407,
        0.0484, 0.0747, 0.0276, 0.0417, 0.0215], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:05,090][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.1641, 0.0608, 0.0369, 0.0384, 0.0452, 0.0737, 0.0423, 0.0532, 0.0365,
        0.0768, 0.0703, 0.0826, 0.0614, 0.1579], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:05,092][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0018, 0.0793, 0.0757, 0.0752, 0.0775, 0.0745, 0.0744, 0.0771, 0.0748,
        0.0757, 0.0790, 0.0777, 0.0788, 0.0784], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:05,093][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0437, 0.1039, 0.0745, 0.0865, 0.0835, 0.0655, 0.0652, 0.0674, 0.0597,
        0.0808, 0.0767, 0.0664, 0.0596, 0.0667], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:05,095][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.4596, 0.0300, 0.0147, 0.0189, 0.0189, 0.0194, 0.0255, 0.0122, 0.0121,
        0.0689, 0.0423, 0.1124, 0.0881, 0.0770], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:05,097][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0010, 0.0532, 0.0960, 0.0357, 0.1370, 0.1146, 0.0724, 0.0606, 0.1171,
        0.0481, 0.0903, 0.0377, 0.0631, 0.0732], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:05,099][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0740, 0.0681, 0.0796, 0.0764, 0.0671, 0.0745, 0.0737, 0.0710, 0.0731,
        0.0737, 0.0615, 0.0706, 0.0654, 0.0712], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:05,101][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0226, 0.1461, 0.0528, 0.0850, 0.0719, 0.0480, 0.0480, 0.1316, 0.0560,
        0.0785, 0.0691, 0.0473, 0.0916, 0.0516], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:05,161][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:29:05,162][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:05,163][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:05,165][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:05,166][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:05,167][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:05,168][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:05,168][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:05,169][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:05,170][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:05,170][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:05,171][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:05,172][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:05,172][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Amanda] are: tensor([0.9852, 0.0148], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:05,173][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Amanda] are: tensor([0.6460, 0.3540], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:05,174][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Amanda] are: tensor([0.9805, 0.0195], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:05,174][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Amanda] are: tensor([0.0890, 0.9110], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:05,176][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Amanda] are: tensor([0.6465, 0.3535], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:05,178][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Amanda] are: tensor([0.6993, 0.3007], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:05,179][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Amanda] are: tensor([9.9999e-01, 1.2139e-05], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:05,180][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Amanda] are: tensor([0.6250, 0.3750], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:05,181][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Amanda] are: tensor([9.9968e-01, 3.2199e-04], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:05,182][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Amanda] are: tensor([0.0098, 0.9902], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:05,182][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Amanda] are: tensor([0.0932, 0.9068], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:05,183][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Amanda] are: tensor([0.0282, 0.9718], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:05,184][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.9775, 0.0180, 0.0045], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:05,185][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.1456, 0.5556, 0.2989], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:05,187][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.9695, 0.0160, 0.0145], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:05,189][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0443, 0.4719, 0.4838], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:05,190][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.7412, 0.1711, 0.0877], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:05,191][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.4299, 0.5069, 0.0632], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:05,192][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([9.9999e-01, 6.9042e-06, 4.3263e-06], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:05,194][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2247, 0.6814, 0.0939], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:05,195][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([9.9943e-01, 5.5183e-04, 2.1918e-05], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:05,197][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0040, 0.5314, 0.4645], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:05,198][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0500, 0.4732, 0.4767], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:05,200][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0256, 0.5015, 0.4728], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:05,202][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ John] are: tensor([0.9432, 0.0282, 0.0108, 0.0178], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:05,203][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ John] are: tensor([0.2651, 0.3050, 0.3187, 0.1112], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:05,205][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ John] are: tensor([0.9575, 0.0178, 0.0148, 0.0099], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:05,206][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ John] are: tensor([0.0300, 0.3172, 0.3246, 0.3282], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:05,208][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ John] are: tensor([0.3759, 0.1938, 0.0696, 0.3607], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:05,210][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ John] are: tensor([0.3169, 0.3154, 0.2435, 0.1242], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:05,211][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ John] are: tensor([9.9998e-01, 1.0561e-05, 6.7556e-06, 4.4632e-06], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:05,212][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ John] are: tensor([0.1916, 0.3834, 0.1590, 0.2660], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:05,213][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ John] are: tensor([9.9844e-01, 6.7026e-04, 6.7567e-04, 2.1900e-04], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:05,214][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ John] are: tensor([0.0025, 0.2837, 0.2635, 0.4503], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:05,214][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ John] are: tensor([0.0329, 0.3211, 0.3231, 0.3229], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:05,215][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ John] are: tensor([0.0151, 0.2518, 0.2731, 0.4601], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:05,217][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([0.8069, 0.0703, 0.0153, 0.0341, 0.0734], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:05,218][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([0.0821, 0.1986, 0.1651, 0.0635, 0.4906], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:05,220][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([0.9579, 0.0147, 0.0126, 0.0082, 0.0066], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:05,221][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([0.0212, 0.2408, 0.2449, 0.2472, 0.2458], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:05,223][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([0.4758, 0.1360, 0.1294, 0.1649, 0.0938], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:05,224][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([0.3125, 0.3912, 0.0709, 0.1617, 0.0637], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:05,226][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([9.9994e-01, 1.9522e-05, 1.1918e-05, 7.6699e-06, 2.0020e-05],
       device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:05,227][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([0.1261, 0.1797, 0.3804, 0.2707, 0.0430], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:05,228][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([9.9676e-01, 1.4742e-03, 9.1499e-04, 5.1761e-04, 3.3192e-04],
       device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:05,230][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([0.0014, 0.1687, 0.1697, 0.3389, 0.3213], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:05,232][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([0.0226, 0.2417, 0.2468, 0.2429, 0.2460], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:05,233][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([0.0103, 0.1729, 0.1949, 0.3263, 0.2955], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:05,235][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.8637, 0.0393, 0.0095, 0.0248, 0.0527, 0.0101], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:05,237][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.1327, 0.2033, 0.1654, 0.0541, 0.2699, 0.1746], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:05,238][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.9446, 0.0161, 0.0144, 0.0087, 0.0072, 0.0091], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:05,240][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0167, 0.1931, 0.1968, 0.1999, 0.1995, 0.1940], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:05,242][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.2917, 0.1486, 0.1627, 0.1929, 0.1163, 0.0878], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:05,243][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.1036, 0.3766, 0.0666, 0.3012, 0.0908, 0.0612], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:05,244][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([9.9988e-01, 3.0862e-05, 1.9177e-05, 1.1170e-05, 2.6700e-05, 3.4863e-05],
       device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:05,245][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.1157, 0.2158, 0.0929, 0.4210, 0.0880, 0.0666], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:05,245][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([9.9851e-01, 7.6796e-04, 7.7790e-05, 2.8540e-04, 3.4885e-04, 1.3885e-05],
       device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:05,246][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0011, 0.1063, 0.1037, 0.1976, 0.2054, 0.3859], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:05,248][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0140, 0.1999, 0.2016, 0.1997, 0.2006, 0.1842], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:05,249][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0146, 0.1132, 0.1280, 0.2072, 0.1853, 0.3516], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:05,251][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.6896, 0.0600, 0.0201, 0.0446, 0.0956, 0.0285, 0.0617],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:05,253][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.1230, 0.1434, 0.1183, 0.0343, 0.2166, 0.2640, 0.1005],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:05,254][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.9338, 0.0163, 0.0151, 0.0088, 0.0072, 0.0091, 0.0097],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:05,256][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0145, 0.1609, 0.1636, 0.1666, 0.1656, 0.1613, 0.1674],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:05,258][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.3140, 0.1473, 0.0889, 0.2039, 0.1111, 0.0597, 0.0751],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:05,259][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.1308, 0.3051, 0.0545, 0.2439, 0.1190, 0.0453, 0.1015],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:05,260][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([9.9988e-01, 2.3683e-05, 1.6178e-05, 9.0658e-06, 2.1254e-05, 2.5823e-05,
        1.9141e-05], device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:05,262][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0920, 0.1860, 0.0868, 0.2596, 0.1620, 0.1432, 0.0704],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:05,263][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([9.9412e-01, 1.8228e-03, 6.5704e-04, 1.0488e-03, 1.8400e-03, 2.9967e-04,
        2.1369e-04], device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:05,265][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0010, 0.0827, 0.0828, 0.1453, 0.1456, 0.2807, 0.2619],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:05,267][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0131, 0.1701, 0.1722, 0.1709, 0.1708, 0.1584, 0.1445],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:05,269][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0122, 0.0960, 0.1012, 0.1657, 0.1454, 0.2736, 0.2059],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:05,270][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ station] are: tensor([0.6546, 0.0543, 0.0161, 0.0387, 0.0803, 0.0213, 0.0570, 0.0777],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:05,272][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ station] are: tensor([0.0534, 0.0998, 0.0959, 0.0285, 0.3159, 0.1824, 0.1129, 0.1113],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:05,274][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ station] are: tensor([0.9334, 0.0154, 0.0134, 0.0081, 0.0065, 0.0084, 0.0089, 0.0059],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:05,275][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ station] are: tensor([0.0150, 0.1355, 0.1378, 0.1394, 0.1391, 0.1358, 0.1406, 0.1568],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:05,276][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ station] are: tensor([0.5256, 0.0913, 0.0534, 0.1096, 0.0537, 0.0273, 0.0394, 0.0997],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:05,277][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ station] are: tensor([0.1043, 0.2211, 0.0912, 0.2263, 0.1554, 0.0692, 0.0880, 0.0445],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:05,277][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ station] are: tensor([9.9996e-01, 7.9751e-06, 5.3292e-06, 2.9628e-06, 7.5409e-06, 9.6113e-06,
        6.5832e-06, 3.0543e-06], device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:05,279][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ station] are: tensor([0.0520, 0.1644, 0.0611, 0.2490, 0.1684, 0.1248, 0.1141, 0.0662],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:05,280][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ station] are: tensor([9.9810e-01, 8.1302e-04, 2.8822e-04, 2.4593e-04, 2.9074e-04, 5.5917e-05,
        1.1790e-04, 8.8446e-05], device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:05,282][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ station] are: tensor([0.0006, 0.0652, 0.0656, 0.1259, 0.1218, 0.2260, 0.2226, 0.1723],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:05,283][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ station] are: tensor([0.0157, 0.1430, 0.1472, 0.1448, 0.1466, 0.1349, 0.1252, 0.1427],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:05,285][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ station] are: tensor([0.0068, 0.0769, 0.0888, 0.1458, 0.1288, 0.2437, 0.1848, 0.1243],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:05,287][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.5544, 0.0642, 0.0179, 0.0437, 0.0910, 0.0178, 0.0508, 0.0988, 0.0613],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:05,288][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0683, 0.0992, 0.0697, 0.0389, 0.2743, 0.1285, 0.0991, 0.1501, 0.0719],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:05,290][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.9530, 0.0104, 0.0090, 0.0054, 0.0043, 0.0057, 0.0059, 0.0040, 0.0023],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:05,292][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0114, 0.1176, 0.1199, 0.1223, 0.1217, 0.1185, 0.1230, 0.1376, 0.1279],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:05,294][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.2505, 0.0813, 0.0895, 0.1595, 0.0672, 0.0418, 0.0852, 0.1032, 0.1217],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:05,295][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.1490, 0.2413, 0.0363, 0.1843, 0.1090, 0.0337, 0.0953, 0.0887, 0.0624],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:05,296][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([9.9986e-01, 2.3925e-05, 1.7973e-05, 9.9759e-06, 2.0315e-05, 2.6828e-05,
        1.8664e-05, 8.7485e-06, 1.6704e-05], device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:05,298][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0497, 0.1417, 0.0478, 0.2741, 0.1578, 0.0787, 0.1466, 0.0827, 0.0209],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:05,299][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([9.9872e-01, 4.4091e-04, 6.0573e-05, 1.9023e-04, 2.7191e-04, 2.8520e-05,
        9.0693e-05, 1.9261e-04, 8.1570e-06], device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:05,301][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0007, 0.0556, 0.0503, 0.1003, 0.1055, 0.1935, 0.1849, 0.1505, 0.1588],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:05,302][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0125, 0.1270, 0.1298, 0.1268, 0.1263, 0.1195, 0.1097, 0.1261, 0.1223],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:05,304][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0091, 0.0754, 0.0753, 0.1331, 0.1127, 0.1997, 0.1619, 0.1145, 0.1184],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:05,306][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ John] are: tensor([0.6594, 0.0372, 0.0119, 0.0241, 0.0490, 0.0168, 0.0426, 0.0733, 0.0523,
        0.0335], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:05,307][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ John] are: tensor([0.1377, 0.0858, 0.0778, 0.0244, 0.1703, 0.1335, 0.1033, 0.0934, 0.1055,
        0.0684], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:05,307][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ John] are: tensor([0.9311, 0.0146, 0.0125, 0.0074, 0.0060, 0.0078, 0.0083, 0.0055, 0.0037,
        0.0030], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:05,308][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ John] are: tensor([0.0112, 0.1041, 0.1061, 0.1078, 0.1073, 0.1046, 0.1083, 0.1210, 0.1129,
        0.1166], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:05,309][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ John] are: tensor([0.1488, 0.0824, 0.0424, 0.1843, 0.0558, 0.0420, 0.0485, 0.1578, 0.0921,
        0.1459], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:05,311][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ John] are: tensor([0.1146, 0.1451, 0.1186, 0.0849, 0.0633, 0.0665, 0.0951, 0.1282, 0.0982,
        0.0856], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:05,312][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ John] are: tensor([9.9979e-01, 3.1654e-05, 2.1799e-05, 1.4641e-05, 2.5402e-05, 3.3794e-05,
        2.5390e-05, 1.1361e-05, 2.1317e-05, 2.7948e-05], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:05,314][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ John] are: tensor([0.1123, 0.1669, 0.0682, 0.1111, 0.0210, 0.1362, 0.0757, 0.0831, 0.0441,
        0.1815], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:05,315][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ John] are: tensor([9.9441e-01, 8.5960e-04, 9.8559e-04, 2.9689e-04, 1.3487e-03, 3.9502e-04,
        4.1712e-04, 7.6597e-04, 3.0066e-04, 2.1894e-04], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:05,316][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ John] are: tensor([0.0006, 0.0480, 0.0471, 0.0714, 0.0806, 0.1417, 0.1336, 0.1143, 0.1313,
        0.2313], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:05,318][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ John] are: tensor([0.0107, 0.1129, 0.1134, 0.1140, 0.1134, 0.1049, 0.0968, 0.1134, 0.1089,
        0.1117], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:05,319][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ John] are: tensor([0.0072, 0.0613, 0.0663, 0.1086, 0.0995, 0.1841, 0.1380, 0.0981, 0.1076,
        0.1292], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:05,321][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.4597, 0.0702, 0.0169, 0.0383, 0.0774, 0.0204, 0.0502, 0.1006, 0.0532,
        0.0441, 0.0688], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:05,323][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0343, 0.0528, 0.0662, 0.0164, 0.2385, 0.1144, 0.0844, 0.0726, 0.1035,
        0.0442, 0.1727], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:05,325][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.9378, 0.0130, 0.0109, 0.0064, 0.0053, 0.0067, 0.0071, 0.0046, 0.0030,
        0.0025, 0.0026], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:05,326][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.0103, 0.0934, 0.0947, 0.0959, 0.0956, 0.0934, 0.0966, 0.1074, 0.1001,
        0.1034, 0.1092], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:05,328][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.1647, 0.0798, 0.0379, 0.1374, 0.0789, 0.0336, 0.0613, 0.1101, 0.0842,
        0.1218, 0.0903], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:05,330][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.1742, 0.1567, 0.0830, 0.1071, 0.0429, 0.0411, 0.0684, 0.0803, 0.1010,
        0.0997, 0.0457], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:05,331][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([9.9987e-01, 1.8723e-05, 1.1212e-05, 7.3380e-06, 1.5370e-05, 1.8959e-05,
        1.3401e-05, 6.0333e-06, 1.1079e-05, 1.3425e-05, 1.1051e-05],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:05,333][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0419, 0.0697, 0.0681, 0.1619, 0.0405, 0.1058, 0.1150, 0.0655, 0.0446,
        0.2587, 0.0280], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:05,334][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([9.9528e-01, 1.3457e-03, 6.8190e-04, 3.8999e-04, 6.5567e-04, 1.3541e-04,
        3.5749e-04, 5.6485e-04, 1.4570e-04, 2.8891e-04, 1.5279e-04],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:05,336][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.0005, 0.0321, 0.0336, 0.0590, 0.0630, 0.1078, 0.1115, 0.0890, 0.1052,
        0.2005, 0.1979], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:05,338][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0084, 0.1015, 0.1050, 0.1020, 0.1027, 0.0967, 0.0887, 0.0993, 0.0984,
        0.0990, 0.0983], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:05,338][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.0055, 0.0526, 0.0613, 0.0980, 0.0875, 0.1694, 0.1313, 0.0862, 0.1010,
        0.1149, 0.0922], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:05,339][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.4050, 0.0473, 0.0143, 0.0333, 0.0685, 0.0168, 0.0464, 0.1052, 0.0604,
        0.0475, 0.0939, 0.0613], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:05,340][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0659, 0.0542, 0.0503, 0.0186, 0.0953, 0.0856, 0.0576, 0.1068, 0.1029,
        0.0685, 0.1344, 0.1599], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:05,342][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.9282, 0.0140, 0.0120, 0.0069, 0.0057, 0.0073, 0.0077, 0.0052, 0.0034,
        0.0028, 0.0029, 0.0039], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:05,344][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0087, 0.0837, 0.0851, 0.0865, 0.0861, 0.0839, 0.0869, 0.0971, 0.0905,
        0.0939, 0.0992, 0.0983], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:05,345][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.1848, 0.0721, 0.0594, 0.1271, 0.0635, 0.0344, 0.0432, 0.0878, 0.0869,
        0.1004, 0.0917, 0.0486], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:05,347][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0827, 0.1471, 0.0304, 0.1682, 0.0466, 0.0291, 0.0713, 0.0741, 0.0736,
        0.1758, 0.0485, 0.0526], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:05,348][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([9.9973e-01, 3.2317e-05, 2.2087e-05, 1.3515e-05, 2.7344e-05, 3.5700e-05,
        2.7378e-05, 1.2833e-05, 2.4119e-05, 2.5847e-05, 2.3174e-05, 2.6190e-05],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:05,350][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0428, 0.0949, 0.0481, 0.1730, 0.0601, 0.0602, 0.0442, 0.0658, 0.0289,
        0.2935, 0.0600, 0.0286], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:05,351][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([9.9057e-01, 1.7021e-03, 8.3169e-04, 1.1593e-03, 1.6856e-03, 2.2086e-04,
        2.7825e-04, 1.5230e-03, 2.0612e-04, 1.0726e-03, 6.6202e-04, 8.4541e-05],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:05,353][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0005, 0.0296, 0.0307, 0.0501, 0.0520, 0.0940, 0.0891, 0.0719, 0.0890,
        0.1644, 0.1700, 0.1588], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:05,354][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0087, 0.0939, 0.0945, 0.0940, 0.0935, 0.0868, 0.0800, 0.0933, 0.0898,
        0.0920, 0.0906, 0.0829], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:05,356][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0067, 0.0498, 0.0550, 0.0880, 0.0811, 0.1486, 0.1097, 0.0758, 0.0888,
        0.1064, 0.0874, 0.1027], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:05,358][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ ring] are: tensor([0.5685, 0.0355, 0.0087, 0.0210, 0.0373, 0.0100, 0.0346, 0.0629, 0.0432,
        0.0281, 0.0506, 0.0482, 0.0514], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:05,360][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ ring] are: tensor([0.0697, 0.0637, 0.0450, 0.0249, 0.0961, 0.0639, 0.0502, 0.0478, 0.0855,
        0.0632, 0.1667, 0.1480, 0.0752], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:05,361][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ ring] are: tensor([0.9158, 0.0160, 0.0131, 0.0075, 0.0062, 0.0081, 0.0083, 0.0056, 0.0036,
        0.0030, 0.0031, 0.0042, 0.0055], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:05,363][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ ring] are: tensor([0.0083, 0.0767, 0.0778, 0.0786, 0.0781, 0.0763, 0.0789, 0.0876, 0.0819,
        0.0849, 0.0895, 0.0891, 0.0923], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:05,365][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ ring] are: tensor([0.2476, 0.1185, 0.0433, 0.1077, 0.0421, 0.0215, 0.0330, 0.0717, 0.0712,
        0.0879, 0.0386, 0.0556, 0.0614], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:05,367][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ ring] are: tensor([0.0504, 0.0862, 0.0286, 0.1832, 0.1060, 0.0416, 0.0395, 0.0352, 0.0607,
        0.1641, 0.0730, 0.0686, 0.0631], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:05,368][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ ring] are: tensor([9.9956e-01, 4.8770e-05, 3.2781e-05, 2.1732e-05, 4.0023e-05, 5.2195e-05,
        3.9209e-05, 1.8484e-05, 3.4287e-05, 4.0044e-05, 3.3945e-05, 3.3868e-05,
        4.5327e-05], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:05,369][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ ring] are: tensor([0.0477, 0.0489, 0.0422, 0.0789, 0.0593, 0.0479, 0.0694, 0.0994, 0.0449,
        0.1023, 0.0544, 0.0359, 0.2688], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:05,370][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ ring] are: tensor([9.9814e-01, 4.6453e-04, 1.8450e-04, 1.8214e-04, 2.4798e-04, 5.4716e-05,
        1.1272e-04, 8.7100e-05, 5.4691e-05, 1.4042e-04, 7.8077e-05, 9.5540e-05,
        1.6112e-04], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:05,370][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ ring] are: tensor([0.0004, 0.0256, 0.0279, 0.0425, 0.0425, 0.0801, 0.0763, 0.0589, 0.0807,
        0.1398, 0.1428, 0.1463, 0.1360], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:05,371][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ ring] are: tensor([0.0082, 0.0843, 0.0859, 0.0855, 0.0860, 0.0798, 0.0743, 0.0842, 0.0831,
        0.0839, 0.0834, 0.0768, 0.0846], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:05,373][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ ring] are: tensor([0.0048, 0.0437, 0.0534, 0.0812, 0.0734, 0.1347, 0.0998, 0.0674, 0.0883,
        0.0967, 0.0802, 0.0954, 0.0809], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:05,375][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.5365, 0.0285, 0.0078, 0.0202, 0.0365, 0.0084, 0.0311, 0.0614, 0.0458,
        0.0327, 0.0515, 0.0451, 0.0770, 0.0175], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:05,376][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.1618, 0.0475, 0.0473, 0.0128, 0.0343, 0.0422, 0.0478, 0.0493, 0.0709,
        0.0408, 0.0825, 0.1927, 0.0675, 0.1027], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:05,378][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.9215, 0.0137, 0.0117, 0.0068, 0.0055, 0.0071, 0.0074, 0.0051, 0.0033,
        0.0027, 0.0028, 0.0037, 0.0049, 0.0038], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:05,380][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0074, 0.0700, 0.0709, 0.0723, 0.0721, 0.0699, 0.0726, 0.0812, 0.0758,
        0.0784, 0.0829, 0.0823, 0.0856, 0.0785], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:05,381][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.1181, 0.0675, 0.0784, 0.0862, 0.0543, 0.0395, 0.0648, 0.0921, 0.1010,
        0.0677, 0.0680, 0.0699, 0.0543, 0.0382], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:05,383][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0335, 0.1416, 0.0251, 0.1283, 0.0403, 0.0247, 0.0606, 0.0495, 0.0752,
        0.1509, 0.0762, 0.0807, 0.0727, 0.0407], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:05,385][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([9.9922e-01, 6.3076e-05, 4.4795e-05, 2.8933e-05, 5.3665e-05, 7.0644e-05,
        5.4047e-05, 2.4761e-05, 4.8253e-05, 5.4831e-05, 4.5694e-05, 4.7551e-05,
        5.9030e-05, 1.8245e-04], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:05,386][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0386, 0.0618, 0.0261, 0.1032, 0.0223, 0.0182, 0.0620, 0.0302, 0.0152,
        0.1847, 0.0547, 0.0501, 0.3047, 0.0282], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:05,388][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([9.9613e-01, 9.1879e-04, 9.2786e-05, 3.7668e-04, 5.0128e-04, 1.5587e-05,
        1.4531e-04, 5.6267e-04, 2.4331e-05, 3.7147e-04, 2.6047e-04, 9.5407e-05,
        4.9614e-04, 6.6290e-06], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:05,389][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0003, 0.0206, 0.0209, 0.0371, 0.0393, 0.0700, 0.0673, 0.0528, 0.0638,
        0.1258, 0.1374, 0.1246, 0.1118, 0.1283], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:05,391][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0064, 0.0795, 0.0801, 0.0793, 0.0798, 0.0739, 0.0677, 0.0790, 0.0762,
        0.0772, 0.0768, 0.0701, 0.0783, 0.0757], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:05,393][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0060, 0.0392, 0.0435, 0.0702, 0.0621, 0.1177, 0.0904, 0.0602, 0.0734,
        0.0880, 0.0680, 0.0867, 0.0745, 0.1201], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:05,396][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:29:05,398][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[9030],
        [4105],
        [ 557],
        [ 868],
        [ 151],
        [ 203],
        [ 732],
        [  16],
        [ 193],
        [ 533],
        [ 248],
        [ 316],
        [1723],
        [ 291]], device='cuda:0')
[2024-07-24 10:29:05,400][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 9735],
        [ 8171],
        [  735],
        [ 4398],
        [ 1212],
        [ 3856],
        [ 9937],
        [  262],
        [ 3105],
        [ 8970],
        [ 2630],
        [11706],
        [14624],
        [ 6174]], device='cuda:0')
[2024-07-24 10:29:05,401][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[ 7918],
        [12369],
        [12077],
        [10220],
        [ 8703],
        [ 8181],
        [ 8022],
        [ 8135],
        [ 8011],
        [ 7479],
        [ 6740],
        [ 6545],
        [ 6116],
        [ 5719]], device='cuda:0')
[2024-07-24 10:29:05,403][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[ 6703],
        [18890],
        [19793],
        [23496],
        [31976],
        [30507],
        [29107],
        [31017],
        [29694],
        [28844],
        [31238],
        [29001],
        [27515],
        [26637]], device='cuda:0')
[2024-07-24 10:29:05,404][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[1269],
        [ 569],
        [ 547],
        [ 538],
        [ 563],
        [ 652],
        [ 695],
        [ 748],
        [ 729],
        [ 697],
        [ 674],
        [ 661],
        [ 672],
        [ 692]], device='cuda:0')
[2024-07-24 10:29:05,405][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[ 6955],
        [10943],
        [11100],
        [11370],
        [11432],
        [11108],
        [11251],
        [11047],
        [10888],
        [10957],
        [10974],
        [10909],
        [10817],
        [10684]], device='cuda:0')
[2024-07-24 10:29:05,407][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[23188],
        [ 1061],
        [ 4278],
        [ 2362],
        [ 5663],
        [ 3715],
        [ 3915],
        [ 9050],
        [ 5689],
        [ 3773],
        [ 5648],
        [ 5503],
        [ 4698],
        [ 5554]], device='cuda:0')
[2024-07-24 10:29:05,409][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[2441],
        [3126],
        [6136],
        [5017],
        [4572],
        [4151],
        [4648],
        [4258],
        [5087],
        [4829],
        [5717],
        [5605],
        [5617],
        [4997]], device='cuda:0')
[2024-07-24 10:29:05,410][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[27104],
        [30258],
        [32823],
        [33203],
        [33429],
        [34274],
        [34828],
        [34998],
        [35282],
        [35151],
        [35084],
        [35063],
        [35182],
        [35387]], device='cuda:0')
[2024-07-24 10:29:05,412][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[19525],
        [39290],
        [42834],
        [43434],
        [44149],
        [44248],
        [44245],
        [44017],
        [44607],
        [44528],
        [44788],
        [44843],
        [44699],
        [44688]], device='cuda:0')
[2024-07-24 10:29:05,413][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[24469],
        [25238],
        [24504],
        [24828],
        [21180],
        [22709],
        [23247],
        [23040],
        [22194],
        [23321],
        [21960],
        [22113],
        [22656],
        [23946]], device='cuda:0')
[2024-07-24 10:29:05,415][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[43193],
        [50256],
        [50254],
        [50250],
        [47298],
        [39651],
        [34772],
        [39896],
        [34458],
        [32218],
        [24206],
        [30545],
        [30500],
        [30952]], device='cuda:0')
[2024-07-24 10:29:05,417][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[ 5938],
        [13957],
        [ 8236],
        [ 8672],
        [10569],
        [ 9568],
        [ 8848],
        [ 9666],
        [ 9217],
        [ 9480],
        [ 9515],
        [ 9708],
        [10419],
        [10057]], device='cuda:0')
[2024-07-24 10:29:05,418][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[29012],
        [19525],
        [18452],
        [18512],
        [17320],
        [17974],
        [18318],
        [17176],
        [17075],
        [17175],
        [16449],
        [16682],
        [17505],
        [17698]], device='cuda:0')
[2024-07-24 10:29:05,420][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 4290],
        [ 7502],
        [13277],
        [ 3678],
        [ 6651],
        [ 1765],
        [ 2305],
        [17411],
        [ 6565],
        [ 3657],
        [10046],
        [ 3249],
        [15463],
        [ 2143]], device='cuda:0')
[2024-07-24 10:29:05,422][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[26391],
        [23962],
        [22583],
        [17147],
        [ 7827],
        [10598],
        [ 4517],
        [ 4075],
        [ 3130],
        [ 3833],
        [ 2807],
        [ 2689],
        [ 3645],
        [ 3462]], device='cuda:0')
[2024-07-24 10:29:05,423][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[28291],
        [27415],
        [21987],
        [17260],
        [28908],
        [26950],
        [27864],
        [25530],
        [22522],
        [21461],
        [22522],
        [19035],
        [16620],
        [14668]], device='cuda:0')
[2024-07-24 10:29:05,425][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[25907],
        [26168],
        [26235],
        [26290],
        [26272],
        [26439],
        [26520],
        [26506],
        [26320],
        [26538],
        [26413],
        [26516],
        [26545],
        [26447]], device='cuda:0')
[2024-07-24 10:29:05,427][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[33431],
        [27458],
        [27649],
        [27844],
        [28392],
        [29566],
        [29838],
        [30752],
        [31463],
        [31422],
        [31407],
        [31872],
        [32524],
        [32770]], device='cuda:0')
[2024-07-24 10:29:05,428][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[44024],
        [44530],
        [43451],
        [36668],
        [33663],
        [28201],
        [29778],
        [31999],
        [25824],
        [28665],
        [27672],
        [26849],
        [30050],
        [24091]], device='cuda:0')
[2024-07-24 10:29:05,430][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[ 4099],
        [15195],
        [18929],
        [24411],
        [24624],
        [27216],
        [26700],
        [25949],
        [25941],
        [26627],
        [26721],
        [28850],
        [27668],
        [29379]], device='cuda:0')
[2024-07-24 10:29:05,431][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[47777],
        [47777],
        [47777],
        [47778],
        [47778],
        [47778],
        [47778],
        [47778],
        [47778],
        [47780],
        [47778],
        [47779],
        [47784],
        [47793]], device='cuda:0')
[2024-07-24 10:29:05,433][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[40276],
        [20059],
        [17164],
        [20998],
        [27874],
        [24150],
        [24794],
        [24587],
        [23997],
        [19669],
        [20337],
        [21307],
        [20536],
        [15794]], device='cuda:0')
[2024-07-24 10:29:05,435][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[9583],
        [9561],
        [9553],
        [9488],
        [9374],
        [9485],
        [9167],
        [9461],
        [9491],
        [9194],
        [9275],
        [8965],
        [9461],
        [9307]], device='cuda:0')
[2024-07-24 10:29:05,436][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[22084],
        [ 4099],
        [ 6805],
        [ 4797],
        [ 7526],
        [10156],
        [11968],
        [12397],
        [13244],
        [12100],
        [13732],
        [13882],
        [13545],
        [14020]], device='cuda:0')
[2024-07-24 10:29:05,437][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[1055],
        [1847],
        [1585],
        [1585],
        [1565],
        [1415],
        [1313],
        [1338],
        [1381],
        [1387],
        [1406],
        [1430],
        [1478],
        [1435]], device='cuda:0')
[2024-07-24 10:29:05,439][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[20734],
        [19467],
        [22449],
        [17370],
        [14874],
        [15982],
        [15674],
        [15202],
        [17186],
        [15938],
        [15365],
        [14884],
        [14253],
        [13741]], device='cuda:0')
[2024-07-24 10:29:05,440][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[17256],
        [24502],
        [26326],
        [32785],
        [30454],
        [30195],
        [32423],
        [32431],
        [34949],
        [35197],
        [34897],
        [35872],
        [35206],
        [37205]], device='cuda:0')
[2024-07-24 10:29:05,442][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[42432],
        [13554],
        [14456],
        [22570],
        [20563],
        [28554],
        [27428],
        [12500],
        [19781],
        [21254],
        [23885],
        [18630],
        [11578],
        [29560]], device='cuda:0')
[2024-07-24 10:29:05,443][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[21561],
        [21561],
        [21561],
        [21561],
        [21561],
        [21561],
        [21561],
        [21561],
        [21561],
        [21561],
        [21561],
        [21561],
        [21561],
        [21561]], device='cuda:0')
[2024-07-24 10:29:05,520][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:29:05,521][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:05,521][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:05,522][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:05,523][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:05,523][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:05,525][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:05,525][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:05,526][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:05,527][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:05,527][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:05,528][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:05,529][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:05,530][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Amanda] are: tensor([0.1632, 0.8368], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:05,530][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Amanda] are: tensor([0.0320, 0.9680], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:05,532][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Amanda] are: tensor([0.0043, 0.9957], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:05,534][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Amanda] are: tensor([0.2941, 0.7059], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:05,535][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Amanda] are: tensor([0.4058, 0.5942], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:05,537][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Amanda] are: tensor([0.9971, 0.0029], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:05,538][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Amanda] are: tensor([0.0642, 0.9358], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:05,540][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Amanda] are: tensor([0.7140, 0.2860], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:05,541][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Amanda] are: tensor([0.4843, 0.5157], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:05,543][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Amanda] are: tensor([0.4414, 0.5586], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:05,545][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Amanda] are: tensor([0.0101, 0.9899], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:05,546][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Amanda] are: tensor([0.6045, 0.3955], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:05,548][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0097, 0.8637, 0.1266], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:05,550][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0228, 0.7223, 0.2549], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:05,551][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0032, 0.9829, 0.0139], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:05,552][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.1682, 0.5988, 0.2330], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:05,552][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0216, 0.9564, 0.0220], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:05,553][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.9894, 0.0080, 0.0026], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:05,554][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0358, 0.5258, 0.4385], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:05,555][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.4036, 0.4010, 0.1954], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:05,557][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.2591, 0.6461, 0.0948], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:05,559][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0883, 0.8398, 0.0719], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:05,560][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0022, 0.6398, 0.3580], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:05,562][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.3377, 0.3786, 0.2838], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:05,563][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ John] are: tensor([0.0076, 0.7477, 0.1181, 0.1266], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:05,565][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ John] are: tensor([0.0167, 0.4579, 0.1965, 0.3288], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:05,567][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ John] are: tensor([0.0012, 0.9381, 0.0169, 0.0439], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:05,568][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ John] are: tensor([0.1357, 0.4113, 0.1886, 0.2645], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:05,570][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ John] are: tensor([0.0904, 0.7575, 0.0146, 0.1375], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:05,572][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ John] are: tensor([0.9959, 0.0018, 0.0012, 0.0012], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:05,573][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ John] are: tensor([0.0237, 0.3517, 0.2985, 0.3261], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:05,575][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ John] are: tensor([0.4685, 0.2841, 0.1714, 0.0759], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:05,576][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ John] are: tensor([0.4217, 0.3403, 0.0748, 0.1632], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:05,578][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ John] are: tensor([0.2243, 0.5122, 0.0501, 0.2133], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:05,579][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ John] are: tensor([0.0454, 0.6560, 0.2578, 0.0408], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:05,581][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ John] are: tensor([0.4641, 0.2193, 0.2127, 0.1038], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:05,582][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ went] are: tensor([0.0015, 0.6288, 0.0437, 0.0862, 0.2399], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:05,583][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ went] are: tensor([0.0131, 0.3739, 0.1766, 0.2707, 0.1657], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:05,584][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ went] are: tensor([0.0123, 0.6839, 0.1296, 0.1058, 0.0683], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:05,584][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ went] are: tensor([0.0643, 0.3113, 0.1299, 0.2042, 0.2902], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:05,585][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ went] are: tensor([0.0367, 0.7173, 0.0160, 0.0701, 0.1600], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:05,587][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ went] are: tensor([0.9882, 0.0051, 0.0018, 0.0036, 0.0012], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:05,588][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ went] are: tensor([0.0157, 0.2654, 0.2248, 0.2483, 0.2458], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:05,590][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ went] are: tensor([0.5027, 0.1751, 0.1004, 0.0719, 0.1500], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:05,591][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.1470, 0.3404, 0.0589, 0.1367, 0.3170], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:05,593][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ went] are: tensor([0.0595, 0.5475, 0.0431, 0.1524, 0.1975], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:05,594][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ went] are: tensor([0.0066, 0.2490, 0.3639, 0.2565, 0.1240], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:05,596][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ went] are: tensor([0.1854, 0.2258, 0.2496, 0.1416, 0.1977], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:05,598][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0028, 0.3448, 0.0415, 0.0759, 0.4169, 0.1181], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:05,599][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0079, 0.3291, 0.1586, 0.2663, 0.1469, 0.0912], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:05,601][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0129, 0.5539, 0.0298, 0.2183, 0.1501, 0.0350], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:05,603][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0450, 0.2864, 0.1365, 0.1730, 0.2315, 0.1277], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:05,604][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0076, 0.7906, 0.0159, 0.0554, 0.1051, 0.0254], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:05,605][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ to] are: tensor([9.9310e-01, 2.4686e-03, 7.8251e-04, 1.5706e-03, 1.3620e-03, 7.1552e-04],
       device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:05,607][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0142, 0.2150, 0.1815, 0.2031, 0.2015, 0.1846], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:05,609][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.5656, 0.1629, 0.0797, 0.0521, 0.0921, 0.0477], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:05,610][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.2910, 0.1564, 0.0579, 0.1011, 0.2640, 0.1297], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:05,612][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0920, 0.4083, 0.0430, 0.1534, 0.2188, 0.0845], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:05,614][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0013, 0.2465, 0.2424, 0.2379, 0.1916, 0.0803], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:05,615][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.1761, 0.2561, 0.2124, 0.1127, 0.1475, 0.0953], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:05,617][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0005, 0.1459, 0.0323, 0.0412, 0.4828, 0.2655, 0.0318],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:05,618][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0111, 0.2530, 0.1403, 0.1976, 0.1404, 0.0989, 0.1588],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:05,619][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0025, 0.1892, 0.0843, 0.1112, 0.1452, 0.4353, 0.0324],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:05,620][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0479, 0.2409, 0.1294, 0.1567, 0.1935, 0.1273, 0.1043],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:05,620][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0181, 0.5906, 0.0184, 0.1060, 0.1689, 0.0909, 0.0071],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:05,621][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ the] are: tensor([9.9476e-01, 1.7024e-03, 7.7384e-04, 1.1833e-03, 7.0160e-04, 4.9961e-04,
        3.8355e-04], device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:05,623][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0125, 0.1795, 0.1514, 0.1688, 0.1671, 0.1543, 0.1663],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:05,624][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.5020, 0.1470, 0.0768, 0.0464, 0.1384, 0.0461, 0.0433],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:05,626][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.3281, 0.1315, 0.0384, 0.0917, 0.2718, 0.1039, 0.0345],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:05,628][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.1250, 0.3401, 0.0414, 0.1401, 0.1959, 0.1119, 0.0456],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:05,629][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0019, 0.2101, 0.2233, 0.2120, 0.1505, 0.0936, 0.1087],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:05,631][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.2803, 0.1666, 0.1429, 0.0901, 0.1710, 0.0867, 0.0625],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:05,632][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ station] are: tensor([1.9206e-04, 2.3841e-01, 1.8733e-02, 6.9232e-02, 3.9480e-01, 2.3747e-01,
        2.7115e-02, 1.4051e-02], device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:05,634][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ station] are: tensor([0.0086, 0.1502, 0.1261, 0.1285, 0.1049, 0.0995, 0.1756, 0.2065],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:05,635][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ station] are: tensor([0.0009, 0.0873, 0.0331, 0.0464, 0.1337, 0.5161, 0.1575, 0.0250],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:05,637][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ station] are: tensor([0.0475, 0.2107, 0.1051, 0.1375, 0.1915, 0.1065, 0.0985, 0.1026],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:05,639][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ station] are: tensor([0.1513, 0.5051, 0.0202, 0.0676, 0.1539, 0.0530, 0.0137, 0.0352],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:05,640][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ station] are: tensor([9.9874e-01, 5.4108e-04, 1.8560e-04, 2.6316e-04, 1.0534e-04, 8.9210e-05,
        6.3452e-05, 1.4895e-05], device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:05,641][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ station] are: tensor([0.0106, 0.1505, 0.1281, 0.1413, 0.1403, 0.1300, 0.1402, 0.1591],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:05,643][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ station] are: tensor([0.8179, 0.0558, 0.0263, 0.0161, 0.0280, 0.0185, 0.0172, 0.0202],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:05,645][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ station] are: tensor([0.2741, 0.1462, 0.0326, 0.0509, 0.3241, 0.0607, 0.0351, 0.0765],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:05,646][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ station] are: tensor([0.1132, 0.3601, 0.0328, 0.1377, 0.1858, 0.0842, 0.0416, 0.0446],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:05,648][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ station] are: tensor([0.0078, 0.1662, 0.1806, 0.3009, 0.0887, 0.0550, 0.1086, 0.0921],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:05,650][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ station] are: tensor([0.4855, 0.0821, 0.1099, 0.0562, 0.0837, 0.0693, 0.0673, 0.0460],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:05,650][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [,] are: tensor([1.3397e-04, 3.7754e-01, 2.4658e-02, 8.4231e-02, 3.3473e-01, 1.1252e-01,
        2.4704e-02, 3.9313e-02, 2.1738e-03], device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:05,651][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0068, 0.2071, 0.0875, 0.1621, 0.0831, 0.0631, 0.1118, 0.1944, 0.0842],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:05,652][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0052, 0.1910, 0.0167, 0.1422, 0.1188, 0.1004, 0.1261, 0.2954, 0.0042],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:05,653][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0188, 0.2391, 0.1212, 0.1366, 0.1748, 0.0915, 0.0749, 0.0910, 0.0521],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:05,655][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0043, 0.5857, 0.0183, 0.0920, 0.2026, 0.0433, 0.0091, 0.0416, 0.0032],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:05,656][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [,] are: tensor([9.9226e-01, 2.2863e-03, 7.8772e-04, 1.2370e-03, 1.2514e-03, 4.8981e-04,
        4.5916e-04, 3.5819e-04, 8.7044e-04], device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:05,657][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0092, 0.1355, 0.1132, 0.1249, 0.1258, 0.1140, 0.1229, 0.1420, 0.1126],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:05,659][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.3636, 0.1387, 0.0780, 0.0563, 0.1096, 0.0619, 0.0563, 0.0941, 0.0415],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:05,661][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.1577, 0.1345, 0.0361, 0.0975, 0.3627, 0.0626, 0.0409, 0.0843, 0.0237],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:05,662][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0322, 0.4462, 0.0339, 0.1362, 0.1606, 0.0513, 0.0305, 0.0863, 0.0228],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:05,664][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0011, 0.1823, 0.1152, 0.2326, 0.1070, 0.0808, 0.1275, 0.1048, 0.0489],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:05,666][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.1017, 0.1749, 0.1018, 0.0755, 0.1574, 0.0969, 0.1167, 0.1081, 0.0671],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:05,667][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ John] are: tensor([0.0011, 0.2558, 0.0374, 0.0444, 0.4203, 0.1086, 0.0378, 0.0459, 0.0132,
        0.0356], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:05,669][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ John] are: tensor([0.0065, 0.1799, 0.0805, 0.1238, 0.0961, 0.0581, 0.0966, 0.1602, 0.0823,
        0.1159], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:05,670][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ John] are: tensor([3.5483e-04, 5.3494e-01, 8.8633e-03, 2.8420e-02, 1.3209e-01, 7.2709e-02,
        1.1772e-01, 5.9644e-02, 1.6237e-02, 2.9013e-02], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:05,672][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ John] are: tensor([0.0402, 0.1866, 0.0937, 0.1160, 0.1444, 0.0888, 0.0824, 0.0915, 0.0611,
        0.0954], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:05,674][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ John] are: tensor([0.0433, 0.6445, 0.0164, 0.1055, 0.0605, 0.0376, 0.0063, 0.0296, 0.0040,
        0.0522], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:05,675][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ John] are: tensor([9.9696e-01, 5.4522e-04, 4.6175e-04, 4.0780e-04, 2.5643e-04, 3.5712e-04,
        2.2425e-04, 8.6736e-05, 3.3365e-04, 3.6463e-04], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:05,677][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ John] are: tensor([0.0082, 0.1180, 0.1001, 0.1096, 0.1101, 0.1008, 0.1100, 0.1277, 0.1011,
        0.1145], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:05,678][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ John] are: tensor([0.2464, 0.0997, 0.0675, 0.0371, 0.1488, 0.0742, 0.0765, 0.1078, 0.0663,
        0.0758], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:05,680][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ John] are: tensor([0.2818, 0.1532, 0.0336, 0.0751, 0.1211, 0.0806, 0.0351, 0.0852, 0.0291,
        0.1052], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:05,681][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ John] are: tensor([0.1302, 0.2938, 0.0243, 0.1133, 0.1679, 0.0605, 0.0273, 0.0748, 0.0202,
        0.0877], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:05,682][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ John] are: tensor([0.0083, 0.1765, 0.1038, 0.0166, 0.0725, 0.1334, 0.0668, 0.3154, 0.0875,
        0.0193], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:05,683][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ John] are: tensor([0.1633, 0.1277, 0.1021, 0.0702, 0.1440, 0.0856, 0.0903, 0.1076, 0.0634,
        0.0459], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:05,684][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.0008, 0.2726, 0.0301, 0.0956, 0.1948, 0.1905, 0.0249, 0.0391, 0.0053,
        0.0534, 0.0929], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:05,685][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0047, 0.2122, 0.0960, 0.0901, 0.0780, 0.0663, 0.1069, 0.1211, 0.0836,
        0.0835, 0.0577], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:05,687][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0041, 0.1726, 0.0522, 0.1302, 0.0244, 0.2485, 0.0692, 0.0507, 0.0809,
        0.1439, 0.0233], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:05,688][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.0270, 0.1863, 0.0808, 0.1115, 0.1454, 0.0763, 0.0664, 0.0744, 0.0433,
        0.0850, 0.1036], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:05,690][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.0326, 0.7504, 0.0117, 0.0512, 0.0747, 0.0130, 0.0048, 0.0191, 0.0017,
        0.0272, 0.0136], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:05,691][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([9.8309e-01, 4.6058e-03, 1.3832e-03, 3.5397e-03, 8.3570e-04, 1.0817e-03,
        7.9043e-04, 3.2535e-04, 1.1225e-03, 2.6651e-03, 5.5720e-04],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:05,693][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0070, 0.1056, 0.0893, 0.0981, 0.0987, 0.0900, 0.0977, 0.1119, 0.0903,
        0.1017, 0.1095], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:05,694][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.4959, 0.0846, 0.0590, 0.0337, 0.0664, 0.0376, 0.0403, 0.0744, 0.0312,
        0.0368, 0.0401], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:05,696][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.1850, 0.1892, 0.0273, 0.0924, 0.1219, 0.0736, 0.0254, 0.0576, 0.0160,
        0.1474, 0.0644], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:05,698][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.0469, 0.3487, 0.0287, 0.1098, 0.1476, 0.0521, 0.0260, 0.0632, 0.0176,
        0.1073, 0.0520], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:05,699][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0023, 0.0927, 0.1205, 0.0641, 0.1059, 0.0642, 0.1814, 0.1584, 0.1274,
        0.0619, 0.0210], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:05,701][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0766, 0.1342, 0.1336, 0.0778, 0.1022, 0.0732, 0.0869, 0.0878, 0.0697,
        0.0797, 0.0784], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:05,702][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ a] are: tensor([3.1187e-04, 1.2181e-01, 1.8280e-02, 3.4105e-02, 3.8500e-01, 9.6988e-02,
        1.7399e-02, 3.7571e-02, 7.1192e-03, 4.0726e-02, 2.1263e-01, 2.8058e-02],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:05,704][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0034, 0.1433, 0.0664, 0.0970, 0.0697, 0.0519, 0.0884, 0.1799, 0.0711,
        0.1026, 0.0608, 0.0655], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:05,706][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0023, 0.0791, 0.0486, 0.0793, 0.0339, 0.1769, 0.0620, 0.2173, 0.0754,
        0.0768, 0.0685, 0.0799], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:05,708][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0235, 0.1576, 0.0849, 0.0974, 0.1317, 0.0739, 0.0599, 0.0740, 0.0469,
        0.0798, 0.1056, 0.0646], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:05,709][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0291, 0.5976, 0.0127, 0.0723, 0.0962, 0.0472, 0.0070, 0.0295, 0.0036,
        0.0503, 0.0254, 0.0291], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:05,711][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ a] are: tensor([9.9241e-01, 1.1063e-03, 6.4460e-04, 7.1016e-04, 6.6511e-04, 4.3571e-04,
        3.8352e-04, 2.1500e-04, 7.0293e-04, 8.7973e-04, 1.4145e-03, 4.2935e-04],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:05,712][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0064, 0.0949, 0.0809, 0.0895, 0.0896, 0.0816, 0.0884, 0.1022, 0.0820,
        0.0935, 0.1011, 0.0898], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:05,713][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.4853, 0.0498, 0.0481, 0.0342, 0.0657, 0.0355, 0.0364, 0.0549, 0.0338,
        0.0438, 0.0670, 0.0454], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:05,714][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.1731, 0.1039, 0.0219, 0.0514, 0.1875, 0.0506, 0.0212, 0.0442, 0.0195,
        0.1085, 0.1869, 0.0314], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:05,715][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0607, 0.2019, 0.0238, 0.0932, 0.1248, 0.0515, 0.0259, 0.0726, 0.0274,
        0.1504, 0.1127, 0.0551], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:05,716][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0008, 0.0664, 0.1273, 0.1059, 0.0891, 0.0654, 0.0941, 0.1487, 0.0788,
        0.0670, 0.0711, 0.0855], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:05,717][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.1067, 0.1273, 0.1125, 0.0687, 0.0997, 0.0565, 0.0860, 0.0633, 0.0730,
        0.0745, 0.1002, 0.0316], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:05,719][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ ring] are: tensor([0.0006, 0.2762, 0.0237, 0.0839, 0.1979, 0.0805, 0.0199, 0.0121, 0.0078,
        0.0540, 0.1627, 0.0361, 0.0446], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:05,721][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ ring] are: tensor([0.0031, 0.1156, 0.0590, 0.0770, 0.0656, 0.0441, 0.0761, 0.1493, 0.0704,
        0.0806, 0.0420, 0.0710, 0.1462], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:05,722][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ ring] are: tensor([0.0030, 0.1901, 0.0282, 0.0338, 0.0582, 0.3175, 0.0632, 0.0660, 0.0504,
        0.0311, 0.0736, 0.0589, 0.0260], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:05,724][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ ring] are: tensor([0.0200, 0.1622, 0.0719, 0.0996, 0.1139, 0.0642, 0.0581, 0.0669, 0.0413,
        0.0722, 0.0984, 0.0558, 0.0755], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:05,726][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ ring] are: tensor([0.0310, 0.5265, 0.0159, 0.0840, 0.0970, 0.0494, 0.0095, 0.0310, 0.0035,
        0.0276, 0.0297, 0.0519, 0.0431], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:05,727][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ ring] are: tensor([9.9231e-01, 1.7343e-03, 7.5186e-04, 6.2703e-04, 5.9310e-04, 3.5438e-04,
        3.3174e-04, 1.0929e-04, 6.7581e-04, 5.7156e-04, 1.1776e-03, 5.8208e-04,
        1.7942e-04], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:05,729][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ ring] are: tensor([0.0059, 0.0870, 0.0750, 0.0831, 0.0812, 0.0757, 0.0810, 0.0934, 0.0746,
        0.0854, 0.0903, 0.0810, 0.0864], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:05,730][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ ring] are: tensor([0.4949, 0.0360, 0.0354, 0.0273, 0.0764, 0.0330, 0.0339, 0.0406, 0.0284,
        0.0368, 0.0636, 0.0438, 0.0499], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:05,732][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ ring] are: tensor([0.2025, 0.1097, 0.0196, 0.0554, 0.1430, 0.0367, 0.0174, 0.0800, 0.0106,
        0.0735, 0.1754, 0.0265, 0.0497], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:05,734][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ ring] are: tensor([0.1150, 0.2410, 0.0213, 0.0833, 0.1541, 0.0360, 0.0161, 0.0490, 0.0155,
        0.0676, 0.0949, 0.0344, 0.0717], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:05,736][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ ring] are: tensor([0.0193, 0.0956, 0.1174, 0.1360, 0.0428, 0.1050, 0.0885, 0.1079, 0.0731,
        0.0504, 0.0370, 0.1013, 0.0256], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:05,738][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ ring] are: tensor([0.0785, 0.0774, 0.1077, 0.0646, 0.0759, 0.0782, 0.1053, 0.0800, 0.0650,
        0.0755, 0.0785, 0.0620, 0.0513], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:05,739][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0017, 0.1291, 0.0141, 0.0430, 0.2105, 0.0422, 0.0212, 0.0209, 0.0131,
        0.0641, 0.2306, 0.0597, 0.1073, 0.0424], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:05,741][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0022, 0.1381, 0.0566, 0.0938, 0.0525, 0.0319, 0.0754, 0.1459, 0.0579,
        0.0954, 0.0384, 0.0561, 0.1289, 0.0269], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:05,743][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0044, 0.1292, 0.0096, 0.0694, 0.0432, 0.0136, 0.1722, 0.0893, 0.0210,
        0.0680, 0.1129, 0.1515, 0.0957, 0.0200], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:05,744][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0246, 0.1204, 0.0650, 0.0805, 0.1053, 0.0603, 0.0568, 0.0653, 0.0433,
        0.0690, 0.0987, 0.0622, 0.0870, 0.0616], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:05,745][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0222, 0.6825, 0.0159, 0.0418, 0.0534, 0.0143, 0.0062, 0.0253, 0.0025,
        0.0265, 0.0355, 0.0223, 0.0299, 0.0217], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:05,746][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ to] are: tensor([9.8929e-01, 1.5877e-03, 5.9661e-04, 1.1101e-03, 6.7050e-04, 4.2117e-04,
        5.1923e-04, 2.9250e-04, 7.6151e-04, 1.5036e-03, 1.1172e-03, 7.7366e-04,
        6.0483e-04, 7.5127e-04], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:05,747][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0059, 0.0811, 0.0683, 0.0757, 0.0751, 0.0687, 0.0738, 0.0851, 0.0676,
        0.0773, 0.0821, 0.0736, 0.0795, 0.0862], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:05,749][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.4386, 0.0610, 0.0368, 0.0283, 0.0461, 0.0257, 0.0342, 0.0698, 0.0253,
        0.0401, 0.0496, 0.0484, 0.0705, 0.0255], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:05,750][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.2192, 0.0616, 0.0197, 0.0364, 0.0703, 0.0340, 0.0308, 0.0414, 0.0270,
        0.0864, 0.1310, 0.0732, 0.0766, 0.0925], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:05,752][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.1129, 0.1553, 0.0191, 0.0667, 0.0917, 0.0327, 0.0207, 0.0517, 0.0214,
        0.1110, 0.0738, 0.0541, 0.0852, 0.1036], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:05,754][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0007, 0.0690, 0.1161, 0.0916, 0.0716, 0.0547, 0.1436, 0.1016, 0.0743,
        0.0618, 0.0631, 0.0964, 0.0243, 0.0312], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:05,755][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0700, 0.1315, 0.1229, 0.0802, 0.0854, 0.0577, 0.0935, 0.0618, 0.0556,
        0.0658, 0.0603, 0.0445, 0.0402, 0.0306], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:05,843][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:29:05,844][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:05,845][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:05,846][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:05,846][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:05,847][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:05,848][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:05,848][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:05,849][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:05,850][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:05,851][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:05,851][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:05,852][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:05,853][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Amanda] are: tensor([0.3914, 0.6086], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:05,853][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Amanda] are: tensor([0.4478, 0.5522], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:05,854][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Amanda] are: tensor([0.0018, 0.9982], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:05,855][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Amanda] are: tensor([0.7234, 0.2766], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:05,856][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Amanda] are: tensor([0.3177, 0.6823], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:05,858][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Amanda] are: tensor([0.9971, 0.0029], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:05,859][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Amanda] are: tensor([0.9370, 0.0630], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:05,860][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Amanda] are: tensor([0.7140, 0.2860], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:05,861][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Amanda] are: tensor([0.4843, 0.5157], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:05,861][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Amanda] are: tensor([0.4414, 0.5586], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:05,862][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Amanda] are: tensor([0.0101, 0.9899], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:05,863][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Amanda] are: tensor([0.6045, 0.3955], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:05,865][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0373, 0.9114, 0.0513], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:05,866][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.6883, 0.2056, 0.1061], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:05,868][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([4.8161e-04, 3.1860e-01, 6.8092e-01], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:05,869][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.4617, 0.4879, 0.0504], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:05,870][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.1066, 0.7947, 0.0987], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:05,872][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.9894, 0.0080, 0.0026], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:05,874][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.8657, 0.0839, 0.0504], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:05,875][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.4036, 0.4010, 0.1954], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:05,877][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.2591, 0.6461, 0.0948], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:05,879][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0883, 0.8398, 0.0719], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:05,880][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0022, 0.6398, 0.3580], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:05,882][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.3377, 0.3786, 0.2838], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:05,883][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ John] are: tensor([0.1129, 0.7017, 0.0676, 0.1177], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:05,885][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ John] are: tensor([0.8267, 0.0936, 0.0421, 0.0376], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:05,886][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ John] are: tensor([0.0023, 0.3212, 0.5304, 0.1461], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:05,888][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ John] are: tensor([0.7279, 0.2063, 0.0238, 0.0420], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:05,890][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ John] are: tensor([0.1563, 0.5226, 0.0442, 0.2769], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:05,891][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ John] are: tensor([0.9959, 0.0018, 0.0012, 0.0012], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:05,892][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ John] are: tensor([0.8575, 0.0729, 0.0351, 0.0345], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:05,893][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ John] are: tensor([0.4685, 0.2841, 0.1714, 0.0759], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:05,893][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ John] are: tensor([0.4217, 0.3403, 0.0748, 0.1632], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:05,894][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ John] are: tensor([0.2243, 0.5122, 0.0501, 0.2133], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:05,896][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ John] are: tensor([0.0454, 0.6560, 0.2578, 0.0408], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:05,897][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ John] are: tensor([0.4641, 0.2193, 0.2127, 0.1038], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:05,899][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([0.0451, 0.5718, 0.0277, 0.1374, 0.2180], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:05,900][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([0.5582, 0.1423, 0.0971, 0.0938, 0.1087], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:05,902][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([3.3280e-04, 1.0662e-01, 3.9757e-01, 2.2724e-01, 2.6824e-01],
       device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:05,903][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([0.3141, 0.3558, 0.0320, 0.0898, 0.2082], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:05,905][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([0.0771, 0.4025, 0.0404, 0.1094, 0.3706], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:05,906][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([0.9882, 0.0051, 0.0018, 0.0036, 0.0012], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:05,908][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([0.7783, 0.0808, 0.0547, 0.0435, 0.0427], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:05,910][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([0.5027, 0.1751, 0.1004, 0.0719, 0.1500], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:05,911][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([0.1470, 0.3404, 0.0589, 0.1367, 0.3170], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:05,913][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([0.0595, 0.5475, 0.0431, 0.1524, 0.1975], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:05,914][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([0.0066, 0.2490, 0.3639, 0.2565, 0.1240], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:05,916][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([0.1854, 0.2258, 0.2496, 0.1416, 0.1977], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:05,918][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0880, 0.2680, 0.0236, 0.0744, 0.3165, 0.2295], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:05,919][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.7680, 0.0674, 0.0357, 0.0429, 0.0673, 0.0187], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:05,921][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([1.6777e-04, 8.0020e-02, 1.7193e-01, 1.0994e-01, 2.3130e-01, 4.0665e-01],
       device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:05,922][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.4318, 0.2529, 0.0335, 0.0644, 0.1558, 0.0616], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:05,923][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.1601, 0.3177, 0.0301, 0.1028, 0.2089, 0.1805], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:05,924][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([9.9310e-01, 2.4686e-03, 7.8251e-04, 1.5706e-03, 1.3620e-03, 7.1552e-04],
       device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:05,925][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.8551, 0.0514, 0.0291, 0.0287, 0.0241, 0.0116], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:05,925][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.5656, 0.1629, 0.0797, 0.0521, 0.0921, 0.0477], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:05,926][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.2910, 0.1564, 0.0579, 0.1011, 0.2640, 0.1297], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:05,928][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0920, 0.4083, 0.0430, 0.1534, 0.2188, 0.0845], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:05,929][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0013, 0.2465, 0.2424, 0.2379, 0.1916, 0.0803], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:05,931][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.1761, 0.2561, 0.2124, 0.1127, 0.1475, 0.0953], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:05,933][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0328, 0.1500, 0.0237, 0.0536, 0.3062, 0.3674, 0.0663],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:05,934][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.8428, 0.0421, 0.0247, 0.0266, 0.0352, 0.0159, 0.0127],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:05,936][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0004, 0.0838, 0.1566, 0.1513, 0.1949, 0.2662, 0.1469],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:05,937][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.4937, 0.2029, 0.0293, 0.0502, 0.1350, 0.0575, 0.0312],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:05,939][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.1385, 0.2342, 0.0273, 0.0947, 0.2369, 0.2242, 0.0442],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:05,940][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([9.9476e-01, 1.7024e-03, 7.7384e-04, 1.1833e-03, 7.0160e-04, 4.9961e-04,
        3.8355e-04], device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:05,942][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.8974, 0.0305, 0.0201, 0.0186, 0.0156, 0.0096, 0.0083],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:05,944][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.5020, 0.1470, 0.0768, 0.0464, 0.1384, 0.0461, 0.0433],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:05,945][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.3281, 0.1315, 0.0384, 0.0917, 0.2718, 0.1039, 0.0345],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:05,947][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.1250, 0.3401, 0.0414, 0.1401, 0.1959, 0.1119, 0.0456],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:05,949][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0019, 0.2101, 0.2233, 0.2120, 0.1505, 0.0936, 0.1087],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:05,950][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.2803, 0.1666, 0.1429, 0.0901, 0.1710, 0.0867, 0.0625],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:05,952][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ station] are: tensor([0.0165, 0.2281, 0.0123, 0.0738, 0.1932, 0.3707, 0.0763, 0.0291],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:05,954][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ station] are: tensor([0.8965, 0.0276, 0.0135, 0.0124, 0.0224, 0.0070, 0.0078, 0.0130],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:05,955][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ station] are: tensor([0.0031, 0.0817, 0.1270, 0.0952, 0.1571, 0.1763, 0.1356, 0.2240],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:05,955][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ station] are: tensor([0.6118, 0.1546, 0.0157, 0.0322, 0.1253, 0.0260, 0.0183, 0.0161],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:05,956][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ station] are: tensor([0.1651, 0.2197, 0.0272, 0.0626, 0.2427, 0.1658, 0.0587, 0.0581],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:05,957][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ station] are: tensor([9.9874e-01, 5.4108e-04, 1.8560e-04, 2.6316e-04, 1.0534e-04, 8.9210e-05,
        6.3452e-05, 1.4895e-05], device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:05,958][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ station] are: tensor([0.9264, 0.0204, 0.0153, 0.0115, 0.0108, 0.0063, 0.0053, 0.0040],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:05,960][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ station] are: tensor([0.8179, 0.0558, 0.0263, 0.0161, 0.0280, 0.0185, 0.0172, 0.0202],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:05,961][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ station] are: tensor([0.2741, 0.1462, 0.0326, 0.0509, 0.3241, 0.0607, 0.0351, 0.0765],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:05,963][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ station] are: tensor([0.1132, 0.3601, 0.0328, 0.1377, 0.1858, 0.0842, 0.0416, 0.0446],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:05,964][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ station] are: tensor([0.0078, 0.1662, 0.1806, 0.3009, 0.0887, 0.0550, 0.1086, 0.0921],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:05,966][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ station] are: tensor([0.4855, 0.0821, 0.1099, 0.0562, 0.0837, 0.0693, 0.0673, 0.0460],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:05,967][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0229, 0.2897, 0.0208, 0.0803, 0.2211, 0.1719, 0.0652, 0.1118, 0.0163],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:05,969][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.7443, 0.0370, 0.0360, 0.0268, 0.0601, 0.0148, 0.0230, 0.0201, 0.0379],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:05,970][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([1.3580e-04, 3.3694e-02, 6.6739e-02, 5.6158e-02, 1.2453e-01, 1.6653e-01,
        1.6863e-01, 2.4645e-01, 1.3714e-01], device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:05,972][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.2613, 0.3148, 0.0366, 0.0645, 0.1755, 0.0434, 0.0303, 0.0528, 0.0208],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:05,974][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0384, 0.2339, 0.0239, 0.1016, 0.3012, 0.1534, 0.0521, 0.0675, 0.0280],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:05,975][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([9.9226e-01, 2.2863e-03, 7.8772e-04, 1.2370e-03, 1.2514e-03, 4.8981e-04,
        4.5916e-04, 3.5819e-04, 8.7044e-04], device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:05,976][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.7974, 0.0504, 0.0313, 0.0359, 0.0267, 0.0142, 0.0127, 0.0135, 0.0181],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:05,978][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.3636, 0.1387, 0.0780, 0.0563, 0.1096, 0.0619, 0.0563, 0.0941, 0.0415],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:05,980][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.1577, 0.1345, 0.0361, 0.0975, 0.3627, 0.0626, 0.0409, 0.0843, 0.0237],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:05,982][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0322, 0.4462, 0.0339, 0.1362, 0.1606, 0.0513, 0.0305, 0.0863, 0.0228],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:05,983][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0011, 0.1823, 0.1152, 0.2326, 0.1070, 0.0808, 0.1275, 0.1048, 0.0489],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:05,985][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.1017, 0.1749, 0.1018, 0.0755, 0.1574, 0.0969, 0.1167, 0.1081, 0.0671],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:05,986][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ John] are: tensor([0.0603, 0.2205, 0.0229, 0.0323, 0.1891, 0.2061, 0.0754, 0.0691, 0.0404,
        0.0840], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:05,987][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ John] are: tensor([0.5758, 0.0526, 0.0341, 0.0345, 0.0732, 0.0335, 0.0268, 0.0546, 0.0441,
        0.0707], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:05,988][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ John] are: tensor([2.3067e-04, 3.7116e-02, 6.3577e-02, 2.5879e-02, 1.0561e-01, 1.3677e-01,
        1.1102e-01, 2.9324e-01, 1.7920e-01, 4.7360e-02], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:05,988][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ John] are: tensor([0.5704, 0.1542, 0.0182, 0.0309, 0.0874, 0.0296, 0.0208, 0.0261, 0.0150,
        0.0475], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:05,990][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ John] are: tensor([0.1227, 0.2196, 0.0193, 0.1140, 0.1182, 0.0976, 0.0375, 0.0496, 0.0303,
        0.1913], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:05,991][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ John] are: tensor([9.9696e-01, 5.4522e-04, 4.6175e-04, 4.0780e-04, 2.5643e-04, 3.5712e-04,
        2.2425e-04, 8.6736e-05, 3.3365e-04, 3.6463e-04], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:05,992][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ John] are: tensor([0.8123, 0.0435, 0.0247, 0.0216, 0.0258, 0.0130, 0.0130, 0.0199, 0.0160,
        0.0102], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:05,994][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ John] are: tensor([0.2464, 0.0997, 0.0675, 0.0371, 0.1488, 0.0742, 0.0765, 0.1078, 0.0663,
        0.0758], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:05,996][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ John] are: tensor([0.2818, 0.1532, 0.0336, 0.0751, 0.1211, 0.0806, 0.0351, 0.0852, 0.0291,
        0.1052], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:05,997][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ John] are: tensor([0.1302, 0.2938, 0.0243, 0.1133, 0.1679, 0.0605, 0.0273, 0.0748, 0.0202,
        0.0877], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:05,999][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ John] are: tensor([0.0083, 0.1765, 0.1038, 0.0166, 0.0725, 0.1334, 0.0668, 0.3154, 0.0875,
        0.0193], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:06,001][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ John] are: tensor([0.1633, 0.1277, 0.1021, 0.0702, 0.1440, 0.0856, 0.0903, 0.1076, 0.0634,
        0.0459], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:06,002][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.0433, 0.1948, 0.0163, 0.0466, 0.1112, 0.2202, 0.0511, 0.0766, 0.0219,
        0.1007, 0.1172], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:06,004][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.3681, 0.0586, 0.0431, 0.0666, 0.1052, 0.0352, 0.0399, 0.0464, 0.0512,
        0.0996, 0.0861], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:06,005][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([1.1054e-04, 2.2650e-02, 5.4905e-02, 4.0523e-02, 9.3017e-02, 1.1839e-01,
        1.1900e-01, 2.5645e-01, 1.8831e-01, 7.0043e-02, 3.6603e-02],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:06,007][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.3179, 0.2714, 0.0219, 0.0548, 0.1156, 0.0367, 0.0210, 0.0242, 0.0128,
        0.0685, 0.0553], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:06,009][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.0904, 0.3442, 0.0220, 0.0657, 0.1331, 0.0751, 0.0403, 0.0351, 0.0216,
        0.1117, 0.0607], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:06,010][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([9.8309e-01, 4.6058e-03, 1.3832e-03, 3.5397e-03, 8.3570e-04, 1.0817e-03,
        7.9043e-04, 3.2535e-04, 1.1225e-03, 2.6651e-03, 5.5720e-04],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:06,012][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.7212, 0.0601, 0.0391, 0.0341, 0.0284, 0.0200, 0.0151, 0.0214, 0.0227,
        0.0166, 0.0213], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:06,013][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.4959, 0.0846, 0.0590, 0.0337, 0.0664, 0.0376, 0.0403, 0.0744, 0.0312,
        0.0368, 0.0401], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:06,015][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.1850, 0.1892, 0.0273, 0.0924, 0.1219, 0.0736, 0.0254, 0.0576, 0.0160,
        0.1474, 0.0644], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:06,017][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.0469, 0.3487, 0.0287, 0.1098, 0.1476, 0.0521, 0.0260, 0.0632, 0.0176,
        0.1073, 0.0520], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:06,017][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0023, 0.0927, 0.1205, 0.0641, 0.1059, 0.0642, 0.1814, 0.1584, 0.1274,
        0.0619, 0.0210], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:06,018][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.0766, 0.1342, 0.1336, 0.0778, 0.1022, 0.0732, 0.0869, 0.0878, 0.0697,
        0.0797, 0.0784], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:06,019][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0407, 0.0865, 0.0133, 0.0215, 0.1496, 0.1301, 0.0307, 0.0601, 0.0276,
        0.0776, 0.2686, 0.0938], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:06,020][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.6878, 0.0249, 0.0222, 0.0218, 0.0486, 0.0124, 0.0162, 0.0194, 0.0297,
        0.0408, 0.0551, 0.0212], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:06,021][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([1.0956e-04, 2.0899e-02, 5.8292e-02, 4.4678e-02, 7.4034e-02, 1.0695e-01,
        9.6014e-02, 2.0471e-01, 1.5833e-01, 6.1136e-02, 8.8382e-02, 8.6467e-02],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:06,023][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.3771, 0.1545, 0.0264, 0.0381, 0.1068, 0.0380, 0.0211, 0.0305, 0.0209,
        0.0732, 0.0712, 0.0420], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:06,024][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0773, 0.1897, 0.0174, 0.0674, 0.1220, 0.1080, 0.0362, 0.0428, 0.0285,
        0.1326, 0.0802, 0.0980], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:06,026][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([9.9241e-01, 1.1063e-03, 6.4460e-04, 7.1016e-04, 6.6511e-04, 4.3571e-04,
        3.8352e-04, 2.1500e-04, 7.0293e-04, 8.7973e-04, 1.4145e-03, 4.2935e-04],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:06,027][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.7854, 0.0337, 0.0246, 0.0231, 0.0221, 0.0145, 0.0118, 0.0132, 0.0218,
        0.0134, 0.0244, 0.0121], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:06,029][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.4853, 0.0498, 0.0481, 0.0342, 0.0657, 0.0355, 0.0364, 0.0549, 0.0338,
        0.0438, 0.0670, 0.0454], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:06,030][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.1731, 0.1039, 0.0219, 0.0514, 0.1875, 0.0506, 0.0212, 0.0442, 0.0195,
        0.1085, 0.1869, 0.0314], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:06,032][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0607, 0.2019, 0.0238, 0.0932, 0.1248, 0.0515, 0.0259, 0.0726, 0.0274,
        0.1504, 0.1127, 0.0551], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:06,034][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0008, 0.0664, 0.1273, 0.1059, 0.0891, 0.0654, 0.0941, 0.1487, 0.0788,
        0.0670, 0.0711, 0.0855], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:06,035][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.1067, 0.1273, 0.1125, 0.0687, 0.0997, 0.0565, 0.0860, 0.0633, 0.0730,
        0.0745, 0.1002, 0.0316], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:06,037][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ ring] are: tensor([0.0283, 0.1857, 0.0112, 0.0593, 0.1028, 0.0805, 0.0265, 0.0239, 0.0154,
        0.0857, 0.2122, 0.1168, 0.0517], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:06,039][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ ring] are: tensor([0.8603, 0.0083, 0.0120, 0.0038, 0.0246, 0.0072, 0.0104, 0.0140, 0.0142,
        0.0054, 0.0173, 0.0080, 0.0145], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:06,040][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ ring] are: tensor([1.6057e-04, 1.4109e-02, 7.1081e-02, 3.3028e-02, 3.8937e-02, 8.3555e-02,
        6.5858e-02, 1.0476e-01, 1.0173e-01, 2.6234e-02, 4.0623e-02, 1.0097e-01,
        3.1896e-01], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:06,042][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ ring] are: tensor([0.3137, 0.2201, 0.0166, 0.0464, 0.1098, 0.0244, 0.0185, 0.0292, 0.0116,
        0.0569, 0.0822, 0.0250, 0.0458], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:06,044][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ ring] are: tensor([0.0402, 0.1811, 0.0174, 0.0747, 0.1280, 0.0788, 0.0369, 0.0371, 0.0214,
        0.0868, 0.0865, 0.1285, 0.0826], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:06,045][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ ring] are: tensor([9.9231e-01, 1.7343e-03, 7.5186e-04, 6.2703e-04, 5.9310e-04, 3.5438e-04,
        3.3174e-04, 1.0929e-04, 6.7581e-04, 5.7156e-04, 1.1776e-03, 5.8208e-04,
        1.7942e-04], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:06,047][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ ring] are: tensor([0.8438, 0.0203, 0.0214, 0.0179, 0.0132, 0.0109, 0.0084, 0.0084, 0.0133,
        0.0077, 0.0132, 0.0080, 0.0134], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:06,049][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ ring] are: tensor([0.4949, 0.0360, 0.0354, 0.0273, 0.0764, 0.0330, 0.0339, 0.0406, 0.0284,
        0.0368, 0.0636, 0.0438, 0.0499], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:06,050][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ ring] are: tensor([0.2025, 0.1097, 0.0196, 0.0554, 0.1430, 0.0367, 0.0174, 0.0800, 0.0106,
        0.0735, 0.1754, 0.0265, 0.0497], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:06,050][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ ring] are: tensor([0.1150, 0.2410, 0.0213, 0.0833, 0.1541, 0.0360, 0.0161, 0.0490, 0.0155,
        0.0676, 0.0949, 0.0344, 0.0717], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:06,051][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ ring] are: tensor([0.0193, 0.0956, 0.1174, 0.1360, 0.0428, 0.1050, 0.0885, 0.1079, 0.0731,
        0.0504, 0.0370, 0.1013, 0.0256], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:06,053][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ ring] are: tensor([0.0785, 0.0774, 0.1077, 0.0646, 0.0759, 0.0782, 0.1053, 0.0800, 0.0650,
        0.0755, 0.0785, 0.0620, 0.0513], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:06,055][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.1486, 0.0694, 0.0068, 0.0195, 0.0585, 0.0457, 0.0236, 0.0221, 0.0193,
        0.0634, 0.1763, 0.1125, 0.0944, 0.1400], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:06,056][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.5934, 0.0322, 0.0299, 0.0273, 0.0625, 0.0156, 0.0232, 0.0150, 0.0288,
        0.0479, 0.0569, 0.0306, 0.0187, 0.0180], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:06,058][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([4.0591e-05, 1.1435e-02, 3.6210e-02, 2.4838e-02, 3.7883e-02, 1.0394e-01,
        1.0848e-01, 8.5777e-02, 1.0483e-01, 4.6474e-02, 7.0560e-02, 1.0737e-01,
        1.8457e-01, 7.7594e-02], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:06,059][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.3488, 0.1055, 0.0180, 0.0319, 0.0711, 0.0288, 0.0229, 0.0282, 0.0182,
        0.0629, 0.0707, 0.0422, 0.0755, 0.0753], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:06,061][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.1506, 0.1213, 0.0123, 0.0404, 0.0604, 0.0586, 0.0351, 0.0339, 0.0225,
        0.0934, 0.0775, 0.0937, 0.0809, 0.1194], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:06,062][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([9.8929e-01, 1.5877e-03, 5.9661e-04, 1.1101e-03, 6.7050e-04, 4.2117e-04,
        5.1923e-04, 2.9250e-04, 7.6151e-04, 1.5036e-03, 1.1172e-03, 7.7366e-04,
        6.0483e-04, 7.5127e-04], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:06,064][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.7894, 0.0360, 0.0237, 0.0255, 0.0186, 0.0097, 0.0106, 0.0102, 0.0161,
        0.0133, 0.0173, 0.0092, 0.0127, 0.0077], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:06,066][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.4386, 0.0610, 0.0368, 0.0283, 0.0461, 0.0257, 0.0342, 0.0698, 0.0253,
        0.0401, 0.0496, 0.0484, 0.0705, 0.0255], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:06,067][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.2192, 0.0616, 0.0197, 0.0364, 0.0703, 0.0340, 0.0308, 0.0414, 0.0270,
        0.0864, 0.1310, 0.0732, 0.0766, 0.0925], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:06,069][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.1129, 0.1553, 0.0191, 0.0667, 0.0917, 0.0327, 0.0207, 0.0517, 0.0214,
        0.1110, 0.0738, 0.0541, 0.0852, 0.1036], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:06,071][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0007, 0.0690, 0.1161, 0.0916, 0.0716, 0.0547, 0.1436, 0.1016, 0.0743,
        0.0618, 0.0631, 0.0964, 0.0243, 0.0312], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:06,073][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0700, 0.1315, 0.1229, 0.0802, 0.0854, 0.0577, 0.0935, 0.0618, 0.0556,
        0.0658, 0.0603, 0.0445, 0.0402, 0.0306], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:06,076][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:29:06,078][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[7169],
        [1681],
        [ 291],
        [2367],
        [ 740],
        [ 708],
        [2252],
        [ 455],
        [ 756],
        [2412],
        [1877],
        [1781],
        [3279],
        [ 974]], device='cuda:0')
[2024-07-24 10:29:06,080][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[8097],
        [8384],
        [2481],
        [8959],
        [3324],
        [2643],
        [5109],
        [1175],
        [1640],
        [7231],
        [3995],
        [3031],
        [7560],
        [1921]], device='cuda:0')
[2024-07-24 10:29:06,081][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[33318],
        [41150],
        [40602],
        [40180],
        [38565],
        [35211],
        [31787],
        [33208],
        [35311],
        [33282],
        [33353],
        [30678],
        [33119],
        [29524]], device='cuda:0')
[2024-07-24 10:29:06,082][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[44135],
        [  116],
        [  655],
        [ 2857],
        [ 4472],
        [ 6277],
        [10193],
        [14916],
        [11313],
        [12757],
        [11526],
        [14722],
        [13753],
        [13065]], device='cuda:0')
[2024-07-24 10:29:06,084][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[8442],
        [   1],
        [   1],
        [   1],
        [   4],
        [  14],
        [ 311],
        [ 919],
        [ 770],
        [   9],
        [ 349],
        [1695],
        [ 323],
        [1046]], device='cuda:0')
[2024-07-24 10:29:06,085][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[11242],
        [ 5116],
        [ 9357],
        [15785],
        [18637],
        [19560],
        [21528],
        [23129],
        [22144],
        [23451],
        [24750],
        [25759],
        [25751],
        [26846]], device='cuda:0')
[2024-07-24 10:29:06,087][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[18812],
        [31046],
        [31939],
        [31280],
        [30361],
        [30820],
        [29557],
        [28799],
        [28876],
        [29325],
        [29935],
        [28160],
        [27271],
        [28513]], device='cuda:0')
[2024-07-24 10:29:06,089][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[25478],
        [26070],
        [27106],
        [25608],
        [25949],
        [25739],
        [25627],
        [25537],
        [25744],
        [25455],
        [25348],
        [25398],
        [25560],
        [25281]], device='cuda:0')
[2024-07-24 10:29:06,090][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[ 82],
        [ 97],
        [101],
        [113],
        [150],
        [156],
        [152],
        [132],
        [127],
        [119],
        [120],
        [116],
        [111],
        [ 98]], device='cuda:0')
[2024-07-24 10:29:06,092][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[48426],
        [49345],
        [48175],
        [48363],
        [48347],
        [48666],
        [48191],
        [49355],
        [46541],
        [45986],
        [47716],
        [47791],
        [47106],
        [46032]], device='cuda:0')
[2024-07-24 10:29:06,093][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[ 2499],
        [39292],
        [42407],
        [38549],
        [40346],
        [35445],
        [33554],
        [33125],
        [34817],
        [35574],
        [38994],
        [36073],
        [34847],
        [33121]], device='cuda:0')
[2024-07-24 10:29:06,095][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[ 4326],
        [   88],
        [  148],
        [ 2100],
        [ 2148],
        [ 5586],
        [ 7832],
        [ 5937],
        [ 3574],
        [ 9417],
        [ 7859],
        [16109],
        [10829],
        [18969]], device='cuda:0')
[2024-07-24 10:29:06,097][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[32129],
        [50256],
        [50228],
        [50251],
        [41780],
        [42332],
        [39945],
        [32482],
        [36516],
        [38965],
        [25051],
        [21163],
        [27765],
        [22886]], device='cuda:0')
[2024-07-24 10:29:06,098][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[12158],
        [49880],
        [49480],
        [49550],
        [49251],
        [49129],
        [48389],
        [46113],
        [48106],
        [48211],
        [48612],
        [48501],
        [47404],
        [48537]], device='cuda:0')
[2024-07-24 10:29:06,100][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 9976],
        [13803],
        [13145],
        [11799],
        [15021],
        [14634],
        [16529],
        [14236],
        [15748],
        [15210],
        [15076],
        [17008],
        [15839],
        [15678]], device='cuda:0')
[2024-07-24 10:29:06,102][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[ 6450],
        [ 2206],
        [ 2908],
        [ 2848],
        [ 4652],
        [ 9337],
        [12796],
        [10500],
        [10226],
        [10373],
        [11120],
        [15206],
        [10943],
        [ 9678]], device='cuda:0')
[2024-07-24 10:29:06,103][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[26182],
        [ 7318],
        [12281],
        [15645],
        [15467],
        [14909],
        [18233],
        [20883],
        [20725],
        [23915],
        [19305],
        [21073],
        [23534],
        [20655]], device='cuda:0')
[2024-07-24 10:29:06,105][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[35096],
        [ 2697],
        [10006],
        [ 6265],
        [17546],
        [16021],
        [14570],
        [20252],
        [23552],
        [24476],
        [24146],
        [27150],
        [24590],
        [25779]], device='cuda:0')
[2024-07-24 10:29:06,107][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[ 8792],
        [ 6836],
        [ 7292],
        [10767],
        [14378],
        [15909],
        [16716],
        [14095],
        [15181],
        [18981],
        [17907],
        [19126],
        [17508],
        [20129]], device='cuda:0')
[2024-07-24 10:29:06,108][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[29311],
        [26203],
        [25308],
        [28937],
        [21863],
        [22753],
        [21419],
        [22688],
        [22787],
        [26062],
        [24248],
        [24150],
        [25398],
        [25427]], device='cuda:0')
[2024-07-24 10:29:06,110][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[39626],
        [39487],
        [39410],
        [39749],
        [39963],
        [39851],
        [39817],
        [39664],
        [39920],
        [39798],
        [40457],
        [40120],
        [40028],
        [40321]], device='cuda:0')
[2024-07-24 10:29:06,112][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[30127],
        [25096],
        [14209],
        [11687],
        [ 6257],
        [12454],
        [16863],
        [20559],
        [ 7042],
        [ 7661],
        [ 4318],
        [ 6571],
        [10071],
        [ 6843]], device='cuda:0')
[2024-07-24 10:29:06,113][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[45363],
        [12936],
        [ 8347],
        [ 9341],
        [16326],
        [17221],
        [16535],
        [33912],
        [12387],
        [11397],
        [13633],
        [12271],
        [12475],
        [11339]], device='cuda:0')
[2024-07-24 10:29:06,115][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[42100],
        [36416],
        [37523],
        [39209],
        [41571],
        [42807],
        [42583],
        [41514],
        [40829],
        [42930],
        [41933],
        [40317],
        [39519],
        [38435]], device='cuda:0')
[2024-07-24 10:29:06,116][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[21209],
        [ 7353],
        [ 6615],
        [10028],
        [ 7131],
        [ 7809],
        [ 8234],
        [ 7207],
        [ 6136],
        [ 6065],
        [ 5782],
        [ 5339],
        [ 5826],
        [ 6046]], device='cuda:0')
[2024-07-24 10:29:06,117][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[35944],
        [15233],
        [23382],
        [21235],
        [26423],
        [28009],
        [28094],
        [26124],
        [27821],
        [30128],
        [30490],
        [28097],
        [26888],
        [28378]], device='cuda:0')
[2024-07-24 10:29:06,119][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[36665],
        [19960],
        [10579],
        [ 8948],
        [ 5985],
        [ 7784],
        [ 8438],
        [10412],
        [ 9007],
        [ 8362],
        [ 7868],
        [ 7765],
        [ 7945],
        [ 8146]], device='cuda:0')
[2024-07-24 10:29:06,120][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[ 4029],
        [39923],
        [40320],
        [39237],
        [34441],
        [29451],
        [26490],
        [21644],
        [29778],
        [27984],
        [30021],
        [28072],
        [27837],
        [30239]], device='cuda:0')
[2024-07-24 10:29:06,122][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[35186],
        [39697],
        [37347],
        [37562],
        [37381],
        [34684],
        [32711],
        [33872],
        [34393],
        [31932],
        [34115],
        [31280],
        [33808],
        [32542]], device='cuda:0')
[2024-07-24 10:29:06,124][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[10503],
        [10503],
        [10503],
        [10503],
        [10503],
        [10503],
        [10503],
        [10503],
        [10503],
        [10503],
        [10503],
        [10503],
        [10503],
        [10503]], device='cuda:0')
[2024-07-24 10:29:06,214][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:29:06,215][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:06,217][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:06,218][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:06,219][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:06,220][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:06,221][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:06,221][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:06,222][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:06,223][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:06,224][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:06,225][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:06,225][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:06,226][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Amanda] are: tensor([0.9989, 0.0011], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:06,227][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Amanda] are: tensor([0.3806, 0.6194], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:06,228][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Amanda] are: tensor([0.3959, 0.6041], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:06,228][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Amanda] are: tensor([0.0350, 0.9650], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:06,229][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Amanda] are: tensor([0.2597, 0.7403], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:06,230][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Amanda] are: tensor([0.5463, 0.4537], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:06,231][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Amanda] are: tensor([0.9937, 0.0063], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:06,232][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Amanda] are: tensor([0.7871, 0.2129], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:06,234][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Amanda] are: tensor([0.2168, 0.7832], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:06,235][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Amanda] are: tensor([0.9678, 0.0322], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:06,236][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Amanda] are: tensor([0.5316, 0.4684], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:06,238][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Amanda] are: tensor([0.0713, 0.9287], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:06,239][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.9935, 0.0020, 0.0045], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:06,241][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.1841, 0.6369, 0.1790], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:06,243][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.1815, 0.3357, 0.4828], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:06,244][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0017, 0.7729, 0.2254], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:06,246][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0142, 0.9774, 0.0085], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:06,248][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.5113, 0.2522, 0.2366], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:06,249][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.9764, 0.0199, 0.0037], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:06,251][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.5667, 0.1057, 0.3275], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:06,252][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.1255, 0.4744, 0.4001], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:06,254][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.9226, 0.0567, 0.0207], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:06,256][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.4478, 0.4803, 0.0720], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:06,257][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0169, 0.9013, 0.0818], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:06,258][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ John] are: tensor([0.9784, 0.0025, 0.0048, 0.0143], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:06,259][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ John] are: tensor([0.4623, 0.3720, 0.1293, 0.0364], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:06,260][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ John] are: tensor([0.0642, 0.2385, 0.3263, 0.3710], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:06,260][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ John] are: tensor([0.0010, 0.2145, 0.0787, 0.7057], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:06,261][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ John] are: tensor([0.0150, 0.9419, 0.0074, 0.0357], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:06,263][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ John] are: tensor([0.2871, 0.1279, 0.1212, 0.4639], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:06,264][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ John] are: tensor([0.9842, 0.0086, 0.0026, 0.0046], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:06,266][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ John] are: tensor([0.4155, 0.0702, 0.3162, 0.1981], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:06,267][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ John] are: tensor([0.1125, 0.3103, 0.2774, 0.2997], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:06,269][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ John] are: tensor([0.9442, 0.0256, 0.0127, 0.0174], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:06,271][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ John] are: tensor([0.4579, 0.3746, 0.0522, 0.1153], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:06,272][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ John] are: tensor([0.0480, 0.6030, 0.0974, 0.2516], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:06,274][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ went] are: tensor([0.9588, 0.0041, 0.0095, 0.0192, 0.0084], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:06,275][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ went] are: tensor([0.1015, 0.2905, 0.1079, 0.1189, 0.3812], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:06,277][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ went] are: tensor([0.0359, 0.1730, 0.2499, 0.2797, 0.2615], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:06,279][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ went] are: tensor([0.0008, 0.1724, 0.0789, 0.5429, 0.2050], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:06,280][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ went] are: tensor([0.0784, 0.7192, 0.0047, 0.0219, 0.1757], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:06,282][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ went] are: tensor([0.6058, 0.0785, 0.0433, 0.2027, 0.0697], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:06,284][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ went] are: tensor([0.9214, 0.0246, 0.0074, 0.0290, 0.0177], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:06,285][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ went] are: tensor([0.3448, 0.0430, 0.2197, 0.1668, 0.2256], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:06,287][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.0616, 0.2320, 0.2142, 0.2269, 0.2653], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:06,289][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ went] are: tensor([0.8361, 0.0388, 0.0194, 0.0197, 0.0860], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:06,289][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ went] are: tensor([0.3302, 0.3264, 0.0552, 0.1242, 0.1640], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:06,290][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ went] are: tensor([0.0357, 0.5128, 0.1037, 0.1880, 0.1597], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:06,291][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.9460, 0.0037, 0.0082, 0.0201, 0.0057, 0.0163], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:06,292][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0712, 0.2080, 0.0589, 0.1028, 0.5264, 0.0326], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:06,293][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0395, 0.1434, 0.1932, 0.2343, 0.2050, 0.1847], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:06,294][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ to] are: tensor([3.8565e-04, 2.8367e-01, 6.5832e-02, 4.8308e-01, 1.4208e-01, 2.4948e-02],
       device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:06,295][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0088, 0.4929, 0.0116, 0.0143, 0.4660, 0.0064], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:06,297][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.3745, 0.0773, 0.0540, 0.2517, 0.0918, 0.1506], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:06,299][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.9535, 0.0191, 0.0048, 0.0111, 0.0068, 0.0047], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:06,300][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.1995, 0.0349, 0.1166, 0.1091, 0.1219, 0.4180], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:06,302][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0575, 0.1914, 0.1759, 0.1884, 0.2166, 0.1703], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:06,304][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.8808, 0.0208, 0.0124, 0.0155, 0.0403, 0.0303], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:06,305][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.4856, 0.2050, 0.0541, 0.0778, 0.0928, 0.0847], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:06,307][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0662, 0.4417, 0.1057, 0.1768, 0.1124, 0.0972], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:06,309][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.5309, 0.0029, 0.0057, 0.0150, 0.0046, 0.0100, 0.4311],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:06,310][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.1077, 0.1916, 0.0666, 0.0955, 0.4700, 0.0489, 0.0197],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:06,312][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0440, 0.1302, 0.1690, 0.2064, 0.1630, 0.1609, 0.1264],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:06,313][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ the] are: tensor([2.3736e-04, 2.7056e-01, 5.2697e-02, 4.9097e-01, 1.2812e-01, 2.2535e-02,
        3.4884e-02], device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:06,315][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0025, 0.7115, 0.0101, 0.0177, 0.2491, 0.0075, 0.0015],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:06,316][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.4946, 0.0638, 0.0339, 0.1704, 0.0555, 0.0918, 0.0899],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:06,318][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ the] are: tensor([9.7529e-01, 8.6355e-03, 1.7524e-03, 5.8951e-03, 4.2649e-03, 3.4413e-03,
        7.2516e-04], device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:06,319][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.2019, 0.0293, 0.1007, 0.0724, 0.0829, 0.2522, 0.2606],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:06,321][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0530, 0.1671, 0.1503, 0.1624, 0.1816, 0.1436, 0.1419],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:06,322][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.8519, 0.0243, 0.0141, 0.0155, 0.0402, 0.0337, 0.0202],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:06,322][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.4478, 0.2293, 0.0473, 0.0889, 0.0835, 0.0655, 0.0377],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:06,323][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0332, 0.4080, 0.0822, 0.2262, 0.1021, 0.0816, 0.0667],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:06,324][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ station] are: tensor([0.6281, 0.0017, 0.0032, 0.0103, 0.0033, 0.0057, 0.3453, 0.0024],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:06,326][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ station] are: tensor([0.4285, 0.1324, 0.0480, 0.0574, 0.2614, 0.0236, 0.0207, 0.0280],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:06,327][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ station] are: tensor([0.0446, 0.1058, 0.1425, 0.1792, 0.1522, 0.1487, 0.1120, 0.1151],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:06,329][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ station] are: tensor([0.0006, 0.1331, 0.0598, 0.4328, 0.1258, 0.0387, 0.0731, 0.1361],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:06,330][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ station] are: tensor([2.0126e-03, 6.8252e-01, 4.7308e-03, 2.6919e-02, 2.8051e-01, 1.8903e-03,
        5.4288e-04, 8.7302e-04], device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:06,332][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ station] are: tensor([0.4250, 0.0537, 0.0295, 0.1364, 0.0497, 0.0806, 0.0842, 0.1409],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:06,333][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ station] are: tensor([9.7924e-01, 5.8397e-03, 1.4188e-03, 5.9171e-03, 3.8756e-03, 1.5727e-03,
        8.6309e-04, 1.2684e-03], device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:06,335][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ station] are: tensor([0.3054, 0.0174, 0.0780, 0.0524, 0.0562, 0.1942, 0.2235, 0.0729],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:06,336][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ station] are: tensor([0.0573, 0.1439, 0.1262, 0.1371, 0.1599, 0.1230, 0.1246, 0.1280],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:06,338][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ station] are: tensor([0.8956, 0.0156, 0.0072, 0.0083, 0.0307, 0.0247, 0.0096, 0.0082],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:06,340][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ station] are: tensor([0.4843, 0.1788, 0.0386, 0.0565, 0.0866, 0.0588, 0.0304, 0.0660],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:06,341][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ station] are: tensor([0.0178, 0.4547, 0.0800, 0.1810, 0.0934, 0.0623, 0.0885, 0.0223],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:06,343][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.7234, 0.0024, 0.0051, 0.0112, 0.0034, 0.0069, 0.2377, 0.0027, 0.0072],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:06,345][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0311, 0.1451, 0.0527, 0.1118, 0.4227, 0.0664, 0.0498, 0.1006, 0.0198],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:06,347][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0380, 0.1129, 0.1438, 0.1764, 0.1401, 0.1351, 0.1015, 0.0987, 0.0535],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:06,348][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [,] are: tensor([2.3072e-04, 2.5725e-01, 4.7137e-02, 4.2031e-01, 1.2576e-01, 2.0404e-02,
        2.7162e-02, 8.4117e-02, 1.7640e-02], device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:06,349][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [,] are: tensor([7.3373e-04, 6.3958e-01, 2.1943e-02, 1.6791e-02, 3.1145e-01, 5.3108e-03,
        1.9269e-03, 2.2125e-03, 4.6811e-05], device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:06,351][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.4786, 0.0630, 0.0242, 0.1289, 0.0368, 0.0597, 0.0626, 0.1075, 0.0389],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:06,352][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.7514, 0.0680, 0.0127, 0.0562, 0.0438, 0.0240, 0.0128, 0.0217, 0.0095],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:06,353][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.2240, 0.0185, 0.0922, 0.0597, 0.0574, 0.2413, 0.2086, 0.0562, 0.0422],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:06,354][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0407, 0.1286, 0.1143, 0.1232, 0.1447, 0.1103, 0.1122, 0.1168, 0.1092],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:06,355][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.7009, 0.0452, 0.0239, 0.0283, 0.0688, 0.0418, 0.0272, 0.0180, 0.0460],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:06,356][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.2855, 0.2866, 0.0511, 0.0921, 0.0939, 0.0506, 0.0353, 0.0676, 0.0373],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:06,357][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0177, 0.5034, 0.0858, 0.1563, 0.0713, 0.0466, 0.0611, 0.0251, 0.0327],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:06,359][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ John] are: tensor([0.5796, 0.0035, 0.0060, 0.0177, 0.0040, 0.0101, 0.3335, 0.0027, 0.0098,
        0.0332], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:06,361][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ John] are: tensor([0.1004, 0.1263, 0.0476, 0.0198, 0.4857, 0.0640, 0.0340, 0.0742, 0.0353,
        0.0128], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:06,362][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ John] are: tensor([0.0172, 0.1066, 0.1383, 0.1680, 0.1193, 0.1239, 0.0934, 0.0942, 0.0512,
        0.0880], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:06,363][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ John] are: tensor([3.7481e-04, 2.2107e-01, 4.3669e-02, 4.1509e-01, 1.0989e-01, 2.6130e-02,
        3.6907e-02, 8.8770e-02, 2.2867e-02, 3.5230e-02], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:06,364][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ John] are: tensor([3.5922e-04, 8.8764e-01, 1.0852e-02, 2.8065e-02, 6.3469e-02, 3.7415e-03,
        1.4722e-03, 3.8480e-03, 4.4334e-05, 5.1204e-04], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:06,366][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ John] are: tensor([0.3566, 0.0453, 0.0280, 0.1098, 0.0426, 0.0719, 0.0737, 0.1149, 0.0541,
        0.1031], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:06,368][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ John] are: tensor([0.9429, 0.0106, 0.0039, 0.0088, 0.0068, 0.0108, 0.0020, 0.0043, 0.0033,
        0.0066], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:06,369][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ John] are: tensor([0.1369, 0.0132, 0.0850, 0.0476, 0.0512, 0.1929, 0.2558, 0.0683, 0.0487,
        0.1004], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:06,371][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ John] are: tensor([0.0369, 0.1069, 0.1026, 0.1097, 0.1222, 0.1047, 0.1046, 0.1039, 0.1006,
        0.1078], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:06,373][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ John] are: tensor([0.7673, 0.0167, 0.0125, 0.0151, 0.0520, 0.0419, 0.0249, 0.0131, 0.0297,
        0.0268], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:06,375][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ John] are: tensor([0.4019, 0.2003, 0.0334, 0.0764, 0.0824, 0.0407, 0.0235, 0.0524, 0.0273,
        0.0616], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:06,376][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ John] are: tensor([0.0622, 0.2653, 0.0884, 0.1202, 0.1523, 0.0820, 0.0673, 0.0493, 0.0600,
        0.0531], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:06,378][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.4991, 0.0045, 0.0069, 0.0172, 0.0054, 0.0089, 0.4087, 0.0037, 0.0095,
        0.0332, 0.0028], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:06,380][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0510, 0.1200, 0.0592, 0.0954, 0.3896, 0.0308, 0.0300, 0.0973, 0.0335,
        0.0656, 0.0276], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:06,381][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0177, 0.0982, 0.1248, 0.1494, 0.1211, 0.1160, 0.0848, 0.0789, 0.0446,
        0.0793, 0.0851], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:06,383][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([1.2544e-04, 1.4315e-01, 4.0786e-02, 4.2181e-01, 1.0397e-01, 3.4721e-02,
        4.3323e-02, 1.0260e-01, 2.5094e-02, 4.1380e-02, 4.3052e-02],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:06,384][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([5.9962e-03, 8.0932e-01, 6.2630e-03, 2.4196e-02, 1.4344e-01, 5.1943e-03,
        1.3807e-03, 1.7213e-03, 1.3118e-05, 3.2267e-04, 2.1570e-03],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:06,385][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.4506, 0.0464, 0.0219, 0.0887, 0.0319, 0.0486, 0.0527, 0.0822, 0.0381,
        0.0757, 0.0632], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:06,386][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.9214, 0.0197, 0.0053, 0.0167, 0.0086, 0.0056, 0.0031, 0.0034, 0.0037,
        0.0090, 0.0035], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:06,387][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.1853, 0.0119, 0.0782, 0.0469, 0.0465, 0.1868, 0.2135, 0.0608, 0.0406,
        0.0805, 0.0489], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:06,387][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.0284, 0.0984, 0.0921, 0.0978, 0.1128, 0.0926, 0.0933, 0.0934, 0.0889,
        0.0966, 0.1056], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:06,389][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.7296, 0.0364, 0.0165, 0.0198, 0.0436, 0.0418, 0.0204, 0.0135, 0.0262,
        0.0279, 0.0243], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:06,391][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.2946, 0.2283, 0.0401, 0.0821, 0.0759, 0.0614, 0.0332, 0.0469, 0.0258,
        0.0660, 0.0456], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:06,392][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0196, 0.3434, 0.0693, 0.1449, 0.1155, 0.0687, 0.0707, 0.0284, 0.0357,
        0.0695, 0.0341], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:06,394][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.3922, 0.0021, 0.0042, 0.0115, 0.0037, 0.0063, 0.2472, 0.0027, 0.0073,
        0.0271, 0.0020, 0.2936], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:06,396][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0340, 0.1516, 0.0662, 0.1687, 0.2500, 0.0514, 0.0338, 0.0605, 0.0298,
        0.0938, 0.0436, 0.0165], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:06,397][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0175, 0.0967, 0.1217, 0.1432, 0.1041, 0.1054, 0.0779, 0.0733, 0.0436,
        0.0762, 0.0762, 0.0643], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:06,399][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ a] are: tensor([2.6742e-04, 2.7243e-01, 4.8674e-02, 3.4979e-01, 1.0216e-01, 1.8786e-02,
        2.8615e-02, 7.7979e-02, 1.9405e-02, 2.8362e-02, 2.9453e-02, 2.4072e-02],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:06,400][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ a] are: tensor([9.0410e-04, 6.3787e-01, 2.2054e-02, 1.3508e-02, 3.0379e-01, 5.7885e-03,
        2.0875e-03, 2.8464e-03, 3.5619e-05, 4.1583e-04, 1.0437e-02, 2.5982e-04],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:06,401][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.4810, 0.0424, 0.0183, 0.0804, 0.0261, 0.0418, 0.0417, 0.0663, 0.0302,
        0.0643, 0.0517, 0.0558], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:06,403][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.8802, 0.0180, 0.0065, 0.0154, 0.0150, 0.0102, 0.0047, 0.0092, 0.0079,
        0.0169, 0.0096, 0.0064], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:06,405][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0722, 0.0153, 0.0803, 0.0489, 0.0514, 0.1665, 0.1864, 0.0637, 0.0480,
        0.0877, 0.0639, 0.1158], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:06,406][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0343, 0.0896, 0.0823, 0.0889, 0.1021, 0.0828, 0.0835, 0.0845, 0.0818,
        0.0906, 0.0974, 0.0823], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:06,408][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.5949, 0.0293, 0.0209, 0.0181, 0.0551, 0.0566, 0.0293, 0.0178, 0.0582,
        0.0340, 0.0413, 0.0446], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:06,410][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.2833, 0.1493, 0.0399, 0.0645, 0.0635, 0.0541, 0.0333, 0.0585, 0.0449,
        0.0817, 0.0528, 0.0742], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:06,412][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0263, 0.3141, 0.0729, 0.0987, 0.0747, 0.0708, 0.0818, 0.0310, 0.0518,
        0.0604, 0.0393, 0.0782], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:06,413][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ ring] are: tensor([0.4068, 0.0021, 0.0043, 0.0134, 0.0034, 0.0066, 0.2437, 0.0024, 0.0074,
        0.0284, 0.0019, 0.2768, 0.0029], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:06,415][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ ring] are: tensor([0.0827, 0.1215, 0.0433, 0.0830, 0.2438, 0.0587, 0.0469, 0.0793, 0.0385,
        0.0556, 0.0569, 0.0488, 0.0410], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:06,416][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ ring] are: tensor([0.0155, 0.0912, 0.1179, 0.1302, 0.0896, 0.0919, 0.0668, 0.0692, 0.0416,
        0.0666, 0.0709, 0.0577, 0.0910], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:06,417][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ ring] are: tensor([2.3677e-04, 2.6022e-01, 3.9400e-02, 3.3453e-01, 9.6090e-02, 1.8171e-02,
        2.9534e-02, 7.4367e-02, 2.0032e-02, 3.0660e-02, 3.0560e-02, 2.5292e-02,
        4.0903e-02], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:06,418][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ ring] are: tensor([1.9822e-04, 7.1482e-01, 1.9356e-02, 2.4355e-02, 2.2513e-01, 2.6921e-03,
        1.2843e-03, 2.4549e-03, 4.9632e-05, 2.7833e-04, 8.8933e-03, 2.8534e-04,
        2.0144e-04], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:06,419][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ ring] are: tensor([0.6082, 0.0311, 0.0114, 0.0576, 0.0167, 0.0316, 0.0285, 0.0477, 0.0189,
        0.0433, 0.0331, 0.0377, 0.0342], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:06,420][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ ring] are: tensor([0.7411, 0.0398, 0.0214, 0.0284, 0.0238, 0.0238, 0.0128, 0.0163, 0.0176,
        0.0224, 0.0173, 0.0177, 0.0177], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:06,422][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ ring] are: tensor([0.0987, 0.0129, 0.0624, 0.0405, 0.0433, 0.1186, 0.1524, 0.0462, 0.0432,
        0.0814, 0.0607, 0.0955, 0.1442], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:06,424][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ ring] are: tensor([0.0301, 0.0818, 0.0791, 0.0829, 0.0935, 0.0759, 0.0784, 0.0793, 0.0758,
        0.0822, 0.0891, 0.0768, 0.0752], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:06,425][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ ring] are: tensor([0.6764, 0.0214, 0.0126, 0.0163, 0.0492, 0.0335, 0.0189, 0.0181, 0.0286,
        0.0234, 0.0366, 0.0211, 0.0440], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:06,427][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ ring] are: tensor([0.2029, 0.1439, 0.0393, 0.1014, 0.0941, 0.0390, 0.0287, 0.0652, 0.0302,
        0.0792, 0.0593, 0.0439, 0.0728], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:06,429][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ ring] are: tensor([0.0301, 0.4139, 0.0525, 0.1292, 0.0825, 0.0502, 0.0610, 0.0294, 0.0276,
        0.0455, 0.0272, 0.0384, 0.0127], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:06,430][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.4313, 0.0019, 0.0042, 0.0112, 0.0028, 0.0068, 0.2294, 0.0024, 0.0076,
        0.0255, 0.0018, 0.2643, 0.0021, 0.0088], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:06,432][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0260, 0.0996, 0.0581, 0.1001, 0.2631, 0.0310, 0.0518, 0.0623, 0.0248,
        0.0797, 0.0413, 0.0485, 0.0943, 0.0196], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:06,434][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0237, 0.0739, 0.0914, 0.1167, 0.0907, 0.0901, 0.0655, 0.0652, 0.0368,
        0.0635, 0.0666, 0.0580, 0.0861, 0.0718], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:06,436][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0004, 0.2341, 0.0711, 0.3349, 0.1029, 0.0226, 0.0292, 0.0766, 0.0191,
        0.0239, 0.0236, 0.0178, 0.0267, 0.0173], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:06,437][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ to] are: tensor([3.5355e-03, 6.3968e-01, 1.6127e-02, 1.6007e-02, 2.8094e-01, 6.8180e-03,
        3.7139e-03, 6.7266e-03, 6.8571e-05, 1.0669e-03, 2.1922e-02, 1.4568e-03,
        1.2941e-03, 6.3799e-04], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:06,439][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.4549, 0.0323, 0.0151, 0.0691, 0.0211, 0.0372, 0.0364, 0.0561, 0.0264,
        0.0570, 0.0463, 0.0499, 0.0431, 0.0549], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:06,441][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.8372, 0.0269, 0.0106, 0.0235, 0.0112, 0.0098, 0.0066, 0.0081, 0.0081,
        0.0195, 0.0100, 0.0129, 0.0068, 0.0087], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:06,442][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.1174, 0.0085, 0.0593, 0.0382, 0.0387, 0.1332, 0.1387, 0.0412, 0.0288,
        0.0630, 0.0428, 0.0824, 0.1492, 0.0588], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:06,444][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0267, 0.0746, 0.0706, 0.0766, 0.0855, 0.0705, 0.0725, 0.0727, 0.0707,
        0.0783, 0.0834, 0.0716, 0.0717, 0.0746], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:06,446][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.7537, 0.0115, 0.0081, 0.0111, 0.0209, 0.0188, 0.0141, 0.0075, 0.0238,
        0.0227, 0.0151, 0.0214, 0.0327, 0.0388], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:06,447][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.4228, 0.0895, 0.0263, 0.0461, 0.0422, 0.0328, 0.0240, 0.0316, 0.0292,
        0.0614, 0.0401, 0.0507, 0.0490, 0.0543], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:06,448][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0472, 0.1718, 0.0643, 0.0870, 0.0553, 0.0645, 0.0897, 0.0262, 0.0579,
        0.0754, 0.0310, 0.0863, 0.0296, 0.1138], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:06,547][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:29:06,548][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:06,550][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:06,551][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:06,552][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:06,553][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:06,553][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:06,554][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:06,555][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:06,556][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:06,557][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:06,558][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:06,558][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:06,559][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Amanda] are: tensor([0.9972, 0.0029], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:06,560][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Amanda] are: tensor([0.3806, 0.6194], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:06,560][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Amanda] are: tensor([0.9737, 0.0263], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:06,561][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Amanda] are: tensor([0.5329, 0.4671], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:06,562][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Amanda] are: tensor([0.0928, 0.9072], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:06,563][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Amanda] are: tensor([0.8391, 0.1609], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:06,563][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Amanda] are: tensor([0.9743, 0.0257], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:06,564][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Amanda] are: tensor([0.0732, 0.9268], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:06,565][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Amanda] are: tensor([0.9798, 0.0202], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:06,565][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Amanda] are: tensor([0.9678, 0.0322], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:06,566][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Amanda] are: tensor([0.5316, 0.4684], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:06,567][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Amanda] are: tensor([0.0713, 0.9287], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:06,568][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.9910, 0.0032, 0.0058], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:06,570][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.1841, 0.6369, 0.1790], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:06,572][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.9159, 0.0678, 0.0163], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:06,573][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.3829, 0.5590, 0.0581], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:06,575][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0140, 0.9427, 0.0433], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:06,576][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.4777, 0.5114, 0.0109], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:06,578][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.9196, 0.0665, 0.0139], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:06,579][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0052, 0.9854, 0.0094], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:06,581][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.9425, 0.0556, 0.0019], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:06,583][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.9226, 0.0567, 0.0207], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:06,584][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.4478, 0.4803, 0.0720], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:06,586][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0169, 0.9013, 0.0818], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:06,588][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ John] are: tensor([0.9769, 0.0028, 0.0053, 0.0151], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:06,589][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ John] are: tensor([0.4623, 0.3720, 0.1293, 0.0364], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:06,591][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ John] are: tensor([0.9479, 0.0278, 0.0084, 0.0158], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:06,592][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ John] are: tensor([0.5761, 0.1977, 0.0293, 0.1969], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:06,594][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ John] are: tensor([0.0231, 0.8354, 0.0315, 0.1100], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:06,596][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ John] are: tensor([0.7089, 0.2377, 0.0105, 0.0429], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:06,597][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ John] are: tensor([0.9679, 0.0176, 0.0059, 0.0086], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:06,599][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ John] are: tensor([0.0223, 0.9014, 0.0203, 0.0561], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:06,600][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ John] are: tensor([9.8742e-01, 1.0113e-02, 4.8822e-04, 1.9796e-03], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:06,601][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ John] are: tensor([0.9442, 0.0256, 0.0127, 0.0174], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:06,601][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ John] are: tensor([0.4579, 0.3746, 0.0522, 0.1153], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:06,602][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ John] are: tensor([0.0480, 0.6030, 0.0974, 0.2516], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:06,604][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([0.9527, 0.0055, 0.0109, 0.0238, 0.0071], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:06,605][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([0.1015, 0.2905, 0.1079, 0.1189, 0.3812], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:06,607][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([0.7823, 0.0876, 0.0279, 0.0415, 0.0606], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:06,609][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([0.2640, 0.3222, 0.0884, 0.2151, 0.1104], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:06,610][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([0.0275, 0.5877, 0.0280, 0.0815, 0.2754], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:06,612][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([0.3897, 0.3910, 0.0079, 0.0650, 0.1464], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:06,613][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([0.8947, 0.0365, 0.0123, 0.0361, 0.0205], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:06,615][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([0.0336, 0.7147, 0.0088, 0.0726, 0.1703], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:06,617][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([0.9519, 0.0277, 0.0016, 0.0061, 0.0128], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:06,618][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([0.8361, 0.0388, 0.0194, 0.0197, 0.0860], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:06,620][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([0.3302, 0.3264, 0.0552, 0.1242, 0.1640], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:06,622][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([0.0357, 0.5128, 0.1037, 0.1880, 0.1597], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:06,623][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.9563, 0.0030, 0.0060, 0.0175, 0.0028, 0.0144], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:06,625][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0712, 0.2080, 0.0589, 0.1028, 0.5264, 0.0326], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:06,627][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.8979, 0.0396, 0.0146, 0.0134, 0.0294, 0.0051], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:06,628][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.3157, 0.3061, 0.0662, 0.1682, 0.1090, 0.0347], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:06,630][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0597, 0.3814, 0.0289, 0.0497, 0.3244, 0.1558], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:06,631][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.7427, 0.1406, 0.0044, 0.0297, 0.0707, 0.0119], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:06,632][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.9493, 0.0220, 0.0053, 0.0117, 0.0070, 0.0047], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:06,633][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0546, 0.4175, 0.0086, 0.0504, 0.1300, 0.3389], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:06,633][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.9657, 0.0205, 0.0010, 0.0046, 0.0064, 0.0018], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:06,635][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.8808, 0.0208, 0.0124, 0.0155, 0.0403, 0.0303], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:06,636][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.4856, 0.2050, 0.0541, 0.0778, 0.0928, 0.0847], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:06,638][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0662, 0.4417, 0.1057, 0.1768, 0.1124, 0.0972], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:06,639][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([1.7851e-01, 8.2203e-04, 1.5338e-03, 5.2795e-03, 7.6828e-04, 3.1248e-03,
        8.0996e-01], device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:06,641][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.1077, 0.1916, 0.0666, 0.0955, 0.4700, 0.0489, 0.0197],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:06,642][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.8532, 0.0484, 0.0232, 0.0203, 0.0324, 0.0057, 0.0168],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:06,644][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.2931, 0.2927, 0.0623, 0.2046, 0.0850, 0.0263, 0.0361],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:06,646][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0201, 0.4938, 0.0245, 0.0564, 0.1996, 0.1424, 0.0631],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:06,647][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.7019, 0.1395, 0.0059, 0.0388, 0.0845, 0.0198, 0.0095],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:06,649][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.9610, 0.0151, 0.0035, 0.0080, 0.0055, 0.0055, 0.0014],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:06,651][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0145, 0.2894, 0.0105, 0.0340, 0.1755, 0.4471, 0.0290],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:06,652][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([9.6865e-01, 1.8648e-02, 9.0248e-04, 4.8757e-03, 4.6376e-03, 1.3877e-03,
        8.9839e-04], device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:06,653][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.8519, 0.0243, 0.0141, 0.0155, 0.0402, 0.0337, 0.0202],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:06,655][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.4478, 0.2293, 0.0473, 0.0889, 0.0835, 0.0655, 0.0377],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:06,657][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0332, 0.4080, 0.0822, 0.2262, 0.1021, 0.0816, 0.0667],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:06,658][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ station] are: tensor([0.2652, 0.0008, 0.0011, 0.0039, 0.0008, 0.0020, 0.7252, 0.0011],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:06,660][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ station] are: tensor([0.4285, 0.1324, 0.0480, 0.0574, 0.2614, 0.0236, 0.0207, 0.0280],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:06,662][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ station] are: tensor([0.9483, 0.0176, 0.0055, 0.0052, 0.0153, 0.0021, 0.0039, 0.0022],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:06,663][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ station] are: tensor([0.3929, 0.2482, 0.0651, 0.1381, 0.0525, 0.0192, 0.0293, 0.0546],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:06,663][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ station] are: tensor([0.0490, 0.4642, 0.0134, 0.0702, 0.2304, 0.0748, 0.0396, 0.0584],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:06,664][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ station] are: tensor([0.7059, 0.1671, 0.0026, 0.0286, 0.0700, 0.0081, 0.0065, 0.0112],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:06,666][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ station] are: tensor([0.9782, 0.0066, 0.0018, 0.0052, 0.0037, 0.0021, 0.0011, 0.0014],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:06,667][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ station] are: tensor([0.0293, 0.4318, 0.0045, 0.0364, 0.1939, 0.2706, 0.0185, 0.0149],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:06,668][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ station] are: tensor([9.7511e-01, 1.4190e-02, 5.8169e-04, 3.6749e-03, 4.0250e-03, 9.6598e-04,
        7.9565e-04, 6.5932e-04], device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:06,670][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ station] are: tensor([0.8956, 0.0156, 0.0072, 0.0083, 0.0307, 0.0247, 0.0096, 0.0082],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:06,671][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ station] are: tensor([0.4843, 0.1788, 0.0386, 0.0565, 0.0866, 0.0588, 0.0304, 0.0660],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:06,673][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ station] are: tensor([0.0178, 0.4547, 0.0800, 0.1810, 0.0934, 0.0623, 0.0885, 0.0223],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:06,674][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.4088, 0.0013, 0.0028, 0.0071, 0.0012, 0.0031, 0.5675, 0.0019, 0.0062],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:06,676][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0311, 0.1451, 0.0527, 0.1118, 0.4227, 0.0664, 0.0498, 0.1006, 0.0198],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:06,678][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.8118, 0.0594, 0.0320, 0.0203, 0.0367, 0.0071, 0.0135, 0.0084, 0.0106],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:06,680][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.1504, 0.2948, 0.0712, 0.1856, 0.1078, 0.0276, 0.0373, 0.0610, 0.0643],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:06,681][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0165, 0.4590, 0.0317, 0.0461, 0.2188, 0.0790, 0.0462, 0.0898, 0.0130],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:06,683][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.4241, 0.3250, 0.0108, 0.0598, 0.1179, 0.0124, 0.0119, 0.0313, 0.0067],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:06,685][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.7289, 0.0756, 0.0164, 0.0539, 0.0392, 0.0319, 0.0159, 0.0254, 0.0127],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:06,687][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0098, 0.6259, 0.0105, 0.0482, 0.1198, 0.1021, 0.0221, 0.0518, 0.0099],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:06,688][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.9377, 0.0343, 0.0015, 0.0093, 0.0102, 0.0019, 0.0017, 0.0019, 0.0016],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:06,690][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.7009, 0.0452, 0.0239, 0.0283, 0.0688, 0.0418, 0.0272, 0.0180, 0.0460],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:06,692][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.2855, 0.2866, 0.0511, 0.0921, 0.0939, 0.0506, 0.0353, 0.0676, 0.0373],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:06,693][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0177, 0.5034, 0.0858, 0.1563, 0.0713, 0.0466, 0.0611, 0.0251, 0.0327],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:06,694][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ John] are: tensor([0.2713, 0.0016, 0.0028, 0.0083, 0.0012, 0.0052, 0.6778, 0.0015, 0.0074,
        0.0230], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:06,694][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ John] are: tensor([0.1004, 0.1263, 0.0476, 0.0198, 0.4857, 0.0640, 0.0340, 0.0742, 0.0353,
        0.0128], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:06,695][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ John] are: tensor([0.8333, 0.0390, 0.0156, 0.0263, 0.0255, 0.0102, 0.0141, 0.0067, 0.0127,
        0.0167], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:06,697][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ John] are: tensor([0.3253, 0.1183, 0.0349, 0.1596, 0.0703, 0.0343, 0.0387, 0.0734, 0.0561,
        0.0890], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:06,698][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ John] are: tensor([0.0183, 0.5280, 0.0167, 0.0580, 0.0715, 0.0697, 0.0431, 0.0994, 0.0087,
        0.0865], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:06,700][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ John] are: tensor([0.6169, 0.1703, 0.0072, 0.0372, 0.0678, 0.0144, 0.0100, 0.0307, 0.0108,
        0.0349], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:06,702][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ John] are: tensor([0.9052, 0.0179, 0.0073, 0.0125, 0.0099, 0.0146, 0.0039, 0.0093, 0.0074,
        0.0119], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:06,704][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ John] are: tensor([0.0206, 0.3780, 0.0107, 0.0294, 0.1200, 0.2456, 0.0285, 0.0748, 0.0159,
        0.0764], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:06,705][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ John] are: tensor([9.7869e-01, 8.5710e-03, 6.8764e-04, 2.7595e-03, 3.0875e-03, 1.3215e-03,
        1.0236e-03, 5.7042e-04, 9.9261e-04, 2.2961e-03], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:06,706][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ John] are: tensor([0.7673, 0.0167, 0.0125, 0.0151, 0.0520, 0.0419, 0.0249, 0.0131, 0.0297,
        0.0268], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:06,708][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ John] are: tensor([0.4019, 0.2003, 0.0334, 0.0764, 0.0824, 0.0407, 0.0235, 0.0524, 0.0273,
        0.0616], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:06,710][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ John] are: tensor([0.0622, 0.2653, 0.0884, 0.1202, 0.1523, 0.0820, 0.0673, 0.0493, 0.0600,
        0.0531], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:06,711][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([1.4647e-01, 2.2385e-03, 2.7252e-03, 8.0040e-03, 1.4985e-03, 3.6719e-03,
        8.0230e-01, 1.9280e-03, 5.8207e-03, 2.4552e-02, 7.9339e-04],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:06,713][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0510, 0.1200, 0.0592, 0.0954, 0.3896, 0.0308, 0.0300, 0.0973, 0.0335,
        0.0656, 0.0276], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:06,714][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.4809, 0.1375, 0.0662, 0.0650, 0.0703, 0.0179, 0.0390, 0.0111, 0.0281,
        0.0314, 0.0526], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:06,716][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.0895, 0.2579, 0.0475, 0.1826, 0.0819, 0.0342, 0.0368, 0.0501, 0.0533,
        0.1060, 0.0601], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:06,718][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.0325, 0.4413, 0.0139, 0.0525, 0.0994, 0.0801, 0.0528, 0.0617, 0.0055,
        0.0886, 0.0718], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:06,720][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.4318, 0.2964, 0.0058, 0.0481, 0.0725, 0.0128, 0.0114, 0.0240, 0.0046,
        0.0442, 0.0483], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:06,721][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.8979, 0.0261, 0.0080, 0.0195, 0.0086, 0.0065, 0.0043, 0.0051, 0.0061,
        0.0128, 0.0050], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:06,723][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0536, 0.4201, 0.0068, 0.0473, 0.0853, 0.1821, 0.0130, 0.0233, 0.0069,
        0.0806, 0.0810], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:06,724][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.9493, 0.0230, 0.0012, 0.0055, 0.0076, 0.0020, 0.0015, 0.0012, 0.0012,
        0.0041, 0.0035], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:06,725][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.7296, 0.0364, 0.0165, 0.0198, 0.0436, 0.0418, 0.0204, 0.0135, 0.0262,
        0.0279, 0.0243], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:06,726][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.2946, 0.2283, 0.0401, 0.0821, 0.0759, 0.0614, 0.0332, 0.0469, 0.0258,
        0.0660, 0.0456], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:06,727][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.0196, 0.3434, 0.0693, 0.1449, 0.1155, 0.0687, 0.0707, 0.0284, 0.0357,
        0.0695, 0.0341], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:06,728][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([1.0236e-01, 6.3264e-04, 1.1611e-03, 3.7455e-03, 6.8055e-04, 1.7217e-03,
        3.5786e-01, 8.2776e-04, 2.8176e-03, 1.4766e-02, 3.2984e-04, 5.1309e-01],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:06,730][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0340, 0.1516, 0.0662, 0.1687, 0.2500, 0.0514, 0.0338, 0.0605, 0.0298,
        0.0938, 0.0436, 0.0165], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:06,731][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.6489, 0.0760, 0.0438, 0.0375, 0.0467, 0.0128, 0.0279, 0.0136, 0.0181,
        0.0207, 0.0406, 0.0134], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:06,733][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.1947, 0.1606, 0.0367, 0.1335, 0.0582, 0.0226, 0.0325, 0.0576, 0.0685,
        0.1014, 0.0862, 0.0475], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:06,735][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0217, 0.2855, 0.0228, 0.0297, 0.1339, 0.0737, 0.0486, 0.0671, 0.0096,
        0.0858, 0.1713, 0.0504], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:06,736][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.5187, 0.1560, 0.0049, 0.0395, 0.0591, 0.0108, 0.0077, 0.0255, 0.0068,
        0.0520, 0.0916, 0.0274], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:06,738][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.8707, 0.0212, 0.0083, 0.0149, 0.0122, 0.0116, 0.0056, 0.0097, 0.0092,
        0.0172, 0.0107, 0.0088], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:06,740][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0211, 0.3236, 0.0072, 0.0283, 0.0735, 0.1194, 0.0121, 0.0497, 0.0127,
        0.0903, 0.2055, 0.0567], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:06,742][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.9465, 0.0198, 0.0012, 0.0065, 0.0064, 0.0021, 0.0014, 0.0015, 0.0016,
        0.0062, 0.0035, 0.0033], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:06,743][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.5949, 0.0293, 0.0209, 0.0181, 0.0551, 0.0566, 0.0293, 0.0178, 0.0582,
        0.0340, 0.0413, 0.0446], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:06,745][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.2833, 0.1493, 0.0399, 0.0645, 0.0635, 0.0541, 0.0333, 0.0585, 0.0449,
        0.0817, 0.0528, 0.0742], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:06,747][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0263, 0.3141, 0.0729, 0.0987, 0.0747, 0.0708, 0.0818, 0.0310, 0.0518,
        0.0604, 0.0393, 0.0782], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:06,748][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ ring] are: tensor([1.2223e-01, 7.9265e-04, 1.4470e-03, 4.8776e-03, 7.0442e-04, 1.8746e-03,
        3.6180e-01, 8.7982e-04, 3.4632e-03, 1.6847e-02, 3.8846e-04, 4.8395e-01,
        7.5166e-04], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:06,750][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ ring] are: tensor([0.0827, 0.1215, 0.0433, 0.0830, 0.2438, 0.0587, 0.0469, 0.0793, 0.0385,
        0.0556, 0.0569, 0.0488, 0.0410], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:06,751][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ ring] are: tensor([0.5747, 0.0737, 0.0436, 0.0588, 0.0513, 0.0114, 0.0204, 0.0150, 0.0245,
        0.0364, 0.0695, 0.0102, 0.0105], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:06,753][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ ring] are: tensor([0.0687, 0.1007, 0.0481, 0.1362, 0.0550, 0.0297, 0.0455, 0.0630, 0.0847,
        0.0792, 0.0570, 0.0545, 0.1776], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:06,755][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ ring] are: tensor([0.0147, 0.3419, 0.0154, 0.0375, 0.1027, 0.0389, 0.0312, 0.0663, 0.0087,
        0.0583, 0.2002, 0.0606, 0.0235], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:06,756][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ ring] are: tensor([0.3788, 0.2471, 0.0071, 0.0507, 0.0797, 0.0091, 0.0073, 0.0363, 0.0060,
        0.0377, 0.0723, 0.0336, 0.0343], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:06,757][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ ring] are: tensor([0.7659, 0.0324, 0.0189, 0.0207, 0.0177, 0.0237, 0.0122, 0.0166, 0.0184,
        0.0188, 0.0182, 0.0202, 0.0164], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:06,757][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ ring] are: tensor([0.0133, 0.5491, 0.0048, 0.0347, 0.0701, 0.0411, 0.0083, 0.0201, 0.0034,
        0.0448, 0.1310, 0.0301, 0.0491], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:06,759][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ ring] are: tensor([0.9376, 0.0177, 0.0022, 0.0072, 0.0096, 0.0024, 0.0021, 0.0024, 0.0022,
        0.0047, 0.0052, 0.0039, 0.0028], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:06,761][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ ring] are: tensor([0.6764, 0.0214, 0.0126, 0.0163, 0.0492, 0.0335, 0.0189, 0.0181, 0.0286,
        0.0234, 0.0366, 0.0211, 0.0440], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:06,762][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ ring] are: tensor([0.2029, 0.1439, 0.0393, 0.1014, 0.0941, 0.0390, 0.0287, 0.0652, 0.0302,
        0.0792, 0.0593, 0.0439, 0.0728], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:06,764][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ ring] are: tensor([0.0301, 0.4139, 0.0525, 0.1292, 0.0825, 0.0502, 0.0610, 0.0294, 0.0276,
        0.0455, 0.0272, 0.0384, 0.0127], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:06,765][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([1.1530e-01, 5.3128e-04, 1.1685e-03, 3.9315e-03, 5.2228e-04, 2.1337e-03,
        3.4150e-01, 9.5240e-04, 4.0047e-03, 1.6759e-02, 3.4808e-04, 5.0825e-01,
        4.4127e-04, 4.1532e-03], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:06,767][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0260, 0.0996, 0.0581, 0.1001, 0.2631, 0.0310, 0.0518, 0.0623, 0.0248,
        0.0797, 0.0413, 0.0485, 0.0943, 0.0196], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:06,769][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.6487, 0.0647, 0.0358, 0.0291, 0.0541, 0.0114, 0.0216, 0.0121, 0.0201,
        0.0165, 0.0523, 0.0152, 0.0088, 0.0095], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:06,771][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.2182, 0.1177, 0.0435, 0.1094, 0.0561, 0.0221, 0.0317, 0.0502, 0.0619,
        0.0849, 0.0464, 0.0569, 0.0751, 0.0257], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:06,772][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0588, 0.1496, 0.0110, 0.0193, 0.0743, 0.0488, 0.0480, 0.0613, 0.0107,
        0.1012, 0.1582, 0.0972, 0.0464, 0.1152], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:06,774][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.6859, 0.0660, 0.0028, 0.0204, 0.0258, 0.0054, 0.0059, 0.0110, 0.0057,
        0.0331, 0.0509, 0.0276, 0.0431, 0.0165], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:06,776][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.8558, 0.0243, 0.0088, 0.0180, 0.0085, 0.0075, 0.0058, 0.0075, 0.0087,
        0.0188, 0.0096, 0.0131, 0.0064, 0.0073], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:06,778][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0816, 0.1350, 0.0028, 0.0199, 0.0174, 0.0519, 0.0072, 0.0164, 0.0076,
        0.0851, 0.0827, 0.0569, 0.1645, 0.2709], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:06,779][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([9.5770e-01, 1.2822e-02, 6.9796e-04, 3.9188e-03, 3.6894e-03, 1.2570e-03,
        1.1303e-03, 1.2050e-03, 1.1777e-03, 4.7828e-03, 3.1426e-03, 2.7814e-03,
        3.7693e-03, 1.9211e-03], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:06,781][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.7537, 0.0115, 0.0081, 0.0111, 0.0209, 0.0188, 0.0141, 0.0075, 0.0238,
        0.0227, 0.0151, 0.0214, 0.0327, 0.0388], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:06,782][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.4228, 0.0895, 0.0263, 0.0461, 0.0422, 0.0328, 0.0240, 0.0316, 0.0292,
        0.0614, 0.0401, 0.0507, 0.0490, 0.0543], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:06,784][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0472, 0.1718, 0.0643, 0.0870, 0.0553, 0.0645, 0.0897, 0.0262, 0.0579,
        0.0754, 0.0310, 0.0863, 0.0296, 0.1138], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:06,788][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:29:06,789][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[5354],
        [1364],
        [ 108],
        [ 848],
        [ 287],
        [ 172],
        [ 318],
        [ 166],
        [ 151],
        [ 777],
        [ 744],
        [ 369],
        [ 568],
        [ 179]], device='cuda:0')
[2024-07-24 10:29:06,791][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[6196],
        [ 994],
        [  84],
        [1297],
        [ 659],
        [ 343],
        [ 693],
        [ 335],
        [ 350],
        [2109],
        [1943],
        [ 880],
        [1084],
        [ 518]], device='cuda:0')
[2024-07-24 10:29:06,792][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[21592],
        [21634],
        [21862],
        [22862],
        [23888],
        [24257],
        [27493],
        [26839],
        [26436],
        [28255],
        [28462],
        [25690],
        [25965],
        [25804]], device='cuda:0')
[2024-07-24 10:29:06,794][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[23594],
        [50017],
        [49462],
        [48824],
        [32983],
        [23004],
        [22184],
        [24721],
        [18907],
        [15140],
        [17620],
        [22717],
        [17068],
        [15812]], device='cuda:0')
[2024-07-24 10:29:06,796][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 668],
        [5930],
        [5556],
        [5093],
        [4524],
        [4482],
        [4256],
        [4025],
        [4118],
        [4258],
        [4350],
        [4467],
        [4551],
        [4437]], device='cuda:0')
[2024-07-24 10:29:06,797][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[11490],
        [13656],
        [ 9906],
        [ 7325],
        [ 6063],
        [ 6705],
        [ 6593],
        [ 4449],
        [ 5717],
        [ 5476],
        [ 4929],
        [ 5749],
        [ 5784],
        [ 5400]], device='cuda:0')
[2024-07-24 10:29:06,799][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[32588],
        [15807],
        [15155],
        [14906],
        [17432],
        [21787],
        [18153],
        [18621],
        [19157],
        [15523],
        [16627],
        [19144],
        [17792],
        [18910]], device='cuda:0')
[2024-07-24 10:29:06,800][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[1679],
        [1173],
        [1298],
        [1170],
        [1191],
        [1156],
        [1227],
        [1316],
        [1308],
        [1372],
        [1280],
        [1271],
        [1291],
        [1291]], device='cuda:0')
[2024-07-24 10:29:06,802][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[18928],
        [20242],
        [22870],
        [21401],
        [27735],
        [24350],
        [21496],
        [20780],
        [33986],
        [22696],
        [26176],
        [25227],
        [26945],
        [27629]], device='cuda:0')
[2024-07-24 10:29:06,803][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[6937],
        [4652],
        [3438],
        [4520],
        [5493],
        [4551],
        [4789],
        [4800],
        [4771],
        [5904],
        [6138],
        [6880],
        [7443],
        [7363]], device='cuda:0')
[2024-07-24 10:29:06,805][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[19294],
        [32167],
        [15214],
        [ 9184],
        [ 8696],
        [ 8152],
        [ 7010],
        [ 6248],
        [ 5252],
        [ 4891],
        [ 5243],
        [ 5353],
        [ 5067],
        [ 5280]], device='cuda:0')
[2024-07-24 10:29:06,807][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[14364],
        [14233],
        [16451],
        [18168],
        [21087],
        [21508],
        [24244],
        [20679],
        [29980],
        [30099],
        [29223],
        [32586],
        [33185],
        [32925]], device='cuda:0')
[2024-07-24 10:29:06,808][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[31328],
        [    5],
        [    8],
        [   27],
        [  200],
        [  349],
        [  293],
        [  661],
        [  349],
        [  676],
        [  717],
        [ 1942],
        [ 3205],
        [ 4051]], device='cuda:0')
[2024-07-24 10:29:06,810][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[16294],
        [50257],
        [50257],
        [50255],
        [50250],
        [50244],
        [50223],
        [50242],
        [50251],
        [49872],
        [50133],
        [50050],
        [50224],
        [47907]], device='cuda:0')
[2024-07-24 10:29:06,812][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[11542],
        [ 9027],
        [ 9064],
        [ 8034],
        [ 8283],
        [ 8626],
        [ 8591],
        [ 8558],
        [ 8717],
        [ 8268],
        [ 8961],
        [ 9252],
        [ 9151],
        [ 8924]], device='cuda:0')
[2024-07-24 10:29:06,813][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[12603],
        [12179],
        [11865],
        [10001],
        [ 8530],
        [ 9270],
        [16985],
        [16828],
        [15904],
        [15578],
        [16025],
        [17555],
        [17276],
        [17323]], device='cuda:0')
[2024-07-24 10:29:06,815][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[7000],
        [3981],
        [4379],
        [6073],
        [3869],
        [3438],
        [3621],
        [4793],
        [3481],
        [4161],
        [3669],
        [3028],
        [4368],
        [4598]], device='cuda:0')
[2024-07-24 10:29:06,816][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[23146],
        [20776],
        [12269],
        [17964],
        [ 4398],
        [15075],
        [ 9394],
        [20389],
        [ 6503],
        [ 7828],
        [ 1798],
        [ 2987],
        [ 2260],
        [ 3770]], device='cuda:0')
[2024-07-24 10:29:06,818][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[ 9078],
        [20431],
        [21111],
        [10541],
        [ 9350],
        [10000],
        [ 9374],
        [10228],
        [ 8787],
        [ 6675],
        [ 6644],
        [ 6047],
        [ 8594],
        [ 7528]], device='cuda:0')
[2024-07-24 10:29:06,820][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[14241],
        [14781],
        [16315],
        [18434],
        [25407],
        [27154],
        [26231],
        [25690],
        [25890],
        [23889],
        [27914],
        [33194],
        [32689],
        [32292]], device='cuda:0')
[2024-07-24 10:29:06,821][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[33225],
        [26508],
        [24940],
        [25146],
        [26110],
        [26501],
        [26595],
        [26439],
        [26886],
        [27609],
        [27889],
        [29571],
        [29232],
        [31319]], device='cuda:0')
[2024-07-24 10:29:06,822][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[24833],
        [16986],
        [ 6168],
        [16427],
        [ 5031],
        [13069],
        [16120],
        [20170],
        [ 1668],
        [ 8175],
        [ 6439],
        [ 5877],
        [ 3881],
        [ 5702]], device='cuda:0')
[2024-07-24 10:29:06,824][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[ 6720],
        [ 8063],
        [ 8503],
        [ 8798],
        [10439],
        [13778],
        [15964],
        [13719],
        [11107],
        [13256],
        [14508],
        [18681],
        [14690],
        [20057]], device='cuda:0')
[2024-07-24 10:29:06,825][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[14189],
        [15940],
        [19460],
        [15134],
        [17332],
        [16608],
        [16385],
        [15735],
        [18324],
        [15425],
        [17312],
        [17276],
        [17835],
        [16718]], device='cuda:0')
[2024-07-24 10:29:06,827][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[39146],
        [38433],
        [35424],
        [35289],
        [27720],
        [29558],
        [27170],
        [32034],
        [21183],
        [22400],
        [20804],
        [19637],
        [20774],
        [21139]], device='cuda:0')
[2024-07-24 10:29:06,829][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[ 4444],
        [31559],
        [34029],
        [28400],
        [24838],
        [30947],
        [30186],
        [32425],
        [31000],
        [28344],
        [25999],
        [24861],
        [22769],
        [24950]], device='cuda:0')
[2024-07-24 10:29:06,830][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[23290],
        [26805],
        [24220],
        [23797],
        [22445],
        [20849],
        [20495],
        [20754],
        [20497],
        [22404],
        [20472],
        [18174],
        [20482],
        [21710]], device='cuda:0')
[2024-07-24 10:29:06,832][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[34442],
        [25931],
        [33420],
        [32330],
        [41529],
        [29538],
        [29962],
        [23687],
        [40354],
        [37993],
        [41411],
        [39741],
        [40525],
        [37269]], device='cuda:0')
[2024-07-24 10:29:06,833][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[33841],
        [39377],
        [38737],
        [39119],
        [40011],
        [40252],
        [40990],
        [40495],
        [41432],
        [40186],
        [40237],
        [39438],
        [39291],
        [38954]], device='cuda:0')
[2024-07-24 10:29:06,835][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[11089],
        [11089],
        [11089],
        [11089],
        [11089],
        [11089],
        [11089],
        [11089],
        [11089],
        [11089],
        [11089],
        [11089],
        [11089],
        [11089]], device='cuda:0')
[2024-07-24 10:29:06,933][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:29:06,934][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:06,935][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:06,936][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:06,936][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:06,937][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:06,938][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:06,939][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:06,940][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:06,942][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:06,943][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:06,944][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:06,946][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:06,947][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Amanda] are: tensor([0.3579, 0.6421], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:06,949][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Amanda] are: tensor([0.0036, 0.9964], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:06,951][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Amanda] are: tensor([0.6242, 0.3758], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:06,952][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Amanda] are: tensor([0.7203, 0.2797], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:06,954][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Amanda] are: tensor([0.0177, 0.9823], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:06,955][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Amanda] are: tensor([0.7241, 0.2759], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:06,957][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Amanda] are: tensor([1.6397e-04, 9.9984e-01], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:06,958][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Amanda] are: tensor([0.1274, 0.8726], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:06,960][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Amanda] are: tensor([0.6859, 0.3141], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:06,961][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Amanda] are: tensor([1.4264e-05, 9.9999e-01], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:06,962][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Amanda] are: tensor([0.0050, 0.9950], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:06,964][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Amanda] are: tensor([0.0031, 0.9969], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:06,965][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.4108, 0.5477, 0.0414], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:06,966][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0069, 0.9399, 0.0532], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:06,966][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.4261, 0.5270, 0.0469], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:06,967][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0862, 0.8956, 0.0183], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:06,968][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0508, 0.7674, 0.1819], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:06,969][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.8938, 0.0983, 0.0079], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:06,970][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ and] are: tensor([3.2238e-04, 8.8264e-01, 1.1704e-01], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:06,972][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0323, 0.9006, 0.0671], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:06,974][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.7566, 0.1633, 0.0801], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:06,975][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ and] are: tensor([1.3184e-05, 6.2584e-01, 3.7414e-01], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:06,976][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ and] are: tensor([6.9778e-04, 9.9219e-01, 7.1141e-03], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:06,978][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0016, 0.8902, 0.1082], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:06,979][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ John] are: tensor([0.4799, 0.3257, 0.0653, 0.1290], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:06,981][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ John] are: tensor([0.0163, 0.7610, 0.0395, 0.1832], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:06,982][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ John] are: tensor([0.2830, 0.3771, 0.0650, 0.2748], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:06,984][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ John] are: tensor([0.3995, 0.1183, 0.0082, 0.4741], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:06,986][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ John] are: tensor([0.0421, 0.5864, 0.1554, 0.2161], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:06,987][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ John] are: tensor([0.7700, 0.1124, 0.0225, 0.0951], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:06,989][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ John] are: tensor([3.4630e-04, 6.4683e-01, 7.4550e-02, 2.7827e-01], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:06,990][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ John] are: tensor([0.1080, 0.2374, 0.1072, 0.5474], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:06,992][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ John] are: tensor([0.3246, 0.1463, 0.1096, 0.4195], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:06,993][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ John] are: tensor([1.0230e-04, 5.7979e-01, 1.6456e-01, 2.5555e-01], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:06,994][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ John] are: tensor([0.0233, 0.3482, 0.0146, 0.6139], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:06,996][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ John] are: tensor([0.0090, 0.4053, 0.1447, 0.4410], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:06,997][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ went] are: tensor([0.3039, 0.2107, 0.1007, 0.1684, 0.2164], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:06,998][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ went] are: tensor([0.0032, 0.1050, 0.0174, 0.3499, 0.5245], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:06,998][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ went] are: tensor([0.4725, 0.2213, 0.0373, 0.1123, 0.1565], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:06,999][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ went] are: tensor([0.2746, 0.1064, 0.0055, 0.5013, 0.1123], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:07,001][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ went] are: tensor([0.0097, 0.2420, 0.1479, 0.1124, 0.4880], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:07,002][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ went] are: tensor([0.8433, 0.0720, 0.0153, 0.0326, 0.0369], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:07,004][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ went] are: tensor([2.3645e-04, 1.8336e-01, 1.2733e-01, 3.2716e-01, 3.6192e-01],
       device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:07,005][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ went] are: tensor([0.0292, 0.2481, 0.0372, 0.2175, 0.4680], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:07,007][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.4525, 0.0451, 0.0551, 0.2480, 0.1994], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:07,008][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ went] are: tensor([1.1986e-05, 9.8024e-02, 3.1418e-01, 3.8417e-01, 2.0362e-01],
       device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:07,010][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ went] are: tensor([0.0016, 0.2650, 0.0027, 0.3528, 0.3779], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:07,011][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ went] are: tensor([0.0006, 0.2071, 0.1231, 0.4285, 0.2407], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:07,013][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.6064, 0.1779, 0.0341, 0.0847, 0.0567, 0.0402], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:07,015][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0018, 0.1712, 0.0184, 0.1528, 0.6199, 0.0360], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:07,016][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.4725, 0.2898, 0.0221, 0.1000, 0.0929, 0.0226], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:07,018][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.6501, 0.0498, 0.0031, 0.1948, 0.0206, 0.0816], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:07,019][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0122, 0.3118, 0.1398, 0.0555, 0.3832, 0.0975], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:07,021][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.9052, 0.0349, 0.0060, 0.0115, 0.0187, 0.0237], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:07,022][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ to] are: tensor([1.3072e-04, 1.6301e-01, 5.4059e-02, 2.5685e-01, 3.2148e-01, 2.0447e-01],
       device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:07,024][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0687, 0.2557, 0.0334, 0.1803, 0.2982, 0.1638], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:07,025][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.6102, 0.0507, 0.0383, 0.1545, 0.0965, 0.0498], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:07,027][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ to] are: tensor([6.3203e-06, 1.0912e-01, 9.3573e-02, 3.0498e-01, 2.8128e-01, 2.1104e-01],
       device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:07,027][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0156, 0.2156, 0.0029, 0.2804, 0.1380, 0.3475], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:07,028][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ to] are: tensor([1.8257e-04, 2.9537e-01, 8.1237e-02, 3.6209e-01, 1.3238e-01, 1.2874e-01],
       device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:07,029][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.5857, 0.1281, 0.0447, 0.0861, 0.0742, 0.0461, 0.0352],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:07,030][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0022, 0.1305, 0.0178, 0.1578, 0.6357, 0.0247, 0.0313],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:07,031][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.5643, 0.1800, 0.0272, 0.0930, 0.0746, 0.0279, 0.0330],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:07,032][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.7938, 0.0209, 0.0029, 0.0960, 0.0171, 0.0565, 0.0128],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:07,034][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0364, 0.2266, 0.0667, 0.0439, 0.5219, 0.0811, 0.0234],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:07,035][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.9220, 0.0269, 0.0053, 0.0100, 0.0112, 0.0143, 0.0103],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:07,037][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ the] are: tensor([8.2538e-05, 1.4098e-01, 4.6897e-02, 2.3431e-01, 3.1991e-01, 1.5924e-01,
        9.8578e-02], device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:07,038][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.1491, 0.1927, 0.0601, 0.1454, 0.2348, 0.1827, 0.0352],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:07,040][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.4534, 0.0713, 0.0398, 0.2113, 0.1276, 0.0579, 0.0389],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:07,041][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ the] are: tensor([3.4021e-06, 7.1044e-02, 6.6091e-02, 2.5956e-01, 1.4030e-01, 2.1546e-01,
        2.4754e-01], device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:07,043][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0353, 0.1336, 0.0031, 0.1619, 0.1700, 0.3543, 0.1417],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:07,044][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0006, 0.2347, 0.0619, 0.3770, 0.1291, 0.0742, 0.1225],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:07,046][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ station] are: tensor([0.5970, 0.1498, 0.0306, 0.0467, 0.0464, 0.0168, 0.0246, 0.0881],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:07,048][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ station] are: tensor([0.0028, 0.0879, 0.0131, 0.1090, 0.6557, 0.0281, 0.0377, 0.0657],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:07,049][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ station] are: tensor([0.6815, 0.1432, 0.0222, 0.0512, 0.0543, 0.0129, 0.0202, 0.0145],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:07,051][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ station] are: tensor([0.7787, 0.0212, 0.0025, 0.0833, 0.0272, 0.0610, 0.0170, 0.0091],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:07,052][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ station] are: tensor([0.0075, 0.2776, 0.0672, 0.0519, 0.2213, 0.0659, 0.0415, 0.2670],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:07,054][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ station] are: tensor([0.8302, 0.0368, 0.0100, 0.0194, 0.0192, 0.0216, 0.0159, 0.0469],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:07,055][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ station] are: tensor([1.9472e-04, 1.2416e-01, 6.7123e-02, 1.4425e-01, 2.2075e-01, 2.2661e-01,
        1.5942e-01, 5.7495e-02], device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:07,057][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ station] are: tensor([0.0311, 0.2606, 0.0321, 0.1970, 0.2636, 0.1149, 0.0683, 0.0325],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:07,058][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ station] are: tensor([0.6249, 0.0266, 0.0365, 0.0717, 0.0713, 0.0473, 0.0413, 0.0803],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:07,059][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ station] are: tensor([1.8498e-05, 1.2207e-01, 1.5127e-01, 2.1053e-01, 1.4741e-01, 1.2423e-01,
        1.5684e-01, 8.7637e-02], device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:07,060][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ station] are: tensor([0.0179, 0.1319, 0.0015, 0.1695, 0.2277, 0.2727, 0.1293, 0.0495],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:07,061][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ station] are: tensor([0.0006, 0.0997, 0.0723, 0.1831, 0.1247, 0.1846, 0.2841, 0.0510],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:07,062][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.4876, 0.1413, 0.0351, 0.0917, 0.0716, 0.0258, 0.0337, 0.0703, 0.0427],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:07,064][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0006, 0.1081, 0.0177, 0.1104, 0.5720, 0.0339, 0.0664, 0.0697, 0.0211],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:07,066][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.5186, 0.1385, 0.0274, 0.0696, 0.0715, 0.0284, 0.0443, 0.0457, 0.0559],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:07,067][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.6245, 0.0625, 0.0054, 0.1212, 0.0142, 0.0235, 0.0117, 0.0673, 0.0696],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:07,069][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0042, 0.1726, 0.1012, 0.0391, 0.2259, 0.0701, 0.0331, 0.1584, 0.1954],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:07,071][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.7506, 0.0741, 0.0118, 0.0253, 0.0305, 0.0252, 0.0196, 0.0522, 0.0107],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:07,072][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [,] are: tensor([2.5980e-05, 9.7361e-02, 2.7050e-02, 1.9433e-01, 1.8237e-01, 1.8672e-01,
        1.3205e-01, 1.5117e-01, 2.8921e-02], device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:07,073][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0381, 0.2751, 0.0536, 0.1800, 0.2587, 0.0923, 0.0283, 0.0481, 0.0259],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:07,075][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.2701, 0.0492, 0.0535, 0.1632, 0.1682, 0.0448, 0.0525, 0.1139, 0.0846],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:07,076][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [,] are: tensor([1.4656e-06, 7.1902e-02, 5.9138e-02, 1.2237e-01, 1.1519e-01, 1.8286e-01,
        2.8196e-01, 1.1178e-01, 5.4798e-02], device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:07,078][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0075, 0.1807, 0.0052, 0.1718, 0.1426, 0.1549, 0.1258, 0.0758, 0.1356],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:07,079][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [,] are: tensor([1.3380e-04, 2.1552e-01, 5.1708e-02, 2.3105e-01, 1.5906e-01, 1.2218e-01,
        1.4129e-01, 4.5447e-02, 3.3613e-02], device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:07,081][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ John] are: tensor([0.2926, 0.0905, 0.0523, 0.0846, 0.0499, 0.0925, 0.0646, 0.1432, 0.0617,
        0.0681], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:07,083][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ John] are: tensor([0.0055, 0.2890, 0.0283, 0.1030, 0.3170, 0.0493, 0.0450, 0.0942, 0.0186,
        0.0501], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:07,084][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ John] are: tensor([0.2137, 0.1172, 0.0455, 0.1282, 0.0733, 0.0815, 0.0650, 0.0665, 0.0679,
        0.1411], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:07,086][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ John] are: tensor([0.4228, 0.0248, 0.0025, 0.1218, 0.0102, 0.0224, 0.0122, 0.0557, 0.0620,
        0.2656], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:07,088][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ John] are: tensor([0.0084, 0.1652, 0.0749, 0.0492, 0.1966, 0.0562, 0.0252, 0.2568, 0.1304,
        0.0372], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:07,090][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ John] are: tensor([0.6489, 0.0377, 0.0170, 0.0408, 0.0319, 0.0527, 0.0309, 0.0732, 0.0155,
        0.0513], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:07,090][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ John] are: tensor([5.8999e-05, 1.6856e-01, 2.4973e-02, 8.8941e-02, 1.8708e-01, 1.4287e-01,
        6.5860e-02, 1.9688e-01, 3.3065e-02, 9.1715e-02], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:07,091][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ John] are: tensor([0.0438, 0.0720, 0.0425, 0.2161, 0.1366, 0.1468, 0.0677, 0.0574, 0.0635,
        0.1535], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:07,092][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ John] are: tensor([0.0797, 0.0284, 0.0322, 0.1112, 0.1134, 0.1054, 0.1808, 0.1099, 0.1103,
        0.1287], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:07,093][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ John] are: tensor([2.1931e-05, 1.3913e-01, 5.3460e-02, 6.6843e-02, 1.0795e-01, 1.7800e-01,
        1.2898e-01, 1.2550e-01, 6.5461e-02, 1.3466e-01], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:07,094][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ John] are: tensor([0.0118, 0.0446, 0.0019, 0.1197, 0.0348, 0.0660, 0.0427, 0.0613, 0.0706,
        0.5468], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:07,096][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ John] are: tensor([0.0009, 0.1359, 0.0590, 0.2434, 0.1092, 0.0898, 0.0961, 0.0542, 0.0466,
        0.1649], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:07,098][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.1000, 0.1606, 0.0304, 0.1752, 0.1155, 0.0496, 0.0359, 0.0860, 0.0439,
        0.0985, 0.1043], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:07,099][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0009, 0.0965, 0.0164, 0.1960, 0.3513, 0.0283, 0.0624, 0.0531, 0.0234,
        0.0938, 0.0779], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:07,101][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.2516, 0.3014, 0.0251, 0.0818, 0.1135, 0.0248, 0.0476, 0.0371, 0.0283,
        0.0513, 0.0375], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:07,103][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.2987, 0.0742, 0.0021, 0.0915, 0.0172, 0.0530, 0.0182, 0.0504, 0.0711,
        0.2453, 0.0783], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:07,104][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.0023, 0.2237, 0.0998, 0.0374, 0.1815, 0.0685, 0.0422, 0.1265, 0.1218,
        0.0278, 0.0685], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:07,106][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.6393, 0.1041, 0.0124, 0.0247, 0.0332, 0.0298, 0.0227, 0.0400, 0.0092,
        0.0296, 0.0550], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:07,107][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([3.3946e-05, 1.1258e-01, 3.5745e-02, 1.5434e-01, 1.4094e-01, 1.4076e-01,
        1.5607e-01, 6.8270e-02, 3.4847e-02, 1.2154e-01, 3.4881e-02],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:07,109][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0128, 0.2342, 0.0268, 0.1520, 0.2359, 0.0997, 0.0439, 0.0267, 0.0185,
        0.0889, 0.0606], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:07,111][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.1048, 0.0226, 0.0285, 0.1436, 0.1022, 0.0575, 0.1101, 0.0962, 0.0905,
        0.1191, 0.1250], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:07,112][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([1.6996e-06, 4.0490e-02, 4.8135e-02, 8.1995e-02, 6.5127e-02, 1.4047e-01,
        2.8219e-01, 5.9825e-02, 4.7462e-02, 1.9389e-01, 4.0424e-02],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:07,114][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0072, 0.1106, 0.0015, 0.0826, 0.0798, 0.1328, 0.0507, 0.0532, 0.0368,
        0.3956, 0.0492], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:07,115][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0004, 0.1545, 0.0519, 0.2218, 0.1102, 0.0680, 0.1285, 0.0386, 0.0476,
        0.1109, 0.0676], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:07,117][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.2901, 0.0868, 0.0324, 0.0731, 0.0699, 0.0321, 0.0248, 0.1104, 0.0468,
        0.0592, 0.1224, 0.0520], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:07,119][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0006, 0.0528, 0.0189, 0.0895, 0.4403, 0.0286, 0.0426, 0.0614, 0.0254,
        0.0639, 0.1512, 0.0246], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:07,121][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.4160, 0.1115, 0.0330, 0.0625, 0.0501, 0.0306, 0.0346, 0.0289, 0.0653,
        0.0608, 0.0335, 0.0732], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:07,122][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.3503, 0.0160, 0.0017, 0.0610, 0.0066, 0.0157, 0.0036, 0.0328, 0.0522,
        0.3347, 0.1140, 0.0113], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:07,122][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0048, 0.0921, 0.0806, 0.0338, 0.1507, 0.0464, 0.0346, 0.1721, 0.1596,
        0.0285, 0.1264, 0.0705], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:07,123][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.7273, 0.0501, 0.0102, 0.0176, 0.0213, 0.0264, 0.0191, 0.0412, 0.0096,
        0.0241, 0.0268, 0.0262], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:07,124][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ a] are: tensor([9.4897e-06, 2.7328e-02, 3.2255e-02, 8.0135e-02, 1.2999e-01, 1.7982e-01,
        1.1516e-01, 1.1024e-01, 4.1573e-02, 1.0378e-01, 8.5578e-02, 9.4137e-02],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:07,126][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0432, 0.1601, 0.0565, 0.1259, 0.1472, 0.0905, 0.0373, 0.0341, 0.0411,
        0.1113, 0.0886, 0.0643], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:07,128][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.2362, 0.0360, 0.0450, 0.1152, 0.0487, 0.0529, 0.0392, 0.1188, 0.1037,
        0.0938, 0.0980, 0.0124], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:07,129][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ a] are: tensor([4.0373e-07, 1.4953e-02, 3.5725e-02, 9.0787e-02, 5.4040e-02, 1.2868e-01,
        1.4842e-01, 6.6226e-02, 4.4021e-02, 2.2824e-01, 4.3263e-02, 1.4565e-01],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:07,131][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0023, 0.0368, 0.0007, 0.0463, 0.0208, 0.0490, 0.0178, 0.0304, 0.0434,
        0.5967, 0.0867, 0.0691], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:07,132][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ a] are: tensor([1.0514e-04, 8.6952e-02, 4.9362e-02, 1.7398e-01, 1.1163e-01, 9.8405e-02,
        1.5045e-01, 5.3116e-02, 4.8265e-02, 1.2120e-01, 6.9168e-02, 3.7368e-02],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:07,134][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ ring] are: tensor([0.0549, 0.0988, 0.0332, 0.1143, 0.0645, 0.0444, 0.0469, 0.0637, 0.0522,
        0.0700, 0.1247, 0.0669, 0.1654], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:07,136][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ ring] are: tensor([0.0013, 0.1296, 0.0246, 0.0693, 0.3530, 0.0341, 0.0605, 0.1059, 0.0200,
        0.0308, 0.1170, 0.0276, 0.0263], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:07,137][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ ring] are: tensor([0.1455, 0.0813, 0.0439, 0.0959, 0.0649, 0.0784, 0.0732, 0.0256, 0.1185,
        0.0962, 0.0603, 0.0961, 0.0202], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:07,139][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ ring] are: tensor([0.1342, 0.0668, 0.0030, 0.2135, 0.0158, 0.0068, 0.0049, 0.0625, 0.0278,
        0.3030, 0.1188, 0.0169, 0.0260], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:07,141][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ ring] are: tensor([0.0008, 0.0489, 0.0296, 0.0280, 0.0786, 0.0542, 0.0278, 0.1316, 0.1199,
        0.0323, 0.1738, 0.0666, 0.2078], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:07,142][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ ring] are: tensor([0.5590, 0.0366, 0.0123, 0.0377, 0.0201, 0.0403, 0.0208, 0.0610, 0.0120,
        0.0484, 0.0440, 0.0345, 0.0732], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:07,144][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ ring] are: tensor([1.7335e-05, 4.7478e-02, 2.6666e-02, 1.3300e-01, 1.2847e-01, 1.0628e-01,
        6.8326e-02, 1.1447e-01, 2.7983e-02, 1.1741e-01, 8.0195e-02, 5.2450e-02,
        9.7268e-02], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:07,146][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ ring] are: tensor([0.0070, 0.1317, 0.0366, 0.2694, 0.1830, 0.0517, 0.0402, 0.0371, 0.0233,
        0.0981, 0.0623, 0.0441, 0.0154], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:07,147][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ ring] are: tensor([0.0374, 0.0131, 0.0337, 0.1356, 0.0766, 0.0813, 0.0712, 0.0734, 0.1109,
        0.1344, 0.1481, 0.0465, 0.0378], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:07,149][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ ring] are: tensor([5.2428e-07, 1.7507e-02, 4.3213e-02, 9.5607e-02, 7.2195e-02, 1.6744e-01,
        1.3575e-01, 5.4621e-02, 4.4210e-02, 1.8058e-01, 3.0069e-02, 8.9737e-02,
        6.9065e-02], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:07,150][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ ring] are: tensor([0.0012, 0.0863, 0.0013, 0.1514, 0.0282, 0.0310, 0.0153, 0.0441, 0.0236,
        0.4586, 0.0824, 0.0462, 0.0303], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:07,152][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ ring] are: tensor([9.0415e-05, 6.3575e-02, 2.9918e-02, 1.9095e-01, 6.5119e-02, 7.7552e-02,
        1.5470e-01, 4.2485e-02, 4.3801e-02, 1.6831e-01, 5.7411e-02, 4.9484e-02,
        5.6611e-02], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:07,153][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.3182, 0.0601, 0.0236, 0.0425, 0.0276, 0.0359, 0.0473, 0.0728, 0.0585,
        0.0507, 0.0656, 0.0753, 0.0608, 0.0612], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:07,154][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0005, 0.0679, 0.0131, 0.1042, 0.3696, 0.0319, 0.0564, 0.0744, 0.0205,
        0.0786, 0.0990, 0.0337, 0.0281, 0.0222], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:07,154][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.5376, 0.1024, 0.0149, 0.0448, 0.0241, 0.0206, 0.0256, 0.0238, 0.0399,
        0.0491, 0.0243, 0.0455, 0.0131, 0.0343], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:07,156][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ to] are: tensor([6.1978e-01, 5.4588e-03, 3.5330e-04, 1.8259e-02, 9.5337e-04, 3.2997e-03,
        1.9738e-03, 1.5335e-02, 1.9688e-02, 1.7192e-01, 2.6865e-02, 1.5408e-02,
        5.3073e-02, 4.7634e-02], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:07,157][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0027, 0.1106, 0.0842, 0.0265, 0.1124, 0.0459, 0.0212, 0.0965, 0.1352,
        0.0197, 0.0948, 0.0576, 0.1070, 0.0857], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:07,159][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.8267, 0.0203, 0.0037, 0.0065, 0.0095, 0.0143, 0.0082, 0.0297, 0.0040,
        0.0105, 0.0118, 0.0101, 0.0193, 0.0251], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:07,161][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ to] are: tensor([1.2576e-05, 3.4247e-02, 2.1016e-02, 9.8438e-02, 1.0907e-01, 1.1215e-01,
        7.0224e-02, 8.1797e-02, 2.4857e-02, 9.6740e-02, 6.9080e-02, 6.2638e-02,
        1.2127e-01, 9.8467e-02], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:07,162][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0697, 0.1149, 0.0272, 0.1172, 0.1113, 0.0725, 0.0299, 0.0351, 0.0402,
        0.1167, 0.0783, 0.0717, 0.0433, 0.0719], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:07,164][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.1876, 0.0279, 0.0306, 0.0957, 0.0473, 0.0481, 0.0513, 0.0605, 0.0912,
        0.1109, 0.1176, 0.0230, 0.0378, 0.0706], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:07,165][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ to] are: tensor([3.5082e-07, 1.1279e-02, 2.4460e-02, 7.2123e-02, 4.2967e-02, 1.1470e-01,
        1.3140e-01, 3.7728e-02, 3.0728e-02, 1.6596e-01, 4.1844e-02, 1.2672e-01,
        1.1410e-01, 8.5993e-02], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:07,166][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ to] are: tensor([6.3114e-03, 1.7900e-02, 2.4961e-04, 2.2827e-02, 3.9777e-03, 1.0945e-02,
        1.3568e-02, 1.3025e-02, 2.9910e-02, 3.8957e-01, 2.3093e-02, 5.2721e-02,
        1.2173e-01, 2.9417e-01], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:07,168][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ to] are: tensor([4.1012e-05, 8.3912e-02, 3.6186e-02, 2.1288e-01, 9.3017e-02, 8.4936e-02,
        1.0560e-01, 3.0006e-02, 2.9162e-02, 1.4643e-01, 6.6045e-02, 3.6978e-02,
        3.8648e-02, 3.6159e-02], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:07,277][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:29:07,278][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:07,279][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:07,279][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:07,281][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:07,282][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:07,283][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:07,285][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:07,286][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:07,287][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:07,288][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:07,290][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:07,291][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:07,293][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Amanda] are: tensor([0.3579, 0.6421], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:07,294][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Amanda] are: tensor([0.0036, 0.9964], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:07,296][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Amanda] are: tensor([0.6242, 0.3758], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:07,298][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Amanda] are: tensor([0.7203, 0.2797], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:07,299][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Amanda] are: tensor([0.0177, 0.9823], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:07,301][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Amanda] are: tensor([0.7241, 0.2759], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:07,302][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Amanda] are: tensor([1.6397e-04, 9.9984e-01], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:07,304][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Amanda] are: tensor([0.1274, 0.8726], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:07,305][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Amanda] are: tensor([0.6859, 0.3141], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:07,306][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Amanda] are: tensor([1.4264e-05, 9.9999e-01], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:07,308][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Amanda] are: tensor([0.0050, 0.9950], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:07,309][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Amanda] are: tensor([0.0031, 0.9969], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:07,309][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.4108, 0.5477, 0.0414], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:07,310][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0069, 0.9399, 0.0532], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:07,311][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.4261, 0.5270, 0.0469], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:07,313][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0862, 0.8956, 0.0183], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:07,314][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0508, 0.7674, 0.1819], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:07,316][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.8938, 0.0983, 0.0079], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:07,317][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([3.2238e-04, 8.8264e-01, 1.1704e-01], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:07,319][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0323, 0.9006, 0.0671], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:07,320][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.7566, 0.1633, 0.0801], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:07,321][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([1.3184e-05, 6.2584e-01, 3.7414e-01], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:07,322][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([6.9778e-04, 9.9219e-01, 7.1141e-03], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:07,324][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0016, 0.8902, 0.1082], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:07,325][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ John] are: tensor([0.4799, 0.3257, 0.0653, 0.1290], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:07,327][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ John] are: tensor([0.0163, 0.7610, 0.0395, 0.1832], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:07,329][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ John] are: tensor([0.2830, 0.3771, 0.0650, 0.2748], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:07,330][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ John] are: tensor([0.3995, 0.1183, 0.0082, 0.4741], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:07,332][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ John] are: tensor([0.0421, 0.5864, 0.1554, 0.2161], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:07,334][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ John] are: tensor([0.7700, 0.1124, 0.0225, 0.0951], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:07,335][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ John] are: tensor([3.4630e-04, 6.4683e-01, 7.4550e-02, 2.7827e-01], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:07,337][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ John] are: tensor([0.1080, 0.2374, 0.1072, 0.5474], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:07,338][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ John] are: tensor([0.3246, 0.1463, 0.1096, 0.4195], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:07,339][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ John] are: tensor([1.0230e-04, 5.7979e-01, 1.6456e-01, 2.5555e-01], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:07,340][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ John] are: tensor([0.0233, 0.3482, 0.0146, 0.6139], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:07,341][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ John] are: tensor([0.0090, 0.4053, 0.1447, 0.4410], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:07,341][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([0.3039, 0.2107, 0.1007, 0.1684, 0.2164], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:07,342][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([0.0032, 0.1050, 0.0174, 0.3499, 0.5245], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:07,344][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([0.4725, 0.2213, 0.0373, 0.1123, 0.1565], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:07,345][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([0.2746, 0.1064, 0.0055, 0.5013, 0.1123], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:07,347][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([0.0097, 0.2420, 0.1479, 0.1124, 0.4880], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:07,349][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([0.8433, 0.0720, 0.0153, 0.0326, 0.0369], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:07,350][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([2.3645e-04, 1.8336e-01, 1.2733e-01, 3.2716e-01, 3.6192e-01],
       device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:07,351][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([0.0292, 0.2481, 0.0372, 0.2175, 0.4680], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:07,353][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([0.4525, 0.0451, 0.0551, 0.2480, 0.1994], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:07,354][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([1.1986e-05, 9.8024e-02, 3.1418e-01, 3.8417e-01, 2.0362e-01],
       device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:07,356][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([0.0016, 0.2650, 0.0027, 0.3528, 0.3779], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:07,357][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([0.0006, 0.2071, 0.1231, 0.4285, 0.2407], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:07,359][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.6064, 0.1779, 0.0341, 0.0847, 0.0567, 0.0402], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:07,360][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0018, 0.1712, 0.0184, 0.1528, 0.6199, 0.0360], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:07,362][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.4725, 0.2898, 0.0221, 0.1000, 0.0929, 0.0226], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:07,364][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.6501, 0.0498, 0.0031, 0.1948, 0.0206, 0.0816], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:07,366][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0122, 0.3118, 0.1398, 0.0555, 0.3832, 0.0975], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:07,367][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.9052, 0.0349, 0.0060, 0.0115, 0.0187, 0.0237], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:07,368][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([1.3072e-04, 1.6301e-01, 5.4059e-02, 2.5685e-01, 3.2148e-01, 2.0447e-01],
       device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:07,370][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0687, 0.2557, 0.0334, 0.1803, 0.2982, 0.1638], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:07,371][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.6102, 0.0507, 0.0383, 0.1545, 0.0965, 0.0498], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:07,372][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([6.3203e-06, 1.0912e-01, 9.3573e-02, 3.0498e-01, 2.8128e-01, 2.1104e-01],
       device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:07,372][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0156, 0.2156, 0.0029, 0.2804, 0.1380, 0.3475], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:07,373][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([1.8257e-04, 2.9537e-01, 8.1237e-02, 3.6209e-01, 1.3238e-01, 1.2874e-01],
       device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:07,375][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.5857, 0.1281, 0.0447, 0.0861, 0.0742, 0.0461, 0.0352],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:07,376][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0022, 0.1305, 0.0178, 0.1578, 0.6357, 0.0247, 0.0313],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:07,378][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.5643, 0.1800, 0.0272, 0.0930, 0.0746, 0.0279, 0.0330],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:07,380][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.7938, 0.0209, 0.0029, 0.0960, 0.0171, 0.0565, 0.0128],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:07,381][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0364, 0.2266, 0.0667, 0.0439, 0.5219, 0.0811, 0.0234],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:07,383][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.9220, 0.0269, 0.0053, 0.0100, 0.0112, 0.0143, 0.0103],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:07,384][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([8.2538e-05, 1.4098e-01, 4.6897e-02, 2.3431e-01, 3.1991e-01, 1.5924e-01,
        9.8578e-02], device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:07,385][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.1491, 0.1927, 0.0601, 0.1454, 0.2348, 0.1827, 0.0352],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:07,387][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.4534, 0.0713, 0.0398, 0.2113, 0.1276, 0.0579, 0.0389],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:07,388][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([3.4021e-06, 7.1044e-02, 6.6091e-02, 2.5956e-01, 1.4030e-01, 2.1546e-01,
        2.4754e-01], device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:07,390][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0353, 0.1336, 0.0031, 0.1619, 0.1700, 0.3543, 0.1417],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:07,391][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0006, 0.2347, 0.0619, 0.3770, 0.1291, 0.0742, 0.1225],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:07,393][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ station] are: tensor([0.5970, 0.1498, 0.0306, 0.0467, 0.0464, 0.0168, 0.0246, 0.0881],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:07,395][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ station] are: tensor([0.0028, 0.0879, 0.0131, 0.1090, 0.6557, 0.0281, 0.0377, 0.0657],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:07,397][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ station] are: tensor([0.6815, 0.1432, 0.0222, 0.0512, 0.0543, 0.0129, 0.0202, 0.0145],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:07,398][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ station] are: tensor([0.7787, 0.0212, 0.0025, 0.0833, 0.0272, 0.0610, 0.0170, 0.0091],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:07,400][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ station] are: tensor([0.0075, 0.2776, 0.0672, 0.0519, 0.2213, 0.0659, 0.0415, 0.2670],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:07,401][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ station] are: tensor([0.8302, 0.0368, 0.0100, 0.0194, 0.0192, 0.0216, 0.0159, 0.0469],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:07,402][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ station] are: tensor([1.9472e-04, 1.2416e-01, 6.7123e-02, 1.4425e-01, 2.2075e-01, 2.2661e-01,
        1.5942e-01, 5.7495e-02], device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:07,403][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ station] are: tensor([0.0311, 0.2606, 0.0321, 0.1970, 0.2636, 0.1149, 0.0683, 0.0325],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:07,404][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ station] are: tensor([0.6249, 0.0266, 0.0365, 0.0717, 0.0713, 0.0473, 0.0413, 0.0803],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:07,405][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ station] are: tensor([1.8498e-05, 1.2207e-01, 1.5127e-01, 2.1053e-01, 1.4741e-01, 1.2423e-01,
        1.5684e-01, 8.7637e-02], device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:07,406][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ station] are: tensor([0.0179, 0.1319, 0.0015, 0.1695, 0.2277, 0.2727, 0.1293, 0.0495],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:07,408][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ station] are: tensor([0.0006, 0.0997, 0.0723, 0.1831, 0.1247, 0.1846, 0.2841, 0.0510],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:07,410][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.4876, 0.1413, 0.0351, 0.0917, 0.0716, 0.0258, 0.0337, 0.0703, 0.0427],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:07,411][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0006, 0.1081, 0.0177, 0.1104, 0.5720, 0.0339, 0.0664, 0.0697, 0.0211],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:07,413][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.5186, 0.1385, 0.0274, 0.0696, 0.0715, 0.0284, 0.0443, 0.0457, 0.0559],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:07,414][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.6245, 0.0625, 0.0054, 0.1212, 0.0142, 0.0235, 0.0117, 0.0673, 0.0696],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:07,416][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0042, 0.1726, 0.1012, 0.0391, 0.2259, 0.0701, 0.0331, 0.1584, 0.1954],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:07,418][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.7506, 0.0741, 0.0118, 0.0253, 0.0305, 0.0252, 0.0196, 0.0522, 0.0107],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:07,419][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([2.5980e-05, 9.7361e-02, 2.7050e-02, 1.9433e-01, 1.8237e-01, 1.8672e-01,
        1.3205e-01, 1.5117e-01, 2.8921e-02], device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:07,421][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0381, 0.2751, 0.0536, 0.1800, 0.2587, 0.0923, 0.0283, 0.0481, 0.0259],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:07,422][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.2701, 0.0492, 0.0535, 0.1632, 0.1682, 0.0448, 0.0525, 0.1139, 0.0846],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:07,424][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([1.4656e-06, 7.1902e-02, 5.9138e-02, 1.2237e-01, 1.1519e-01, 1.8286e-01,
        2.8196e-01, 1.1178e-01, 5.4798e-02], device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:07,425][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0075, 0.1807, 0.0052, 0.1718, 0.1426, 0.1549, 0.1258, 0.0758, 0.1356],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:07,427][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([1.3380e-04, 2.1552e-01, 5.1708e-02, 2.3105e-01, 1.5906e-01, 1.2218e-01,
        1.4129e-01, 4.5447e-02, 3.3613e-02], device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:07,428][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ John] are: tensor([0.2926, 0.0905, 0.0523, 0.0846, 0.0499, 0.0925, 0.0646, 0.1432, 0.0617,
        0.0681], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:07,430][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ John] are: tensor([0.0055, 0.2890, 0.0283, 0.1030, 0.3170, 0.0493, 0.0450, 0.0942, 0.0186,
        0.0501], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:07,432][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ John] are: tensor([0.2137, 0.1172, 0.0455, 0.1282, 0.0733, 0.0815, 0.0650, 0.0665, 0.0679,
        0.1411], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:07,433][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ John] are: tensor([0.4228, 0.0248, 0.0025, 0.1218, 0.0102, 0.0224, 0.0122, 0.0557, 0.0620,
        0.2656], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:07,434][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ John] are: tensor([0.0084, 0.1652, 0.0749, 0.0492, 0.1966, 0.0562, 0.0252, 0.2568, 0.1304,
        0.0372], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:07,434][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ John] are: tensor([0.6489, 0.0377, 0.0170, 0.0408, 0.0319, 0.0527, 0.0309, 0.0732, 0.0155,
        0.0513], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:07,435][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ John] are: tensor([5.8999e-05, 1.6856e-01, 2.4973e-02, 8.8941e-02, 1.8708e-01, 1.4287e-01,
        6.5860e-02, 1.9688e-01, 3.3065e-02, 9.1715e-02], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:07,437][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ John] are: tensor([0.0438, 0.0720, 0.0425, 0.2161, 0.1366, 0.1468, 0.0677, 0.0574, 0.0635,
        0.1535], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:07,438][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ John] are: tensor([0.0797, 0.0284, 0.0322, 0.1112, 0.1134, 0.1054, 0.1808, 0.1099, 0.1103,
        0.1287], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:07,440][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ John] are: tensor([2.1931e-05, 1.3913e-01, 5.3460e-02, 6.6843e-02, 1.0795e-01, 1.7800e-01,
        1.2898e-01, 1.2550e-01, 6.5461e-02, 1.3466e-01], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:07,441][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ John] are: tensor([0.0118, 0.0446, 0.0019, 0.1197, 0.0348, 0.0660, 0.0427, 0.0613, 0.0706,
        0.5468], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:07,443][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ John] are: tensor([0.0009, 0.1359, 0.0590, 0.2434, 0.1092, 0.0898, 0.0961, 0.0542, 0.0466,
        0.1649], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:07,445][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.1000, 0.1606, 0.0304, 0.1752, 0.1155, 0.0496, 0.0359, 0.0860, 0.0439,
        0.0985, 0.1043], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:07,447][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0009, 0.0965, 0.0164, 0.1960, 0.3513, 0.0283, 0.0624, 0.0531, 0.0234,
        0.0938, 0.0779], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:07,448][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.2516, 0.3014, 0.0251, 0.0818, 0.1135, 0.0248, 0.0476, 0.0371, 0.0283,
        0.0513, 0.0375], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:07,450][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.2987, 0.0742, 0.0021, 0.0915, 0.0172, 0.0530, 0.0182, 0.0504, 0.0711,
        0.2453, 0.0783], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:07,452][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.0023, 0.2237, 0.0998, 0.0374, 0.1815, 0.0685, 0.0422, 0.1265, 0.1218,
        0.0278, 0.0685], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:07,454][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.6393, 0.1041, 0.0124, 0.0247, 0.0332, 0.0298, 0.0227, 0.0400, 0.0092,
        0.0296, 0.0550], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:07,455][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([3.3946e-05, 1.1258e-01, 3.5745e-02, 1.5434e-01, 1.4094e-01, 1.4076e-01,
        1.5607e-01, 6.8270e-02, 3.4847e-02, 1.2154e-01, 3.4881e-02],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:07,457][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0128, 0.2342, 0.0268, 0.1520, 0.2359, 0.0997, 0.0439, 0.0267, 0.0185,
        0.0889, 0.0606], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:07,458][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.1048, 0.0226, 0.0285, 0.1436, 0.1022, 0.0575, 0.1101, 0.0962, 0.0905,
        0.1191, 0.1250], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:07,460][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([1.6996e-06, 4.0490e-02, 4.8135e-02, 8.1995e-02, 6.5127e-02, 1.4047e-01,
        2.8219e-01, 5.9825e-02, 4.7462e-02, 1.9389e-01, 4.0424e-02],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:07,461][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0072, 0.1106, 0.0015, 0.0826, 0.0798, 0.1328, 0.0507, 0.0532, 0.0368,
        0.3956, 0.0492], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:07,463][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.0004, 0.1545, 0.0519, 0.2218, 0.1102, 0.0680, 0.1285, 0.0386, 0.0476,
        0.1109, 0.0676], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:07,464][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.2901, 0.0868, 0.0324, 0.0731, 0.0699, 0.0321, 0.0248, 0.1104, 0.0468,
        0.0592, 0.1224, 0.0520], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:07,465][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0006, 0.0528, 0.0189, 0.0895, 0.4403, 0.0286, 0.0426, 0.0614, 0.0254,
        0.0639, 0.1512, 0.0246], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:07,466][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.4160, 0.1115, 0.0330, 0.0625, 0.0501, 0.0306, 0.0346, 0.0289, 0.0653,
        0.0608, 0.0335, 0.0732], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:07,467][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.3503, 0.0160, 0.0017, 0.0610, 0.0066, 0.0157, 0.0036, 0.0328, 0.0522,
        0.3347, 0.1140, 0.0113], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:07,468][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0048, 0.0921, 0.0806, 0.0338, 0.1507, 0.0464, 0.0346, 0.1721, 0.1596,
        0.0285, 0.1264, 0.0705], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:07,470][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.7273, 0.0501, 0.0102, 0.0176, 0.0213, 0.0264, 0.0191, 0.0412, 0.0096,
        0.0241, 0.0268, 0.0262], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:07,471][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([9.4897e-06, 2.7328e-02, 3.2255e-02, 8.0135e-02, 1.2999e-01, 1.7982e-01,
        1.1516e-01, 1.1024e-01, 4.1573e-02, 1.0378e-01, 8.5578e-02, 9.4137e-02],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:07,473][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0432, 0.1601, 0.0565, 0.1259, 0.1472, 0.0905, 0.0373, 0.0341, 0.0411,
        0.1113, 0.0886, 0.0643], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:07,475][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.2362, 0.0360, 0.0450, 0.1152, 0.0487, 0.0529, 0.0392, 0.1188, 0.1037,
        0.0938, 0.0980, 0.0124], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:07,476][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([4.0373e-07, 1.4953e-02, 3.5725e-02, 9.0787e-02, 5.4040e-02, 1.2868e-01,
        1.4842e-01, 6.6226e-02, 4.4021e-02, 2.2824e-01, 4.3263e-02, 1.4565e-01],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:07,478][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0023, 0.0368, 0.0007, 0.0463, 0.0208, 0.0490, 0.0178, 0.0304, 0.0434,
        0.5967, 0.0867, 0.0691], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:07,479][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([1.0514e-04, 8.6952e-02, 4.9362e-02, 1.7398e-01, 1.1163e-01, 9.8405e-02,
        1.5045e-01, 5.3116e-02, 4.8265e-02, 1.2120e-01, 6.9168e-02, 3.7368e-02],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:07,480][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ ring] are: tensor([0.0549, 0.0988, 0.0332, 0.1143, 0.0645, 0.0444, 0.0469, 0.0637, 0.0522,
        0.0700, 0.1247, 0.0669, 0.1654], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:07,482][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ ring] are: tensor([0.0013, 0.1296, 0.0246, 0.0693, 0.3530, 0.0341, 0.0605, 0.1059, 0.0200,
        0.0308, 0.1170, 0.0276, 0.0263], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:07,484][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ ring] are: tensor([0.1455, 0.0813, 0.0439, 0.0959, 0.0649, 0.0784, 0.0732, 0.0256, 0.1185,
        0.0962, 0.0603, 0.0961, 0.0202], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:07,485][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ ring] are: tensor([0.1342, 0.0668, 0.0030, 0.2135, 0.0158, 0.0068, 0.0049, 0.0625, 0.0278,
        0.3030, 0.1188, 0.0169, 0.0260], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:07,487][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ ring] are: tensor([0.0008, 0.0489, 0.0296, 0.0280, 0.0786, 0.0542, 0.0278, 0.1316, 0.1199,
        0.0323, 0.1738, 0.0666, 0.2078], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:07,489][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ ring] are: tensor([0.5590, 0.0366, 0.0123, 0.0377, 0.0201, 0.0403, 0.0208, 0.0610, 0.0120,
        0.0484, 0.0440, 0.0345, 0.0732], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:07,490][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ ring] are: tensor([1.7335e-05, 4.7478e-02, 2.6666e-02, 1.3300e-01, 1.2847e-01, 1.0628e-01,
        6.8326e-02, 1.1447e-01, 2.7983e-02, 1.1741e-01, 8.0195e-02, 5.2450e-02,
        9.7268e-02], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:07,492][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ ring] are: tensor([0.0070, 0.1317, 0.0366, 0.2694, 0.1830, 0.0517, 0.0402, 0.0371, 0.0233,
        0.0981, 0.0623, 0.0441, 0.0154], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:07,494][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ ring] are: tensor([0.0374, 0.0131, 0.0337, 0.1356, 0.0766, 0.0813, 0.0712, 0.0734, 0.1109,
        0.1344, 0.1481, 0.0465, 0.0378], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:07,495][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ ring] are: tensor([5.2428e-07, 1.7507e-02, 4.3213e-02, 9.5607e-02, 7.2195e-02, 1.6744e-01,
        1.3575e-01, 5.4621e-02, 4.4210e-02, 1.8058e-01, 3.0069e-02, 8.9737e-02,
        6.9065e-02], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:07,496][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ ring] are: tensor([0.0012, 0.0863, 0.0013, 0.1514, 0.0282, 0.0310, 0.0153, 0.0441, 0.0236,
        0.4586, 0.0824, 0.0462, 0.0303], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:07,497][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ ring] are: tensor([9.0415e-05, 6.3575e-02, 2.9918e-02, 1.9095e-01, 6.5119e-02, 7.7552e-02,
        1.5470e-01, 4.2485e-02, 4.3801e-02, 1.6831e-01, 5.7411e-02, 4.9484e-02,
        5.6611e-02], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:07,498][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.3182, 0.0601, 0.0236, 0.0425, 0.0276, 0.0359, 0.0473, 0.0728, 0.0585,
        0.0507, 0.0656, 0.0753, 0.0608, 0.0612], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:07,499][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0005, 0.0679, 0.0131, 0.1042, 0.3696, 0.0319, 0.0564, 0.0744, 0.0205,
        0.0786, 0.0990, 0.0337, 0.0281, 0.0222], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:07,501][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.5376, 0.1024, 0.0149, 0.0448, 0.0241, 0.0206, 0.0256, 0.0238, 0.0399,
        0.0491, 0.0243, 0.0455, 0.0131, 0.0343], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:07,502][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([6.1978e-01, 5.4588e-03, 3.5330e-04, 1.8259e-02, 9.5337e-04, 3.2997e-03,
        1.9738e-03, 1.5335e-02, 1.9688e-02, 1.7192e-01, 2.6865e-02, 1.5408e-02,
        5.3073e-02, 4.7634e-02], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:07,504][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0027, 0.1106, 0.0842, 0.0265, 0.1124, 0.0459, 0.0212, 0.0965, 0.1352,
        0.0197, 0.0948, 0.0576, 0.1070, 0.0857], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:07,505][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.8267, 0.0203, 0.0037, 0.0065, 0.0095, 0.0143, 0.0082, 0.0297, 0.0040,
        0.0105, 0.0118, 0.0101, 0.0193, 0.0251], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:07,507][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([1.2576e-05, 3.4247e-02, 2.1016e-02, 9.8438e-02, 1.0907e-01, 1.1215e-01,
        7.0224e-02, 8.1797e-02, 2.4857e-02, 9.6740e-02, 6.9080e-02, 6.2638e-02,
        1.2127e-01, 9.8467e-02], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:07,508][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0697, 0.1149, 0.0272, 0.1172, 0.1113, 0.0725, 0.0299, 0.0351, 0.0402,
        0.1167, 0.0783, 0.0717, 0.0433, 0.0719], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:07,510][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.1876, 0.0279, 0.0306, 0.0957, 0.0473, 0.0481, 0.0513, 0.0605, 0.0912,
        0.1109, 0.1176, 0.0230, 0.0378, 0.0706], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:07,511][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([3.5082e-07, 1.1279e-02, 2.4460e-02, 7.2123e-02, 4.2967e-02, 1.1470e-01,
        1.3140e-01, 3.7728e-02, 3.0728e-02, 1.6596e-01, 4.1844e-02, 1.2672e-01,
        1.1410e-01, 8.5993e-02], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:07,513][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([6.3114e-03, 1.7900e-02, 2.4961e-04, 2.2827e-02, 3.9777e-03, 1.0945e-02,
        1.3568e-02, 1.3025e-02, 2.9910e-02, 3.8957e-01, 2.3093e-02, 5.2721e-02,
        1.2173e-01, 2.9417e-01], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:07,514][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([4.1012e-05, 8.3912e-02, 3.6186e-02, 2.1288e-01, 9.3017e-02, 8.4936e-02,
        1.0560e-01, 3.0006e-02, 2.9162e-02, 1.4643e-01, 6.6045e-02, 3.6978e-02,
        3.8648e-02, 3.6159e-02], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:07,517][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:29:07,519][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 2665],
        [    5],
        [ 5537],
        [ 6845],
        [ 2131],
        [ 1750],
        [ 6779],
        [ 2167],
        [ 1267],
        [ 5799],
        [ 7804],
        [13662],
        [ 6910],
        [ 1691]], device='cuda:0')
[2024-07-24 10:29:07,521][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 2445],
        [    1],
        [ 1056],
        [ 2917],
        [ 1314],
        [ 1060],
        [ 5299],
        [ 1493],
        [  831],
        [ 4621],
        [ 6586],
        [12280],
        [ 5422],
        [ 1263]], device='cuda:0')
[2024-07-24 10:29:07,523][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[11573],
        [44192],
        [43649],
        [41500],
        [41138],
        [38105],
        [35301],
        [38270],
        [36006],
        [32155],
        [36713],
        [33636],
        [39501],
        [31808]], device='cuda:0')
[2024-07-24 10:29:07,524][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[21649],
        [27668],
        [28101],
        [33637],
        [42963],
        [40479],
        [40762],
        [40778],
        [41135],
        [41299],
        [44320],
        [43670],
        [43136],
        [44276]], device='cuda:0')
[2024-07-24 10:29:07,526][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[23812],
        [50170],
        [50163],
        [49547],
        [49454],
        [49990],
        [49102],
        [49485],
        [45728],
        [25368],
        [49230],
        [35019],
        [17252],
        [37861]], device='cuda:0')
[2024-07-24 10:29:07,528][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[24450],
        [41553],
        [47722],
        [45123],
        [45513],
        [42425],
        [37518],
        [38263],
        [43273],
        [45585],
        [46507],
        [45854],
        [46919],
        [43213]], device='cuda:0')
[2024-07-24 10:29:07,529][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[24947],
        [13034],
        [13001],
        [10278],
        [16086],
        [15987],
        [17951],
        [18671],
        [16546],
        [17040],
        [16607],
        [18210],
        [26794],
        [20669]], device='cuda:0')
[2024-07-24 10:29:07,531][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[39683],
        [13872],
        [26307],
        [21785],
        [27711],
        [35093],
        [36927],
        [37771],
        [33810],
        [35998],
        [30894],
        [36379],
        [36501],
        [40575]], device='cuda:0')
[2024-07-24 10:29:07,532][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[41704],
        [50251],
        [50243],
        [50154],
        [22568],
        [20991],
        [17979],
        [21006],
        [21636],
        [32537],
        [22152],
        [11177],
        [12803],
        [11080]], device='cuda:0')
[2024-07-24 10:29:07,534][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[ 2105],
        [25586],
        [26645],
        [24454],
        [37495],
        [36993],
        [36163],
        [34545],
        [34697],
        [30740],
        [32792],
        [28446],
        [28422],
        [25712]], device='cuda:0')
[2024-07-24 10:29:07,535][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[ 3441],
        [50206],
        [49284],
        [49540],
        [47063],
        [45504],
        [46779],
        [39093],
        [42770],
        [39572],
        [42987],
        [42416],
        [40921],
        [40263]], device='cuda:0')
[2024-07-24 10:29:07,537][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[17430],
        [50257],
        [50257],
        [50253],
        [32151],
        [37034],
        [37968],
        [46343],
        [46327],
        [48808],
        [41370],
        [37229],
        [38313],
        [40669]], device='cuda:0')
[2024-07-24 10:29:07,538][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[ 4336],
        [ 9771],
        [ 9760],
        [ 6768],
        [ 8510],
        [ 9375],
        [10400],
        [10109],
        [10183],
        [ 8586],
        [ 9112],
        [ 9222],
        [ 8735],
        [11932]], device='cuda:0')
[2024-07-24 10:29:07,540][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[22746],
        [50137],
        [50126],
        [50197],
        [49957],
        [50130],
        [50025],
        [45647],
        [49122],
        [49635],
        [49315],
        [47680],
        [48915],
        [49132]], device='cuda:0')
[2024-07-24 10:29:07,542][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[19817],
        [11615],
        [13985],
        [12613],
        [11741],
        [13006],
        [11533],
        [13508],
        [10169],
        [ 9028],
        [ 7304],
        [11293],
        [11986],
        [10394]], device='cuda:0')
[2024-07-24 10:29:07,543][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[14294],
        [17600],
        [17593],
        [17389],
        [25278],
        [20043],
        [22343],
        [23408],
        [23608],
        [23555],
        [21447],
        [20595],
        [15220],
        [17393]], device='cuda:0')
[2024-07-24 10:29:07,545][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[12252],
        [14957],
        [14914],
        [15125],
        [ 8183],
        [ 5149],
        [ 4649],
        [ 3914],
        [ 4512],
        [10019],
        [ 7555],
        [ 4345],
        [ 6008],
        [ 5683]], device='cuda:0')
[2024-07-24 10:29:07,546][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[ 5496],
        [ 6379],
        [ 7879],
        [10680],
        [ 8722],
        [ 7808],
        [ 9189],
        [ 7907],
        [13177],
        [10654],
        [ 8933],
        [11459],
        [ 7092],
        [13120]], device='cuda:0')
[2024-07-24 10:29:07,548][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[1225],
        [  71],
        [  57],
        [  30],
        [  51],
        [  38],
        [  85],
        [  75],
        [  35],
        [  33],
        [  33],
        [  41],
        [  90],
        [  45]], device='cuda:0')
[2024-07-24 10:29:07,550][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[11804],
        [44610],
        [43499],
        [45569],
        [46882],
        [46001],
        [46392],
        [45352],
        [44802],
        [45246],
        [45155],
        [44733],
        [43395],
        [44031]], device='cuda:0')
[2024-07-24 10:29:07,551][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[1474],
        [8544],
        [2208],
        [6030],
        [2817],
        [1483],
        [1152],
        [3179],
        [4965],
        [6367],
        [5564],
        [4141],
        [5655],
        [2226]], device='cuda:0')
[2024-07-24 10:29:07,553][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[ 8874],
        [ 8945],
        [ 8983],
        [11491],
        [16522],
        [18215],
        [21793],
        [26571],
        [28398],
        [25130],
        [28915],
        [33152],
        [33157],
        [33119]], device='cuda:0')
[2024-07-24 10:29:07,555][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[ 7402],
        [ 4874],
        [ 5027],
        [16229],
        [ 5400],
        [ 7431],
        [ 8040],
        [ 6986],
        [ 6197],
        [12450],
        [ 8948],
        [10614],
        [11665],
        [11141]], device='cuda:0')
[2024-07-24 10:29:07,556][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[35847],
        [35763],
        [26370],
        [26266],
        [18195],
        [18133],
        [19550],
        [15950],
        [17386],
        [18140],
        [16680],
        [16210],
        [16878],
        [17079]], device='cuda:0')
[2024-07-24 10:29:07,558][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[17042],
        [20533],
        [22720],
        [18009],
        [ 7948],
        [ 8450],
        [ 8762],
        [ 9996],
        [12656],
        [12525],
        [ 8966],
        [ 9433],
        [ 8021],
        [ 8003]], device='cuda:0')
[2024-07-24 10:29:07,559][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[ 1680],
        [27684],
        [27572],
        [15659],
        [16243],
        [12277],
        [11189],
        [12980],
        [14289],
        [ 9586],
        [10241],
        [ 8435],
        [ 9734],
        [ 9362]], device='cuda:0')
[2024-07-24 10:29:07,561][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[6701],
        [ 317],
        [ 315],
        [ 687],
        [ 857],
        [ 718],
        [ 687],
        [2024],
        [1228],
        [1100],
        [1203],
        [1806],
        [1446],
        [1388]], device='cuda:0')
[2024-07-24 10:29:07,563][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[48406],
        [42605],
        [44617],
        [45554],
        [47748],
        [48613],
        [47617],
        [47652],
        [47308],
        [47182],
        [47919],
        [48274],
        [48065],
        [48221]], device='cuda:0')
[2024-07-24 10:29:07,565][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[33417],
        [46406],
        [48923],
        [46046],
        [46868],
        [46231],
        [45370],
        [43623],
        [45498],
        [44387],
        [46143],
        [44718],
        [45105],
        [45317]], device='cuda:0')
[2024-07-24 10:29:07,566][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[11117],
        [11117],
        [11117],
        [11117],
        [11117],
        [11117],
        [11117],
        [11117],
        [11117],
        [11117],
        [11117],
        [11117],
        [11117],
        [11117]], device='cuda:0')
[2024-07-24 10:29:07,679][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:29:07,680][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:07,681][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:07,682][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:07,684][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:07,685][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:07,687][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:07,688][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:07,689][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:07,690][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:07,691][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:07,692][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:07,693][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:07,693][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Amanda] are: tensor([0.0174, 0.9826], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:07,694][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Amanda] are: tensor([0.0046, 0.9954], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:07,696][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Amanda] are: tensor([0.2205, 0.7795], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:07,697][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Amanda] are: tensor([0.0308, 0.9692], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:07,699][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Amanda] are: tensor([0.3116, 0.6884], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:07,700][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Amanda] are: tensor([0.0106, 0.9894], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:07,702][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Amanda] are: tensor([0.0229, 0.9771], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:07,703][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Amanda] are: tensor([0.0708, 0.9292], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:07,705][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Amanda] are: tensor([0.0218, 0.9782], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:07,707][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Amanda] are: tensor([0.0028, 0.9972], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:07,708][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Amanda] are: tensor([0.0914, 0.9086], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:07,709][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Amanda] are: tensor([1.9241e-04, 9.9981e-01], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:07,711][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0449, 0.8501, 0.1051], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:07,712][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0403, 0.9527, 0.0070], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:07,714][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.1575, 0.8022, 0.0403], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:07,716][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0711, 0.7998, 0.1290], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:07,717][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.3737, 0.5898, 0.0365], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:07,719][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0205, 0.5283, 0.4512], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:07,720][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0609, 0.9238, 0.0153], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:07,722][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0199, 0.9095, 0.0705], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:07,723][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0020, 0.2063, 0.7917], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:07,724][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0016, 0.6505, 0.3479], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:07,724][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ and] are: tensor([3.6536e-04, 2.4282e-03, 9.9721e-01], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:07,725][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ and] are: tensor([1.7460e-04, 2.5380e-01, 7.4603e-01], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:07,726][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ John] are: tensor([0.0082, 0.6480, 0.0741, 0.2697], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:07,727][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ John] are: tensor([0.0095, 0.9723, 0.0076, 0.0106], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:07,729][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ John] are: tensor([0.0393, 0.9408, 0.0086, 0.0113], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:07,730][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ John] are: tensor([0.0245, 0.6446, 0.2110, 0.1199], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:07,732][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ John] are: tensor([0.0565, 0.2912, 0.0277, 0.6246], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:07,734][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ John] are: tensor([0.0134, 0.2873, 0.2443, 0.4550], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:07,735][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ John] are: tensor([0.0201, 0.9303, 0.0093, 0.0403], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:07,737][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ John] are: tensor([0.0322, 0.4583, 0.0335, 0.4760], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:07,738][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ John] are: tensor([0.0063, 0.1965, 0.2666, 0.5306], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:07,740][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ John] are: tensor([0.0065, 0.0167, 0.0200, 0.9568], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:07,741][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ John] are: tensor([1.2871e-04, 1.2725e-03, 9.9160e-01, 6.9981e-03], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:07,742][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ John] are: tensor([7.1978e-06, 2.5536e-02, 8.9596e-01, 7.8496e-02], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:07,744][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ went] are: tensor([0.0058, 0.4846, 0.1516, 0.1494, 0.2086], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:07,745][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ went] are: tensor([0.0219, 0.8831, 0.0428, 0.0333, 0.0189], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:07,747][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ went] are: tensor([0.0530, 0.8437, 0.0411, 0.0321, 0.0301], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:07,748][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ went] are: tensor([0.0175, 0.4946, 0.1822, 0.1513, 0.1544], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:07,750][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ went] are: tensor([0.0832, 0.2187, 0.0149, 0.5259, 0.1574], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:07,751][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ went] are: tensor([0.0128, 0.1614, 0.1021, 0.1960, 0.5277], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:07,753][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ went] are: tensor([0.0351, 0.8240, 0.0600, 0.0503, 0.0307], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:07,755][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ went] are: tensor([0.0289, 0.4473, 0.0472, 0.2914, 0.1852], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:07,755][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ went] are: tensor([5.0203e-04, 2.5192e-02, 1.2472e-01, 3.2079e-01, 5.2880e-01],
       device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:07,756][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ went] are: tensor([0.0008, 0.0060, 0.0029, 0.4866, 0.5037], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:07,757][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ went] are: tensor([2.5864e-04, 6.2491e-04, 9.7716e-01, 4.3244e-03, 1.7630e-02],
       device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:07,757][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ went] are: tensor([5.9673e-05, 4.1874e-02, 5.7802e-01, 1.2908e-01, 2.5097e-01],
       device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:07,759][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0082, 0.4473, 0.0780, 0.2188, 0.1711, 0.0765], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:07,761][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0502, 0.8675, 0.0092, 0.0313, 0.0308, 0.0110], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:07,762][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0672, 0.7749, 0.0267, 0.0446, 0.0432, 0.0435], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:07,764][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0179, 0.4964, 0.1336, 0.1338, 0.1250, 0.0934], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:07,766][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0612, 0.2681, 0.0135, 0.4699, 0.1749, 0.0122], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:07,767][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0142, 0.1034, 0.0724, 0.1713, 0.3155, 0.3231], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:07,769][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0398, 0.8172, 0.0126, 0.0959, 0.0239, 0.0106], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:07,770][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0575, 0.3783, 0.0393, 0.3430, 0.0511, 0.1309], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:07,772][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ to] are: tensor([2.1994e-04, 3.3000e-02, 1.4227e-01, 9.4024e-02, 4.3688e-01, 2.9360e-01],
       device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:07,773][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0092, 0.0046, 0.0020, 0.1276, 0.0372, 0.8195], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:07,775][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ to] are: tensor([4.3012e-04, 3.4601e-03, 8.6103e-01, 1.4369e-02, 4.2003e-02, 7.8709e-02],
       device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:07,776][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ to] are: tensor([8.3149e-05, 7.1466e-02, 3.3344e-01, 9.6277e-02, 9.9732e-02, 3.9900e-01],
       device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:07,777][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0204, 0.5189, 0.0809, 0.1413, 0.1199, 0.0792, 0.0394],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:07,779][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0463, 0.8898, 0.0215, 0.0160, 0.0124, 0.0107, 0.0033],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:07,781][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0438, 0.8785, 0.0255, 0.0147, 0.0138, 0.0209, 0.0029],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:07,782][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0294, 0.4381, 0.1394, 0.1076, 0.1273, 0.1128, 0.0454],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:07,784][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0574, 0.2859, 0.0154, 0.4244, 0.1782, 0.0170, 0.0219],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:07,786][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0210, 0.0898, 0.0622, 0.1274, 0.2429, 0.2311, 0.2257],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:07,787][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0569, 0.7762, 0.0260, 0.0959, 0.0209, 0.0129, 0.0112],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:07,788][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0875, 0.1932, 0.0423, 0.4053, 0.0474, 0.0942, 0.1300],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:07,788][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0010, 0.0309, 0.1028, 0.0983, 0.4477, 0.2119, 0.1075],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:07,789][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0434, 0.0024, 0.0012, 0.0455, 0.0164, 0.3008, 0.5903],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:07,790][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ the] are: tensor([7.3818e-04, 3.0025e-03, 8.5912e-01, 7.5000e-03, 2.0873e-02, 5.5962e-02,
        5.2803e-02], device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:07,791][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ the] are: tensor([6.4276e-05, 5.6760e-02, 2.7407e-01, 9.6952e-02, 1.0122e-01, 3.3660e-01,
        1.3433e-01], device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:07,793][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ station] are: tensor([0.0031, 0.5110, 0.0568, 0.0813, 0.0806, 0.0587, 0.0340, 0.1746],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:07,794][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ station] are: tensor([2.2321e-02, 9.1321e-01, 1.3528e-02, 8.9540e-03, 1.8702e-02, 1.8002e-02,
        4.5731e-03, 7.1338e-04], device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:07,796][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ station] are: tensor([0.0260, 0.8912, 0.0289, 0.0107, 0.0138, 0.0151, 0.0046, 0.0097],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:07,797][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ station] are: tensor([0.0085, 0.4830, 0.1276, 0.0805, 0.1103, 0.0894, 0.0576, 0.0431],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:07,799][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ station] are: tensor([0.0359, 0.2265, 0.0157, 0.2322, 0.1120, 0.0115, 0.0197, 0.3465],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:07,801][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ station] are: tensor([0.0041, 0.0703, 0.0590, 0.0860, 0.2319, 0.2363, 0.2385, 0.0738],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:07,802][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ station] are: tensor([0.0124, 0.8659, 0.0204, 0.0270, 0.0252, 0.0167, 0.0129, 0.0195],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:07,804][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ station] are: tensor([0.0190, 0.2215, 0.0371, 0.2407, 0.0387, 0.0954, 0.1004, 0.2471],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:07,805][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ station] are: tensor([3.2654e-04, 2.5405e-02, 6.6456e-02, 1.1929e-01, 4.0543e-01, 1.1369e-01,
        1.0170e-01, 1.6770e-01], device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:07,807][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ station] are: tensor([0.0021, 0.0008, 0.0008, 0.0481, 0.0230, 0.2247, 0.3987, 0.3019],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:07,808][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ station] are: tensor([5.9466e-04, 1.3858e-03, 8.2701e-01, 6.4462e-03, 2.4981e-02, 4.6935e-02,
        9.2406e-02, 2.4363e-04], device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:07,809][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ station] are: tensor([2.6208e-05, 3.7296e-02, 3.0430e-01, 5.1444e-02, 7.9194e-02, 2.9887e-01,
        1.3419e-01, 9.4682e-02], device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:07,811][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0143, 0.3915, 0.0390, 0.1563, 0.1116, 0.0449, 0.0318, 0.1824, 0.0282],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:07,812][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0352, 0.8805, 0.0061, 0.0303, 0.0240, 0.0117, 0.0029, 0.0081, 0.0012],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:07,814][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0382, 0.8516, 0.0148, 0.0255, 0.0213, 0.0146, 0.0038, 0.0212, 0.0090],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:07,816][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0181, 0.4916, 0.0897, 0.0974, 0.1016, 0.0701, 0.0480, 0.0378, 0.0457],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:07,818][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0463, 0.1860, 0.0125, 0.3191, 0.1183, 0.0112, 0.0176, 0.2733, 0.0156],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:07,818][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0024, 0.0473, 0.0652, 0.0842, 0.1747, 0.2237, 0.2092, 0.0733, 0.1201],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:07,819][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0202, 0.7980, 0.0061, 0.0944, 0.0189, 0.0050, 0.0046, 0.0500, 0.0027],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:07,820][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0162, 0.2083, 0.0297, 0.3669, 0.0543, 0.0676, 0.0900, 0.0830, 0.0840],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:07,821][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [,] are: tensor([6.4667e-05, 1.5936e-02, 5.4106e-02, 5.9795e-02, 2.8020e-01, 1.7072e-01,
        1.1677e-01, 2.0347e-01, 9.8943e-02], device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:07,822][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0051, 0.0011, 0.0008, 0.0158, 0.0040, 0.0408, 0.1834, 0.1697, 0.5794],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:07,824][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [,] are: tensor([5.6180e-04, 4.1493e-03, 7.1854e-01, 1.3960e-02, 3.1445e-02, 5.0786e-02,
        6.8688e-02, 6.2210e-04, 1.1125e-01], device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:07,825][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [,] are: tensor([1.6684e-07, 2.0819e-03, 2.2125e-01, 2.8537e-02, 3.9036e-02, 4.1201e-01,
        2.0139e-01, 9.0777e-02, 4.9162e-03], device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:07,826][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ John] are: tensor([0.0021, 0.2993, 0.0452, 0.1135, 0.0854, 0.0538, 0.0277, 0.2378, 0.0456,
        0.0896], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:07,828][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ John] are: tensor([0.0066, 0.9392, 0.0047, 0.0042, 0.0176, 0.0178, 0.0026, 0.0033, 0.0014,
        0.0025], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:07,830][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ John] are: tensor([0.0106, 0.9597, 0.0035, 0.0033, 0.0071, 0.0048, 0.0011, 0.0046, 0.0038,
        0.0015], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:07,832][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ John] are: tensor([0.0062, 0.4106, 0.1454, 0.0666, 0.0760, 0.1048, 0.0557, 0.0342, 0.0684,
        0.0320], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:07,833][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ John] are: tensor([0.0143, 0.1394, 0.0124, 0.2361, 0.0730, 0.0082, 0.0128, 0.2746, 0.0145,
        0.2148], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:07,835][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ John] are: tensor([0.0004, 0.0650, 0.0642, 0.0914, 0.2062, 0.1960, 0.1790, 0.0891, 0.0929,
        0.0158], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:07,837][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ John] are: tensor([0.0144, 0.8872, 0.0070, 0.0207, 0.0080, 0.0070, 0.0063, 0.0292, 0.0053,
        0.0148], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:07,838][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ John] are: tensor([0.0092, 0.1487, 0.0194, 0.1873, 0.0230, 0.0459, 0.0677, 0.1010, 0.0504,
        0.3474], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:07,840][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ John] are: tensor([0.0003, 0.0314, 0.0711, 0.0810, 0.2270, 0.1455, 0.0817, 0.2057, 0.0738,
        0.0824], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:07,841][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ John] are: tensor([4.6366e-04, 2.5179e-04, 2.2033e-04, 1.0160e-02, 2.3020e-03, 3.2477e-02,
        1.7071e-01, 1.7386e-01, 4.9657e-01, 1.1298e-01], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:07,843][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ John] are: tensor([4.8341e-05, 8.3338e-04, 6.8863e-01, 4.2330e-03, 1.3950e-02, 4.4492e-02,
        8.5952e-02, 1.9956e-04, 1.6064e-01, 1.0255e-03], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:07,844][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ John] are: tensor([5.0255e-08, 9.9241e-04, 1.3939e-01, 7.0988e-03, 1.6446e-02, 5.0507e-01,
        2.4728e-01, 7.5920e-02, 3.4426e-03, 4.3526e-03], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:07,846][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.0063, 0.2469, 0.0365, 0.1023, 0.0704, 0.0500, 0.0355, 0.2829, 0.0360,
        0.0931, 0.0402], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:07,847][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0445, 0.8594, 0.0066, 0.0280, 0.0140, 0.0176, 0.0027, 0.0059, 0.0012,
        0.0140, 0.0060], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:07,849][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0455, 0.8470, 0.0128, 0.0131, 0.0135, 0.0104, 0.0035, 0.0192, 0.0104,
        0.0093, 0.0155], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:07,850][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.0162, 0.3650, 0.1179, 0.0884, 0.0828, 0.0802, 0.0465, 0.0718, 0.0707,
        0.0506, 0.0101], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:07,851][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.0362, 0.1363, 0.0074, 0.1889, 0.0606, 0.0059, 0.0106, 0.2885, 0.0159,
        0.2172, 0.0327], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:07,852][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.0012, 0.0569, 0.0433, 0.0724, 0.2069, 0.1904, 0.1825, 0.0735, 0.1128,
        0.0130, 0.0469], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:07,853][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0162, 0.5954, 0.0079, 0.0903, 0.0149, 0.0063, 0.0066, 0.1581, 0.0052,
        0.0920, 0.0070], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:07,854][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0192, 0.1313, 0.0137, 0.2151, 0.0237, 0.0330, 0.0459, 0.0713, 0.0294,
        0.2906, 0.1268], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:07,855][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([6.1157e-05, 9.7411e-03, 4.6376e-02, 1.3601e-01, 2.4055e-01, 9.4409e-02,
        9.1882e-02, 1.1528e-01, 4.9138e-02, 1.4107e-01, 7.5481e-02],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:07,857][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([1.4865e-04, 6.4349e-04, 1.8904e-04, 2.1097e-02, 1.3267e-02, 4.7889e-02,
        1.6341e-01, 1.5404e-01, 3.2920e-01, 1.8218e-01, 8.7937e-02],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:07,858][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([5.6076e-04, 1.2871e-03, 7.0591e-01, 6.9652e-03, 1.8645e-02, 4.2567e-02,
        5.8773e-02, 2.4460e-04, 1.3739e-01, 1.2730e-03, 2.6379e-02],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:07,859][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([5.8251e-07, 5.4850e-03, 2.2896e-01, 1.9477e-02, 3.2799e-02, 4.3411e-01,
        1.4679e-01, 1.1260e-01, 5.4702e-03, 8.6517e-03, 5.6580e-03],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:07,861][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0152, 0.2414, 0.0515, 0.0990, 0.0717, 0.0547, 0.0266, 0.2806, 0.0302,
        0.0832, 0.0270, 0.0188], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:07,862][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0347, 0.9009, 0.0083, 0.0160, 0.0052, 0.0062, 0.0012, 0.0072, 0.0016,
        0.0120, 0.0035, 0.0032], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:07,864][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0553, 0.7880, 0.0182, 0.0177, 0.0168, 0.0176, 0.0032, 0.0214, 0.0167,
        0.0108, 0.0113, 0.0230], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:07,866][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0160, 0.3632, 0.0937, 0.0988, 0.0827, 0.1047, 0.0416, 0.0664, 0.0595,
        0.0527, 0.0058, 0.0150], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:07,867][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0282, 0.1162, 0.0077, 0.1932, 0.0686, 0.0086, 0.0110, 0.3127, 0.0112,
        0.1950, 0.0367, 0.0108], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:07,869][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0010, 0.0582, 0.0658, 0.0839, 0.1777, 0.1688, 0.1532, 0.0792, 0.1063,
        0.0169, 0.0529, 0.0359], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:07,871][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0418, 0.5873, 0.0216, 0.1004, 0.0157, 0.0130, 0.0116, 0.0996, 0.0135,
        0.0856, 0.0071, 0.0030], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:07,873][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0493, 0.1622, 0.0227, 0.1734, 0.0279, 0.0342, 0.0532, 0.0523, 0.0483,
        0.2585, 0.0536, 0.0643], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:07,874][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ a] are: tensor([1.0839e-04, 1.6252e-02, 8.7856e-02, 9.0585e-02, 2.0994e-01, 1.2050e-01,
        7.5563e-02, 1.0431e-01, 6.1703e-02, 1.0477e-01, 8.5076e-02, 4.3342e-02],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:07,875][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ a] are: tensor([1.7828e-03, 4.7485e-04, 1.5156e-04, 1.0437e-02, 1.9814e-03, 1.8901e-02,
        5.4409e-02, 1.0540e-01, 4.0410e-01, 1.8133e-01, 1.2531e-01, 9.5713e-02],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:07,876][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ a] are: tensor([3.1316e-04, 2.6087e-03, 6.9628e-01, 8.8412e-03, 1.7237e-02, 4.9644e-02,
        5.4319e-02, 4.1154e-04, 1.0531e-01, 1.6603e-03, 1.8011e-02, 4.5366e-02],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:07,878][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ a] are: tensor([2.1329e-07, 2.5707e-03, 2.6763e-01, 3.0016e-02, 3.2138e-02, 3.9765e-01,
        1.3343e-01, 1.0359e-01, 5.8089e-03, 1.2930e-02, 6.9481e-03, 7.2835e-03],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:07,880][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ ring] are: tensor([0.0024, 0.3660, 0.0501, 0.0685, 0.0678, 0.0486, 0.0242, 0.1337, 0.0336,
        0.0446, 0.0179, 0.0137, 0.1289], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:07,881][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ ring] are: tensor([4.0469e-03, 9.7716e-01, 3.1066e-03, 3.4223e-03, 2.6103e-03, 5.4881e-03,
        8.2030e-04, 2.5102e-04, 4.5532e-04, 9.0569e-04, 1.1048e-03, 4.2178e-04,
        2.0240e-04], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:07,881][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ ring] are: tensor([0.0082, 0.9186, 0.0121, 0.0060, 0.0087, 0.0075, 0.0017, 0.0064, 0.0066,
        0.0021, 0.0057, 0.0098, 0.0064], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:07,882][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ ring] are: tensor([0.0034, 0.4428, 0.1228, 0.0804, 0.0804, 0.0689, 0.0405, 0.0257, 0.0690,
        0.0320, 0.0079, 0.0135, 0.0129], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:07,883][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ ring] are: tensor([0.0171, 0.0999, 0.0063, 0.1138, 0.0392, 0.0035, 0.0079, 0.1729, 0.0118,
        0.1222, 0.0206, 0.0068, 0.3779], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:07,885][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ ring] are: tensor([0.0002, 0.0630, 0.0735, 0.0736, 0.1874, 0.1624, 0.1523, 0.0823, 0.0919,
        0.0137, 0.0625, 0.0319, 0.0054], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:07,887][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ ring] are: tensor([0.0070, 0.8900, 0.0179, 0.0209, 0.0046, 0.0086, 0.0051, 0.0208, 0.0059,
        0.0125, 0.0030, 0.0016, 0.0021], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:07,888][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ ring] are: tensor([0.0035, 0.0637, 0.0187, 0.1675, 0.0315, 0.0353, 0.0500, 0.0694, 0.0357,
        0.2462, 0.0937, 0.0558, 0.1290], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:07,889][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ ring] are: tensor([9.3956e-05, 1.0993e-02, 5.3394e-02, 1.0691e-01, 1.7381e-01, 1.2121e-01,
        9.3591e-02, 1.4336e-01, 5.7375e-02, 1.0539e-01, 7.3062e-02, 4.8674e-02,
        1.2135e-02], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:07,891][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ ring] are: tensor([5.9946e-05, 9.0589e-04, 1.1394e-03, 2.5615e-02, 5.0742e-03, 2.1735e-02,
        1.0290e-01, 2.6219e-01, 2.5078e-01, 1.1118e-01, 1.2670e-01, 5.9711e-02,
        3.2008e-02], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:07,892][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ ring] are: tensor([6.2035e-05, 1.1359e-03, 6.3985e-01, 5.2986e-03, 1.2488e-02, 4.7009e-02,
        5.9597e-02, 3.0417e-04, 1.6695e-01, 1.0656e-03, 2.0472e-02, 4.5158e-02,
        6.1281e-04], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:07,893][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ ring] are: tensor([5.2671e-07, 2.1083e-03, 2.9038e-01, 1.4168e-02, 2.1405e-02, 3.5826e-01,
        2.2250e-01, 6.6184e-02, 4.6060e-03, 5.1393e-03, 3.4444e-03, 6.9843e-03,
        4.8237e-03], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:07,895][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0026, 0.2537, 0.0485, 0.1243, 0.1038, 0.0472, 0.0305, 0.0826, 0.0266,
        0.0755, 0.0281, 0.0205, 0.1313, 0.0248], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:07,896][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ to] are: tensor([2.0925e-02, 9.0491e-01, 7.2442e-03, 1.3670e-02, 2.4582e-02, 7.8540e-03,
        2.2695e-03, 3.7921e-03, 1.0792e-03, 4.8725e-03, 4.3029e-03, 1.5825e-03,
        2.0626e-03, 8.5477e-04], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:07,898][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0250, 0.8800, 0.0090, 0.0130, 0.0182, 0.0108, 0.0025, 0.0072, 0.0056,
        0.0037, 0.0053, 0.0092, 0.0060, 0.0046], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:07,900][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0058, 0.4088, 0.1007, 0.0913, 0.0767, 0.0708, 0.0410, 0.0404, 0.0657,
        0.0423, 0.0060, 0.0133, 0.0138, 0.0237], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:07,902][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0112, 0.0848, 0.0046, 0.1340, 0.0443, 0.0035, 0.0064, 0.1735, 0.0057,
        0.1209, 0.0196, 0.0062, 0.3826, 0.0026], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:07,903][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0021, 0.0476, 0.0462, 0.0805, 0.1500, 0.1590, 0.1600, 0.0699, 0.1030,
        0.0177, 0.0551, 0.0376, 0.0073, 0.0639], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:07,905][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0213, 0.8186, 0.0101, 0.0602, 0.0169, 0.0077, 0.0065, 0.0151, 0.0050,
        0.0305, 0.0040, 0.0013, 0.0009, 0.0017], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:07,907][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0129, 0.0941, 0.0152, 0.1534, 0.0256, 0.0337, 0.0503, 0.0588, 0.0419,
        0.2840, 0.0466, 0.0502, 0.0515, 0.0818], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:07,908][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ to] are: tensor([2.9847e-05, 7.6774e-03, 7.1251e-02, 4.5447e-02, 1.7130e-01, 1.5225e-01,
        1.0541e-01, 1.0632e-01, 8.4062e-02, 6.5133e-02, 4.8119e-02, 6.7411e-02,
        4.3470e-03, 7.1242e-02], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:07,910][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ to] are: tensor([3.2938e-03, 2.6139e-04, 6.3635e-05, 5.9505e-03, 5.9567e-04, 8.5661e-03,
        5.0275e-02, 5.7685e-02, 2.4197e-01, 1.5030e-01, 2.8523e-02, 9.6222e-02,
        4.1788e-02, 3.1451e-01], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:07,911][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ to] are: tensor([1.0003e-04, 1.5752e-03, 5.5734e-01, 8.2874e-03, 2.4703e-02, 6.0321e-02,
        6.6095e-02, 3.6996e-04, 1.7543e-01, 1.6810e-03, 2.8739e-02, 5.0114e-02,
        8.2258e-04, 2.4416e-02], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:07,912][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ to] are: tensor([1.8138e-06, 1.0662e-02, 2.4806e-01, 4.6111e-02, 4.2726e-02, 2.9556e-01,
        1.0148e-01, 1.1570e-01, 9.5068e-03, 2.0659e-02, 9.3707e-03, 9.8179e-03,
        1.5526e-02, 7.4813e-02], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:08,030][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:29:08,031][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:08,033][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:08,034][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:08,035][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:08,037][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:08,038][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:08,039][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:08,039][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:08,040][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:08,041][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:08,042][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:08,043][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:08,044][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Amanda] are: tensor([0.0024, 0.9976], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:08,045][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Amanda] are: tensor([1.6056e-05, 9.9998e-01], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:08,047][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Amanda] are: tensor([0.0012, 0.9988], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:08,049][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Amanda] are: tensor([0.0662, 0.9338], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:08,050][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Amanda] are: tensor([0.3149, 0.6851], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:08,052][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Amanda] are: tensor([0.0016, 0.9984], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:08,053][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Amanda] are: tensor([3.7510e-04, 9.9962e-01], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:08,055][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Amanda] are: tensor([0.0685, 0.9315], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:08,056][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Amanda] are: tensor([0.0218, 0.9782], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:08,058][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Amanda] are: tensor([0.0028, 0.9972], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:08,059][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Amanda] are: tensor([0.6497, 0.3503], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:08,060][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Amanda] are: tensor([2.0781e-04, 9.9979e-01], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:08,062][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0011, 0.8119, 0.1870], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:08,063][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([7.0835e-06, 3.7127e-01, 6.2872e-01], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:08,064][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([2.3060e-04, 5.6745e-01, 4.3232e-01], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:08,066][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0111, 0.7109, 0.2781], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:08,068][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0130, 0.1050, 0.8820], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:08,070][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0021, 0.5940, 0.4039], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:08,070][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([8.2261e-05, 3.9804e-01, 6.0188e-01], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:08,071][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0206, 0.9070, 0.0724], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:08,072][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0020, 0.2063, 0.7917], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:08,072][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0016, 0.6505, 0.3479], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:08,073][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([3.2788e-01, 6.7196e-01, 1.6476e-04], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:08,074][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([1.7666e-04, 8.0951e-01, 1.9031e-01], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:08,075][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ John] are: tensor([3.8432e-04, 1.5769e-01, 1.0556e-01, 7.3636e-01], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:08,076][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ John] are: tensor([1.1552e-04, 1.7999e-01, 1.0378e-01, 7.1611e-01], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:08,078][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ John] are: tensor([0.0014, 0.2868, 0.2216, 0.4902], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:08,079][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ John] are: tensor([0.0415, 0.3977, 0.1815, 0.3793], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:08,081][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ John] are: tensor([0.0701, 0.1532, 0.7122, 0.0646], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:08,082][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ John] are: tensor([0.0026, 0.0186, 0.0151, 0.9637], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:08,084][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ John] are: tensor([1.1730e-04, 2.8027e-01, 3.5295e-01, 3.6666e-01], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:08,085][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ John] are: tensor([0.0309, 0.4532, 0.0340, 0.4819], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:08,087][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ John] are: tensor([0.0063, 0.1965, 0.2666, 0.5306], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:08,088][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ John] are: tensor([0.0065, 0.0167, 0.0200, 0.9568], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:08,089][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ John] are: tensor([4.9541e-01, 2.3035e-01, 2.9019e-04, 2.7396e-01], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:08,091][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ John] are: tensor([6.6670e-05, 4.5836e-01, 3.6286e-01, 1.7871e-01], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:08,092][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([2.6661e-04, 3.3479e-02, 6.8580e-02, 2.7784e-01, 6.1983e-01],
       device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:08,093][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([1.3778e-06, 1.7112e-02, 5.6282e-02, 6.9406e-01, 2.3255e-01],
       device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:08,094][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([1.1172e-04, 4.8380e-02, 1.9308e-01, 3.6895e-01, 3.8948e-01],
       device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:08,095][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([0.0061, 0.0579, 0.1294, 0.1397, 0.6669], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:08,097][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([0.0073, 0.0234, 0.5429, 0.0369, 0.3895], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:08,098][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([2.5210e-04, 7.2737e-03, 4.1472e-03, 3.4362e-01, 6.4470e-01],
       device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:08,099][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([1.3574e-05, 2.2739e-02, 1.6064e-01, 4.1074e-02, 7.7554e-01],
       device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:08,101][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([0.0293, 0.4453, 0.0474, 0.2906, 0.1875], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:08,102][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([5.0203e-04, 2.5192e-02, 1.2472e-01, 3.2079e-01, 5.2880e-01],
       device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:08,102][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([0.0008, 0.0060, 0.0029, 0.4866, 0.5037], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:08,103][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([9.0235e-02, 1.5400e-01, 4.2859e-04, 6.6899e-01, 8.6340e-02],
       device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:08,104][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([1.7187e-04, 1.9180e-01, 1.2477e-01, 1.3362e-01, 5.4963e-01],
       device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:08,105][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([3.5114e-04, 6.9235e-02, 5.2331e-02, 3.2968e-01, 3.5174e-01, 1.9667e-01],
       device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:08,106][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([1.0453e-06, 9.0224e-03, 3.5973e-02, 4.0967e-01, 4.1329e-01, 1.3205e-01],
       device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:08,107][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([1.7446e-04, 7.9500e-02, 8.5872e-02, 2.9643e-01, 3.5833e-01, 1.7969e-01],
       device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:08,109][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0030, 0.0651, 0.0808, 0.1055, 0.4870, 0.2585], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:08,111][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0331, 0.0432, 0.4032, 0.0643, 0.2562, 0.2000], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:08,112][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0061, 0.0070, 0.0034, 0.3395, 0.1763, 0.4676], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:08,113][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([3.4145e-05, 4.4094e-02, 1.3219e-01, 9.7186e-02, 5.7341e-01, 1.5309e-01],
       device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:08,115][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0527, 0.3741, 0.0395, 0.3414, 0.0510, 0.1412], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:08,116][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([2.1994e-04, 3.3000e-02, 1.4227e-01, 9.4024e-02, 4.3688e-01, 2.9360e-01],
       device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:08,118][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0092, 0.0046, 0.0020, 0.1276, 0.0372, 0.8195], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:08,119][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([3.4608e-01, 1.1914e-01, 1.5094e-04, 4.5946e-01, 7.4703e-02, 4.6489e-04],
       device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:08,120][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([9.1119e-05, 2.3126e-01, 1.1529e-01, 1.1114e-01, 1.4490e-01, 3.9731e-01],
       device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:08,122][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([2.4712e-04, 3.7886e-02, 4.6910e-02, 2.7344e-01, 3.4224e-01, 1.8666e-01,
        1.1262e-01], device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:08,123][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([3.5119e-06, 1.2343e-02, 2.9317e-02, 4.3958e-01, 3.7942e-01, 9.0491e-02,
        4.8853e-02], device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:08,124][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0009, 0.0796, 0.0530, 0.3031, 0.2810, 0.1043, 0.1781],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:08,126][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0071, 0.0684, 0.0673, 0.0941, 0.4254, 0.1905, 0.1471],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:08,128][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0586, 0.0397, 0.3281, 0.0389, 0.2076, 0.1918, 0.1352],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:08,129][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.0401, 0.0038, 0.0017, 0.1304, 0.0652, 0.1841, 0.5747],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:08,131][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([2.9595e-05, 3.1432e-02, 1.2149e-01, 8.1864e-02, 4.9103e-01, 1.6521e-01,
        1.0894e-01], device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:08,132][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0786, 0.1920, 0.0427, 0.4035, 0.0475, 0.0999, 0.1359],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:08,133][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0010, 0.0309, 0.1028, 0.0983, 0.4477, 0.2119, 0.1075],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:08,134][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0434, 0.0024, 0.0012, 0.0455, 0.0164, 0.3008, 0.5903],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:08,134][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([4.9883e-01, 1.0899e-01, 8.1269e-05, 3.4723e-01, 4.4583e-02, 2.2409e-04,
        5.8497e-05], device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:08,135][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([8.2754e-05, 1.8364e-01, 1.0004e-01, 1.1103e-01, 1.6890e-01, 3.3649e-01,
        9.9815e-02], device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:08,137][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ station] are: tensor([0.0004, 0.0672, 0.0724, 0.1864, 0.3211, 0.1374, 0.0824, 0.1326],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:08,138][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ station] are: tensor([2.2002e-06, 1.5098e-02, 2.7713e-02, 3.5066e-01, 2.3135e-01, 7.2866e-02,
        2.8609e-02, 2.7370e-01], device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:08,139][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ station] are: tensor([1.4179e-04, 2.6847e-02, 1.0319e-01, 1.3184e-01, 2.8661e-01, 1.1275e-01,
        1.5847e-01, 1.8015e-01], device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:08,141][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ station] are: tensor([0.0037, 0.0389, 0.0574, 0.0441, 0.3690, 0.1499, 0.1130, 0.2240],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:08,143][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ station] are: tensor([0.0072, 0.0205, 0.3349, 0.0297, 0.1801, 0.1563, 0.1407, 0.1305],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:08,144][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ station] are: tensor([0.0008, 0.0014, 0.0016, 0.0696, 0.0873, 0.1633, 0.5414, 0.1347],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:08,145][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ station] are: tensor([4.1310e-05, 3.5893e-02, 1.5241e-01, 6.4875e-02, 4.8819e-01, 9.5527e-02,
        6.0776e-02, 1.0229e-01], device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:08,147][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ station] are: tensor([0.0173, 0.2193, 0.0367, 0.2361, 0.0380, 0.1009, 0.1038, 0.2480],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:08,148][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ station] are: tensor([3.2654e-04, 2.5405e-02, 6.6456e-02, 1.1929e-01, 4.0543e-01, 1.1369e-01,
        1.0170e-01, 1.6770e-01], device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:08,150][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ station] are: tensor([0.0021, 0.0008, 0.0008, 0.0481, 0.0230, 0.2247, 0.3987, 0.3019],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:08,151][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ station] are: tensor([1.8748e-01, 1.6986e-01, 7.0122e-04, 5.1310e-01, 7.9379e-02, 6.4397e-04,
        2.2404e-04, 4.8608e-02], device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:08,152][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ station] are: tensor([3.7680e-05, 1.8244e-01, 9.9080e-02, 8.2054e-02, 1.8027e-01, 2.0692e-01,
        6.2906e-02, 1.8629e-01], device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:08,154][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([1.1094e-04, 5.3724e-02, 3.7253e-02, 2.2379e-01, 2.9854e-01, 9.5650e-02,
        6.6905e-02, 1.9929e-01, 2.4734e-02], device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:08,155][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([2.4046e-07, 4.6719e-03, 1.5595e-02, 1.3349e-01, 1.6471e-01, 5.6339e-02,
        2.2274e-02, 5.8569e-01, 1.7232e-02], device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:08,156][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([2.9432e-05, 2.2862e-02, 4.2873e-02, 1.8954e-01, 2.1583e-01, 7.0362e-02,
        1.3077e-01, 2.3231e-01, 9.5424e-02], device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:08,158][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0008, 0.0371, 0.0400, 0.0494, 0.2759, 0.1102, 0.0737, 0.3297, 0.0831],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:08,159][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0069, 0.0386, 0.2562, 0.0384, 0.2099, 0.0992, 0.0776, 0.1279, 0.1455],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:08,161][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0026, 0.0019, 0.0020, 0.0794, 0.0348, 0.0717, 0.2632, 0.1081, 0.4363],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:08,162][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([1.2351e-05, 2.5174e-02, 9.6813e-02, 7.6074e-02, 3.5678e-01, 1.2129e-01,
        8.6024e-02, 1.6303e-01, 7.4800e-02], device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:08,164][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0139, 0.2064, 0.0300, 0.3626, 0.0543, 0.0722, 0.0940, 0.0837, 0.0829],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:08,164][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([6.4667e-05, 1.5936e-02, 5.4106e-02, 5.9795e-02, 2.8020e-01, 1.7072e-01,
        1.1677e-01, 2.0347e-01, 9.8943e-02], device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:08,165][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0051, 0.0011, 0.0008, 0.0158, 0.0040, 0.0408, 0.1834, 0.1697, 0.5794],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:08,166][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([1.0895e-01, 1.3805e-01, 2.4974e-04, 5.7537e-01, 8.8419e-02, 5.1833e-04,
        1.4471e-04, 8.8166e-02, 1.3042e-04], device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:08,167][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([5.1450e-06, 5.7519e-02, 8.5997e-02, 1.2568e-01, 1.4752e-01, 2.3503e-01,
        9.4466e-02, 2.2057e-01, 3.3206e-02], device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:08,168][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ John] are: tensor([4.6018e-05, 3.0534e-02, 4.2194e-02, 2.4089e-01, 2.4880e-01, 1.1044e-01,
        6.4720e-02, 1.1775e-01, 2.7310e-02, 1.1732e-01], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:08,169][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ John] are: tensor([3.0927e-06, 1.3111e-02, 1.3191e-02, 9.6393e-02, 1.9691e-01, 5.8607e-02,
        1.4111e-02, 5.2122e-01, 1.2620e-02, 7.3838e-02], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:08,170][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ John] are: tensor([9.5608e-05, 4.0372e-02, 5.0560e-02, 1.2234e-01, 1.4809e-01, 6.6472e-02,
        1.1659e-01, 2.1823e-01, 1.0576e-01, 1.3150e-01], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:08,172][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ John] are: tensor([0.0022, 0.0378, 0.0344, 0.0536, 0.1836, 0.1278, 0.1154, 0.2615, 0.1192,
        0.0646], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:08,173][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ John] are: tensor([0.0103, 0.0226, 0.1835, 0.0131, 0.1498, 0.1227, 0.1300, 0.1172, 0.2370,
        0.0139], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:08,175][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ John] are: tensor([0.0005, 0.0009, 0.0007, 0.0487, 0.0175, 0.0416, 0.1917, 0.1403, 0.3141,
        0.2439], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:08,176][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ John] are: tensor([7.4424e-06, 3.4548e-02, 1.0860e-01, 5.8256e-02, 2.8958e-01, 1.1593e-01,
        9.2723e-02, 1.9564e-01, 5.2144e-02, 5.2563e-02], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:08,178][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ John] are: tensor([0.0083, 0.1469, 0.0196, 0.1869, 0.0233, 0.0493, 0.0712, 0.1019, 0.0501,
        0.3425], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:08,180][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ John] are: tensor([0.0003, 0.0314, 0.0711, 0.0810, 0.2270, 0.1455, 0.0817, 0.2057, 0.0738,
        0.0824], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:08,181][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ John] are: tensor([4.6366e-04, 2.5179e-04, 2.2033e-04, 1.0160e-02, 2.3020e-03, 3.2477e-02,
        1.7071e-01, 1.7386e-01, 4.9657e-01, 1.1298e-01], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:08,183][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ John] are: tensor([0.2188, 0.2010, 0.0005, 0.3233, 0.0714, 0.0019, 0.0005, 0.1323, 0.0004,
        0.0500], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:08,184][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ John] are: tensor([4.4220e-07, 1.9568e-02, 5.0165e-02, 1.6840e-02, 5.6911e-02, 3.9018e-01,
        1.6371e-01, 2.4227e-01, 3.6391e-02, 2.3966e-02], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:08,185][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([4.9295e-05, 4.7912e-02, 2.3884e-02, 3.0108e-01, 2.3805e-01, 8.7628e-02,
        5.6399e-02, 7.8542e-02, 1.4249e-02, 1.0387e-01, 4.8329e-02],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:08,186][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([1.5423e-07, 6.2681e-03, 1.2133e-02, 1.8905e-01, 1.5055e-01, 4.1329e-02,
        2.0986e-02, 3.4118e-01, 1.5385e-02, 2.0136e-01, 2.1762e-02],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:08,187][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([7.0245e-05, 2.7583e-02, 3.3486e-02, 1.0443e-01, 2.1698e-01, 5.7199e-02,
        1.0018e-01, 1.4912e-01, 7.1092e-02, 1.1863e-01, 1.2124e-01],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:08,189][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.0010, 0.0248, 0.0311, 0.0488, 0.2378, 0.1111, 0.0776, 0.2777, 0.1019,
        0.0365, 0.0517], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:08,191][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.0168, 0.0313, 0.2364, 0.0239, 0.1313, 0.1058, 0.0837, 0.0641, 0.1948,
        0.0116, 0.1003], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:08,192][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([2.2886e-04, 1.0398e-03, 4.4649e-04, 3.0213e-02, 3.8273e-02, 5.1845e-02,
        2.2911e-01, 9.6380e-02, 3.3073e-01, 2.0048e-01, 2.1252e-02],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:08,193][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([1.9195e-05, 4.5063e-02, 5.1171e-02, 8.3730e-02, 4.2482e-01, 7.5357e-02,
        4.1703e-02, 1.4142e-01, 3.4280e-02, 5.3213e-02, 4.9224e-02],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:08,195][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0172, 0.1331, 0.0141, 0.2158, 0.0241, 0.0358, 0.0483, 0.0731, 0.0292,
        0.2861, 0.1231], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:08,196][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([6.1157e-05, 9.7411e-03, 4.6376e-02, 1.3601e-01, 2.4055e-01, 9.4409e-02,
        9.1882e-02, 1.1528e-01, 4.9138e-02, 1.4107e-01, 7.5481e-02],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:08,197][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([1.4865e-04, 6.4349e-04, 1.8904e-04, 2.1097e-02, 1.3267e-02, 4.7889e-02,
        1.6341e-01, 1.5404e-01, 3.2920e-01, 1.8218e-01, 8.7937e-02],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:08,198][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([2.8317e-02, 6.9927e-02, 2.4510e-04, 6.1990e-01, 7.9148e-02, 8.3623e-04,
        3.4148e-04, 8.2206e-02, 1.9613e-04, 7.7945e-02, 4.0938e-02],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:08,198][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([6.3905e-05, 2.4327e-01, 7.1965e-02, 5.5888e-02, 1.1000e-01, 1.8501e-01,
        5.0631e-02, 2.1280e-01, 2.5813e-02, 2.1451e-02, 2.3112e-02],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:08,199][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([7.3942e-05, 1.9017e-02, 4.0894e-02, 1.8545e-01, 2.0967e-01, 1.0114e-01,
        6.8858e-02, 1.2315e-01, 3.0905e-02, 1.2050e-01, 6.3594e-02, 3.6739e-02],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:08,200][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([1.6776e-07, 3.6874e-03, 1.4692e-02, 1.6735e-01, 1.2120e-01, 4.2815e-02,
        1.7920e-02, 3.7109e-01, 1.2394e-02, 1.8893e-01, 3.4410e-02, 2.5507e-02],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:08,202][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([6.3635e-05, 2.5170e-02, 4.2930e-02, 1.2695e-01, 1.2566e-01, 4.0570e-02,
        7.3513e-02, 1.2809e-01, 7.3082e-02, 1.4650e-01, 1.2037e-01, 9.7105e-02],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:08,203][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0019, 0.0268, 0.0553, 0.0402, 0.1326, 0.1122, 0.0761, 0.2478, 0.1149,
        0.0426, 0.0393, 0.1103], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:08,205][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0217, 0.0327, 0.2420, 0.0271, 0.1332, 0.0644, 0.0556, 0.0474, 0.1922,
        0.0133, 0.1306, 0.0399], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:08,207][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0013, 0.0011, 0.0008, 0.0377, 0.0144, 0.0331, 0.1261, 0.0751, 0.3334,
        0.2598, 0.0268, 0.0904], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:08,208][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([1.2981e-05, 1.3730e-02, 9.3075e-02, 6.5152e-02, 3.1945e-01, 9.9089e-02,
        7.1305e-02, 1.0569e-01, 5.8752e-02, 6.2805e-02, 5.0157e-02, 6.0777e-02],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:08,210][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0416, 0.1642, 0.0236, 0.1740, 0.0288, 0.0369, 0.0562, 0.0533, 0.0481,
        0.2542, 0.0531, 0.0660], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:08,211][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([1.0839e-04, 1.6252e-02, 8.7856e-02, 9.0585e-02, 2.0994e-01, 1.2050e-01,
        7.5563e-02, 1.0431e-01, 6.1703e-02, 1.0477e-01, 8.5076e-02, 4.3342e-02],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:08,212][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([1.7828e-03, 4.7485e-04, 1.5156e-04, 1.0437e-02, 1.9814e-03, 1.8901e-02,
        5.4409e-02, 1.0540e-01, 4.0410e-01, 1.8133e-01, 1.2531e-01, 9.5713e-02],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:08,213][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([1.6309e-01, 9.1006e-02, 2.3172e-04, 5.1832e-01, 5.2523e-02, 3.8253e-04,
        1.2520e-04, 5.6257e-02, 9.9326e-05, 4.7688e-02, 6.9906e-02, 3.7119e-04],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:08,214][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([1.2077e-05, 5.9530e-02, 9.2868e-02, 9.4956e-02, 1.0557e-01, 2.0804e-01,
        4.5929e-02, 2.1188e-01, 3.7332e-02, 5.7824e-02, 4.4948e-02, 4.1108e-02],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:08,216][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ ring] are: tensor([4.7752e-05, 2.1276e-02, 5.1093e-02, 1.5420e-01, 2.3159e-01, 9.8636e-02,
        7.3185e-02, 1.2843e-01, 3.4495e-02, 6.8927e-02, 9.7684e-02, 3.0322e-02,
        1.0112e-02], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:08,217][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ ring] are: tensor([4.7203e-07, 4.1937e-03, 2.9891e-02, 1.4395e-01, 1.1281e-01, 5.6052e-02,
        2.5834e-02, 3.7069e-01, 2.0180e-02, 1.3779e-01, 5.6595e-02, 2.8535e-02,
        1.3482e-02], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:08,218][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ ring] are: tensor([4.2996e-05, 1.0288e-02, 6.2813e-02, 1.0162e-01, 1.0310e-01, 6.7820e-02,
        8.5384e-02, 1.1802e-01, 9.4334e-02, 1.0541e-01, 1.1822e-01, 6.8900e-02,
        6.4050e-02], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:08,220][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ ring] are: tensor([0.0009, 0.0212, 0.0565, 0.0534, 0.1059, 0.1328, 0.0754, 0.2295, 0.1172,
        0.0408, 0.0438, 0.0650, 0.0576], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:08,222][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ ring] are: tensor([0.0015, 0.0149, 0.3338, 0.0081, 0.0832, 0.0643, 0.0623, 0.0662, 0.1948,
        0.0053, 0.1169, 0.0426, 0.0061], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:08,223][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ ring] are: tensor([3.9240e-05, 2.9317e-03, 3.5253e-03, 6.5217e-02, 4.4417e-02, 3.5194e-02,
        1.5125e-01, 1.9096e-01, 2.3585e-01, 1.5079e-01, 5.6051e-02, 5.8661e-02,
        5.1149e-03], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:08,224][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ ring] are: tensor([5.9990e-06, 8.4153e-03, 1.4825e-01, 6.2588e-02, 2.0252e-01, 1.1143e-01,
        8.1443e-02, 9.9649e-02, 7.3752e-02, 4.7883e-02, 6.1347e-02, 5.7793e-02,
        4.4932e-02], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:08,226][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ ring] are: tensor([0.0029, 0.0645, 0.0187, 0.1701, 0.0317, 0.0371, 0.0520, 0.0701, 0.0347,
        0.2456, 0.0907, 0.0558, 0.1261], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:08,227][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ ring] are: tensor([9.3956e-05, 1.0993e-02, 5.3394e-02, 1.0691e-01, 1.7381e-01, 1.2121e-01,
        9.3591e-02, 1.4336e-01, 5.7375e-02, 1.0539e-01, 7.3062e-02, 4.8674e-02,
        1.2135e-02], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:08,228][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ ring] are: tensor([5.9946e-05, 9.0589e-04, 1.1394e-03, 2.5615e-02, 5.0742e-03, 2.1735e-02,
        1.0290e-01, 2.6219e-01, 2.5078e-01, 1.1118e-01, 1.2670e-01, 5.9711e-02,
        3.2008e-02], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:08,229][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ ring] are: tensor([2.4084e-02, 5.8777e-02, 8.3672e-04, 4.6780e-01, 7.1855e-02, 1.5101e-03,
        4.9703e-04, 1.5041e-01, 3.8109e-04, 5.8640e-02, 1.1978e-01, 1.5090e-03,
        4.3914e-02], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:08,230][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ ring] are: tensor([8.2316e-06, 4.1694e-02, 1.4790e-01, 4.7327e-02, 7.2353e-02, 2.2294e-01,
        1.2426e-01, 1.6454e-01, 3.2422e-02, 2.8080e-02, 2.6243e-02, 5.5978e-02,
        3.6253e-02], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:08,231][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([7.3273e-05, 2.1964e-02, 3.1872e-02, 1.8134e-01, 1.4992e-01, 1.0233e-01,
        6.3768e-02, 1.0781e-01, 2.9827e-02, 1.3254e-01, 5.6940e-02, 3.4222e-02,
        1.5212e-02, 7.2177e-02], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:08,232][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([1.0267e-07, 1.8457e-03, 1.7822e-02, 1.3002e-01, 1.1865e-01, 6.5120e-02,
        2.3652e-02, 2.9232e-01, 1.7163e-02, 1.7371e-01, 3.0789e-02, 2.4693e-02,
        1.1493e-02, 9.2722e-02], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:08,233][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([1.5576e-05, 1.2345e-02, 2.0404e-02, 9.2524e-02, 1.0061e-01, 4.7358e-02,
        6.9421e-02, 9.1383e-02, 5.2252e-02, 1.3472e-01, 7.1838e-02, 8.8168e-02,
        7.4499e-02, 1.4447e-01], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:08,235][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0005, 0.0130, 0.0287, 0.0361, 0.1228, 0.0923, 0.0709, 0.2363, 0.0740,
        0.0459, 0.0261, 0.0947, 0.0406, 0.1180], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:08,236][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0098, 0.0329, 0.1949, 0.0203, 0.1087, 0.0780, 0.0562, 0.0399, 0.1573,
        0.0123, 0.1019, 0.0466, 0.0097, 0.1314], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:08,238][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0016, 0.0005, 0.0003, 0.0235, 0.0058, 0.0198, 0.1086, 0.0568, 0.2620,
        0.2418, 0.0272, 0.0835, 0.0112, 0.1573], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:08,239][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([1.2533e-05, 1.4784e-02, 8.4074e-02, 6.4968e-02, 2.4011e-01, 7.7936e-02,
        6.5785e-02, 1.1497e-01, 5.2166e-02, 6.2698e-02, 4.6000e-02, 5.3770e-02,
        4.5669e-02, 7.7055e-02], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:08,241][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0113, 0.0920, 0.0152, 0.1505, 0.0253, 0.0363, 0.0536, 0.0589, 0.0419,
        0.2816, 0.0450, 0.0515, 0.0506, 0.0862], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:08,242][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([2.9847e-05, 7.6774e-03, 7.1251e-02, 4.5447e-02, 1.7130e-01, 1.5225e-01,
        1.0541e-01, 1.0632e-01, 8.4062e-02, 6.5133e-02, 4.8119e-02, 6.7411e-02,
        4.3470e-03, 7.1242e-02], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:08,244][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([3.2938e-03, 2.6139e-04, 6.3635e-05, 5.9505e-03, 5.9567e-04, 8.5661e-03,
        5.0275e-02, 5.7685e-02, 2.4197e-01, 1.5030e-01, 2.8523e-02, 9.6222e-02,
        4.1788e-02, 3.1451e-01], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:08,245][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([9.8103e-02, 6.6461e-02, 2.0926e-04, 5.0845e-01, 8.2186e-02, 8.4252e-04,
        1.8533e-04, 6.4779e-02, 1.4502e-04, 5.8810e-02, 7.9732e-02, 7.1483e-04,
        3.9098e-02, 2.8988e-04], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:08,246][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([1.4313e-05, 6.6715e-02, 6.8870e-02, 8.0597e-02, 6.1941e-02, 1.9099e-01,
        5.3349e-02, 1.6922e-01, 2.8124e-02, 4.5153e-02, 2.0951e-02, 3.6211e-02,
        4.5937e-02, 1.3193e-01], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:08,250][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:29:08,252][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[2411],
        [   1],
        [   9],
        [ 117],
        [   8],
        [  16],
        [ 121],
        [  67],
        [  18],
        [ 131],
        [  84],
        [ 297],
        [ 140],
        [  12]], device='cuda:0')
[2024-07-24 10:29:08,254][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[2026],
        [   1],
        [ 204],
        [ 659],
        [  93],
        [ 161],
        [ 602],
        [ 359],
        [ 112],
        [ 494],
        [ 352],
        [1093],
        [ 510],
        [ 116]], device='cuda:0')
[2024-07-24 10:29:08,255][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[1514],
        [   1],
        [   1],
        [   1],
        [   1],
        [   1],
        [   1],
        [   1],
        [   1],
        [   5],
        [  48],
        [  54],
        [   1],
        [   7]], device='cuda:0')
[2024-07-24 10:29:08,257][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[28992],
        [  300],
        [  318],
        [  324],
        [  465],
        [  439],
        [  406],
        [  397],
        [  441],
        [  372],
        [  476],
        [  404],
        [  324],
        [  418]], device='cuda:0')
[2024-07-24 10:29:08,259][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[8667],
        [   2],
        [   2],
        [   2],
        [   2],
        [   3],
        [   2],
        [   2],
        [   2],
        [   2],
        [   2],
        [   3],
        [   2],
        [   2]], device='cuda:0')
[2024-07-24 10:29:08,260][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[6469],
        [ 137],
        [ 171],
        [ 373],
        [1465],
        [1272],
        [1785],
        [1243],
        [1131],
        [1811],
        [2496],
        [2615],
        [1589],
        [1981]], device='cuda:0')
[2024-07-24 10:29:08,262][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[22189],
        [ 4810],
        [ 5048],
        [ 2631],
        [ 2702],
        [ 2623],
        [ 2674],
        [ 2424],
        [ 2459],
        [ 2335],
        [ 2493],
        [ 2545],
        [ 2026],
        [ 2013]], device='cuda:0')
[2024-07-24 10:29:08,263][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[13910],
        [22149],
        [21288],
        [20993],
        [20878],
        [20637],
        [20224],
        [20609],
        [20129],
        [20428],
        [20250],
        [20214],
        [20286],
        [20015]], device='cuda:0')
[2024-07-24 10:29:08,264][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[3221],
        [  22],
        [  26],
        [  27],
        [  36],
        [  34],
        [  42],
        [  34],
        [  47],
        [  33],
        [ 115],
        [ 105],
        [  32],
        [  40]], device='cuda:0')
[2024-07-24 10:29:08,266][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[43078],
        [    1],
        [    2],
        [ 1140],
        [  437],
        [ 1367],
        [12428],
        [ 1589],
        [ 6961],
        [13451],
        [15112],
        [10728],
        [21995],
        [18330]], device='cuda:0')
[2024-07-24 10:29:08,268][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[31051],
        [ 5264],
        [ 8980],
        [15170],
        [20390],
        [16963],
        [16384],
        [16239],
        [14964],
        [15286],
        [17710],
        [16658],
        [16506],
        [15763]], device='cuda:0')
[2024-07-24 10:29:08,269][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[21996],
        [50135],
        [50150],
        [46193],
        [48974],
        [49039],
        [48142],
        [49371],
        [48709],
        [48440],
        [48284],
        [48151],
        [48955],
        [48318]], device='cuda:0')
[2024-07-24 10:29:08,271][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[23590],
        [  404],
        [17337],
        [17496],
        [17464],
        [18330],
        [18414],
        [18669],
        [18866],
        [19061],
        [18162],
        [19052],
        [19161],
        [19812]], device='cuda:0')
[2024-07-24 10:29:08,272][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[24935],
        [23059],
        [13779],
        [11633],
        [13982],
        [14785],
        [14538],
        [14606],
        [14504],
        [14734],
        [14736],
        [14422],
        [13847],
        [14927]], device='cuda:0')
[2024-07-24 10:29:08,274][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[25304],
        [15925],
        [ 5838],
        [11119],
        [ 9990],
        [ 4361],
        [11894],
        [16211],
        [ 7991],
        [11319],
        [ 8848],
        [13820],
        [ 9497],
        [ 2957]], device='cuda:0')
[2024-07-24 10:29:08,276][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[22241],
        [33503],
        [34479],
        [36151],
        [31367],
        [34443],
        [34671],
        [32558],
        [31755],
        [34183],
        [34226],
        [33937],
        [33478],
        [34742]], device='cuda:0')
[2024-07-24 10:29:08,277][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[32718],
        [ 9098],
        [15590],
        [18691],
        [25932],
        [26887],
        [26697],
        [31274],
        [34203],
        [34177],
        [33260],
        [32785],
        [30934],
        [28309]], device='cuda:0')
[2024-07-24 10:29:08,279][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[32582],
        [15960],
        [21456],
        [19315],
        [19263],
        [20783],
        [21406],
        [27189],
        [25892],
        [24463],
        [25950],
        [24607],
        [26289],
        [25021]], device='cuda:0')
[2024-07-24 10:29:08,281][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[22739],
        [20017],
        [26941],
        [29218],
        [31770],
        [35567],
        [37887],
        [34120],
        [32699],
        [37090],
        [33968],
        [39037],
        [39451],
        [39541]], device='cuda:0')
[2024-07-24 10:29:08,282][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[ 8393],
        [26469],
        [33205],
        [32469],
        [37166],
        [36917],
        [36367],
        [38264],
        [38030],
        [36618],
        [36051],
        [35638],
        [35908],
        [34021]], device='cuda:0')
[2024-07-24 10:29:08,284][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[18180],
        [10979],
        [13569],
        [19164],
        [18408],
        [14319],
        [17198],
        [19119],
        [18474],
        [17215],
        [17427],
        [16644],
        [18923],
        [15985]], device='cuda:0')
[2024-07-24 10:29:08,286][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[32468],
        [41793],
        [33401],
        [30732],
        [26455],
        [25634],
        [24542],
        [24244],
        [21881],
        [21293],
        [23281],
        [22144],
        [21298],
        [20982]], device='cuda:0')
[2024-07-24 10:29:08,287][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[16161],
        [34350],
        [33740],
        [31611],
        [30755],
        [29616],
        [26092],
        [24408],
        [24649],
        [22230],
        [22341],
        [22200],
        [18133],
        [19249]], device='cuda:0')
[2024-07-24 10:29:08,289][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[13306],
        [15643],
        [14226],
        [15233],
        [20902],
        [21452],
        [21379],
        [22290],
        [22884],
        [22550],
        [23476],
        [23807],
        [24031],
        [24072]], device='cuda:0')
[2024-07-24 10:29:08,291][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[40339],
        [ 4399],
        [ 2828],
        [10963],
        [ 4774],
        [ 3362],
        [ 2870],
        [ 2894],
        [ 1876],
        [ 2161],
        [ 2478],
        [ 2273],
        [ 2203],
        [ 2136]], device='cuda:0')
[2024-07-24 10:29:08,292][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[24768],
        [16770],
        [16686],
        [ 7983],
        [ 6939],
        [ 7244],
        [ 7370],
        [ 7561],
        [ 7521],
        [ 9497],
        [ 6760],
        [ 6651],
        [ 7143],
        [ 6409]], device='cuda:0')
[2024-07-24 10:29:08,294][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[10377],
        [24179],
        [24862],
        [26202],
        [20413],
        [24435],
        [23565],
        [24041],
        [22707],
        [22304],
        [24589],
        [22263],
        [21646],
        [21130]], device='cuda:0')
[2024-07-24 10:29:08,295][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[10658],
        [13004],
        [12382],
        [ 9781],
        [11747],
        [12093],
        [12313],
        [11085],
        [12077],
        [11925],
        [11127],
        [11573],
        [12191],
        [13803]], device='cuda:0')
[2024-07-24 10:29:08,296][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[13843],
        [25356],
        [29380],
        [31176],
        [30996],
        [32217],
        [27285],
        [22108],
        [30572],
        [28164],
        [30683],
        [28349],
        [31762],
        [37416]], device='cuda:0')
[2024-07-24 10:29:08,298][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[21092],
        [21092],
        [21092],
        [21092],
        [21092],
        [21092],
        [21092],
        [21092],
        [21092],
        [21092],
        [21092],
        [21092],
        [21092],
        [21092]], device='cuda:0')
[2024-07-24 10:29:08,425][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:29:08,427][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:08,428][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:08,429][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:08,431][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:08,432][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:08,433][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:08,435][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:08,436][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:08,437][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:08,439][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:08,440][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:08,441][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:08,442][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Amanda] are: tensor([0.3347, 0.6653], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:08,442][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Amanda] are: tensor([0.1549, 0.8451], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:08,443][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Amanda] are: tensor([0.0152, 0.9848], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:08,444][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Amanda] are: tensor([0.0346, 0.9654], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:08,445][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Amanda] are: tensor([0.0192, 0.9808], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:08,445][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Amanda] are: tensor([0.3705, 0.6295], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:08,446][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Amanda] are: tensor([0.1346, 0.8654], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:08,447][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Amanda] are: tensor([0.6942, 0.3058], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:08,448][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Amanda] are: tensor([1.8343e-05, 9.9998e-01], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:08,449][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Amanda] are: tensor([2.2883e-04, 9.9977e-01], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:08,451][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Amanda] are: tensor([0.0275, 0.9725], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:08,452][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Amanda] are: tensor([0.6954, 0.3046], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:08,454][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.3373, 0.4224, 0.2403], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:08,455][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0431, 0.9545, 0.0024], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:08,457][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0089, 0.8909, 0.1002], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:08,458][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ and] are: tensor([3.1939e-02, 9.6727e-01, 7.9214e-04], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:08,459][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ and] are: tensor([3.6903e-04, 1.4313e-02, 9.8532e-01], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:08,461][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0966, 0.6318, 0.2716], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:08,462][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0140, 0.9536, 0.0324], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:08,463][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0816, 0.8405, 0.0779], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:08,464][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ and] are: tensor([2.0140e-07, 8.2094e-01, 1.7906e-01], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:08,464][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.1263, 0.8576, 0.0161], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:08,466][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0310, 0.8590, 0.1100], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:08,467][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.4403, 0.3204, 0.2393], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:08,469][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ John] are: tensor([0.7771, 0.1144, 0.0056, 0.1029], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:08,470][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ John] are: tensor([0.4753, 0.3139, 0.0007, 0.2101], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:08,471][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ John] are: tensor([0.0049, 0.7630, 0.0589, 0.1732], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:08,473][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ John] are: tensor([0.0829, 0.8907, 0.0024, 0.0240], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:08,474][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ John] are: tensor([1.3112e-04, 2.6812e-03, 9.1773e-03, 9.8801e-01], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:08,476][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ John] are: tensor([0.1127, 0.5433, 0.2274, 0.1166], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:08,477][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ John] are: tensor([0.0575, 0.6827, 0.0360, 0.2239], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:08,479][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ John] are: tensor([0.8492, 0.1300, 0.0014, 0.0194], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:08,480][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ John] are: tensor([7.1239e-06, 5.6927e-01, 1.5452e-01, 2.7621e-01], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:08,482][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ John] are: tensor([0.3075, 0.6878, 0.0022, 0.0025], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:08,483][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ John] are: tensor([0.1264, 0.1730, 0.0018, 0.6988], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:08,485][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ John] are: tensor([0.0622, 0.0750, 0.0704, 0.7923], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:08,487][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ went] are: tensor([0.5600, 0.2255, 0.0079, 0.0942, 0.1124], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:08,488][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ went] are: tensor([0.1109, 0.5847, 0.0028, 0.2819, 0.0197], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:08,490][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ went] are: tensor([0.0075, 0.4827, 0.0914, 0.2193, 0.1991], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:08,491][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ went] are: tensor([0.0692, 0.8875, 0.0047, 0.0252, 0.0134], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:08,493][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ went] are: tensor([2.1465e-04, 2.0466e-02, 6.0830e-02, 8.7091e-01, 4.7580e-02],
       device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:08,493][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ went] are: tensor([0.1042, 0.2786, 0.2431, 0.1287, 0.2454], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:08,494][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ went] are: tensor([0.1080, 0.4510, 0.0473, 0.3559, 0.0379], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:08,495][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ went] are: tensor([0.1043, 0.2163, 0.0190, 0.4153, 0.2451], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:08,496][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ went] are: tensor([7.0445e-06, 6.0338e-01, 9.3786e-02, 1.9544e-01, 1.0739e-01],
       device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:08,497][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ went] are: tensor([0.1680, 0.8114, 0.0067, 0.0080, 0.0060], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:08,498][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ went] are: tensor([3.1671e-03, 9.2516e-03, 2.2232e-04, 5.5089e-04, 9.8681e-01],
       device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:08,499][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ went] are: tensor([0.0406, 0.1031, 0.0774, 0.6674, 0.1115], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:08,501][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.4319, 0.1494, 0.0663, 0.0753, 0.0518, 0.2254], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:08,502][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ to] are: tensor([4.1651e-02, 7.8899e-02, 1.4978e-04, 8.7667e-01, 1.0600e-03, 1.5660e-03],
       device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:08,504][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0026, 0.4586, 0.0755, 0.2873, 0.1442, 0.0319], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:08,505][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ to] are: tensor([7.0997e-02, 8.6205e-01, 5.6966e-04, 1.1452e-02, 7.8591e-03, 4.7076e-02],
       device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:08,506][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ to] are: tensor([1.5362e-04, 2.4905e-03, 4.1011e-03, 9.1844e-01, 1.4315e-02, 6.0499e-02],
       device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:08,508][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0639, 0.2588, 0.1814, 0.1005, 0.2469, 0.1484], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:08,509][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0151, 0.6847, 0.0135, 0.2407, 0.0081, 0.0379], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:08,511][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.2128, 0.3806, 0.0110, 0.3558, 0.0095, 0.0303], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:08,512][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ to] are: tensor([4.2459e-06, 4.0199e-01, 1.6092e-01, 1.6408e-01, 9.2857e-02, 1.8016e-01],
       device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:08,514][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.2952, 0.5786, 0.0101, 0.0250, 0.0301, 0.0610], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:08,515][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.2072, 0.4575, 0.0068, 0.0059, 0.3138, 0.0089], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:08,517][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0607, 0.0680, 0.0764, 0.6459, 0.0753, 0.0737], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:08,519][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.4774, 0.1214, 0.0411, 0.0181, 0.0219, 0.1177, 0.2024],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:08,520][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ the] are: tensor([9.3558e-02, 1.5327e-02, 1.7496e-05, 8.9070e-01, 1.9517e-04, 1.6033e-04,
        4.3140e-05], device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:08,521][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0017, 0.3761, 0.0757, 0.3003, 0.1580, 0.0394, 0.0487],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:08,523][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ the] are: tensor([7.1864e-02, 8.9992e-01, 1.6894e-04, 4.8287e-03, 1.1088e-03, 1.0607e-02,
        1.1506e-02], device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:08,524][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ the] are: tensor([5.7477e-04, 1.8503e-03, 4.7069e-03, 7.6401e-01, 8.9656e-03, 2.9799e-02,
        1.9009e-01], device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:08,525][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0553, 0.2061, 0.1669, 0.1176, 0.2020, 0.1476, 0.1045],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:08,525][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0225, 0.8040, 0.0205, 0.1296, 0.0033, 0.0185, 0.0016],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:08,526][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.8119, 0.0775, 0.0011, 0.0960, 0.0037, 0.0030, 0.0069],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:08,527][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ the] are: tensor([3.0323e-05, 2.4156e-01, 1.1803e-01, 1.4462e-01, 7.0037e-02, 1.4088e-01,
        2.8485e-01], device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:08,529][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.5171, 0.4485, 0.0033, 0.0079, 0.0069, 0.0132, 0.0031],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:08,530][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.6842, 0.2207, 0.0039, 0.0044, 0.0816, 0.0027, 0.0024],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:08,532][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0395, 0.0587, 0.0698, 0.5974, 0.0751, 0.0641, 0.0955],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:08,533][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ station] are: tensor([0.4131, 0.1685, 0.0241, 0.0434, 0.0830, 0.0882, 0.0589, 0.1208],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:08,535][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ station] are: tensor([8.8064e-02, 6.6146e-01, 5.8503e-04, 2.3676e-01, 2.9456e-03, 3.9986e-03,
        1.1994e-03, 4.9870e-03], device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:08,536][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ station] are: tensor([0.0066, 0.4026, 0.0554, 0.1087, 0.1416, 0.0344, 0.0659, 0.1847],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:08,538][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ station] are: tensor([0.0479, 0.7386, 0.0008, 0.0195, 0.0157, 0.1092, 0.0673, 0.0009],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:08,539][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ station] are: tensor([7.8348e-05, 1.5048e-02, 6.1070e-02, 2.5343e-01, 1.5444e-02, 8.5702e-02,
        5.6029e-01, 8.9411e-03], device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:08,541][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ station] are: tensor([0.0228, 0.1601, 0.0876, 0.0966, 0.1427, 0.0887, 0.0695, 0.3320],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:08,542][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ station] are: tensor([0.0279, 0.5770, 0.0709, 0.1277, 0.0155, 0.0631, 0.0219, 0.0961],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:08,544][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ station] are: tensor([0.1507, 0.6829, 0.0084, 0.1032, 0.0099, 0.0142, 0.0216, 0.0090],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:08,545][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ station] are: tensor([1.3973e-05, 3.0565e-01, 9.1325e-02, 1.0206e-01, 5.9109e-02, 7.6036e-02,
        1.7960e-01, 1.8621e-01], device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:08,547][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ station] are: tensor([0.2968, 0.6809, 0.0022, 0.0074, 0.0048, 0.0057, 0.0012, 0.0011],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:08,549][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ station] are: tensor([0.0641, 0.2275, 0.1011, 0.0231, 0.3853, 0.1036, 0.0924, 0.0028],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:08,550][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ station] are: tensor([0.0282, 0.0604, 0.0677, 0.5159, 0.0844, 0.0638, 0.0975, 0.0820],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:08,552][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.2708, 0.1645, 0.0422, 0.0438, 0.0111, 0.1030, 0.1520, 0.0194, 0.1932],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:08,553][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [,] are: tensor([9.1336e-03, 1.0913e-01, 2.3918e-05, 8.7919e-01, 2.9587e-04, 2.2946e-04,
        1.0664e-04, 1.8434e-03, 5.5392e-05], device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:08,555][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0008, 0.1256, 0.0215, 0.1191, 0.0571, 0.0122, 0.0134, 0.6204, 0.0298],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:08,556][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [,] are: tensor([5.6604e-02, 9.2420e-01, 5.3539e-05, 2.7624e-03, 1.5321e-03, 5.0273e-03,
        3.7917e-03, 1.2901e-03, 4.7340e-03], device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:08,557][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [,] are: tensor([2.0096e-05, 8.9651e-04, 1.3939e-03, 3.8494e-01, 5.5623e-03, 2.3367e-02,
        5.4195e-01, 3.9686e-04, 4.1478e-02], device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:08,558][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0383, 0.1233, 0.1183, 0.0776, 0.1511, 0.1056, 0.0726, 0.2908, 0.0223],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:08,558][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0228, 0.4755, 0.0068, 0.2085, 0.0071, 0.0168, 0.0026, 0.2535, 0.0064],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:08,560][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0599, 0.2465, 0.0038, 0.2617, 0.0063, 0.0159, 0.1195, 0.2124, 0.0741],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:08,561][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [,] are: tensor([5.1961e-05, 2.3062e-01, 1.1157e-01, 1.0963e-01, 8.0153e-02, 7.9430e-02,
        1.5205e-01, 7.7079e-02, 1.5941e-01], device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:08,563][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.2400, 0.6845, 0.0066, 0.0192, 0.0139, 0.0177, 0.0043, 0.0070, 0.0068],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:08,564][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [,] are: tensor([1.0945e-01, 5.6792e-01, 4.4198e-03, 8.7323e-03, 1.4662e-01, 3.6170e-03,
        1.4617e-03, 1.5909e-05, 1.5777e-01], device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:08,565][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0356, 0.0526, 0.0644, 0.5749, 0.0619, 0.0405, 0.0683, 0.0717, 0.0301],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:08,567][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ John] are: tensor([0.5708, 0.1196, 0.0027, 0.0591, 0.0240, 0.0228, 0.0204, 0.0649, 0.0514,
        0.0644], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:08,568][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ John] are: tensor([4.1122e-01, 1.3167e-01, 2.3064e-04, 3.1418e-01, 3.6734e-03, 1.0457e-03,
        8.7962e-04, 3.8784e-02, 5.4370e-04, 9.7766e-02], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:08,570][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ John] are: tensor([0.0011, 0.1975, 0.0301, 0.0906, 0.0633, 0.0188, 0.0238, 0.4926, 0.0521,
        0.0302], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:08,571][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ John] are: tensor([0.0606, 0.4395, 0.0008, 0.0133, 0.0158, 0.1277, 0.1512, 0.0073, 0.1470,
        0.0369], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:08,573][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ John] are: tensor([5.9698e-05, 1.9280e-03, 1.9655e-03, 5.5411e-01, 6.6922e-03, 1.6210e-02,
        5.4641e-02, 1.5304e-02, 4.6218e-03, 3.4447e-01], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:08,574][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ John] are: tensor([0.0841, 0.1109, 0.1076, 0.0516, 0.1257, 0.0989, 0.0555, 0.3283, 0.0219,
        0.0155], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:08,576][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ John] are: tensor([0.0184, 0.4141, 0.0153, 0.0888, 0.0409, 0.0309, 0.0081, 0.3101, 0.0151,
        0.0582], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:08,578][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ John] are: tensor([0.8227, 0.0979, 0.0011, 0.0135, 0.0015, 0.0024, 0.0054, 0.0408, 0.0076,
        0.0071], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:08,579][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ John] are: tensor([5.6326e-06, 2.1436e-01, 4.9055e-02, 8.9571e-02, 5.8030e-02, 7.6395e-02,
        2.0137e-01, 1.3456e-01, 1.6695e-01, 9.7031e-03], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:08,581][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ John] are: tensor([0.5011, 0.4814, 0.0014, 0.0043, 0.0027, 0.0040, 0.0009, 0.0022, 0.0014,
        0.0006], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:08,582][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ John] are: tensor([9.1021e-02, 7.8561e-02, 3.5943e-03, 1.7294e-01, 4.0795e-01, 4.9264e-03,
        8.6059e-03, 5.4782e-06, 1.0623e-01, 1.2616e-01], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:08,583][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ John] are: tensor([0.0203, 0.0505, 0.0506, 0.4359, 0.0758, 0.0495, 0.0666, 0.0623, 0.0287,
        0.1599], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:08,585][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.2774, 0.1556, 0.0033, 0.0596, 0.0715, 0.0257, 0.0215, 0.1185, 0.1128,
        0.0579, 0.0963], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:08,587][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([3.1914e-03, 1.6787e-02, 1.6663e-05, 5.5251e-01, 4.7311e-04, 2.8662e-04,
        8.2111e-04, 1.2959e-02, 1.0038e-04, 4.1125e-01, 1.6016e-03],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:08,587][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0010, 0.2876, 0.0312, 0.1308, 0.0704, 0.0141, 0.0207, 0.3609, 0.0368,
        0.0253, 0.0213], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:08,588][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.0103, 0.4748, 0.0009, 0.0122, 0.0083, 0.0894, 0.1952, 0.0017, 0.1683,
        0.0378, 0.0012], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:08,589][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([9.4489e-06, 1.0998e-03, 3.1120e-03, 3.3335e-01, 8.6973e-03, 1.6534e-02,
        1.2621e-01, 9.3581e-03, 6.6938e-03, 4.8608e-01, 8.8561e-03],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:08,590][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.0608, 0.1448, 0.1082, 0.0859, 0.1630, 0.0809, 0.0578, 0.2189, 0.0171,
        0.0170, 0.0457], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:08,592][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0181, 0.3476, 0.0055, 0.1485, 0.0242, 0.0102, 0.0055, 0.2800, 0.0029,
        0.1525, 0.0051], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:08,593][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0025, 0.0755, 0.0087, 0.0774, 0.0081, 0.0295, 0.6457, 0.0540, 0.0353,
        0.0579, 0.0055], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:08,595][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([3.9948e-07, 4.7297e-01, 3.3918e-02, 4.3336e-02, 5.0944e-02, 4.1133e-02,
        9.7373e-02, 1.0926e-01, 1.4782e-01, 1.8665e-03, 1.3719e-03],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:08,596][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.2242, 0.7366, 0.0016, 0.0092, 0.0091, 0.0083, 0.0019, 0.0039, 0.0020,
        0.0011, 0.0023], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:08,597][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([6.2551e-03, 6.2277e-02, 4.5390e-03, 2.0680e-02, 4.0643e-01, 1.0233e-02,
        4.9324e-02, 9.1607e-05, 3.9600e-01, 4.0650e-02, 3.5240e-03],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:08,599][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0165, 0.0653, 0.0339, 0.4118, 0.0595, 0.0331, 0.0526, 0.0576, 0.0274,
        0.1747, 0.0677], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:08,601][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.2283, 0.0598, 0.0221, 0.0249, 0.0199, 0.0813, 0.2384, 0.0303, 0.1921,
        0.0187, 0.0398, 0.0444], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:08,602][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ a] are: tensor([1.8597e-02, 3.3811e-03, 2.2479e-06, 6.6567e-01, 4.5734e-05, 1.7027e-05,
        9.3151e-06, 1.1466e-03, 9.6780e-06, 3.1100e-01, 1.1589e-04, 5.4553e-06],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:08,604][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0006, 0.1269, 0.0250, 0.1375, 0.0671, 0.0118, 0.0169, 0.5306, 0.0263,
        0.0293, 0.0216, 0.0065], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:08,605][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0355, 0.6797, 0.0011, 0.0230, 0.0095, 0.0645, 0.0813, 0.0051, 0.0513,
        0.0338, 0.0053, 0.0100], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:08,607][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ a] are: tensor([4.4664e-05, 5.3934e-04, 6.5469e-04, 2.6233e-01, 3.2244e-03, 4.8389e-03,
        5.4750e-02, 1.5294e-03, 4.0737e-03, 5.8170e-01, 1.0320e-03, 8.5289e-02],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:08,609][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0892, 0.0902, 0.1165, 0.0663, 0.1752, 0.0874, 0.0541, 0.2161, 0.0157,
        0.0157, 0.0536, 0.0201], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:08,610][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0148, 0.2800, 0.0078, 0.1250, 0.0089, 0.0099, 0.0025, 0.4053, 0.0064,
        0.1312, 0.0022, 0.0059], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:08,612][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.4447, 0.0413, 0.0019, 0.2173, 0.0014, 0.0023, 0.0136, 0.0710, 0.0098,
        0.1759, 0.0025, 0.0184], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:08,613][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ a] are: tensor([7.0700e-07, 2.9525e-01, 3.6427e-02, 4.2718e-02, 5.2033e-02, 6.0761e-02,
        1.6021e-01, 8.9051e-02, 2.5597e-01, 3.3274e-03, 2.9954e-03, 1.2598e-03],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:08,615][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.2807, 0.6676, 0.0035, 0.0145, 0.0070, 0.0085, 0.0021, 0.0047, 0.0034,
        0.0020, 0.0042, 0.0017], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:08,616][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ a] are: tensor([2.7429e-01, 1.5013e-01, 6.8319e-03, 1.4042e-02, 2.8356e-01, 3.4151e-03,
        8.1233e-03, 1.7082e-05, 2.3587e-01, 2.0201e-02, 4.2122e-04, 3.1070e-03],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:08,618][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0280, 0.0642, 0.0425, 0.3876, 0.0474, 0.0352, 0.0483, 0.0460, 0.0274,
        0.1559, 0.0655, 0.0520], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:08,619][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ ring] are: tensor([0.0496, 0.0210, 0.0093, 0.0141, 0.0326, 0.0437, 0.0415, 0.1111, 0.3326,
        0.0227, 0.0599, 0.0294, 0.2324], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:08,620][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ ring] are: tensor([1.6642e-01, 1.8201e-01, 1.8652e-04, 5.9343e-01, 1.4305e-03, 9.5953e-04,
        4.6587e-04, 7.3533e-03, 1.3373e-04, 4.6623e-02, 7.4271e-04, 1.2917e-04,
        1.1126e-04], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:08,620][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ ring] are: tensor([0.0009, 0.1980, 0.0269, 0.1210, 0.0852, 0.0115, 0.0199, 0.3600, 0.0330,
        0.0243, 0.0250, 0.0121, 0.0823], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:08,621][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ ring] are: tensor([0.0410, 0.3280, 0.0018, 0.0231, 0.0253, 0.1447, 0.1694, 0.0078, 0.0954,
        0.0425, 0.0086, 0.1110, 0.0016], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:08,623][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ ring] are: tensor([5.3369e-05, 4.3606e-03, 1.7337e-02, 1.1093e-01, 9.5751e-03, 4.8439e-02,
        3.2382e-01, 8.6206e-03, 4.4329e-02, 1.0897e-01, 4.1116e-03, 3.1869e-01,
        7.6184e-04], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:08,624][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ ring] are: tensor([0.1115, 0.0985, 0.1360, 0.0647, 0.1554, 0.0848, 0.0509, 0.2103, 0.0124,
        0.0106, 0.0423, 0.0162, 0.0064], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:08,626][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ ring] are: tensor([0.0008, 0.7300, 0.0267, 0.0960, 0.0235, 0.0111, 0.0044, 0.0592, 0.0035,
        0.0264, 0.0013, 0.0028, 0.0143], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:08,628][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ ring] are: tensor([0.1958, 0.5430, 0.0150, 0.1122, 0.0058, 0.0201, 0.0229, 0.0141, 0.0255,
        0.0153, 0.0028, 0.0257, 0.0017], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:08,629][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ ring] are: tensor([5.7480e-07, 3.1066e-01, 2.6524e-02, 5.1077e-02, 4.8238e-02, 6.0170e-02,
        1.7657e-01, 1.4340e-01, 1.7445e-01, 3.6622e-03, 1.6827e-03, 1.2629e-03,
        2.3023e-03], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:08,630][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ ring] are: tensor([1.4651e-01, 8.2609e-01, 2.8710e-03, 7.3910e-03, 4.5678e-03, 4.8126e-03,
        1.2175e-03, 1.9198e-03, 8.0168e-04, 6.4195e-04, 1.7276e-03, 5.2705e-04,
        9.2386e-04], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:08,631][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ ring] are: tensor([7.1820e-03, 1.1559e-02, 4.4095e-02, 1.6297e-02, 1.2188e-01, 1.1462e-02,
        4.8880e-02, 8.9573e-06, 7.1547e-01, 1.4658e-02, 2.0779e-04, 8.2493e-03,
        5.7296e-05], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:08,633][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ ring] are: tensor([0.0290, 0.0598, 0.0396, 0.3526, 0.0615, 0.0316, 0.0449, 0.0524, 0.0270,
        0.1371, 0.0843, 0.0680, 0.0124], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:08,635][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0777, 0.0675, 0.0316, 0.0191, 0.0199, 0.1204, 0.2064, 0.0271, 0.2624,
        0.0129, 0.0356, 0.0361, 0.0318, 0.0515], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:08,636][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ to] are: tensor([1.5503e-02, 2.0419e-02, 1.7950e-05, 5.9953e-01, 2.6737e-04, 1.8207e-04,
        2.0217e-04, 2.1960e-03, 6.2750e-05, 3.6078e-01, 2.8485e-04, 3.6643e-05,
        1.4038e-04, 3.7952e-04], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:08,637][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ to] are: tensor([3.3174e-04, 1.0459e-01, 2.8257e-02, 1.2557e-01, 4.5115e-02, 1.2148e-02,
        1.5439e-02, 4.8147e-01, 2.6081e-02, 2.3678e-02, 1.5068e-02, 5.7274e-03,
        1.1244e-01, 4.0771e-03], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:08,639][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ to] are: tensor([4.9570e-02, 6.1054e-01, 5.2010e-04, 1.2792e-02, 7.9920e-03, 4.9814e-02,
        6.3376e-02, 1.6961e-03, 9.2988e-02, 2.8878e-02, 6.4345e-03, 2.1906e-02,
        4.2891e-04, 5.3062e-02], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:08,640][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ to] are: tensor([1.7028e-05, 4.4445e-04, 3.6502e-04, 3.0599e-01, 3.6723e-03, 5.8294e-03,
        3.7593e-02, 8.1825e-04, 2.6216e-03, 5.8868e-01, 7.0776e-04, 4.8499e-02,
        1.8873e-04, 4.5763e-03], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:08,641][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0929, 0.0717, 0.1131, 0.0539, 0.1672, 0.0970, 0.0553, 0.1973, 0.0176,
        0.0143, 0.0523, 0.0221, 0.0092, 0.0361], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:08,643][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0016, 0.6546, 0.0082, 0.1280, 0.0192, 0.0137, 0.0034, 0.0980, 0.0045,
        0.0354, 0.0010, 0.0020, 0.0253, 0.0051], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:08,645][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.1100, 0.1365, 0.0059, 0.1415, 0.0030, 0.0192, 0.1579, 0.1442, 0.0315,
        0.1829, 0.0045, 0.0451, 0.0050, 0.0129], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:08,646][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ to] are: tensor([4.9548e-07, 3.1993e-01, 4.8364e-02, 3.7454e-02, 4.9665e-02, 5.7733e-02,
        1.3974e-01, 7.0606e-02, 2.6684e-01, 2.6645e-03, 2.6214e-03, 1.1901e-03,
        1.0838e-03, 2.1046e-03], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:08,648][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.2407, 0.5586, 0.0051, 0.0302, 0.0228, 0.0414, 0.0098, 0.0221, 0.0125,
        0.0083, 0.0118, 0.0059, 0.0109, 0.0199], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:08,649][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ to] are: tensor([5.1569e-02, 7.0519e-02, 7.2658e-03, 4.9610e-03, 1.1855e-01, 1.0797e-02,
        1.2487e-02, 2.3744e-06, 6.9267e-01, 8.2142e-03, 3.2224e-04, 1.5104e-03,
        1.6565e-07, 2.1128e-02], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:08,650][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0340, 0.0595, 0.0374, 0.3455, 0.0532, 0.0304, 0.0464, 0.0497, 0.0252,
        0.1428, 0.0731, 0.0503, 0.0190, 0.0333], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:08,767][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:29:08,768][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:08,768][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:08,769][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:08,770][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:08,770][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:08,771][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:08,772][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:08,773][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:08,775][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:08,776][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:08,777][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:08,777][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:29:08,778][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Amanda] are: tensor([0.3347, 0.6653], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:08,779][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Amanda] are: tensor([0.1549, 0.8451], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:08,780][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Amanda] are: tensor([0.5017, 0.4983], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:08,782][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Amanda] are: tensor([0.0528, 0.9472], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:08,784][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Amanda] are: tensor([0.0122, 0.9878], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:08,785][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Amanda] are: tensor([0.0042, 0.9958], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:08,787][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Amanda] are: tensor([0.0508, 0.9492], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:08,788][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Amanda] are: tensor([0.6942, 0.3058], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:08,789][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Amanda] are: tensor([1.1711e-06, 1.0000e+00], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:08,791][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Amanda] are: tensor([6.5019e-06, 9.9999e-01], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:08,792][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Amanda] are: tensor([0.0275, 0.9725], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:08,794][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Amanda] are: tensor([0.9800, 0.0200], device='cuda:0') for source tokens [After Amanda]
[2024-07-24 10:29:08,795][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.3373, 0.4224, 0.2403], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:08,795][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0431, 0.9545, 0.0024], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:08,796][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0012, 0.9941, 0.0046], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:08,797][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([4.6831e-02, 9.5281e-01, 3.6366e-04], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:08,798][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([7.2111e-04, 3.4523e-02, 9.6476e-01], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:08,799][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0232, 0.9143, 0.0625], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:08,801][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0882, 0.8977, 0.0141], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:08,802][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0816, 0.8405, 0.0779], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:08,803][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([4.6270e-04, 4.9892e-02, 9.4965e-01], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:08,804][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([8.5960e-03, 9.9110e-01, 2.9930e-04], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:08,806][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0310, 0.8590, 0.1100], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:08,807][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([8.3760e-01, 1.6200e-01, 3.9576e-04], device='cuda:0') for source tokens [After Amanda and]
[2024-07-24 10:29:08,809][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ John] are: tensor([0.7771, 0.1144, 0.0056, 0.1029], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:08,810][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ John] are: tensor([0.4753, 0.3139, 0.0007, 0.2101], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:08,812][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ John] are: tensor([4.6629e-04, 9.9043e-01, 4.2045e-04, 8.6795e-03], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:08,813][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ John] are: tensor([0.0880, 0.8933, 0.0015, 0.0172], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:08,814][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ John] are: tensor([4.7851e-04, 1.0791e-02, 2.0773e-02, 9.6796e-01], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:08,816][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ John] are: tensor([0.1433, 0.8295, 0.0062, 0.0210], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:08,817][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ John] are: tensor([0.2842, 0.5927, 0.0031, 0.1200], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:08,819][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ John] are: tensor([0.8492, 0.1300, 0.0014, 0.0194], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:08,821][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ John] are: tensor([0.3421, 0.6020, 0.0277, 0.0281], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:08,822][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ John] are: tensor([2.6224e-02, 9.7373e-01, 4.0989e-06, 3.9565e-05], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:08,824][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ John] are: tensor([0.1264, 0.1730, 0.0018, 0.6988], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:08,825][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ John] are: tensor([9.1490e-01, 8.4224e-02, 1.7146e-04, 7.0408e-04], device='cuda:0') for source tokens [After Amanda and John]
[2024-07-24 10:29:08,826][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([0.5600, 0.2255, 0.0079, 0.0942, 0.1124], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:08,827][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([0.1109, 0.5847, 0.0028, 0.2819, 0.0197], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:08,827][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([0.0044, 0.7878, 0.0131, 0.1292, 0.0656], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:08,828][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([0.0945, 0.8769, 0.0028, 0.0177, 0.0081], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:08,829][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([0.0009, 0.0600, 0.0989, 0.7513, 0.0888], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:08,831][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([0.0320, 0.6315, 0.0172, 0.0174, 0.3020], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:08,832][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([0.0352, 0.5534, 0.0340, 0.3043, 0.0730], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:08,834][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([0.1043, 0.2163, 0.0190, 0.4153, 0.2451], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:08,835][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([0.0687, 0.8816, 0.0047, 0.0317, 0.0132], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:08,837][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([0.0718, 0.8230, 0.0200, 0.0176, 0.0676], device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:08,838][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([3.1671e-03, 9.2516e-03, 2.2232e-04, 5.5089e-04, 9.8681e-01],
       device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:08,839][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([9.2242e-01, 6.2797e-02, 5.3706e-04, 7.7911e-04, 1.3465e-02],
       device='cuda:0') for source tokens [After Amanda and John went]
[2024-07-24 10:29:08,841][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.4319, 0.1494, 0.0663, 0.0753, 0.0518, 0.2254], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:08,842][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([4.1651e-02, 7.8899e-02, 1.4978e-04, 8.7667e-01, 1.0600e-03, 1.5660e-03],
       device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:08,844][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0033, 0.4921, 0.0019, 0.4520, 0.0400, 0.0107], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:08,845][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([1.0367e-01, 8.5854e-01, 2.5674e-04, 7.4236e-03, 4.4744e-03, 2.5631e-02],
       device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:08,846][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([6.3732e-04, 1.0075e-02, 9.1376e-03, 8.0126e-01, 3.2720e-02, 1.4617e-01],
       device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:08,848][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0080, 0.0894, 0.0034, 0.0111, 0.8671, 0.0209], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:08,849][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.1279, 0.7589, 0.0015, 0.0727, 0.0126, 0.0264], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:08,851][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.2128, 0.3806, 0.0110, 0.3558, 0.0095, 0.0303], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:08,853][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0023, 0.0835, 0.0638, 0.0613, 0.0339, 0.7552], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:08,855][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.1032, 0.6445, 0.0011, 0.0471, 0.1791, 0.0252], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:08,856][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.2072, 0.4575, 0.0068, 0.0059, 0.3138, 0.0089], device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:08,857][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([8.9687e-01, 9.7631e-02, 9.0692e-05, 8.1554e-04, 2.2916e-03, 2.2980e-03],
       device='cuda:0') for source tokens [After Amanda and John went to]
[2024-07-24 10:29:08,858][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.4774, 0.1214, 0.0411, 0.0181, 0.0219, 0.1177, 0.2024],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:08,859][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([9.3558e-02, 1.5327e-02, 1.7496e-05, 8.9070e-01, 1.9517e-04, 1.6033e-04,
        4.3140e-05], device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:08,860][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0157, 0.7368, 0.0008, 0.2275, 0.0119, 0.0046, 0.0027],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:08,861][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([1.0140e-01, 8.8717e-01, 5.7547e-05, 2.6331e-03, 4.5375e-04, 4.3662e-03,
        3.9168e-03], device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:08,862][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0021, 0.0073, 0.0110, 0.6665, 0.0202, 0.0724, 0.2205],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:08,864][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.1333, 0.1632, 0.0025, 0.0126, 0.6784, 0.0088, 0.0012],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:08,865][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([6.5235e-01, 3.0082e-01, 1.7582e-04, 3.9440e-02, 3.5501e-03, 3.2365e-03,
        4.3319e-04], device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:08,866][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.8119, 0.0775, 0.0011, 0.0960, 0.0037, 0.0030, 0.0069],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:08,868][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0112, 0.0766, 0.0601, 0.0397, 0.0161, 0.6552, 0.1411],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:08,869][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([3.6318e-01, 5.4799e-01, 1.1841e-04, 1.1447e-02, 7.3563e-02, 3.5396e-03,
        1.5726e-04], device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:08,871][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.6842, 0.2207, 0.0039, 0.0044, 0.0816, 0.0027, 0.0024],
       device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:08,872][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([9.6293e-01, 3.6103e-02, 5.8684e-06, 9.7549e-05, 5.3256e-04, 2.6026e-04,
        7.4590e-05], device='cuda:0') for source tokens [After Amanda and John went to the]
[2024-07-24 10:29:08,874][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ station] are: tensor([0.4131, 0.1685, 0.0241, 0.0434, 0.0830, 0.0882, 0.0589, 0.1208],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:08,875][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ station] are: tensor([8.8064e-02, 6.6146e-01, 5.8503e-04, 2.3676e-01, 2.9456e-03, 3.9986e-03,
        1.1994e-03, 4.9870e-03], device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:08,876][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ station] are: tensor([6.0113e-04, 9.4390e-01, 2.6982e-03, 3.1604e-02, 1.0559e-02, 3.6961e-03,
        6.0194e-03, 9.2430e-04], device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:08,877][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ station] are: tensor([6.1984e-02, 7.7994e-01, 5.4225e-04, 1.7468e-02, 1.2611e-02, 8.5738e-02,
        4.1249e-02, 4.6603e-04], device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:08,878][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ station] are: tensor([2.4182e-04, 4.1412e-02, 8.7026e-02, 2.0063e-01, 2.6489e-02, 1.6215e-01,
        4.7041e-01, 1.1638e-02], device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:08,880][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ station] are: tensor([0.0038, 0.7702, 0.0022, 0.0038, 0.1780, 0.0223, 0.0035, 0.0162],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:08,882][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ station] are: tensor([0.0449, 0.6643, 0.0119, 0.0548, 0.0296, 0.0986, 0.0240, 0.0719],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:08,883][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ station] are: tensor([0.1507, 0.6829, 0.0084, 0.1032, 0.0099, 0.0142, 0.0216, 0.0090],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:08,885][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ station] are: tensor([0.0150, 0.3178, 0.0168, 0.0248, 0.0196, 0.4489, 0.1214, 0.0357],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:08,886][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ station] are: tensor([7.1150e-03, 9.4604e-01, 1.2975e-04, 1.2252e-03, 3.5264e-02, 3.3992e-03,
        1.9724e-04, 6.6296e-03], device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:08,888][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ station] are: tensor([0.0641, 0.2275, 0.1011, 0.0231, 0.3853, 0.1036, 0.0924, 0.0028],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:08,889][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ station] are: tensor([0.7688, 0.1085, 0.0077, 0.0070, 0.0207, 0.0465, 0.0176, 0.0230],
       device='cuda:0') for source tokens [After Amanda and John went to the station]
[2024-07-24 10:29:08,890][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.2708, 0.1645, 0.0422, 0.0438, 0.0111, 0.1030, 0.1520, 0.0194, 0.1932],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:08,890][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([9.1336e-03, 1.0913e-01, 2.3918e-05, 8.7919e-01, 2.9587e-04, 2.2946e-04,
        1.0664e-04, 1.8434e-03, 5.5392e-05], device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:08,891][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([6.1277e-04, 4.5950e-01, 3.3469e-04, 2.5070e-01, 1.2995e-02, 1.4857e-03,
        8.5912e-04, 2.7231e-01, 1.2018e-03], device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:08,892][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([7.5515e-02, 9.1758e-01, 1.4776e-05, 1.3500e-03, 6.3645e-04, 1.8260e-03,
        1.0540e-03, 4.5709e-04, 1.5684e-03], device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:08,893][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([6.4758e-05, 3.3548e-03, 3.1789e-03, 3.3115e-01, 1.1257e-02, 5.4677e-02,
        5.3987e-01, 8.2563e-04, 5.5623e-02], device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:08,895][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0010, 0.0287, 0.0010, 0.0019, 0.7880, 0.0077, 0.0015, 0.1668, 0.0033],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:08,896][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0632, 0.4937, 0.0006, 0.1472, 0.0073, 0.0237, 0.0039, 0.2550, 0.0055],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:08,898][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0599, 0.2465, 0.0038, 0.2617, 0.0063, 0.0159, 0.1195, 0.2124, 0.0741],
       device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:08,899][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([1.3386e-05, 4.8618e-03, 5.5903e-02, 1.6934e-01, 6.9347e-02, 1.5745e-01,
        6.7798e-02, 1.0661e-02, 4.6462e-01], device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:08,900][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([7.9168e-03, 5.6486e-01, 4.7861e-05, 1.2513e-02, 6.4783e-02, 4.0221e-03,
        1.2839e-04, 3.4549e-01, 2.4232e-04], device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:08,902][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([1.0945e-01, 5.6792e-01, 4.4198e-03, 8.7323e-03, 1.4662e-01, 3.6170e-03,
        1.4617e-03, 1.5909e-05, 1.5777e-01], device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:08,903][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([8.6312e-01, 1.3081e-01, 2.6873e-05, 3.7598e-04, 2.2033e-03, 5.1321e-04,
        5.7281e-05, 1.5789e-03, 1.3148e-03], device='cuda:0') for source tokens [After Amanda and John went to the station,]
[2024-07-24 10:29:08,905][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ John] are: tensor([0.5708, 0.1196, 0.0027, 0.0591, 0.0240, 0.0228, 0.0204, 0.0649, 0.0514,
        0.0644], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:08,906][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ John] are: tensor([4.1122e-01, 1.3167e-01, 2.3064e-04, 3.1418e-01, 3.6734e-03, 1.0457e-03,
        8.7962e-04, 3.8784e-02, 5.4370e-04, 9.7766e-02], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:08,907][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ John] are: tensor([2.7154e-04, 8.7153e-01, 5.4836e-04, 1.0897e-02, 1.2001e-02, 1.0094e-03,
        6.6608e-04, 9.9738e-02, 1.1825e-03, 2.1542e-03], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:08,908][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ John] are: tensor([7.3442e-02, 5.6108e-01, 5.2355e-04, 1.0974e-02, 1.2155e-02, 1.0269e-01,
        1.0081e-01, 4.4118e-03, 1.0971e-01, 2.4199e-02], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:08,909][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ John] are: tensor([2.4837e-04, 7.6913e-03, 4.8550e-03, 5.5510e-01, 1.6021e-02, 4.3882e-02,
        7.6497e-02, 2.5372e-02, 9.1053e-03, 2.6123e-01], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:08,911][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ John] are: tensor([0.1521, 0.3705, 0.0018, 0.0062, 0.0974, 0.0067, 0.0009, 0.3591, 0.0030,
        0.0022], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:08,913][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ John] are: tensor([0.1593, 0.2175, 0.0008, 0.0866, 0.0388, 0.0200, 0.0030, 0.4168, 0.0062,
        0.0510], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:08,914][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ John] are: tensor([0.8227, 0.0979, 0.0011, 0.0135, 0.0015, 0.0024, 0.0054, 0.0408, 0.0076,
        0.0071], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:08,916][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ John] are: tensor([7.3858e-01, 2.0719e-01, 1.4922e-03, 9.3036e-04, 4.1633e-04, 1.9311e-02,
        6.8761e-03, 1.5410e-03, 2.2386e-02, 1.2785e-03], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:08,917][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ John] are: tensor([8.8294e-02, 8.6944e-01, 2.6269e-06, 7.3316e-05, 7.5299e-04, 3.5609e-05,
        1.2669e-06, 4.1366e-02, 9.5166e-06, 2.6286e-05], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:08,918][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ John] are: tensor([9.1021e-02, 7.8561e-02, 3.5943e-03, 1.7294e-01, 4.0795e-01, 4.9264e-03,
        8.6059e-03, 5.4782e-06, 1.0623e-01, 1.2616e-01], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:08,919][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ John] are: tensor([8.7906e-01, 7.0509e-02, 1.2397e-04, 2.7987e-04, 2.7117e-02, 5.4663e-03,
        2.4287e-03, 1.2258e-02, 2.5335e-03, 2.1922e-04], device='cuda:0') for source tokens [After Amanda and John went to the station, John]
[2024-07-24 10:29:08,920][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.2774, 0.1556, 0.0033, 0.0596, 0.0715, 0.0257, 0.0215, 0.1185, 0.1128,
        0.0579, 0.0963], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:08,921][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([3.1914e-03, 1.6787e-02, 1.6663e-05, 5.5251e-01, 4.7311e-04, 2.8662e-04,
        8.2111e-04, 1.2959e-02, 1.0038e-04, 4.1125e-01, 1.6016e-03],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:08,922][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([3.4694e-06, 3.0952e-01, 8.6821e-04, 3.5055e-01, 2.1273e-02, 3.7124e-03,
        5.6808e-03, 1.7350e-01, 3.4036e-03, 1.3143e-01, 6.2179e-05],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:08,923][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([1.3662e-02, 6.0344e-01, 5.9278e-04, 1.0079e-02, 6.3372e-03, 6.7719e-02,
        1.3716e-01, 8.3986e-04, 1.3327e-01, 2.6379e-02, 5.2181e-04],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:08,924][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([3.6259e-05, 4.7411e-03, 7.7367e-03, 3.4278e-01, 2.0804e-02, 4.8164e-02,
        1.6483e-01, 1.6162e-02, 1.3103e-02, 3.4187e-01, 3.9771e-02],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:08,926][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.0245, 0.4198, 0.0013, 0.0239, 0.2361, 0.0074, 0.0026, 0.2349, 0.0039,
        0.0195, 0.0262], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:08,928][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.0065, 0.3782, 0.0008, 0.0522, 0.0200, 0.0183, 0.0075, 0.4794, 0.0022,
        0.0302, 0.0047], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:08,929][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0025, 0.0755, 0.0087, 0.0774, 0.0081, 0.0295, 0.6457, 0.0540, 0.0353,
        0.0579, 0.0055], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:08,931][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.2223, 0.2225, 0.0030, 0.0277, 0.0053, 0.0844, 0.0378, 0.0445, 0.2532,
        0.0601, 0.0394], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:08,932][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([5.1868e-03, 1.4884e-01, 1.1743e-05, 5.2387e-03, 2.4692e-02, 1.1744e-03,
        1.2442e-04, 8.0392e-01, 1.1090e-04, 4.2668e-03, 6.4337e-03],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:08,933][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([6.2551e-03, 6.2277e-02, 4.5390e-03, 2.0680e-02, 4.0643e-01, 1.0233e-02,
        4.9324e-02, 9.1607e-05, 3.9600e-01, 4.0650e-02, 3.5240e-03],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:08,935][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([5.6965e-01, 2.0075e-01, 2.9882e-04, 1.8937e-02, 8.6295e-02, 8.1677e-03,
        1.1542e-02, 5.8473e-02, 1.7155e-02, 2.6124e-02, 2.6113e-03],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave]
[2024-07-24 10:29:08,936][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.2283, 0.0598, 0.0221, 0.0249, 0.0199, 0.0813, 0.2384, 0.0303, 0.1921,
        0.0187, 0.0398, 0.0444], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:08,937][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([1.8597e-02, 3.3811e-03, 2.2479e-06, 6.6567e-01, 4.5734e-05, 1.7027e-05,
        9.3151e-06, 1.1466e-03, 9.6780e-06, 3.1100e-01, 1.1589e-04, 5.4553e-06],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:08,939][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([1.3571e-03, 1.3340e-01, 4.7901e-04, 3.5718e-01, 7.4672e-03, 1.4704e-03,
        1.2743e-03, 2.9716e-01, 2.3688e-03, 1.9771e-01, 3.6825e-05, 9.2866e-05],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:08,940][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([4.8491e-02, 7.9750e-01, 5.4127e-04, 1.6573e-02, 5.8481e-03, 3.7539e-02,
        3.9296e-02, 2.2747e-03, 2.7479e-02, 1.8560e-02, 2.2879e-03, 3.6130e-03],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:08,941][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([2.8809e-04, 3.0224e-03, 2.1710e-03, 3.0983e-01, 9.5982e-03, 1.6984e-02,
        8.4712e-02, 3.4187e-03, 9.1336e-03, 4.3772e-01, 6.6242e-03, 1.1650e-01],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:08,942][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([3.5509e-02, 3.0740e-02, 3.5176e-04, 2.8098e-03, 5.4240e-01, 8.1724e-04,
        1.0024e-04, 3.4103e-01, 9.9077e-04, 2.4039e-03, 4.2655e-02, 1.9135e-04],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:08,944][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.2202, 0.1295, 0.0003, 0.2969, 0.0066, 0.0032, 0.0010, 0.1178, 0.0014,
        0.2186, 0.0040, 0.0005], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:08,946][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.4447, 0.0413, 0.0019, 0.2173, 0.0014, 0.0023, 0.0136, 0.0710, 0.0098,
        0.1759, 0.0025, 0.0184], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:08,948][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0167, 0.0415, 0.0162, 0.0297, 0.0221, 0.1712, 0.0913, 0.0062, 0.2288,
        0.0799, 0.1933, 0.1029], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:08,949][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([9.7817e-02, 2.2807e-01, 1.9847e-05, 1.0698e-02, 1.4295e-02, 4.3840e-04,
        1.9704e-05, 6.2536e-01, 7.1564e-05, 7.3295e-03, 1.5869e-02, 1.1535e-05],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:08,950][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([2.7429e-01, 1.5013e-01, 6.8319e-03, 1.4042e-02, 2.8356e-01, 3.4151e-03,
        8.1233e-03, 1.7082e-05, 2.3587e-01, 2.0201e-02, 4.2122e-04, 3.1070e-03],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:08,951][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([8.9057e-01, 9.1099e-02, 7.4995e-05, 3.2866e-04, 5.8531e-03, 1.4204e-03,
        4.1199e-04, 5.2910e-03, 2.5036e-03, 4.2750e-04, 1.4115e-03, 6.0771e-04],
       device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a]
[2024-07-24 10:29:08,952][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ ring] are: tensor([0.0496, 0.0210, 0.0093, 0.0141, 0.0326, 0.0437, 0.0415, 0.1111, 0.3326,
        0.0227, 0.0599, 0.0294, 0.2324], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:08,953][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ ring] are: tensor([1.6642e-01, 1.8201e-01, 1.8652e-04, 5.9343e-01, 1.4305e-03, 9.5953e-04,
        4.6587e-04, 7.3533e-03, 1.3373e-04, 4.6623e-02, 7.4271e-04, 1.2917e-04,
        1.1126e-04], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:08,954][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ ring] are: tensor([6.4632e-04, 8.8280e-01, 4.4589e-03, 6.9002e-02, 6.6034e-03, 2.1585e-03,
        1.3488e-03, 2.4192e-02, 1.9161e-03, 5.6328e-03, 7.7694e-05, 2.5279e-04,
        9.0986e-04], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:08,955][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ ring] are: tensor([0.0545, 0.3908, 0.0017, 0.0257, 0.0256, 0.1426, 0.1396, 0.0065, 0.0855,
        0.0384, 0.0063, 0.0815, 0.0013], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:08,956][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ ring] are: tensor([1.4630e-04, 1.3577e-02, 2.8439e-02, 9.3715e-02, 1.6338e-02, 9.8235e-02,
        3.1022e-01, 1.0203e-02, 5.5785e-02, 6.4099e-02, 1.3786e-02, 2.9320e-01,
        2.2550e-03], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:08,958][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ ring] are: tensor([0.0117, 0.7528, 0.0094, 0.0055, 0.1116, 0.0189, 0.0040, 0.0589, 0.0033,
        0.0010, 0.0188, 0.0012, 0.0028], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:08,960][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ ring] are: tensor([0.1203, 0.2740, 0.0066, 0.3340, 0.0362, 0.0529, 0.0090, 0.0688, 0.0028,
        0.0754, 0.0070, 0.0039, 0.0089], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:08,961][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ ring] are: tensor([0.1958, 0.5430, 0.0150, 0.1122, 0.0058, 0.0201, 0.0229, 0.0141, 0.0255,
        0.0153, 0.0028, 0.0257, 0.0017], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:08,963][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ ring] are: tensor([0.0082, 0.0491, 0.0140, 0.0141, 0.0130, 0.2280, 0.0684, 0.0455, 0.3191,
        0.0294, 0.1277, 0.0664, 0.0172], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:08,964][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ ring] are: tensor([1.0573e-02, 9.1766e-01, 2.6351e-05, 6.3742e-04, 2.5588e-02, 5.5770e-04,
        3.0581e-05, 2.9994e-02, 2.0873e-05, 1.4562e-04, 3.7102e-03, 1.3510e-05,
        1.1046e-02], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:08,965][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ ring] are: tensor([7.1820e-03, 1.1559e-02, 4.4095e-02, 1.6297e-02, 1.2188e-01, 1.1462e-02,
        4.8880e-02, 8.9573e-06, 7.1547e-01, 1.4658e-02, 2.0779e-04, 8.2493e-03,
        5.7296e-05], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:08,967][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ ring] are: tensor([8.6074e-01, 7.8444e-02, 1.4250e-03, 1.3758e-03, 2.8474e-02, 7.0415e-03,
        2.2704e-03, 5.0046e-03, 8.0331e-03, 6.8868e-04, 1.5164e-03, 3.2046e-03,
        1.7860e-03], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring]
[2024-07-24 10:29:08,968][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0777, 0.0675, 0.0316, 0.0191, 0.0199, 0.1204, 0.2064, 0.0271, 0.2624,
        0.0129, 0.0356, 0.0361, 0.0318, 0.0515], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:08,970][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([1.5503e-02, 2.0419e-02, 1.7950e-05, 5.9953e-01, 2.6737e-04, 1.8207e-04,
        2.0217e-04, 2.1960e-03, 6.2750e-05, 3.6078e-01, 2.8485e-04, 3.6643e-05,
        1.4038e-04, 3.7952e-04], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:08,971][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([3.8176e-04, 3.4032e-01, 1.1650e-03, 3.7474e-01, 2.9290e-02, 4.7932e-03,
        2.8931e-03, 9.8723e-02, 3.4543e-03, 1.2553e-01, 4.2400e-05, 2.3687e-04,
        1.4295e-02, 4.1311e-03], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:08,972][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([7.8525e-02, 7.3404e-01, 2.5936e-04, 9.2022e-03, 5.0558e-03, 2.9987e-02,
        3.1314e-02, 7.7967e-04, 5.6563e-02, 1.6380e-02, 2.9759e-03, 8.8003e-03,
        2.0358e-04, 2.5912e-02], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:08,973][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([8.6979e-05, 2.4300e-03, 1.1923e-03, 3.4778e-01, 1.0932e-02, 2.1017e-02,
        5.9520e-02, 1.8508e-03, 6.1014e-03, 4.5118e-01, 4.8516e-03, 7.4027e-02,
        1.0297e-03, 1.7993e-02], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:08,975][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0189, 0.1158, 0.0019, 0.0074, 0.5291, 0.0096, 0.0011, 0.2567, 0.0028,
        0.0050, 0.0323, 0.0009, 0.0078, 0.0106], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:08,977][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0528, 0.4001, 0.0011, 0.1576, 0.0212, 0.0184, 0.0035, 0.2295, 0.0035,
        0.0841, 0.0020, 0.0006, 0.0193, 0.0062], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:08,978][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.1100, 0.1365, 0.0059, 0.1415, 0.0030, 0.0192, 0.1579, 0.1442, 0.0315,
        0.1829, 0.0045, 0.0451, 0.0050, 0.0129], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:08,980][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0303, 0.0252, 0.0062, 0.0048, 0.0038, 0.1201, 0.0505, 0.0041, 0.2968,
        0.0153, 0.1388, 0.0405, 0.0012, 0.2624], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:08,982][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([8.6020e-02, 5.8436e-01, 7.2041e-05, 1.5151e-02, 4.1392e-02, 4.1585e-03,
        1.3277e-04, 2.2829e-01, 2.3510e-04, 7.0091e-03, 5.0587e-03, 2.7156e-05,
        2.5743e-02, 2.3572e-03], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:08,983][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([5.1569e-02, 7.0519e-02, 7.2658e-03, 4.9610e-03, 1.1855e-01, 1.0797e-02,
        1.2487e-02, 2.3744e-06, 6.9267e-01, 8.2142e-03, 3.2224e-04, 1.5104e-03,
        1.6565e-07, 2.1128e-02], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:08,984][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([7.1750e-01, 1.3781e-01, 1.9398e-04, 1.0167e-03, 9.4400e-03, 6.6082e-03,
        1.3949e-03, 1.4461e-02, 2.3208e-02, 2.0732e-03, 6.7139e-04, 9.2968e-04,
        7.1208e-02, 1.3485e-02], device='cuda:0') for source tokens [After Amanda and John went to the station, John gave a ring to]
[2024-07-24 10:29:08,987][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:29:08,989][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[2348],
        [   1],
        [  22],
        [  71],
        [  25],
        [   9],
        [  24],
        [ 123],
        [   3],
        [  93],
        [  50],
        [  88],
        [  26],
        [   1]], device='cuda:0')
[2024-07-24 10:29:08,991][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[2476],
        [   2],
        [  39],
        [  96],
        [  61],
        [  38],
        [  76],
        [ 144],
        [  14],
        [ 124],
        [ 139],
        [ 103],
        [  35],
        [   6]], device='cuda:0')
[2024-07-24 10:29:08,992][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[14603],
        [ 1759],
        [ 5094],
        [ 6623],
        [ 4465],
        [ 8746],
        [ 7959],
        [ 6931],
        [ 9363],
        [ 7927],
        [ 9389],
        [10720],
        [11374],
        [11492]], device='cuda:0')
[2024-07-24 10:29:08,994][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[ 3720],
        [50254],
        [50253],
        [50234],
        [50240],
        [43562],
        [38446],
        [50243],
        [45172],
        [48536],
        [33716],
        [33624],
        [48694],
        [34732]], device='cuda:0')
[2024-07-24 10:29:08,995][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 3847],
        [49971],
        [49680],
        [48623],
        [35206],
        [32688],
        [22922],
        [33992],
        [15134],
        [20114],
        [26669],
        [12594],
        [13016],
        [ 6811]], device='cuda:0')
[2024-07-24 10:29:08,997][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[44080],
        [50226],
        [50226],
        [50220],
        [50221],
        [50220],
        [50223],
        [50195],
        [50224],
        [49813],
        [49804],
        [50159],
        [49305],
        [50114]], device='cuda:0')
[2024-07-24 10:29:08,999][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[23908],
        [ 8042],
        [23428],
        [22429],
        [22785],
        [23328],
        [27284],
        [38030],
        [36404],
        [25755],
        [28108],
        [27940],
        [36954],
        [27109]], device='cuda:0')
[2024-07-24 10:29:09,000][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[16867],
        [ 3735],
        [ 3953],
        [ 4958],
        [ 3574],
        [ 3538],
        [ 4115],
        [ 4714],
        [ 4570],
        [ 4754],
        [ 4156],
        [ 3978],
        [ 4113],
        [ 3806]], device='cuda:0')
[2024-07-24 10:29:09,002][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[ 9451],
        [   19],
        [   27],
        [  108],
        [  815],
        [  132],
        [   58],
        [  454],
        [ 1899],
        [ 4044],
        [ 7367],
        [15190],
        [  122],
        [  253]], device='cuda:0')
[2024-07-24 10:29:09,004][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[43002],
        [21802],
        [13196],
        [31862],
        [15112],
        [12937],
        [31555],
        [12852],
        [23328],
        [35753],
        [28043],
        [23149],
        [15332],
        [25063]], device='cuda:0')
[2024-07-24 10:29:09,005][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[11623],
        [ 3617],
        [ 4998],
        [ 5532],
        [ 4849],
        [ 6964],
        [ 8118],
        [ 7488],
        [ 8193],
        [ 8264],
        [ 6113],
        [ 7823],
        [ 7509],
        [ 7768]], device='cuda:0')
[2024-07-24 10:29:09,007][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[ 5831],
        [20923],
        [20190],
        [19366],
        [20103],
        [17757],
        [16871],
        [19229],
        [18954],
        [17347],
        [19531],
        [19093],
        [20117],
        [17434]], device='cuda:0')
[2024-07-24 10:29:09,008][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[37513],
        [    1],
        [    2],
        [ 3579],
        [46896],
        [  111],
        [  134],
        [15618],
        [   30],
        [32687],
        [45935],
        [24853],
        [47978],
        [44813]], device='cuda:0')
[2024-07-24 10:29:09,010][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[1940],
        [9132],
        [8424],
        [3643],
        [3963],
        [3670],
        [3545],
        [3976],
        [3797],
        [3563],
        [3601],
        [3516],
        [3542],
        [3457]], device='cuda:0')
[2024-07-24 10:29:09,012][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[19230],
        [19847],
        [13311],
        [10170],
        [15175],
        [15588],
        [ 7112],
        [13383],
        [11438],
        [13463],
        [15212],
        [19254],
        [17264],
        [17746]], device='cuda:0')
[2024-07-24 10:29:09,014][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[20134],
        [22950],
        [26020],
        [26666],
        [30340],
        [27701],
        [24897],
        [29253],
        [26386],
        [30005],
        [31616],
        [26114],
        [31210],
        [26613]], device='cuda:0')
[2024-07-24 10:29:09,015][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[21282],
        [12467],
        [12472],
        [10525],
        [10145],
        [11830],
        [13723],
        [10375],
        [11355],
        [10578],
        [14870],
        [15079],
        [11019],
        [14716]], device='cuda:0')
[2024-07-24 10:29:09,017][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[33452],
        [14104],
        [10092],
        [10059],
        [11986],
        [18294],
        [13281],
        [10581],
        [21655],
        [11781],
        [26721],
        [32486],
        [11472],
        [24995]], device='cuda:0')
[2024-07-24 10:29:09,018][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[19687],
        [ 8518],
        [ 8520],
        [ 8672],
        [ 8724],
        [ 8752],
        [ 8583],
        [ 9157],
        [ 8559],
        [ 9376],
        [ 9174],
        [ 9097],
        [ 9675],
        [ 9223]], device='cuda:0')
[2024-07-24 10:29:09,019][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[17149],
        [11048],
        [14644],
        [14244],
        [15073],
        [14553],
        [16217],
        [17798],
        [19798],
        [14993],
        [16765],
        [17035],
        [21111],
        [15964]], device='cuda:0')
[2024-07-24 10:29:09,021][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[2779],
        [3995],
        [3530],
        [3666],
        [1568],
        [2535],
        [2051],
        [2210],
        [2129],
        [ 826],
        [ 843],
        [1438],
        [2129],
        [1231]], device='cuda:0')
[2024-07-24 10:29:09,022][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[ 8981],
        [26386],
        [26625],
        [25951],
        [25562],
        [26702],
        [21373],
        [26328],
        [18497],
        [13908],
        [13893],
        [21524],
        [24431],
        [18856]], device='cuda:0')
[2024-07-24 10:29:09,024][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[27589],
        [13102],
        [12249],
        [17698],
        [ 9071],
        [10277],
        [18342],
        [11955],
        [16703],
        [20607],
        [23095],
        [12507],
        [11907],
        [15531]], device='cuda:0')
[2024-07-24 10:29:09,026][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[21416],
        [22230],
        [26196],
        [21800],
        [22130],
        [27458],
        [27539],
        [23674],
        [25049],
        [21529],
        [21881],
        [21730],
        [22378],
        [18766]], device='cuda:0')
[2024-07-24 10:29:09,027][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[ 7563],
        [15723],
        [15729],
        [15748],
        [17192],
        [19696],
        [18204],
        [16331],
        [17871],
        [16100],
        [ 9328],
        [10660],
        [16274],
        [17438]], device='cuda:0')
[2024-07-24 10:29:09,029][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[ 7323],
        [34374],
        [33354],
        [18888],
        [22550],
        [32760],
        [20815],
        [23704],
        [32060],
        [23554],
        [19105],
        [20471],
        [16341],
        [17003]], device='cuda:0')
[2024-07-24 10:29:09,031][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[7728],
        [8178],
        [8115],
        [8601],
        [9111],
        [8530],
        [8438],
        [8234],
        [8334],
        [9381],
        [9497],
        [8697],
        [9266],
        [7500]], device='cuda:0')
[2024-07-24 10:29:09,032][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[31277],
        [29667],
        [32222],
        [33365],
        [34867],
        [29498],
        [31643],
        [33180],
        [29075],
        [34822],
        [31543],
        [30922],
        [34570],
        [31284]], device='cuda:0')
[2024-07-24 10:29:09,034][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[25989],
        [19952],
        [11348],
        [29345],
        [21095],
        [18669],
        [23371],
        [28385],
        [24313],
        [27635],
        [15898],
        [21189],
        [22740],
        [19015]], device='cuda:0')
[2024-07-24 10:29:09,036][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[17268],
        [17268],
        [17268],
        [17268],
        [17268],
        [17268],
        [17268],
        [17268],
        [17268],
        [17268],
        [17268],
        [17268],
        [17268],
        [17268]], device='cuda:0')
