[2024-07-24 10:20:06,627][explain_satisfiability.py][line:287][INFO] ############ CASE TEXT isAfter Benjamin and Alexander went to the station, Benjamin gave a computer to
[2024-07-24 10:20:06,627][explain_satisfiability.py][line:288][INFO] ############ CASE Prediction is  Alexander
[2024-07-24 10:20:06,627][explain_satisfiability.py][line:289][INFO] ############ Refined Forward Graph
[2024-07-24 10:20:06,627][explain_satisfiability.py][line:290][INFO] ****** Layer 1
[2024-07-24 10:20:06,628][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 0
[2024-07-24 10:20:06,628][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,628][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 1
[2024-07-24 10:20:06,628][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit24']
[2024-07-24 10:20:06,628][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 2
[2024-07-24 10:20:06,628][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:20:06,628][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 3
[2024-07-24 10:20:06,628][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,628][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 4
[2024-07-24 10:20:06,628][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit3', 'circuit6', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:06,628][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 5
[2024-07-24 10:20:06,628][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit2', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:06,628][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 6
[2024-07-24 10:20:06,628][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit4', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:06,629][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 7
[2024-07-24 10:20:06,629][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:06,629][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 8
[2024-07-24 10:20:06,629][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit5', 'circuit8', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:06,629][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 9
[2024-07-24 10:20:06,629][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit2', 'circuit12', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:20:06,629][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 10
[2024-07-24 10:20:06,629][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:06,629][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 11
[2024-07-24 10:20:06,629][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit4', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:20:06,629][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 12
[2024-07-24 10:20:06,629][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit6', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,629][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 13
[2024-07-24 10:20:06,629][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit3', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,629][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 14
[2024-07-24 10:20:06,629][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:06,630][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 15
[2024-07-24 10:20:06,630][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:06,630][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 16
[2024-07-24 10:20:06,630][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit24', 'circuit26']
[2024-07-24 10:20:06,630][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 17
[2024-07-24 10:20:06,630][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit27']
[2024-07-24 10:20:06,630][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 18
[2024-07-24 10:20:06,630][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:06,630][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 19
[2024-07-24 10:20:06,630][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:06,630][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 20
[2024-07-24 10:20:06,630][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit26']
[2024-07-24 10:20:06,630][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 21
[2024-07-24 10:20:06,630][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:06,630][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 22
[2024-07-24 10:20:06,630][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,631][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 23
[2024-07-24 10:20:06,631][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit13', 'circuit14', 'circuit15', 'circuit21', 'circuit22', 'circuit23', 'circuit26', 'circuit27']
[2024-07-24 10:20:06,631][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 24
[2024-07-24 10:20:06,631][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:06,631][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 25
[2024-07-24 10:20:06,631][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit6', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:06,631][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 26
[2024-07-24 10:20:06,631][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,631][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 27
[2024-07-24 10:20:06,631][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,631][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 28
[2024-07-24 10:20:06,631][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,631][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 0
[2024-07-24 10:20:06,631][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit5', 'circuit6', 'circuit7', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,631][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,631][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 1
[2024-07-24 10:20:06,631][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:06,632][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit21', 'circuit24']
[2024-07-24 10:20:06,632][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 2
[2024-07-24 10:20:06,632][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:20:06,632][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit2', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:20:06,632][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 3
[2024-07-24 10:20:06,632][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit18', 'circuit21', 'circuit22']
[2024-07-24 10:20:06,632][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,632][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 4
[2024-07-24 10:20:06,632][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:20:06,632][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,632][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 5
[2024-07-24 10:20:06,632][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit24', 'circuit27']
[2024-07-24 10:20:06,632][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,632][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 6
[2024-07-24 10:20:06,632][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:06,632][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,633][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 7
[2024-07-24 10:20:06,633][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:20:06,633][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit21', 'circuit25']
[2024-07-24 10:20:06,633][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 8
[2024-07-24 10:20:06,633][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:20:06,633][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit22']
[2024-07-24 10:20:06,633][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 9
[2024-07-24 10:20:06,633][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:06,633][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21']
[2024-07-24 10:20:06,633][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 10
[2024-07-24 10:20:06,633][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit8', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,633][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:20:06,633][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 11
[2024-07-24 10:20:06,633][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit4', 'circuit6', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,633][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:06,633][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 12
[2024-07-24 10:20:06,634][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit13', 'circuit27']
[2024-07-24 10:20:06,634][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,634][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 13
[2024-07-24 10:20:06,634][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit6', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,634][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,634][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 14
[2024-07-24 10:20:06,634][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit6', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:20:06,634][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit19', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:20:06,634][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 15
[2024-07-24 10:20:06,634][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:20:06,634][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit20', 'circuit27']
[2024-07-24 10:20:06,634][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 16
[2024-07-24 10:20:06,634][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,634][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit20']
[2024-07-24 10:20:06,634][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 17
[2024-07-24 10:20:06,634][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit22']
[2024-07-24 10:20:06,635][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit16']
[2024-07-24 10:20:06,635][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 18
[2024-07-24 10:20:06,635][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17']
[2024-07-24 10:20:06,635][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,635][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 19
[2024-07-24 10:20:06,635][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:06,635][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:20:06,635][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 20
[2024-07-24 10:20:06,635][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit20', 'circuit21', 'circuit27']
[2024-07-24 10:20:06,635][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,635][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 21
[2024-07-24 10:20:06,635][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:20:06,635][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,635][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 22
[2024-07-24 10:20:06,635][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:20:06,635][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,635][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 23
[2024-07-24 10:20:06,636][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit18', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:20:06,636][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,636][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 24
[2024-07-24 10:20:06,636][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit24', 'circuit27']
[2024-07-24 10:20:06,636][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit22']
[2024-07-24 10:20:06,636][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 25
[2024-07-24 10:20:06,636][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,636][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,636][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 26
[2024-07-24 10:20:06,636][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,636][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,636][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 27
[2024-07-24 10:20:06,636][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,636][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,636][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 28
[2024-07-24 10:20:06,636][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,637][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,637][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 0
[2024-07-24 10:20:06,637][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,637][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,637][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit4', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,637][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 1
[2024-07-24 10:20:06,637][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,637][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit6', 'circuit7', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit26', 'circuit28']
[2024-07-24 10:20:06,637][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,637][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 2
[2024-07-24 10:20:06,637][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit27']
[2024-07-24 10:20:06,637][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,637][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:06,637][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 3
[2024-07-24 10:20:06,637][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:20:06,637][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,638][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,638][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 4
[2024-07-24 10:20:06,638][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit22']
[2024-07-24 10:20:06,638][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,638][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,638][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 5
[2024-07-24 10:20:06,638][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:20:06,638][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15']
[2024-07-24 10:20:06,638][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit23']
[2024-07-24 10:20:06,638][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 6
[2024-07-24 10:20:06,638][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:20:06,638][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit21', 'circuit26']
[2024-07-24 10:20:06,638][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit18']
[2024-07-24 10:20:06,638][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 7
[2024-07-24 10:20:06,638][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,638][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit27']
[2024-07-24 10:20:06,639][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit19', 'circuit20', 'circuit23']
[2024-07-24 10:20:06,639][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 8
[2024-07-24 10:20:06,639][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit27']
[2024-07-24 10:20:06,639][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,639][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,639][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 9
[2024-07-24 10:20:06,639][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit17', 'circuit18', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:20:06,639][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit19', 'circuit21', 'circuit23', 'circuit24']
[2024-07-24 10:20:06,639][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:06,639][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 10
[2024-07-24 10:20:06,639][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:20:06,639][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:20:06,639][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,639][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 11
[2024-07-24 10:20:06,639][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit22', 'circuit23', 'circuit26', 'circuit27']
[2024-07-24 10:20:06,639][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit1', 'circuit7', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:20:06,640][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:06,640][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 12
[2024-07-24 10:20:06,640][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,640][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit27']
[2024-07-24 10:20:06,640][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,640][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 13
[2024-07-24 10:20:06,640][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit3', 'circuit5', 'circuit6', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,640][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:06,640][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit4', 'circuit6', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:06,640][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 14
[2024-07-24 10:20:06,640][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit17', 'circuit19', 'circuit20', 'circuit23', 'circuit25']
[2024-07-24 10:20:06,640][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,640][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:06,640][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 15
[2024-07-24 10:20:06,640][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,640][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,640][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit4', 'circuit10', 'circuit12', 'circuit14', 'circuit26']
[2024-07-24 10:20:06,641][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 16
[2024-07-24 10:20:06,641][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:20:06,641][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit21']
[2024-07-24 10:20:06,641][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit23']
[2024-07-24 10:20:06,641][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 17
[2024-07-24 10:20:06,641][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit16', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:20:06,641][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,641][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,641][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 18
[2024-07-24 10:20:06,641][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,641][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit1', 'circuit5', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:06,641][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit5', 'circuit6', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:06,641][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 19
[2024-07-24 10:20:06,641][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:06,641][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit20']
[2024-07-24 10:20:06,641][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit18', 'circuit23']
[2024-07-24 10:20:06,642][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 20
[2024-07-24 10:20:06,642][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit17', 'circuit21', 'circuit22', 'circuit24', 'circuit27']
[2024-07-24 10:20:06,642][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,642][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19']
[2024-07-24 10:20:06,642][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 21
[2024-07-24 10:20:06,642][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:20:06,642][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13', 'circuit18']
[2024-07-24 10:20:06,642][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13']
[2024-07-24 10:20:06,642][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 22
[2024-07-24 10:20:06,642][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:20:06,642][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit21']
[2024-07-24 10:20:06,642][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:06,642][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 23
[2024-07-24 10:20:06,642][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,642][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,642][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14']
[2024-07-24 10:20:06,643][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 24
[2024-07-24 10:20:06,643][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit27']
[2024-07-24 10:20:06,643][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,643][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14']
[2024-07-24 10:20:06,643][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 25
[2024-07-24 10:20:06,643][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit22']
[2024-07-24 10:20:06,643][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit6', 'circuit7', 'circuit13']
[2024-07-24 10:20:06,643][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit24', 'circuit25']
[2024-07-24 10:20:06,643][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 26
[2024-07-24 10:20:06,643][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,643][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,643][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,643][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 27
[2024-07-24 10:20:06,643][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,643][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,643][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,643][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 28
[2024-07-24 10:20:06,644][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,644][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,644][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,644][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 0
[2024-07-24 10:20:06,644][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,644][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit4', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:06,644][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit5', 'circuit6', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:06,644][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit4', 'circuit5', 'circuit6', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,644][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 1
[2024-07-24 10:20:06,644][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:06,644][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit17', 'circuit20', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:20:06,644][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:06,644][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:06,644][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 2
[2024-07-24 10:20:06,644][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:06,644][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit8', 'circuit10', 'circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:06,645][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit24']
[2024-07-24 10:20:06,645][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:06,645][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 3
[2024-07-24 10:20:06,645][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:06,645][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit1', 'circuit4', 'circuit5', 'circuit8', 'circuit10', 'circuit12', 'circuit14', 'circuit15', 'circuit17', 'circuit25', 'circuit27']
[2024-07-24 10:20:06,645][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0']
[2024-07-24 10:20:06,645][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit20', 'circuit25']
[2024-07-24 10:20:06,645][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 4
[2024-07-24 10:20:06,645][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit27']
[2024-07-24 10:20:06,645][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,645][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,645][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,645][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 5
[2024-07-24 10:20:06,645][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:20:06,645][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit21', 'circuit25']
[2024-07-24 10:20:06,645][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:06,646][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:20:06,646][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 6
[2024-07-24 10:20:06,646][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit20']
[2024-07-24 10:20:06,646][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,646][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,646][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,646][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 7
[2024-07-24 10:20:06,646][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:20:06,646][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,646][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17']
[2024-07-24 10:20:06,646][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit25']
[2024-07-24 10:20:06,646][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 8
[2024-07-24 10:20:06,646][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:06,646][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,646][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:06,646][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit15']
[2024-07-24 10:20:06,647][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 9
[2024-07-24 10:20:06,647][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:20:06,647][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13', 'circuit19', 'circuit20', 'circuit24']
[2024-07-24 10:20:06,647][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:20:06,647][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit22', 'circuit24']
[2024-07-24 10:20:06,647][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 10
[2024-07-24 10:20:06,647][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:20:06,647][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,647][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16']
[2024-07-24 10:20:06,647][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit19', 'circuit20']
[2024-07-24 10:20:06,647][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 11
[2024-07-24 10:20:06,647][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:06,647][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit21', 'circuit24', 'circuit25']
[2024-07-24 10:20:06,647][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,647][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit15', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:20:06,647][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 12
[2024-07-24 10:20:06,648][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:06,648][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,648][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,648][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,648][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 13
[2024-07-24 10:20:06,648][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,648][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit7', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:06,648][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit5', 'circuit7', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:06,648][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit5', 'circuit6', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:06,648][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 14
[2024-07-24 10:20:06,648][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit20', 'circuit22']
[2024-07-24 10:20:06,648][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,648][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,648][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,648][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 15
[2024-07-24 10:20:06,648][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,649][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,649][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,649][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,649][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 16
[2024-07-24 10:20:06,649][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit21']
[2024-07-24 10:20:06,649][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,649][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,649][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,649][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 17
[2024-07-24 10:20:06,649][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,649][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,649][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,649][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit18']
[2024-07-24 10:20:06,649][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 18
[2024-07-24 10:20:06,649][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit27']
[2024-07-24 10:20:06,649][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,650][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,650][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,650][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 19
[2024-07-24 10:20:06,650][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,650][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,650][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,650][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,650][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 20
[2024-07-24 10:20:06,650][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:20:06,650][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit20']
[2024-07-24 10:20:06,650][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit17', 'circuit23', 'circuit24']
[2024-07-24 10:20:06,650][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:06,650][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 21
[2024-07-24 10:20:06,650][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit7', 'circuit8', 'circuit10', 'circuit27']
[2024-07-24 10:20:06,650][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:20:06,650][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit20', 'circuit22', 'circuit23']
[2024-07-24 10:20:06,650][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,651][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 22
[2024-07-24 10:20:06,651][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,651][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,651][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit5', 'circuit6', 'circuit26']
[2024-07-24 10:20:06,651][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,651][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 23
[2024-07-24 10:20:06,651][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:20:06,651][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,651][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,651][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,651][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 24
[2024-07-24 10:20:06,651][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:06,651][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,651][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,651][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,651][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 25
[2024-07-24 10:20:06,652][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,652][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,652][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,652][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,652][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 26
[2024-07-24 10:20:06,652][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,652][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,652][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,652][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,652][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 27
[2024-07-24 10:20:06,652][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,652][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,652][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,652][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,652][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 28
[2024-07-24 10:20:06,652][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,653][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,653][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,653][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,653][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 0
[2024-07-24 10:20:06,653][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit4', 'circuit6', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,653][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,653][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit6', 'circuit7', 'circuit8', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:06,653][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit5', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,653][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit5', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:06,653][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 1
[2024-07-24 10:20:06,653][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,653][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit8', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:06,653][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit4', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:06,653][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:06,653][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit2', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:20:06,653][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 2
[2024-07-24 10:20:06,654][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:20:06,654][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:06,654][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:06,654][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit5', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:06,654][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,654][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 3
[2024-07-24 10:20:06,654][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit20', 'circuit21', 'circuit23']
[2024-07-24 10:20:06,654][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15']
[2024-07-24 10:20:06,654][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit24']
[2024-07-24 10:20:06,654][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit23', 'circuit25']
[2024-07-24 10:20:06,654][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit15']
[2024-07-24 10:20:06,654][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 4
[2024-07-24 10:20:06,654][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,654][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16']
[2024-07-24 10:20:06,654][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit11', 'circuit13', 'circuit14']
[2024-07-24 10:20:06,654][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit15', 'circuit26']
[2024-07-24 10:20:06,655][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,655][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 5
[2024-07-24 10:20:06,655][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit21', 'circuit24']
[2024-07-24 10:20:06,655][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,655][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,655][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,655][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,655][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 6
[2024-07-24 10:20:06,655][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit21', 'circuit24']
[2024-07-24 10:20:06,655][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,655][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit24']
[2024-07-24 10:20:06,655][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,655][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,655][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 7
[2024-07-24 10:20:06,655][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,655][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,656][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,656][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,656][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,656][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 8
[2024-07-24 10:20:06,656][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,656][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,656][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,656][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,656][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,656][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 9
[2024-07-24 10:20:06,656][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:20:06,656][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16']
[2024-07-24 10:20:06,656][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,656][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,656][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,656][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 10
[2024-07-24 10:20:06,657][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit22', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:06,657][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit20', 'circuit21', 'circuit23']
[2024-07-24 10:20:06,657][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:06,657][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,657][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit23', 'circuit24']
[2024-07-24 10:20:06,657][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 11
[2024-07-24 10:20:06,657][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit19', 'circuit20']
[2024-07-24 10:20:06,657][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit20']
[2024-07-24 10:20:06,657][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,657][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,657][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,657][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 12
[2024-07-24 10:20:06,657][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,657][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15']
[2024-07-24 10:20:06,657][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,657][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,658][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,658][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 13
[2024-07-24 10:20:06,658][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,658][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:20:06,658][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:06,658][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit3', 'circuit7', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:06,658][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:06,658][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 14
[2024-07-24 10:20:06,658][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit27']
[2024-07-24 10:20:06,658][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit19', 'circuit21', 'circuit24']
[2024-07-24 10:20:06,658][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit22']
[2024-07-24 10:20:06,658][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:06,658][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:20:06,658][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 15
[2024-07-24 10:20:06,658][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:20:06,658][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,659][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19']
[2024-07-24 10:20:06,659][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,659][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,659][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 16
[2024-07-24 10:20:06,659][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,659][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,659][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,659][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,659][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit13']
[2024-07-24 10:20:06,659][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 17
[2024-07-24 10:20:06,659][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,659][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,659][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14']
[2024-07-24 10:20:06,659][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,659][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,659][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 18
[2024-07-24 10:20:06,659][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,660][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,660][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,660][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,660][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,660][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 19
[2024-07-24 10:20:06,660][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,660][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,660][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,660][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,660][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,660][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 20
[2024-07-24 10:20:06,660][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,660][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,660][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,660][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,660][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,661][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 21
[2024-07-24 10:20:06,661][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,661][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,661][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,661][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,661][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,661][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 22
[2024-07-24 10:20:06,661][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,661][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,661][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,661][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,661][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,661][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 23
[2024-07-24 10:20:06,661][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,661][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,661][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,662][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,662][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,662][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 24
[2024-07-24 10:20:06,662][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,662][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,662][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,662][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,662][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,662][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 25
[2024-07-24 10:20:06,662][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,662][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,662][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,662][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,662][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,662][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 26
[2024-07-24 10:20:06,662][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,662][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,663][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,663][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,663][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,663][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 27
[2024-07-24 10:20:06,663][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,663][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,663][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,663][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,663][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,663][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 28
[2024-07-24 10:20:06,663][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,663][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,663][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,663][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,663][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,664][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 0
[2024-07-24 10:20:06,664][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,664][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:06,664][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:06,664][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:06,664][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit3', 'circuit5', 'circuit7', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:06,664][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit4', 'circuit6', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,664][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 1
[2024-07-24 10:20:06,664][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit15', 'circuit17', 'circuit21']
[2024-07-24 10:20:06,664][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,664][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:06,664][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit20', 'circuit21', 'circuit24']
[2024-07-24 10:20:06,664][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit23']
[2024-07-24 10:20:06,664][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,664][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 2
[2024-07-24 10:20:06,664][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:20:06,665][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,665][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,665][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,665][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,665][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:20:06,665][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 3
[2024-07-24 10:20:06,665][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:06,665][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:20:06,665][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit26']
[2024-07-24 10:20:06,665][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,665][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit27']
[2024-07-24 10:20:06,665][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit18', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:06,665][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 4
[2024-07-24 10:20:06,665][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit19', 'circuit21', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:06,665][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit4', 'circuit12']
[2024-07-24 10:20:06,665][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:06,666][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:20:06,666][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit22', 'circuit23']
[2024-07-24 10:20:06,666][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,666][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 5
[2024-07-24 10:20:06,666][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit20']
[2024-07-24 10:20:06,666][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit17', 'circuit18', 'circuit24']
[2024-07-24 10:20:06,666][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,666][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit15']
[2024-07-24 10:20:06,666][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit16', 'circuit18']
[2024-07-24 10:20:06,666][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,666][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 6
[2024-07-24 10:20:06,666][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:20:06,666][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15']
[2024-07-24 10:20:06,666][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:20:06,666][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,666][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit21', 'circuit23', 'circuit24']
[2024-07-24 10:20:06,667][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,667][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 7
[2024-07-24 10:20:06,667][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,667][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit8', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:20:06,667][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit17']
[2024-07-24 10:20:06,667][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:06,667][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit10', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:06,667][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:20:06,667][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 8
[2024-07-24 10:20:06,667][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:20:06,667][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,667][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,667][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,667][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,667][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,667][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 9
[2024-07-24 10:20:06,667][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,668][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,668][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,668][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,668][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,668][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,668][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 10
[2024-07-24 10:20:06,668][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,668][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,668][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,668][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,668][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit26']
[2024-07-24 10:20:06,668][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,668][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 11
[2024-07-24 10:20:06,668][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,668][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit13', 'circuit14', 'circuit16', 'circuit20', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:20:06,668][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit26', 'circuit27']
[2024-07-24 10:20:06,669][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:06,669][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:20:06,669][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:20:06,669][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 12
[2024-07-24 10:20:06,669][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit24', 'circuit25']
[2024-07-24 10:20:06,669][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,669][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14']
[2024-07-24 10:20:06,669][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit15', 'circuit21', 'circuit24']
[2024-07-24 10:20:06,669][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:20:06,669][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,669][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 13
[2024-07-24 10:20:06,669][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:06,669][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit3', 'circuit4', 'circuit6', 'circuit7', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,669][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:06,669][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:06,669][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,670][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit6', 'circuit10', 'circuit12', 'circuit13', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:20:06,670][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 14
[2024-07-24 10:20:06,670][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit23']
[2024-07-24 10:20:06,670][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,670][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,670][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,670][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,670][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,670][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 15
[2024-07-24 10:20:06,670][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit20', 'circuit21']
[2024-07-24 10:20:06,670][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,670][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,670][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,670][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,670][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,670][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 16
[2024-07-24 10:20:06,671][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:20:06,671][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit20']
[2024-07-24 10:20:06,671][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,671][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19']
[2024-07-24 10:20:06,671][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,671][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,671][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 17
[2024-07-24 10:20:06,671][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,671][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit10', 'circuit27']
[2024-07-24 10:20:06,671][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,671][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,671][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,671][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,671][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 18
[2024-07-24 10:20:06,671][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,671][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15']
[2024-07-24 10:20:06,672][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,672][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,672][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,672][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,672][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 19
[2024-07-24 10:20:06,672][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit22']
[2024-07-24 10:20:06,672][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit5', 'circuit13', 'circuit24']
[2024-07-24 10:20:06,672][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,672][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit19', 'circuit20', 'circuit24']
[2024-07-24 10:20:06,672][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit16', 'circuit18', 'circuit19', 'circuit22', 'circuit23']
[2024-07-24 10:20:06,672][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,672][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 20
[2024-07-24 10:20:06,672][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit20', 'circuit22', 'circuit23']
[2024-07-24 10:20:06,672][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,672][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,672][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14']
[2024-07-24 10:20:06,673][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,673][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,673][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 21
[2024-07-24 10:20:06,673][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit28']
[2024-07-24 10:20:06,673][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit9', 'circuit10', 'circuit14', 'circuit15', 'circuit16']
[2024-07-24 10:20:06,673][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,673][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,673][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,673][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,673][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 22
[2024-07-24 10:20:06,673][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,673][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,673][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,673][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:06,673][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,673][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,673][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 23
[2024-07-24 10:20:06,674][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,674][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,674][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,674][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,674][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,674][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,674][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 24
[2024-07-24 10:20:06,674][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit20']
[2024-07-24 10:20:06,674][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,674][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,674][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,674][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,674][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,674][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 25
[2024-07-24 10:20:06,674][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,674][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,675][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,675][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,675][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,675][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,675][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 26
[2024-07-24 10:20:06,675][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,675][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,675][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,675][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,675][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,675][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,675][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 27
[2024-07-24 10:20:06,675][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,675][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,675][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,675][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,676][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,676][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,676][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 28
[2024-07-24 10:20:06,676][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,676][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,676][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,676][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,676][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,676][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,676][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 0
[2024-07-24 10:20:06,676][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,676][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,676][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:06,676][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:06,676][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit2', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:06,677][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:20:06,677][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit2', 'circuit7', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:06,677][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 1
[2024-07-24 10:20:06,677][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit13', 'circuit14', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:06,677][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:20:06,677][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,677][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,677][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,677][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21']
[2024-07-24 10:20:06,677][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:06,677][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 2
[2024-07-24 10:20:06,677][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit4', 'circuit7', 'circuit8', 'circuit9', 'circuit22']
[2024-07-24 10:20:06,677][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,677][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,677][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,677][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,678][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,678][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,678][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 3
[2024-07-24 10:20:06,678][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,678][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,678][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,678][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,678][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,678][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,678][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,678][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 4
[2024-07-24 10:20:06,678][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit17', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:06,678][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,678][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit24', 'circuit25']
[2024-07-24 10:20:06,678][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:06,678][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,678][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit21', 'circuit23']
[2024-07-24 10:20:06,679][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,679][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 5
[2024-07-24 10:20:06,679][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,679][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15']
[2024-07-24 10:20:06,679][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,679][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,679][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit18', 'circuit19']
[2024-07-24 10:20:06,679][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,679][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,679][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 6
[2024-07-24 10:20:06,679][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit18', 'circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:20:06,679][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,679][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,679][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,679][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,679][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,680][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,680][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 7
[2024-07-24 10:20:06,680][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:20:06,680][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit25']
[2024-07-24 10:20:06,680][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,680][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:06,680][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit18', 'circuit22']
[2024-07-24 10:20:06,680][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,680][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,680][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 8
[2024-07-24 10:20:06,680][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit28']
[2024-07-24 10:20:06,680][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit13', 'circuit14', 'circuit15', 'circuit24']
[2024-07-24 10:20:06,680][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:06,680][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit20', 'circuit25']
[2024-07-24 10:20:06,680][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit19', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:20:06,680][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,681][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,681][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 9
[2024-07-24 10:20:06,681][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,681][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,681][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,681][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,681][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,681][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,681][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,681][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 10
[2024-07-24 10:20:06,681][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit22']
[2024-07-24 10:20:06,681][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,681][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,681][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,681][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,681][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,682][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,682][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 11
[2024-07-24 10:20:06,682][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,682][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15']
[2024-07-24 10:20:06,682][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,682][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit20']
[2024-07-24 10:20:06,682][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,682][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit23']
[2024-07-24 10:20:06,682][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,682][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 12
[2024-07-24 10:20:06,682][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16']
[2024-07-24 10:20:06,682][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,682][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,682][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit17']
[2024-07-24 10:20:06,682][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,682][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,682][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,683][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 13
[2024-07-24 10:20:06,683][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:06,683][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit16', 'circuit20', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:20:06,683][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21']
[2024-07-24 10:20:06,683][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit15', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:06,683][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:06,683][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:20:06,683][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:20:06,683][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 14
[2024-07-24 10:20:06,683][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,683][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,683][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,683][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,683][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,683][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,683][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,684][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 15
[2024-07-24 10:20:06,684][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,684][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,684][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,684][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,684][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,684][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,684][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,684][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 16
[2024-07-24 10:20:06,684][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,684][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,684][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,684][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,684][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,684][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,684][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,685][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 17
[2024-07-24 10:20:06,685][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,685][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,685][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,685][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,685][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,685][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,685][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,685][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 18
[2024-07-24 10:20:06,685][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,685][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,685][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,685][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,685][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,685][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,685][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,686][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 19
[2024-07-24 10:20:06,686][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,686][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,686][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,686][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,686][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,686][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,686][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,686][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 20
[2024-07-24 10:20:06,686][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,686][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,686][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,686][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,686][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,686][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,686][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,686][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 21
[2024-07-24 10:20:06,687][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,687][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,687][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,687][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,687][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,687][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,687][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,687][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 22
[2024-07-24 10:20:06,687][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,687][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,687][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,687][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,687][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,687][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,687][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,687][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 23
[2024-07-24 10:20:06,688][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,688][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,688][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,688][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,688][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,688][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,688][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,688][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 24
[2024-07-24 10:20:06,688][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,688][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,688][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,688][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,688][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,688][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,688][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,688][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 25
[2024-07-24 10:20:06,689][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,689][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,689][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,689][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,689][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,689][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,689][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,689][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 26
[2024-07-24 10:20:06,689][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,689][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,689][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,689][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,689][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,689][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,689][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,689][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 27
[2024-07-24 10:20:06,690][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,690][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,690][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,690][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,690][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,690][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,690][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,690][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 28
[2024-07-24 10:20:06,690][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,690][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,690][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,690][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,690][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,690][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,690][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,690][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 0
[2024-07-24 10:20:06,691][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,691][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit5', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,691][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit5', 'circuit7', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:06,691][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:06,691][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,691][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:06,691][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit7', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:06,691][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit7', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:06,691][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 1
[2024-07-24 10:20:06,691][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0']
[2024-07-24 10:20:06,691][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,691][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,691][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:20:06,691][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,691][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit14', 'circuit15']
[2024-07-24 10:20:06,691][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,692][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,692][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 2
[2024-07-24 10:20:06,692][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,692][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,692][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,692][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit19', 'circuit20']
[2024-07-24 10:20:06,692][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,692][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,692][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,692][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit17']
[2024-07-24 10:20:06,692][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 3
[2024-07-24 10:20:06,692][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,692][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:20:06,692][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit17', 'circuit19', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:20:06,692][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit15', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:06,692][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:20:06,693][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit21', 'circuit22']
[2024-07-24 10:20:06,693][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,693][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit13', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:06,693][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 4
[2024-07-24 10:20:06,693][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:06,693][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:06,693][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:06,693][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:06,693][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:20:06,693][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit3', 'circuit4', 'circuit6', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:20:06,693][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit3', 'circuit13', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:20:06,693][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit5', 'circuit7', 'circuit13', 'circuit20', 'circuit21', 'circuit23', 'circuit26']
[2024-07-24 10:20:06,693][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 5
[2024-07-24 10:20:06,693][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:20:06,693][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit10', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:06,693][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,694][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,694][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,694][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,694][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,694][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,694][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 6
[2024-07-24 10:20:06,694][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,694][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,694][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,694][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,694][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit13']
[2024-07-24 10:20:06,694][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,694][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit27']
[2024-07-24 10:20:06,694][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,694][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 7
[2024-07-24 10:20:06,694][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,695][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,695][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,695][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,695][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,695][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,695][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,695][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,695][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 8
[2024-07-24 10:20:06,695][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,695][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,695][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,695][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,695][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,695][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,695][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,695][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0']
[2024-07-24 10:20:06,696][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 9
[2024-07-24 10:20:06,696][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24']
[2024-07-24 10:20:06,696][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,696][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,696][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,696][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,696][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,696][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,696][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,696][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 10
[2024-07-24 10:20:06,696][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,696][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,696][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,696][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,696][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,696][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,697][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,697][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,697][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 11
[2024-07-24 10:20:06,697][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit22', 'circuit24']
[2024-07-24 10:20:06,697][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,697][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,697][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,697][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,697][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,697][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,697][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,697][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 12
[2024-07-24 10:20:06,697][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:20:06,697][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,697][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,697][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,697][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,698][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,698][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,698][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,698][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 13
[2024-07-24 10:20:06,698][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:06,698][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit16', 'circuit19', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:06,698][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:06,698][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:06,698][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit15', 'circuit17', 'circuit21', 'circuit26']
[2024-07-24 10:20:06,698][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit16', 'circuit17', 'circuit19', 'circuit22', 'circuit24', 'circuit27']
[2024-07-24 10:20:06,698][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit13', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:20:06,698][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit22', 'circuit23', 'circuit25', 'circuit27']
[2024-07-24 10:20:06,698][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 14
[2024-07-24 10:20:06,698][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:20:06,698][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,698][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,699][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,699][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,699][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,699][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,699][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,699][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 15
[2024-07-24 10:20:06,699][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,699][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,699][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,699][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,699][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,699][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,699][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,699][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,699][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 16
[2024-07-24 10:20:06,699][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,700][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,700][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,700][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,700][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,700][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,700][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,700][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,700][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 17
[2024-07-24 10:20:06,700][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,700][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,700][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,700][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,700][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,700][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,700][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,700][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,701][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 18
[2024-07-24 10:20:06,701][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,701][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,701][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,701][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,701][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,701][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,701][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,701][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,701][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 19
[2024-07-24 10:20:06,701][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,701][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,701][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,701][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,701][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,701][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,701][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,702][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0']
[2024-07-24 10:20:06,702][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 20
[2024-07-24 10:20:06,702][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit24']
[2024-07-24 10:20:06,702][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,702][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,702][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,702][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,702][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,702][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,702][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,702][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 21
[2024-07-24 10:20:06,702][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:06,702][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:06,702][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:06,702][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:06,702][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit8', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:20:06,703][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit3', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:20:06,703][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:06,703][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit5', 'circuit11', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:06,703][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 22
[2024-07-24 10:20:06,703][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit20', 'circuit24', 'circuit27']
[2024-07-24 10:20:06,703][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15']
[2024-07-24 10:20:06,703][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:06,703][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:20:06,703][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:06,703][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:20:06,703][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit20', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:06,703][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit7', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:20:06,703][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 23
[2024-07-24 10:20:06,703][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:20:06,703][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit15']
[2024-07-24 10:20:06,703][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit20', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:20:06,704][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit24', 'circuit25']
[2024-07-24 10:20:06,704][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,704][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,704][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:06,704][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,704][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 24
[2024-07-24 10:20:06,704][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,704][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,704][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,704][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,704][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,704][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,704][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,704][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,704][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 25
[2024-07-24 10:20:06,704][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,705][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,705][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,705][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,705][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,705][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,705][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,705][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,705][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 26
[2024-07-24 10:20:06,705][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,705][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,705][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,705][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,705][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,705][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,705][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,706][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,706][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 27
[2024-07-24 10:20:06,706][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,706][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,706][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,706][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,706][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,706][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,706][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,706][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,706][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 28
[2024-07-24 10:20:06,706][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,706][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,706][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,706][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,706][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,707][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,707][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,707][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,707][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 0
[2024-07-24 10:20:06,707][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,707][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit8', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:06,707][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit4', 'circuit5', 'circuit7', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:20:06,707][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit3', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:06,707][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit7', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:06,707][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit5', 'circuit6', 'circuit8', 'circuit9', 'circuit12', 'circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:20:06,707][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit6', 'circuit7', 'circuit11', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:06,707][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit4', 'circuit5', 'circuit7', 'circuit13', 'circuit14', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:20:06,707][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:20:06,707][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 1
[2024-07-24 10:20:06,707][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,708][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,708][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,708][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,708][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,708][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,708][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,708][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,708][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:06,708][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 2
[2024-07-24 10:20:06,708][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,708][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,708][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,708][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,708][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,708][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,708][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,709][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,709][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:06,709][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 3
[2024-07-24 10:20:06,709][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,709][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,709][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,709][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,709][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,709][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,709][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,709][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,709][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:06,709][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 4
[2024-07-24 10:20:06,709][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,709][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,709][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,709][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,710][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,710][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,710][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,710][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,710][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:06,710][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 5
[2024-07-24 10:20:06,710][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,710][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,710][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,710][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,710][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,710][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,710][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,710][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,710][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:06,710][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 6
[2024-07-24 10:20:06,711][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,711][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,711][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,711][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,711][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,711][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,711][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,711][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,711][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:06,711][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 7
[2024-07-24 10:20:06,711][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,711][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,711][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,711][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,711][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,711][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,712][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,712][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,712][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:06,712][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 8
[2024-07-24 10:20:06,712][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,712][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,712][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,712][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,712][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,712][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,712][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,712][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,712][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:06,712][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 9
[2024-07-24 10:20:06,712][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,712][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,713][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,713][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,713][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,713][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,713][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,713][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,713][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:06,713][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 10
[2024-07-24 10:20:06,713][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,713][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,713][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13']
[2024-07-24 10:20:06,713][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit13']
[2024-07-24 10:20:06,713][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0']
[2024-07-24 10:20:06,713][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,713][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,713][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,713][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:06,714][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 11
[2024-07-24 10:20:06,714][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,714][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,714][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,714][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,714][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,714][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,714][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,714][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,714][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:06,714][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 12
[2024-07-24 10:20:06,714][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:20:06,714][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,714][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,714][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,714][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit21', 'circuit23', 'circuit24']
[2024-07-24 10:20:06,715][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit16', 'circuit26']
[2024-07-24 10:20:06,715][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit15', 'circuit20', 'circuit22']
[2024-07-24 10:20:06,715][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,715][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit2', 'circuit7', 'circuit8', 'circuit9', 'circuit10']
[2024-07-24 10:20:06,715][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 13
[2024-07-24 10:20:06,715][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit24']
[2024-07-24 10:20:06,715][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit17', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:06,715][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:06,715][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:06,715][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:06,715][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:06,715][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit13', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:20:06,715][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,715][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:20:06,715][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 14
[2024-07-24 10:20:06,715][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,716][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,716][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,716][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,716][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,716][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,716][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,716][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,716][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:06,716][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 15
[2024-07-24 10:20:06,716][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,716][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,716][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,716][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,716][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,716][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,716][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,717][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,717][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:06,717][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 16
[2024-07-24 10:20:06,717][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,717][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,717][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,717][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,717][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,717][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,717][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,717][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,717][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:06,717][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 17
[2024-07-24 10:20:06,717][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,717][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,717][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,717][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,718][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,718][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,718][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,718][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,718][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:06,718][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 18
[2024-07-24 10:20:06,718][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,718][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,718][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,718][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,718][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,718][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,718][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,718][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,718][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:06,718][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 19
[2024-07-24 10:20:06,719][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,719][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,719][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,719][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,719][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,719][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,719][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,719][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,719][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:06,719][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 20
[2024-07-24 10:20:06,719][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,719][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,719][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,719][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,719][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,719][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,720][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,720][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,720][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:06,720][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 21
[2024-07-24 10:20:06,720][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,720][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,720][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,720][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,720][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,720][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,720][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,720][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,720][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:06,720][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 22
[2024-07-24 10:20:06,720][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,720][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,721][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,721][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,721][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,721][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,721][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,721][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,721][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:06,721][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 23
[2024-07-24 10:20:06,721][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,721][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,721][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,721][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,721][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,721][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,721][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,721][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,721][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:06,722][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 24
[2024-07-24 10:20:06,722][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,722][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,722][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,722][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,722][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,722][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,722][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,722][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,722][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:06,722][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 25
[2024-07-24 10:20:06,722][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,722][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,722][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,722][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,722][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,723][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,723][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,723][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,723][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:06,723][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 26
[2024-07-24 10:20:06,723][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,723][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,723][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,723][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,723][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,723][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,723][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,723][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,723][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,723][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 27
[2024-07-24 10:20:06,723][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,724][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,724][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,724][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,724][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,724][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,724][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,724][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,724][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,724][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 28
[2024-07-24 10:20:06,724][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,724][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,724][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,724][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,724][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,724][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,725][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,725][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,725][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,725][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 0
[2024-07-24 10:20:06,725][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit21', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:06,725][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit1', 'circuit2', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:20:06,725][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:20:06,725][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:20:06,725][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:06,725][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit13', 'circuit14', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:20:06,725][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit5', 'circuit8', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:20:06,725][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit5', 'circuit12', 'circuit13', 'circuit14', 'circuit25', 'circuit28']
[2024-07-24 10:20:06,725][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit26', 'circuit27']
[2024-07-24 10:20:06,725][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit13', 'circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit24']
[2024-07-24 10:20:06,725][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 1
[2024-07-24 10:20:06,725][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,726][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,726][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,726][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,726][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,726][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,726][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,726][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,726][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:06,726][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:06,726][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 2
[2024-07-24 10:20:06,726][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,726][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,726][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,726][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,726][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,726][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,727][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,727][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,727][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:06,727][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:06,727][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 3
[2024-07-24 10:20:06,727][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,727][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,727][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,727][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,727][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,727][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,727][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,727][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,727][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:06,727][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:06,727][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 4
[2024-07-24 10:20:06,728][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,728][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,728][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,728][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,728][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,728][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,728][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,728][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,728][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:06,728][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:06,728][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 5
[2024-07-24 10:20:06,728][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,728][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,728][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,728][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,728][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,729][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,729][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,729][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,729][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:06,729][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:06,729][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 6
[2024-07-24 10:20:06,729][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,729][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,729][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,729][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,729][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,729][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,729][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,729][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,729][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:06,729][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:06,730][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 7
[2024-07-24 10:20:06,730][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,730][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,730][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,730][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,730][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,730][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,730][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,730][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,730][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:06,730][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:06,730][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 8
[2024-07-24 10:20:06,730][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,730][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,730][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,730][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,730][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,731][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,731][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,731][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,731][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:06,731][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:06,731][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 9
[2024-07-24 10:20:06,731][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,731][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,731][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,731][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,731][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,731][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,731][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,731][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,731][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:06,731][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:06,732][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 10
[2024-07-24 10:20:06,732][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,732][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,732][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,732][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,732][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,732][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,732][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,732][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,732][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:06,732][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:06,732][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 11
[2024-07-24 10:20:06,732][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:20:06,732][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,732][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,732][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,733][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,733][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,733][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,733][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,733][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:06,733][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:06,733][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 12
[2024-07-24 10:20:06,733][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,733][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,733][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,733][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,733][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,733][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,733][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,733][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,733][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:06,734][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:06,734][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 13
[2024-07-24 10:20:06,734][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:20:06,734][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:20:06,734][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,734][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,734][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,734][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,734][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,734][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,734][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit17', 'circuit19', 'circuit23', 'circuit25']
[2024-07-24 10:20:06,734][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:06,734][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 14
[2024-07-24 10:20:06,734][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,734][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,734][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,734][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,735][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,735][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,735][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,735][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,735][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:06,735][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:06,735][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 15
[2024-07-24 10:20:06,735][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,735][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,735][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,735][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,735][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,735][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,735][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,735][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,735][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:06,736][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:06,736][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 16
[2024-07-24 10:20:06,736][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,736][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,736][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,736][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,736][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,736][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,736][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,736][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,736][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:06,736][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:06,736][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 17
[2024-07-24 10:20:06,736][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,736][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,736][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,737][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,737][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,737][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,737][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,737][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,737][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:06,737][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:06,737][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 18
[2024-07-24 10:20:06,737][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,737][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,737][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,737][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,737][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,737][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,737][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,737][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,738][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:06,738][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:06,738][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 19
[2024-07-24 10:20:06,738][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,738][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,738][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,738][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,738][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,738][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,738][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,738][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,738][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:06,738][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:06,738][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 20
[2024-07-24 10:20:06,738][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,738][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,739][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,739][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,739][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,739][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,739][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,739][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,739][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:06,739][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:06,739][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 21
[2024-07-24 10:20:06,739][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,739][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,739][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,739][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,739][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,739][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,739][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,740][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,740][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:06,740][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:06,740][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 22
[2024-07-24 10:20:06,740][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,740][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,740][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,740][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,740][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,740][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,740][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,740][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,740][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:06,740][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:06,740][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 23
[2024-07-24 10:20:06,740][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,740][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,741][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,741][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,741][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,741][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,741][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,741][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,741][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:06,741][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:06,741][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 24
[2024-07-24 10:20:06,741][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,741][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,741][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,741][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,741][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,741][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,741][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,742][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,742][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:06,742][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:06,742][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 25
[2024-07-24 10:20:06,742][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,742][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,742][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,742][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,742][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,742][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,742][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,742][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,742][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:06,742][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:06,742][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 26
[2024-07-24 10:20:06,742][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,743][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,743][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,743][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,743][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,743][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,743][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,743][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,743][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,743][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,743][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 27
[2024-07-24 10:20:06,743][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,743][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,743][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,743][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,743][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,744][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,744][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,744][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,744][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,744][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,744][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 28
[2024-07-24 10:20:06,744][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,744][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,744][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,744][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,744][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,744][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,744][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,744][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,744][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,744][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,745][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 0
[2024-07-24 10:20:06,745][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:06,745][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:20:06,745][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit19', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:20:06,745][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:06,745][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:06,745][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,745][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit20', 'circuit23', 'circuit25']
[2024-07-24 10:20:06,745][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit3', 'circuit4', 'circuit5', 'circuit7']
[2024-07-24 10:20:06,745][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit14', 'circuit17', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:20:06,745][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit13', 'circuit17', 'circuit18', 'circuit19']
[2024-07-24 10:20:06,745][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:20:06,745][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 1
[2024-07-24 10:20:06,745][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,745][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,745][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,746][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,746][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,746][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,746][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,746][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,746][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:06,746][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:06,746][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:20:06,746][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 2
[2024-07-24 10:20:06,746][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,746][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,746][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:06,746][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,746][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,746][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,746][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,747][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,747][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit19', 'circuit20']
[2024-07-24 10:20:06,747][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:06,747][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit20', 'circuit21', 'circuit24']
[2024-07-24 10:20:06,747][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 3
[2024-07-24 10:20:06,747][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:20:06,747][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,747][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,747][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,747][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,747][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,747][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,747][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,747][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:06,747][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:06,747][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:20:06,748][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 4
[2024-07-24 10:20:06,748][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,748][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,748][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,748][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,748][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,748][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,748][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,748][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,748][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0']
[2024-07-24 10:20:06,748][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-24 10:20:06,748][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0']
[2024-07-24 10:20:06,748][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 5
[2024-07-24 10:20:06,748][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit24']
[2024-07-24 10:20:06,748][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,748][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,749][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,749][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,749][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,749][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,749][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,749][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:06,749][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:06,749][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:20:06,749][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 6
[2024-07-24 10:20:06,749][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,749][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,749][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,749][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,749][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,749][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,749][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,749][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,750][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:06,750][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:06,750][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit7', 'circuit18']
[2024-07-24 10:20:06,750][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 7
[2024-07-24 10:20:06,750][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:20:06,750][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:20:06,750][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:06,750][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit13', 'circuit14', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:20:06,750][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit24']
[2024-07-24 10:20:06,750][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,750][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:06,750][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,750][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:06,750][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:06,750][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:20:06,750][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 8
[2024-07-24 10:20:06,751][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,751][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,751][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,751][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,751][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,751][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,751][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,751][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,751][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:06,751][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:06,751][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:20:06,751][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 9
[2024-07-24 10:20:06,751][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,751][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,751][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,751][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,752][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,752][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,752][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,752][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,752][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:06,752][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:06,752][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:20:06,752][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 10
[2024-07-24 10:20:06,752][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,752][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,752][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,752][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,752][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,752][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,752][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,752][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,753][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:06,753][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:06,753][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:20:06,753][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 11
[2024-07-24 10:20:06,753][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,753][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,753][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,753][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,753][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,753][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,753][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,753][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,753][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:06,753][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:06,753][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0']
[2024-07-24 10:20:06,753][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 12
[2024-07-24 10:20:06,754][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,754][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,754][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,754][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,754][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,754][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,754][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit21']
[2024-07-24 10:20:06,754][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,754][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:06,754][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:06,754][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0']
[2024-07-24 10:20:06,754][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 13
[2024-07-24 10:20:06,754][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit24']
[2024-07-24 10:20:06,754][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit13', 'circuit17', 'circuit18']
[2024-07-24 10:20:06,754][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit22']
[2024-07-24 10:20:06,754][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:20:06,754][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit19']
[2024-07-24 10:20:06,755][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit21', 'circuit25']
[2024-07-24 10:20:06,755][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit19', 'circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:06,755][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,755][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit19']
[2024-07-24 10:20:06,755][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-24 10:20:06,755][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit13', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:06,755][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 14
[2024-07-24 10:20:06,755][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,755][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,755][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,755][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,755][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,755][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,755][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,755][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,755][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:06,756][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:06,756][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:20:06,756][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 15
[2024-07-24 10:20:06,756][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,756][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,756][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,756][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,756][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,756][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,756][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,756][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,756][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:06,756][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:06,756][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:20:06,756][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 16
[2024-07-24 10:20:06,756][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,757][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,757][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,757][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,757][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,757][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,757][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,757][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,757][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:06,757][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:06,757][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:20:06,757][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 17
[2024-07-24 10:20:06,757][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,757][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,757][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,757][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,757][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,758][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,758][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,758][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,758][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:06,758][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:06,758][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:20:06,758][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 18
[2024-07-24 10:20:06,758][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,758][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,758][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,758][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,758][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,758][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,758][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,758][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,758][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:06,759][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:06,759][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:20:06,759][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 19
[2024-07-24 10:20:06,759][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,759][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,759][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,759][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,759][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,759][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,759][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,759][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,759][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:06,759][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:06,759][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:20:06,759][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 20
[2024-07-24 10:20:06,759][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,759][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,760][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,760][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,760][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,760][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,760][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,760][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,760][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:06,760][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:06,760][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:20:06,760][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 21
[2024-07-24 10:20:06,760][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,760][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,760][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,760][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,760][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,760][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,761][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,761][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,761][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:06,761][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:06,761][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:20:06,761][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 22
[2024-07-24 10:20:06,761][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,761][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,761][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,761][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,761][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,761][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,761][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,761][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,761][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:06,761][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:06,762][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:20:06,762][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 23
[2024-07-24 10:20:06,762][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,762][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,762][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,762][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,762][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,762][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,762][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,762][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,762][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:06,762][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:06,762][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:20:06,762][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 24
[2024-07-24 10:20:06,762][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,762][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,763][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,763][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,763][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,763][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,763][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,763][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,763][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:06,763][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:06,763][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:20:06,763][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 25
[2024-07-24 10:20:06,763][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:06,763][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:06,763][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:06,763][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:06,763][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:06,763][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:06,763][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:06,764][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:06,764][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:06,764][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:06,764][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:20:06,764][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 26
[2024-07-24 10:20:06,764][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,764][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,764][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,764][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,764][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,764][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,764][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,764][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,764][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,764][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,765][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,765][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 27
[2024-07-24 10:20:06,765][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,765][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,765][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,765][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,765][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,765][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,765][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,765][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,765][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,765][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,765][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,765][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 28
[2024-07-24 10:20:06,765][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,765][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,766][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,766][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,766][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,766][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,766][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,766][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,766][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,766][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:06,766][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:07,744][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:20:07,745][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:07,745][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:07,745][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:07,746][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:07,746][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:07,747][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:07,747][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:07,747][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:07,749][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:07,749][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:07,750][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:07,750][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:07,750][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Benjamin] are: tensor([0.8183, 0.1817], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:07,751][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Benjamin] are: tensor([6.2538e-04, 9.9937e-01], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:07,751][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Benjamin] are: tensor([0.8797, 0.1203], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:07,751][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Benjamin] are: tensor([0.1231, 0.8769], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:07,752][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Benjamin] are: tensor([0.3480, 0.6520], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:07,752][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Benjamin] are: tensor([0.0271, 0.9729], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:07,752][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Benjamin] are: tensor([0.6174, 0.3826], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:07,752][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Benjamin] are: tensor([0.9223, 0.0777], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:07,753][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Benjamin] are: tensor([0.7616, 0.2384], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:07,755][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Benjamin] are: tensor([0.9496, 0.0504], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:07,755][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Benjamin] are: tensor([0.6785, 0.3215], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:07,756][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Benjamin] are: tensor([0.7509, 0.2491], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:07,756][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.7969, 0.1355, 0.0675], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:07,756][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ and] are: tensor([4.4099e-03, 4.6795e-04, 9.9512e-01], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:07,757][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.4097, 0.0612, 0.5291], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:07,757][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.2514, 0.0119, 0.7367], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:07,757][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.6844, 0.1153, 0.2003], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:07,758][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1826, 0.0143, 0.8031], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:07,760][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.5948, 0.3836, 0.0216], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:07,762][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.4940, 0.2521, 0.2539], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:07,762][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.2531, 0.0421, 0.7048], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:07,762][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.6193, 0.1254, 0.2553], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:07,763][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.6686, 0.0977, 0.2337], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:07,763][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.5429, 0.1165, 0.3407], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:07,763][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Alexander] are: tensor([0.3511, 0.1805, 0.2706, 0.1979], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:07,764][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Alexander] are: tensor([1.1963e-03, 4.1999e-03, 3.5199e-04, 9.9425e-01], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:07,764][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Alexander] are: tensor([0.6010, 0.1056, 0.0793, 0.2141], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:07,765][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Alexander] are: tensor([2.1888e-03, 1.0657e-02, 5.5184e-05, 9.8710e-01], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:07,769][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Alexander] are: tensor([0.0587, 0.0935, 0.0068, 0.8411], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:07,769][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Alexander] are: tensor([7.3493e-03, 6.6297e-04, 4.8928e-06, 9.9198e-01], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:07,769][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Alexander] are: tensor([0.2588, 0.5092, 0.0681, 0.1639], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:07,770][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Alexander] are: tensor([0.2317, 0.2912, 0.3401, 0.1369], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:07,770][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Alexander] are: tensor([0.4557, 0.3118, 0.1447, 0.0878], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:07,770][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Alexander] are: tensor([0.5631, 0.1694, 0.2396, 0.0279], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:07,771][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Alexander] are: tensor([0.3909, 0.2087, 0.1435, 0.2569], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:07,771][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Alexander] are: tensor([0.3292, 0.1709, 0.4000, 0.0999], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:07,773][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ went] are: tensor([0.4765, 0.0679, 0.0843, 0.1085, 0.2629], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:07,775][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ went] are: tensor([1.1730e-03, 3.3773e-04, 1.7646e-03, 3.5019e-04, 9.9637e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:07,776][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ went] are: tensor([0.6048, 0.0507, 0.1913, 0.0665, 0.0867], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:07,776][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ went] are: tensor([3.0824e-02, 3.7625e-04, 2.0196e-03, 8.7323e-04, 9.6591e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:07,776][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ went] are: tensor([0.3738, 0.0267, 0.0548, 0.1720, 0.3727], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:07,777][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ went] are: tensor([2.6719e-02, 3.0249e-05, 6.5631e-05, 4.7681e-05, 9.7314e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:07,777][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ went] are: tensor([0.3021, 0.2970, 0.0458, 0.3101, 0.0449], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:07,777][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ went] are: tensor([0.2006, 0.0884, 0.2133, 0.3201, 0.1776], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:07,778][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.4003, 0.0844, 0.3898, 0.0603, 0.0652], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:07,780][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ went] are: tensor([0.4339, 0.1145, 0.2121, 0.1229, 0.1166], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:07,782][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ went] are: tensor([0.4195, 0.0847, 0.1889, 0.0429, 0.2639], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:07,782][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ went] are: tensor([0.4838, 0.0920, 0.2409, 0.0615, 0.1218], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:07,783][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.4638, 0.0995, 0.0624, 0.0901, 0.2509, 0.0333], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:07,783][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ to] are: tensor([5.9630e-03, 4.1575e-04, 6.7588e-02, 1.3395e-04, 8.4857e-04, 9.2505e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:07,784][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.3967, 0.0459, 0.1787, 0.0430, 0.0805, 0.2552], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:07,784][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0326, 0.0078, 0.0213, 0.0025, 0.4629, 0.4729], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:07,784][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.1576, 0.0302, 0.0265, 0.0228, 0.6295, 0.1333], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:07,785][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0827, 0.0245, 0.1440, 0.0059, 0.0154, 0.7275], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:07,787][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.2729, 0.2010, 0.0150, 0.1063, 0.0711, 0.3338], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:07,789][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.1441, 0.0662, 0.1227, 0.0977, 0.3131, 0.2562], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:07,789][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0606, 0.0138, 0.3499, 0.0151, 0.0655, 0.4952], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:07,790][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.3585, 0.0797, 0.1919, 0.0921, 0.0901, 0.1876], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:07,790][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.3529, 0.0733, 0.2434, 0.0414, 0.0912, 0.1979], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:07,790][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.3377, 0.1044, 0.1794, 0.0705, 0.1240, 0.1840], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:07,791][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.5364, 0.1220, 0.0471, 0.0878, 0.1438, 0.0248, 0.0380],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:07,791][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ the] are: tensor([9.1017e-03, 1.3035e-03, 6.6695e-02, 1.2241e-03, 1.9109e-04, 8.7241e-02,
        8.3424e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:07,791][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.3359, 0.0576, 0.1431, 0.0372, 0.1105, 0.2754, 0.0403],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:07,794][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0505, 0.0103, 0.0233, 0.0121, 0.0852, 0.1823, 0.6363],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:07,796][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.2870, 0.0456, 0.0399, 0.0951, 0.2769, 0.1188, 0.1366],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:07,796][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.1750, 0.0362, 0.1483, 0.0165, 0.0401, 0.1319, 0.4519],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:07,796][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.3063, 0.3456, 0.0071, 0.2398, 0.0857, 0.0113, 0.0042],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:07,797][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.1189, 0.0308, 0.0828, 0.0857, 0.1469, 0.2299, 0.3049],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:07,797][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0305, 0.0074, 0.1958, 0.0152, 0.0524, 0.2097, 0.4890],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:07,797][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.3293, 0.0733, 0.1605, 0.0711, 0.0805, 0.1561, 0.1293],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:07,798][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.3563, 0.0708, 0.1711, 0.0557, 0.0453, 0.1162, 0.1846],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:07,798][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.2795, 0.0955, 0.1464, 0.0708, 0.1064, 0.1421, 0.1593],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:07,801][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ station] are: tensor([0.2575, 0.1962, 0.1146, 0.1396, 0.0653, 0.0554, 0.0875, 0.0838],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:07,802][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ station] are: tensor([5.8236e-04, 4.4617e-03, 4.0125e-03, 1.8105e-04, 1.0896e-03, 1.8377e-03,
        4.8264e-04, 9.8735e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:07,803][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ station] are: tensor([0.2708, 0.1811, 0.0794, 0.0854, 0.0694, 0.0837, 0.0674, 0.1628],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:07,803][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ station] are: tensor([1.2288e-02, 3.9139e-04, 1.7966e-04, 1.3702e-03, 6.2819e-03, 1.4383e-03,
        9.7179e-04, 9.7708e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:07,804][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ station] are: tensor([0.0625, 0.0115, 0.0059, 0.0063, 0.0331, 0.0110, 0.0179, 0.8519],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:07,804][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ station] are: tensor([1.2827e-02, 7.5131e-04, 1.8602e-05, 4.4947e-05, 5.4310e-05, 3.4121e-06,
        4.1123e-06, 9.8630e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:07,804][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ station] are: tensor([0.2231, 0.3023, 0.0378, 0.1564, 0.0237, 0.0250, 0.0317, 0.1999],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:07,805][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ station] are: tensor([0.0706, 0.0047, 0.0530, 0.0478, 0.1118, 0.2027, 0.3421, 0.1671],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:07,805][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ station] are: tensor([0.2195, 0.1001, 0.1488, 0.0846, 0.0572, 0.1331, 0.1040, 0.1528],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:07,808][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ station] are: tensor([0.2689, 0.1875, 0.1372, 0.0713, 0.0805, 0.1160, 0.1222, 0.0164],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:07,809][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ station] are: tensor([0.1609, 0.0861, 0.1472, 0.0522, 0.0593, 0.1103, 0.1023, 0.2816],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:07,810][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ station] are: tensor([0.2392, 0.0741, 0.1090, 0.0634, 0.0962, 0.1684, 0.0490, 0.2005],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:07,810][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.4633, 0.0906, 0.0213, 0.0902, 0.1252, 0.0195, 0.0619, 0.1137, 0.0143],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:07,810][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [,] are: tensor([3.4321e-03, 3.6751e-04, 2.5582e-02, 1.2650e-04, 5.2712e-04, 9.1319e-03,
        1.2521e-03, 1.1308e-04, 9.5947e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:07,811][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.2794, 0.0243, 0.1222, 0.0162, 0.0482, 0.0617, 0.0140, 0.0118, 0.4221],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:07,811][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0515, 0.0014, 0.0081, 0.0017, 0.0736, 0.0445, 0.1175, 0.0662, 0.6355],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:07,812][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.5264, 0.0363, 0.0156, 0.0122, 0.0731, 0.0527, 0.0288, 0.0766, 0.1782],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:07,814][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.1331, 0.0398, 0.1914, 0.0414, 0.0575, 0.0951, 0.1419, 0.0189, 0.2809],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:07,816][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.3208, 0.2788, 0.0112, 0.1169, 0.0690, 0.0221, 0.0073, 0.1671, 0.0068],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:07,816][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0523, 0.0244, 0.0332, 0.0629, 0.0676, 0.0889, 0.1752, 0.1545, 0.3410],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:07,817][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0342, 0.0072, 0.1778, 0.0081, 0.0215, 0.1578, 0.2310, 0.0122, 0.3502],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:07,817][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.2681, 0.0796, 0.1360, 0.0685, 0.0727, 0.1261, 0.0999, 0.0465, 0.1027],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:07,817][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.2338, 0.0795, 0.1682, 0.0549, 0.0715, 0.1394, 0.1015, 0.0378, 0.1134],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:07,818][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.2491, 0.0755, 0.1225, 0.0526, 0.0922, 0.1120, 0.0637, 0.0961, 0.1365],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:07,818][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Benjamin] are: tensor([0.2366, 0.1103, 0.1037, 0.0572, 0.0409, 0.0992, 0.0686, 0.0898, 0.1092,
        0.0845], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:07,820][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Benjamin] are: tensor([9.5941e-05, 5.0581e-01, 3.3352e-05, 9.7520e-04, 2.2109e-05, 4.9386e-05,
        4.5377e-05, 4.2831e-05, 5.7306e-06, 4.9292e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:07,823][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Benjamin] are: tensor([0.2978, 0.1534, 0.0639, 0.0829, 0.0393, 0.0605, 0.0710, 0.0991, 0.0410,
        0.0910], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:07,823][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Benjamin] are: tensor([1.5600e-03, 3.6802e-03, 2.8850e-06, 1.8834e-03, 7.3738e-06, 3.1812e-05,
        6.2872e-05, 2.3887e-04, 6.8927e-05, 9.9246e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:07,823][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Benjamin] are: tensor([1.1443e-02, 5.5552e-02, 8.5728e-04, 2.9520e-03, 1.0033e-03, 2.4364e-03,
        1.1006e-03, 2.4236e-03, 5.4999e-03, 9.1673e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:07,824][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Benjamin] are: tensor([2.3013e-03, 7.3642e-01, 1.4848e-07, 5.1413e-05, 6.9578e-08, 3.6578e-08,
        3.4019e-08, 9.0156e-07, 7.1354e-09, 2.6122e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:07,824][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Benjamin] are: tensor([0.1599, 0.2545, 0.0610, 0.0994, 0.0142, 0.0139, 0.0577, 0.0785, 0.0577,
        0.2032], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:07,825][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Benjamin] are: tensor([0.0639, 0.0236, 0.0338, 0.0495, 0.0338, 0.1028, 0.1285, 0.1139, 0.2330,
        0.2171], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:07,825][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Benjamin] are: tensor([0.2296, 0.1579, 0.0933, 0.0626, 0.0482, 0.0782, 0.0660, 0.0376, 0.0922,
        0.1343], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:07,827][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Benjamin] are: tensor([0.3122, 0.0226, 0.1278, 0.0538, 0.0768, 0.0978, 0.1122, 0.0728, 0.1108,
        0.0131], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:07,832][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Benjamin] are: tensor([0.1531, 0.3002, 0.0834, 0.0759, 0.0238, 0.0537, 0.0517, 0.0181, 0.0484,
        0.1918], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:07,833][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Benjamin] are: tensor([0.1300, 0.0749, 0.1298, 0.0445, 0.1057, 0.1139, 0.0693, 0.1070, 0.1337,
        0.0913], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:07,833][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.2853, 0.0237, 0.0344, 0.0750, 0.2309, 0.0225, 0.0212, 0.0508, 0.0246,
        0.0227, 0.2088], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:07,833][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([9.4645e-04, 1.2041e-03, 2.3578e-03, 2.3586e-04, 8.8412e-03, 1.1975e-03,
        3.2204e-04, 1.6754e-04, 3.6756e-04, 4.6144e-04, 9.8390e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:07,834][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.3394, 0.0383, 0.0823, 0.0472, 0.0950, 0.1255, 0.0812, 0.0174, 0.0510,
        0.0277, 0.0951], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:07,834][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([2.3838e-03, 2.3405e-05, 2.9771e-05, 6.1147e-06, 1.0941e-03, 1.3014e-04,
        1.9857e-04, 5.5547e-04, 1.7803e-03, 1.6690e-03, 9.9213e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:07,835][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.1394, 0.0185, 0.0145, 0.0164, 0.0399, 0.0328, 0.0216, 0.0245, 0.0469,
        0.0765, 0.5689], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:07,835][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([4.7300e-02, 3.3997e-04, 3.9505e-05, 9.8320e-05, 1.0252e-02, 4.1298e-06,
        1.4027e-05, 2.1773e-06, 1.9010e-06, 3.7154e-05, 9.4191e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:07,835][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.1871, 0.1541, 0.0260, 0.1253, 0.0412, 0.0188, 0.0248, 0.1719, 0.0208,
        0.1855, 0.0444], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:07,838][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0526, 0.0102, 0.0234, 0.0231, 0.0266, 0.0533, 0.0892, 0.0523, 0.2190,
        0.1727, 0.2775], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:07,840][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.1348, 0.0325, 0.1465, 0.0153, 0.0491, 0.1394, 0.1907, 0.0383, 0.1707,
        0.0351, 0.0476], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:07,840][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.1928, 0.0749, 0.1023, 0.0663, 0.0836, 0.0996, 0.0816, 0.0603, 0.0903,
        0.0748, 0.0735], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:07,841][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.1630, 0.0753, 0.0965, 0.0440, 0.1028, 0.0919, 0.0648, 0.0250, 0.0702,
        0.0561, 0.2106], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:07,841][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.3029, 0.0489, 0.1276, 0.0320, 0.0512, 0.1082, 0.0480, 0.0511, 0.1052,
        0.0473, 0.0777], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:07,841][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.3166, 0.0825, 0.0298, 0.0508, 0.0778, 0.0192, 0.0355, 0.0777, 0.0307,
        0.0970, 0.1537, 0.0286], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:07,842][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ a] are: tensor([3.0347e-03, 1.6570e-03, 3.7301e-03, 4.8766e-04, 1.0824e-04, 9.8385e-03,
        3.0977e-02, 5.2401e-05, 1.0093e-03, 6.6312e-04, 2.1886e-04, 9.4822e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:07,842][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.1980, 0.0370, 0.1290, 0.0304, 0.0892, 0.2091, 0.0295, 0.0191, 0.0851,
        0.0322, 0.1139, 0.0274], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:07,844][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ a] are: tensor([1.2209e-02, 4.0394e-04, 9.5837e-04, 2.5434e-04, 2.0133e-03, 4.1563e-03,
        1.6370e-02, 7.3955e-03, 5.0113e-02, 1.7264e-02, 1.3623e-01, 7.5263e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:07,847][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0627, 0.0063, 0.0063, 0.0083, 0.0642, 0.0167, 0.0179, 0.0175, 0.0323,
        0.0381, 0.5445, 0.1852], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:07,847][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0642, 0.0157, 0.1024, 0.0129, 0.0108, 0.0907, 0.2202, 0.0021, 0.0307,
        0.0034, 0.0073, 0.4396], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:07,847][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.1705, 0.1628, 0.0049, 0.1030, 0.0706, 0.0091, 0.0037, 0.1399, 0.0034,
        0.2353, 0.0907, 0.0061], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:07,848][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0365, 0.0053, 0.0118, 0.0069, 0.0247, 0.0238, 0.0415, 0.0341, 0.1224,
        0.0937, 0.3018, 0.2975], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:07,848][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0159, 0.0035, 0.0798, 0.0059, 0.0220, 0.0965, 0.2265, 0.0124, 0.1530,
        0.0060, 0.0279, 0.3506], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:07,849][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.1942, 0.0509, 0.1108, 0.0549, 0.0555, 0.1060, 0.0903, 0.0434, 0.0872,
        0.0436, 0.0723, 0.0908], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:07,849][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.1802, 0.0547, 0.1153, 0.0382, 0.0399, 0.1073, 0.1148, 0.0292, 0.0754,
        0.0365, 0.0417, 0.1670], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:07,852][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.1917, 0.0668, 0.0839, 0.0440, 0.0661, 0.0930, 0.0505, 0.0693, 0.0959,
        0.0772, 0.0923, 0.0692], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:07,853][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ computer] are: tensor([0.2282, 0.0727, 0.0719, 0.0562, 0.0751, 0.0416, 0.0334, 0.0794, 0.0717,
        0.0620, 0.0645, 0.0450, 0.0985], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:07,854][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ computer] are: tensor([1.9937e-04, 1.8101e-03, 6.3471e-04, 9.9254e-05, 2.8511e-04, 5.0036e-04,
        4.0996e-04, 3.6566e-04, 2.4234e-04, 6.5938e-04, 5.4591e-05, 1.2953e-04,
        9.9461e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:07,854][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ computer] are: tensor([0.2554, 0.0634, 0.0731, 0.0561, 0.0438, 0.0756, 0.0828, 0.0378, 0.0347,
        0.0461, 0.0517, 0.0736, 0.1059], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:07,855][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ computer] are: tensor([4.7062e-04, 1.8193e-05, 1.0506e-06, 9.3066e-06, 8.5852e-06, 8.1228e-06,
        1.3752e-05, 1.2851e-04, 2.9195e-05, 2.5117e-03, 9.5646e-04, 3.6131e-04,
        9.9548e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:07,855][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ computer] are: tensor([0.0499, 0.0035, 0.0017, 0.0070, 0.0019, 0.0029, 0.0043, 0.0047, 0.0072,
        0.0096, 0.0166, 0.0223, 0.8682], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:07,856][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ computer] are: tensor([1.7272e-03, 8.9261e-04, 8.3428e-06, 1.1599e-04, 8.1765e-06, 1.3748e-06,
        1.3573e-05, 1.8843e-05, 3.0462e-06, 1.3827e-04, 1.4640e-07, 6.0213e-06,
        9.9707e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:07,856][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ computer] are: tensor([0.1221, 0.1556, 0.0183, 0.1024, 0.0258, 0.0173, 0.0143, 0.1598, 0.0166,
        0.1256, 0.0252, 0.0154, 0.2016], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:07,858][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ computer] are: tensor([0.0517, 0.0048, 0.0157, 0.0072, 0.0208, 0.0262, 0.0393, 0.0504, 0.0899,
        0.0445, 0.2429, 0.2896, 0.1169], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:07,860][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ computer] are: tensor([0.1925, 0.0560, 0.0937, 0.0183, 0.0570, 0.0713, 0.1049, 0.0524, 0.0711,
        0.0477, 0.0362, 0.0759, 0.1231], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:07,861][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ computer] are: tensor([0.1805, 0.0863, 0.0822, 0.0837, 0.0360, 0.0689, 0.0778, 0.0781, 0.0693,
        0.0792, 0.0581, 0.0841, 0.0160], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:07,861][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ computer] are: tensor([0.1493, 0.0596, 0.0823, 0.0378, 0.0344, 0.0671, 0.0762, 0.0373, 0.0580,
        0.0409, 0.0313, 0.0572, 0.2687], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:07,862][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ computer] are: tensor([0.2594, 0.0552, 0.0906, 0.0422, 0.0498, 0.0800, 0.0336, 0.0678, 0.1115,
        0.0517, 0.0708, 0.0350, 0.0526], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:07,862][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.2454, 0.0477, 0.0258, 0.0489, 0.1444, 0.0139, 0.0313, 0.0616, 0.0273,
        0.0568, 0.1549, 0.0313, 0.0921, 0.0185], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:07,862][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ to] are: tensor([2.8453e-03, 1.0105e-04, 2.1800e-02, 3.5192e-05, 2.6967e-04, 4.6074e-01,
        1.1718e-03, 1.1463e-04, 4.8520e-03, 3.5308e-05, 3.8290e-04, 7.0097e-04,
        3.6335e-05, 5.0691e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:07,863][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.2048, 0.0258, 0.1012, 0.0274, 0.0566, 0.1536, 0.0300, 0.0158, 0.0605,
        0.0200, 0.0696, 0.0269, 0.0312, 0.1766], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:07,864][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ to] are: tensor([4.3622e-03, 1.2843e-04, 2.0889e-04, 1.8043e-05, 3.0383e-03, 2.1426e-03,
        2.6693e-03, 6.3275e-04, 7.1099e-03, 3.1378e-03, 2.6901e-01, 7.4935e-02,
        1.8132e-02, 6.1448e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:07,867][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0367, 0.0029, 0.0032, 0.0017, 0.0611, 0.0119, 0.0072, 0.0168, 0.0105,
        0.0174, 0.3386, 0.0759, 0.1827, 0.2334], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:07,867][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0218, 0.0110, 0.0615, 0.0021, 0.0087, 0.3797, 0.1409, 0.0015, 0.0137,
        0.0030, 0.0043, 0.0957, 0.0039, 0.2521], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:07,868][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1031, 0.0772, 0.0046, 0.0489, 0.0305, 0.1367, 0.0029, 0.0614, 0.0035,
        0.1029, 0.0467, 0.0050, 0.1265, 0.2499], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:07,868][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0275, 0.0041, 0.0065, 0.0051, 0.0131, 0.0090, 0.0202, 0.0153, 0.0518,
        0.0546, 0.1258, 0.1710, 0.1939, 0.3022], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:07,869][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0133, 0.0031, 0.0877, 0.0043, 0.0194, 0.1196, 0.1617, 0.0096, 0.1380,
        0.0047, 0.0187, 0.1896, 0.0112, 0.2191], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:07,869][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.1595, 0.0430, 0.0913, 0.0524, 0.0487, 0.0872, 0.0779, 0.0372, 0.0729,
        0.0385, 0.0644, 0.0828, 0.0410, 0.1031], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:07,870][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.1277, 0.0340, 0.1099, 0.0278, 0.0679, 0.1230, 0.0855, 0.0287, 0.0784,
        0.0245, 0.0603, 0.0841, 0.0339, 0.1142], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:07,873][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.1700, 0.0590, 0.0773, 0.0371, 0.0636, 0.0766, 0.0373, 0.0608, 0.0807,
        0.0645, 0.0854, 0.0498, 0.0588, 0.0791], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:07,892][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:20:07,892][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:07,893][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:07,893][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:07,893][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:07,894][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:07,894][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:07,894][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:07,894][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:07,895][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:07,895][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:07,895][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:07,898][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:07,898][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Benjamin] are: tensor([0.8183, 0.1817], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:07,898][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Benjamin] are: tensor([6.2538e-04, 9.9937e-01], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:07,899][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Benjamin] are: tensor([0.8797, 0.1203], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:07,899][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Benjamin] are: tensor([0.1231, 0.8769], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:07,899][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Benjamin] are: tensor([0.3480, 0.6520], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:07,899][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Benjamin] are: tensor([0.0271, 0.9729], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:07,900][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Benjamin] are: tensor([0.6174, 0.3826], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:07,900][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Benjamin] are: tensor([0.9223, 0.0777], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:07,900][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Benjamin] are: tensor([0.7616, 0.2384], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:07,903][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Benjamin] are: tensor([0.9496, 0.0504], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:07,905][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Benjamin] are: tensor([0.6785, 0.3215], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:07,905][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Benjamin] are: tensor([0.7509, 0.2491], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:07,905][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.7969, 0.1355, 0.0675], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:07,905][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([4.4099e-03, 4.6795e-04, 9.9512e-01], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:07,906][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.4097, 0.0612, 0.5291], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:07,906][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.2514, 0.0119, 0.7367], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:07,906][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.6844, 0.1153, 0.2003], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:07,906][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.1826, 0.0143, 0.8031], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:07,907][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.5948, 0.3836, 0.0216], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:07,907][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.4940, 0.2521, 0.2539], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:07,909][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.2531, 0.0421, 0.7048], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:07,911][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.6193, 0.1254, 0.2553], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:07,912][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.6686, 0.0977, 0.2337], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:07,912][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.5429, 0.1165, 0.3407], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:07,912][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Alexander] are: tensor([0.3511, 0.1805, 0.2706, 0.1979], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:07,912][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Alexander] are: tensor([1.1963e-03, 4.1999e-03, 3.5199e-04, 9.9425e-01], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:07,913][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Alexander] are: tensor([0.6010, 0.1056, 0.0793, 0.2141], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:07,913][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Alexander] are: tensor([2.1888e-03, 1.0657e-02, 5.5184e-05, 9.8710e-01], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:07,913][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Alexander] are: tensor([0.0587, 0.0935, 0.0068, 0.8411], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:07,914][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Alexander] are: tensor([7.3493e-03, 6.6297e-04, 4.8928e-06, 9.9198e-01], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:07,914][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Alexander] are: tensor([0.2588, 0.5092, 0.0681, 0.1639], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:07,916][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Alexander] are: tensor([0.2317, 0.2912, 0.3401, 0.1369], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:07,918][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Alexander] are: tensor([0.4557, 0.3118, 0.1447, 0.0878], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:07,918][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Alexander] are: tensor([0.5631, 0.1694, 0.2396, 0.0279], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:07,919][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Alexander] are: tensor([0.3909, 0.2087, 0.1435, 0.2569], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:07,919][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Alexander] are: tensor([0.3292, 0.1709, 0.4000, 0.0999], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:07,919][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([0.4765, 0.0679, 0.0843, 0.1085, 0.2629], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:07,919][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([1.1730e-03, 3.3773e-04, 1.7646e-03, 3.5019e-04, 9.9637e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:07,920][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([0.6048, 0.0507, 0.1913, 0.0665, 0.0867], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:07,920][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([3.0824e-02, 3.7625e-04, 2.0196e-03, 8.7323e-04, 9.6591e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:07,920][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([0.3738, 0.0267, 0.0548, 0.1720, 0.3727], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:07,921][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([2.6719e-02, 3.0249e-05, 6.5631e-05, 4.7681e-05, 9.7314e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:07,925][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([0.3021, 0.2970, 0.0458, 0.3101, 0.0449], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:07,925][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([0.2006, 0.0884, 0.2133, 0.3201, 0.1776], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:07,925][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([0.4003, 0.0844, 0.3898, 0.0603, 0.0652], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:07,926][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([0.4339, 0.1145, 0.2121, 0.1229, 0.1166], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:07,926][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([0.4195, 0.0847, 0.1889, 0.0429, 0.2639], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:07,926][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([0.4838, 0.0920, 0.2409, 0.0615, 0.1218], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:07,927][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.4638, 0.0995, 0.0624, 0.0901, 0.2509, 0.0333], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:07,927][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([5.9630e-03, 4.1575e-04, 6.7588e-02, 1.3395e-04, 8.4857e-04, 9.2505e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:07,927][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.3967, 0.0459, 0.1787, 0.0430, 0.0805, 0.2552], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:07,929][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0326, 0.0078, 0.0213, 0.0025, 0.4629, 0.4729], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:07,932][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.1576, 0.0302, 0.0265, 0.0228, 0.6295, 0.1333], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:07,932][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0827, 0.0245, 0.1440, 0.0059, 0.0154, 0.7275], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:07,932][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.2729, 0.2010, 0.0150, 0.1063, 0.0711, 0.3338], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:07,932][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.1441, 0.0662, 0.1227, 0.0977, 0.3131, 0.2562], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:07,933][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0606, 0.0138, 0.3499, 0.0151, 0.0655, 0.4952], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:07,933][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.3585, 0.0797, 0.1919, 0.0921, 0.0901, 0.1876], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:07,933][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.3529, 0.0733, 0.2434, 0.0414, 0.0912, 0.1979], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:07,934][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.3377, 0.1044, 0.1794, 0.0705, 0.1240, 0.1840], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:07,934][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.5364, 0.1220, 0.0471, 0.0878, 0.1438, 0.0248, 0.0380],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:07,935][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([9.1017e-03, 1.3035e-03, 6.6695e-02, 1.2241e-03, 1.9109e-04, 8.7241e-02,
        8.3424e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:07,938][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.3359, 0.0576, 0.1431, 0.0372, 0.1105, 0.2754, 0.0403],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:07,939][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0505, 0.0103, 0.0233, 0.0121, 0.0852, 0.1823, 0.6363],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:07,939][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.2870, 0.0456, 0.0399, 0.0951, 0.2769, 0.1188, 0.1366],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:07,939][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.1750, 0.0362, 0.1483, 0.0165, 0.0401, 0.1319, 0.4519],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:07,940][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.3063, 0.3456, 0.0071, 0.2398, 0.0857, 0.0113, 0.0042],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:07,940][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.1189, 0.0308, 0.0828, 0.0857, 0.1469, 0.2299, 0.3049],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:07,940][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0305, 0.0074, 0.1958, 0.0152, 0.0524, 0.2097, 0.4890],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:07,941][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.3293, 0.0733, 0.1605, 0.0711, 0.0805, 0.1561, 0.1293],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:07,941][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.3563, 0.0708, 0.1711, 0.0557, 0.0453, 0.1162, 0.1846],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:07,943][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.2795, 0.0955, 0.1464, 0.0708, 0.1064, 0.1421, 0.1593],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:07,945][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ station] are: tensor([0.2575, 0.1962, 0.1146, 0.1396, 0.0653, 0.0554, 0.0875, 0.0838],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:07,945][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ station] are: tensor([5.8236e-04, 4.4617e-03, 4.0125e-03, 1.8105e-04, 1.0896e-03, 1.8377e-03,
        4.8264e-04, 9.8735e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:07,946][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ station] are: tensor([0.2708, 0.1811, 0.0794, 0.0854, 0.0694, 0.0837, 0.0674, 0.1628],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:07,946][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ station] are: tensor([1.2288e-02, 3.9139e-04, 1.7966e-04, 1.3702e-03, 6.2819e-03, 1.4383e-03,
        9.7179e-04, 9.7708e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:07,946][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ station] are: tensor([0.0625, 0.0115, 0.0059, 0.0063, 0.0331, 0.0110, 0.0179, 0.8519],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:07,947][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ station] are: tensor([1.2827e-02, 7.5131e-04, 1.8602e-05, 4.4947e-05, 5.4310e-05, 3.4121e-06,
        4.1123e-06, 9.8630e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:07,947][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ station] are: tensor([0.2231, 0.3023, 0.0378, 0.1564, 0.0237, 0.0250, 0.0317, 0.1999],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:07,947][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ station] are: tensor([0.0706, 0.0047, 0.0530, 0.0478, 0.1118, 0.2027, 0.3421, 0.1671],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:07,948][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ station] are: tensor([0.2195, 0.1001, 0.1488, 0.0846, 0.0572, 0.1331, 0.1040, 0.1528],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:07,950][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ station] are: tensor([0.2689, 0.1875, 0.1372, 0.0713, 0.0805, 0.1160, 0.1222, 0.0164],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:07,952][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ station] are: tensor([0.1609, 0.0861, 0.1472, 0.0522, 0.0593, 0.1103, 0.1023, 0.2816],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:07,952][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ station] are: tensor([0.2392, 0.0741, 0.1090, 0.0634, 0.0962, 0.1684, 0.0490, 0.2005],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:07,953][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.4633, 0.0906, 0.0213, 0.0902, 0.1252, 0.0195, 0.0619, 0.1137, 0.0143],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:07,953][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([3.4321e-03, 3.6751e-04, 2.5582e-02, 1.2650e-04, 5.2712e-04, 9.1319e-03,
        1.2521e-03, 1.1308e-04, 9.5947e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:07,953][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.2794, 0.0243, 0.1222, 0.0162, 0.0482, 0.0617, 0.0140, 0.0118, 0.4221],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:07,954][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0515, 0.0014, 0.0081, 0.0017, 0.0736, 0.0445, 0.1175, 0.0662, 0.6355],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:07,954][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.5264, 0.0363, 0.0156, 0.0122, 0.0731, 0.0527, 0.0288, 0.0766, 0.1782],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:07,954][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.1331, 0.0398, 0.1914, 0.0414, 0.0575, 0.0951, 0.1419, 0.0189, 0.2809],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:07,955][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.3208, 0.2788, 0.0112, 0.1169, 0.0690, 0.0221, 0.0073, 0.1671, 0.0068],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:07,959][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0523, 0.0244, 0.0332, 0.0629, 0.0676, 0.0889, 0.1752, 0.1545, 0.3410],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:07,959][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0342, 0.0072, 0.1778, 0.0081, 0.0215, 0.1578, 0.2310, 0.0122, 0.3502],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:07,959][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.2681, 0.0796, 0.1360, 0.0685, 0.0727, 0.1261, 0.0999, 0.0465, 0.1027],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:07,960][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.2338, 0.0795, 0.1682, 0.0549, 0.0715, 0.1394, 0.1015, 0.0378, 0.1134],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:07,960][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.2491, 0.0755, 0.1225, 0.0526, 0.0922, 0.1120, 0.0637, 0.0961, 0.1365],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:07,960][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Benjamin] are: tensor([0.2366, 0.1103, 0.1037, 0.0572, 0.0409, 0.0992, 0.0686, 0.0898, 0.1092,
        0.0845], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:07,961][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Benjamin] are: tensor([9.5941e-05, 5.0581e-01, 3.3352e-05, 9.7520e-04, 2.2109e-05, 4.9386e-05,
        4.5377e-05, 4.2831e-05, 5.7306e-06, 4.9292e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:07,961][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Benjamin] are: tensor([0.2978, 0.1534, 0.0639, 0.0829, 0.0393, 0.0605, 0.0710, 0.0991, 0.0410,
        0.0910], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:07,961][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Benjamin] are: tensor([1.5600e-03, 3.6802e-03, 2.8850e-06, 1.8834e-03, 7.3738e-06, 3.1812e-05,
        6.2872e-05, 2.3887e-04, 6.8927e-05, 9.9246e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:07,963][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Benjamin] are: tensor([1.1443e-02, 5.5552e-02, 8.5728e-04, 2.9520e-03, 1.0033e-03, 2.4364e-03,
        1.1006e-03, 2.4236e-03, 5.4999e-03, 9.1673e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:07,965][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Benjamin] are: tensor([2.3013e-03, 7.3642e-01, 1.4848e-07, 5.1413e-05, 6.9578e-08, 3.6578e-08,
        3.4019e-08, 9.0156e-07, 7.1354e-09, 2.6122e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:07,966][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Benjamin] are: tensor([0.1599, 0.2545, 0.0610, 0.0994, 0.0142, 0.0139, 0.0577, 0.0785, 0.0577,
        0.2032], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:07,966][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Benjamin] are: tensor([0.0639, 0.0236, 0.0338, 0.0495, 0.0338, 0.1028, 0.1285, 0.1139, 0.2330,
        0.2171], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:07,966][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Benjamin] are: tensor([0.2296, 0.1579, 0.0933, 0.0626, 0.0482, 0.0782, 0.0660, 0.0376, 0.0922,
        0.1343], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:07,967][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Benjamin] are: tensor([0.3122, 0.0226, 0.1278, 0.0538, 0.0768, 0.0978, 0.1122, 0.0728, 0.1108,
        0.0131], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:07,967][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Benjamin] are: tensor([0.1531, 0.3002, 0.0834, 0.0759, 0.0238, 0.0537, 0.0517, 0.0181, 0.0484,
        0.1918], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:07,967][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Benjamin] are: tensor([0.1300, 0.0749, 0.1298, 0.0445, 0.1057, 0.1139, 0.0693, 0.1070, 0.1337,
        0.0913], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:07,968][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.2853, 0.0237, 0.0344, 0.0750, 0.2309, 0.0225, 0.0212, 0.0508, 0.0246,
        0.0227, 0.2088], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:07,968][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([9.4645e-04, 1.2041e-03, 2.3578e-03, 2.3586e-04, 8.8412e-03, 1.1975e-03,
        3.2204e-04, 1.6754e-04, 3.6756e-04, 4.6144e-04, 9.8390e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:07,972][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.3394, 0.0383, 0.0823, 0.0472, 0.0950, 0.1255, 0.0812, 0.0174, 0.0510,
        0.0277, 0.0951], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:07,972][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([2.3838e-03, 2.3405e-05, 2.9771e-05, 6.1147e-06, 1.0941e-03, 1.3014e-04,
        1.9857e-04, 5.5547e-04, 1.7803e-03, 1.6690e-03, 9.9213e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:07,973][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.1394, 0.0185, 0.0145, 0.0164, 0.0399, 0.0328, 0.0216, 0.0245, 0.0469,
        0.0765, 0.5689], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:07,973][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([4.7300e-02, 3.3997e-04, 3.9505e-05, 9.8320e-05, 1.0252e-02, 4.1298e-06,
        1.4027e-05, 2.1773e-06, 1.9010e-06, 3.7154e-05, 9.4191e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:07,973][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.1871, 0.1541, 0.0260, 0.1253, 0.0412, 0.0188, 0.0248, 0.1719, 0.0208,
        0.1855, 0.0444], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:07,974][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0526, 0.0102, 0.0234, 0.0231, 0.0266, 0.0533, 0.0892, 0.0523, 0.2190,
        0.1727, 0.2775], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:07,974][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.1348, 0.0325, 0.1465, 0.0153, 0.0491, 0.1394, 0.1907, 0.0383, 0.1707,
        0.0351, 0.0476], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:07,974][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.1928, 0.0749, 0.1023, 0.0663, 0.0836, 0.0996, 0.0816, 0.0603, 0.0903,
        0.0748, 0.0735], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:07,976][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.1630, 0.0753, 0.0965, 0.0440, 0.1028, 0.0919, 0.0648, 0.0250, 0.0702,
        0.0561, 0.2106], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:07,979][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.3029, 0.0489, 0.1276, 0.0320, 0.0512, 0.1082, 0.0480, 0.0511, 0.1052,
        0.0473, 0.0777], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:07,979][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.3166, 0.0825, 0.0298, 0.0508, 0.0778, 0.0192, 0.0355, 0.0777, 0.0307,
        0.0970, 0.1537, 0.0286], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:07,980][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([3.0347e-03, 1.6570e-03, 3.7301e-03, 4.8766e-04, 1.0824e-04, 9.8385e-03,
        3.0977e-02, 5.2401e-05, 1.0093e-03, 6.6312e-04, 2.1886e-04, 9.4822e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:07,980][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.1980, 0.0370, 0.1290, 0.0304, 0.0892, 0.2091, 0.0295, 0.0191, 0.0851,
        0.0322, 0.1139, 0.0274], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:07,980][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([1.2209e-02, 4.0394e-04, 9.5837e-04, 2.5434e-04, 2.0133e-03, 4.1563e-03,
        1.6370e-02, 7.3955e-03, 5.0113e-02, 1.7264e-02, 1.3623e-01, 7.5263e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:07,981][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0627, 0.0063, 0.0063, 0.0083, 0.0642, 0.0167, 0.0179, 0.0175, 0.0323,
        0.0381, 0.5445, 0.1852], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:07,981][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0642, 0.0157, 0.1024, 0.0129, 0.0108, 0.0907, 0.2202, 0.0021, 0.0307,
        0.0034, 0.0073, 0.4396], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:07,981][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.1705, 0.1628, 0.0049, 0.1030, 0.0706, 0.0091, 0.0037, 0.1399, 0.0034,
        0.2353, 0.0907, 0.0061], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:07,984][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0365, 0.0053, 0.0118, 0.0069, 0.0247, 0.0238, 0.0415, 0.0341, 0.1224,
        0.0937, 0.3018, 0.2975], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:07,986][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0159, 0.0035, 0.0798, 0.0059, 0.0220, 0.0965, 0.2265, 0.0124, 0.1530,
        0.0060, 0.0279, 0.3506], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:07,986][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.1942, 0.0509, 0.1108, 0.0549, 0.0555, 0.1060, 0.0903, 0.0434, 0.0872,
        0.0436, 0.0723, 0.0908], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:07,986][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.1802, 0.0547, 0.1153, 0.0382, 0.0399, 0.1073, 0.1148, 0.0292, 0.0754,
        0.0365, 0.0417, 0.1670], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:07,987][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.1917, 0.0668, 0.0839, 0.0440, 0.0661, 0.0930, 0.0505, 0.0693, 0.0959,
        0.0772, 0.0923, 0.0692], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:07,987][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ computer] are: tensor([0.2282, 0.0727, 0.0719, 0.0562, 0.0751, 0.0416, 0.0334, 0.0794, 0.0717,
        0.0620, 0.0645, 0.0450, 0.0985], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:07,987][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ computer] are: tensor([1.9937e-04, 1.8101e-03, 6.3471e-04, 9.9254e-05, 2.8511e-04, 5.0036e-04,
        4.0996e-04, 3.6566e-04, 2.4234e-04, 6.5938e-04, 5.4591e-05, 1.2953e-04,
        9.9461e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:07,988][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ computer] are: tensor([0.2554, 0.0634, 0.0731, 0.0561, 0.0438, 0.0756, 0.0828, 0.0378, 0.0347,
        0.0461, 0.0517, 0.0736, 0.1059], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:07,988][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ computer] are: tensor([4.7062e-04, 1.8193e-05, 1.0506e-06, 9.3066e-06, 8.5852e-06, 8.1228e-06,
        1.3752e-05, 1.2851e-04, 2.9195e-05, 2.5117e-03, 9.5646e-04, 3.6131e-04,
        9.9548e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:07,991][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ computer] are: tensor([0.0499, 0.0035, 0.0017, 0.0070, 0.0019, 0.0029, 0.0043, 0.0047, 0.0072,
        0.0096, 0.0166, 0.0223, 0.8682], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:07,992][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ computer] are: tensor([1.7272e-03, 8.9261e-04, 8.3428e-06, 1.1599e-04, 8.1765e-06, 1.3748e-06,
        1.3573e-05, 1.8843e-05, 3.0462e-06, 1.3827e-04, 1.4640e-07, 6.0213e-06,
        9.9707e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:07,993][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ computer] are: tensor([0.1221, 0.1556, 0.0183, 0.1024, 0.0258, 0.0173, 0.0143, 0.1598, 0.0166,
        0.1256, 0.0252, 0.0154, 0.2016], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:07,993][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ computer] are: tensor([0.0517, 0.0048, 0.0157, 0.0072, 0.0208, 0.0262, 0.0393, 0.0504, 0.0899,
        0.0445, 0.2429, 0.2896, 0.1169], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:07,994][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ computer] are: tensor([0.1925, 0.0560, 0.0937, 0.0183, 0.0570, 0.0713, 0.1049, 0.0524, 0.0711,
        0.0477, 0.0362, 0.0759, 0.1231], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:07,994][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ computer] are: tensor([0.1805, 0.0863, 0.0822, 0.0837, 0.0360, 0.0689, 0.0778, 0.0781, 0.0693,
        0.0792, 0.0581, 0.0841, 0.0160], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:07,994][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ computer] are: tensor([0.1493, 0.0596, 0.0823, 0.0378, 0.0344, 0.0671, 0.0762, 0.0373, 0.0580,
        0.0409, 0.0313, 0.0572, 0.2687], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:07,995][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ computer] are: tensor([0.2594, 0.0552, 0.0906, 0.0422, 0.0498, 0.0800, 0.0336, 0.0678, 0.1115,
        0.0517, 0.0708, 0.0350, 0.0526], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:07,995][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.2454, 0.0477, 0.0258, 0.0489, 0.1444, 0.0139, 0.0313, 0.0616, 0.0273,
        0.0568, 0.1549, 0.0313, 0.0921, 0.0185], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:07,996][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([2.8453e-03, 1.0105e-04, 2.1800e-02, 3.5192e-05, 2.6967e-04, 4.6074e-01,
        1.1718e-03, 1.1463e-04, 4.8520e-03, 3.5308e-05, 3.8290e-04, 7.0097e-04,
        3.6335e-05, 5.0691e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:07,999][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.2048, 0.0258, 0.1012, 0.0274, 0.0566, 0.1536, 0.0300, 0.0158, 0.0605,
        0.0200, 0.0696, 0.0269, 0.0312, 0.1766], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:08,000][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([4.3622e-03, 1.2843e-04, 2.0889e-04, 1.8043e-05, 3.0383e-03, 2.1426e-03,
        2.6693e-03, 6.3275e-04, 7.1099e-03, 3.1378e-03, 2.6901e-01, 7.4935e-02,
        1.8132e-02, 6.1448e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:08,000][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0367, 0.0029, 0.0032, 0.0017, 0.0611, 0.0119, 0.0072, 0.0168, 0.0105,
        0.0174, 0.3386, 0.0759, 0.1827, 0.2334], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:08,000][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0218, 0.0110, 0.0615, 0.0021, 0.0087, 0.3797, 0.1409, 0.0015, 0.0137,
        0.0030, 0.0043, 0.0957, 0.0039, 0.2521], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:08,001][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.1031, 0.0772, 0.0046, 0.0489, 0.0305, 0.1367, 0.0029, 0.0614, 0.0035,
        0.1029, 0.0467, 0.0050, 0.1265, 0.2499], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:08,001][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0275, 0.0041, 0.0065, 0.0051, 0.0131, 0.0090, 0.0202, 0.0153, 0.0518,
        0.0546, 0.1258, 0.1710, 0.1939, 0.3022], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:08,001][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0133, 0.0031, 0.0877, 0.0043, 0.0194, 0.1196, 0.1617, 0.0096, 0.1380,
        0.0047, 0.0187, 0.1896, 0.0112, 0.2191], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:08,002][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.1595, 0.0430, 0.0913, 0.0524, 0.0487, 0.0872, 0.0779, 0.0372, 0.0729,
        0.0385, 0.0644, 0.0828, 0.0410, 0.1031], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:08,004][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.1277, 0.0340, 0.1099, 0.0278, 0.0679, 0.1230, 0.0855, 0.0287, 0.0784,
        0.0245, 0.0603, 0.0841, 0.0339, 0.1142], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:08,006][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.1700, 0.0590, 0.0773, 0.0371, 0.0636, 0.0766, 0.0373, 0.0608, 0.0807,
        0.0645, 0.0854, 0.0498, 0.0588, 0.0791], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:08,007][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:20:08,008][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 8185],
        [  100],
        [ 9435],
        [    1],
        [14521],
        [ 8718],
        [16020],
        [ 9361],
        [ 8696],
        [   85],
        [13037],
        [20081],
        [21950],
        [ 8152]], device='cuda:0')
[2024-07-24 10:20:08,009][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[34411],
        [  174],
        [30077],
        [    1],
        [40596],
        [33871],
        [19020],
        [35676],
        [25665],
        [  190],
        [23355],
        [16253],
        [25635],
        [24141]], device='cuda:0')
[2024-07-24 10:20:08,011][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[3545],
        [1374],
        [1949],
        [1370],
        [4889],
        [4995],
        [2731],
        [1613],
        [1661],
        [4024],
        [8466],
        [1818],
        [3962],
        [5964]], device='cuda:0')
[2024-07-24 10:20:08,014][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[21302],
        [17352],
        [17007],
        [15608],
        [10300],
        [25511],
        [46608],
        [14562],
        [ 4716],
        [13986],
        [17054],
        [45721],
        [34792],
        [24398]], device='cuda:0')
[2024-07-24 10:20:08,014][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[20383],
        [19617],
        [31296],
        [20218],
        [25798],
        [33742],
        [34147],
        [28793],
        [26612],
        [25188],
        [28804],
        [32745],
        [27874],
        [35524]], device='cuda:0')
[2024-07-24 10:20:08,015][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[39074],
        [11235],
        [26233],
        [ 1933],
        [21088],
        [13457],
        [13780],
        [29524],
        [20639],
        [ 5677],
        [40315],
        [ 8859],
        [19577],
        [14855]], device='cuda:0')
[2024-07-24 10:20:08,016][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[27863],
        [ 5633],
        [20128],
        [  794],
        [16536],
        [27150],
        [17933],
        [28295],
        [23600],
        [ 2439],
        [22097],
        [25532],
        [ 6261],
        [18170]], device='cuda:0')
[2024-07-24 10:20:08,018][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[40271],
        [34547],
        [35689],
        [ 8089],
        [27838],
        [32462],
        [30239],
        [44848],
        [32344],
        [33967],
        [28411],
        [23236],
        [24113],
        [27662]], device='cuda:0')
[2024-07-24 10:20:08,021][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[31465],
        [15009],
        [14317],
        [ 3159],
        [ 1065],
        [ 3455],
        [ 1635],
        [ 3338],
        [ 5392],
        [ 2401],
        [ 3059],
        [ 3749],
        [12492],
        [ 5510]], device='cuda:0')
[2024-07-24 10:20:08,022][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[ 3371],
        [ 2749],
        [ 3624],
        [ 6137],
        [ 7394],
        [ 7888],
        [19104],
        [26498],
        [16982],
        [10144],
        [ 6773],
        [16969],
        [20076],
        [12695]], device='cuda:0')
[2024-07-24 10:20:08,022][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[ 4144],
        [ 4868],
        [11520],
        [ 5917],
        [ 6130],
        [13521],
        [10519],
        [ 8744],
        [15528],
        [ 8128],
        [10675],
        [10480],
        [16204],
        [12496]], device='cuda:0')
[2024-07-24 10:20:08,023][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[22609],
        [20271],
        [23489],
        [19365],
        [15868],
        [23486],
        [25631],
        [17073],
        [26472],
        [27909],
        [20786],
        [26594],
        [15257],
        [26097]], device='cuda:0')
[2024-07-24 10:20:08,025][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[ 9874],
        [20902],
        [ 7327],
        [25641],
        [ 6436],
        [ 4120],
        [ 7128],
        [ 9295],
        [ 4261],
        [25522],
        [ 4499],
        [ 7477],
        [28338],
        [ 4329]], device='cuda:0')
[2024-07-24 10:20:08,028][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[27474],
        [27357],
        [16129],
        [12386],
        [13346],
        [10090],
        [12623],
        [14434],
        [12962],
        [11515],
        [10825],
        [ 9797],
        [11623],
        [ 8196]], device='cuda:0')
[2024-07-24 10:20:08,029][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[26563],
        [  270],
        [24986],
        [    2],
        [41400],
        [14372],
        [19941],
        [30741],
        [11284],
        [  257],
        [46091],
        [27751],
        [42257],
        [13107]], device='cuda:0')
[2024-07-24 10:20:08,030][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[20833],
        [22409],
        [22869],
        [19297],
        [19204],
        [20204],
        [20806],
        [20560],
        [21551],
        [23364],
        [17573],
        [22304],
        [22112],
        [19102]], device='cuda:0')
[2024-07-24 10:20:08,030][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[ 4876],
        [29729],
        [20443],
        [11674],
        [25485],
        [ 6343],
        [ 3259],
        [13545],
        [25127],
        [24935],
        [24202],
        [ 3251],
        [ 8647],
        [ 6000]], device='cuda:0')
[2024-07-24 10:20:08,032][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[42572],
        [43417],
        [34277],
        [42895],
        [40682],
        [38084],
        [38400],
        [42242],
        [33572],
        [44516],
        [39948],
        [37906],
        [41789],
        [37669]], device='cuda:0')
[2024-07-24 10:20:08,035][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[28308],
        [28165],
        [29864],
        [31352],
        [16051],
        [22934],
        [25001],
        [15996],
        [29155],
        [32993],
        [29719],
        [32658],
        [25218],
        [34208]], device='cuda:0')
[2024-07-24 10:20:08,036][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[14314],
        [20624],
        [16605],
        [21733],
        [13916],
        [ 9733],
        [18941],
        [14782],
        [17660],
        [18074],
        [11247],
        [13139],
        [17821],
        [15837]], device='cuda:0')
[2024-07-24 10:20:08,037][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[22988],
        [18752],
        [24618],
        [34331],
        [30230],
        [27008],
        [15380],
        [ 4939],
        [19905],
        [18583],
        [21415],
        [16654],
        [20212],
        [24071]], device='cuda:0')
[2024-07-24 10:20:08,038][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[45331],
        [25831],
        [27122],
        [ 6756],
        [ 3312],
        [32908],
        [ 4864],
        [ 9729],
        [13083],
        [13821],
        [11274],
        [10350],
        [ 8234],
        [32916]], device='cuda:0')
[2024-07-24 10:20:08,039][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[14937],
        [15555],
        [12135],
        [12100],
        [14242],
        [ 3870],
        [ 8970],
        [10090],
        [ 6904],
        [12765],
        [ 8165],
        [12260],
        [13002],
        [ 9955]], device='cuda:0')
[2024-07-24 10:20:08,042][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[ 3847],
        [ 8334],
        [13049],
        [12069],
        [ 9044],
        [12881],
        [ 8859],
        [10068],
        [11964],
        [12626],
        [ 8282],
        [ 8737],
        [ 9929],
        [ 9896]], device='cuda:0')
[2024-07-24 10:20:08,043][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[20212],
        [22029],
        [30268],
        [32235],
        [35633],
        [35114],
        [33530],
        [36797],
        [34425],
        [33629],
        [38275],
        [34899],
        [38533],
        [35507]], device='cuda:0')
[2024-07-24 10:20:08,044][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[38899],
        [34212],
        [43826],
        [35874],
        [39639],
        [44736],
        [42837],
        [38770],
        [43484],
        [34185],
        [39914],
        [40278],
        [36583],
        [41820]], device='cuda:0')
[2024-07-24 10:20:08,045][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 3953],
        [ 4805],
        [ 6260],
        [24030],
        [14745],
        [27876],
        [21893],
        [27126],
        [26521],
        [28986],
        [25405],
        [26472],
        [24211],
        [24847]], device='cuda:0')
[2024-07-24 10:20:08,046][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[ 6268],
        [ 9583],
        [ 7316],
        [11200],
        [12266],
        [ 7414],
        [12101],
        [10775],
        [ 7790],
        [ 9849],
        [ 9585],
        [10661],
        [10790],
        [ 7712]], device='cuda:0')
[2024-07-24 10:20:08,050][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[11621],
        [48978],
        [13540],
        [50245],
        [ 4666],
        [24314],
        [18434],
        [10894],
        [27649],
        [49153],
        [ 1755],
        [12962],
        [ 4155],
        [25772]], device='cuda:0')
[2024-07-24 10:20:08,053][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[8126],
        [8126],
        [8126],
        [8126],
        [8126],
        [8126],
        [8126],
        [8126],
        [8126],
        [8126],
        [8126],
        [8126],
        [8126],
        [8126]], device='cuda:0')
[2024-07-24 10:20:08,055][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:20:08,056][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:08,056][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:08,056][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:08,057][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:08,057][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:08,057][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:08,057][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:08,058][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:08,058][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:08,058][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:08,059][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:08,059][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:08,059][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Benjamin] are: tensor([0.1365, 0.8635], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:08,060][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Benjamin] are: tensor([0.5147, 0.4853], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:08,060][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Benjamin] are: tensor([0.8940, 0.1060], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:08,060][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Benjamin] are: tensor([0.6727, 0.3273], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:08,061][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Benjamin] are: tensor([0.9219, 0.0781], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:08,061][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Benjamin] are: tensor([0.8622, 0.1378], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:08,061][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Benjamin] are: tensor([0.9340, 0.0660], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:08,064][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Benjamin] are: tensor([0.8991, 0.1009], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:08,066][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Benjamin] are: tensor([0.9103, 0.0897], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:08,066][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Benjamin] are: tensor([0.0012, 0.9988], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:08,066][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Benjamin] are: tensor([0.3937, 0.6063], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:08,067][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Benjamin] are: tensor([0.6137, 0.3863], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:08,067][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0287, 0.7968, 0.1745], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:08,067][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.1174, 0.8168, 0.0659], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:08,067][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.4953, 0.0849, 0.4198], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:08,068][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.4630, 0.2665, 0.2705], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:08,068][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.6910, 0.1441, 0.1649], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:08,070][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.3851, 0.0591, 0.5558], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:08,072][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.7830, 0.0896, 0.1274], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:08,073][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.6762, 0.1674, 0.1563], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:08,073][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.7363, 0.1173, 0.1464], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:08,073][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ and] are: tensor([3.4770e-04, 4.3176e-01, 5.6789e-01], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:08,073][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.2630, 0.4150, 0.3220], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:08,074][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.5781, 0.0063, 0.4156], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:08,074][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Alexander] are: tensor([0.0097, 0.3490, 0.1490, 0.4923], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:08,074][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Alexander] are: tensor([0.1576, 0.2465, 0.2919, 0.3039], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:08,075][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Alexander] are: tensor([0.3488, 0.0722, 0.4034, 0.1756], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:08,075][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Alexander] are: tensor([0.4003, 0.1788, 0.2258, 0.1951], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:08,077][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Alexander] are: tensor([0.4813, 0.0886, 0.2100, 0.2201], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:08,079][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Alexander] are: tensor([0.0245, 0.6882, 0.0556, 0.2316], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:08,079][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Alexander] are: tensor([0.0497, 0.1180, 0.0990, 0.7333], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:08,080][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Alexander] are: tensor([0.4358, 0.2391, 0.1692, 0.1559], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:08,080][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Alexander] are: tensor([0.7129, 0.0871, 0.1197, 0.0803], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:08,080][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Alexander] are: tensor([1.1210e-04, 1.7139e-01, 1.7430e-01, 6.5421e-01], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:08,081][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Alexander] are: tensor([0.1863, 0.2871, 0.2233, 0.3034], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:08,081][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Alexander] are: tensor([0.2224, 0.0284, 0.0949, 0.6544], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:08,081][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ went] are: tensor([0.0108, 0.0286, 0.0386, 0.0918, 0.8302], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:08,081][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ went] are: tensor([0.0658, 0.3553, 0.0939, 0.4533, 0.0317], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:08,082][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ went] are: tensor([0.2983, 0.0584, 0.2878, 0.1238, 0.2317], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:08,086][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ went] are: tensor([0.3081, 0.1553, 0.1651, 0.1795, 0.1920], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:08,086][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ went] are: tensor([0.3556, 0.0802, 0.1555, 0.2143, 0.1945], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:08,086][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ went] are: tensor([0.4561, 0.1300, 0.1269, 0.0259, 0.2612], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:08,087][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ went] are: tensor([0.4723, 0.0918, 0.2221, 0.1751, 0.0387], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:08,087][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ went] are: tensor([0.5146, 0.1145, 0.0962, 0.2120, 0.0627], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:08,087][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.5495, 0.0856, 0.1126, 0.0881, 0.1642], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:08,088][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ went] are: tensor([1.0883e-04, 1.8843e-01, 1.6898e-01, 6.1631e-01, 2.6165e-02],
       device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:08,088][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ went] are: tensor([0.1422, 0.2243, 0.1745, 0.2399, 0.2191], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:08,088][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ went] are: tensor([5.0592e-02, 6.1020e-04, 4.9971e-02, 3.7838e-04, 8.9845e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:08,088][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0015, 0.0133, 0.0040, 0.0093, 0.9676, 0.0044], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:08,091][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0556, 0.2024, 0.1354, 0.4412, 0.1440, 0.0215], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:08,093][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.2322, 0.0424, 0.2038, 0.0884, 0.1654, 0.2677], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:08,093][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.2646, 0.1375, 0.1283, 0.1529, 0.1704, 0.1463], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:08,093][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.1973, 0.0717, 0.1087, 0.1705, 0.1723, 0.2795], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:08,094][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ to] are: tensor([4.7397e-03, 8.8660e-04, 5.3621e-04, 2.2908e-03, 3.5739e-04, 9.9119e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:08,094][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1067, 0.2590, 0.3274, 0.1174, 0.0739, 0.1155], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:08,094][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.3472, 0.1146, 0.1011, 0.2440, 0.0400, 0.1531], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:08,095][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.4746, 0.0817, 0.1099, 0.0803, 0.1616, 0.0919], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:08,095][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ to] are: tensor([1.0166e-04, 1.7249e-01, 1.6368e-01, 5.9555e-01, 2.2717e-02, 4.5460e-02],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:08,095][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.1198, 0.1889, 0.1476, 0.2048, 0.1872, 0.1516], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:08,098][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.4245, 0.0042, 0.2097, 0.0046, 0.0054, 0.3516], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:08,099][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0084, 0.0175, 0.0331, 0.0666, 0.5346, 0.2394, 0.1004],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:08,100][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.1020, 0.1511, 0.1423, 0.1865, 0.2488, 0.1190, 0.0502],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:08,100][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.1516, 0.0308, 0.1520, 0.0667, 0.1251, 0.1932, 0.2806],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:08,100][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.2288, 0.1261, 0.1188, 0.1373, 0.1400, 0.1132, 0.1358],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:08,101][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.1685, 0.0550, 0.0926, 0.1226, 0.1415, 0.1973, 0.2224],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:08,101][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.2124, 0.1844, 0.0508, 0.0615, 0.0554, 0.3781, 0.0574],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:08,101][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0525, 0.2199, 0.1738, 0.3348, 0.0239, 0.1480, 0.0471],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:08,102][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.2771, 0.0863, 0.0604, 0.2271, 0.0617, 0.0913, 0.1961],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:08,102][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.4365, 0.0665, 0.0938, 0.0571, 0.1263, 0.0735, 0.1463],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:08,103][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ the] are: tensor([9.9674e-05, 1.5345e-01, 1.6765e-01, 5.4644e-01, 2.3907e-02, 5.0358e-02,
        5.8093e-02], device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:08,106][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.1047, 0.1668, 0.1301, 0.1796, 0.1643, 0.1329, 0.1216],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:08,107][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.2215, 0.0066, 0.1249, 0.0124, 0.0117, 0.0518, 0.5712],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:08,107][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ station] are: tensor([3.4269e-04, 1.0875e-02, 6.2137e-03, 3.3888e-02, 7.8884e-01, 8.4906e-02,
        5.8189e-02, 1.6749e-02], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:08,107][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ station] are: tensor([0.0370, 0.0972, 0.0712, 0.2978, 0.3641, 0.0360, 0.0871, 0.0095],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:08,107][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ station] are: tensor([0.1226, 0.0288, 0.1304, 0.0556, 0.1048, 0.1726, 0.2654, 0.1199],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:08,108][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ station] are: tensor([0.2455, 0.0912, 0.1186, 0.1081, 0.1225, 0.1209, 0.1055, 0.0876],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:08,108][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ station] are: tensor([0.2850, 0.0420, 0.0902, 0.0936, 0.1077, 0.1623, 0.1508, 0.0685],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:08,108][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ station] are: tensor([0.0726, 0.0769, 0.0844, 0.0200, 0.2263, 0.1951, 0.1284, 0.1963],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:08,109][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ station] are: tensor([0.0078, 0.4607, 0.1531, 0.0139, 0.0457, 0.0459, 0.0277, 0.2452],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:08,111][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ station] are: tensor([0.1905, 0.1523, 0.0764, 0.2610, 0.0278, 0.0877, 0.1293, 0.0749],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:08,113][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ station] are: tensor([0.4716, 0.0580, 0.0788, 0.0502, 0.0987, 0.0605, 0.1603, 0.0220],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:08,113][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ station] are: tensor([9.2762e-05, 1.1961e-01, 1.1569e-01, 4.7431e-01, 1.9078e-02, 2.1841e-02,
        2.7185e-02, 2.2220e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:08,114][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ station] are: tensor([0.0927, 0.1461, 0.1137, 0.1544, 0.1411, 0.1147, 0.1056, 0.1318],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:08,114][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ station] are: tensor([0.0341, 0.0032, 0.0528, 0.0034, 0.0048, 0.0382, 0.0086, 0.8548],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:08,114][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0148, 0.0539, 0.0307, 0.0862, 0.3938, 0.1210, 0.1505, 0.0855, 0.0637],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:08,115][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0373, 0.1855, 0.0869, 0.3189, 0.1748, 0.0360, 0.0700, 0.0445, 0.0460],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:08,115][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.1051, 0.0215, 0.1022, 0.0452, 0.0841, 0.1297, 0.1878, 0.0919, 0.2325],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:08,115][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.1996, 0.0897, 0.0991, 0.1004, 0.1145, 0.0991, 0.0918, 0.0955, 0.1103],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:08,116][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.1282, 0.0470, 0.0712, 0.0988, 0.1144, 0.1277, 0.1285, 0.0844, 0.1998],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:08,118][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0666, 0.0183, 0.0089, 0.0471, 0.0286, 0.0675, 0.0515, 0.0412, 0.6702],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:08,120][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0701, 0.0415, 0.0331, 0.1782, 0.0380, 0.0309, 0.0176, 0.5738, 0.0168],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:08,120][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.2451, 0.0602, 0.0507, 0.1668, 0.0363, 0.0663, 0.0934, 0.1915, 0.0897],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:08,121][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.3821, 0.0612, 0.0880, 0.0560, 0.1201, 0.0711, 0.1438, 0.0222, 0.0555],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:08,121][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [,] are: tensor([6.4784e-05, 1.0283e-01, 1.1428e-01, 4.3286e-01, 1.7808e-02, 3.6476e-02,
        3.9600e-02, 2.0429e-01, 5.1788e-02], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:08,121][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0813, 0.1301, 0.1016, 0.1414, 0.1289, 0.1038, 0.0951, 0.1224, 0.0953],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:08,121][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.3262, 0.0376, 0.1705, 0.0424, 0.0339, 0.0970, 0.0781, 0.0362, 0.1781],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:08,122][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Benjamin] are: tensor([0.0019, 0.0215, 0.0305, 0.1239, 0.3025, 0.1081, 0.1188, 0.0612, 0.1666,
        0.0650], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:08,122][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Benjamin] are: tensor([0.0348, 0.0557, 0.0850, 0.1738, 0.3010, 0.0548, 0.0704, 0.0394, 0.0936,
        0.0915], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:08,124][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Benjamin] are: tensor([0.0695, 0.0201, 0.0984, 0.0411, 0.0803, 0.1266, 0.1845, 0.0927, 0.2279,
        0.0590], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:08,127][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Benjamin] are: tensor([0.1915, 0.0726, 0.0948, 0.0860, 0.1082, 0.0919, 0.0846, 0.0846, 0.1134,
        0.0724], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:08,127][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Benjamin] are: tensor([0.1444, 0.0270, 0.0809, 0.0671, 0.0907, 0.1439, 0.1243, 0.0452, 0.2267,
        0.0499], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:08,127][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Benjamin] are: tensor([0.0102, 0.0182, 0.0099, 0.8015, 0.0017, 0.0579, 0.0059, 0.0021, 0.0687,
        0.0238], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:08,128][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Benjamin] are: tensor([0.0234, 0.0272, 0.1398, 0.1010, 0.0195, 0.2049, 0.1500, 0.0080, 0.3201,
        0.0059], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:08,128][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Benjamin] are: tensor([0.1427, 0.0229, 0.0480, 0.1233, 0.0404, 0.0723, 0.1729, 0.1689, 0.1782,
        0.0303], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:08,128][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Benjamin] are: tensor([0.4192, 0.0563, 0.0773, 0.0489, 0.0966, 0.0605, 0.1492, 0.0209, 0.0593,
        0.0118], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:08,129][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Benjamin] are: tensor([7.7953e-05, 8.9574e-02, 1.1346e-01, 3.7941e-01, 1.9854e-02, 3.3191e-02,
        3.5211e-02, 1.6455e-01, 4.8184e-02, 1.1649e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:08,129][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Benjamin] are: tensor([0.0744, 0.1163, 0.0905, 0.1242, 0.1137, 0.0921, 0.0844, 0.1062, 0.0845,
        0.1137], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:08,131][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Benjamin] are: tensor([0.0181, 0.2805, 0.0066, 0.0248, 0.0008, 0.0067, 0.0022, 0.0018, 0.2144,
        0.4441], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:08,133][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.0012, 0.0068, 0.0106, 0.0252, 0.5449, 0.0562, 0.0532, 0.0347, 0.0689,
        0.0229, 0.1752], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:08,134][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0192, 0.1426, 0.0357, 0.2731, 0.0343, 0.0189, 0.0860, 0.0270, 0.0531,
        0.2787, 0.0313], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:08,134][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0759, 0.0186, 0.0860, 0.0372, 0.0690, 0.1100, 0.1618, 0.0786, 0.1995,
        0.0513, 0.1121], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:08,134][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.1732, 0.0663, 0.0817, 0.0801, 0.0942, 0.0891, 0.0749, 0.0784, 0.1024,
        0.0685, 0.0913], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:08,135][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.1663, 0.0325, 0.0653, 0.0619, 0.0780, 0.1178, 0.0963, 0.0439, 0.1791,
        0.0696, 0.0892], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:08,135][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.1439, 0.0348, 0.0219, 0.0279, 0.2795, 0.1606, 0.0617, 0.0128, 0.1558,
        0.0168, 0.0842], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:08,135][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0412, 0.0589, 0.1000, 0.0356, 0.0853, 0.1115, 0.0791, 0.0996, 0.1718,
        0.1348, 0.0823], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:08,136][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.1787, 0.0499, 0.0512, 0.0920, 0.0324, 0.0754, 0.0965, 0.1728, 0.1670,
        0.0603, 0.0238], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:08,138][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.3189, 0.0597, 0.0809, 0.0620, 0.1190, 0.0700, 0.1527, 0.0254, 0.0582,
        0.0130, 0.0402], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:08,140][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([6.3480e-05, 1.0579e-01, 9.0458e-02, 3.7168e-01, 1.6079e-02, 2.9254e-02,
        3.0922e-02, 1.7189e-01, 3.8922e-02, 1.4296e-01, 1.9866e-03],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:08,140][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0659, 0.1051, 0.0818, 0.1134, 0.1032, 0.0836, 0.0767, 0.0980, 0.0768,
        0.1046, 0.0908], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:08,141][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([8.1464e-02, 3.9166e-03, 3.2389e-02, 1.5268e-03, 8.9609e-03, 1.5813e-02,
        2.6719e-03, 1.9960e-03, 5.3635e-02, 5.0622e-04, 7.9712e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:08,141][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0015, 0.0056, 0.0104, 0.0172, 0.3239, 0.0444, 0.0677, 0.0147, 0.0594,
        0.0205, 0.3321, 0.1025], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:08,142][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0440, 0.0843, 0.0375, 0.1164, 0.0698, 0.0444, 0.1073, 0.0311, 0.0798,
        0.1875, 0.1764, 0.0215], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:08,142][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0664, 0.0153, 0.0748, 0.0342, 0.0621, 0.0927, 0.1325, 0.0707, 0.1605,
        0.0469, 0.0943, 0.1495], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:08,142][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.1476, 0.0743, 0.0687, 0.0799, 0.0806, 0.0704, 0.0797, 0.0740, 0.0873,
        0.0774, 0.0827, 0.0772], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:08,143][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0902, 0.0252, 0.0547, 0.0566, 0.0652, 0.1093, 0.1168, 0.0599, 0.1669,
        0.0540, 0.0888, 0.1123], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:08,145][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0643, 0.0786, 0.0251, 0.0184, 0.0674, 0.1944, 0.0507, 0.0896, 0.2387,
        0.0437, 0.1110, 0.0181], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:08,147][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0620, 0.1212, 0.1384, 0.1356, 0.0399, 0.1369, 0.0564, 0.0816, 0.1237,
        0.0331, 0.0280, 0.0431], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:08,147][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.1971, 0.0556, 0.0404, 0.0940, 0.0210, 0.0715, 0.0967, 0.0992, 0.1474,
        0.0665, 0.0260, 0.0846], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:08,148][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.3767, 0.0559, 0.0768, 0.0466, 0.0984, 0.0593, 0.1328, 0.0194, 0.0519,
        0.0101, 0.0327, 0.0396], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:08,148][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ a] are: tensor([7.2306e-05, 9.8816e-02, 9.5999e-02, 3.8342e-01, 1.4933e-02, 2.2736e-02,
        2.8130e-02, 1.8801e-01, 3.3493e-02, 1.2742e-01, 1.8321e-03, 5.1395e-03],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:08,148][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0610, 0.0967, 0.0756, 0.1050, 0.0960, 0.0770, 0.0704, 0.0910, 0.0706,
        0.0968, 0.0840, 0.0758], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:08,149][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.1362, 0.0030, 0.0546, 0.0026, 0.0101, 0.0471, 0.0187, 0.0009, 0.0804,
        0.0009, 0.0024, 0.6429], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:08,149][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ computer] are: tensor([2.1183e-04, 1.1692e-02, 4.4518e-03, 2.5037e-02, 1.1695e-01, 2.5847e-02,
        4.3437e-02, 2.9541e-02, 3.3525e-02, 4.3797e-02, 1.6578e-01, 4.7324e-01,
        2.6494e-02], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:08,149][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ computer] are: tensor([0.0354, 0.0638, 0.0609, 0.1457, 0.0877, 0.0300, 0.0668, 0.0228, 0.0824,
        0.1368, 0.1272, 0.1274, 0.0130], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:08,152][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ computer] are: tensor([0.0506, 0.0149, 0.0683, 0.0291, 0.0548, 0.0866, 0.1284, 0.0640, 0.1552,
        0.0415, 0.0907, 0.1515, 0.0644], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:08,154][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ computer] are: tensor([0.1526, 0.0621, 0.0708, 0.0735, 0.0803, 0.0720, 0.0677, 0.0674, 0.0891,
        0.0627, 0.0789, 0.0654, 0.0575], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:08,154][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ computer] are: tensor([0.1222, 0.0250, 0.0636, 0.0523, 0.0556, 0.1100, 0.0883, 0.0380, 0.1725,
        0.0557, 0.0752, 0.0970, 0.0446], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:08,154][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ computer] are: tensor([0.0529, 0.0502, 0.0175, 0.0155, 0.0385, 0.0399, 0.0568, 0.3954, 0.1276,
        0.0106, 0.0100, 0.0333, 0.1519], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:08,155][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ computer] are: tensor([0.0341, 0.2886, 0.0277, 0.0281, 0.0065, 0.0183, 0.0068, 0.1028, 0.0358,
        0.0245, 0.0031, 0.0114, 0.4124], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:08,155][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ computer] are: tensor([0.1223, 0.0581, 0.0561, 0.0836, 0.0228, 0.0592, 0.0917, 0.2403, 0.1235,
        0.0314, 0.0329, 0.0606, 0.0175], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:08,155][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ computer] are: tensor([0.3738, 0.0505, 0.0710, 0.0454, 0.0875, 0.0544, 0.1403, 0.0205, 0.0555,
        0.0111, 0.0339, 0.0449, 0.0113], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:08,156][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ computer] are: tensor([7.9842e-05, 1.0032e-01, 9.4318e-02, 3.7605e-01, 1.6617e-02, 2.0206e-02,
        2.4756e-02, 1.7531e-01, 3.1456e-02, 1.2058e-01, 2.0899e-03, 4.4417e-03,
        3.3783e-02], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:08,156][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ computer] are: tensor([0.0562, 0.0884, 0.0696, 0.0943, 0.0868, 0.0707, 0.0649, 0.0816, 0.0649,
        0.0869, 0.0762, 0.0695, 0.0900], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:08,159][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ computer] are: tensor([0.0927, 0.0064, 0.0646, 0.0028, 0.0057, 0.0384, 0.0056, 0.0113, 0.1135,
        0.0011, 0.0011, 0.0040, 0.6528], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:08,160][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0007, 0.0054, 0.0019, 0.0035, 0.4733, 0.0015, 0.0144, 0.0048, 0.0144,
        0.0205, 0.3825, 0.0676, 0.0076, 0.0019], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:08,161][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0233, 0.0822, 0.0525, 0.1948, 0.0580, 0.0079, 0.0714, 0.0322, 0.0518,
        0.1565, 0.1004, 0.0934, 0.0677, 0.0079], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:08,161][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0541, 0.0133, 0.0614, 0.0279, 0.0509, 0.0766, 0.1092, 0.0573, 0.1328,
        0.0382, 0.0783, 0.1240, 0.0569, 0.1191], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:08,162][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.1364, 0.0607, 0.0588, 0.0701, 0.0793, 0.0681, 0.0625, 0.0655, 0.0764,
        0.0629, 0.0779, 0.0608, 0.0587, 0.0619], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:08,162][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0660, 0.0217, 0.0449, 0.0468, 0.0537, 0.1034, 0.0897, 0.0447, 0.1284,
        0.0432, 0.0818, 0.0939, 0.0536, 0.1283], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:08,162][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ to] are: tensor([4.4392e-04, 1.7519e-04, 4.1630e-05, 8.0781e-04, 2.2240e-04, 2.3512e-01,
        3.4763e-04, 2.2623e-04, 1.5615e-04, 1.6136e-04, 1.0779e-04, 4.3277e-04,
        1.1978e-03, 7.6056e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:08,163][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0144, 0.0683, 0.0670, 0.0379, 0.0354, 0.0210, 0.0134, 0.1024, 0.0313,
        0.0303, 0.0697, 0.0472, 0.4380, 0.0236], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:08,163][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.1217, 0.0287, 0.0266, 0.0732, 0.0157, 0.0484, 0.0589, 0.1242, 0.1110,
        0.0375, 0.0181, 0.0531, 0.1960, 0.0871], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:08,165][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.3378, 0.0570, 0.0785, 0.0497, 0.1059, 0.0623, 0.1317, 0.0203, 0.0512,
        0.0103, 0.0337, 0.0392, 0.0116, 0.0108], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:08,167][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ to] are: tensor([5.9243e-05, 1.0035e-01, 8.4547e-02, 3.7569e-01, 1.2614e-02, 1.7925e-02,
        2.1957e-02, 1.8554e-01, 2.7535e-02, 1.2590e-01, 1.4402e-03, 4.0914e-03,
        3.6705e-02, 5.6363e-03], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:08,168][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0513, 0.0811, 0.0637, 0.0890, 0.0813, 0.0653, 0.0597, 0.0781, 0.0599,
        0.0824, 0.0716, 0.0646, 0.0864, 0.0658], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:08,168][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.2378, 0.0024, 0.1298, 0.0025, 0.0036, 0.2442, 0.0069, 0.0024, 0.1001,
        0.0007, 0.0027, 0.0122, 0.0081, 0.2467], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:08,170][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:20:08,171][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:08,172][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:08,172][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:08,172][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:08,172][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:08,173][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:08,173][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:08,173][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:08,174][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:08,174][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:08,174][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:08,175][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:08,175][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Benjamin] are: tensor([0.1490, 0.8510], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:08,175][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Benjamin] are: tensor([0.2313, 0.7687], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:08,178][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Benjamin] are: tensor([0.8001, 0.1999], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:08,179][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Benjamin] are: tensor([0.7089, 0.2911], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:08,179][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Benjamin] are: tensor([0.2011, 0.7989], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:08,179][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Benjamin] are: tensor([0.5592, 0.4408], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:08,180][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Benjamin] are: tensor([5.8794e-04, 9.9941e-01], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:08,180][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Benjamin] are: tensor([0.3753, 0.6247], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:08,180][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Benjamin] are: tensor([0.8700, 0.1300], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:08,181][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Benjamin] are: tensor([0.0471, 0.9529], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:08,181][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Benjamin] are: tensor([0.1633, 0.8367], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:08,183][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Benjamin] are: tensor([0.4521, 0.5479], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:08,185][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0516, 0.6555, 0.2929], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:08,185][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.1090, 0.4743, 0.4167], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:08,186][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.3210, 0.1042, 0.5748], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:08,186][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.3547, 0.1750, 0.4703], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:08,186][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.1374, 0.5283, 0.3343], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:08,187][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0273, 0.0314, 0.9412], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:08,187][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([4.1693e-04, 9.5831e-01, 4.1268e-02], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:08,187][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.3056, 0.3851, 0.3093], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:08,187][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.7346, 0.1733, 0.0921], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:08,188][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0541, 0.6703, 0.2757], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:08,190][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.1006, 0.5526, 0.3469], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:08,192][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.1301, 0.0043, 0.8656], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:08,192][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Alexander] are: tensor([0.0212, 0.4048, 0.2138, 0.3601], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:08,192][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Alexander] are: tensor([0.0548, 0.2333, 0.3374, 0.3745], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:08,193][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Alexander] are: tensor([0.2755, 0.1237, 0.4297, 0.1711], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:08,193][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Alexander] are: tensor([0.3130, 0.1259, 0.4288, 0.1324], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:08,193][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Alexander] are: tensor([0.0836, 0.3650, 0.2335, 0.3179], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:08,194][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Alexander] are: tensor([0.0141, 0.7431, 0.1061, 0.1367], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:08,194][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Alexander] are: tensor([1.9570e-04, 2.9734e-02, 2.3980e-02, 9.4609e-01], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:08,194][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Alexander] are: tensor([0.1435, 0.3862, 0.2162, 0.2541], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:08,194][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Alexander] are: tensor([0.6626, 0.1596, 0.0588, 0.1190], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:08,197][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Alexander] are: tensor([0.0281, 0.5561, 0.3386, 0.0772], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:08,199][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Alexander] are: tensor([0.0769, 0.3684, 0.2455, 0.3092], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:08,199][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Alexander] are: tensor([0.1551, 0.0158, 0.8183, 0.0108], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:08,199][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([0.0302, 0.1523, 0.1359, 0.1963, 0.4852], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:08,200][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([0.0461, 0.2145, 0.2127, 0.3307, 0.1960], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:08,200][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([0.2366, 0.1004, 0.3856, 0.1469, 0.1305], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:08,200][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([0.2527, 0.1137, 0.3208, 0.1243, 0.1885], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:08,200][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([0.0646, 0.2729, 0.1736, 0.2425, 0.2464], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:08,201][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([0.0903, 0.1335, 0.0210, 0.0043, 0.7509], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:08,201][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([0.0038, 0.0284, 0.1041, 0.4960, 0.3676], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:08,203][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([0.1025, 0.2098, 0.1367, 0.2329, 0.3181], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:08,205][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([0.5501, 0.1478, 0.0604, 0.1009, 0.1407], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:08,206][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([0.0515, 0.5806, 0.2366, 0.0523, 0.0790], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:08,206][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([0.0533, 0.2778, 0.1778, 0.2357, 0.2554], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:08,206][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([1.1653e-01, 2.5218e-03, 8.0192e-01, 3.5112e-04, 7.8685e-02],
       device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:08,207][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0134, 0.1263, 0.0655, 0.0815, 0.6452, 0.0681], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:08,207][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0397, 0.1437, 0.1703, 0.2292, 0.1939, 0.2232], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:08,207][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1598, 0.0665, 0.2548, 0.1144, 0.0895, 0.3149], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:08,208][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.1865, 0.0892, 0.2184, 0.0937, 0.1466, 0.2656], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:08,208][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0635, 0.2230, 0.1446, 0.2086, 0.2065, 0.1539], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:08,210][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.3098, 0.2237, 0.2376, 0.0635, 0.1278, 0.0376], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:08,212][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([3.9461e-05, 1.1967e-02, 2.0706e-03, 2.7219e-01, 7.0180e-01, 1.1936e-02],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:08,212][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.1205, 0.1393, 0.1169, 0.1695, 0.2258, 0.2281], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:08,213][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.4291, 0.2166, 0.0412, 0.1334, 0.0971, 0.0826], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:08,213][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0541, 0.5606, 0.2133, 0.0488, 0.0907, 0.0325], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:08,213][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0448, 0.2357, 0.1483, 0.2056, 0.2167, 0.1488], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:08,214][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([7.0212e-02, 2.0727e-03, 3.2131e-01, 5.7810e-04, 2.4585e-03, 6.0337e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:08,214][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0197, 0.0851, 0.0905, 0.1158, 0.2914, 0.1738, 0.2237],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:08,214][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0349, 0.1082, 0.1285, 0.1561, 0.1702, 0.2088, 0.1933],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:08,215][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.1213, 0.0559, 0.1995, 0.0901, 0.0723, 0.1980, 0.2629],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:08,217][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.1440, 0.0730, 0.1816, 0.0757, 0.1091, 0.1868, 0.2298],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:08,219][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0523, 0.1968, 0.1249, 0.1852, 0.1777, 0.1266, 0.1364],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:08,219][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([4.2734e-02, 4.0155e-01, 2.9771e-01, 1.6713e-02, 3.9180e-02, 7.1887e-05,
        2.0204e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:08,220][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([8.3334e-06, 1.4767e-01, 3.9086e-03, 7.5201e-01, 7.6281e-02, 2.0122e-02,
        2.3150e-06], device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:08,220][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.1139, 0.1115, 0.0886, 0.1251, 0.1792, 0.1629, 0.2188],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:08,220][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.2810, 0.1846, 0.0365, 0.1022, 0.0656, 0.0715, 0.2586],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:08,221][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0641, 0.5033, 0.1739, 0.0392, 0.0670, 0.0215, 0.1311],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:08,221][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0397, 0.2069, 0.1310, 0.1810, 0.1881, 0.1281, 0.1251],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:08,221][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0614, 0.0034, 0.4411, 0.0018, 0.0036, 0.1801, 0.3086],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:08,221][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ station] are: tensor([0.0046, 0.0841, 0.0584, 0.0957, 0.3764, 0.1319, 0.2122, 0.0367],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:08,224][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ station] are: tensor([0.0161, 0.0792, 0.1100, 0.1530, 0.1677, 0.1891, 0.2368, 0.0481],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:08,226][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ station] are: tensor([0.1221, 0.0578, 0.1996, 0.0811, 0.0658, 0.1977, 0.1832, 0.0926],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:08,226][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ station] are: tensor([0.1608, 0.0536, 0.1892, 0.0604, 0.0985, 0.2050, 0.1856, 0.0468],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:08,226][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ station] are: tensor([0.0401, 0.1692, 0.1152, 0.1447, 0.1521, 0.1123, 0.1226, 0.1438],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:08,227][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ station] are: tensor([8.2227e-03, 8.1807e-02, 2.5792e-02, 2.0364e-03, 7.4285e-01, 7.6893e-05,
        7.0697e-02, 6.8517e-02], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:08,227][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ station] are: tensor([1.1912e-04, 1.1952e-02, 4.0126e-02, 8.2658e-02, 2.6097e-01, 1.4151e-01,
        1.3753e-04, 4.6253e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:08,227][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ station] are: tensor([0.0558, 0.1549, 0.0760, 0.1365, 0.2268, 0.1079, 0.1685, 0.0736],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:08,228][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ station] are: tensor([0.2357, 0.0940, 0.0420, 0.1054, 0.1292, 0.0731, 0.2879, 0.0326],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:08,228][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ station] are: tensor([0.0251, 0.3584, 0.2105, 0.0608, 0.0728, 0.0382, 0.1854, 0.0488],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:08,228][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ station] are: tensor([0.0338, 0.1785, 0.1176, 0.1497, 0.1594, 0.1118, 0.1053, 0.1438],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:08,230][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ station] are: tensor([7.0178e-02, 3.7937e-03, 5.5799e-01, 5.1382e-04, 1.8073e-03, 3.3814e-01,
        2.5943e-02, 1.6321e-03], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:08,233][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0178, 0.1154, 0.0670, 0.0977, 0.1941, 0.1077, 0.2053, 0.0752, 0.1197],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:08,233][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0260, 0.0927, 0.0957, 0.1363, 0.1255, 0.1361, 0.1555, 0.0615, 0.1706],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:08,233][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0795, 0.0349, 0.1265, 0.0600, 0.0563, 0.1354, 0.1432, 0.0761, 0.2880],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:08,234][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.1304, 0.0545, 0.1581, 0.0579, 0.0935, 0.1706, 0.1647, 0.0518, 0.1185],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:08,234][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0426, 0.1470, 0.0963, 0.1399, 0.1393, 0.0968, 0.1016, 0.1337, 0.1028],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:08,234][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([3.3258e-02, 6.1949e-02, 5.0826e-01, 6.1611e-02, 5.7751e-02, 1.7070e-05,
        2.5102e-01, 8.7017e-03, 1.7433e-02], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:08,234][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([5.6748e-06, 1.0525e-02, 1.3027e-03, 2.4188e-01, 5.5714e-02, 8.1328e-03,
        4.1767e-06, 6.8036e-01, 2.0691e-03], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:08,235][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0775, 0.0787, 0.0758, 0.1013, 0.1149, 0.1426, 0.1711, 0.0920, 0.1460],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:08,235][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.2643, 0.1174, 0.0406, 0.0839, 0.0780, 0.0529, 0.2325, 0.0693, 0.0610],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:08,237][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0597, 0.4553, 0.1561, 0.0365, 0.0617, 0.0221, 0.1068, 0.0193, 0.0824],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:08,239][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0300, 0.1595, 0.1023, 0.1400, 0.1495, 0.1004, 0.0948, 0.1355, 0.0880],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:08,240][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0555, 0.0034, 0.1927, 0.0013, 0.0025, 0.1106, 0.0432, 0.0008, 0.5900],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:08,240][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Benjamin] are: tensor([0.0065, 0.0733, 0.0640, 0.1104, 0.1776, 0.0879, 0.1907, 0.0445, 0.1784,
        0.0666], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:08,240][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Benjamin] are: tensor([0.0127, 0.0528, 0.0779, 0.1040, 0.1243, 0.1413, 0.1741, 0.0450, 0.1958,
        0.0722], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:08,241][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Benjamin] are: tensor([0.0771, 0.0392, 0.1517, 0.0550, 0.0562, 0.1309, 0.1203, 0.0687, 0.2379,
        0.0630], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:08,241][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Benjamin] are: tensor([0.1254, 0.0443, 0.1558, 0.0497, 0.0896, 0.1616, 0.1527, 0.0461, 0.1243,
        0.0506], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:08,241][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Benjamin] are: tensor([0.0313, 0.1302, 0.0894, 0.1183, 0.1211, 0.0874, 0.0941, 0.1132, 0.0983,
        0.1166], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:08,242][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Benjamin] are: tensor([0.1314, 0.0983, 0.1051, 0.3265, 0.0448, 0.0008, 0.1949, 0.0008, 0.0116,
        0.0858], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:08,243][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Benjamin] are: tensor([2.1235e-04, 3.2789e-02, 4.1176e-02, 6.0823e-01, 4.8085e-03, 1.3235e-01,
        2.3054e-04, 6.7006e-02, 7.9007e-03, 1.0530e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:08,246][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Benjamin] are: tensor([0.0500, 0.0966, 0.0666, 0.0970, 0.1388, 0.1060, 0.1399, 0.0895, 0.1194,
        0.0963], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:08,246][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Benjamin] are: tensor([0.2990, 0.0561, 0.0331, 0.0650, 0.0598, 0.0920, 0.2090, 0.0229, 0.1172,
        0.0459], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:08,247][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Benjamin] are: tensor([0.0137, 0.2611, 0.1665, 0.0412, 0.0527, 0.0221, 0.1794, 0.0359, 0.1987,
        0.0287], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:08,247][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Benjamin] are: tensor([0.0301, 0.1392, 0.0919, 0.1204, 0.1289, 0.0883, 0.0840, 0.1160, 0.0790,
        0.1223], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:08,247][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Benjamin] are: tensor([2.6293e-02, 1.6260e-02, 1.0820e-01, 2.8814e-04, 1.2447e-04, 7.0340e-02,
        6.0881e-03, 7.2374e-05, 7.6789e-01, 4.4478e-03], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:08,248][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.0063, 0.0528, 0.0472, 0.0625, 0.2637, 0.0847, 0.1364, 0.0433, 0.1225,
        0.0514, 0.1290], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:08,248][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0141, 0.0671, 0.0664, 0.1131, 0.0754, 0.1109, 0.1592, 0.0441, 0.1718,
        0.0921, 0.0860], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:08,248][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.0676, 0.0352, 0.1201, 0.0517, 0.0472, 0.1121, 0.1034, 0.0656, 0.2543,
        0.0657, 0.0772], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:08,250][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.1183, 0.0423, 0.1393, 0.0480, 0.0806, 0.1612, 0.1413, 0.0446, 0.1156,
        0.0501, 0.0587], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:08,253][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.0300, 0.1198, 0.0767, 0.1038, 0.1097, 0.0785, 0.0817, 0.1024, 0.0844,
        0.1056, 0.1075], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:08,253][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([6.9578e-02, 2.1690e-01, 1.9920e-02, 1.6760e-02, 2.9337e-01, 6.1048e-05,
        4.1282e-02, 8.2074e-05, 1.6327e-03, 2.3646e-01, 1.0396e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:08,254][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([3.9591e-05, 7.2260e-03, 2.0451e-02, 4.1246e-02, 5.0003e-02, 3.6242e-02,
        5.3361e-06, 3.5495e-01, 2.4859e-03, 1.3026e-01, 3.5709e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:08,254][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0468, 0.0965, 0.0577, 0.0856, 0.1479, 0.0967, 0.1222, 0.0787, 0.0956,
        0.1014, 0.0711], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:08,254][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.2790, 0.0824, 0.0316, 0.0641, 0.1042, 0.0456, 0.1742, 0.0334, 0.0721,
        0.0604, 0.0529], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:08,255][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.0366, 0.3546, 0.1534, 0.0372, 0.0539, 0.0221, 0.1188, 0.0236, 0.1069,
        0.0275, 0.0653], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:08,255][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0239, 0.1250, 0.0802, 0.1101, 0.1182, 0.0797, 0.0747, 0.1067, 0.0696,
        0.1120, 0.0999], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:08,255][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([2.7262e-02, 1.6536e-03, 1.3871e-01, 2.4624e-04, 1.1594e-03, 1.0313e-01,
        7.2912e-03, 1.3688e-04, 7.0039e-01, 5.9379e-04, 1.9421e-02],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:08,257][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0064, 0.0416, 0.0415, 0.0506, 0.1732, 0.0685, 0.1424, 0.0321, 0.1163,
        0.0486, 0.1481, 0.1307], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:08,262][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0164, 0.0566, 0.0592, 0.0855, 0.0777, 0.1028, 0.1280, 0.0421, 0.1421,
        0.0794, 0.1021, 0.1081], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:08,263][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0562, 0.0284, 0.1008, 0.0441, 0.0333, 0.1041, 0.1170, 0.0606, 0.2239,
        0.0639, 0.0587, 0.1087], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:08,263][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0944, 0.0453, 0.1104, 0.0457, 0.0657, 0.1208, 0.1411, 0.0399, 0.0926,
        0.0540, 0.0505, 0.1395], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:08,263][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0293, 0.1076, 0.0708, 0.0988, 0.0950, 0.0712, 0.0765, 0.1009, 0.0767,
        0.1005, 0.0979, 0.0749], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:08,264][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([3.5923e-02, 1.7979e-01, 3.2866e-01, 1.2674e-03, 4.5227e-02, 9.8620e-05,
        1.2095e-01, 1.1972e-03, 6.1683e-03, 2.0885e-01, 2.4377e-02, 4.7499e-02],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:08,264][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([1.4872e-06, 5.3531e-02, 1.0244e-03, 1.4027e-01, 2.5847e-02, 5.6812e-03,
        2.8056e-06, 1.9113e-01, 5.4275e-04, 4.6934e-01, 1.1263e-01, 6.7271e-06],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:08,264][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0675, 0.0672, 0.0538, 0.0713, 0.1027, 0.1031, 0.1247, 0.0567, 0.0995,
        0.0776, 0.0635, 0.1122], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:08,265][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.1824, 0.1174, 0.0208, 0.0645, 0.0572, 0.0353, 0.1188, 0.0394, 0.0348,
        0.0626, 0.0313, 0.2354], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:08,265][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0502, 0.3788, 0.1297, 0.0299, 0.0507, 0.0172, 0.0961, 0.0157, 0.0759,
        0.0232, 0.0527, 0.0799], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:08,266][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0227, 0.1171, 0.0746, 0.1024, 0.1076, 0.0729, 0.0702, 0.0989, 0.0646,
        0.1052, 0.0945, 0.0694], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:08,266][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([1.9752e-02, 1.0376e-03, 1.0586e-01, 3.4953e-04, 1.2258e-03, 8.3230e-02,
        3.2667e-02, 9.4846e-05, 5.2442e-01, 5.0119e-04, 1.7923e-03, 2.2907e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:08,269][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ computer] are: tensor([0.0023, 0.0543, 0.0311, 0.0540, 0.1312, 0.0546, 0.1184, 0.0312, 0.0916,
        0.0515, 0.1167, 0.2193, 0.0440], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:08,270][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ computer] are: tensor([0.0098, 0.0381, 0.0562, 0.0709, 0.0678, 0.0990, 0.1241, 0.0311, 0.1559,
        0.0550, 0.0906, 0.1614, 0.0400], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:08,270][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ computer] are: tensor([0.0591, 0.0336, 0.1040, 0.0495, 0.0354, 0.1066, 0.0857, 0.0606, 0.2022,
        0.0620, 0.0697, 0.0862, 0.0454], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:08,271][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ computer] are: tensor([0.0994, 0.0379, 0.1171, 0.0423, 0.0662, 0.1266, 0.1228, 0.0368, 0.0974,
        0.0437, 0.0489, 0.1213, 0.0396], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:08,271][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ computer] are: tensor([0.0237, 0.1006, 0.0674, 0.0883, 0.0883, 0.0668, 0.0714, 0.0840, 0.0758,
        0.0897, 0.0917, 0.0682, 0.0840], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:08,272][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ computer] are: tensor([2.4538e-03, 1.0716e-01, 1.9657e-02, 8.5916e-03, 1.2886e-02, 9.1778e-06,
        1.7425e-01, 4.3808e-02, 2.3170e-03, 1.4072e-01, 2.7585e-03, 1.1653e-02,
        4.7374e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:08,272][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ computer] are: tensor([1.6204e-05, 6.5990e-04, 3.1925e-03, 2.6186e-02, 8.0761e-04, 4.8078e-03,
        1.8236e-05, 2.0061e-03, 7.7447e-04, 2.6259e-03, 1.6995e-03, 3.1285e-05,
        9.5717e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:08,272][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ computer] are: tensor([0.0344, 0.0688, 0.0450, 0.0702, 0.1442, 0.0694, 0.1029, 0.0794, 0.0847,
        0.0669, 0.0832, 0.0924, 0.0583], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:08,273][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ computer] are: tensor([0.2047, 0.0561, 0.0227, 0.0471, 0.1062, 0.0300, 0.0984, 0.0294, 0.0367,
        0.0325, 0.0781, 0.2304, 0.0277], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:08,275][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ computer] are: tensor([0.0124, 0.2098, 0.1318, 0.0385, 0.0470, 0.0244, 0.1228, 0.0340, 0.1369,
        0.0276, 0.0783, 0.1157, 0.0208], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:08,277][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ computer] are: tensor([0.0206, 0.1068, 0.0687, 0.0907, 0.0974, 0.0668, 0.0642, 0.0875, 0.0594,
        0.0939, 0.0849, 0.0627, 0.0964], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:08,277][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ computer] are: tensor([1.4388e-02, 7.9654e-04, 1.5144e-01, 8.1689e-05, 3.7062e-04, 6.2716e-02,
        7.9381e-03, 5.3521e-05, 7.5241e-01, 2.5450e-04, 2.6658e-04, 4.6015e-03,
        4.6830e-03], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:08,278][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0053, 0.0570, 0.0284, 0.0330, 0.2588, 0.0267, 0.0922, 0.0244, 0.0775,
        0.0563, 0.1628, 0.1196, 0.0374, 0.0207], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:08,278][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0144, 0.0504, 0.0550, 0.0800, 0.0652, 0.0695, 0.1004, 0.0361, 0.1144,
        0.0657, 0.0787, 0.1259, 0.0605, 0.0837], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:08,278][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0419, 0.0232, 0.0723, 0.0401, 0.0326, 0.0946, 0.0948, 0.0529, 0.1782,
        0.0512, 0.0609, 0.0900, 0.0426, 0.1247], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:08,279][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0821, 0.0363, 0.0913, 0.0388, 0.0623, 0.1121, 0.1078, 0.0346, 0.0782,
        0.0430, 0.0456, 0.1070, 0.0389, 0.1222], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:08,279][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0266, 0.0901, 0.0586, 0.0844, 0.0824, 0.0617, 0.0641, 0.0832, 0.0643,
        0.0840, 0.0874, 0.0633, 0.0852, 0.0647], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:08,279][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.1661, 0.1532, 0.1381, 0.0483, 0.0901, 0.0330, 0.0466, 0.0151, 0.0005,
        0.1912, 0.0164, 0.0087, 0.0389, 0.0537], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:08,281][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([8.0606e-07, 1.4039e-04, 4.5271e-05, 2.8980e-03, 8.7808e-03, 1.4687e-04,
        2.4101e-07, 2.7441e-03, 2.6931e-05, 1.1295e-03, 2.2246e-02, 1.9167e-06,
        9.6139e-01, 4.5131e-04], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:08,284][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0488, 0.0480, 0.0448, 0.0582, 0.0795, 0.0910, 0.0980, 0.0532, 0.0948,
        0.0601, 0.0580, 0.0927, 0.0831, 0.0899], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:08,284][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.1419, 0.1235, 0.0116, 0.0720, 0.0502, 0.0267, 0.0820, 0.0467, 0.0241,
        0.0524, 0.0252, 0.2337, 0.0918, 0.0182], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:08,284][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0271, 0.3144, 0.1283, 0.0306, 0.0536, 0.0223, 0.0962, 0.0208, 0.0843,
        0.0245, 0.0638, 0.0803, 0.0142, 0.0395], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:08,285][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0194, 0.0989, 0.0626, 0.0878, 0.0915, 0.0627, 0.0588, 0.0845, 0.0548,
        0.0895, 0.0805, 0.0579, 0.0924, 0.0588], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:08,285][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([2.0374e-02, 6.1865e-04, 9.1887e-02, 2.0056e-04, 6.7352e-04, 1.7169e-01,
        1.0225e-02, 1.2466e-04, 3.6152e-01, 3.5148e-04, 8.1966e-04, 1.3063e-02,
        6.3683e-04, 3.2782e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:08,286][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:20:08,287][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[4576],
        [ 101],
        [2163],
        [   1],
        [6908],
        [1731],
        [2839],
        [1729],
        [1635],
        [  34],
        [3130],
        [5618],
        [6943],
        [1594]], device='cuda:0')
[2024-07-24 10:20:08,289][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 7065],
        [  157],
        [11773],
        [    1],
        [24303],
        [12227],
        [17233],
        [ 5490],
        [19052],
        [  217],
        [16818],
        [24034],
        [22777],
        [12342]], device='cuda:0')
[2024-07-24 10:20:08,290][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[37610],
        [ 5941],
        [ 4598],
        [ 3217],
        [ 2426],
        [ 2942],
        [ 3355],
        [ 2860],
        [ 2943],
        [ 3132],
        [ 2891],
        [ 4407],
        [13723],
        [ 3741]], device='cuda:0')
[2024-07-24 10:20:08,293][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[12296],
        [ 5924],
        [ 4744],
        [ 6297],
        [ 4709],
        [ 8085],
        [19474],
        [22176],
        [11803],
        [20774],
        [ 7167],
        [16829],
        [20673],
        [14177]], device='cuda:0')
[2024-07-24 10:20:08,293][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[25105],
        [24005],
        [14882],
        [13389],
        [12478],
        [13002],
        [12688],
        [11513],
        [12377],
        [11702],
        [11678],
        [12056],
        [11830],
        [12533]], device='cuda:0')
[2024-07-24 10:20:08,294][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[15698],
        [21785],
        [18493],
        [20019],
        [22892],
        [20121],
        [17432],
        [17930],
        [17866],
        [18801],
        [20153],
        [19482],
        [19620],
        [19120]], device='cuda:0')
[2024-07-24 10:20:08,295][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[  946],
        [  830],
        [ 2226],
        [ 2866],
        [ 2359],
        [ 6145],
        [ 6391],
        [ 5223],
        [ 9551],
        [11250],
        [ 9544],
        [11643],
        [12474],
        [16874]], device='cuda:0')
[2024-07-24 10:20:08,297][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[48319],
        [48653],
        [22992],
        [21417],
        [41118],
        [23277],
        [40395],
        [44681],
        [38004],
        [12432],
        [38809],
        [40508],
        [32439],
        [ 9562]], device='cuda:0')
[2024-07-24 10:20:08,298][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[30965],
        [31915],
        [35928],
        [16219],
        [31230],
        [35149],
        [27770],
        [38069],
        [33148],
        [43040],
        [33914],
        [36134],
        [30720],
        [26578]], device='cuda:0')
[2024-07-24 10:20:08,301][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[13510],
        [ 5590],
        [ 3751],
        [  581],
        [  559],
        [  535],
        [  238],
        [  230],
        [  615],
        [  593],
        [  680],
        [  439],
        [ 1123],
        [ 4370]], device='cuda:0')
[2024-07-24 10:20:08,302][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[4928],
        [5532],
        [6348],
        [5858],
        [6293],
        [6327],
        [5812],
        [5576],
        [5709],
        [5535],
        [5704],
        [5415],
        [5304],
        [5458]], device='cuda:0')
[2024-07-24 10:20:08,302][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[20935],
        [21331],
        [14003],
        [ 6853],
        [ 7151],
        [ 7192],
        [ 7140],
        [ 4680],
        [ 4853],
        [ 4567],
        [ 4439],
        [ 4312],
        [ 4407],
        [ 4278]], device='cuda:0')
[2024-07-24 10:20:08,303][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[8365],
        [7399],
        [7278],
        [6492],
        [6147],
        [6191],
        [6156],
        [5869],
        [5777],
        [5639],
        [5574],
        [5558],
        [5439],
        [5446]], device='cuda:0')
[2024-07-24 10:20:08,305][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[ 2798],
        [ 4748],
        [ 3728],
        [37647],
        [31982],
        [ 4817],
        [11602],
        [11190],
        [ 6807],
        [20585],
        [33248],
        [25878],
        [ 3420],
        [ 8203]], device='cuda:0')
[2024-07-24 10:20:08,306][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 4103],
        [ 2861],
        [ 3173],
        [ 8218],
        [ 9793],
        [ 6184],
        [ 8291],
        [19513],
        [ 5252],
        [15995],
        [ 9579],
        [11792],
        [21061],
        [ 8223]], device='cuda:0')
[2024-07-24 10:20:08,309][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[20391],
        [ 9104],
        [ 7715],
        [10888],
        [25409],
        [28151],
        [20248],
        [21934],
        [14984],
        [14118],
        [15871],
        [11315],
        [10150],
        [13353]], device='cuda:0')
[2024-07-24 10:20:08,309][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[5313],
        [3292],
        [4748],
        [4442],
        [3843],
        [4385],
        [3522],
        [3257],
        [4197],
        [4096],
        [3941],
        [3359],
        [3143],
        [3350]], device='cuda:0')
[2024-07-24 10:20:08,310][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[2514],
        [2186],
        [ 618],
        [ 689],
        [ 792],
        [ 375],
        [ 523],
        [ 525],
        [ 546],
        [ 533],
        [ 654],
        [ 659],
        [ 688],
        [ 515]], device='cuda:0')
[2024-07-24 10:20:08,311][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[5442],
        [7870],
        [8310],
        [8076],
        [9597],
        [8575],
        [7971],
        [7957],
        [8271],
        [8525],
        [8518],
        [8292],
        [8443],
        [8150]], device='cuda:0')
[2024-07-24 10:20:08,313][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[13968],
        [13461],
        [13450],
        [13484],
        [12071],
        [12266],
        [12359],
        [12052],
        [11989],
        [12048],
        [11727],
        [11853],
        [11567],
        [11639]], device='cuda:0')
[2024-07-24 10:20:08,314][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[23134],
        [ 7124],
        [ 5651],
        [ 8414],
        [33343],
        [11378],
        [ 6528],
        [30985],
        [ 7311],
        [11718],
        [18506],
        [ 6081],
        [19492],
        [ 8873]], device='cuda:0')
[2024-07-24 10:20:08,317][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[ 7298],
        [14793],
        [13513],
        [23765],
        [14894],
        [11439],
        [21644],
        [ 9065],
        [ 5200],
        [20152],
        [ 3898],
        [ 8047],
        [19363],
        [18870]], device='cuda:0')
[2024-07-24 10:20:08,317][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[ 1381],
        [14705],
        [ 4498],
        [ 7599],
        [ 6181],
        [ 2153],
        [ 2209],
        [ 3496],
        [ 1705],
        [ 2838],
        [ 3108],
        [ 2700],
        [ 3145],
        [ 2149]], device='cuda:0')
[2024-07-24 10:20:08,318][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[25192],
        [22449],
        [20066],
        [16914],
        [13091],
        [ 7037],
        [ 4072],
        [ 3232],
        [ 3229],
        [ 8123],
        [ 5081],
        [ 2231],
        [ 1890],
        [ 2135]], device='cuda:0')
[2024-07-24 10:20:08,319][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[ 9914],
        [24434],
        [27871],
        [30164],
        [29867],
        [30206],
        [30691],
        [33504],
        [31570],
        [34721],
        [33558],
        [32851],
        [35217],
        [33843]], device='cuda:0')
[2024-07-24 10:20:08,321][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[7062],
        [7018],
        [7466],
        [7207],
        [7582],
        [7543],
        [7600],
        [7671],
        [7722],
        [7687],
        [7746],
        [7803],
        [7839],
        [7814]], device='cuda:0')
[2024-07-24 10:20:08,322][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[23151],
        [11265],
        [17352],
        [17091],
        [16091],
        [15834],
        [12501],
        [15891],
        [19895],
        [20873],
        [20515],
        [16916],
        [20860],
        [17703]], device='cuda:0')
[2024-07-24 10:20:08,325][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[42645],
        [44907],
        [47941],
        [46191],
        [41910],
        [46758],
        [48031],
        [46715],
        [48927],
        [46173],
        [48514],
        [49175],
        [46950],
        [48132]], device='cuda:0')
[2024-07-24 10:20:08,325][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[23867],
        [36254],
        [46212],
        [25811],
        [28374],
        [39386],
        [35727],
        [21020],
        [42242],
        [12350],
        [33838],
        [33366],
        [27982],
        [38592]], device='cuda:0')
[2024-07-24 10:20:08,326][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[5268],
        [5268],
        [5268],
        [5268],
        [5268],
        [5268],
        [5268],
        [5268],
        [5268],
        [5268],
        [5268],
        [5268],
        [5268],
        [5268]], device='cuda:0')
[2024-07-24 10:20:08,353][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:20:08,356][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:08,357][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:08,357][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:08,357][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:08,358][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:08,358][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:08,358][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:08,359][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:08,359][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:08,361][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:08,363][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:08,363][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:08,364][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Benjamin] are: tensor([0.6530, 0.3470], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:08,364][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Benjamin] are: tensor([0.0353, 0.9647], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:08,364][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Benjamin] are: tensor([0.7321, 0.2679], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:08,365][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Benjamin] are: tensor([0.5410, 0.4590], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:08,365][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Benjamin] are: tensor([0.5117, 0.4883], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:08,365][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Benjamin] are: tensor([0.8374, 0.1626], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:08,365][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Benjamin] are: tensor([0.4489, 0.5511], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:08,366][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Benjamin] are: tensor([0.6918, 0.3082], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:08,368][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Benjamin] are: tensor([0.9622, 0.0378], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:08,370][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Benjamin] are: tensor([0.9494, 0.0506], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:08,370][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Benjamin] are: tensor([0.0021, 0.9979], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:08,370][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Benjamin] are: tensor([0.0951, 0.9049], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:08,371][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.4244, 0.2853, 0.2903], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:08,371][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ and] are: tensor([9.9939e-01, 6.1000e-04, 2.0765e-08], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:08,371][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0980, 0.8234, 0.0786], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:08,372][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.2488, 0.4557, 0.2954], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:08,372][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0012, 0.9969, 0.0019], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:08,372][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.2679, 0.7260, 0.0061], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:08,372][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.4773, 0.2939, 0.2288], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:08,375][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.4734, 0.2919, 0.2347], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:08,377][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.9135, 0.0245, 0.0620], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:08,377][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.9719, 0.0221, 0.0061], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:08,377][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ and] are: tensor([1.7243e-04, 2.4639e-01, 7.5343e-01], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:08,377][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0510, 0.4779, 0.4711], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:08,378][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Alexander] are: tensor([0.2878, 0.2266, 0.2321, 0.2536], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:08,378][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Alexander] are: tensor([9.7868e-01, 1.9195e-02, 4.1931e-05, 2.0878e-03], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:08,378][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Alexander] are: tensor([0.1279, 0.2477, 0.5614, 0.0629], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:08,379][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Alexander] are: tensor([0.2002, 0.2779, 0.3179, 0.2040], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:08,379][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Alexander] are: tensor([0.0157, 0.5152, 0.4020, 0.0671], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:08,379][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Alexander] are: tensor([0.0591, 0.6183, 0.3050, 0.0177], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:08,381][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Alexander] are: tensor([0.2763, 0.2845, 0.2366, 0.2025], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:08,383][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Alexander] are: tensor([0.3959, 0.2098, 0.1759, 0.2184], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:08,384][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Alexander] are: tensor([0.6856, 0.0496, 0.1783, 0.0866], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:08,384][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Alexander] are: tensor([0.9538, 0.0226, 0.0068, 0.0168], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:08,384][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Alexander] are: tensor([0.0004, 0.1681, 0.4156, 0.4159], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:08,385][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Alexander] are: tensor([0.0259, 0.2152, 0.2561, 0.5028], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:08,385][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ went] are: tensor([0.2052, 0.1828, 0.1956, 0.3101, 0.1064], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:08,385][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ went] are: tensor([9.5697e-01, 1.9535e-02, 1.0538e-03, 2.1674e-02, 7.6772e-04],
       device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:08,385][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ went] are: tensor([0.1426, 0.2617, 0.2796, 0.3113, 0.0048], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:08,386][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ went] are: tensor([0.2023, 0.1647, 0.2380, 0.2373, 0.1578], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:08,387][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ went] are: tensor([0.5330, 0.0014, 0.3858, 0.0304, 0.0494], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:08,390][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ went] are: tensor([0.0141, 0.5269, 0.3661, 0.0846, 0.0083], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:08,390][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ went] are: tensor([0.2992, 0.2805, 0.2144, 0.1537, 0.0522], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:08,391][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ went] are: tensor([0.3458, 0.1569, 0.1371, 0.1748, 0.1855], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:08,391][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.6830, 0.0364, 0.1138, 0.0549, 0.1119], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:08,391][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ went] are: tensor([0.9287, 0.0296, 0.0083, 0.0214, 0.0120], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:08,391][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ went] are: tensor([2.1542e-04, 1.0983e-01, 4.1052e-01, 3.2421e-01, 1.5524e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:08,392][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ went] are: tensor([0.0258, 0.1923, 0.2135, 0.3442, 0.2242], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:08,392][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.2194, 0.1071, 0.1629, 0.2001, 0.1139, 0.1965], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:08,392][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ to] are: tensor([9.9956e-01, 4.3086e-04, 1.5399e-08, 4.4810e-06, 1.3599e-07, 1.3857e-08],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:08,393][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1435, 0.0979, 0.1538, 0.1977, 0.4054, 0.0018], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:08,397][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0981, 0.1756, 0.2039, 0.2544, 0.1782, 0.0898], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:08,397][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ to] are: tensor([1.7389e-06, 1.7241e-03, 2.7496e-05, 3.3965e-03, 9.9482e-01, 2.6143e-05],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:08,397][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0517, 0.4576, 0.2411, 0.2382, 0.0108, 0.0006], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:08,398][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.4573, 0.0914, 0.3344, 0.0466, 0.0186, 0.0518], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:08,398][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.2597, 0.1444, 0.1265, 0.1345, 0.1385, 0.1963], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:08,398][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.6321, 0.0228, 0.0733, 0.0341, 0.1041, 0.1336], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:08,399][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.8149, 0.0569, 0.0193, 0.0571, 0.0297, 0.0222], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:08,399][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ to] are: tensor([5.7759e-05, 1.5244e-02, 6.9677e-02, 8.7783e-02, 3.0080e-02, 7.9716e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:08,399][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0233, 0.1621, 0.1641, 0.2753, 0.1687, 0.2065], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:08,401][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.1627, 0.1005, 0.1352, 0.1913, 0.1124, 0.2028, 0.0950],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:08,403][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ the] are: tensor([9.9727e-01, 2.6960e-03, 2.0600e-07, 2.8922e-05, 1.1125e-06, 1.5089e-07,
        1.4241e-06], device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:08,404][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0930, 0.1188, 0.1848, 0.1716, 0.3678, 0.0626, 0.0014],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:08,404][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0825, 0.1127, 0.1590, 0.1499, 0.1722, 0.1548, 0.1690],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:08,404][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0078, 0.2161, 0.0790, 0.2261, 0.2336, 0.2353, 0.0021],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:08,405][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0090, 0.2594, 0.3176, 0.3539, 0.0227, 0.0368, 0.0006],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:08,405][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.3843, 0.1182, 0.2373, 0.0767, 0.0567, 0.0854, 0.0414],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:08,405][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.2073, 0.1294, 0.1113, 0.1201, 0.1171, 0.1663, 0.1485],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:08,406][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.3992, 0.0237, 0.0663, 0.0362, 0.1031, 0.1497, 0.2218],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:08,406][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.6847, 0.0703, 0.0274, 0.0973, 0.0494, 0.0344, 0.0365],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:08,407][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ the] are: tensor([3.7673e-05, 9.0075e-03, 3.9642e-02, 5.0821e-02, 1.7742e-02, 4.7074e-01,
        4.1201e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:08,410][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0194, 0.1334, 0.1257, 0.2381, 0.1443, 0.1672, 0.1718],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:08,411][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ station] are: tensor([0.1281, 0.1113, 0.1068, 0.1565, 0.1010, 0.1474, 0.0898, 0.1590],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:08,411][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ station] are: tensor([9.5036e-01, 3.8260e-02, 8.7831e-05, 2.2608e-03, 1.2533e-04, 1.2056e-04,
        5.3528e-04, 8.2545e-03], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:08,411][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ station] are: tensor([0.0545, 0.2032, 0.1304, 0.2204, 0.3155, 0.0283, 0.0328, 0.0149],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:08,411][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ station] are: tensor([0.0483, 0.1025, 0.1007, 0.1453, 0.1940, 0.0579, 0.2096, 0.1416],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:08,412][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ station] are: tensor([4.1367e-04, 2.7346e-02, 2.7603e-03, 8.0746e-03, 9.3366e-01, 4.1671e-03,
        1.7988e-02, 5.5931e-03], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:08,412][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ station] are: tensor([0.0685, 0.4449, 0.1518, 0.1298, 0.1029, 0.0390, 0.0620, 0.0012],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:08,412][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ station] are: tensor([0.2877, 0.1298, 0.1818, 0.1471, 0.0733, 0.0690, 0.0812, 0.0301],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:08,413][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ station] are: tensor([0.1912, 0.0893, 0.0868, 0.0931, 0.0933, 0.1434, 0.1301, 0.1728],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:08,415][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ station] are: tensor([0.4952, 0.0264, 0.0670, 0.0281, 0.0837, 0.0916, 0.1399, 0.0681],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:08,417][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ station] are: tensor([0.9367, 0.0155, 0.0053, 0.0144, 0.0082, 0.0071, 0.0084, 0.0045],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:08,417][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ station] are: tensor([0.0009, 0.0216, 0.0664, 0.0536, 0.0415, 0.4141, 0.3284, 0.0736],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:08,418][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ station] are: tensor([0.0193, 0.1088, 0.1255, 0.1897, 0.1347, 0.1554, 0.1549, 0.1116],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:08,418][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.1096, 0.0736, 0.0968, 0.1407, 0.0920, 0.1399, 0.0815, 0.1609, 0.1050],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:08,418][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [,] are: tensor([9.9822e-01, 1.7691e-03, 7.1683e-09, 3.3241e-06, 9.7580e-08, 3.9570e-09,
        6.3317e-08, 3.1613e-06, 1.1528e-08], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:08,419][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0530, 0.1330, 0.1047, 0.2471, 0.2996, 0.0274, 0.0122, 0.1216, 0.0014],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:08,419][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0775, 0.0823, 0.1028, 0.1098, 0.1354, 0.1080, 0.1686, 0.1808, 0.0349],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:08,419][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [,] are: tensor([2.9376e-04, 6.8463e-01, 7.4677e-04, 9.7863e-02, 7.7166e-03, 4.7137e-03,
        9.0775e-02, 1.1280e-01, 4.6253e-04], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:08,420][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0234, 0.1008, 0.3620, 0.1049, 0.1557, 0.0523, 0.0688, 0.0967, 0.0353],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:08,422][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.3201, 0.1727, 0.1863, 0.0887, 0.0411, 0.0633, 0.0619, 0.0130, 0.0528],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:08,424][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.1544, 0.1042, 0.0869, 0.0905, 0.0862, 0.1215, 0.1057, 0.1315, 0.1191],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:08,424][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.5231, 0.0139, 0.0402, 0.0156, 0.0518, 0.0685, 0.1141, 0.0691, 0.1038],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:08,424][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.6660, 0.0611, 0.0260, 0.0779, 0.0404, 0.0300, 0.0339, 0.0264, 0.0383],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:08,425][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [,] are: tensor([6.9422e-05, 8.6127e-03, 3.0455e-02, 5.7294e-02, 1.7810e-02, 3.2190e-01,
        2.4853e-01, 4.2612e-02, 2.7272e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:08,425][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0154, 0.1048, 0.0977, 0.1727, 0.1045, 0.1179, 0.1208, 0.0899, 0.1763],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:08,425][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Benjamin] are: tensor([0.0848, 0.0501, 0.0728, 0.1311, 0.1044, 0.1288, 0.0776, 0.1393, 0.1009,
        0.1102], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:08,426][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Benjamin] are: tensor([8.3323e-01, 1.4930e-01, 8.9800e-05, 4.0455e-03, 2.4662e-04, 5.3519e-05,
        2.7778e-04, 3.3847e-03, 9.4496e-05, 9.2793e-03], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:08,426][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Benjamin] are: tensor([0.0775, 0.0408, 0.1331, 0.1596, 0.1865, 0.0339, 0.0612, 0.2679, 0.0141,
        0.0255], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:08,428][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Benjamin] are: tensor([0.0490, 0.0507, 0.0664, 0.1128, 0.1446, 0.0648, 0.1878, 0.2163, 0.0284,
        0.0793], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:08,430][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Benjamin] are: tensor([3.3438e-05, 4.5539e-05, 9.9290e-04, 2.6942e-04, 1.4187e-02, 5.8231e-02,
        1.4583e-01, 7.7411e-01, 5.6591e-03, 6.4400e-04], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:08,431][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Benjamin] are: tensor([0.0756, 0.0156, 0.3205, 0.0528, 0.1602, 0.0607, 0.0598, 0.1533, 0.0951,
        0.0064], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:08,431][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Benjamin] are: tensor([0.1950, 0.1596, 0.1672, 0.1344, 0.0609, 0.0601, 0.0368, 0.0323, 0.0804,
        0.0732], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:08,431][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Benjamin] are: tensor([0.1277, 0.0918, 0.0749, 0.0812, 0.0771, 0.1072, 0.0973, 0.1370, 0.1088,
        0.0970], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:08,432][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Benjamin] are: tensor([0.2686, 0.0163, 0.0516, 0.0243, 0.0669, 0.0928, 0.1511, 0.0901, 0.1640,
        0.0743], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:08,432][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Benjamin] are: tensor([0.9550, 0.0097, 0.0031, 0.0071, 0.0046, 0.0040, 0.0051, 0.0026, 0.0059,
        0.0028], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:08,432][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Benjamin] are: tensor([6.9027e-05, 1.6205e-02, 4.2509e-02, 6.2060e-02, 2.2726e-02, 2.1705e-01,
        1.9923e-01, 2.7355e-02, 1.5600e-01, 2.5680e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:08,433][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Benjamin] are: tensor([0.0085, 0.0579, 0.0803, 0.1358, 0.0897, 0.1131, 0.1151, 0.0818, 0.1819,
        0.1360], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:08,435][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.0754, 0.0596, 0.0792, 0.1106, 0.0916, 0.1285, 0.0707, 0.1234, 0.0943,
        0.1206, 0.0461], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:08,437][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([9.9886e-01, 8.8602e-04, 1.7111e-07, 2.7255e-05, 5.5865e-07, 1.7985e-07,
        1.7594e-06, 3.2222e-05, 1.0945e-06, 1.9165e-04, 9.2875e-07],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:08,437][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0284, 0.1885, 0.1983, 0.1605, 0.0419, 0.0233, 0.0319, 0.1395, 0.0246,
        0.1506, 0.0123], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:08,438][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.0626, 0.0652, 0.0749, 0.0698, 0.0756, 0.0740, 0.1838, 0.2054, 0.0384,
        0.0998, 0.0506], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:08,438][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.0375, 0.0228, 0.0443, 0.0367, 0.0404, 0.1335, 0.1177, 0.0391, 0.1654,
        0.3606, 0.0017], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:08,438][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.0176, 0.1741, 0.1238, 0.0760, 0.0216, 0.0469, 0.1444, 0.1155, 0.1401,
        0.1393, 0.0007], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:08,439][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.2214, 0.1641, 0.1290, 0.1124, 0.0582, 0.0337, 0.0437, 0.0323, 0.1021,
        0.0735, 0.0296], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:08,439][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.1526, 0.0681, 0.0602, 0.0672, 0.0649, 0.1010, 0.0869, 0.1152, 0.0993,
        0.0814, 0.1032], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:08,439][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.4472, 0.0136, 0.0432, 0.0146, 0.0404, 0.0516, 0.0882, 0.0399, 0.1016,
        0.0428, 0.1170], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:08,442][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.8659, 0.0231, 0.0079, 0.0232, 0.0119, 0.0100, 0.0124, 0.0084, 0.0148,
        0.0104, 0.0120], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:08,444][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([2.5968e-05, 9.5813e-03, 3.7313e-02, 3.4958e-02, 2.0821e-02, 3.1086e-01,
        1.8150e-01, 2.2811e-02, 1.6606e-01, 1.6515e-01, 5.0929e-02],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:08,444][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0142, 0.0832, 0.0916, 0.1264, 0.0827, 0.0981, 0.0928, 0.0611, 0.1391,
        0.0940, 0.1169], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:08,445][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0781, 0.0531, 0.0791, 0.1082, 0.0564, 0.1104, 0.0615, 0.1195, 0.0945,
        0.1227, 0.0547, 0.0618], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:08,445][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ a] are: tensor([9.7718e-01, 1.9748e-02, 9.5109e-06, 4.6545e-04, 4.9075e-05, 6.6289e-06,
        3.4498e-05, 8.3860e-04, 1.8511e-05, 1.4137e-03, 3.7629e-05, 1.9623e-04],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:08,445][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0410, 0.0901, 0.1885, 0.0715, 0.1527, 0.0290, 0.0101, 0.2048, 0.0112,
        0.1021, 0.0986, 0.0004], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:08,446][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0389, 0.0671, 0.0795, 0.0597, 0.0865, 0.0649, 0.1453, 0.1560, 0.0334,
        0.1002, 0.1090, 0.0596], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:08,446][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0036, 0.0074, 0.0732, 0.0024, 0.1866, 0.1298, 0.0266, 0.0433, 0.1349,
        0.0978, 0.2828, 0.0115], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:08,446][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ a] are: tensor([8.4348e-03, 2.7937e-01, 5.6274e-02, 1.6886e-01, 2.5689e-02, 2.7550e-02,
        1.1754e-02, 1.4647e-01, 7.9840e-02, 1.6962e-01, 2.6016e-02, 1.2044e-04],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:08,449][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.2656, 0.1017, 0.1674, 0.0609, 0.0436, 0.0541, 0.0449, 0.0219, 0.0887,
        0.0424, 0.0466, 0.0621], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:08,451][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.1297, 0.0673, 0.0611, 0.0618, 0.0617, 0.0912, 0.0779, 0.0942, 0.0898,
        0.0713, 0.0869, 0.1070], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:08,451][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.2682, 0.0107, 0.0295, 0.0131, 0.0429, 0.0496, 0.0839, 0.0544, 0.0803,
        0.0463, 0.1927, 0.1285], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:08,451][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.6051, 0.0487, 0.0202, 0.0709, 0.0357, 0.0258, 0.0289, 0.0240, 0.0336,
        0.0324, 0.0333, 0.0415], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:08,452][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ a] are: tensor([3.5430e-05, 2.9776e-03, 1.4329e-02, 1.8615e-02, 1.0641e-02, 2.0167e-01,
        1.3147e-01, 1.8685e-02, 1.0951e-01, 1.2787e-01, 3.3040e-02, 3.3116e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:08,452][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0150, 0.0732, 0.0756, 0.1070, 0.0714, 0.0840, 0.0815, 0.0594, 0.1196,
        0.0836, 0.1036, 0.1261], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:08,452][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ computer] are: tensor([0.0623, 0.0537, 0.0592, 0.0912, 0.0546, 0.0900, 0.0520, 0.1065, 0.0770,
        0.1092, 0.0629, 0.0597, 0.1218], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:08,453][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ computer] are: tensor([9.3831e-01, 5.8756e-02, 6.0858e-06, 4.2250e-04, 2.4372e-05, 3.9104e-06,
        2.6460e-05, 4.4478e-04, 1.4315e-05, 1.7270e-03, 2.1741e-05, 1.7094e-04,
        6.9488e-05], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:08,453][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ computer] are: tensor([0.0236, 0.1583, 0.0402, 0.1741, 0.2083, 0.0199, 0.0095, 0.0971, 0.0056,
        0.1190, 0.1260, 0.0078, 0.0108], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:08,455][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ computer] are: tensor([0.0226, 0.0458, 0.0602, 0.0618, 0.1176, 0.0375, 0.0980, 0.1233, 0.0236,
        0.0716, 0.1738, 0.1394, 0.0248], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:08,457][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ computer] are: tensor([4.9858e-06, 2.0765e-02, 5.1555e-04, 1.0543e-02, 9.9513e-03, 1.5161e-02,
        4.1833e-03, 2.6592e-01, 3.5764e-03, 6.0089e-01, 2.2663e-02, 4.1260e-02,
        4.5659e-03], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:08,458][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ computer] are: tensor([0.0234, 0.1259, 0.1099, 0.0203, 0.0489, 0.0395, 0.0155, 0.0317, 0.1566,
        0.0584, 0.3467, 0.0229, 0.0004], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:08,458][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ computer] are: tensor([0.1753, 0.0874, 0.1183, 0.0885, 0.0576, 0.0598, 0.0415, 0.0329, 0.1285,
        0.0422, 0.0593, 0.0687, 0.0401], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:08,458][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ computer] are: tensor([0.1446, 0.0454, 0.0440, 0.0465, 0.0479, 0.0802, 0.0673, 0.0834, 0.0808,
        0.0585, 0.0747, 0.1017, 0.1249], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:08,459][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ computer] are: tensor([0.2212, 0.0146, 0.0395, 0.0152, 0.0480, 0.0520, 0.0954, 0.0542, 0.0871,
        0.0448, 0.1367, 0.1415, 0.0497], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:08,459][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ computer] are: tensor([0.9313, 0.0090, 0.0032, 0.0086, 0.0048, 0.0044, 0.0055, 0.0032, 0.0070,
        0.0039, 0.0059, 0.0086, 0.0045], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:08,459][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ computer] are: tensor([1.9704e-05, 4.1953e-03, 2.2147e-02, 1.7969e-02, 1.1674e-02, 2.1178e-01,
        1.4053e-01, 1.9715e-02, 1.3834e-01, 7.2917e-02, 2.8089e-02, 3.0040e-01,
        3.2231e-02], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:08,460][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ computer] are: tensor([0.0147, 0.0617, 0.0767, 0.0913, 0.0676, 0.0814, 0.0747, 0.0512, 0.1150,
        0.0638, 0.0967, 0.1166, 0.0886], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:08,462][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0821, 0.0403, 0.0597, 0.0766, 0.0435, 0.0690, 0.0439, 0.0992, 0.0753,
        0.0959, 0.0496, 0.0573, 0.1292, 0.0785], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:08,464][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ to] are: tensor([9.9640e-01, 2.7846e-03, 1.1890e-06, 1.1647e-04, 7.4484e-06, 8.1479e-07,
        4.7483e-06, 1.5976e-04, 2.6899e-06, 3.8374e-04, 6.5652e-06, 3.9145e-05,
        2.8004e-05, 6.3906e-05], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:08,464][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0757, 0.0524, 0.0824, 0.1550, 0.2409, 0.0010, 0.0154, 0.1030, 0.0072,
        0.0553, 0.1487, 0.0165, 0.0460, 0.0004], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:08,465][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0282, 0.0512, 0.0662, 0.0738, 0.0523, 0.0241, 0.1118, 0.1289, 0.0285,
        0.0863, 0.1516, 0.1360, 0.0499, 0.0112], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:08,465][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ to] are: tensor([1.1396e-06, 5.7711e-04, 1.7773e-05, 1.7015e-03, 7.1890e-01, 1.9523e-05,
        3.0555e-05, 5.5138e-03, 5.5269e-05, 2.8834e-02, 2.4412e-01, 7.6004e-05,
        7.1965e-05, 7.5657e-05], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:08,465][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ to] are: tensor([3.6345e-02, 1.6988e-01, 1.4745e-01, 1.6352e-01, 6.4748e-03, 1.5001e-04,
        1.4034e-02, 9.6452e-02, 3.1051e-02, 7.8297e-02, 1.8520e-01, 2.7287e-03,
        6.8350e-02, 6.4757e-05], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:08,466][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.3162, 0.0596, 0.2320, 0.0322, 0.0137, 0.0412, 0.0445, 0.0046, 0.0771,
        0.0234, 0.0219, 0.0814, 0.0168, 0.0354], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:08,466][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.1171, 0.0562, 0.0510, 0.0488, 0.0483, 0.0735, 0.0616, 0.0691, 0.0724,
        0.0534, 0.0642, 0.0830, 0.0939, 0.1076], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:08,467][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.4486, 0.0094, 0.0245, 0.0102, 0.0292, 0.0298, 0.0539, 0.0333, 0.0456,
        0.0290, 0.1134, 0.0714, 0.0278, 0.0741], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:08,470][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.5434, 0.0449, 0.0207, 0.0634, 0.0310, 0.0240, 0.0314, 0.0246, 0.0370,
        0.0311, 0.0332, 0.0445, 0.0317, 0.0390], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:08,473][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ to] are: tensor([8.9388e-06, 1.3590e-03, 8.3217e-03, 1.0359e-02, 6.5236e-03, 1.2193e-01,
        7.4344e-02, 9.9862e-03, 5.8075e-02, 8.1881e-02, 2.5050e-02, 1.8696e-01,
        1.7622e-02, 3.9757e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:08,474][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0147, 0.0645, 0.0641, 0.0892, 0.0610, 0.0663, 0.0643, 0.0448, 0.0949,
        0.0621, 0.0809, 0.0907, 0.0736, 0.1289], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:08,499][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:20:08,499][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:08,499][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:08,500][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:08,500][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:08,500][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:08,501][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:08,502][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:08,502][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:08,503][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:08,503][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:08,503][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:08,504][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:08,504][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Benjamin] are: tensor([0.5400, 0.4600], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:08,504][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Benjamin] are: tensor([0.4427, 0.5573], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:08,505][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Benjamin] are: tensor([0.1828, 0.8172], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:08,505][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Benjamin] are: tensor([0.2228, 0.7772], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:08,505][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Benjamin] are: tensor([0.9781, 0.0219], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:08,506][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Benjamin] are: tensor([0.9580, 0.0420], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:08,506][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Benjamin] are: tensor([0.3948, 0.6052], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:08,506][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Benjamin] are: tensor([0.4905, 0.5095], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:08,507][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Benjamin] are: tensor([0.9883, 0.0117], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:08,507][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Benjamin] are: tensor([0.3942, 0.6058], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:08,507][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Benjamin] are: tensor([0.1873, 0.8127], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:08,508][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Benjamin] are: tensor([0.0496, 0.9504], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:08,511][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.3498, 0.3600, 0.2902], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:08,511][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.2082, 0.3263, 0.4654], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:08,511][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0717, 0.4635, 0.4649], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:08,520][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0994, 0.3171, 0.5835], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:08,522][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.3443, 0.3785, 0.2772], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:08,524][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.8311, 0.1446, 0.0243], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:08,525][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.4458, 0.4550, 0.0992], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:08,525][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2947, 0.3508, 0.3545], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:08,525][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.8852, 0.0494, 0.0654], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:08,526][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0704, 0.6468, 0.2828], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:08,526][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.2795, 0.3472, 0.3733], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:08,526][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0319, 0.6330, 0.3352], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:08,527][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Alexander] are: tensor([0.2399, 0.2832, 0.2250, 0.2519], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:08,529][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Alexander] are: tensor([0.0871, 0.1902, 0.2325, 0.4902], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:08,531][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Alexander] are: tensor([0.0465, 0.1767, 0.2135, 0.5632], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:08,531][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Alexander] are: tensor([0.0560, 0.1551, 0.3945, 0.3945], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:08,532][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Alexander] are: tensor([0.4183, 0.0924, 0.4706, 0.0187], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:08,532][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Alexander] are: tensor([0.3928, 0.3195, 0.1749, 0.1128], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:08,532][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Alexander] are: tensor([0.0998, 0.2548, 0.0819, 0.5634], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:08,533][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Alexander] are: tensor([0.2414, 0.2549, 0.2884, 0.2153], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:08,533][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Alexander] are: tensor([0.7668, 0.0365, 0.1863, 0.0104], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:08,533][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Alexander] are: tensor([0.0610, 0.2709, 0.4553, 0.2127], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:08,536][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Alexander] are: tensor([0.0616, 0.2590, 0.2805, 0.3990], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:08,538][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Alexander] are: tensor([0.0215, 0.3319, 0.2431, 0.4035], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:08,538][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([0.1788, 0.2278, 0.1923, 0.2822, 0.1190], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:08,539][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([0.0119, 0.1994, 0.3013, 0.4805, 0.0069], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:08,539][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([0.0432, 0.1507, 0.1693, 0.5104, 0.1265], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:08,539][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([0.0447, 0.0978, 0.2143, 0.2192, 0.4241], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:08,540][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([7.6752e-01, 6.5782e-04, 2.2366e-01, 5.3799e-03, 2.7914e-03],
       device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:08,540][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([0.2186, 0.2925, 0.1955, 0.2645, 0.0288], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:08,540][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([0.1147, 0.2392, 0.0495, 0.3838, 0.2128], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:08,543][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([0.1889, 0.1908, 0.2336, 0.1611, 0.2256], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:08,545][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([0.7124, 0.0767, 0.1360, 0.0506, 0.0242], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:08,545][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([0.0239, 0.1940, 0.2342, 0.3536, 0.1943], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:08,545][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([0.0386, 0.1687, 0.1723, 0.2533, 0.3671], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:08,546][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([0.0189, 0.2349, 0.1773, 0.2899, 0.2790], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:08,546][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.1833, 0.1495, 0.1659, 0.1867, 0.1342, 0.1803], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:08,546][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0200, 0.1428, 0.2304, 0.5993, 0.0064, 0.0012], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:08,547][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0232, 0.1307, 0.1402, 0.4957, 0.1020, 0.1081], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:08,547][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0182, 0.0850, 0.1535, 0.2205, 0.3748, 0.1481], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:08,549][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0833, 0.0892, 0.2005, 0.1223, 0.4659, 0.0388], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:08,551][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.3607, 0.1209, 0.0980, 0.3373, 0.0476, 0.0354], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:08,552][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.3165, 0.1275, 0.1664, 0.1466, 0.1181, 0.1248], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:08,552][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.1499, 0.1689, 0.1833, 0.1407, 0.1909, 0.1663], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:08,552][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([9.4292e-03, 2.6886e-03, 7.5342e-03, 4.8813e-03, 9.7537e-01, 9.7449e-05],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:08,553][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0269, 0.1453, 0.1887, 0.2881, 0.2673, 0.0838], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:08,553][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0457, 0.0859, 0.1182, 0.1151, 0.1672, 0.4679], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:08,553][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0159, 0.1787, 0.1174, 0.2000, 0.1963, 0.2916], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:08,554][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.1383, 0.1390, 0.1417, 0.1872, 0.1170, 0.1895, 0.0873],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:08,556][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0793, 0.1382, 0.2143, 0.2780, 0.0183, 0.0137, 0.2582],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:08,558][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0130, 0.0890, 0.1082, 0.2841, 0.0751, 0.2133, 0.2172],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:08,559][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0090, 0.0621, 0.1286, 0.1916, 0.3354, 0.1184, 0.1549],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:08,559][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.4396, 0.0559, 0.2697, 0.0398, 0.0109, 0.1570, 0.0272],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:08,559][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.2073, 0.1197, 0.1102, 0.3935, 0.0515, 0.0684, 0.0494],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:08,560][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.1654, 0.1142, 0.0691, 0.1627, 0.2500, 0.1660, 0.0727],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:08,560][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.1252, 0.1472, 0.1562, 0.1196, 0.1580, 0.1401, 0.1537],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:08,560][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.1743, 0.0225, 0.1833, 0.0159, 0.4286, 0.1732, 0.0022],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:08,561][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0272, 0.1175, 0.1612, 0.2097, 0.1924, 0.1551, 0.1369],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:08,565][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0217, 0.0493, 0.0731, 0.0669, 0.0899, 0.3875, 0.3116],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:08,565][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0134, 0.1426, 0.0872, 0.1596, 0.1582, 0.2215, 0.2175],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:08,566][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ station] are: tensor([0.1179, 0.1453, 0.1174, 0.1574, 0.1106, 0.1431, 0.0813, 0.1270],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:08,566][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ station] are: tensor([5.6294e-03, 2.4362e-01, 3.9332e-01, 1.9551e-01, 8.1055e-04, 8.2526e-05,
        1.1818e-01, 4.2855e-02], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:08,566][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ station] are: tensor([0.0208, 0.0868, 0.0944, 0.2555, 0.0717, 0.0925, 0.2060, 0.1722],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:08,567][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ station] are: tensor([0.0191, 0.0361, 0.0827, 0.0865, 0.1732, 0.0863, 0.1117, 0.4044],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:08,567][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ station] are: tensor([0.3178, 0.0260, 0.1920, 0.0231, 0.1791, 0.0497, 0.2103, 0.0019],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:08,568][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ station] are: tensor([0.2109, 0.1361, 0.0730, 0.2241, 0.0630, 0.0729, 0.2147, 0.0054],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:08,571][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ station] are: tensor([0.0382, 0.1185, 0.0308, 0.3172, 0.2568, 0.0439, 0.0924, 0.1022],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:08,572][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ station] are: tensor([0.1157, 0.1159, 0.1388, 0.1005, 0.1444, 0.1254, 0.1362, 0.1232],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:08,572][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ station] are: tensor([0.6574, 0.0286, 0.0697, 0.0194, 0.1447, 0.0501, 0.0266, 0.0035],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:08,572][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ station] are: tensor([0.0089, 0.0829, 0.0927, 0.1766, 0.2124, 0.0769, 0.2638, 0.0859],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:08,573][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ station] are: tensor([0.0194, 0.0467, 0.0843, 0.0563, 0.1052, 0.2225, 0.2009, 0.2646],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:08,573][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ station] are: tensor([0.0090, 0.0728, 0.0565, 0.0886, 0.0861, 0.1439, 0.1467, 0.3964],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:08,574][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0991, 0.0999, 0.1082, 0.1406, 0.1033, 0.1423, 0.0775, 0.1342, 0.0948],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:08,574][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([2.2461e-03, 5.8262e-03, 8.3575e-03, 1.0610e-02, 5.3273e-04, 2.1004e-04,
        7.8592e-03, 7.1110e-03, 9.5725e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:08,577][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0130, 0.0603, 0.0592, 0.2217, 0.0642, 0.1108, 0.1752, 0.1964, 0.0991],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:08,578][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0051, 0.0384, 0.0737, 0.1120, 0.1872, 0.0686, 0.0974, 0.3223, 0.0955],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:08,579][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.1069, 0.3124, 0.0883, 0.0846, 0.0084, 0.0541, 0.2552, 0.0565, 0.0338],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:08,579][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.1737, 0.0470, 0.0683, 0.1393, 0.0527, 0.0526, 0.1164, 0.0439, 0.3062],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:08,580][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.1213, 0.1819, 0.0455, 0.2145, 0.1361, 0.0649, 0.1329, 0.0794, 0.0236],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:08,580][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.1006, 0.1136, 0.1220, 0.0930, 0.1257, 0.1083, 0.1185, 0.1069, 0.1115],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:08,580][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.3447, 0.0120, 0.0921, 0.0253, 0.3751, 0.0849, 0.0425, 0.0105, 0.0130],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:08,581][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0175, 0.0832, 0.1053, 0.1231, 0.1389, 0.0961, 0.1972, 0.1532, 0.0854],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:08,583][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0121, 0.0375, 0.0430, 0.0436, 0.0678, 0.1801, 0.2060, 0.1755, 0.2345],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:08,585][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0083, 0.0757, 0.0465, 0.0794, 0.0719, 0.1018, 0.1048, 0.3070, 0.2046],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:08,586][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Benjamin] are: tensor([0.0855, 0.0796, 0.0849, 0.1402, 0.1159, 0.1293, 0.0736, 0.1183, 0.0832,
        0.0897], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:08,586][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Benjamin] are: tensor([2.3438e-03, 5.4243e-03, 6.4258e-03, 9.1459e-03, 3.6712e-04, 1.1424e-04,
        5.5511e-03, 4.0485e-03, 9.3204e-01, 3.4538e-02], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:08,586][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Benjamin] are: tensor([0.0118, 0.0247, 0.0330, 0.0856, 0.0312, 0.0711, 0.0841, 0.1470, 0.1029,
        0.4087], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:08,587][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Benjamin] are: tensor([0.0094, 0.0218, 0.0532, 0.0542, 0.1141, 0.0536, 0.0725, 0.2608, 0.0745,
        0.2859], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:08,587][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Benjamin] are: tensor([0.0935, 0.0026, 0.0738, 0.0062, 0.0393, 0.1411, 0.3303, 0.2289, 0.0829,
        0.0014], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:08,588][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Benjamin] are: tensor([0.1411, 0.0157, 0.0626, 0.0713, 0.0565, 0.0503, 0.1115, 0.0657, 0.3975,
        0.0278], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:08,590][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Benjamin] are: tensor([0.0369, 0.0823, 0.0380, 0.2246, 0.1724, 0.0465, 0.0332, 0.1357, 0.0396,
        0.1908], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:08,592][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Benjamin] are: tensor([0.0927, 0.0941, 0.1152, 0.0804, 0.1166, 0.1034, 0.1125, 0.1061, 0.1124,
        0.0667], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:08,592][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Benjamin] are: tensor([0.3535, 0.0055, 0.0733, 0.0199, 0.0247, 0.3301, 0.0336, 0.0926, 0.0631,
        0.0038], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:08,593][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Benjamin] are: tensor([0.0084, 0.0149, 0.0971, 0.1009, 0.1742, 0.0833, 0.2043, 0.1437, 0.1522,
        0.0210], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:08,593][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Benjamin] are: tensor([0.0037, 0.0263, 0.0278, 0.0457, 0.0601, 0.1810, 0.1871, 0.1881, 0.1906,
        0.0896], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:08,594][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Benjamin] are: tensor([0.0041, 0.0377, 0.0328, 0.0477, 0.0473, 0.0686, 0.0767, 0.1993, 0.1647,
        0.3211], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:08,594][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.0779, 0.0831, 0.0872, 0.1178, 0.1023, 0.1296, 0.0652, 0.1093, 0.0837,
        0.0970, 0.0469], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:08,594][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([3.0145e-04, 2.0846e-03, 3.2191e-03, 4.9210e-03, 5.2480e-05, 1.4975e-05,
        3.2064e-03, 1.0587e-03, 9.2695e-01, 1.4925e-02, 4.3266e-02],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:08,597][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.0093, 0.0275, 0.0266, 0.0970, 0.0259, 0.0442, 0.0769, 0.0906, 0.0552,
        0.4380, 0.1087], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:08,599][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.0067, 0.0220, 0.0475, 0.0551, 0.1021, 0.0446, 0.0536, 0.2107, 0.0563,
        0.2614, 0.1400], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:08,599][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.4205, 0.0099, 0.1810, 0.0129, 0.0077, 0.0768, 0.0970, 0.0068, 0.1796,
        0.0072, 0.0007], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:08,600][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.0801, 0.0739, 0.0553, 0.1084, 0.0216, 0.0403, 0.1319, 0.0380, 0.3224,
        0.1174, 0.0106], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:08,600][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.0457, 0.0836, 0.0195, 0.1678, 0.1443, 0.0263, 0.0515, 0.1567, 0.0376,
        0.2103, 0.0566], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:08,600][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0858, 0.0886, 0.1048, 0.0752, 0.1088, 0.0982, 0.1010, 0.0909, 0.1017,
        0.0609, 0.0842], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:08,601][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.2610, 0.0386, 0.0927, 0.0517, 0.0182, 0.2979, 0.0766, 0.0156, 0.1105,
        0.0306, 0.0066], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:08,601][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.0126, 0.0520, 0.0705, 0.1275, 0.1130, 0.0691, 0.1753, 0.1311, 0.1425,
        0.0683, 0.0382], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:08,604][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0049, 0.0239, 0.0235, 0.0312, 0.0598, 0.1494, 0.1372, 0.1046, 0.2237,
        0.0954, 0.1464], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:08,606][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.0059, 0.0414, 0.0315, 0.0421, 0.0416, 0.0742, 0.0634, 0.1622, 0.1630,
        0.2520, 0.1228], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:08,606][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0751, 0.0824, 0.0928, 0.1195, 0.0659, 0.1149, 0.0619, 0.1000, 0.0831,
        0.1024, 0.0530, 0.0490], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:08,606][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([1.0589e-03, 1.8593e-03, 2.6006e-03, 3.5692e-03, 1.3031e-04, 1.0434e-04,
        3.3424e-03, 2.0698e-03, 2.9444e-01, 1.0905e-02, 4.5382e-02, 6.3453e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:08,607][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0052, 0.0200, 0.0212, 0.0764, 0.0196, 0.0417, 0.0580, 0.0803, 0.0520,
        0.3591, 0.1197, 0.1469], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:08,607][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0022, 0.0171, 0.0374, 0.0535, 0.0955, 0.0324, 0.0421, 0.1961, 0.0463,
        0.2816, 0.1370, 0.0587], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:08,608][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.2202, 0.0109, 0.3311, 0.0036, 0.0183, 0.1157, 0.0835, 0.0133, 0.1642,
        0.0074, 0.0125, 0.0193], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:08,608][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0869, 0.0704, 0.0358, 0.1496, 0.0233, 0.0330, 0.0589, 0.0388, 0.2640,
        0.1151, 0.0722, 0.0519], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:08,610][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0347, 0.0629, 0.0300, 0.0917, 0.1351, 0.0474, 0.0692, 0.1727, 0.0487,
        0.1614, 0.1060, 0.0402], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:08,612][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0762, 0.0909, 0.0952, 0.0744, 0.0950, 0.0850, 0.0939, 0.0848, 0.0862,
        0.0603, 0.0744, 0.0836], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:08,613][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([3.2842e-02, 3.3172e-03, 1.8178e-02, 3.8651e-03, 6.0964e-02, 1.0063e-02,
        3.4598e-03, 5.8025e-02, 6.3419e-03, 3.8696e-03, 7.9856e-01, 5.1249e-04],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:08,613][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0123, 0.0570, 0.0770, 0.0991, 0.0961, 0.0715, 0.0809, 0.1433, 0.1319,
        0.0720, 0.1005, 0.0583], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:08,614][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0071, 0.0202, 0.0249, 0.0286, 0.0377, 0.1734, 0.1312, 0.0874, 0.1448,
        0.0655, 0.1149, 0.1641], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:08,614][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0065, 0.0375, 0.0260, 0.0369, 0.0337, 0.0566, 0.0516, 0.1422, 0.1175,
        0.2172, 0.1123, 0.1620], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:08,614][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ computer] are: tensor([0.0632, 0.0807, 0.0711, 0.1027, 0.0663, 0.0955, 0.0538, 0.0942, 0.0695,
        0.0922, 0.0631, 0.0469, 0.1007], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:08,615][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ computer] are: tensor([2.9802e-05, 9.9752e-05, 1.4954e-04, 1.1999e-04, 5.3755e-06, 3.9609e-06,
        1.1656e-04, 5.9944e-05, 1.0462e-02, 3.2030e-04, 1.2722e-03, 1.7648e-02,
        9.6971e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:08,617][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ computer] are: tensor([0.0076, 0.0125, 0.0121, 0.0441, 0.0156, 0.0364, 0.0423, 0.0760, 0.0410,
        0.2590, 0.0975, 0.1314, 0.2244], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:08,619][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ computer] are: tensor([0.0057, 0.0134, 0.0314, 0.0331, 0.0668, 0.0312, 0.0388, 0.1589, 0.0424,
        0.1890, 0.1132, 0.0510, 0.2251], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:08,620][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ computer] are: tensor([0.0435, 0.0748, 0.0955, 0.0525, 0.0246, 0.1247, 0.1015, 0.0789, 0.1249,
        0.0616, 0.0209, 0.1782, 0.0185], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:08,620][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ computer] are: tensor([0.0507, 0.0404, 0.0307, 0.0369, 0.0253, 0.0310, 0.0469, 0.0163, 0.2385,
        0.0632, 0.1976, 0.2142, 0.0083], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:08,620][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ computer] are: tensor([0.0223, 0.0582, 0.0189, 0.1463, 0.1513, 0.0246, 0.0353, 0.1306, 0.0549,
        0.1355, 0.1133, 0.0253, 0.0835], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:08,621][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ computer] are: tensor([0.0742, 0.0734, 0.0913, 0.0635, 0.0877, 0.0822, 0.0868, 0.0802, 0.0881,
        0.0521, 0.0714, 0.0818, 0.0671], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:08,621][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ computer] are: tensor([0.2937, 0.0431, 0.0709, 0.0570, 0.1799, 0.0748, 0.0173, 0.0478, 0.0273,
        0.0473, 0.1178, 0.0175, 0.0056], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:08,622][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ computer] are: tensor([0.0049, 0.0401, 0.0468, 0.1289, 0.0946, 0.0460, 0.1164, 0.1003, 0.0774,
        0.0511, 0.0880, 0.1517, 0.0538], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:08,625][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ computer] are: tensor([0.0039, 0.0133, 0.0225, 0.0291, 0.0376, 0.1290, 0.0955, 0.1221, 0.1463,
        0.0422, 0.1067, 0.1455, 0.1063], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:08,626][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ computer] are: tensor([0.0073, 0.0307, 0.0280, 0.0322, 0.0276, 0.0551, 0.0430, 0.1323, 0.1035,
        0.1643, 0.0909, 0.1359, 0.1491], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:08,626][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0765, 0.0679, 0.0745, 0.0889, 0.0569, 0.0784, 0.0484, 0.0861, 0.0685,
        0.0834, 0.0530, 0.0465, 0.1073, 0.0637], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:08,627][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([2.0201e-04, 2.6327e-04, 3.7468e-04, 2.6613e-04, 3.3417e-05, 3.5741e-05,
        3.6834e-04, 3.2894e-04, 1.0146e-02, 6.3234e-04, 3.1295e-03, 1.5625e-02,
        2.5614e-01, 7.1246e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:08,627][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0045, 0.0104, 0.0102, 0.0412, 0.0114, 0.0204, 0.0402, 0.0510, 0.0341,
        0.1909, 0.0763, 0.1186, 0.2339, 0.1568], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:08,628][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0018, 0.0136, 0.0282, 0.0414, 0.0721, 0.0243, 0.0327, 0.1436, 0.0365,
        0.1971, 0.1022, 0.0463, 0.2071, 0.0531], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:08,628][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0433, 0.0438, 0.1254, 0.0624, 0.2769, 0.0257, 0.0493, 0.0359, 0.0946,
        0.0522, 0.1408, 0.0321, 0.0037, 0.0138], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:08,630][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0934, 0.0260, 0.0228, 0.0869, 0.0116, 0.0075, 0.0457, 0.0256, 0.1394,
        0.0534, 0.1237, 0.1658, 0.1452, 0.0529], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:08,633][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.1071, 0.0516, 0.0580, 0.0666, 0.0574, 0.0373, 0.0977, 0.0409, 0.0775,
        0.1205, 0.0700, 0.0673, 0.0924, 0.0558], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:08,633][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0677, 0.0767, 0.0836, 0.0650, 0.0849, 0.0759, 0.0805, 0.0732, 0.0771,
        0.0529, 0.0671, 0.0728, 0.0680, 0.0546], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:08,633][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([2.8569e-03, 9.3516e-04, 2.6241e-03, 1.4285e-03, 3.2581e-01, 2.4575e-05,
        8.7910e-04, 8.2278e-04, 2.0527e-03, 9.2166e-04, 6.6011e-01, 1.0409e-03,
        4.7272e-04, 1.5281e-05], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:08,634][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0082, 0.0428, 0.0538, 0.0850, 0.0741, 0.0222, 0.1127, 0.0879, 0.0767,
        0.0508, 0.0825, 0.1494, 0.1370, 0.0169], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:08,634][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0049, 0.0129, 0.0235, 0.0163, 0.0305, 0.1272, 0.0751, 0.0572, 0.1142,
        0.0348, 0.0763, 0.0825, 0.0548, 0.2896], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:08,635][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0064, 0.0273, 0.0189, 0.0249, 0.0263, 0.0363, 0.0362, 0.0917, 0.0798,
        0.1313, 0.0768, 0.1059, 0.1421, 0.1960], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:08,636][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:20:08,638][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 4917],
        [  600],
        [ 3856],
        [   79],
        [15823],
        [ 1363],
        [ 2173],
        [ 1869],
        [ 1084],
        [   84],
        [ 2522],
        [ 2872],
        [ 6939],
        [  857]], device='cuda:0')
[2024-07-24 10:20:08,639][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 4827],
        [  300],
        [ 3549],
        [   70],
        [11864],
        [ 2990],
        [ 4142],
        [ 1793],
        [ 2638],
        [   98],
        [ 4612],
        [ 7855],
        [ 7966],
        [ 1978]], device='cuda:0')
[2024-07-24 10:20:08,642][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[10582],
        [ 6448],
        [ 7155],
        [ 5788],
        [ 6059],
        [ 7061],
        [ 7207],
        [ 6469],
        [ 6544],
        [ 6331],
        [ 6581],
        [ 6596],
        [ 6319],
        [ 6425]], device='cuda:0')
[2024-07-24 10:20:08,643][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[43274],
        [34008],
        [43271],
        [43424],
        [43931],
        [43273],
        [43276],
        [43617],
        [43276],
        [41671],
        [43288],
        [43476],
        [43127],
        [43318]], device='cuda:0')
[2024-07-24 10:20:08,643][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[14966],
        [11227],
        [ 7131],
        [ 7594],
        [ 4764],
        [  991],
        [ 1040],
        [ 1180],
        [ 1257],
        [ 3059],
        [ 4891],
        [ 3676],
        [ 2202],
        [ 2040]], device='cuda:0')
[2024-07-24 10:20:08,645][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[44980],
        [27498],
        [17200],
        [17653],
        [18720],
        [15600],
        [16040],
        [11290],
        [13221],
        [10488],
        [11190],
        [11732],
        [13230],
        [13031]], device='cuda:0')
[2024-07-24 10:20:08,646][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[30320],
        [18965],
        [10236],
        [15851],
        [29175],
        [21842],
        [33082],
        [22165],
        [19730],
        [41897],
        [23098],
        [32390],
        [22130],
        [26314]], device='cuda:0')
[2024-07-24 10:20:08,648][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[35475],
        [35905],
        [33621],
        [30945],
        [32120],
        [37546],
        [40033],
        [38883],
        [35674],
        [33367],
        [35244],
        [35225],
        [39911],
        [37784]], device='cuda:0')
[2024-07-24 10:20:08,650][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[13429],
        [ 8286],
        [10612],
        [17234],
        [19471],
        [18758],
        [22847],
        [24547],
        [19742],
        [19859],
        [20532],
        [22270],
        [25295],
        [20765]], device='cuda:0')
[2024-07-24 10:20:08,651][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[29035],
        [26186],
        [24925],
        [23305],
        [22385],
        [22810],
        [22361],
        [20490],
        [20770],
        [19997],
        [19995],
        [19922],
        [19139],
        [19334]], device='cuda:0')
[2024-07-24 10:20:08,652][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[ 1749],
        [ 1922],
        [ 1985],
        [ 3314],
        [ 2412],
        [ 2392],
        [ 3364],
        [ 3317],
        [ 3569],
        [ 6559],
        [ 5543],
        [10522],
        [12144],
        [ 7067]], device='cuda:0')
[2024-07-24 10:20:08,653][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[29363],
        [27439],
        [28332],
        [27595],
        [26537],
        [21624],
        [16705],
        [26680],
        [15610],
        [27377],
        [23123],
        [12872],
        [26003],
        [11001]], device='cuda:0')
[2024-07-24 10:20:08,654][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[20699],
        [24660],
        [17674],
        [13016],
        [ 9908],
        [ 5306],
        [ 4088],
        [ 4405],
        [ 6498],
        [10302],
        [ 7693],
        [ 6384],
        [ 6037],
        [ 4589]], device='cuda:0')
[2024-07-24 10:20:08,656][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[25163],
        [11227],
        [ 9161],
        [ 8633],
        [ 8528],
        [ 8011],
        [ 7797],
        [ 7761],
        [ 7399],
        [ 6773],
        [ 6801],
        [ 6460],
        [ 6158],
        [ 5939]], device='cuda:0')
[2024-07-24 10:20:08,658][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 4659],
        [  727],
        [ 4996],
        [ 7407],
        [12204],
        [21125],
        [10053],
        [19173],
        [11371],
        [ 1254],
        [ 7404],
        [14727],
        [19793],
        [32973]], device='cuda:0')
[2024-07-24 10:20:08,659][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[5009],
        [8231],
        [7578],
        [9632],
        [9125],
        [7803],
        [7675],
        [8219],
        [8220],
        [8285],
        [8047],
        [8053],
        [8306],
        [8195]], device='cuda:0')
[2024-07-24 10:20:08,660][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[7520],
        [4726],
        [4115],
        [3405],
        [3343],
        [3253],
        [2888],
        [3203],
        [2194],
        [2167],
        [2145],
        [1665],
        [9114],
        [4093]], device='cuda:0')
[2024-07-24 10:20:08,661][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[12942],
        [ 4838],
        [ 5424],
        [ 5310],
        [ 5079],
        [ 5103],
        [ 5954],
        [ 6060],
        [ 5723],
        [ 4975],
        [ 5021],
        [ 5171],
        [ 4726],
        [ 4819]], device='cuda:0')
[2024-07-24 10:20:08,663][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[ 864],
        [2064],
        [1932],
        [2025],
        [2039],
        [1992],
        [1995],
        [2246],
        [2215],
        [2264],
        [2255],
        [2241],
        [2278],
        [2271]], device='cuda:0')
[2024-07-24 10:20:08,664][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[2999],
        [3021],
        [2032],
        [2117],
        [2508],
        [3651],
        [2145],
        [3757],
        [4989],
        [4695],
        [2061],
        [1973],
        [3949],
        [3857]], device='cuda:0')
[2024-07-24 10:20:08,667][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[1567],
        [1588],
        [1623],
        [1532],
        [1453],
        [1436],
        [1384],
        [1462],
        [1876],
        [2068],
        [1848],
        [1858],
        [2079],
        [2094]], device='cuda:0')
[2024-07-24 10:20:08,667][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[13369],
        [ 2051],
        [ 5031],
        [ 2444],
        [12055],
        [24637],
        [34294],
        [27378],
        [24887],
        [17260],
        [19482],
        [32563],
        [30032],
        [27816]], device='cuda:0')
[2024-07-24 10:20:08,668][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[11709],
        [14226],
        [15186],
        [14416],
        [14186],
        [13823],
        [14137],
        [13745],
        [13525],
        [13461],
        [13516],
        [13636],
        [13867],
        [13867]], device='cuda:0')
[2024-07-24 10:20:08,669][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[10556],
        [10630],
        [11226],
        [11613],
        [11131],
        [ 5456],
        [ 8851],
        [ 9567],
        [ 8541],
        [11855],
        [11910],
        [16047],
        [12101],
        [10326]], device='cuda:0')
[2024-07-24 10:20:08,671][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[2569],
        [7830],
        [9418],
        [7046],
        [7614],
        [6330],
        [6066],
        [6705],
        [5625],
        [5003],
        [5741],
        [5379],
        [5903],
        [5486]], device='cuda:0')
[2024-07-24 10:20:08,672][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[6903],
        [7983],
        [5452],
        [6763],
        [6855],
        [4449],
        [3756],
        [6209],
        [2273],
        [2825],
        [2816],
        [2502],
        [3123],
        [2678]], device='cuda:0')
[2024-07-24 10:20:08,675][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 2228],
        [44874],
        [43965],
        [44090],
        [43790],
        [42392],
        [41180],
        [44280],
        [43947],
        [44242],
        [43665],
        [42960],
        [41743],
        [40010]], device='cuda:0')
[2024-07-24 10:20:08,676][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[29014],
        [29429],
        [27029],
        [29053],
        [26325],
        [22072],
        [23386],
        [21893],
        [22109],
        [22988],
        [24323],
        [22810],
        [21816],
        [22253]], device='cuda:0')
[2024-07-24 10:20:08,677][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[37497],
        [20095],
        [31626],
        [28547],
        [25465],
        [38916],
        [41496],
        [29235],
        [44192],
        [49168],
        [42336],
        [33382],
        [22259],
        [25391]], device='cuda:0')
[2024-07-24 10:20:08,678][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[40455],
        [40455],
        [40455],
        [40455],
        [40455],
        [40455],
        [40455],
        [40455],
        [40455],
        [40455],
        [40455],
        [40455],
        [40455],
        [40455]], device='cuda:0')
[2024-07-24 10:20:08,711][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:20:08,711][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:08,712][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:08,712][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:08,712][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:08,713][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:08,713][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:08,713][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:08,713][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:08,714][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:08,714][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:08,714][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:08,715][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:08,716][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Benjamin] are: tensor([9.9962e-01, 3.8109e-04], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:08,718][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Benjamin] are: tensor([0.5745, 0.4255], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:08,718][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Benjamin] are: tensor([0.0066, 0.9934], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:08,719][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Benjamin] are: tensor([0.1444, 0.8556], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:08,719][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Benjamin] are: tensor([0.8387, 0.1613], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:08,719][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Benjamin] are: tensor([0.7748, 0.2252], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:08,719][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Benjamin] are: tensor([0.4080, 0.5920], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:08,720][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Benjamin] are: tensor([0.9261, 0.0739], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:08,720][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Benjamin] are: tensor([0.6738, 0.3262], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:08,721][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Benjamin] are: tensor([0.0576, 0.9424], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:08,724][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Benjamin] are: tensor([0.5815, 0.4185], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:08,725][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Benjamin] are: tensor([0.1660, 0.8340], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:08,725][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ and] are: tensor([9.5902e-01, 5.4231e-04, 4.0443e-02], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:08,725][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.4199, 0.2957, 0.2844], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:08,726][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0023, 0.0329, 0.9648], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:08,726][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0087, 0.8326, 0.1588], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:08,726][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.6923, 0.1507, 0.1571], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:08,727][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.5278, 0.3255, 0.1467], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:08,727][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.2605, 0.3872, 0.3523], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:08,729][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0686, 0.9258, 0.0056], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:08,731][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.5430, 0.3829, 0.0741], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:08,732][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0393, 0.3879, 0.5727], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:08,732][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.3549, 0.2851, 0.3600], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:08,732][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0480, 0.2933, 0.6587], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:08,733][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Alexander] are: tensor([9.0839e-01, 8.9109e-04, 4.5844e-02, 4.4876e-02], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:08,733][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Alexander] are: tensor([0.3140, 0.2328, 0.2264, 0.2268], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:08,733][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Alexander] are: tensor([3.8445e-05, 3.0725e-02, 9.6150e-01, 7.7354e-03], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:08,734][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Alexander] are: tensor([0.0526, 0.2736, 0.4821, 0.1916], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:08,735][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Alexander] are: tensor([0.6056, 0.1237, 0.1358, 0.1349], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:08,738][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Alexander] are: tensor([0.3786, 0.3735, 0.1643, 0.0836], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:08,738][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Alexander] are: tensor([0.1840, 0.2906, 0.2611, 0.2643], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:08,739][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Alexander] are: tensor([0.2547, 0.3539, 0.3649, 0.0265], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:08,739][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Alexander] are: tensor([0.4669, 0.3182, 0.1230, 0.0918], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:08,739][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Alexander] are: tensor([0.0200, 0.2786, 0.3996, 0.3018], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:08,740][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Alexander] are: tensor([0.2185, 0.1945, 0.2475, 0.3394], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:08,740][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Alexander] are: tensor([0.0050, 0.2313, 0.6674, 0.0962], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:08,740][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ went] are: tensor([9.7977e-01, 9.0561e-05, 1.0287e-02, 8.8148e-03, 1.0349e-03],
       device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:08,742][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ went] are: tensor([0.2623, 0.1895, 0.1845, 0.1838, 0.1799], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:08,745][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ went] are: tensor([2.0164e-04, 4.2217e-02, 9.0226e-01, 1.0965e-02, 4.4358e-02],
       device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:08,745][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ went] are: tensor([0.0509, 0.3445, 0.2588, 0.3333, 0.0124], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:08,746][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ went] are: tensor([0.5590, 0.1046, 0.1109, 0.1116, 0.1139], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:08,746][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ went] are: tensor([0.3389, 0.1804, 0.1303, 0.0932, 0.2573], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:08,746][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ went] are: tensor([0.1411, 0.2333, 0.2078, 0.2097, 0.2081], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:08,747][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ went] are: tensor([4.4188e-02, 2.0738e-01, 9.3322e-02, 6.5457e-01, 5.4203e-04],
       device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:08,747][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.5179, 0.2381, 0.0829, 0.1237, 0.0373], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:08,747][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ went] are: tensor([0.0185, 0.1684, 0.2465, 0.1826, 0.3841], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:08,750][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ went] are: tensor([0.1415, 0.1471, 0.1868, 0.2824, 0.2422], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:08,752][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ went] are: tensor([0.0257, 0.1033, 0.5898, 0.1302, 0.1510], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:08,752][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.6321, 0.0019, 0.1334, 0.0995, 0.0317, 0.1014], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:08,752][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.2176, 0.1552, 0.1500, 0.1508, 0.1492, 0.1772], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:08,753][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ to] are: tensor([7.9183e-05, 1.0405e-02, 6.8339e-01, 2.8548e-03, 2.6518e-02, 2.7676e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:08,753][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0028, 0.2742, 0.0830, 0.2598, 0.3647, 0.0156], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:08,753][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.4687, 0.0987, 0.1032, 0.1066, 0.1086, 0.1142], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:08,754][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.1337, 0.3235, 0.1194, 0.1160, 0.2438, 0.0635], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:08,754][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1257, 0.1856, 0.1688, 0.1721, 0.1730, 0.1747], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:08,757][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0082, 0.1190, 0.0112, 0.8423, 0.0162, 0.0031], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:08,758][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.3224, 0.2279, 0.1025, 0.1463, 0.1135, 0.0875], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:08,759][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0212, 0.1503, 0.1838, 0.1523, 0.2958, 0.1967], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:08,759][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.1723, 0.1650, 0.1661, 0.2015, 0.1590, 0.1361], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:08,760][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0570, 0.0628, 0.2005, 0.0573, 0.1285, 0.4939], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:08,760][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.5272, 0.0018, 0.1223, 0.0793, 0.0266, 0.0881, 0.1549],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:08,760][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.1890, 0.1343, 0.1306, 0.1300, 0.1283, 0.1567, 0.1311],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:08,761][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ the] are: tensor([1.3123e-04, 1.0603e-02, 4.8364e-01, 2.9615e-03, 3.0278e-02, 4.2111e-01,
        5.1285e-02], device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:08,761][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0107, 0.2634, 0.1008, 0.2780, 0.1744, 0.0655, 0.1072],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:08,763][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.4431, 0.0877, 0.0904, 0.0916, 0.0932, 0.0988, 0.0953],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:08,765][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.1433, 0.3018, 0.1182, 0.1854, 0.1708, 0.0717, 0.0089],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:08,766][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.1024, 0.1599, 0.1437, 0.1455, 0.1479, 0.1515, 0.1492],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:08,766][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0169, 0.4812, 0.0120, 0.4179, 0.0414, 0.0116, 0.0190],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:08,766][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.3605, 0.2547, 0.0722, 0.0970, 0.0705, 0.0883, 0.0568],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:08,767][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0185, 0.1221, 0.1488, 0.1230, 0.2640, 0.1954, 0.1282],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:08,767][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.1292, 0.1032, 0.1279, 0.1453, 0.1230, 0.1225, 0.2489],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:08,767][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0492, 0.0564, 0.1114, 0.0424, 0.0893, 0.5513, 0.1001],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:08,768][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ station] are: tensor([8.3582e-01, 7.7704e-04, 3.8585e-02, 2.6683e-02, 5.8103e-03, 2.8446e-02,
        5.4354e-02, 9.5217e-03], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:08,770][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ station] are: tensor([0.1649, 0.1186, 0.1147, 0.1165, 0.1144, 0.1368, 0.1144, 0.1197],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:08,772][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ station] are: tensor([2.2090e-04, 1.6816e-02, 4.7984e-01, 3.3405e-03, 1.8651e-02, 3.4781e-01,
        7.7925e-02, 5.5399e-02], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:08,772][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ station] are: tensor([0.0235, 0.4559, 0.1181, 0.0849, 0.0618, 0.1030, 0.1387, 0.0141],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:08,773][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ station] are: tensor([0.3864, 0.0738, 0.0828, 0.0864, 0.0868, 0.0915, 0.0864, 0.1060],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:08,773][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ station] are: tensor([0.1348, 0.1862, 0.0762, 0.1055, 0.3327, 0.0266, 0.0071, 0.1309],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:08,774][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ station] are: tensor([0.0851, 0.1410, 0.1258, 0.1257, 0.1287, 0.1332, 0.1304, 0.1302],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:08,774][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ station] are: tensor([0.0491, 0.0686, 0.0919, 0.2433, 0.0643, 0.1020, 0.3790, 0.0017],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:08,774][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ station] are: tensor([0.2720, 0.2080, 0.0798, 0.0943, 0.0716, 0.1058, 0.0861, 0.0825],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:08,776][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ station] are: tensor([0.0145, 0.1010, 0.1261, 0.1019, 0.2139, 0.1677, 0.1062, 0.1687],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:08,779][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ station] are: tensor([0.0792, 0.0706, 0.0936, 0.1168, 0.1032, 0.1028, 0.2121, 0.2216],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:08,779][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ station] are: tensor([4.6460e-04, 6.8403e-02, 1.2479e-01, 3.2279e-02, 5.1641e-02, 5.5288e-01,
        1.5984e-01, 9.7010e-03], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:08,780][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.5359, 0.0014, 0.0851, 0.0541, 0.0154, 0.0544, 0.0867, 0.0153, 0.1518],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:08,780][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.1479, 0.1048, 0.1016, 0.1031, 0.1012, 0.1209, 0.1024, 0.1053, 0.1129],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:08,780][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [,] are: tensor([8.6117e-05, 6.4097e-03, 3.3263e-01, 2.1996e-03, 1.9765e-02, 2.7049e-01,
        3.6331e-02, 4.2181e-02, 2.8991e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:08,781][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0051, 0.2945, 0.0438, 0.1504, 0.1565, 0.0455, 0.2087, 0.0653, 0.0304],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:08,781][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.3483, 0.0734, 0.0764, 0.0780, 0.0781, 0.0825, 0.0800, 0.0884, 0.0950],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:08,783][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.1445, 0.1605, 0.0780, 0.1787, 0.2547, 0.0350, 0.0161, 0.1255, 0.0071],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:08,786][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0809, 0.1227, 0.1090, 0.1113, 0.1120, 0.1148, 0.1140, 0.1150, 0.1203],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:08,786][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0076, 0.1086, 0.0035, 0.1488, 0.0274, 0.0066, 0.4891, 0.2073, 0.0011],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:08,786][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.2032, 0.1765, 0.0668, 0.0893, 0.0945, 0.0839, 0.1069, 0.1317, 0.0472],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:08,787][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0145, 0.0822, 0.1070, 0.0899, 0.1900, 0.1497, 0.1042, 0.1592, 0.1033],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:08,787][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0885, 0.0787, 0.0868, 0.1001, 0.0809, 0.0873, 0.1547, 0.1199, 0.2030],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:08,788][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.1012, 0.0120, 0.0341, 0.0100, 0.0344, 0.1504, 0.0395, 0.0057, 0.6127],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:08,788][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Benjamin] are: tensor([0.3404, 0.0055, 0.1275, 0.0772, 0.0270, 0.0724, 0.1068, 0.0321, 0.1398,
        0.0714], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:08,790][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Benjamin] are: tensor([0.1281, 0.0963, 0.0930, 0.0942, 0.0922, 0.1092, 0.0918, 0.0967, 0.1011,
        0.0974], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:08,792][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Benjamin] are: tensor([3.9436e-05, 1.1139e-02, 2.8254e-01, 2.0316e-03, 1.0181e-02, 2.4425e-01,
        4.1939e-02, 4.1313e-02, 3.6248e-01, 4.0951e-03], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:08,793][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Benjamin] are: tensor([0.0045, 0.0482, 0.0915, 0.1658, 0.1516, 0.0630, 0.1640, 0.1945, 0.0766,
        0.0403], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:08,793][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Benjamin] are: tensor([0.3291, 0.0654, 0.0709, 0.0709, 0.0723, 0.0771, 0.0739, 0.0815, 0.0881,
        0.0708], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:08,794][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Benjamin] are: tensor([0.2439, 0.0796, 0.0518, 0.1472, 0.1429, 0.0540, 0.0148, 0.2218, 0.0132,
        0.0307], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:08,794][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Benjamin] are: tensor([0.0711, 0.1113, 0.0989, 0.0998, 0.1000, 0.1022, 0.1004, 0.1024, 0.1077,
        0.1062], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:08,794][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Benjamin] are: tensor([0.0457, 0.0033, 0.0230, 0.0662, 0.2294, 0.0103, 0.3274, 0.2652, 0.0122,
        0.0172], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:08,795][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Benjamin] are: tensor([0.2245, 0.1436, 0.0642, 0.0675, 0.0570, 0.0828, 0.0672, 0.1231, 0.0481,
        0.1220], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:08,797][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Benjamin] are: tensor([0.0098, 0.0883, 0.1136, 0.0930, 0.1938, 0.1386, 0.0789, 0.1288, 0.0797,
        0.0756], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:08,799][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Benjamin] are: tensor([0.0570, 0.0513, 0.0654, 0.0790, 0.0673, 0.0629, 0.1487, 0.1340, 0.2355,
        0.0990], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:08,800][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Benjamin] are: tensor([0.0007, 0.0140, 0.0469, 0.0110, 0.0319, 0.2224, 0.0485, 0.0102, 0.6094,
        0.0049], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:08,800][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([8.2790e-01, 2.8117e-04, 2.2525e-02, 1.6053e-02, 2.6889e-03, 1.4343e-02,
        2.5781e-02, 3.5623e-03, 4.2786e-02, 2.2223e-02, 2.1857e-02],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:08,800][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.1190, 0.0877, 0.0844, 0.0854, 0.0839, 0.0998, 0.0843, 0.0878, 0.0931,
        0.0891, 0.0855], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:08,801][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([3.6949e-05, 9.0033e-03, 2.5882e-01, 1.8494e-03, 8.9182e-03, 2.4285e-01,
        3.8197e-02, 4.5108e-02, 3.6365e-01, 5.8187e-03, 2.5747e-02],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:08,801][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.0121, 0.1730, 0.1459, 0.1527, 0.0439, 0.1230, 0.0850, 0.0246, 0.0702,
        0.1639, 0.0057], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:08,802][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.3002, 0.0618, 0.0657, 0.0673, 0.0678, 0.0719, 0.0693, 0.0772, 0.0815,
        0.0673, 0.0700], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:08,805][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.1747, 0.1493, 0.0471, 0.0765, 0.1467, 0.0251, 0.0109, 0.2251, 0.0120,
        0.0636, 0.0690], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:08,806][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0639, 0.1003, 0.0894, 0.0893, 0.0900, 0.0924, 0.0906, 0.0921, 0.0967,
        0.0951, 0.1002], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:08,806][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0321, 0.0403, 0.0146, 0.0529, 0.0211, 0.0229, 0.4097, 0.1977, 0.0195,
        0.1862, 0.0030], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:08,807][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.1941, 0.1295, 0.0583, 0.0579, 0.0761, 0.0708, 0.0627, 0.1161, 0.0496,
        0.1383, 0.0468], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:08,807][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.0098, 0.0656, 0.0880, 0.0690, 0.1421, 0.1213, 0.0800, 0.1209, 0.0862,
        0.0691, 0.1480], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:08,807][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0430, 0.0442, 0.0549, 0.0758, 0.0659, 0.0573, 0.1215, 0.1257, 0.1763,
        0.1000, 0.1355], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:08,808][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0100, 0.0136, 0.0493, 0.0084, 0.0207, 0.1697, 0.0402, 0.0052, 0.6303,
        0.0061, 0.0465], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:08,812][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.2152, 0.0024, 0.1127, 0.0558, 0.0321, 0.0673, 0.0973, 0.0245, 0.1648,
        0.0425, 0.1171, 0.0682], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:08,812][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.1091, 0.0791, 0.0769, 0.0775, 0.0773, 0.0915, 0.0779, 0.0801, 0.0865,
        0.0815, 0.0792, 0.0834], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:08,812][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ a] are: tensor([5.1975e-06, 5.8666e-03, 2.4482e-01, 1.2446e-03, 1.0237e-02, 3.1287e-01,
        2.7018e-02, 3.7147e-02, 3.2204e-01, 4.2713e-03, 3.0728e-02, 3.7532e-03],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:08,813][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0063, 0.0932, 0.0759, 0.1949, 0.1688, 0.0656, 0.0963, 0.0911, 0.0680,
        0.0763, 0.0449, 0.0186], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:08,813][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.2887, 0.0593, 0.0613, 0.0618, 0.0625, 0.0660, 0.0644, 0.0692, 0.0757,
        0.0621, 0.0646, 0.0646], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:08,814][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0672, 0.2570, 0.0815, 0.1600, 0.1205, 0.0372, 0.0124, 0.0892, 0.0223,
        0.0855, 0.0533, 0.0138], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:08,814][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0602, 0.0903, 0.0805, 0.0806, 0.0822, 0.0843, 0.0829, 0.0844, 0.0876,
        0.0858, 0.0920, 0.0891], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:08,818][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0043, 0.0416, 0.0052, 0.0640, 0.0122, 0.0118, 0.0607, 0.5108, 0.0082,
        0.2487, 0.0313, 0.0011], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:08,818][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.1867, 0.1466, 0.0497, 0.0579, 0.0656, 0.0607, 0.0399, 0.0993, 0.0435,
        0.1452, 0.0668, 0.0379], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:08,819][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0108, 0.0676, 0.0788, 0.0681, 0.1382, 0.1072, 0.0747, 0.1136, 0.0780,
        0.0637, 0.1443, 0.0551], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:08,819][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0509, 0.0409, 0.0504, 0.0626, 0.0540, 0.0591, 0.1082, 0.0954, 0.1464,
        0.0856, 0.1024, 0.1442], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:08,819][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0449, 0.0146, 0.0291, 0.0088, 0.0216, 0.1071, 0.0285, 0.0037, 0.4908,
        0.0052, 0.0815, 0.1641], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:08,820][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ computer] are: tensor([7.6703e-01, 5.5828e-04, 2.9053e-02, 2.0358e-02, 3.3048e-03, 1.4478e-02,
        2.6304e-02, 4.6926e-03, 4.3436e-02, 2.4745e-02, 2.0945e-02, 2.5907e-02,
        1.9193e-02], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:08,820][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ computer] are: tensor([0.1003, 0.0740, 0.0716, 0.0721, 0.0713, 0.0838, 0.0713, 0.0739, 0.0791,
        0.0750, 0.0728, 0.0764, 0.0784], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:08,822][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ computer] are: tensor([2.6218e-05, 8.4875e-03, 2.6776e-01, 1.1924e-03, 8.1445e-03, 1.7489e-01,
        4.1526e-02, 3.4414e-02, 4.1579e-01, 3.3316e-03, 2.6468e-02, 7.0101e-03,
        1.0957e-02], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:08,824][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ computer] are: tensor([0.0070, 0.1676, 0.0672, 0.1903, 0.0305, 0.0455, 0.1000, 0.0722, 0.0482,
        0.1501, 0.0351, 0.0568, 0.0294], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:08,825][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ computer] are: tensor([0.2566, 0.0519, 0.0577, 0.0585, 0.0590, 0.0633, 0.0601, 0.0713, 0.0729,
        0.0589, 0.0626, 0.0614, 0.0658], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:08,825][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ computer] are: tensor([0.1382, 0.0999, 0.0342, 0.0828, 0.1882, 0.0318, 0.0158, 0.1658, 0.0200,
        0.0634, 0.0997, 0.0208, 0.0394], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:08,825][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ computer] are: tensor([0.0545, 0.0839, 0.0746, 0.0730, 0.0742, 0.0781, 0.0766, 0.0776, 0.0800,
        0.0785, 0.0847, 0.0823, 0.0820], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:08,826][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ computer] are: tensor([0.0292, 0.0381, 0.0163, 0.0551, 0.0132, 0.0214, 0.1231, 0.3498, 0.0085,
        0.1941, 0.0566, 0.0938, 0.0010], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:08,826][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ computer] are: tensor([0.1867, 0.1639, 0.0442, 0.0612, 0.0316, 0.0575, 0.0411, 0.0812, 0.0338,
        0.1468, 0.0605, 0.0487, 0.0430], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:08,830][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ computer] are: tensor([0.0081, 0.0479, 0.0706, 0.0521, 0.1203, 0.0948, 0.0700, 0.1079, 0.0720,
        0.0606, 0.1292, 0.0514, 0.1151], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:08,831][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ computer] are: tensor([0.0305, 0.0249, 0.0359, 0.0454, 0.0425, 0.0467, 0.0906, 0.0961, 0.1530,
        0.0729, 0.1048, 0.1544, 0.1022], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:08,831][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ computer] are: tensor([0.0027, 0.0158, 0.0187, 0.0053, 0.0127, 0.1118, 0.0428, 0.0039, 0.3599,
        0.0058, 0.0681, 0.2772, 0.0750], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:08,831][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.2279, 0.0024, 0.0990, 0.0529, 0.0303, 0.0549, 0.0764, 0.0235, 0.1367,
        0.0368, 0.1015, 0.0522, 0.0633, 0.0421], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:08,832][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0947, 0.0670, 0.0648, 0.0660, 0.0658, 0.0766, 0.0660, 0.0676, 0.0731,
        0.0693, 0.0676, 0.0709, 0.0717, 0.0788], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:08,832][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ to] are: tensor([6.4903e-06, 3.9362e-03, 3.0871e-01, 7.5556e-04, 8.3627e-03, 1.1027e-01,
        3.2515e-02, 2.6235e-02, 4.3012e-01, 3.5963e-03, 3.3921e-02, 2.9888e-03,
        1.2156e-02, 2.6430e-02], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:08,833][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0013, 0.1330, 0.0362, 0.1393, 0.1851, 0.0075, 0.1259, 0.0852, 0.0318,
        0.1250, 0.0390, 0.0338, 0.0531, 0.0037], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:08,836][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.2517, 0.0510, 0.0533, 0.0542, 0.0552, 0.0583, 0.0576, 0.0627, 0.0681,
        0.0548, 0.0577, 0.0580, 0.0578, 0.0596], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:08,837][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0693, 0.1727, 0.1027, 0.0458, 0.1230, 0.0490, 0.0157, 0.0817, 0.0279,
        0.0528, 0.0766, 0.0242, 0.1095, 0.0489], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:08,837][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0502, 0.0759, 0.0677, 0.0683, 0.0701, 0.0712, 0.0710, 0.0725, 0.0742,
        0.0723, 0.0777, 0.0760, 0.0753, 0.0777], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:08,838][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ to] are: tensor([1.2447e-03, 1.2420e-02, 1.6444e-03, 1.0541e-01, 2.2815e-03, 3.2008e-04,
        1.7120e-01, 3.8752e-01, 2.8206e-03, 1.0599e-01, 2.7101e-02, 2.6987e-02,
        1.5386e-01, 1.1987e-03], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:08,838][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.1305, 0.1125, 0.0483, 0.0667, 0.0532, 0.0395, 0.0625, 0.0834, 0.0415,
        0.1091, 0.0640, 0.0554, 0.0885, 0.0449], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:08,839][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0102, 0.0533, 0.0650, 0.0542, 0.1106, 0.0805, 0.0703, 0.0975, 0.0712,
        0.0542, 0.1237, 0.0517, 0.0968, 0.0608], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:08,839][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0513, 0.0421, 0.0454, 0.0539, 0.0453, 0.0572, 0.0875, 0.0745, 0.1111,
        0.0746, 0.0760, 0.1026, 0.0689, 0.1096], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:08,843][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0457, 0.0077, 0.0148, 0.0038, 0.0092, 0.0302, 0.0133, 0.0008, 0.2091,
        0.0021, 0.0384, 0.1071, 0.0307, 0.4870], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:08,875][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:20:08,876][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:08,876][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:08,877][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:08,877][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:08,877][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:08,878][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:08,878][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:08,878][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:08,879][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:08,882][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:08,883][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:08,883][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:08,883][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Benjamin] are: tensor([0.7096, 0.2904], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:08,884][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Benjamin] are: tensor([0.5245, 0.4755], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:08,884][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Benjamin] are: tensor([0.6414, 0.3586], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:08,884][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Benjamin] are: tensor([0.6195, 0.3805], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:08,885][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Benjamin] are: tensor([0.5379, 0.4621], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:08,885][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Benjamin] are: tensor([0.5670, 0.4330], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:08,886][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Benjamin] are: tensor([0.5056, 0.4944], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:08,889][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Benjamin] are: tensor([0.5933, 0.4067], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:08,889][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Benjamin] are: tensor([0.6063, 0.3937], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:08,890][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Benjamin] are: tensor([0.5123, 0.4877], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:08,890][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Benjamin] are: tensor([0.2156, 0.7844], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:08,890][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Benjamin] are: tensor([0.6330, 0.3670], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:08,891][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.5222, 0.1535, 0.3243], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:08,891][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.3529, 0.3225, 0.3246], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:08,891][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.4663, 0.2481, 0.2856], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:08,895][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0010, 0.9671, 0.0320], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:08,895][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.3663, 0.3177, 0.3160], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:08,896][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.3479, 0.3932, 0.2589], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:08,896][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0960, 0.8325, 0.0715], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:08,896][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.4431, 0.1061, 0.4508], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:08,897][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.1592, 0.8369, 0.0038], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:08,897][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.3030, 0.3898, 0.3073], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:08,897][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.4728, 0.1959, 0.3313], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:08,899][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.4610, 0.2548, 0.2841], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:08,902][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Alexander] are: tensor([0.4703, 0.1280, 0.2220, 0.1796], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:08,902][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Alexander] are: tensor([0.2705, 0.2473, 0.2499, 0.2322], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:08,902][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Alexander] are: tensor([0.3879, 0.1966, 0.2271, 0.1884], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:08,903][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Alexander] are: tensor([0.1409, 0.0301, 0.7757, 0.0532], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:08,903][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Alexander] are: tensor([0.2817, 0.2431, 0.2411, 0.2341], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:08,903][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Alexander] are: tensor([0.2035, 0.3535, 0.2165, 0.2264], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:08,904][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Alexander] are: tensor([0.1086, 0.3755, 0.3504, 0.1656], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:08,904][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Alexander] are: tensor([0.1226, 0.1499, 0.6547, 0.0728], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:08,909][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Alexander] are: tensor([0.2057, 0.3484, 0.3938, 0.0520], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:08,910][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Alexander] are: tensor([0.1685, 0.3668, 0.2800, 0.1847], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:08,911][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Alexander] are: tensor([0.1164, 0.5164, 0.0634, 0.3038], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:08,911][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Alexander] are: tensor([0.3731, 0.2083, 0.2660, 0.1526], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:08,912][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([0.4268, 0.0923, 0.2072, 0.0942, 0.1795], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:08,912][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([0.2207, 0.2016, 0.2046, 0.1891, 0.1840], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:08,912][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([0.3146, 0.1688, 0.1898, 0.1619, 0.1649], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:08,913][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([7.1389e-02, 5.1059e-02, 6.6752e-01, 2.1001e-01, 2.0117e-05],
       device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:08,913][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([0.2269, 0.1952, 0.1940, 0.1871, 0.1968], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:08,913][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([0.1557, 0.2027, 0.2383, 0.1605, 0.2428], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:08,914][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([0.0317, 0.3480, 0.0725, 0.5073, 0.0405], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:08,917][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([0.1944, 0.1055, 0.4561, 0.0502, 0.1939], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:08,918][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([0.2835, 0.4862, 0.0855, 0.1423, 0.0026], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:08,918][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([0.1158, 0.2076, 0.2682, 0.0801, 0.3283], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:08,918][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([0.1289, 0.3385, 0.0413, 0.2642, 0.2271], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:08,919][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([0.3632, 0.1543, 0.2208, 0.1341, 0.1277], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:08,919][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.3143, 0.1015, 0.1718, 0.0937, 0.1125, 0.2061], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:08,920][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.1821, 0.1689, 0.1694, 0.1587, 0.1537, 0.1672], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:08,920][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.2779, 0.1489, 0.1651, 0.1404, 0.1412, 0.1265], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:08,922][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([1.8878e-04, 4.2832e-02, 1.1493e-02, 8.6997e-01, 6.9316e-02, 6.1955e-03],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:08,924][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.1867, 0.1611, 0.1604, 0.1554, 0.1634, 0.1730], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:08,924][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.1586, 0.1920, 0.1640, 0.1503, 0.2074, 0.1277], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:08,924][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0234, 0.2353, 0.0894, 0.3530, 0.2138, 0.0850], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:08,925][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.3044, 0.0517, 0.2518, 0.0251, 0.1206, 0.2464], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:08,925][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0399, 0.4729, 0.1162, 0.3634, 0.0055, 0.0021], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:08,926][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0614, 0.1657, 0.1461, 0.0769, 0.4090, 0.1408], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:08,926][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0507, 0.1086, 0.0581, 0.1086, 0.0896, 0.5845], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:08,928][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.2579, 0.1526, 0.1751, 0.1274, 0.1308, 0.1563], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:08,930][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.2697, 0.0817, 0.1531, 0.0827, 0.0905, 0.1513, 0.1711],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:08,930][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.1578, 0.1451, 0.1467, 0.1368, 0.1323, 0.1460, 0.1353],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:08,931][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.2530, 0.1323, 0.1459, 0.1239, 0.1247, 0.1112, 0.1091],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:08,931][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0049, 0.0560, 0.0838, 0.5181, 0.0016, 0.3302, 0.0054],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:08,932][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.1621, 0.1383, 0.1376, 0.1323, 0.1398, 0.1487, 0.1412],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:08,932][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.1280, 0.1922, 0.1122, 0.1793, 0.1730, 0.1141, 0.1012],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:08,932][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0129, 0.1576, 0.0721, 0.3485, 0.1990, 0.1581, 0.0518],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:08,936][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.1708, 0.0441, 0.2250, 0.0197, 0.0973, 0.2304, 0.2126],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:08,936][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0304, 0.8143, 0.0208, 0.0918, 0.0165, 0.0228, 0.0034],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:08,937][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0532, 0.1741, 0.1398, 0.0800, 0.2894, 0.1644, 0.0991],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:08,937][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0314, 0.0987, 0.0278, 0.0890, 0.3844, 0.0189, 0.3498],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:08,938][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.2408, 0.1239, 0.1507, 0.1073, 0.1085, 0.1463, 0.1225],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:08,938][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ station] are: tensor([0.2388, 0.0780, 0.1369, 0.0717, 0.0727, 0.1474, 0.1390, 0.1155],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:08,938][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ station] are: tensor([0.1393, 0.1278, 0.1297, 0.1207, 0.1168, 0.1290, 0.1200, 0.1168],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:08,939][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ station] are: tensor([0.2199, 0.1174, 0.1330, 0.1123, 0.1150, 0.1059, 0.1028, 0.0937],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:08,941][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ station] are: tensor([7.8850e-03, 6.6152e-02, 6.7321e-02, 1.0863e-02, 5.0770e-04, 8.4326e-01,
        3.7413e-03, 2.7497e-04], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:08,943][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ station] are: tensor([0.1392, 0.1211, 0.1204, 0.1164, 0.1224, 0.1299, 0.1234, 0.1272],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:08,943][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ station] are: tensor([0.0857, 0.1445, 0.1205, 0.0892, 0.2454, 0.0960, 0.1060, 0.1127],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:08,943][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ station] are: tensor([0.0373, 0.0975, 0.1305, 0.1016, 0.1958, 0.2759, 0.1265, 0.0348],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:08,944][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ station] are: tensor([0.1723, 0.0403, 0.2060, 0.0166, 0.0774, 0.2036, 0.1988, 0.0852],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:08,944][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ station] are: tensor([0.2495, 0.3306, 0.1163, 0.1352, 0.0207, 0.1177, 0.0282, 0.0018],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:08,945][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ station] are: tensor([0.0463, 0.1574, 0.1170, 0.0747, 0.2126, 0.1588, 0.1012, 0.1319],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:08,945][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ station] are: tensor([0.0948, 0.0454, 0.0837, 0.0452, 0.2258, 0.1040, 0.0585, 0.3425],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:08,949][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ station] are: tensor([0.2097, 0.1144, 0.1339, 0.0938, 0.0987, 0.1285, 0.1181, 0.1029],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:08,949][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.2117, 0.0639, 0.1261, 0.0634, 0.0767, 0.1284, 0.1228, 0.0688, 0.1382],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:08,949][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.1238, 0.1139, 0.1151, 0.1077, 0.1043, 0.1143, 0.1066, 0.1043, 0.1100],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:08,950][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.2060, 0.1083, 0.1190, 0.1015, 0.1028, 0.0922, 0.0907, 0.0835, 0.0960],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:08,950][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0009, 0.3293, 0.0071, 0.3263, 0.0083, 0.1797, 0.1132, 0.0326, 0.0026],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:08,951][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.1215, 0.1068, 0.1063, 0.1029, 0.1083, 0.1147, 0.1094, 0.1126, 0.1176],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:08,951][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0966, 0.1296, 0.0962, 0.1375, 0.1690, 0.0759, 0.1294, 0.1010, 0.0649],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:08,955][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0152, 0.2567, 0.0367, 0.2188, 0.0773, 0.1099, 0.1903, 0.0579, 0.0373],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:08,955][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.1905, 0.0230, 0.1222, 0.0101, 0.0491, 0.1115, 0.1027, 0.0658, 0.3251],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:08,956][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.1455, 0.4278, 0.0263, 0.1063, 0.1092, 0.0114, 0.1390, 0.0248, 0.0098],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:08,956][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0390, 0.1494, 0.1095, 0.0870, 0.1684, 0.1634, 0.0872, 0.1237, 0.0723],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:08,957][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0489, 0.0554, 0.2714, 0.0139, 0.0293, 0.0543, 0.1797, 0.0263, 0.3208],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:08,957][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.1765, 0.0992, 0.1216, 0.0793, 0.0864, 0.1122, 0.1032, 0.1033, 0.1183],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:08,957][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Benjamin] are: tensor([0.1992, 0.0882, 0.1047, 0.0595, 0.0587, 0.1096, 0.1035, 0.0606, 0.1161,
        0.1000], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:08,961][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Benjamin] are: tensor([0.1123, 0.1032, 0.1044, 0.0971, 0.0940, 0.1035, 0.0964, 0.0939, 0.0992,
        0.0961], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:08,962][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Benjamin] are: tensor([0.1853, 0.0976, 0.1087, 0.0916, 0.0929, 0.0851, 0.0826, 0.0767, 0.0887,
        0.0909], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:08,962][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Benjamin] are: tensor([8.2565e-03, 1.1846e-03, 7.9718e-02, 1.3251e-01, 4.2372e-02, 5.8527e-01,
        2.6554e-02, 1.6021e-02, 1.0797e-01, 1.4614e-04], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:08,963][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Benjamin] are: tensor([0.1098, 0.0961, 0.0955, 0.0923, 0.0970, 0.1026, 0.0976, 0.1007, 0.1051,
        0.1033], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:08,963][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Benjamin] are: tensor([0.0816, 0.0821, 0.0721, 0.1281, 0.1253, 0.1019, 0.1118, 0.1278, 0.0701,
        0.0991], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:08,963][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Benjamin] are: tensor([0.0256, 0.0265, 0.0811, 0.0421, 0.1133, 0.2482, 0.0979, 0.0737, 0.2481,
        0.0436], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:08,964][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Benjamin] are: tensor([0.0337, 0.0225, 0.1120, 0.0100, 0.0488, 0.1337, 0.1322, 0.0637, 0.4207,
        0.0229], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:08,968][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Benjamin] are: tensor([0.0610, 0.0612, 0.1238, 0.0673, 0.0605, 0.1831, 0.1193, 0.0762, 0.1890,
        0.0586], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:08,968][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Benjamin] are: tensor([0.0440, 0.1245, 0.1158, 0.0906, 0.1200, 0.1231, 0.0916, 0.1152, 0.0703,
        0.1050], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:08,968][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Benjamin] are: tensor([0.0335, 0.1673, 0.0238, 0.0985, 0.1221, 0.0086, 0.2069, 0.0521, 0.0199,
        0.2674], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:08,969][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Benjamin] are: tensor([0.1565, 0.0868, 0.1001, 0.0755, 0.0798, 0.1013, 0.0955, 0.1051, 0.1110,
        0.0882], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:08,969][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.1817, 0.0521, 0.1058, 0.0496, 0.0648, 0.1183, 0.0976, 0.0562, 0.1155,
        0.0621, 0.0963], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:08,970][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.1027, 0.0942, 0.0957, 0.0885, 0.0857, 0.0949, 0.0883, 0.0858, 0.0909,
        0.0877, 0.0856], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:08,970][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.1672, 0.0906, 0.0997, 0.0847, 0.0859, 0.0785, 0.0767, 0.0710, 0.0816,
        0.0838, 0.0803], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:08,972][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([2.0759e-03, 6.5997e-03, 1.3277e-01, 1.7769e-02, 4.2823e-05, 7.7010e-01,
        1.2626e-03, 3.0338e-04, 6.8300e-02, 7.7682e-04, 1.4076e-06],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:08,974][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.0997, 0.0870, 0.0865, 0.0834, 0.0878, 0.0930, 0.0885, 0.0910, 0.0953,
        0.0937, 0.0942], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:08,974][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.0555, 0.1278, 0.0787, 0.1048, 0.1098, 0.0555, 0.0755, 0.1190, 0.0533,
        0.1157, 0.1045], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:08,975][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.0159, 0.1257, 0.0516, 0.1573, 0.0331, 0.0922, 0.1141, 0.0786, 0.1545,
        0.1564, 0.0206], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:08,975][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0874, 0.0222, 0.1172, 0.0090, 0.0412, 0.1080, 0.0977, 0.0580, 0.3123,
        0.0193, 0.1276], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:08,976][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.0951, 0.1334, 0.1694, 0.0276, 0.1161, 0.0590, 0.0315, 0.0905, 0.1793,
        0.0904, 0.0076], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:08,976][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.0392, 0.0661, 0.0701, 0.0308, 0.0988, 0.0882, 0.0526, 0.0557, 0.0594,
        0.0545, 0.3845], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:08,976][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0540, 0.0320, 0.0521, 0.0375, 0.2749, 0.0849, 0.0901, 0.0732, 0.0971,
        0.0824, 0.1217], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:08,980][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.1618, 0.0767, 0.1051, 0.0637, 0.0677, 0.1004, 0.0914, 0.0839, 0.1042,
        0.0781, 0.0669], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:08,980][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.1750, 0.0559, 0.0902, 0.0538, 0.0541, 0.0946, 0.0927, 0.0542, 0.0977,
        0.0637, 0.0557, 0.1125], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:08,981][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0935, 0.0861, 0.0871, 0.0813, 0.0789, 0.0865, 0.0806, 0.0788, 0.0832,
        0.0808, 0.0788, 0.0844], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:08,981][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.1680, 0.0859, 0.0932, 0.0781, 0.0787, 0.0701, 0.0687, 0.0635, 0.0738,
        0.0761, 0.0731, 0.0707], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:08,982][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0046, 0.0034, 0.0459, 0.2490, 0.0045, 0.3296, 0.0032, 0.0548, 0.3017,
        0.0004, 0.0020, 0.0010], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:08,982][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0912, 0.0793, 0.0790, 0.0763, 0.0802, 0.0850, 0.0809, 0.0834, 0.0873,
        0.0854, 0.0861, 0.0859], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:08,983][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0695, 0.1219, 0.0661, 0.0989, 0.1011, 0.0617, 0.0678, 0.0774, 0.0591,
        0.1265, 0.0835, 0.0666], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:08,986][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0070, 0.0896, 0.0534, 0.1681, 0.0610, 0.0963, 0.0339, 0.1471, 0.0827,
        0.1685, 0.0839, 0.0086], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:08,987][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0756, 0.0181, 0.1000, 0.0071, 0.0368, 0.0959, 0.0786, 0.0570, 0.2777,
        0.0162, 0.1212, 0.1158], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:08,987][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([2.7105e-02, 3.5007e-01, 4.5899e-02, 8.6475e-02, 2.0885e-02, 2.2707e-02,
        2.2568e-03, 1.6558e-02, 7.2882e-02, 3.2581e-01, 2.9107e-02, 2.4588e-04],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:08,988][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0199, 0.0497, 0.0435, 0.0202, 0.0740, 0.0538, 0.0305, 0.0524, 0.0293,
        0.0396, 0.5276, 0.0595], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:08,988][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0366, 0.0604, 0.0382, 0.0811, 0.1433, 0.0289, 0.1540, 0.0647, 0.0260,
        0.1252, 0.0728, 0.1689], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:08,988][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.1350, 0.0786, 0.0938, 0.0686, 0.0634, 0.0877, 0.0798, 0.0843, 0.1001,
        0.0782, 0.0677, 0.0628], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:08,989][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ computer] are: tensor([0.1521, 0.0504, 0.0917, 0.0443, 0.0509, 0.0825, 0.0919, 0.0517, 0.0930,
        0.0578, 0.0475, 0.0770, 0.1091], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:08,993][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ computer] are: tensor([0.0874, 0.0801, 0.0811, 0.0751, 0.0727, 0.0804, 0.0746, 0.0726, 0.0771,
        0.0747, 0.0730, 0.0784, 0.0727], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:08,993][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ computer] are: tensor([0.1546, 0.0797, 0.0873, 0.0725, 0.0740, 0.0666, 0.0651, 0.0593, 0.0682,
        0.0719, 0.0688, 0.0675, 0.0645], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:08,993][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ computer] are: tensor([1.4502e-03, 4.3878e-02, 4.8725e-02, 4.3501e-01, 3.2813e-04, 3.1757e-01,
        4.5003e-03, 3.8812e-02, 4.9665e-02, 2.4056e-02, 1.4504e-03, 3.3586e-02,
        9.7008e-04], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:08,994][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ computer] are: tensor([0.0855, 0.0737, 0.0731, 0.0706, 0.0745, 0.0791, 0.0749, 0.0776, 0.0810,
        0.0794, 0.0799, 0.0798, 0.0708], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:08,994][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ computer] are: tensor([0.0358, 0.0938, 0.0440, 0.0939, 0.1203, 0.0569, 0.0788, 0.1150, 0.0512,
        0.1072, 0.1015, 0.0665, 0.0350], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:08,995][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ computer] are: tensor([0.0108, 0.0940, 0.0476, 0.0664, 0.0528, 0.1296, 0.0648, 0.0666, 0.1040,
        0.1225, 0.1760, 0.0370, 0.0279], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:08,995][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ computer] are: tensor([0.0725, 0.0172, 0.1055, 0.0059, 0.0315, 0.0913, 0.0804, 0.0383, 0.2649,
        0.0124, 0.1103, 0.1223, 0.0475], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:08,999][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ computer] are: tensor([0.0543, 0.2805, 0.0230, 0.0523, 0.0015, 0.0215, 0.0037, 0.0102, 0.0236,
        0.4532, 0.0690, 0.0060, 0.0012], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:08,999][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ computer] are: tensor([0.0281, 0.0446, 0.0448, 0.0206, 0.0721, 0.0558, 0.0344, 0.0574, 0.0314,
        0.0348, 0.4018, 0.0720, 0.1021], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:09,000][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ computer] are: tensor([0.0852, 0.0182, 0.0613, 0.0278, 0.0599, 0.0228, 0.0599, 0.2542, 0.0466,
        0.0369, 0.0897, 0.0364, 0.2011], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:09,000][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ computer] are: tensor([0.1293, 0.0744, 0.0853, 0.0568, 0.0600, 0.0801, 0.0778, 0.0744, 0.0900,
        0.0753, 0.0689, 0.0696, 0.0584], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:09,000][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.1389, 0.0481, 0.0774, 0.0452, 0.0508, 0.0892, 0.0767, 0.0494, 0.0856,
        0.0551, 0.0536, 0.0792, 0.0542, 0.0966], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:09,001][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0800, 0.0739, 0.0745, 0.0697, 0.0676, 0.0740, 0.0689, 0.0675, 0.0713,
        0.0694, 0.0677, 0.0724, 0.0674, 0.0758], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:09,003][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1534, 0.0753, 0.0823, 0.0687, 0.0694, 0.0609, 0.0601, 0.0553, 0.0645,
        0.0664, 0.0634, 0.0622, 0.0596, 0.0584], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:09,005][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0003, 0.0111, 0.0173, 0.1712, 0.0725, 0.0067, 0.1360, 0.2020, 0.2713,
        0.0041, 0.0337, 0.0473, 0.0179, 0.0084], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:09,006][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0790, 0.0681, 0.0679, 0.0657, 0.0692, 0.0733, 0.0697, 0.0723, 0.0754,
        0.0738, 0.0743, 0.0743, 0.0662, 0.0709], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:09,006][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0665, 0.0884, 0.0631, 0.0731, 0.0860, 0.0554, 0.0715, 0.0606, 0.0572,
        0.0962, 0.0922, 0.0718, 0.0573, 0.0607], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:09,006][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0078, 0.1105, 0.0333, 0.1236, 0.0788, 0.0296, 0.0957, 0.0634, 0.1127,
        0.1486, 0.0476, 0.0451, 0.0682, 0.0353], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:09,007][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.1397, 0.0137, 0.0795, 0.0051, 0.0292, 0.0640, 0.0561, 0.0408, 0.1980,
        0.0118, 0.0886, 0.0787, 0.0497, 0.1452], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:09,007][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0298, 0.2048, 0.0878, 0.1582, 0.0042, 0.0014, 0.0963, 0.0120, 0.1548,
        0.1025, 0.0259, 0.0069, 0.1117, 0.0039], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:09,010][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0181, 0.0311, 0.0300, 0.0147, 0.0727, 0.0302, 0.0248, 0.0347, 0.0244,
        0.0274, 0.4992, 0.0533, 0.0602, 0.0794], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:09,012][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0145, 0.0364, 0.0150, 0.0318, 0.0268, 0.1951, 0.0236, 0.0321, 0.0366,
        0.0908, 0.0995, 0.0102, 0.0144, 0.3732], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:09,012][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.1182, 0.0702, 0.0800, 0.0583, 0.0559, 0.0695, 0.0687, 0.0661, 0.0853,
        0.0703, 0.0626, 0.0625, 0.0654, 0.0669], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:09,013][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:20:09,014][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 4929],
        [  751],
        [11152],
        [ 4392],
        [20812],
        [ 3937],
        [ 9937],
        [ 1112],
        [ 4652],
        [ 1091],
        [11431],
        [10942],
        [ 6451],
        [ 5837]], device='cuda:0')
[2024-07-24 10:20:09,017][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 4558],
        [  424],
        [ 5527],
        [ 3155],
        [17739],
        [ 1786],
        [ 3243],
        [ 1855],
        [ 2101],
        [   97],
        [ 4303],
        [ 4272],
        [ 4747],
        [ 1520]], device='cuda:0')
[2024-07-24 10:20:09,019][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[25466],
        [25459],
        [25518],
        [24943],
        [25322],
        [25485],
        [26811],
        [26279],
        [26669],
        [26165],
        [26099],
        [25882],
        [26189],
        [26010]], device='cuda:0')
[2024-07-24 10:20:09,020][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[38316],
        [37398],
        [37012],
        [36640],
        [35866],
        [35273],
        [34724],
        [34762],
        [34401],
        [34287],
        [34171],
        [34174],
        [34260],
        [34039]], device='cuda:0')
[2024-07-24 10:20:09,021][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 8182],
        [13433],
        [12945],
        [12972],
        [13038],
        [12217],
        [12187],
        [12806],
        [11257],
        [10986],
        [10943],
        [10866],
        [10878],
        [10824]], device='cuda:0')
[2024-07-24 10:20:09,022][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[36731],
        [47498],
        [47265],
        [41064],
        [42705],
        [38964],
        [41194],
        [45529],
        [43116],
        [37261],
        [43162],
        [39377],
        [44051],
        [42332]], device='cuda:0')
[2024-07-24 10:20:09,025][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[24978],
        [25745],
        [25892],
        [27187],
        [27617],
        [27792],
        [27966],
        [28422],
        [28673],
        [29406],
        [29646],
        [29755],
        [30211],
        [30151]], device='cuda:0')
[2024-07-24 10:20:09,026][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[42827],
        [28659],
        [25376],
        [19971],
        [33030],
        [25300],
        [23073],
        [32814],
        [31130],
        [33810],
        [30068],
        [21245],
        [33278],
        [33676]], device='cuda:0')
[2024-07-24 10:20:09,027][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[ 8489],
        [13917],
        [16524],
        [16660],
        [17006],
        [18307],
        [18655],
        [18530],
        [18347],
        [17959],
        [17880],
        [17722],
        [17666],
        [18146]], device='cuda:0')
[2024-07-24 10:20:09,028][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[ 3584],
        [ 4142],
        [23437],
        [ 6718],
        [20252],
        [24192],
        [23135],
        [ 8701],
        [13909],
        [13559],
        [12658],
        [28379],
        [18989],
        [23370]], device='cuda:0')
[2024-07-24 10:20:09,030][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[ 5467],
        [20479],
        [24891],
        [25135],
        [21275],
        [22728],
        [21896],
        [22288],
        [22641],
        [24438],
        [24880],
        [25820],
        [27144],
        [25187]], device='cuda:0')
[2024-07-24 10:20:09,033][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[3753],
        [7418],
        [8359],
        [9312],
        [8873],
        [8549],
        [8196],
        [7833],
        [7458],
        [7770],
        [7105],
        [6870],
        [7277],
        [7216]], device='cuda:0')
[2024-07-24 10:20:09,034][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[44174],
        [37074],
        [35301],
        [29702],
        [29081],
        [32485],
        [34032],
        [32037],
        [33135],
        [32385],
        [32134],
        [32615],
        [31505],
        [31955]], device='cuda:0')
[2024-07-24 10:20:09,034][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[39599],
        [30720],
        [35913],
        [35833],
        [34074],
        [37104],
        [37923],
        [38219],
        [41109],
        [40933],
        [41271],
        [39582],
        [37320],
        [40574]], device='cuda:0')
[2024-07-24 10:20:09,036][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[7618],
        [1115],
        [3864],
        [2411],
        [2376],
        [1193],
        [4696],
        [ 127],
        [2474],
        [7403],
        [ 409],
        [8119],
        [2506],
        [3831]], device='cuda:0')
[2024-07-24 10:20:09,039][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[5417],
        [4856],
        [5001],
        [5547],
        [5571],
        [5702],
        [5706],
        [6214],
        [6258],
        [6179],
        [6353],
        [6537],
        [6363],
        [6645]], device='cuda:0')
[2024-07-24 10:20:09,040][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[36377],
        [35853],
        [35778],
        [35424],
        [35069],
        [34692],
        [33950],
        [33818],
        [33567],
        [33403],
        [33322],
        [32986],
        [32890],
        [32751]], device='cuda:0')
[2024-07-24 10:20:09,041][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[25519],
        [22921],
        [20206],
        [19421],
        [18446],
        [18035],
        [17633],
        [16908],
        [16564],
        [16097],
        [15857],
        [15875],
        [15751],
        [15606]], device='cuda:0')
[2024-07-24 10:20:09,042][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[ 1493],
        [ 2657],
        [15983],
        [ 1243],
        [ 1708],
        [ 6549],
        [ 5514],
        [ 1213],
        [ 9940],
        [ 1796],
        [ 1138],
        [ 2765],
        [ 6051],
        [ 2411]], device='cuda:0')
[2024-07-24 10:20:09,044][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[6745],
        [5924],
        [5901],
        [5926],
        [6244],
        [6689],
        [6769],
        [6871],
        [7046],
        [7072],
        [7155],
        [7327],
        [7317],
        [7405]], device='cuda:0')
[2024-07-24 10:20:09,047][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[  656],
        [ 2136],
        [ 2445],
        [ 7153],
        [ 5261],
        [ 5093],
        [ 7193],
        [ 4842],
        [ 5867],
        [ 7872],
        [10073],
        [ 8389],
        [ 9143],
        [ 5900]], device='cuda:0')
[2024-07-24 10:20:09,047][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[5992],
        [ 765],
        [ 403],
        [ 510],
        [ 232],
        [ 214],
        [ 204],
        [ 309],
        [ 252],
        [6340],
        [ 681],
        [ 317],
        [ 461],
        [ 425]], device='cuda:0')
[2024-07-24 10:20:09,048][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[14428],
        [14243],
        [14054],
        [13434],
        [13156],
        [13449],
        [12915],
        [12996],
        [13275],
        [12845],
        [12809],
        [12631],
        [12572],
        [12956]], device='cuda:0')
[2024-07-24 10:20:09,050][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[ 4438],
        [ 8568],
        [15245],
        [12561],
        [12303],
        [11210],
        [13369],
        [ 7483],
        [10027],
        [ 4593],
        [ 8593],
        [15858],
        [16380],
        [12623]], device='cuda:0')
[2024-07-24 10:20:09,053][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[21730],
        [26953],
        [25056],
        [25994],
        [18042],
        [15874],
        [17648],
        [20074],
        [21159],
        [22999],
        [20558],
        [20266],
        [21184],
        [19933]], device='cuda:0')
[2024-07-24 10:20:09,054][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[1865],
        [5001],
        [7891],
        [5299],
        [7192],
        [1145],
        [2371],
        [5331],
        [7308],
        [3727],
        [3686],
        [1441],
        [2238],
        [1000]], device='cuda:0')
[2024-07-24 10:20:09,055][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[25463],
        [25017],
        [25548],
        [24617],
        [25481],
        [25402],
        [26559],
        [26503],
        [25136],
        [25113],
        [24762],
        [25124],
        [25198],
        [25196]], device='cuda:0')
[2024-07-24 10:20:09,056][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[24374],
        [26305],
        [24808],
        [27107],
        [28245],
        [30158],
        [28491],
        [30017],
        [27958],
        [23946],
        [27789],
        [28854],
        [27357],
        [28122]], device='cuda:0')
[2024-07-24 10:20:09,058][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[39547],
        [32075],
        [30001],
        [29723],
        [36814],
        [47062],
        [42438],
        [42138],
        [37786],
        [28077],
        [46108],
        [36433],
        [32971],
        [45050]], device='cuda:0')
[2024-07-24 10:20:09,060][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[24302],
        [24302],
        [24302],
        [24302],
        [24302],
        [24302],
        [24302],
        [24302],
        [24302],
        [24302],
        [24302],
        [24302],
        [24302],
        [24302]], device='cuda:0')
[2024-07-24 10:20:09,095][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:20:09,099][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:09,101][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:09,101][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:09,102][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:09,102][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:09,102][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:09,103][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:09,103][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:09,103][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:09,104][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:09,104][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:09,104][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:09,104][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Benjamin] are: tensor([0.8064, 0.1936], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:09,107][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Benjamin] are: tensor([0.0988, 0.9012], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:09,109][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Benjamin] are: tensor([0.5809, 0.4191], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:09,109][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Benjamin] are: tensor([0.6703, 0.3297], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:09,109][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Benjamin] are: tensor([0.2618, 0.7382], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:09,110][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Benjamin] are: tensor([0.3873, 0.6127], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:09,110][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Benjamin] are: tensor([0.2982, 0.7018], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:09,110][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Benjamin] are: tensor([0.2050, 0.7950], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:09,110][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Benjamin] are: tensor([0.5120, 0.4880], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:09,111][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Benjamin] are: tensor([0.3464, 0.6536], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:09,112][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Benjamin] are: tensor([0.2005, 0.7995], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:09,114][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Benjamin] are: tensor([1.0000e+00, 1.7195e-11], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:09,115][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.6476, 0.2056, 0.1468], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:09,116][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0501, 0.3560, 0.5939], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:09,116][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.3913, 0.2369, 0.3719], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:09,116][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0221, 0.9757, 0.0022], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:09,117][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.1484, 0.3735, 0.4780], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:09,117][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.3900, 0.3850, 0.2250], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:09,117][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.1391, 0.3539, 0.5070], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:09,118][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.1265, 0.4663, 0.4072], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:09,118][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.3136, 0.3047, 0.3817], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:09,118][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.2187, 0.3678, 0.4134], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:09,119][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.1364, 0.3782, 0.4854], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:09,119][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ and] are: tensor([9.9938e-01, 6.2376e-04, 2.4467e-10], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:09,119][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Alexander] are: tensor([0.4715, 0.1739, 0.1462, 0.2085], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:09,119][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Alexander] are: tensor([0.0455, 0.2276, 0.4173, 0.3097], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:09,120][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Alexander] are: tensor([0.2904, 0.1789, 0.2870, 0.2438], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:09,120][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Alexander] are: tensor([0.0749, 0.3554, 0.1707, 0.3990], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:09,121][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Alexander] are: tensor([0.0863, 0.2299, 0.2902, 0.3935], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:09,121][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Alexander] are: tensor([0.0917, 0.4432, 0.3756, 0.0896], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:09,121][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Alexander] are: tensor([0.0971, 0.2538, 0.5044, 0.1447], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:09,122][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Alexander] are: tensor([0.1058, 0.3114, 0.2677, 0.3152], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:09,122][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Alexander] are: tensor([0.2281, 0.2238, 0.2728, 0.2754], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:09,122][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Alexander] are: tensor([0.1757, 0.3270, 0.2720, 0.2253], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:09,123][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Alexander] are: tensor([0.0567, 0.2674, 0.2414, 0.4345], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:09,123][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Alexander] are: tensor([9.7924e-01, 9.7332e-12, 2.0758e-02, 6.7149e-16], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:09,123][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ went] are: tensor([0.3956, 0.1379, 0.1374, 0.1906, 0.1387], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:09,124][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ went] are: tensor([0.0374, 0.1765, 0.3374, 0.2366, 0.2121], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:09,124][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ went] are: tensor([0.2602, 0.1505, 0.2399, 0.1952, 0.1542], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:09,124][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ went] are: tensor([0.0242, 0.2879, 0.0495, 0.6355, 0.0028], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:09,125][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ went] are: tensor([0.0733, 0.1897, 0.2334, 0.3288, 0.1747], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:09,125][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ went] are: tensor([0.1051, 0.4024, 0.3110, 0.1151, 0.0664], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:09,127][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ went] are: tensor([0.0703, 0.2019, 0.3604, 0.1659, 0.2015], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:09,129][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ went] are: tensor([0.0882, 0.2358, 0.2065, 0.2444, 0.2251], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:09,129][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.1784, 0.1712, 0.2135, 0.2089, 0.2280], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:09,130][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ went] are: tensor([0.1214, 0.2185, 0.2420, 0.2024, 0.2157], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:09,130][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ went] are: tensor([0.0681, 0.1639, 0.2004, 0.2241, 0.3435], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:09,130][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ went] are: tensor([1.6802e-01, 6.5914e-07, 8.3197e-01, 2.0457e-08, 6.6178e-15],
       device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:09,131][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.3429, 0.1169, 0.1013, 0.1553, 0.1617, 0.1219], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:09,131][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0312, 0.1458, 0.2318, 0.2103, 0.1838, 0.1970], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:09,132][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.2054, 0.1223, 0.1944, 0.1599, 0.1298, 0.1881], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:09,135][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0401, 0.5888, 0.0318, 0.2983, 0.0141, 0.0270], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:09,135][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0780, 0.1567, 0.1927, 0.2149, 0.1143, 0.2434], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:09,136][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0572, 0.5005, 0.2222, 0.1490, 0.0617, 0.0094], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:09,136][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0642, 0.1545, 0.2854, 0.1089, 0.1965, 0.1905], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:09,136][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0549, 0.2070, 0.1749, 0.1997, 0.1762, 0.1873], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:09,137][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.1459, 0.1399, 0.1723, 0.1677, 0.1814, 0.1927], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:09,137][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0821, 0.1660, 0.1844, 0.1837, 0.2097, 0.1741], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:09,137][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0520, 0.1616, 0.2025, 0.1808, 0.2134, 0.1898], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:09,139][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ to] are: tensor([9.9614e-01, 3.7430e-03, 7.1187e-07, 1.1997e-04, 2.3909e-10, 7.5598e-15],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:09,141][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.3073, 0.1072, 0.0892, 0.1486, 0.1224, 0.1343, 0.0910],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:09,142][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0208, 0.1214, 0.1958, 0.1755, 0.1578, 0.1766, 0.1522],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:09,142][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.1674, 0.1049, 0.1569, 0.1356, 0.1062, 0.1520, 0.1769],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:09,142][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0410, 0.5568, 0.0707, 0.2128, 0.0104, 0.1065, 0.0018],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:09,143][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0557, 0.1352, 0.1485, 0.1987, 0.0980, 0.1511, 0.2128],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:09,143][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0504, 0.3035, 0.1491, 0.0664, 0.1015, 0.0627, 0.2663],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:09,143][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0453, 0.1229, 0.2232, 0.0941, 0.1713, 0.1715, 0.1717],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:09,147][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0363, 0.1738, 0.1408, 0.1750, 0.1511, 0.1565, 0.1666],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:09,148][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.1223, 0.1194, 0.1490, 0.1455, 0.1588, 0.1660, 0.1390],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:09,148][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0728, 0.1444, 0.1565, 0.1514, 0.1624, 0.1642, 0.1483],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:09,148][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0386, 0.1327, 0.1435, 0.1743, 0.2264, 0.1353, 0.1493],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:09,149][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ the] are: tensor([6.3077e-01, 3.3021e-06, 3.6643e-01, 2.8176e-09, 8.1625e-10, 2.7960e-03,
        5.1394e-13], device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:09,149][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ station] are: tensor([0.2596, 0.0926, 0.0926, 0.1500, 0.1074, 0.1238, 0.0988, 0.0751],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:09,150][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ station] are: tensor([0.0202, 0.0928, 0.1774, 0.1381, 0.1382, 0.1624, 0.1551, 0.1158],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:09,151][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ station] are: tensor([0.1534, 0.0867, 0.1328, 0.1140, 0.0864, 0.1264, 0.1475, 0.1528],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:09,154][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ station] are: tensor([0.0383, 0.2864, 0.0177, 0.4237, 0.0066, 0.1224, 0.0951, 0.0098],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:09,154][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ station] are: tensor([0.0479, 0.1074, 0.1303, 0.1687, 0.0920, 0.1463, 0.1962, 0.1112],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:09,154][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ station] are: tensor([0.0411, 0.2412, 0.1696, 0.0908, 0.1088, 0.0882, 0.2331, 0.0272],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:09,155][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ station] are: tensor([0.0354, 0.1093, 0.1952, 0.0829, 0.1401, 0.1543, 0.1563, 0.1265],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:09,155][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ station] are: tensor([0.0494, 0.1387, 0.1259, 0.1415, 0.1255, 0.1314, 0.1424, 0.1453],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:09,155][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ station] are: tensor([0.1037, 0.1049, 0.1243, 0.1268, 0.1361, 0.1344, 0.1157, 0.1540],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:09,156][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ station] are: tensor([0.0673, 0.1223, 0.1247, 0.1244, 0.1645, 0.1315, 0.1457, 0.1195],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:09,160][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ station] are: tensor([0.0260, 0.1138, 0.1282, 0.1285, 0.1720, 0.1563, 0.1167, 0.1586],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:09,160][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ station] are: tensor([5.7019e-06, 1.2287e-09, 9.9043e-01, 4.9047e-11, 6.3066e-12, 9.4738e-03,
        8.6855e-05, 9.0048e-13], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:09,161][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.2373, 0.0912, 0.0689, 0.1201, 0.1122, 0.1046, 0.0887, 0.0834, 0.0935],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:09,161][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0252, 0.0855, 0.1390, 0.1214, 0.1151, 0.1315, 0.1315, 0.1093, 0.1416],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:09,161][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.1235, 0.0772, 0.1133, 0.0971, 0.0769, 0.1055, 0.1230, 0.1239, 0.1596],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:09,162][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [,] are: tensor([7.8267e-03, 3.6636e-01, 3.9058e-03, 1.3205e-01, 8.1221e-03, 2.2841e-02,
        1.0114e-02, 4.4856e-01, 2.1732e-04], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:09,162][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0359, 0.0918, 0.1095, 0.1258, 0.0699, 0.1343, 0.1687, 0.0813, 0.1829],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:09,166][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.1098, 0.1039, 0.1757, 0.0574, 0.1060, 0.0578, 0.3088, 0.0595, 0.0210],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:09,166][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0390, 0.0865, 0.1500, 0.0686, 0.1156, 0.1213, 0.1334, 0.1406, 0.1450],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:09,167][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0355, 0.1302, 0.1100, 0.1269, 0.1100, 0.1170, 0.1199, 0.1237, 0.1268],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:09,167][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0942, 0.0909, 0.1102, 0.1062, 0.1159, 0.1201, 0.1027, 0.1320, 0.1277],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:09,167][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0736, 0.1168, 0.1072, 0.1105, 0.1445, 0.1151, 0.1219, 0.1145, 0.0959],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:09,168][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0375, 0.1114, 0.1191, 0.1228, 0.1270, 0.1138, 0.1060, 0.1017, 0.1608],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:09,168][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [,] are: tensor([8.6637e-01, 8.9055e-10, 1.8544e-16, 1.6713e-10, 9.7368e-11, 1.9977e-14,
        2.0963e-08, 1.3363e-01, 5.8812e-22], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:09,172][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Benjamin] are: tensor([0.2288, 0.0705, 0.0757, 0.1131, 0.0871, 0.0979, 0.0832, 0.0690, 0.1021,
        0.0725], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:09,172][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Benjamin] are: tensor([0.0142, 0.0750, 0.1348, 0.1096, 0.1099, 0.1274, 0.1156, 0.0950, 0.1426,
        0.0757], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:09,173][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Benjamin] are: tensor([0.1345, 0.0547, 0.1015, 0.0797, 0.0653, 0.0906, 0.1070, 0.1174, 0.1595,
        0.0898], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:09,173][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Benjamin] are: tensor([0.0811, 0.0312, 0.0411, 0.1038, 0.0139, 0.1652, 0.0470, 0.3501, 0.0549,
        0.1117], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:09,174][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Benjamin] are: tensor([0.0295, 0.0868, 0.0987, 0.1366, 0.0690, 0.1043, 0.1430, 0.0770, 0.1456,
        0.1096], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:09,174][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Benjamin] are: tensor([0.0300, 0.0782, 0.1334, 0.0389, 0.0981, 0.1209, 0.2505, 0.1262, 0.0638,
        0.0599], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:09,174][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Benjamin] are: tensor([0.0257, 0.0599, 0.1374, 0.0547, 0.1199, 0.1076, 0.1215, 0.1644, 0.1502,
        0.0586], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:09,178][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Benjamin] are: tensor([0.0340, 0.1137, 0.0960, 0.1134, 0.0964, 0.1014, 0.1102, 0.1128, 0.1103,
        0.1120], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:09,179][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Benjamin] are: tensor([0.0838, 0.0806, 0.0965, 0.0959, 0.1047, 0.1043, 0.0901, 0.1179, 0.1102,
        0.1161], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:09,179][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Benjamin] are: tensor([0.0494, 0.0818, 0.1165, 0.1024, 0.1197, 0.1207, 0.1225, 0.1302, 0.1175,
        0.0394], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:09,179][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Benjamin] are: tensor([0.0190, 0.0758, 0.0977, 0.1285, 0.1094, 0.1099, 0.1104, 0.1164, 0.1433,
        0.0896], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:09,180][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Benjamin] are: tensor([9.0277e-01, 5.0090e-11, 5.4903e-02, 2.3080e-09, 9.5741e-07, 7.4033e-04,
        4.1448e-02, 1.2858e-04, 5.1712e-06, 3.9844e-10], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:09,180][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.2113, 0.0707, 0.0711, 0.0989, 0.0806, 0.1082, 0.0839, 0.0633, 0.1016,
        0.0695, 0.0408], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:09,181][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0159, 0.0736, 0.1251, 0.0981, 0.0844, 0.1155, 0.1067, 0.0835, 0.1295,
        0.0813, 0.0864], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:09,185][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.1148, 0.0559, 0.0912, 0.0722, 0.0590, 0.0844, 0.1002, 0.1034, 0.1369,
        0.0835, 0.0985], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:09,185][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([4.9343e-03, 2.2418e-01, 3.4600e-03, 1.4662e-01, 1.7706e-03, 1.7081e-02,
        2.8877e-03, 3.4423e-02, 1.0388e-03, 5.6318e-01, 4.1978e-04],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:09,185][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.0288, 0.0755, 0.0879, 0.1176, 0.0625, 0.0973, 0.1376, 0.0765, 0.1407,
        0.1018, 0.0738], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:09,186][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.0336, 0.2134, 0.1004, 0.0479, 0.0114, 0.0380, 0.2633, 0.0308, 0.0380,
        0.2057, 0.0175], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:09,186][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0283, 0.0754, 0.1348, 0.0501, 0.0968, 0.1015, 0.1133, 0.1151, 0.1394,
        0.0681, 0.0773], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:09,187][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0332, 0.0993, 0.0885, 0.0992, 0.0886, 0.0920, 0.0972, 0.0996, 0.1004,
        0.0985, 0.1036], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:09,187][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.0715, 0.0714, 0.0855, 0.0863, 0.0925, 0.0931, 0.0799, 0.1054, 0.0992,
        0.1041, 0.1111], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:09,191][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.0600, 0.0808, 0.1184, 0.0904, 0.1232, 0.1142, 0.1164, 0.0780, 0.1001,
        0.0421, 0.0764], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:09,191][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0230, 0.0754, 0.0800, 0.1161, 0.1461, 0.0834, 0.0865, 0.0980, 0.1106,
        0.0890, 0.0919], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:09,192][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([4.3384e-01, 8.3505e-09, 4.0238e-01, 4.9885e-09, 3.2081e-10, 1.5901e-01,
        2.8449e-03, 2.7740e-04, 1.6442e-03, 2.0181e-07, 2.1393e-10],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:09,192][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.1787, 0.0776, 0.0626, 0.0947, 0.0779, 0.0918, 0.0691, 0.0744, 0.0857,
        0.0812, 0.0512, 0.0550], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:09,192][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0167, 0.0699, 0.1047, 0.0983, 0.0847, 0.0997, 0.0904, 0.0812, 0.1151,
        0.0748, 0.0831, 0.0814], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:09,193][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0923, 0.0544, 0.0826, 0.0684, 0.0563, 0.0780, 0.0897, 0.0926, 0.1192,
        0.0780, 0.0900, 0.0984], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:09,193][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ a] are: tensor([8.7489e-03, 1.2653e-01, 3.2539e-02, 3.3239e-02, 3.2561e-03, 6.5843e-02,
        2.2069e-03, 1.5763e-01, 4.2723e-03, 5.5866e-01, 6.5985e-03, 4.7259e-04],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:09,197][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0386, 0.0842, 0.0941, 0.1167, 0.0592, 0.0793, 0.1082, 0.0569, 0.1081,
        0.0800, 0.0603, 0.1146], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:09,197][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0134, 0.2600, 0.0451, 0.0382, 0.0277, 0.0434, 0.1513, 0.0982, 0.0214,
        0.2272, 0.0367, 0.0373], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:09,198][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0235, 0.0571, 0.1214, 0.0479, 0.0878, 0.0906, 0.1064, 0.1188, 0.1307,
        0.0590, 0.0912, 0.0656], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:09,198][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0229, 0.0906, 0.0769, 0.0925, 0.0797, 0.0839, 0.0902, 0.0921, 0.0900,
        0.0911, 0.0928, 0.0973], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:09,199][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0658, 0.0651, 0.0791, 0.0775, 0.0839, 0.0861, 0.0733, 0.0959, 0.0927,
        0.0954, 0.1032, 0.0820], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:09,199][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0461, 0.0956, 0.0948, 0.0919, 0.1064, 0.0972, 0.0906, 0.0915, 0.0857,
        0.0535, 0.0875, 0.0594], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:09,199][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0203, 0.0871, 0.0752, 0.1110, 0.1121, 0.0722, 0.0764, 0.0809, 0.1019,
        0.0990, 0.0693, 0.0947], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:09,201][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ a] are: tensor([7.7989e-01, 1.0268e-08, 1.8281e-01, 4.1608e-11, 8.6137e-12, 1.6724e-03,
        7.2918e-13, 3.5460e-02, 1.5935e-04, 8.8835e-07, 1.8722e-06, 3.9743e-15],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:09,203][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ computer] are: tensor([0.1441, 0.0754, 0.0652, 0.1092, 0.0723, 0.0938, 0.0643, 0.0613, 0.0869,
        0.0800, 0.0393, 0.0575, 0.0507], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:09,204][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ computer] are: tensor([0.0189, 0.0599, 0.1018, 0.0782, 0.0793, 0.0984, 0.0891, 0.0719, 0.1004,
        0.0630, 0.0740, 0.0809, 0.0841], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:09,204][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ computer] are: tensor([0.0955, 0.0454, 0.0719, 0.0569, 0.0473, 0.0678, 0.0774, 0.0821, 0.1061,
        0.0678, 0.0773, 0.0856, 0.1188], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:09,204][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ computer] are: tensor([0.0063, 0.1350, 0.0068, 0.0553, 0.0031, 0.0318, 0.0186, 0.0273, 0.0008,
        0.6625, 0.0057, 0.0151, 0.0317], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:09,205][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ computer] are: tensor([0.0275, 0.0572, 0.0738, 0.0823, 0.0441, 0.0907, 0.1207, 0.0587, 0.1250,
        0.0800, 0.0542, 0.1310, 0.0548], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:09,205][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ computer] are: tensor([0.0287, 0.1946, 0.1203, 0.0383, 0.0487, 0.0654, 0.1168, 0.0510, 0.0567,
        0.1608, 0.0291, 0.0716, 0.0180], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:09,209][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ computer] are: tensor([0.0263, 0.0636, 0.1057, 0.0496, 0.0934, 0.0827, 0.0909, 0.0923, 0.1131,
        0.0575, 0.0859, 0.0688, 0.0703], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:09,209][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ computer] are: tensor([0.0281, 0.0803, 0.0720, 0.0842, 0.0701, 0.0754, 0.0817, 0.0863, 0.0830,
        0.0803, 0.0839, 0.0881, 0.0865], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:09,210][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ computer] are: tensor([0.0591, 0.0612, 0.0705, 0.0739, 0.0782, 0.0756, 0.0660, 0.0864, 0.0800,
        0.0872, 0.0916, 0.0734, 0.0970], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:09,210][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ computer] are: tensor([0.0421, 0.0895, 0.0907, 0.0891, 0.0972, 0.0811, 0.0940, 0.0814, 0.0753,
        0.0460, 0.0859, 0.0707, 0.0571], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:09,211][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ computer] are: tensor([0.0125, 0.0633, 0.0630, 0.0850, 0.1060, 0.0634, 0.0678, 0.0902, 0.0802,
        0.0758, 0.0541, 0.0789, 0.1597], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:09,211][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ computer] are: tensor([3.2678e-03, 1.1220e-12, 9.4233e-01, 1.8097e-12, 1.1325e-11, 5.3920e-02,
        1.0634e-04, 3.8138e-10, 3.5640e-04, 1.7863e-11, 1.3208e-08, 1.5900e-05,
        2.5213e-14], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:09,212][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.1559, 0.0666, 0.0511, 0.0857, 0.0782, 0.0625, 0.0703, 0.0650, 0.0737,
        0.0683, 0.0467, 0.0615, 0.0615, 0.0531], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:09,215][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0125, 0.0566, 0.0849, 0.0830, 0.0705, 0.0772, 0.0801, 0.0702, 0.0918,
        0.0625, 0.0641, 0.0772, 0.0954, 0.0739], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:09,216][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0813, 0.0432, 0.0654, 0.0545, 0.0441, 0.0615, 0.0710, 0.0738, 0.0945,
        0.0630, 0.0699, 0.0783, 0.1088, 0.0908], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:09,216][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0060, 0.0806, 0.0051, 0.0366, 0.0026, 0.0037, 0.0075, 0.1928, 0.0028,
        0.5130, 0.0075, 0.0048, 0.1269, 0.0100], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:09,217][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0340, 0.0626, 0.0737, 0.0767, 0.0418, 0.0895, 0.0987, 0.0486, 0.1043,
        0.0709, 0.0502, 0.1100, 0.0507, 0.0883], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:09,217][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0165, 0.2087, 0.0641, 0.0534, 0.0198, 0.0026, 0.1874, 0.0391, 0.0112,
        0.1985, 0.0183, 0.1268, 0.0519, 0.0018], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:09,217][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0214, 0.0536, 0.1007, 0.0395, 0.0682, 0.0667, 0.0824, 0.0945, 0.1020,
        0.0552, 0.0804, 0.0646, 0.1087, 0.0621], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:09,220][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0194, 0.0799, 0.0654, 0.0773, 0.0669, 0.0720, 0.0732, 0.0751, 0.0750,
        0.0789, 0.0780, 0.0803, 0.0811, 0.0775], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:09,222][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0554, 0.0559, 0.0659, 0.0651, 0.0696, 0.0715, 0.0617, 0.0782, 0.0758,
        0.0787, 0.0845, 0.0686, 0.0878, 0.0813], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:09,222][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0346, 0.0739, 0.0784, 0.0810, 0.0892, 0.0721, 0.0883, 0.0939, 0.0716,
        0.0421, 0.0692, 0.0677, 0.0838, 0.0542], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:09,222][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0207, 0.0644, 0.0834, 0.0757, 0.0873, 0.0799, 0.0704, 0.0615, 0.1038,
        0.0715, 0.0538, 0.0887, 0.0674, 0.0713], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:09,223][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ to] are: tensor([6.0356e-01, 1.3048e-05, 1.3632e-06, 7.1678e-08, 1.3882e-10, 9.0237e-14,
        1.9161e-04, 1.2694e-01, 1.2523e-09, 1.8468e-04, 4.2065e-08, 3.4851e-08,
        2.6911e-01, 3.2943e-14], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:09,259][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:20:09,259][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:09,259][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:09,260][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:09,260][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:09,260][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:09,261][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:09,261][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:09,261][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:09,262][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:09,262][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:09,262][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:09,262][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:09,263][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Benjamin] are: tensor([0.6376, 0.3624], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:09,263][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Benjamin] are: tensor([0.5658, 0.4342], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:09,263][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Benjamin] are: tensor([0.9198, 0.0802], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:09,264][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Benjamin] are: tensor([0.9576, 0.0424], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:09,264][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Benjamin] are: tensor([0.8632, 0.1368], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:09,266][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Benjamin] are: tensor([0.5522, 0.4478], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:09,268][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Benjamin] are: tensor([0.2352, 0.7648], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:09,268][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Benjamin] are: tensor([0.0613, 0.9387], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:09,269][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Benjamin] are: tensor([0.5602, 0.4398], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:09,269][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Benjamin] are: tensor([0.7661, 0.2339], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:09,269][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Benjamin] are: tensor([0.7507, 0.2493], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:09,270][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Benjamin] are: tensor([1.0000e+00, 5.3923e-09], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:09,270][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.6516, 0.3166, 0.0318], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:09,270][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.3437, 0.0283, 0.6280], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:09,271][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.6269, 0.0608, 0.3123], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:09,271][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.8471, 0.0748, 0.0781], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:09,271][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.1726, 0.0176, 0.8097], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:09,272][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.2597, 0.1241, 0.6162], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:09,272][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.1152, 0.4374, 0.4475], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:09,272][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0191, 0.2156, 0.7653], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:09,273][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.3683, 0.3085, 0.3232], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:09,273][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.4769, 0.1119, 0.4113], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:09,273][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.2904, 0.3487, 0.3609], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:09,274][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([9.8956e-01, 1.0440e-02, 1.0199e-07], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:09,274][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Alexander] are: tensor([0.2449, 0.2219, 0.4613, 0.0719], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:09,275][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Alexander] are: tensor([0.0375, 0.0220, 0.8304, 0.1100], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:09,275][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Alexander] are: tensor([0.2034, 0.1749, 0.4843, 0.1374], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:09,275][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Alexander] are: tensor([0.6223, 0.0975, 0.1508, 0.1294], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:09,276][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Alexander] are: tensor([0.1390, 0.0703, 0.1339, 0.6568], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:09,276][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Alexander] are: tensor([0.0513, 0.0886, 0.6884, 0.1717], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:09,276][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Alexander] are: tensor([0.0874, 0.2954, 0.3382, 0.2790], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:09,277][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Alexander] are: tensor([0.0150, 0.1950, 0.5097, 0.2803], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:09,279][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Alexander] are: tensor([0.2930, 0.2319, 0.2431, 0.2320], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:09,281][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Alexander] are: tensor([0.2845, 0.1156, 0.5201, 0.0798], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:09,281][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Alexander] are: tensor([0.4484, 0.1906, 0.2092, 0.1518], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:09,282][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Alexander] are: tensor([9.5210e-01, 2.7565e-03, 4.5089e-02, 5.7939e-05], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:09,282][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([0.0625, 0.2446, 0.5159, 0.1276, 0.0494], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:09,282][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([0.0207, 0.0338, 0.8283, 0.0980, 0.0191], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:09,283][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([0.1145, 0.0799, 0.6093, 0.1107, 0.0856], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:09,283][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([0.1684, 0.1795, 0.3165, 0.3071, 0.0285], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:09,283][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([0.1065, 0.0222, 0.1618, 0.0405, 0.6690], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:09,286][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([0.0254, 0.0370, 0.7942, 0.1359, 0.0076], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:09,288][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([0.0625, 0.2322, 0.2559, 0.2344, 0.2150], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:09,288][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([0.0113, 0.1115, 0.3316, 0.1849, 0.3607], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:09,288][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([0.2359, 0.1854, 0.1967, 0.1871, 0.1948], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:09,289][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([0.4349, 0.0735, 0.3380, 0.0712, 0.0824], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:09,289][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([0.3079, 0.1846, 0.2046, 0.0901, 0.2128], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:09,289][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([2.2432e-03, 4.2622e-01, 2.0131e-02, 5.5140e-01, 4.7260e-06],
       device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:09,290][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.2173, 0.2837, 0.0270, 0.0906, 0.3763, 0.0051], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:09,290][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.1566, 0.0323, 0.5199, 0.1228, 0.0882, 0.0803], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:09,293][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.6201, 0.0195, 0.1969, 0.0305, 0.0484, 0.0846], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:09,295][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.3731, 0.0948, 0.1587, 0.1132, 0.0648, 0.1954], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:09,295][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.1687, 0.0081, 0.5634, 0.1720, 0.0705, 0.0172], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:09,295][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.1701, 0.0273, 0.5554, 0.1064, 0.0535, 0.0873], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:09,296][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0516, 0.1873, 0.2019, 0.1818, 0.1804, 0.1970], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:09,296][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0249, 0.1090, 0.2451, 0.1110, 0.1993, 0.3108], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:09,296][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.1946, 0.1559, 0.1647, 0.1577, 0.1636, 0.1635], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:09,297][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.2918, 0.0445, 0.2004, 0.0466, 0.0813, 0.3355], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:09,297][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.3253, 0.1118, 0.1432, 0.0875, 0.1301, 0.2021], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:09,298][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([9.9712e-01, 9.3011e-05, 6.6009e-09, 4.3505e-06, 2.7824e-03, 1.9110e-06],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:09,301][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.4003, 0.2946, 0.0381, 0.0776, 0.1185, 0.0650, 0.0059],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:09,302][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0473, 0.0205, 0.5373, 0.1020, 0.0640, 0.1775, 0.0514],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:09,302][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.3809, 0.0232, 0.2818, 0.0378, 0.0740, 0.0976, 0.1047],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:09,302][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.3319, 0.0737, 0.1636, 0.0893, 0.0527, 0.2101, 0.0788],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:09,303][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.2030, 0.0303, 0.3700, 0.2491, 0.0201, 0.0081, 0.1194],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:09,303][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.1272, 0.0306, 0.4574, 0.0705, 0.0500, 0.2102, 0.0541],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:09,304][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0383, 0.1545, 0.1679, 0.1529, 0.1544, 0.1694, 0.1626],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:09,304][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0084, 0.0781, 0.1488, 0.0957, 0.1468, 0.2118, 0.3104],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:09,306][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.1707, 0.1332, 0.1412, 0.1341, 0.1399, 0.1404, 0.1405],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:09,308][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.1289, 0.0353, 0.1268, 0.0315, 0.0447, 0.2852, 0.3477],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:09,309][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.2271, 0.0833, 0.1111, 0.0738, 0.0995, 0.1701, 0.2351],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:09,309][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([9.9494e-01, 1.8777e-04, 2.1587e-05, 1.3459e-05, 1.0818e-03, 3.7548e-03,
        2.2745e-07], device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:09,309][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ station] are: tensor([0.1183, 0.1538, 0.2212, 0.1676, 0.0580, 0.2200, 0.0557, 0.0053],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:09,310][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ station] are: tensor([0.0383, 0.0160, 0.3170, 0.0637, 0.0689, 0.2021, 0.1890, 0.1049],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:09,310][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ station] are: tensor([0.3051, 0.0397, 0.2199, 0.0563, 0.0880, 0.1158, 0.1342, 0.0409],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:09,310][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ station] are: tensor([0.2825, 0.0911, 0.1163, 0.1054, 0.0518, 0.1552, 0.1368, 0.0609],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:09,311][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ station] are: tensor([2.0984e-02, 6.2682e-04, 1.2355e-01, 2.8646e-03, 9.9000e-03, 9.8440e-04,
        1.6897e-02, 8.2420e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:09,314][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ station] are: tensor([0.0381, 0.0214, 0.4396, 0.0559, 0.0467, 0.1766, 0.1461, 0.0755],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:09,318][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ station] are: tensor([0.0387, 0.1343, 0.1440, 0.1324, 0.1287, 0.1427, 0.1388, 0.1405],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:09,318][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ station] are: tensor([0.0047, 0.0517, 0.1523, 0.0701, 0.1178, 0.2015, 0.2344, 0.1674],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:09,318][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ station] are: tensor([0.1474, 0.1175, 0.1240, 0.1182, 0.1234, 0.1229, 0.1229, 0.1237],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:09,319][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ station] are: tensor([0.1554, 0.0339, 0.1301, 0.0233, 0.0362, 0.2097, 0.3102, 0.1013],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:09,319][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ station] are: tensor([0.1321, 0.0898, 0.1067, 0.0514, 0.0798, 0.1494, 0.2198, 0.1710],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:09,320][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ station] are: tensor([9.5190e-01, 5.8441e-03, 1.9225e-05, 2.3801e-04, 3.6045e-02, 3.6789e-04,
        5.4847e-03, 9.8912e-05], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:09,320][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.3475, 0.2208, 0.0249, 0.0686, 0.2138, 0.0274, 0.0379, 0.0519, 0.0073],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:09,320][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.1424, 0.0039, 0.2831, 0.0409, 0.0427, 0.1106, 0.0845, 0.0548, 0.2371],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:09,321][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.2825, 0.0157, 0.2036, 0.0415, 0.1128, 0.0953, 0.1103, 0.0270, 0.1113],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:09,321][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.2209, 0.0342, 0.0792, 0.0471, 0.0618, 0.1534, 0.1212, 0.1108, 0.1715],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:09,325][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0514, 0.0051, 0.2464, 0.0367, 0.0079, 0.0018, 0.0166, 0.3972, 0.2369],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:09,325][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0920, 0.0061, 0.2699, 0.0291, 0.0258, 0.0826, 0.1214, 0.0533, 0.3199],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:09,326][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0338, 0.1147, 0.1218, 0.1133, 0.1123, 0.1236, 0.1216, 0.1296, 0.1293],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:09,326][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0040, 0.0484, 0.1421, 0.0561, 0.0937, 0.1635, 0.1797, 0.1256, 0.1869],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:09,327][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.1276, 0.1045, 0.1104, 0.1061, 0.1101, 0.1097, 0.1098, 0.1108, 0.1109],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:09,327][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.1342, 0.0180, 0.0724, 0.0162, 0.0223, 0.1380, 0.1754, 0.1011, 0.3224],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:09,327][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.2169, 0.0514, 0.0679, 0.0537, 0.0615, 0.0966, 0.1435, 0.1113, 0.1973],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:09,328][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([6.4235e-01, 3.1765e-04, 7.2848e-07, 7.2566e-05, 4.2720e-03, 5.0757e-05,
        5.5216e-05, 3.5182e-01, 1.0630e-03], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:09,330][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Benjamin] are: tensor([0.0460, 0.0411, 0.2885, 0.0574, 0.0351, 0.2686, 0.0929, 0.0147, 0.1282,
        0.0274], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:09,332][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Benjamin] are: tensor([0.0087, 0.0022, 0.1485, 0.0187, 0.0277, 0.0760, 0.0248, 0.0429, 0.6271,
        0.0234], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:09,333][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Benjamin] are: tensor([0.1428, 0.0293, 0.1941, 0.0542, 0.0344, 0.1081, 0.1573, 0.0738, 0.1837,
        0.0223], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:09,333][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Benjamin] are: tensor([0.2585, 0.0229, 0.0693, 0.0469, 0.0489, 0.1175, 0.0855, 0.0964, 0.2225,
        0.0317], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:09,333][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Benjamin] are: tensor([0.2247, 0.0438, 0.0683, 0.2304, 0.0057, 0.0043, 0.0228, 0.1373, 0.1927,
        0.0698], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:09,334][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Benjamin] are: tensor([0.0251, 0.0058, 0.1664, 0.0353, 0.0228, 0.0473, 0.0762, 0.0664, 0.5323,
        0.0224], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:09,334][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Benjamin] are: tensor([0.0298, 0.0955, 0.1089, 0.0994, 0.1026, 0.1077, 0.1093, 0.1227, 0.1191,
        0.1049], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:09,334][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Benjamin] are: tensor([0.0039, 0.0463, 0.0964, 0.0633, 0.1042, 0.1447, 0.1790, 0.1411, 0.1431,
        0.0781], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:09,337][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Benjamin] are: tensor([0.1168, 0.0949, 0.0999, 0.0960, 0.0996, 0.0990, 0.0990, 0.1000, 0.0999,
        0.0950], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:09,339][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Benjamin] are: tensor([0.1159, 0.0136, 0.0689, 0.0105, 0.0147, 0.1340, 0.1922, 0.0556, 0.3751,
        0.0194], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:09,339][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Benjamin] are: tensor([0.2380, 0.0416, 0.0535, 0.0365, 0.0491, 0.0934, 0.1411, 0.1053, 0.1853,
        0.0561], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:09,340][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Benjamin] are: tensor([7.2047e-02, 2.1508e-08, 2.0176e-05, 3.8628e-07, 4.4628e-04, 5.4405e-06,
        9.6295e-04, 8.2102e-04, 9.2570e-01, 1.1514e-06], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:09,340][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.0153, 0.0657, 0.2078, 0.0386, 0.0541, 0.3103, 0.1084, 0.0206, 0.1081,
        0.0578, 0.0135], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:09,340][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0179, 0.0084, 0.1423, 0.0216, 0.0070, 0.0503, 0.0513, 0.0529, 0.5833,
        0.0341, 0.0308], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:09,341][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.0485, 0.0362, 0.2428, 0.0487, 0.0471, 0.1361, 0.1804, 0.0555, 0.1421,
        0.0287, 0.0340], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:09,341][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.0908, 0.0543, 0.1120, 0.0768, 0.0298, 0.1538, 0.0695, 0.0920, 0.1772,
        0.0626, 0.0814], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:09,344][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.0442, 0.0046, 0.1186, 0.0230, 0.0620, 0.0056, 0.0571, 0.1833, 0.2683,
        0.0076, 0.2257], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:09,346][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.0233, 0.0080, 0.2216, 0.0304, 0.0036, 0.0228, 0.0433, 0.0311, 0.5459,
        0.0404, 0.0295], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:09,346][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.0263, 0.0922, 0.1006, 0.0902, 0.0914, 0.1005, 0.0991, 0.1064, 0.1092,
        0.0995, 0.0846], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:09,346][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0018, 0.0283, 0.1054, 0.0435, 0.0910, 0.1420, 0.1554, 0.1083, 0.1576,
        0.0498, 0.1169], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:09,347][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.1051, 0.0860, 0.0907, 0.0868, 0.0907, 0.0903, 0.0903, 0.0911, 0.0911,
        0.0866, 0.0914], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:09,347][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.1761, 0.0144, 0.0626, 0.0135, 0.0165, 0.1084, 0.1403, 0.0779, 0.2719,
        0.0291, 0.0893], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:09,348][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.1496, 0.0567, 0.0596, 0.0331, 0.0570, 0.0893, 0.1084, 0.0933, 0.1492,
        0.0609, 0.1429], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:09,348][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([1.7156e-03, 3.7642e-03, 1.5763e-03, 3.4026e-03, 4.4073e-04, 5.6982e-03,
        1.7463e-04, 4.7743e-01, 4.2166e-01, 8.2674e-02, 1.4708e-03],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:09,351][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.2277, 0.1775, 0.0536, 0.0439, 0.0696, 0.0822, 0.0144, 0.0449, 0.0305,
        0.1349, 0.1173, 0.0037], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:09,352][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0390, 0.0051, 0.1392, 0.0212, 0.0165, 0.0662, 0.0168, 0.0533, 0.4847,
        0.0260, 0.0474, 0.0844], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:09,353][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0785, 0.0212, 0.2748, 0.0263, 0.0416, 0.0870, 0.0943, 0.0384, 0.1235,
        0.0211, 0.0504, 0.1429], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:09,353][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.1707, 0.0256, 0.0864, 0.0377, 0.0380, 0.1227, 0.0594, 0.0702, 0.1703,
        0.0335, 0.1277, 0.0578], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:09,354][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0662, 0.0149, 0.1570, 0.0899, 0.0254, 0.0016, 0.0317, 0.1305, 0.2377,
        0.0201, 0.0171, 0.2079], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:09,354][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0507, 0.0038, 0.0752, 0.0118, 0.0046, 0.0336, 0.0390, 0.0453, 0.5994,
        0.0263, 0.0411, 0.0692], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:09,355][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0227, 0.0819, 0.0919, 0.0835, 0.0833, 0.0919, 0.0915, 0.0990, 0.1009,
        0.0905, 0.0812, 0.0818], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:09,355][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0047, 0.0320, 0.0862, 0.0436, 0.0739, 0.1029, 0.1501, 0.0966, 0.1272,
        0.0491, 0.0914, 0.1423], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:09,357][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0975, 0.0787, 0.0830, 0.0795, 0.0825, 0.0822, 0.0822, 0.0833, 0.0832,
        0.0799, 0.0838, 0.0842], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:09,359][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0692, 0.0121, 0.0449, 0.0095, 0.0149, 0.0970, 0.1146, 0.0693, 0.2680,
        0.0284, 0.1169, 0.1551], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:09,360][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.2759, 0.0362, 0.0431, 0.0351, 0.0366, 0.0620, 0.0959, 0.0685, 0.1262,
        0.0521, 0.0993, 0.0690], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:09,360][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([7.6838e-01, 3.3013e-04, 3.8008e-06, 1.4279e-05, 2.7481e-04, 1.1765e-04,
        1.2685e-06, 1.1733e-02, 7.2901e-03, 4.0129e-03, 2.0760e-01, 2.3538e-04],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:09,361][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ computer] are: tensor([0.0778, 0.2119, 0.1052, 0.1405, 0.0434, 0.1656, 0.0259, 0.0084, 0.0527,
        0.1225, 0.0180, 0.0176, 0.0106], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:09,361][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ computer] are: tensor([0.0109, 0.0014, 0.0927, 0.0033, 0.0104, 0.0453, 0.0284, 0.0146, 0.3952,
        0.0125, 0.0422, 0.2123, 0.1307], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:09,361][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ computer] are: tensor([0.0262, 0.0259, 0.1841, 0.0148, 0.0409, 0.1028, 0.1362, 0.0493, 0.1430,
        0.0204, 0.0482, 0.1960, 0.0122], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:09,362][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ computer] are: tensor([0.0656, 0.0267, 0.0611, 0.0409, 0.0333, 0.0782, 0.0733, 0.0536, 0.1472,
        0.0468, 0.0997, 0.1139, 0.1598], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:09,365][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ computer] are: tensor([0.0516, 0.0033, 0.0982, 0.0185, 0.0025, 0.0014, 0.0153, 0.0500, 0.0731,
        0.0055, 0.0040, 0.0082, 0.6684], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:09,366][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ computer] are: tensor([0.0353, 0.0041, 0.1056, 0.0108, 0.0089, 0.0205, 0.0624, 0.0126, 0.3246,
        0.0161, 0.0384, 0.2563, 0.1044], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:09,366][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ computer] are: tensor([0.0235, 0.0777, 0.0819, 0.0777, 0.0788, 0.0819, 0.0818, 0.0882, 0.0889,
        0.0848, 0.0751, 0.0767, 0.0830], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:09,367][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ computer] are: tensor([0.0049, 0.0265, 0.0799, 0.0431, 0.0569, 0.0940, 0.1288, 0.1037, 0.1162,
        0.0437, 0.0794, 0.1321, 0.0908], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:09,367][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ computer] are: tensor([0.0954, 0.0721, 0.0764, 0.0726, 0.0757, 0.0761, 0.0758, 0.0768, 0.0770,
        0.0733, 0.0773, 0.0778, 0.0737], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:09,368][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ computer] are: tensor([0.1017, 0.0121, 0.0560, 0.0087, 0.0128, 0.0895, 0.1235, 0.0408, 0.2445,
        0.0162, 0.0711, 0.1678, 0.0554], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:09,368][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ computer] are: tensor([0.1308, 0.0432, 0.0527, 0.0252, 0.0395, 0.0694, 0.1069, 0.0809, 0.1272,
        0.0434, 0.0919, 0.0807, 0.1081], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:09,369][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ computer] are: tensor([6.9284e-01, 1.3946e-06, 1.6822e-06, 7.5615e-08, 3.2749e-06, 4.4033e-07,
        8.5403e-05, 1.0355e-05, 3.6832e-03, 6.7689e-05, 5.2934e-03, 2.8304e-01,
        1.4970e-02], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:09,373][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0798, 0.1850, 0.0161, 0.0558, 0.2739, 0.0021, 0.0382, 0.0331, 0.0066,
        0.1276, 0.1082, 0.0214, 0.0514, 0.0008], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:09,373][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0946, 0.0038, 0.0482, 0.0097, 0.0107, 0.0132, 0.0174, 0.0269, 0.2646,
        0.0156, 0.0173, 0.1420, 0.1299, 0.2061], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:09,374][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.2138, 0.0175, 0.2148, 0.0144, 0.0361, 0.0538, 0.0825, 0.0232, 0.0801,
        0.0136, 0.0444, 0.1304, 0.0035, 0.0717], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:09,374][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.1858, 0.0145, 0.0402, 0.0215, 0.0197, 0.0573, 0.0479, 0.0355, 0.1185,
        0.0190, 0.0829, 0.0696, 0.1220, 0.1656], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:09,374][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0758, 0.0029, 0.2549, 0.0599, 0.0248, 0.0063, 0.0244, 0.1673, 0.3158,
        0.0037, 0.0096, 0.0383, 0.0101, 0.0061], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:09,375][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0497, 0.0019, 0.0509, 0.0100, 0.0083, 0.0073, 0.0341, 0.0210, 0.4312,
        0.0120, 0.0348, 0.2173, 0.0769, 0.0447], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:09,375][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0198, 0.0701, 0.0771, 0.0697, 0.0686, 0.0752, 0.0756, 0.0821, 0.0834,
        0.0767, 0.0699, 0.0712, 0.0876, 0.0730], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:09,379][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0083, 0.0348, 0.0773, 0.0345, 0.0673, 0.0928, 0.1038, 0.0782, 0.1014,
        0.0501, 0.0767, 0.1009, 0.0728, 0.1011], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:09,379][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0844, 0.0673, 0.0712, 0.0684, 0.0709, 0.0707, 0.0706, 0.0718, 0.0717,
        0.0688, 0.0719, 0.0725, 0.0694, 0.0704], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:09,380][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.1047, 0.0081, 0.0384, 0.0078, 0.0157, 0.0603, 0.0792, 0.0577, 0.1811,
        0.0205, 0.0935, 0.1037, 0.0796, 0.1497], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:09,380][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.2828, 0.0328, 0.0415, 0.0284, 0.0345, 0.0475, 0.0840, 0.0556, 0.0938,
        0.0400, 0.0809, 0.0563, 0.0762, 0.0456], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:09,381][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([2.9734e-01, 3.3041e-06, 3.2594e-10, 1.1684e-07, 2.9672e-06, 6.1134e-10,
        1.2565e-08, 2.6979e-04, 1.3980e-05, 4.0167e-05, 3.0971e-04, 1.0162e-04,
        7.0010e-01, 1.8149e-03], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:09,382][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:20:09,384][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[4797],
        [ 321],
        [1654],
        [ 816],
        [2113],
        [ 171],
        [ 302],
        [  23],
        [ 540],
        [ 135],
        [ 503],
        [ 560],
        [  57],
        [ 182]], device='cuda:0')
[2024-07-24 10:20:09,385][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 5042],
        [ 3167],
        [22601],
        [32963],
        [32297],
        [11231],
        [16977],
        [ 1993],
        [10814],
        [ 4676],
        [18473],
        [16415],
        [ 8988],
        [15461]], device='cuda:0')
[2024-07-24 10:20:09,388][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[2194],
        [4524],
        [4993],
        [5126],
        [3935],
        [3568],
        [4083],
        [4368],
        [4427],
        [5127],
        [5279],
        [5622],
        [5591],
        [5259]], device='cuda:0')
[2024-07-24 10:20:09,389][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[13554],
        [ 9928],
        [10462],
        [10434],
        [ 9592],
        [ 8853],
        [ 8112],
        [ 7533],
        [ 7707],
        [ 7648],
        [ 8203],
        [ 8163],
        [ 8087],
        [ 7961]], device='cuda:0')
[2024-07-24 10:20:09,390][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[11053],
        [ 8472],
        [ 7498],
        [ 7575],
        [ 7385],
        [ 7490],
        [ 7920],
        [ 8783],
        [ 9147],
        [10168],
        [10335],
        [10402],
        [10471],
        [10611]], device='cuda:0')
[2024-07-24 10:20:09,391][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[ 1753],
        [14426],
        [39651],
        [17693],
        [25882],
        [31860],
        [25324],
        [19475],
        [ 8115],
        [ 1487],
        [38949],
        [27962],
        [37773],
        [22433]], device='cuda:0')
[2024-07-24 10:20:09,392][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[19380],
        [ 9645],
        [10673],
        [10258],
        [10553],
        [11889],
        [10495],
        [11022],
        [10891],
        [10177],
        [10689],
        [10962],
        [11614],
        [12370]], device='cuda:0')
[2024-07-24 10:20:09,394][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[12785],
        [ 6291],
        [ 8314],
        [ 8289],
        [ 7885],
        [ 6658],
        [ 6403],
        [ 7759],
        [ 8489],
        [11269],
        [ 5645],
        [ 7244],
        [ 9661],
        [ 7235]], device='cuda:0')
[2024-07-24 10:20:09,396][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[11383],
        [18662],
        [13959],
        [14655],
        [14292],
        [13163],
        [14986],
        [15507],
        [15649],
        [15764],
        [15689],
        [15828],
        [15767],
        [15569]], device='cuda:0')
[2024-07-24 10:20:09,397][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[20617],
        [28064],
        [23436],
        [23029],
        [21723],
        [21101],
        [21200],
        [20646],
        [20729],
        [21704],
        [21625],
        [21656],
        [21775],
        [21860]], device='cuda:0')
[2024-07-24 10:20:09,398][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[16998],
        [13807],
        [14724],
        [13465],
        [12829],
        [13615],
        [13559],
        [12825],
        [12783],
        [12703],
        [12805],
        [12774],
        [12683],
        [13009]], device='cuda:0')
[2024-07-24 10:20:09,399][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[5096],
        [1837],
        [1932],
        [1232],
        [1253],
        [1393],
        [1421],
        [1151],
        [1194],
        [1112],
        [1010],
        [ 884],
        [ 878],
        [ 912]], device='cuda:0')
[2024-07-24 10:20:09,400][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[28571],
        [18623],
        [24183],
        [20439],
        [28545],
        [28600],
        [30487],
        [29135],
        [30630],
        [29079],
        [28828],
        [28671],
        [28825],
        [29986]], device='cuda:0')
[2024-07-24 10:20:09,402][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[16514],
        [16514],
        [16499],
        [16842],
        [26292],
        [16446],
        [22212],
        [26810],
        [10544],
        [18306],
        [21122],
        [17765],
        [26136],
        [ 2649]], device='cuda:0')
[2024-07-24 10:20:09,404][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 213],
        [2584],
        [8625],
        [1235],
        [3279],
        [4361],
        [2444],
        [2959],
        [6825],
        [3636],
        [1116],
        [1929],
        [ 415],
        [2575]], device='cuda:0')
[2024-07-24 10:20:09,405][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[  399],
        [ 3200],
        [ 2840],
        [ 2306],
        [ 2838],
        [13722],
        [ 5167],
        [ 2988],
        [ 8704],
        [ 2192],
        [ 2421],
        [ 5511],
        [ 4038],
        [11826]], device='cuda:0')
[2024-07-24 10:20:09,406][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[7547],
        [2339],
        [7522],
        [6467],
        [6242],
        [5698],
        [5541],
        [6561],
        [7428],
        [6611],
        [6408],
        [6890],
        [7729],
        [5949]], device='cuda:0')
[2024-07-24 10:20:09,407][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[   4],
        [  39],
        [ 258],
        [ 726],
        [ 715],
        [ 475],
        [1077],
        [1683],
        [1809],
        [2737],
        [2584],
        [2583],
        [3516],
        [2352]], device='cuda:0')
[2024-07-24 10:20:09,409][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[  414],
        [  369],
        [  286],
        [ 3397],
        [ 9658],
        [ 8761],
        [ 9634],
        [ 9879],
        [10123],
        [ 9145],
        [10580],
        [11015],
        [12897],
        [11613]], device='cuda:0')
[2024-07-24 10:20:09,410][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[4343],
        [5991],
        [ 350],
        [1411],
        [1111],
        [ 623],
        [ 726],
        [1112],
        [ 458],
        [4680],
        [ 537],
        [ 810],
        [4041],
        [ 760]], device='cuda:0')
[2024-07-24 10:20:09,413][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[ 4821],
        [10650],
        [ 6976],
        [ 7462],
        [ 7109],
        [ 6932],
        [ 6280],
        [ 5206],
        [ 5082],
        [ 6047],
        [ 6076],
        [ 5304],
        [ 3082],
        [ 3767]], device='cuda:0')
[2024-07-24 10:20:09,413][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[535],
        [416],
        [351],
        [328],
        [360],
        [365],
        [368],
        [377],
        [380],
        [382],
        [381],
        [390],
        [394],
        [402]], device='cuda:0')
[2024-07-24 10:20:09,414][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[6595],
        [ 807],
        [ 931],
        [ 925],
        [ 856],
        [ 857],
        [ 803],
        [ 805],
        [ 814],
        [ 802],
        [ 777],
        [ 785],
        [ 760],
        [ 756]], device='cuda:0')
[2024-07-24 10:20:09,415][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[1429],
        [1158],
        [1092],
        [ 928],
        [ 836],
        [ 802],
        [ 791],
        [ 726],
        [ 696],
        [ 689],
        [ 687],
        [ 672],
        [ 672],
        [ 657]], device='cuda:0')
[2024-07-24 10:20:09,417][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[43402],
        [23571],
        [13529],
        [10851],
        [11808],
        [10667],
        [ 9505],
        [ 9033],
        [ 8715],
        [ 8808],
        [ 8778],
        [ 8082],
        [ 8547],
        [ 8608]], device='cuda:0')
[2024-07-24 10:20:09,419][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[1408],
        [1835],
        [1638],
        [1370],
        [1078],
        [1256],
        [1409],
        [1279],
        [1238],
        [1183],
        [1029],
        [1110],
        [1097],
        [1115]], device='cuda:0')
[2024-07-24 10:20:09,421][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[29632],
        [29632],
        [29086],
        [29571],
        [ 2648],
        [29658],
        [29609],
        [29583],
        [17664],
        [ 5837],
        [ 8611],
        [30560],
        [28336],
        [ 8078]], device='cuda:0')
[2024-07-24 10:20:09,422][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[49281],
        [48518],
        [49145],
        [48066],
        [48595],
        [48227],
        [48283],
        [48096],
        [48308],
        [47855],
        [48332],
        [48210],
        [47580],
        [48299]], device='cuda:0')
[2024-07-24 10:20:09,423][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[49890],
        [49533],
        [47877],
        [49173],
        [47304],
        [46346],
        [47205],
        [47813],
        [46230],
        [48180],
        [48885],
        [48179],
        [49374],
        [46697]], device='cuda:0')
[2024-07-24 10:20:09,424][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[2554],
        [2554],
        [2554],
        [2554],
        [2554],
        [2554],
        [2554],
        [2554],
        [2554],
        [2554],
        [2554],
        [2554],
        [2554],
        [2554]], device='cuda:0')
[2024-07-24 10:20:09,453][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:20:09,454][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:09,454][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:09,455][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:09,456][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:09,456][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:09,457][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:09,458][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:09,458][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:09,459][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:09,460][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:09,460][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:09,461][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:09,462][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Benjamin] are: tensor([0.4991, 0.5009], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:09,462][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Benjamin] are: tensor([0.0263, 0.9737], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:09,463][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Benjamin] are: tensor([0.2157, 0.7843], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:09,466][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Benjamin] are: tensor([0.6974, 0.3026], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:09,467][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Benjamin] are: tensor([0.9241, 0.0759], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:09,467][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Benjamin] are: tensor([0.0073, 0.9927], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:09,468][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Benjamin] are: tensor([0.6480, 0.3520], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:09,469][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Benjamin] are: tensor([0.6943, 0.3057], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:09,471][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Benjamin] are: tensor([0.8232, 0.1768], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:09,473][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Benjamin] are: tensor([0.2039, 0.7961], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:09,474][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Benjamin] are: tensor([0.7903, 0.2097], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:09,475][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Benjamin] are: tensor([0.4857, 0.5143], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:09,476][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0520, 0.3829, 0.5651], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:09,477][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ and] are: tensor([3.5524e-04, 2.3726e-02, 9.7592e-01], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:09,480][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.1644, 0.3750, 0.4606], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:09,481][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.5512, 0.2399, 0.2089], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:09,481][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.8833, 0.0298, 0.0869], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:09,482][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0199, 0.8983, 0.0818], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:09,485][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.2561, 0.5142, 0.2297], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:09,487][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.8692, 0.0135, 0.1174], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:09,488][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.5229, 0.0747, 0.4024], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:09,488][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0990, 0.4292, 0.4719], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:09,489][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.8980, 0.0242, 0.0779], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:09,492][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.5796, 0.0635, 0.3569], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:09,494][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Alexander] are: tensor([0.0096, 0.1323, 0.1424, 0.7157], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:09,494][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Alexander] are: tensor([0.0011, 0.1378, 0.4416, 0.4194], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:09,495][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Alexander] are: tensor([0.0911, 0.3602, 0.4499, 0.0988], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:09,496][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Alexander] are: tensor([0.4436, 0.2024, 0.1794, 0.1745], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:09,498][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Alexander] are: tensor([0.5212, 0.0860, 0.3466, 0.0462], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:09,500][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Alexander] are: tensor([0.0078, 0.5598, 0.1904, 0.2420], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:09,501][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Alexander] are: tensor([0.3306, 0.3567, 0.1697, 0.1430], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:09,502][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Alexander] are: tensor([0.4695, 0.0864, 0.3189, 0.1252], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:09,503][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Alexander] are: tensor([0.4183, 0.0358, 0.2768, 0.2692], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:09,505][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Alexander] are: tensor([0.0671, 0.3048, 0.3310, 0.2971], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:09,507][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Alexander] are: tensor([0.3030, 0.0812, 0.1074, 0.5084], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:09,508][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Alexander] are: tensor([0.2316, 0.0821, 0.4857, 0.2006], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:09,509][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ went] are: tensor([0.0021, 0.0094, 0.1271, 0.8542, 0.0072], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:09,509][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ went] are: tensor([0.0212, 0.4075, 0.1093, 0.1167, 0.3454], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:09,512][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ went] are: tensor([0.0958, 0.3038, 0.3637, 0.0887, 0.1480], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:09,514][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ went] are: tensor([0.3637, 0.1747, 0.1550, 0.1532, 0.1534], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:09,515][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ went] are: tensor([0.3764, 0.0761, 0.3474, 0.0493, 0.1508], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:09,515][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ went] are: tensor([0.0077, 0.4735, 0.0632, 0.4398, 0.0159], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:09,516][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ went] are: tensor([0.0570, 0.1579, 0.3562, 0.3723, 0.0566], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:09,519][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ went] are: tensor([0.5038, 0.0122, 0.1543, 0.0591, 0.2706], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:09,521][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.2853, 0.0504, 0.2636, 0.2203, 0.1803], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:09,521][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ went] are: tensor([0.0538, 0.2326, 0.2593, 0.2314, 0.2229], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:09,522][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ went] are: tensor([0.2862, 0.1137, 0.1763, 0.3061, 0.1177], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:09,523][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ went] are: tensor([0.5484, 0.0209, 0.0829, 0.0220, 0.3259], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:09,525][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0233, 0.1026, 0.2350, 0.4779, 0.0593, 0.1018], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:09,527][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0188, 0.8639, 0.0384, 0.0213, 0.0474, 0.0102], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:09,528][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1153, 0.1870, 0.2748, 0.0698, 0.1117, 0.2413], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:09,529][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.3290, 0.1507, 0.1297, 0.1336, 0.1352, 0.1218], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:09,530][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.7747, 0.0097, 0.0275, 0.0067, 0.0132, 0.1681], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:09,532][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0277, 0.2439, 0.1052, 0.4478, 0.1262, 0.0492], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:09,534][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.2885, 0.0856, 0.0529, 0.0823, 0.2702, 0.2204], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:09,535][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.4569, 0.0080, 0.0469, 0.0244, 0.2244, 0.2394], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:09,536][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.3913, 0.0259, 0.1551, 0.1469, 0.1044, 0.1764], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:09,536][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0387, 0.1868, 0.2062, 0.1917, 0.1859, 0.1906], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:09,539][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.7570, 0.0237, 0.0802, 0.0526, 0.0472, 0.0394], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:09,544][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.4417, 0.0263, 0.0883, 0.0365, 0.1125, 0.2946], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:09,545][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0105, 0.0867, 0.0975, 0.3339, 0.3691, 0.0471, 0.0551],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:09,545][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0063, 0.8205, 0.0533, 0.0343, 0.0651, 0.0099, 0.0107],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:09,546][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0754, 0.1638, 0.2310, 0.0575, 0.0973, 0.2087, 0.1664],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:09,547][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.2791, 0.1347, 0.1192, 0.1198, 0.1204, 0.1112, 0.1156],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:09,550][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.2978, 0.0147, 0.0474, 0.0111, 0.0269, 0.3837, 0.2182],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:09,552][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0466, 0.2908, 0.1069, 0.2987, 0.0787, 0.1140, 0.0644],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:09,552][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.3261, 0.0751, 0.0559, 0.1150, 0.1750, 0.2380, 0.0149],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:09,553][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.3892, 0.0081, 0.0747, 0.0281, 0.1151, 0.3083, 0.0766],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:09,554][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.2207, 0.0274, 0.1801, 0.1518, 0.1384, 0.1981, 0.0836],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:09,558][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0350, 0.1583, 0.1732, 0.1578, 0.1528, 0.1604, 0.1626],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:09,558][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.5633, 0.0409, 0.0666, 0.2553, 0.0100, 0.0166, 0.0472],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:09,559][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.3542, 0.0194, 0.0542, 0.0367, 0.0575, 0.1809, 0.2971],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:09,560][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ station] are: tensor([0.0394, 0.0434, 0.0739, 0.6010, 0.0312, 0.0800, 0.0424, 0.0887],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:09,561][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ station] are: tensor([0.0093, 0.1306, 0.0437, 0.0258, 0.2384, 0.0438, 0.0419, 0.4666],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:09,564][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ station] are: tensor([0.0607, 0.1432, 0.1881, 0.0487, 0.0858, 0.1893, 0.1517, 0.1325],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:09,565][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ station] are: tensor([0.2464, 0.1212, 0.1076, 0.1059, 0.1071, 0.1003, 0.1063, 0.1052],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:09,566][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ station] are: tensor([0.3005, 0.0155, 0.0591, 0.0095, 0.0341, 0.2855, 0.2659, 0.0300],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:09,567][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ station] are: tensor([0.0108, 0.1889, 0.0762, 0.4208, 0.0488, 0.0664, 0.0896, 0.0986],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:09,568][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ station] are: tensor([0.0927, 0.0640, 0.0457, 0.0908, 0.1909, 0.1704, 0.0855, 0.2599],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:09,571][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ station] are: tensor([0.2601, 0.0104, 0.0553, 0.0339, 0.1354, 0.2514, 0.0877, 0.1657],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:09,572][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ station] are: tensor([0.1563, 0.0201, 0.1562, 0.1214, 0.1061, 0.2017, 0.0892, 0.1491],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:09,573][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ station] are: tensor([0.0305, 0.1341, 0.1497, 0.1349, 0.1316, 0.1399, 0.1430, 0.1363],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:09,574][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ station] are: tensor([0.1329, 0.0156, 0.0361, 0.0324, 0.0563, 0.0147, 0.0599, 0.6521],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:09,574][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ station] are: tensor([0.0753, 0.0288, 0.1524, 0.0290, 0.1031, 0.2923, 0.2288, 0.0904],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:09,578][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0046, 0.0429, 0.1171, 0.7099, 0.0146, 0.0176, 0.0482, 0.0310, 0.0140],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:09,579][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0045, 0.3585, 0.0750, 0.0501, 0.1113, 0.0330, 0.0373, 0.2185, 0.1117],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:09,580][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0655, 0.1050, 0.1487, 0.0460, 0.0695, 0.1448, 0.1237, 0.1075, 0.1892],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:09,580][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.2341, 0.1055, 0.0936, 0.0964, 0.0980, 0.0901, 0.0952, 0.0966, 0.0905],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:09,581][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.3332, 0.0064, 0.0268, 0.0052, 0.0138, 0.2110, 0.1473, 0.0288, 0.2275],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:09,585][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0233, 0.1807, 0.0619, 0.3182, 0.0746, 0.0486, 0.0640, 0.1959, 0.0328],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:09,586][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.2041, 0.0456, 0.0350, 0.0423, 0.0411, 0.1335, 0.0277, 0.3670, 0.1038],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:09,586][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.4262, 0.0025, 0.0555, 0.0200, 0.0470, 0.2632, 0.0414, 0.0961, 0.0481],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:09,587][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.3047, 0.0155, 0.1106, 0.0886, 0.0861, 0.1222, 0.0525, 0.0940, 0.1259],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:09,588][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0295, 0.1184, 0.1283, 0.1209, 0.1151, 0.1175, 0.1217, 0.1196, 0.1291],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:09,591][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.4184, 0.0242, 0.0510, 0.0536, 0.0138, 0.0204, 0.0487, 0.3186, 0.0513],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:09,592][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.1773, 0.0119, 0.0521, 0.0185, 0.0523, 0.0933, 0.0760, 0.0353, 0.4834],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:09,593][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Benjamin] are: tensor([0.0314, 0.0202, 0.1037, 0.1295, 0.1482, 0.1070, 0.0802, 0.0684, 0.0405,
        0.2709], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:09,594][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Benjamin] are: tensor([0.0031, 0.1078, 0.1221, 0.0697, 0.0753, 0.0335, 0.0576, 0.3153, 0.1566,
        0.0590], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:09,595][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Benjamin] are: tensor([0.0564, 0.0921, 0.1321, 0.0365, 0.0599, 0.1285, 0.1056, 0.0922, 0.1799,
        0.1167], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:09,599][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Benjamin] are: tensor([0.2220, 0.0988, 0.0869, 0.0869, 0.0859, 0.0797, 0.0855, 0.0863, 0.0826,
        0.0855], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:09,600][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Benjamin] are: tensor([0.0734, 0.0070, 0.0325, 0.0045, 0.0219, 0.2160, 0.2245, 0.0253, 0.3864,
        0.0086], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:09,600][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Benjamin] are: tensor([0.0017, 0.0555, 0.0353, 0.2003, 0.1545, 0.0534, 0.0438, 0.3616, 0.0408,
        0.0532], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:09,601][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Benjamin] are: tensor([0.0948, 0.0245, 0.0322, 0.0363, 0.0322, 0.0681, 0.0414, 0.3165, 0.3325,
        0.0215], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:09,605][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Benjamin] are: tensor([0.3135, 0.0320, 0.0469, 0.0507, 0.1264, 0.1791, 0.0623, 0.0758, 0.0668,
        0.0463], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:09,606][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Benjamin] are: tensor([0.2118, 0.0140, 0.0934, 0.0836, 0.0726, 0.0925, 0.0537, 0.1036, 0.1262,
        0.1484], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:09,607][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Benjamin] are: tensor([0.0254, 0.1051, 0.1139, 0.1059, 0.1024, 0.1053, 0.1085, 0.1063, 0.1164,
        0.1108], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:09,607][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Benjamin] are: tensor([0.3227, 0.1070, 0.1720, 0.0970, 0.0063, 0.0151, 0.0133, 0.0388, 0.0480,
        0.1798], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:09,609][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Benjamin] are: tensor([0.2589, 0.0227, 0.0815, 0.0475, 0.0474, 0.1125, 0.0903, 0.0313, 0.2112,
        0.0966], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:09,612][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.0059, 0.0150, 0.0914, 0.7510, 0.0112, 0.0217, 0.0196, 0.0252, 0.0095,
        0.0383, 0.0112], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:09,613][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0074, 0.1614, 0.0781, 0.1079, 0.1199, 0.0423, 0.0360, 0.2039, 0.0719,
        0.0230, 0.1483], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:09,614][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0443, 0.0817, 0.1143, 0.0344, 0.0528, 0.1170, 0.0948, 0.0878, 0.1591,
        0.1040, 0.1097], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:09,615][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.2095, 0.0893, 0.0786, 0.0790, 0.0789, 0.0742, 0.0792, 0.0780, 0.0750,
        0.0794, 0.0789], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:09,618][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.0958, 0.0066, 0.0246, 0.0049, 0.0097, 0.2241, 0.1680, 0.0265, 0.3642,
        0.0106, 0.0650], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:09,619][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.0153, 0.1667, 0.0532, 0.1370, 0.0522, 0.0449, 0.0638, 0.2670, 0.0463,
        0.0996, 0.0541], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:09,620][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0126, 0.0179, 0.0295, 0.0368, 0.0206, 0.1648, 0.0259, 0.4755, 0.1703,
        0.0220, 0.0241], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:09,621][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.4343, 0.0091, 0.0264, 0.0108, 0.0542, 0.2142, 0.0357, 0.1006, 0.0624,
        0.0163, 0.0361], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:09,623][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.1591, 0.0135, 0.0803, 0.0671, 0.0511, 0.1022, 0.0542, 0.1018, 0.1267,
        0.1604, 0.0837], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:09,626][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.0215, 0.0939, 0.1035, 0.0961, 0.0924, 0.0947, 0.0979, 0.0950, 0.1033,
        0.1013, 0.1002], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:09,627][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.4415, 0.0556, 0.0385, 0.0884, 0.0063, 0.0166, 0.0610, 0.0781, 0.0499,
        0.1188, 0.0453], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:09,627][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.2081, 0.0133, 0.0549, 0.0141, 0.0520, 0.1308, 0.1121, 0.0224, 0.2011,
        0.0516, 0.1395], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:09,628][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0080, 0.0369, 0.0569, 0.4659, 0.0682, 0.0178, 0.0304, 0.0402, 0.0139,
        0.0559, 0.0147, 0.1912], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:09,632][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0139, 0.7913, 0.0296, 0.0260, 0.0299, 0.0077, 0.0059, 0.0475, 0.0137,
        0.0081, 0.0223, 0.0041], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:09,633][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0389, 0.0839, 0.1101, 0.0317, 0.0477, 0.1090, 0.0838, 0.0794, 0.1434,
        0.1007, 0.1046, 0.0668], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:09,634][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.1923, 0.0842, 0.0741, 0.0741, 0.0739, 0.0690, 0.0721, 0.0737, 0.0709,
        0.0752, 0.0752, 0.0654], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:09,634][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0447, 0.0063, 0.0267, 0.0050, 0.0118, 0.2338, 0.1449, 0.0301, 0.2921,
        0.0091, 0.0711, 0.1244], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:09,637][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0197, 0.2208, 0.0579, 0.1681, 0.0320, 0.0426, 0.0322, 0.1293, 0.0415,
        0.1194, 0.0988, 0.0377], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:09,639][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.1056, 0.0246, 0.0167, 0.0335, 0.0728, 0.1012, 0.0077, 0.3407, 0.1032,
        0.0237, 0.1607, 0.0096], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:09,640][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.2635, 0.0079, 0.0350, 0.0107, 0.0855, 0.1983, 0.0360, 0.1322, 0.0623,
        0.0186, 0.1062, 0.0438], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:09,641][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.1850, 0.0084, 0.0701, 0.0588, 0.0526, 0.0778, 0.0392, 0.0886, 0.1142,
        0.1564, 0.1019, 0.0469], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:09,642][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0196, 0.0871, 0.0936, 0.0881, 0.0842, 0.0850, 0.0874, 0.0861, 0.0933,
        0.0927, 0.0917, 0.0913], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:09,645][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.3315, 0.0557, 0.0308, 0.1668, 0.0221, 0.0089, 0.0374, 0.1349, 0.0278,
        0.1091, 0.0224, 0.0525], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:09,646][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.4687, 0.0094, 0.0204, 0.0104, 0.0321, 0.0398, 0.0515, 0.0240, 0.0721,
        0.0351, 0.0363, 0.2002], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:09,647][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ computer] are: tensor([0.0046, 0.0425, 0.0400, 0.2804, 0.1607, 0.0298, 0.0200, 0.1094, 0.0120,
        0.0527, 0.0302, 0.1333, 0.0845], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:09,648][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ computer] are: tensor([0.0126, 0.9072, 0.0186, 0.0140, 0.0081, 0.0028, 0.0021, 0.0122, 0.0035,
        0.0048, 0.0061, 0.0012, 0.0068], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:09,650][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ computer] are: tensor([0.0514, 0.0647, 0.0895, 0.0246, 0.0363, 0.1029, 0.0770, 0.0650, 0.1346,
        0.0889, 0.0921, 0.0642, 0.1088], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:09,653][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ computer] are: tensor([0.1713, 0.0791, 0.0693, 0.0695, 0.0690, 0.0650, 0.0696, 0.0690, 0.0658,
        0.0716, 0.0708, 0.0638, 0.0661], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:09,654][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ computer] are: tensor([0.0342, 0.0066, 0.0304, 0.0037, 0.0120, 0.1679, 0.1430, 0.0120, 0.2682,
        0.0066, 0.0847, 0.2268, 0.0040], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:09,655][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ computer] are: tensor([0.0155, 0.2109, 0.0302, 0.1656, 0.0404, 0.0285, 0.0327, 0.1375, 0.0231,
        0.1366, 0.1058, 0.0508, 0.0225], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:09,655][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ computer] are: tensor([0.1351, 0.0227, 0.0173, 0.0184, 0.0300, 0.0308, 0.0404, 0.2416, 0.1535,
        0.0288, 0.0782, 0.0825, 0.1208], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:09,659][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ computer] are: tensor([0.4818, 0.0075, 0.0275, 0.0119, 0.0581, 0.0920, 0.0264, 0.0672, 0.0740,
        0.0199, 0.0533, 0.0419, 0.0384], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:09,660][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ computer] are: tensor([0.1494, 0.0089, 0.0676, 0.0541, 0.0457, 0.0776, 0.0410, 0.0780, 0.1067,
        0.1514, 0.0989, 0.0524, 0.0682], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:09,661][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ computer] are: tensor([0.0194, 0.0787, 0.0863, 0.0805, 0.0779, 0.0793, 0.0816, 0.0783, 0.0869,
        0.0839, 0.0834, 0.0842, 0.0797], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:09,662][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ computer] are: tensor([0.6226, 0.0164, 0.0136, 0.0283, 0.0063, 0.0027, 0.0129, 0.0398, 0.0079,
        0.0367, 0.0042, 0.0159, 0.1928], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:09,664][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ computer] are: tensor([0.1039, 0.0035, 0.0423, 0.0071, 0.0258, 0.0687, 0.1730, 0.0245, 0.2421,
        0.0203, 0.0539, 0.2218, 0.0131], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:09,666][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ to] are: tensor([5.4567e-04, 2.5576e-02, 1.0266e-01, 6.2634e-01, 6.1849e-03, 7.3396e-03,
        1.8392e-02, 1.7637e-02, 3.4690e-03, 5.0730e-03, 1.3811e-03, 1.3252e-01,
        5.0426e-02, 2.4583e-03], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:09,667][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ to] are: tensor([1.2218e-02, 9.5183e-01, 1.0193e-02, 4.6144e-03, 3.8580e-03, 1.3227e-03,
        9.7592e-04, 6.3798e-03, 1.9451e-03, 1.3129e-03, 2.7025e-03, 4.5418e-04,
        1.6833e-03, 5.0903e-04], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:09,668][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0434, 0.0591, 0.0894, 0.0251, 0.0356, 0.0833, 0.0701, 0.0616, 0.1226,
        0.0800, 0.0809, 0.0577, 0.0968, 0.0944], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:09,669][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.1733, 0.0732, 0.0636, 0.0648, 0.0655, 0.0597, 0.0637, 0.0645, 0.0615,
        0.0658, 0.0658, 0.0585, 0.0607, 0.0593], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:09,673][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.1753, 0.0047, 0.0154, 0.0036, 0.0053, 0.0966, 0.0927, 0.0155, 0.1708,
        0.0058, 0.0348, 0.1184, 0.0043, 0.2567], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:09,673][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0113, 0.1013, 0.0436, 0.1531, 0.0541, 0.0203, 0.0606, 0.1610, 0.0332,
        0.0690, 0.0894, 0.0900, 0.0916, 0.0214], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:09,674][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1622, 0.0123, 0.0062, 0.0115, 0.0537, 0.0256, 0.0127, 0.1883, 0.1292,
        0.0178, 0.0743, 0.0235, 0.1714, 0.1112], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:09,675][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.3656, 0.0060, 0.0180, 0.0090, 0.0842, 0.0575, 0.0202, 0.0571, 0.0514,
        0.0137, 0.0727, 0.0304, 0.0261, 0.1882], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:09,678][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.2875, 0.0061, 0.0475, 0.0430, 0.0303, 0.0511, 0.0300, 0.0541, 0.0815,
        0.1405, 0.0677, 0.0413, 0.0536, 0.0659], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:09,680][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0162, 0.0717, 0.0787, 0.0755, 0.0725, 0.0720, 0.0749, 0.0740, 0.0788,
        0.0785, 0.0777, 0.0776, 0.0769, 0.0749], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:09,681][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.4244, 0.0116, 0.0093, 0.0301, 0.0211, 0.0050, 0.0117, 0.3824, 0.0101,
        0.0187, 0.0199, 0.0111, 0.0420, 0.0027], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:09,682][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.3155, 0.0044, 0.0315, 0.0093, 0.0389, 0.0962, 0.0459, 0.0211, 0.1632,
        0.0119, 0.0375, 0.1144, 0.0056, 0.1045], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:09,747][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:20:09,751][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:09,752][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:09,752][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:09,753][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:09,754][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:09,755][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:09,756][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:09,757][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:09,757][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:09,758][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:09,759][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:09,759][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:09,760][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Benjamin] are: tensor([0.0061, 0.9939], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:09,761][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Benjamin] are: tensor([0.0645, 0.9355], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:09,762][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Benjamin] are: tensor([0.2284, 0.7716], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:09,762][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Benjamin] are: tensor([0.8631, 0.1369], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:09,765][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Benjamin] are: tensor([0.7441, 0.2559], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:09,766][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Benjamin] are: tensor([0.8379, 0.1621], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:09,767][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Benjamin] are: tensor([0.6480, 0.3520], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:09,768][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Benjamin] are: tensor([0.6943, 0.3057], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:09,770][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Benjamin] are: tensor([0.8405, 0.1595], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:09,773][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Benjamin] are: tensor([0.9121, 0.0879], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:09,773][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Benjamin] are: tensor([0.8578, 0.1422], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:09,774][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Benjamin] are: tensor([0.9026, 0.0974], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:09,775][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0031, 0.5074, 0.4895], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:09,777][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0530, 0.5302, 0.4168], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:09,779][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.1699, 0.4218, 0.4082], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:09,780][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.8385, 0.0520, 0.1096], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:09,781][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.5606, 0.0726, 0.3668], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:09,782][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.9519, 0.0449, 0.0032], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:09,784][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.2561, 0.5142, 0.2297], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:09,786][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.8692, 0.0135, 0.1174], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:09,787][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.8142, 0.0768, 0.1090], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:09,787][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.8588, 0.1151, 0.0261], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:09,788][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.9362, 0.0440, 0.0198], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:09,791][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.9257, 0.0219, 0.0523], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:09,793][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Alexander] are: tensor([0.0020, 0.2781, 0.5717, 0.1482], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:09,794][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Alexander] are: tensor([0.0307, 0.3160, 0.2780, 0.3753], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:09,794][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Alexander] are: tensor([0.0674, 0.0527, 0.5379, 0.3420], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:09,795][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Alexander] are: tensor([0.4296, 0.1006, 0.3045, 0.1654], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:09,798][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Alexander] are: tensor([0.1330, 0.0517, 0.5856, 0.2297], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:09,799][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Alexander] are: tensor([0.9067, 0.0466, 0.0102, 0.0365], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:09,800][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Alexander] are: tensor([0.3306, 0.3567, 0.1697, 0.1430], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:09,801][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Alexander] are: tensor([0.4695, 0.0864, 0.3189, 0.1252], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:09,802][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Alexander] are: tensor([0.6942, 0.0339, 0.1703, 0.1015], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:09,804][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Alexander] are: tensor([0.8901, 0.0707, 0.0224, 0.0167], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:09,806][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Alexander] are: tensor([0.8942, 0.0395, 0.0226, 0.0436], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:09,807][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Alexander] are: tensor([0.7714, 0.0431, 0.1115, 0.0739], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:09,808][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([0.0012, 0.2757, 0.4238, 0.1292, 0.1700], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:09,808][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([0.0308, 0.2119, 0.1941, 0.2567, 0.3065], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:09,811][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([0.0273, 0.0913, 0.1872, 0.6627, 0.0315], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:09,813][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([0.2832, 0.0850, 0.2553, 0.2992, 0.0773], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:09,814][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([0.1203, 0.0595, 0.3757, 0.2907, 0.1537], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:09,814][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([0.8405, 0.0537, 0.0355, 0.0201, 0.0502], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:09,815][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([0.0570, 0.1579, 0.3562, 0.3723, 0.0566], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:09,818][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([0.5038, 0.0122, 0.1543, 0.0591, 0.2706], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:09,820][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([0.4203, 0.0648, 0.2986, 0.1213, 0.0950], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:09,820][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([0.8114, 0.0588, 0.0314, 0.0687, 0.0297], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:09,821][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([0.7072, 0.1181, 0.0438, 0.0997, 0.0313], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:09,822][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([0.8061, 0.0223, 0.0460, 0.0188, 0.1067], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:09,824][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0013, 0.1883, 0.2714, 0.0902, 0.1779, 0.2708], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:09,826][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0346, 0.2125, 0.1454, 0.2172, 0.2413, 0.1491], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:09,827][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0568, 0.0527, 0.0421, 0.1315, 0.0115, 0.7054], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:09,828][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.6207, 0.0273, 0.0606, 0.1140, 0.0593, 0.1180], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:09,829][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.2246, 0.0384, 0.1038, 0.1166, 0.0809, 0.4357], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:09,832][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.9404, 0.0191, 0.0042, 0.0139, 0.0122, 0.0101], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:09,833][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.2885, 0.0856, 0.0529, 0.0823, 0.2702, 0.2204], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:09,834][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.4569, 0.0080, 0.0469, 0.0244, 0.2244, 0.2394], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:09,835][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.8291, 0.0180, 0.0270, 0.0498, 0.0244, 0.0518], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:09,835][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.9182, 0.0281, 0.0072, 0.0221, 0.0102, 0.0142], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:09,839][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.9704, 0.0089, 0.0038, 0.0050, 0.0067, 0.0053], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:09,840][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.8454, 0.0145, 0.0222, 0.0140, 0.0245, 0.0794], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:09,841][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0009, 0.1241, 0.2383, 0.0608, 0.1216, 0.2541, 0.2002],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:09,841][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0270, 0.1712, 0.1393, 0.1880, 0.2137, 0.1321, 0.1287],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:09,842][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0266, 0.0236, 0.0160, 0.0370, 0.0062, 0.7450, 0.1456],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:09,846][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.4648, 0.0179, 0.0624, 0.0880, 0.0398, 0.1335, 0.1936],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:09,847][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0607, 0.0175, 0.0818, 0.0568, 0.0740, 0.6179, 0.0912],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:09,847][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.9661, 0.0075, 0.0013, 0.0066, 0.0055, 0.0101, 0.0029],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:09,848][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.3261, 0.0751, 0.0559, 0.1150, 0.1750, 0.2380, 0.0149],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:09,849][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.3892, 0.0081, 0.0747, 0.0281, 0.1151, 0.3083, 0.0766],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:09,852][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.7819, 0.0165, 0.0207, 0.0609, 0.0327, 0.0684, 0.0189],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:09,853][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.9363, 0.0182, 0.0046, 0.0136, 0.0084, 0.0096, 0.0092],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:09,854][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.9436, 0.0139, 0.0061, 0.0105, 0.0098, 0.0081, 0.0080],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:09,855][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.8040, 0.0136, 0.0189, 0.0167, 0.0189, 0.0629, 0.0649],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:09,856][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ station] are: tensor([0.0007, 0.1199, 0.1761, 0.0657, 0.1038, 0.2040, 0.1834, 0.1463],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:09,859][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ station] are: tensor([0.0274, 0.1381, 0.1219, 0.1559, 0.1829, 0.1200, 0.1299, 0.1240],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:09,860][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ station] are: tensor([0.0093, 0.0131, 0.0122, 0.0162, 0.0042, 0.6348, 0.2881, 0.0222],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:09,861][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ station] are: tensor([0.2342, 0.0312, 0.0754, 0.0644, 0.0406, 0.1100, 0.3112, 0.1329],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:09,862][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ station] are: tensor([0.0596, 0.0101, 0.0869, 0.0451, 0.0801, 0.4692, 0.1528, 0.0963],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:09,863][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ station] are: tensor([0.9177, 0.0300, 0.0022, 0.0140, 0.0087, 0.0101, 0.0116, 0.0058],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:09,866][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ station] are: tensor([0.0927, 0.0640, 0.0457, 0.0908, 0.1909, 0.1704, 0.0855, 0.2599],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:09,867][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ station] are: tensor([0.2601, 0.0104, 0.0553, 0.0339, 0.1354, 0.2514, 0.0877, 0.1657],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:09,868][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ station] are: tensor([0.4381, 0.0186, 0.0403, 0.0551, 0.0416, 0.2355, 0.1475, 0.0232],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:09,869][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ station] are: tensor([0.8789, 0.0312, 0.0084, 0.0339, 0.0085, 0.0144, 0.0181, 0.0067],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:09,872][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ station] are: tensor([0.9726, 0.0040, 0.0022, 0.0011, 0.0051, 0.0058, 0.0045, 0.0048],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:09,873][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ station] are: tensor([0.6032, 0.0252, 0.0569, 0.0198, 0.0449, 0.1325, 0.0762, 0.0413],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:09,874][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0009, 0.1160, 0.1231, 0.0567, 0.0914, 0.1616, 0.1566, 0.1477, 0.1460],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:09,875][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0312, 0.1373, 0.1036, 0.1448, 0.1539, 0.0985, 0.1065, 0.1256, 0.0986],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:09,876][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0210, 0.0107, 0.0177, 0.0641, 0.0031, 0.3880, 0.3524, 0.1261, 0.0168],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:09,880][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.5443, 0.0058, 0.0159, 0.0303, 0.0202, 0.0684, 0.1090, 0.1117, 0.0944],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:09,880][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.1162, 0.0069, 0.0542, 0.0283, 0.0673, 0.3443, 0.1037, 0.1636, 0.1155],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:09,881][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.9030, 0.0183, 0.0053, 0.0169, 0.0084, 0.0147, 0.0089, 0.0204, 0.0040],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:09,882][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.2041, 0.0456, 0.0350, 0.0423, 0.0411, 0.1335, 0.0277, 0.3670, 0.1038],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:09,886][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.4262, 0.0025, 0.0555, 0.0200, 0.0470, 0.2632, 0.0414, 0.0961, 0.0481],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:09,886][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.7573, 0.0131, 0.0173, 0.0428, 0.0324, 0.0714, 0.0375, 0.0153, 0.0127],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:09,887][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.9282, 0.0162, 0.0044, 0.0153, 0.0059, 0.0066, 0.0078, 0.0099, 0.0057],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:09,888][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.9492, 0.0075, 0.0047, 0.0051, 0.0063, 0.0056, 0.0047, 0.0032, 0.0136],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:09,889][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.6726, 0.0143, 0.0269, 0.0148, 0.0257, 0.0582, 0.0326, 0.0189, 0.1360],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:09,893][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Benjamin] are: tensor([0.0007, 0.0839, 0.1426, 0.0469, 0.0783, 0.1382, 0.1253, 0.1115, 0.1550,
        0.1176], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:09,894][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Benjamin] are: tensor([0.0127, 0.1014, 0.0920, 0.1317, 0.1568, 0.0852, 0.0846, 0.1166, 0.0811,
        0.1381], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:09,895][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Benjamin] are: tensor([0.0272, 0.0152, 0.1758, 0.0912, 0.0110, 0.3266, 0.1976, 0.0512, 0.0844,
        0.0197], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:09,895][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Benjamin] are: tensor([0.1679, 0.0178, 0.0623, 0.0606, 0.0233, 0.0723, 0.1792, 0.1487, 0.2207,
        0.0471], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:09,899][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Benjamin] are: tensor([0.0477, 0.0045, 0.0475, 0.0316, 0.0641, 0.2776, 0.0843, 0.1695, 0.2412,
        0.0320], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:09,900][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Benjamin] are: tensor([0.8134, 0.0321, 0.0270, 0.0497, 0.0224, 0.0092, 0.0112, 0.0146, 0.0149,
        0.0055], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:09,901][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Benjamin] are: tensor([0.0948, 0.0245, 0.0322, 0.0363, 0.0322, 0.0681, 0.0414, 0.3165, 0.3325,
        0.0215], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:09,901][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Benjamin] are: tensor([0.3135, 0.0320, 0.0469, 0.0507, 0.1264, 0.1791, 0.0623, 0.0758, 0.0668,
        0.0463], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:09,903][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Benjamin] are: tensor([0.7341, 0.0113, 0.0250, 0.0612, 0.0489, 0.0319, 0.0182, 0.0204, 0.0350,
        0.0139], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:09,906][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Benjamin] are: tensor([0.8795, 0.0158, 0.0133, 0.0187, 0.0123, 0.0112, 0.0153, 0.0189, 0.0111,
        0.0039], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:09,907][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Benjamin] are: tensor([0.8644, 0.0130, 0.0097, 0.0095, 0.0163, 0.0182, 0.0093, 0.0121, 0.0324,
        0.0151], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:09,908][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Benjamin] are: tensor([0.7020, 0.0165, 0.0309, 0.0245, 0.0198, 0.0533, 0.0328, 0.0144, 0.0592,
        0.0465], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:09,909][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.0006, 0.0829, 0.1233, 0.0385, 0.0540, 0.1356, 0.1303, 0.1005, 0.1458,
        0.1210, 0.0676], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:09,912][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0157, 0.0963, 0.0770, 0.1216, 0.1292, 0.0779, 0.0795, 0.1075, 0.0772,
        0.1290, 0.0891], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:09,913][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.0009, 0.0013, 0.0013, 0.0163, 0.0011, 0.5517, 0.2395, 0.1659, 0.0150,
        0.0037, 0.0033], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:09,914][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.1895, 0.0063, 0.0254, 0.0335, 0.0171, 0.0907, 0.3193, 0.1112, 0.1446,
        0.0358, 0.0266], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:09,915][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.0354, 0.0088, 0.0400, 0.0348, 0.0209, 0.2794, 0.0734, 0.2122, 0.1656,
        0.0672, 0.0623], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:09,917][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.6901, 0.0277, 0.0096, 0.0429, 0.0196, 0.0242, 0.0326, 0.0579, 0.0334,
        0.0576, 0.0042], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:09,920][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.0126, 0.0179, 0.0295, 0.0368, 0.0206, 0.1648, 0.0259, 0.4755, 0.1703,
        0.0220, 0.0241], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:09,920][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.4343, 0.0091, 0.0264, 0.0108, 0.0542, 0.2142, 0.0357, 0.1006, 0.0624,
        0.0163, 0.0361], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:09,921][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.3950, 0.0165, 0.0238, 0.0692, 0.0164, 0.0950, 0.0985, 0.0872, 0.1212,
        0.0682, 0.0090], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:09,922][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.8229, 0.0255, 0.0067, 0.0176, 0.0108, 0.0207, 0.0180, 0.0266, 0.0213,
        0.0206, 0.0093], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:09,926][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.8064, 0.0288, 0.0090, 0.0163, 0.0097, 0.0217, 0.0090, 0.0114, 0.0319,
        0.0392, 0.0167], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:09,927][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.6689, 0.0134, 0.0261, 0.0107, 0.0240, 0.0672, 0.0410, 0.0115, 0.0618,
        0.0308, 0.0445], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:09,927][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0004, 0.0598, 0.1229, 0.0329, 0.0585, 0.1338, 0.1071, 0.0983, 0.1502,
        0.0920, 0.0727, 0.0714], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:09,928][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0196, 0.0973, 0.0760, 0.1067, 0.1178, 0.0736, 0.0718, 0.0975, 0.0728,
        0.1133, 0.0932, 0.0606], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:09,931][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0159, 0.0078, 0.0023, 0.0378, 0.0017, 0.5129, 0.2025, 0.1608, 0.0135,
        0.0119, 0.0071, 0.0257], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:09,933][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.3353, 0.0081, 0.0262, 0.0380, 0.0139, 0.0630, 0.1110, 0.1117, 0.1339,
        0.0449, 0.0540, 0.0601], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:09,934][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0562, 0.0093, 0.0336, 0.0315, 0.0374, 0.1952, 0.0500, 0.1517, 0.1202,
        0.0546, 0.1385, 0.1220], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:09,935][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.9434, 0.0063, 0.0013, 0.0058, 0.0043, 0.0035, 0.0039, 0.0093, 0.0037,
        0.0064, 0.0105, 0.0015], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:09,936][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.1056, 0.0246, 0.0167, 0.0335, 0.0728, 0.1012, 0.0077, 0.3407, 0.1032,
        0.0237, 0.1607, 0.0096], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:09,939][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.2635, 0.0079, 0.0350, 0.0107, 0.0855, 0.1983, 0.0360, 0.1322, 0.0623,
        0.0186, 0.1062, 0.0438], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:09,940][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.7576, 0.0081, 0.0110, 0.0266, 0.0140, 0.0223, 0.0175, 0.0173, 0.0388,
        0.0311, 0.0430, 0.0126], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:09,941][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.9109, 0.0109, 0.0037, 0.0068, 0.0071, 0.0084, 0.0072, 0.0150, 0.0090,
        0.0080, 0.0090, 0.0041], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:09,942][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.9295, 0.0064, 0.0036, 0.0043, 0.0067, 0.0047, 0.0034, 0.0030, 0.0133,
        0.0117, 0.0075, 0.0059], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:09,944][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.7535, 0.0110, 0.0146, 0.0090, 0.0179, 0.0299, 0.0238, 0.0133, 0.0300,
        0.0221, 0.0155, 0.0593], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:09,947][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ computer] are: tensor([0.0006, 0.0714, 0.1000, 0.0453, 0.0593, 0.1112, 0.1076, 0.0811, 0.1143,
        0.0990, 0.0701, 0.0843, 0.0557], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:09,948][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ computer] are: tensor([0.0103, 0.0782, 0.0654, 0.0961, 0.1229, 0.0732, 0.0661, 0.0888, 0.0644,
        0.1099, 0.0977, 0.0556, 0.0713], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:09,948][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ computer] are: tensor([0.0099, 0.0076, 0.0016, 0.0408, 0.0014, 0.2727, 0.1074, 0.0430, 0.0049,
        0.0366, 0.0145, 0.0385, 0.4210], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:09,949][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ computer] are: tensor([0.1556, 0.0084, 0.0201, 0.0265, 0.0097, 0.0514, 0.1247, 0.0606, 0.0791,
        0.0394, 0.0363, 0.1307, 0.2572], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:09,953][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ computer] are: tensor([0.0517, 0.0037, 0.0270, 0.0202, 0.0201, 0.1644, 0.0462, 0.0695, 0.1352,
        0.0343, 0.0998, 0.2670, 0.0608], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:09,956][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ computer] are: tensor([0.7098, 0.0208, 0.0037, 0.0224, 0.0145, 0.0298, 0.0180, 0.0136, 0.0136,
        0.0381, 0.0993, 0.0131, 0.0033], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:09,957][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ computer] are: tensor([0.1351, 0.0227, 0.0173, 0.0184, 0.0300, 0.0308, 0.0404, 0.2416, 0.1535,
        0.0288, 0.0782, 0.0825, 0.1208], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:09,958][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ computer] are: tensor([0.4818, 0.0075, 0.0275, 0.0119, 0.0581, 0.0920, 0.0264, 0.0672, 0.0740,
        0.0199, 0.0533, 0.0419, 0.0384], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:09,959][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ computer] are: tensor([0.5362, 0.0096, 0.0105, 0.0179, 0.0164, 0.0571, 0.0296, 0.0184, 0.0594,
        0.0525, 0.1366, 0.0407, 0.0151], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:09,960][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ computer] are: tensor([8.9483e-01, 1.5767e-02, 6.0810e-03, 1.4106e-02, 6.5283e-03, 9.8176e-03,
        7.3894e-03, 1.3351e-02, 1.2457e-02, 7.0943e-03, 8.6978e-03, 3.7591e-03,
        1.2608e-04], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:09,962][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ computer] are: tensor([9.7417e-01, 2.4695e-03, 9.3111e-04, 3.6953e-04, 1.9919e-03, 1.8424e-03,
        1.0933e-03, 1.3793e-03, 7.0469e-03, 3.4124e-03, 1.6272e-03, 2.5629e-03,
        1.0995e-03], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:09,964][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ computer] are: tensor([0.5374, 0.0064, 0.0292, 0.0081, 0.0192, 0.0532, 0.0791, 0.0180, 0.1014,
        0.0191, 0.0285, 0.0875, 0.0128], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:09,964][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0005, 0.0597, 0.0847, 0.0293, 0.0572, 0.0857, 0.0999, 0.0883, 0.1087,
        0.0835, 0.0659, 0.0797, 0.0620, 0.0949], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:09,965][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0140, 0.0912, 0.0636, 0.0954, 0.1019, 0.0652, 0.0619, 0.0793, 0.0639,
        0.0994, 0.0818, 0.0560, 0.0726, 0.0540], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:09,967][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1044, 0.0089, 0.0014, 0.0317, 0.0011, 0.0889, 0.0559, 0.0659, 0.0071,
        0.0253, 0.0047, 0.0460, 0.3254, 0.2333], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:09,970][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.4406, 0.0036, 0.0092, 0.0169, 0.0072, 0.0222, 0.0493, 0.0475, 0.0576,
        0.0193, 0.0236, 0.0415, 0.2072, 0.0541], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:09,971][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.1204, 0.0053, 0.0094, 0.0163, 0.0099, 0.0358, 0.0345, 0.0533, 0.0629,
        0.0270, 0.0576, 0.2040, 0.0721, 0.2914], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:09,972][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.9205, 0.0086, 0.0023, 0.0066, 0.0039, 0.0027, 0.0078, 0.0072, 0.0080,
        0.0076, 0.0104, 0.0057, 0.0059, 0.0028], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:09,974][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.1622, 0.0123, 0.0062, 0.0115, 0.0537, 0.0256, 0.0127, 0.1883, 0.1292,
        0.0178, 0.0743, 0.0235, 0.1714, 0.1112], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:09,977][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.3656, 0.0060, 0.0180, 0.0090, 0.0842, 0.0575, 0.0202, 0.0571, 0.0514,
        0.0137, 0.0727, 0.0304, 0.0261, 0.1882], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:09,978][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.8001, 0.0057, 0.0065, 0.0142, 0.0051, 0.0120, 0.0208, 0.0034, 0.0289,
        0.0174, 0.0174, 0.0321, 0.0118, 0.0246], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:09,979][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.9562, 0.0048, 0.0014, 0.0033, 0.0031, 0.0038, 0.0037, 0.0044, 0.0033,
        0.0029, 0.0048, 0.0029, 0.0012, 0.0042], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:09,979][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([9.8613e-01, 7.3886e-04, 5.0864e-04, 4.2122e-04, 1.5648e-03, 7.3977e-04,
        4.7845e-04, 2.8441e-04, 2.1537e-03, 1.2312e-03, 1.4700e-03, 1.3508e-03,
        8.5856e-05, 2.8455e-03], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:09,983][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.7850, 0.0045, 0.0123, 0.0057, 0.0143, 0.0366, 0.0138, 0.0079, 0.0354,
        0.0067, 0.0107, 0.0252, 0.0035, 0.0384], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:09,986][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:20:09,989][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[5085],
        [2636],
        [5827],
        [9907],
        [4828],
        [1766],
        [2249],
        [ 602],
        [2693],
        [1196],
        [2291],
        [3388],
        [ 325],
        [ 994]], device='cuda:0')
[2024-07-24 10:20:09,991][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[4935],
        [1039],
        [2741],
        [9376],
        [2912],
        [ 403],
        [ 493],
        [  26],
        [ 854],
        [ 400],
        [ 787],
        [ 885],
        [  64],
        [ 334]], device='cuda:0')
[2024-07-24 10:20:09,993][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[16388],
        [16339],
        [13795],
        [19245],
        [20077],
        [19709],
        [26405],
        [20665],
        [19945],
        [25773],
        [20794],
        [21511],
        [23931],
        [19926]], device='cuda:0')
[2024-07-24 10:20:09,994][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[11444],
        [12677],
        [18370],
        [22873],
        [24863],
        [14330],
        [15172],
        [30658],
        [24112],
        [29382],
        [30532],
        [15414],
        [13697],
        [13150]], device='cuda:0')
[2024-07-24 10:20:09,996][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 2654],
        [ 8985],
        [ 8783],
        [ 9817],
        [10423],
        [ 9873],
        [ 9007],
        [ 9310],
        [ 8374],
        [ 9043],
        [ 9897],
        [ 9738],
        [ 9550],
        [ 9399]], device='cuda:0')
[2024-07-24 10:20:09,999][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[40797],
        [43404],
        [43285],
        [43693],
        [43899],
        [44035],
        [44116],
        [44153],
        [43986],
        [43752],
        [43916],
        [43874],
        [43808],
        [43771]], device='cuda:0')
[2024-07-24 10:20:10,000][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[ 7233],
        [ 9215],
        [ 7706],
        [14332],
        [14739],
        [10159],
        [15680],
        [15208],
        [18941],
        [21335],
        [21429],
        [20332],
        [19666],
        [17112]], device='cuda:0')
[2024-07-24 10:20:10,001][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[48881],
        [26667],
        [27799],
        [27462],
        [24798],
        [27365],
        [28799],
        [29102],
        [33042],
        [37952],
        [36701],
        [34141],
        [34569],
        [37536]], device='cuda:0')
[2024-07-24 10:20:10,003][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[18587],
        [28441],
        [37014],
        [39511],
        [43641],
        [41216],
        [41726],
        [47212],
        [48405],
        [47818],
        [48423],
        [47087],
        [44008],
        [43184]], device='cuda:0')
[2024-07-24 10:20:10,006][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[  601],
        [ 5242],
        [ 1733],
        [10562],
        [15670],
        [14197],
        [12986],
        [20635],
        [12194],
        [16571],
        [12297],
        [17363],
        [11296],
        [11512]], device='cuda:0')
[2024-07-24 10:20:10,007][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[19175],
        [18519],
        [15610],
        [13365],
        [13050],
        [12160],
        [11721],
        [10432],
        [10619],
        [10365],
        [10465],
        [10679],
        [10824],
        [11179]], device='cuda:0')
[2024-07-24 10:20:10,009][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[22664],
        [31693],
        [32672],
        [32805],
        [33147],
        [33861],
        [34220],
        [34971],
        [34930],
        [35083],
        [35259],
        [35436],
        [35766],
        [35839]], device='cuda:0')
[2024-07-24 10:20:10,010][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[15664],
        [12801],
        [25909],
        [ 7494],
        [13571],
        [21044],
        [10243],
        [24176],
        [23338],
        [20526],
        [16489],
        [14130],
        [27210],
        [23358]], device='cuda:0')
[2024-07-24 10:20:10,013][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[2635],
        [4253],
        [ 999],
        [ 854],
        [1511],
        [1785],
        [1847],
        [2281],
        [1325],
        [1280],
        [1436],
        [1041],
        [1270],
        [1231]], device='cuda:0')
[2024-07-24 10:20:10,015][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 6233],
        [24280],
        [25998],
        [30458],
        [25250],
        [30813],
        [31518],
        [35606],
        [34758],
        [21545],
        [30717],
        [33755],
        [29105],
        [32210]], device='cuda:0')
[2024-07-24 10:20:10,016][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[19327],
        [13753],
        [13347],
        [12498],
        [12254],
        [12393],
        [12233],
        [12614],
        [13023],
        [12882],
        [12910],
        [13059],
        [12953],
        [13077]], device='cuda:0')
[2024-07-24 10:20:10,018][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[29906],
        [19845],
        [22372],
        [23254],
        [22863],
        [23194],
        [24115],
        [24513],
        [25082],
        [24851],
        [24653],
        [24802],
        [25245],
        [25337]], device='cuda:0')
[2024-07-24 10:20:10,021][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[17023],
        [28806],
        [23387],
        [20490],
        [27724],
        [34198],
        [35765],
        [36285],
        [35428],
        [31897],
        [35302],
        [34574],
        [32888],
        [31897]], device='cuda:0')
[2024-07-24 10:20:10,022][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[ 479],
        [ 307],
        [ 212],
        [ 375],
        [ 486],
        [ 648],
        [1103],
        [1283],
        [1197],
        [ 882],
        [1270],
        [1088],
        [1172],
        [1488]], device='cuda:0')
[2024-07-24 10:20:10,023][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[21989],
        [ 8108],
        [16090],
        [ 5581],
        [ 4471],
        [12828],
        [13517],
        [11766],
        [12623],
        [11207],
        [ 9762],
        [11065],
        [14807],
        [26116]], device='cuda:0')
[2024-07-24 10:20:10,025][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[6726],
        [4323],
        [6028],
        [5742],
        [7077],
        [6618],
        [6799],
        [6560],
        [6709],
        [7144],
        [8835],
        [6706],
        [9010],
        [7070]], device='cuda:0')
[2024-07-24 10:20:10,028][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[46840],
        [34826],
        [17287],
        [16439],
        [ 9415],
        [13794],
        [15242],
        [16949],
        [23341],
        [22223],
        [21206],
        [22562],
        [21509],
        [22774]], device='cuda:0')
[2024-07-24 10:20:10,029][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[12316],
        [ 7338],
        [ 6708],
        [ 3160],
        [ 4806],
        [ 3424],
        [ 2645],
        [ 3455],
        [ 2614],
        [ 3657],
        [ 2769],
        [ 2734],
        [ 3054],
        [ 3073]], device='cuda:0')
[2024-07-24 10:20:10,031][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[ 4844],
        [ 3170],
        [ 3129],
        [ 2797],
        [ 4031],
        [ 3793],
        [ 3779],
        [ 6790],
        [ 4421],
        [ 4626],
        [ 6219],
        [ 5757],
        [10469],
        [ 5083]], device='cuda:0')
[2024-07-24 10:20:10,033][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[24158],
        [24825],
        [24261],
        [24366],
        [23517],
        [24316],
        [24194],
        [24281],
        [24471],
        [24185],
        [25021],
        [24885],
        [24935],
        [24571]], device='cuda:0')
[2024-07-24 10:20:10,036][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[13885],
        [ 7642],
        [11467],
        [ 9895],
        [ 3489],
        [13783],
        [13249],
        [13479],
        [12489],
        [10233],
        [ 7582],
        [12251],
        [13201],
        [13685]], device='cuda:0')
[2024-07-24 10:20:10,037][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[43559],
        [42748],
        [44781],
        [46896],
        [46221],
        [47080],
        [47190],
        [47120],
        [47807],
        [48025],
        [48023],
        [48760],
        [48557],
        [48908]], device='cuda:0')
[2024-07-24 10:20:10,038][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[19006],
        [29934],
        [31417],
        [35134],
        [35194],
        [31963],
        [31515],
        [28846],
        [29833],
        [29105],
        [28080],
        [29447],
        [24525],
        [25645]], device='cuda:0')
[2024-07-24 10:20:10,040][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[15199],
        [11444],
        [16921],
        [17253],
        [19302],
        [11855],
        [10426],
        [11212],
        [ 9661],
        [13201],
        [14846],
        [12387],
        [13599],
        [10955]], device='cuda:0')
[2024-07-24 10:20:10,043][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[10918],
        [10918],
        [10918],
        [10918],
        [10918],
        [10918],
        [10918],
        [10918],
        [10918],
        [10918],
        [10918],
        [10918],
        [10918],
        [10918]], device='cuda:0')
[2024-07-24 10:20:10,115][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:20:10,117][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:10,117][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:10,118][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:10,119][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:10,119][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:10,120][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:10,121][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:10,121][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:10,122][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:10,122][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:10,123][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:10,124][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:10,127][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Benjamin] are: tensor([0.1006, 0.8994], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:10,128][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Benjamin] are: tensor([0.2367, 0.7633], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:10,128][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Benjamin] are: tensor([0.4161, 0.5839], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:10,129][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Benjamin] are: tensor([0.0281, 0.9719], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:10,131][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Benjamin] are: tensor([0.5595, 0.4405], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:10,134][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Benjamin] are: tensor([0.2252, 0.7748], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:10,135][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Benjamin] are: tensor([0.6154, 0.3846], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:10,135][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Benjamin] are: tensor([0.6994, 0.3006], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:10,136][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Benjamin] are: tensor([0.9747, 0.0253], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:10,138][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Benjamin] are: tensor([0.1725, 0.8275], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:10,141][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Benjamin] are: tensor([0.5759, 0.4241], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:10,141][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Benjamin] are: tensor([0.2421, 0.7579], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:10,142][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0847, 0.4886, 0.4267], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:10,143][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.4062, 0.4353, 0.1585], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:10,145][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.3055, 0.3294, 0.3651], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:10,147][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0136, 0.4677, 0.5188], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:10,148][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.3028, 0.1802, 0.5171], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:10,149][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1367, 0.4135, 0.4497], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:10,150][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.5304, 0.2844, 0.1851], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:10,152][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.8709, 0.0916, 0.0375], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:10,154][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.9845, 0.0048, 0.0107], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:10,155][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0836, 0.3614, 0.5550], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:10,156][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.3715, 0.3014, 0.3272], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:10,156][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.2456, 0.4834, 0.2710], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:10,159][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Alexander] are: tensor([0.0400, 0.3518, 0.3239, 0.2844], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:10,161][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Alexander] are: tensor([0.0822, 0.4250, 0.2505, 0.2424], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:10,162][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Alexander] are: tensor([0.2085, 0.2632, 0.2993, 0.2290], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:10,162][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Alexander] are: tensor([0.0088, 0.3037, 0.3374, 0.3500], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:10,163][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Alexander] are: tensor([0.2559, 0.1189, 0.4234, 0.2017], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:10,166][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Alexander] are: tensor([0.0918, 0.2919, 0.3411, 0.2752], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:10,168][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Alexander] are: tensor([0.4421, 0.2122, 0.1644, 0.1813], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:10,168][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Alexander] are: tensor([0.5507, 0.2165, 0.1390, 0.0938], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:10,169][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Alexander] are: tensor([0.9455, 0.0073, 0.0251, 0.0221], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:10,170][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Alexander] are: tensor([0.0625, 0.2535, 0.3981, 0.2859], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:10,172][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Alexander] are: tensor([0.2904, 0.2261, 0.2426, 0.2409], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:10,177][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Alexander] are: tensor([0.1292, 0.3436, 0.2249, 0.3023], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:10,178][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ went] are: tensor([0.0327, 0.2577, 0.2427, 0.2249, 0.2419], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:10,178][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ went] are: tensor([0.0911, 0.3045, 0.2083, 0.2055, 0.1905], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:10,179][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ went] are: tensor([0.2231, 0.2097, 0.2324, 0.1874, 0.1474], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:10,180][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ went] are: tensor([0.0060, 0.2259, 0.2505, 0.2630, 0.2545], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:10,183][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ went] are: tensor([0.2356, 0.0869, 0.3581, 0.1725, 0.1468], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:10,185][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ went] are: tensor([0.0761, 0.2250, 0.2568, 0.2130, 0.2291], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:10,185][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ went] are: tensor([0.3848, 0.1610, 0.1542, 0.1612, 0.1387], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:10,186][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ went] are: tensor([0.5991, 0.1539, 0.1139, 0.0750, 0.0581], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:10,187][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.8959, 0.0050, 0.0322, 0.0378, 0.0290], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:10,189][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ went] are: tensor([0.0581, 0.2122, 0.3134, 0.2275, 0.1887], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:10,191][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ went] are: tensor([0.3164, 0.1736, 0.1895, 0.1770, 0.1435], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:10,192][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ went] are: tensor([0.0925, 0.2520, 0.1733, 0.2366, 0.2456], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:10,193][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0340, 0.2070, 0.1972, 0.1813, 0.1894, 0.1910], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:10,194][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.1135, 0.2886, 0.0973, 0.1844, 0.2420, 0.0742], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:10,196][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1551, 0.1821, 0.1947, 0.1750, 0.1418, 0.1513], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:10,198][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0064, 0.1753, 0.1925, 0.2018, 0.1957, 0.2283], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:10,199][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.1851, 0.0479, 0.1912, 0.0955, 0.0816, 0.3987], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:10,200][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0621, 0.1853, 0.2023, 0.1769, 0.1834, 0.1901], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:10,200][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.3031, 0.1484, 0.1269, 0.1385, 0.1220, 0.1610], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:10,203][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.7602, 0.0880, 0.0436, 0.0447, 0.0429, 0.0206], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:10,205][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ to] are: tensor([9.1899e-01, 7.3271e-04, 2.7938e-03, 8.3131e-03, 2.1525e-02, 4.7649e-02],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:10,206][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0356, 0.1631, 0.2478, 0.1941, 0.1604, 0.1991], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:10,206][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.1711, 0.1613, 0.1691, 0.1649, 0.1511, 0.1825], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:10,207][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0850, 0.2197, 0.1260, 0.2161, 0.2111, 0.1422], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:10,210][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0214, 0.1774, 0.1654, 0.1542, 0.1634, 0.1671, 0.1511],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:10,212][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.1146, 0.1934, 0.1120, 0.1648, 0.1907, 0.0802, 0.1444],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:10,212][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.1446, 0.1641, 0.1718, 0.1460, 0.1310, 0.1347, 0.1079],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:10,213][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0048, 0.1445, 0.1591, 0.1658, 0.1609, 0.1889, 0.1760],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:10,214][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.1489, 0.0444, 0.1831, 0.0792, 0.0717, 0.2982, 0.1745],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:10,217][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0482, 0.1543, 0.1733, 0.1480, 0.1566, 0.1631, 0.1564],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:10,218][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.2777, 0.1299, 0.1235, 0.1297, 0.1041, 0.1354, 0.0997],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:10,219][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.6608, 0.0940, 0.0627, 0.0521, 0.0641, 0.0344, 0.0319],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:10,220][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.8022, 0.0013, 0.0090, 0.0155, 0.0191, 0.1190, 0.0339],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:10,221][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0260, 0.1406, 0.2177, 0.1641, 0.1390, 0.1724, 0.1402],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:10,224][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.1490, 0.1404, 0.1467, 0.1391, 0.1248, 0.1505, 0.1496],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:10,225][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0804, 0.1934, 0.1093, 0.1755, 0.1773, 0.1291, 0.1351],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:10,226][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ station] are: tensor([0.0195, 0.1452, 0.1385, 0.1241, 0.1403, 0.1447, 0.1429, 0.1448],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:10,227][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ station] are: tensor([0.0701, 0.1477, 0.1189, 0.1080, 0.1651, 0.0803, 0.1330, 0.1768],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:10,227][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ station] are: tensor([0.1138, 0.1329, 0.1607, 0.1307, 0.1131, 0.1229, 0.0996, 0.1264],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:10,231][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ station] are: tensor([0.0035, 0.1216, 0.1352, 0.1407, 0.1365, 0.1611, 0.1500, 0.1514],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:10,232][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ station] are: tensor([0.1020, 0.0395, 0.1762, 0.0894, 0.0906, 0.2558, 0.1898, 0.0567],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:10,233][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ station] are: tensor([0.0447, 0.1291, 0.1511, 0.1222, 0.1345, 0.1402, 0.1323, 0.1458],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:10,233][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ station] are: tensor([0.2660, 0.1267, 0.1135, 0.1134, 0.0869, 0.1173, 0.0846, 0.0914],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:10,234][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ station] are: tensor([0.7006, 0.0734, 0.0476, 0.0427, 0.0478, 0.0290, 0.0306, 0.0283],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:10,237][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ station] are: tensor([0.7502, 0.0011, 0.0062, 0.0107, 0.0199, 0.1057, 0.0841, 0.0219],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:10,238][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ station] are: tensor([0.0355, 0.1228, 0.1817, 0.1458, 0.1224, 0.1477, 0.1233, 0.1208],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:10,239][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ station] are: tensor([0.1398, 0.1157, 0.1207, 0.1204, 0.1022, 0.1348, 0.1324, 0.1339],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:10,240][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ station] are: tensor([0.0549, 0.1486, 0.1026, 0.1273, 0.1469, 0.1151, 0.1196, 0.1848],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:10,241][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0253, 0.1286, 0.1158, 0.1115, 0.1238, 0.1221, 0.1160, 0.1320, 0.1248],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:10,244][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.1216, 0.1313, 0.0586, 0.1012, 0.1769, 0.0559, 0.1147, 0.1695, 0.0704],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:10,245][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.1126, 0.1221, 0.1423, 0.1187, 0.1050, 0.1072, 0.0806, 0.1070, 0.1045],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:10,246][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0041, 0.1056, 0.1158, 0.1209, 0.1169, 0.1367, 0.1274, 0.1296, 0.1430],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:10,247][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.1118, 0.0406, 0.1547, 0.0709, 0.0699, 0.2297, 0.1423, 0.0548, 0.1252],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:10,248][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0430, 0.1147, 0.1275, 0.1082, 0.1158, 0.1199, 0.1148, 0.1288, 0.1273],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:10,252][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.2438, 0.1278, 0.0964, 0.0945, 0.0819, 0.1153, 0.0824, 0.0871, 0.0707],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:10,252][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.7265, 0.0664, 0.0332, 0.0335, 0.0421, 0.0184, 0.0282, 0.0240, 0.0277],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:10,253][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [,] are: tensor([8.9759e-01, 4.1346e-04, 1.7834e-03, 4.6152e-03, 7.6379e-03, 3.5946e-02,
        2.2130e-02, 5.0880e-03, 2.4798e-02], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:10,254][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0350, 0.1144, 0.1617, 0.1350, 0.1071, 0.1298, 0.1092, 0.1067, 0.1011],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:10,258][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0983, 0.1036, 0.1086, 0.1103, 0.1014, 0.1182, 0.1196, 0.1177, 0.1223],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:10,258][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0767, 0.1386, 0.0766, 0.1287, 0.1313, 0.0919, 0.1047, 0.1674, 0.0841],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:10,259][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Benjamin] are: tensor([0.0149, 0.1116, 0.1087, 0.0960, 0.1051, 0.1128, 0.1043, 0.1204, 0.1166,
        0.1096], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:10,260][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Benjamin] are: tensor([0.0278, 0.1446, 0.0931, 0.1040, 0.0836, 0.0597, 0.0908, 0.1814, 0.0913,
        0.1238], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:10,262][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Benjamin] are: tensor([0.0794, 0.1229, 0.1242, 0.1086, 0.0878, 0.1011, 0.0766, 0.0971, 0.0945,
        0.1077], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:10,265][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Benjamin] are: tensor([0.0029, 0.0922, 0.1028, 0.1061, 0.1036, 0.1213, 0.1135, 0.1143, 0.1284,
        0.1149], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:10,266][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Benjamin] are: tensor([0.1979, 0.0322, 0.1177, 0.0566, 0.0489, 0.2115, 0.1131, 0.0386, 0.0892,
        0.0944], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:10,266][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Benjamin] are: tensor([0.0334, 0.1008, 0.1200, 0.0966, 0.1039, 0.1091, 0.1028, 0.1153, 0.1157,
        0.1024], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:10,267][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Benjamin] are: tensor([0.2208, 0.1111, 0.1141, 0.1194, 0.0789, 0.0958, 0.0701, 0.0763, 0.0616,
        0.0520], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:10,271][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Benjamin] are: tensor([0.3089, 0.1202, 0.1029, 0.0586, 0.0694, 0.0595, 0.0462, 0.0688, 0.1174,
        0.0481], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:10,272][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Benjamin] are: tensor([0.6804, 0.0023, 0.0112, 0.0256, 0.0207, 0.0719, 0.0412, 0.0293, 0.0971,
        0.0203], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:10,273][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Benjamin] are: tensor([0.0227, 0.0963, 0.1551, 0.1191, 0.1016, 0.1172, 0.0998, 0.0953, 0.0992,
        0.0937], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:10,273][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Benjamin] are: tensor([0.1104, 0.0946, 0.0979, 0.0945, 0.0824, 0.1037, 0.1054, 0.1047, 0.1082,
        0.0982], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:10,275][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Benjamin] are: tensor([0.0324, 0.1149, 0.0753, 0.1057, 0.1074, 0.0844, 0.0900, 0.1566, 0.0850,
        0.1483], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:10,278][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.0143, 0.1010, 0.0948, 0.0894, 0.0991, 0.1006, 0.0973, 0.1048, 0.1035,
        0.0979, 0.0973], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:10,279][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0292, 0.1352, 0.0681, 0.0851, 0.0811, 0.0425, 0.0961, 0.1751, 0.0793,
        0.1285, 0.0798], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:10,280][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0968, 0.1092, 0.1105, 0.0921, 0.0749, 0.0858, 0.0700, 0.0947, 0.0871,
        0.0963, 0.0826], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:10,281][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.0028, 0.0826, 0.0913, 0.0956, 0.0925, 0.1080, 0.1008, 0.1019, 0.1150,
        0.1028, 0.1066], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:10,284][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.0942, 0.0365, 0.1101, 0.0602, 0.0586, 0.1970, 0.1103, 0.0376, 0.0842,
        0.0955, 0.1158], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:10,285][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.0325, 0.0910, 0.1064, 0.0864, 0.0920, 0.0993, 0.0927, 0.1026, 0.1046,
        0.0938, 0.0987], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:10,286][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.2454, 0.0968, 0.0878, 0.0883, 0.0737, 0.1025, 0.0708, 0.0760, 0.0617,
        0.0475, 0.0495], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:10,287][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.5517, 0.0802, 0.0524, 0.0421, 0.0437, 0.0312, 0.0367, 0.0339, 0.0467,
        0.0374, 0.0439], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:10,288][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([7.9407e-01, 5.4933e-04, 2.4918e-03, 6.4418e-03, 6.6706e-03, 4.7099e-02,
        4.1840e-02, 1.3599e-02, 5.2388e-02, 1.5906e-02, 1.8944e-02],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:10,292][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.0242, 0.0900, 0.1371, 0.1087, 0.0871, 0.1087, 0.0931, 0.0915, 0.0899,
        0.0917, 0.0780], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:10,292][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.1145, 0.0827, 0.0863, 0.0836, 0.0715, 0.0958, 0.0968, 0.0958, 0.0983,
        0.0870, 0.0877], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:10,293][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0303, 0.1064, 0.0704, 0.0955, 0.1015, 0.0798, 0.0894, 0.1306, 0.0795,
        0.1278, 0.0889], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:10,294][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0171, 0.0956, 0.0898, 0.0833, 0.0882, 0.0907, 0.0818, 0.0981, 0.0945,
        0.0928, 0.0906, 0.0772], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:10,298][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0266, 0.1230, 0.0679, 0.0849, 0.0949, 0.0473, 0.0928, 0.1340, 0.0717,
        0.1199, 0.0827, 0.0544], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:10,299][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0814, 0.0973, 0.1033, 0.0890, 0.0773, 0.0800, 0.0684, 0.0856, 0.0809,
        0.0888, 0.0844, 0.0635], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:10,299][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0027, 0.0745, 0.0823, 0.0860, 0.0833, 0.0974, 0.0911, 0.0920, 0.1029,
        0.0925, 0.0963, 0.0989], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:10,300][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0830, 0.0277, 0.1021, 0.0512, 0.0523, 0.1618, 0.0936, 0.0383, 0.0885,
        0.0825, 0.1160, 0.1030], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:10,303][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0283, 0.0841, 0.0937, 0.0812, 0.0852, 0.0886, 0.0849, 0.0956, 0.0950,
        0.0883, 0.0909, 0.0842], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:10,305][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.1903, 0.0933, 0.0891, 0.0896, 0.0739, 0.0986, 0.0718, 0.0737, 0.0634,
        0.0493, 0.0498, 0.0572], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:10,306][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.4435, 0.1035, 0.0574, 0.0574, 0.0505, 0.0325, 0.0342, 0.0413, 0.0504,
        0.0458, 0.0541, 0.0294], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:10,307][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ a] are: tensor([7.3036e-01, 6.8703e-04, 3.4591e-03, 9.9974e-03, 9.8274e-03, 5.5758e-02,
        1.9636e-02, 1.0230e-02, 5.6922e-02, 2.1132e-02, 4.8264e-02, 3.3729e-02],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:10,308][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0227, 0.0824, 0.1292, 0.0992, 0.0839, 0.1002, 0.0846, 0.0817, 0.0796,
        0.0803, 0.0762, 0.0800], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:10,311][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0850, 0.0800, 0.0814, 0.0821, 0.0703, 0.0879, 0.0883, 0.0882, 0.0898,
        0.0800, 0.0813, 0.0857], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:10,312][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0381, 0.1026, 0.0604, 0.0914, 0.0925, 0.0706, 0.0750, 0.1229, 0.0677,
        0.1267, 0.0841, 0.0680], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:10,313][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ computer] are: tensor([0.0174, 0.0867, 0.0777, 0.0754, 0.0826, 0.0830, 0.0801, 0.0858, 0.0823,
        0.0852, 0.0832, 0.0760, 0.0846], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:10,314][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ computer] are: tensor([0.0262, 0.0919, 0.0691, 0.0614, 0.0778, 0.0454, 0.0668, 0.1185, 0.0643,
        0.0860, 0.0862, 0.0809, 0.1254], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:10,316][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ computer] are: tensor([0.0725, 0.0909, 0.0953, 0.0879, 0.0710, 0.0758, 0.0615, 0.0735, 0.0764,
        0.0808, 0.0805, 0.0604, 0.0735], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:10,319][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ computer] are: tensor([0.0021, 0.0680, 0.0757, 0.0785, 0.0763, 0.0904, 0.0841, 0.0847, 0.0948,
        0.0849, 0.0881, 0.0910, 0.0814], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:10,319][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ computer] are: tensor([0.0820, 0.0242, 0.0948, 0.0436, 0.0552, 0.1286, 0.0862, 0.0416, 0.0846,
        0.0655, 0.1109, 0.1117, 0.0710], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:10,320][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ computer] are: tensor([0.0251, 0.0774, 0.0907, 0.0731, 0.0797, 0.0829, 0.0772, 0.0872, 0.0879,
        0.0796, 0.0854, 0.0768, 0.0771], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:10,321][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ computer] are: tensor([0.1695, 0.0918, 0.0725, 0.0738, 0.0702, 0.0918, 0.0680, 0.0734, 0.0552,
        0.0483, 0.0455, 0.0511, 0.0889], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:10,325][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ computer] are: tensor([0.5011, 0.0877, 0.0451, 0.0428, 0.0514, 0.0253, 0.0275, 0.0323, 0.0463,
        0.0381, 0.0405, 0.0324, 0.0294], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:10,326][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ computer] are: tensor([7.5323e-01, 5.9013e-04, 2.9136e-03, 6.5416e-03, 5.3531e-03, 4.1770e-02,
        2.5315e-02, 6.2666e-03, 4.1327e-02, 1.1346e-02, 3.9606e-02, 4.7524e-02,
        1.8218e-02], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:10,326][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ computer] are: tensor([0.0228, 0.0759, 0.1170, 0.0894, 0.0761, 0.0931, 0.0754, 0.0733, 0.0728,
        0.0778, 0.0747, 0.0739, 0.0776], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:10,327][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ computer] are: tensor([0.1009, 0.0662, 0.0726, 0.0717, 0.0569, 0.0841, 0.0838, 0.0826, 0.0888,
        0.0758, 0.0756, 0.0821, 0.0588], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:10,330][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ computer] are: tensor([0.0295, 0.0919, 0.0605, 0.0764, 0.0836, 0.0670, 0.0704, 0.1092, 0.0653,
        0.1075, 0.0742, 0.0617, 0.1028], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:10,332][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0140, 0.0784, 0.0752, 0.0696, 0.0738, 0.0733, 0.0702, 0.0829, 0.0801,
        0.0774, 0.0789, 0.0703, 0.0825, 0.0734], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:10,333][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0261, 0.1029, 0.0379, 0.0649, 0.0841, 0.0291, 0.0706, 0.1226, 0.0471,
        0.1069, 0.0782, 0.0531, 0.1534, 0.0231], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:10,334][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0675, 0.0851, 0.0932, 0.0824, 0.0676, 0.0725, 0.0556, 0.0689, 0.0709,
        0.0768, 0.0723, 0.0535, 0.0694, 0.0642], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:10,335][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0025, 0.0631, 0.0695, 0.0723, 0.0702, 0.0820, 0.0768, 0.0773, 0.0859,
        0.0776, 0.0804, 0.0829, 0.0743, 0.0851], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:10,339][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0830, 0.0177, 0.0776, 0.0360, 0.0370, 0.1294, 0.0719, 0.0286, 0.0823,
        0.0711, 0.0924, 0.0808, 0.0576, 0.1345], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:10,340][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0235, 0.0730, 0.0805, 0.0698, 0.0728, 0.0752, 0.0715, 0.0824, 0.0802,
        0.0766, 0.0789, 0.0725, 0.0731, 0.0699], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:10,340][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1590, 0.0817, 0.0610, 0.0697, 0.0670, 0.0907, 0.0663, 0.0674, 0.0499,
        0.0522, 0.0434, 0.0492, 0.0788, 0.0637], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:10,341][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.4381, 0.0876, 0.0497, 0.0448, 0.0450, 0.0240, 0.0387, 0.0333, 0.0427,
        0.0380, 0.0633, 0.0398, 0.0394, 0.0157], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:10,343][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ to] are: tensor([8.1079e-01, 2.2858e-04, 8.8707e-04, 3.2854e-03, 4.0149e-03, 1.3037e-02,
        1.0231e-02, 3.1699e-03, 2.0824e-02, 6.7397e-03, 1.4153e-02, 2.0377e-02,
        1.5099e-02, 7.7165e-02], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:10,346][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0203, 0.0723, 0.1054, 0.0847, 0.0677, 0.0852, 0.0718, 0.0697, 0.0680,
        0.0715, 0.0655, 0.0707, 0.0747, 0.0725], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:10,347][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.1025, 0.0643, 0.0716, 0.0662, 0.0558, 0.0774, 0.0770, 0.0752, 0.0809,
        0.0691, 0.0687, 0.0744, 0.0533, 0.0635], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:10,347][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0299, 0.0831, 0.0482, 0.0824, 0.0783, 0.0542, 0.0626, 0.1065, 0.0545,
        0.1080, 0.0693, 0.0601, 0.1063, 0.0566], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:10,423][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:20:10,424][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:10,424][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:10,425][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:10,426][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:10,426][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:10,427][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:10,428][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:10,428][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:10,429][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:10,429][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:10,430][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:10,431][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:10,431][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Benjamin] are: tensor([0.9810, 0.0190], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:10,432][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Benjamin] are: tensor([0.7357, 0.2643], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:10,433][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Benjamin] are: tensor([0.2651, 0.7349], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:10,434][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Benjamin] are: tensor([0.9526, 0.0474], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:10,437][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Benjamin] are: tensor([0.9720, 0.0280], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:10,438][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Benjamin] are: tensor([0.5696, 0.4304], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:10,438][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Benjamin] are: tensor([0.2130, 0.7870], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:10,439][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Benjamin] are: tensor([0.9775, 0.0225], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:10,441][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Benjamin] are: tensor([0.7537, 0.2463], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:10,444][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Benjamin] are: tensor([0.1465, 0.8535], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:10,444][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Benjamin] are: tensor([0.3909, 0.6091], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:10,445][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Benjamin] are: tensor([0.7780, 0.2220], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:10,446][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([9.9802e-01, 1.8537e-03, 1.2795e-04], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:10,450][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.9787, 0.0194, 0.0019], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:10,450][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.2421, 0.3871, 0.3708], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:10,451][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.9568, 0.0142, 0.0290], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:10,452][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.9810, 0.0151, 0.0038], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:10,456][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.3537, 0.2747, 0.3716], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:10,457][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0312, 0.0889, 0.8799], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:10,457][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.9360, 0.0170, 0.0469], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:10,458][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.4802, 0.1103, 0.4095], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:10,462][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.2061, 0.4339, 0.3600], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:10,463][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.4981, 0.3646, 0.1374], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:10,463][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.8137, 0.0224, 0.1639], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:10,464][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Alexander] are: tensor([0.7662, 0.1482, 0.0462, 0.0393], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:10,468][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Alexander] are: tensor([0.2864, 0.4283, 0.2320, 0.0534], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:10,469][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Alexander] are: tensor([0.1314, 0.2859, 0.3016, 0.2812], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:10,470][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Alexander] are: tensor([0.7982, 0.0373, 0.0780, 0.0865], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:10,470][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Alexander] are: tensor([0.9868, 0.0082, 0.0025, 0.0025], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:10,474][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Alexander] are: tensor([0.2812, 0.1917, 0.2651, 0.2620], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:10,475][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Alexander] are: tensor([0.0896, 0.1106, 0.3383, 0.4615], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:10,476][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Alexander] are: tensor([0.9211, 0.0220, 0.0422, 0.0147], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:10,477][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Alexander] are: tensor([0.3989, 0.0953, 0.3600, 0.1457], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:10,481][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Alexander] are: tensor([0.0791, 0.1538, 0.4715, 0.2956], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:10,481][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Alexander] are: tensor([0.1493, 0.4177, 0.1277, 0.3053], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:10,482][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Alexander] are: tensor([0.4829, 0.0401, 0.3036, 0.1735], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:10,483][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([0.9889, 0.0020, 0.0017, 0.0045, 0.0028], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:10,487][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([0.5449, 0.1937, 0.2107, 0.0321, 0.0186], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:10,488][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([0.0951, 0.1928, 0.2654, 0.2340, 0.2126], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:10,488][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([0.6879, 0.0333, 0.0569, 0.1039, 0.1181], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:10,489][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([9.8474e-01, 6.5975e-03, 4.1976e-03, 3.8321e-03, 6.3291e-04],
       device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:10,493][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([0.2196, 0.1396, 0.1936, 0.1957, 0.2515], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:10,494][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([0.1048, 0.0586, 0.3034, 0.2230, 0.3103], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:10,494][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([0.8473, 0.0349, 0.0705, 0.0327, 0.0146], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:10,495][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([0.2439, 0.0728, 0.4544, 0.1567, 0.0722], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:10,499][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([0.1055, 0.1775, 0.4570, 0.1136, 0.1463], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:10,500][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([0.1211, 0.1237, 0.1032, 0.1143, 0.5377], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:10,501][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([0.3050, 0.0329, 0.2560, 0.2765, 0.1297], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:10,501][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([9.8354e-01, 4.0764e-03, 9.4715e-04, 8.0588e-03, 2.6105e-03, 7.7207e-04],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:10,505][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.8982, 0.0753, 0.0079, 0.0069, 0.0109, 0.0009], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:10,506][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1020, 0.1808, 0.1654, 0.2295, 0.1787, 0.1436], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:10,507][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.8836, 0.0051, 0.0061, 0.0197, 0.0241, 0.0614], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:10,508][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([9.9867e-01, 7.0985e-04, 1.8092e-04, 1.8821e-04, 8.9640e-05, 1.5924e-04],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:10,512][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.1859, 0.1165, 0.1596, 0.1620, 0.2105, 0.1655], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:10,512][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.1037, 0.0230, 0.1755, 0.1142, 0.0737, 0.5099], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:10,513][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.8972, 0.0120, 0.0268, 0.0140, 0.0111, 0.0388], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:10,514][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.4233, 0.0277, 0.1177, 0.0809, 0.0595, 0.2908], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:10,518][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0372, 0.1387, 0.1222, 0.2935, 0.1719, 0.2365], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:10,519][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.2025, 0.1962, 0.0354, 0.1085, 0.3792, 0.0781], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:10,519][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.5450, 0.0052, 0.0270, 0.0599, 0.0563, 0.3066], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:10,520][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([9.8017e-01, 5.6403e-03, 1.0619e-03, 7.8673e-03, 2.2071e-03, 2.6263e-03,
        4.2526e-04], device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:10,524][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.9149, 0.0243, 0.0224, 0.0125, 0.0095, 0.0033, 0.0130],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:10,525][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0670, 0.1407, 0.1175, 0.1548, 0.1602, 0.1055, 0.2543],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:10,526][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.8174, 0.0059, 0.0075, 0.0204, 0.0269, 0.0732, 0.0486],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:10,526][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([9.9397e-01, 1.5078e-03, 8.2162e-04, 5.9954e-04, 1.7881e-04, 6.8258e-04,
        2.2362e-03], device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:10,530][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.1608, 0.0957, 0.1346, 0.1396, 0.1824, 0.1419, 0.1450],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:10,531][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0577, 0.0248, 0.1904, 0.1056, 0.1122, 0.1996, 0.3096],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:10,532][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.7503, 0.0232, 0.0601, 0.0272, 0.0189, 0.0841, 0.0362],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:10,532][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.2163, 0.0285, 0.1576, 0.0772, 0.0443, 0.3581, 0.1180],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:10,536][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.1023, 0.1136, 0.0962, 0.1801, 0.2274, 0.1979, 0.0825],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:10,537][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.1310, 0.0866, 0.0280, 0.0755, 0.2592, 0.0954, 0.3242],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:10,538][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.1805, 0.0052, 0.0376, 0.0533, 0.0578, 0.5545, 0.1112],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:10,539][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ station] are: tensor([0.7794, 0.0038, 0.0094, 0.0043, 0.0142, 0.0623, 0.1256, 0.0010],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:10,543][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ station] are: tensor([0.7093, 0.0423, 0.0998, 0.0123, 0.0529, 0.0178, 0.0511, 0.0144],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:10,543][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ station] are: tensor([0.0683, 0.0822, 0.1378, 0.1262, 0.1449, 0.0966, 0.1914, 0.1525],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:10,544][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ station] are: tensor([0.7782, 0.0044, 0.0070, 0.0135, 0.0264, 0.0779, 0.0740, 0.0185],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:10,545][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ station] are: tensor([9.9181e-01, 1.4628e-03, 6.8631e-04, 6.7622e-04, 3.9121e-04, 1.1587e-03,
        3.6458e-03, 1.6894e-04], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:10,549][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ station] are: tensor([0.1277, 0.0842, 0.1171, 0.1217, 0.1582, 0.1232, 0.1265, 0.1416],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:10,550][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ station] are: tensor([0.0334, 0.0319, 0.1734, 0.0949, 0.1207, 0.2104, 0.1633, 0.1720],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:10,550][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ station] are: tensor([0.6927, 0.0159, 0.0585, 0.0220, 0.0230, 0.1114, 0.0494, 0.0271],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:10,551][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ station] are: tensor([0.1237, 0.0290, 0.1258, 0.0686, 0.0430, 0.3119, 0.1386, 0.1594],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:10,555][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ station] are: tensor([0.1928, 0.1827, 0.1097, 0.2226, 0.0654, 0.1084, 0.0865, 0.0320],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:10,556][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ station] are: tensor([0.0940, 0.0681, 0.0243, 0.0416, 0.1960, 0.0716, 0.2332, 0.2713],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:10,557][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ station] are: tensor([0.1832, 0.0040, 0.0303, 0.0263, 0.0338, 0.4315, 0.1198, 0.1711],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:10,558][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([9.8447e-01, 2.1560e-03, 1.9817e-04, 3.1591e-03, 5.7573e-03, 1.4930e-03,
        1.3775e-03, 1.2210e-03, 1.6683e-04], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:10,561][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.9402, 0.0136, 0.0037, 0.0031, 0.0138, 0.0011, 0.0124, 0.0104, 0.0018],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:10,562][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0662, 0.0852, 0.1183, 0.1033, 0.1286, 0.0981, 0.1582, 0.1206, 0.1214],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:10,563][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.8349, 0.0036, 0.0034, 0.0116, 0.0158, 0.0433, 0.0346, 0.0114, 0.0414],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:10,564][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([9.9749e-01, 8.3376e-04, 2.1831e-04, 2.2258e-04, 1.2168e-04, 1.8479e-04,
        5.2263e-04, 4.3237e-05, 3.6747e-04], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:10,568][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.1248, 0.0732, 0.1054, 0.1071, 0.1396, 0.1102, 0.1131, 0.1298, 0.0969],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:10,569][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0446, 0.0171, 0.1242, 0.0729, 0.0634, 0.1952, 0.1127, 0.0673, 0.3026],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:10,569][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.7390, 0.0174, 0.0448, 0.0236, 0.0224, 0.0742, 0.0350, 0.0181, 0.0256],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:10,570][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.2122, 0.0115, 0.0642, 0.0431, 0.0268, 0.1985, 0.1042, 0.0932, 0.2461],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:10,575][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0407, 0.1067, 0.0582, 0.4513, 0.0643, 0.0958, 0.0875, 0.0479, 0.0476],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:10,577][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.2478, 0.0781, 0.0246, 0.0539, 0.1885, 0.0520, 0.1397, 0.1687, 0.0468],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:10,578][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.2598, 0.0015, 0.0153, 0.0221, 0.0238, 0.2344, 0.0567, 0.0996, 0.2868],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:10,579][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Benjamin] are: tensor([0.4995, 0.0344, 0.0707, 0.0312, 0.0126, 0.1982, 0.0822, 0.0416, 0.0213,
        0.0082], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:10,580][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Benjamin] are: tensor([0.1736, 0.2013, 0.1618, 0.0671, 0.0104, 0.0179, 0.0391, 0.1651, 0.0433,
        0.1205], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:10,581][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Benjamin] are: tensor([0.0442, 0.1100, 0.0956, 0.1144, 0.0972, 0.0762, 0.1287, 0.1080, 0.1020,
        0.1237], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:10,584][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Benjamin] are: tensor([0.5660, 0.0078, 0.0106, 0.0302, 0.0336, 0.0927, 0.0697, 0.0427, 0.1163,
        0.0304], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:10,585][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Benjamin] are: tensor([9.9245e-01, 1.0898e-03, 5.7922e-04, 5.4720e-04, 2.6266e-04, 9.1471e-04,
        1.6278e-03, 2.4471e-04, 1.2270e-03, 1.0593e-03], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:10,586][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Benjamin] are: tensor([0.1115, 0.0675, 0.0972, 0.0989, 0.1306, 0.0990, 0.1015, 0.1174, 0.0857,
        0.0906], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:10,587][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Benjamin] are: tensor([0.0461, 0.0472, 0.0755, 0.0937, 0.0476, 0.1454, 0.0541, 0.0766, 0.1012,
        0.3125], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:10,590][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Benjamin] are: tensor([0.8666, 0.0153, 0.0257, 0.0132, 0.0061, 0.0356, 0.0096, 0.0106, 0.0098,
        0.0075], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:10,591][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Benjamin] are: tensor([0.1423, 0.0227, 0.1012, 0.0546, 0.0273, 0.1728, 0.0771, 0.1090, 0.2072,
        0.0859], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:10,592][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Benjamin] are: tensor([0.0192, 0.1072, 0.2326, 0.2296, 0.0834, 0.0684, 0.0816, 0.0238, 0.1332,
        0.0211], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:10,593][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Benjamin] are: tensor([0.0896, 0.0368, 0.0133, 0.0375, 0.1713, 0.0688, 0.1439, 0.3144, 0.0544,
        0.0701], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:10,597][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Benjamin] are: tensor([0.0550, 0.0036, 0.0333, 0.0288, 0.0427, 0.2354, 0.0658, 0.1103, 0.3761,
        0.0490], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:10,598][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.9524, 0.0029, 0.0019, 0.0077, 0.0080, 0.0075, 0.0141, 0.0024, 0.0010,
        0.0012, 0.0010], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:10,598][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.2751, 0.2035, 0.0751, 0.0198, 0.0115, 0.0064, 0.0798, 0.1197, 0.0444,
        0.1308, 0.0339], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:10,599][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.0549, 0.0927, 0.1004, 0.0861, 0.0733, 0.0736, 0.1299, 0.1164, 0.1047,
        0.0905, 0.0776], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:10,603][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.6133, 0.0069, 0.0078, 0.0192, 0.0245, 0.0928, 0.0744, 0.0265, 0.0898,
        0.0227, 0.0221], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:10,604][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([9.9396e-01, 1.9888e-03, 3.1178e-04, 4.6697e-04, 1.9704e-04, 4.0850e-04,
        1.0636e-03, 1.2499e-04, 4.6054e-04, 9.4804e-04, 7.1193e-05],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:10,605][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.1057, 0.0609, 0.0854, 0.0872, 0.1125, 0.0887, 0.0915, 0.1043, 0.0771,
        0.0827, 0.1039], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:10,606][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.0573, 0.0192, 0.1050, 0.0606, 0.0605, 0.1489, 0.0787, 0.0652, 0.1415,
        0.1570, 0.1060], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:10,609][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.7792, 0.0127, 0.0251, 0.0149, 0.0096, 0.0687, 0.0233, 0.0169, 0.0236,
        0.0144, 0.0114], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:10,610][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.0634, 0.0118, 0.0647, 0.0339, 0.0196, 0.1899, 0.0922, 0.1016, 0.2744,
        0.0789, 0.0698], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:10,611][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.0243, 0.0738, 0.0728, 0.1875, 0.0527, 0.0646, 0.0977, 0.0869, 0.1810,
        0.1527, 0.0061], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:10,612][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0938, 0.0456, 0.0185, 0.0257, 0.1380, 0.0502, 0.1398, 0.2550, 0.0594,
        0.1064, 0.0677], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:10,616][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.0696, 0.0020, 0.0200, 0.0211, 0.0118, 0.2275, 0.0876, 0.1059, 0.3758,
        0.0528, 0.0259], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:10,617][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([9.8023e-01, 4.9623e-03, 1.0417e-03, 5.5467e-03, 1.5182e-03, 2.5239e-03,
        4.2059e-04, 9.5937e-04, 4.0804e-04, 1.2885e-03, 7.5995e-04, 3.4098e-04],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:10,617][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.2428, 0.1125, 0.1056, 0.0218, 0.0227, 0.0207, 0.1605, 0.0458, 0.0654,
        0.1260, 0.0605, 0.0156], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:10,618][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0477, 0.0786, 0.0647, 0.0859, 0.0778, 0.0575, 0.1321, 0.0921, 0.0741,
        0.0850, 0.0786, 0.1259], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:10,622][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.8170, 0.0029, 0.0036, 0.0093, 0.0144, 0.0308, 0.0236, 0.0091, 0.0396,
        0.0105, 0.0135, 0.0257], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:10,623][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([9.9815e-01, 4.3695e-04, 8.3376e-05, 9.2071e-05, 5.8821e-05, 1.0528e-04,
        2.0469e-04, 4.5434e-05, 2.2041e-04, 1.8455e-04, 2.7134e-05, 3.9004e-04],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:10,624][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0897, 0.0563, 0.0779, 0.0810, 0.1037, 0.0813, 0.0832, 0.0964, 0.0714,
        0.0776, 0.0965, 0.0850], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:10,625][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0633, 0.0160, 0.0802, 0.0680, 0.0514, 0.1553, 0.0953, 0.0507, 0.1442,
        0.1085, 0.0684, 0.0987], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:10,628][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.7504, 0.0118, 0.0343, 0.0164, 0.0152, 0.0504, 0.0219, 0.0128, 0.0258,
        0.0131, 0.0176, 0.0304], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:10,629][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.1153, 0.0123, 0.0634, 0.0352, 0.0221, 0.1529, 0.0652, 0.0784, 0.1812,
        0.0807, 0.0817, 0.1114], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:10,630][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0636, 0.0979, 0.0823, 0.1328, 0.0863, 0.0799, 0.0947, 0.0352, 0.1090,
        0.1050, 0.0726, 0.0408], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:10,631][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.1085, 0.0444, 0.0130, 0.0422, 0.1534, 0.0592, 0.1525, 0.1760, 0.0598,
        0.0743, 0.0740, 0.0427], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:10,635][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.1232, 0.0019, 0.0128, 0.0194, 0.0258, 0.1683, 0.0360, 0.1210, 0.3068,
        0.0469, 0.0734, 0.0645], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:10,636][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ computer] are: tensor([9.3386e-01, 6.5031e-03, 1.6321e-03, 5.8589e-03, 7.3811e-03, 2.0773e-02,
        1.0811e-02, 1.3355e-03, 6.2888e-04, 2.8528e-03, 2.4744e-03, 5.1393e-03,
        7.5248e-04], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:10,637][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ computer] are: tensor([0.1596, 0.0844, 0.1238, 0.0266, 0.0530, 0.0167, 0.0311, 0.0960, 0.0422,
        0.0692, 0.1449, 0.0486, 0.1040], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:10,637][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ computer] are: tensor([0.0515, 0.0603, 0.0652, 0.0893, 0.0623, 0.0565, 0.1056, 0.0698, 0.0817,
        0.0702, 0.0862, 0.1117, 0.0897], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:10,641][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ computer] are: tensor([0.6370, 0.0035, 0.0084, 0.0104, 0.0184, 0.0680, 0.0513, 0.0136, 0.0736,
        0.0166, 0.0256, 0.0489, 0.0248], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:10,642][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ computer] are: tensor([9.9895e-01, 2.9255e-04, 5.4658e-05, 3.6022e-05, 5.3685e-05, 4.5003e-05,
        9.3257e-05, 2.7920e-05, 7.1556e-05, 6.6188e-05, 1.4927e-05, 2.7214e-04,
        1.9262e-05], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:10,643][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ computer] are: tensor([0.0720, 0.0549, 0.0727, 0.0746, 0.0959, 0.0758, 0.0771, 0.0885, 0.0655,
        0.0692, 0.0876, 0.0781, 0.0878], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:10,644][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ computer] are: tensor([0.0419, 0.0124, 0.0713, 0.0464, 0.0459, 0.1280, 0.0916, 0.0608, 0.1863,
        0.1056, 0.0794, 0.0739, 0.0565], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:10,647][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ computer] are: tensor([0.8086, 0.0064, 0.0272, 0.0086, 0.0124, 0.0418, 0.0171, 0.0099, 0.0148,
        0.0046, 0.0128, 0.0284, 0.0074], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:10,648][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ computer] are: tensor([0.0757, 0.0117, 0.0565, 0.0295, 0.0179, 0.1347, 0.0598, 0.0695, 0.1449,
        0.0619, 0.0739, 0.1066, 0.1575], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:10,649][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ computer] are: tensor([0.0031, 0.0178, 0.0694, 0.0594, 0.0522, 0.1848, 0.0421, 0.0190, 0.1040,
        0.1015, 0.2611, 0.0716, 0.0139], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:10,650][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ computer] are: tensor([0.0329, 0.0443, 0.0217, 0.0291, 0.1131, 0.0588, 0.1193, 0.2048, 0.0773,
        0.1076, 0.0884, 0.0492, 0.0535], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:10,654][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ computer] are: tensor([0.1019, 0.0015, 0.0097, 0.0135, 0.0157, 0.1286, 0.0408, 0.0773, 0.2878,
        0.0275, 0.0713, 0.1155, 0.1088], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:10,654][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([9.5174e-01, 6.6631e-03, 9.1884e-04, 1.4063e-02, 4.1808e-03, 9.1787e-04,
        2.2176e-03, 2.8838e-03, 5.3781e-04, 2.0801e-03, 2.8003e-03, 6.9806e-03,
        3.6023e-03, 4.1754e-04], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:10,655][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.4838, 0.0868, 0.0125, 0.0071, 0.0124, 0.0015, 0.0518, 0.0317, 0.0135,
        0.0856, 0.0561, 0.0164, 0.1397, 0.0012], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:10,657][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0506, 0.0610, 0.0647, 0.0813, 0.0680, 0.0562, 0.0970, 0.0729, 0.0683,
        0.0698, 0.0698, 0.1082, 0.0706, 0.0616], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:10,660][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.8329, 0.0016, 0.0021, 0.0051, 0.0081, 0.0193, 0.0177, 0.0048, 0.0262,
        0.0065, 0.0093, 0.0213, 0.0094, 0.0357], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:10,661][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([9.9971e-01, 6.9250e-05, 1.0845e-05, 9.0556e-06, 1.5087e-05, 8.8639e-06,
        2.9568e-05, 4.7710e-06, 3.3079e-05, 3.0815e-05, 4.4749e-06, 5.4203e-05,
        3.3056e-06, 1.8378e-05], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:10,662][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0807, 0.0494, 0.0675, 0.0693, 0.0885, 0.0687, 0.0713, 0.0834, 0.0590,
        0.0646, 0.0817, 0.0711, 0.0814, 0.0633], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:10,664][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.1545, 0.0090, 0.0547, 0.0407, 0.0184, 0.1728, 0.0557, 0.0386, 0.1220,
        0.0846, 0.0427, 0.0464, 0.0341, 0.1257], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:10,666][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.8203, 0.0051, 0.0192, 0.0066, 0.0098, 0.0283, 0.0174, 0.0075, 0.0172,
        0.0052, 0.0111, 0.0211, 0.0114, 0.0197], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:10,667][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.1538, 0.0059, 0.0264, 0.0203, 0.0120, 0.0672, 0.0410, 0.0480, 0.1158,
        0.0496, 0.0501, 0.0823, 0.1562, 0.1713], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:10,668][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0155, 0.0707, 0.0665, 0.1282, 0.0748, 0.1064, 0.0936, 0.0248, 0.0948,
        0.1157, 0.0663, 0.0569, 0.0345, 0.0514], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:10,671][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.2277, 0.0829, 0.0203, 0.0428, 0.1795, 0.0363, 0.0662, 0.0851, 0.0348,
        0.0687, 0.0448, 0.0365, 0.0462, 0.0281], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:10,673][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.2912, 0.0012, 0.0043, 0.0145, 0.0121, 0.0484, 0.0169, 0.0499, 0.1568,
        0.0193, 0.0290, 0.0407, 0.0833, 0.2323], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:10,676][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:20:10,680][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 5197],
        [ 8115],
        [10613],
        [28603],
        [ 9588],
        [ 5823],
        [ 4556],
        [ 1117],
        [ 7723],
        [ 2951],
        [ 3785],
        [ 8020],
        [  828],
        [ 3376]], device='cuda:0')
[2024-07-24 10:20:10,681][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 5308],
        [18001],
        [23290],
        [42950],
        [18431],
        [15637],
        [13699],
        [ 3011],
        [15370],
        [ 8005],
        [ 8644],
        [16062],
        [ 2209],
        [ 9680]], device='cuda:0')
[2024-07-24 10:20:10,682][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[39525],
        [42294],
        [41446],
        [40628],
        [41870],
        [41261],
        [41028],
        [41749],
        [41023],
        [41238],
        [41466],
        [41328],
        [41398],
        [41164]], device='cuda:0')
[2024-07-24 10:20:10,685][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[ 8783],
        [12690],
        [12258],
        [10270],
        [12200],
        [12496],
        [13690],
        [13079],
        [13345],
        [12885],
        [13869],
        [15157],
        [16343],
        [15828]], device='cuda:0')
[2024-07-24 10:20:10,687][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[18673],
        [15416],
        [17352],
        [17948],
        [17447],
        [16930],
        [17038],
        [15639],
        [16112],
        [14956],
        [15816],
        [16043],
        [15914],
        [15782]], device='cuda:0')
[2024-07-24 10:20:10,688][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[5979],
        [4055],
        [4571],
        [4641],
        [4885],
        [5094],
        [5173],
        [5499],
        [5417],
        [5413],
        [5400],
        [5487],
        [5497],
        [5506]], device='cuda:0')
[2024-07-24 10:20:10,690][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[ 9234],
        [14086],
        [13673],
        [15982],
        [16781],
        [20807],
        [18696],
        [17961],
        [17605],
        [18558],
        [19498],
        [18880],
        [18429],
        [20909]], device='cuda:0')
[2024-07-24 10:20:10,693][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[ 1481],
        [10031],
        [10256],
        [13091],
        [15620],
        [15860],
        [15810],
        [14888],
        [15267],
        [14973],
        [15346],
        [15613],
        [15178],
        [15409]], device='cuda:0')
[2024-07-24 10:20:10,695][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[6129],
        [2356],
        [2497],
        [1699],
        [1926],
        [2208],
        [2322],
        [2535],
        [2849],
        [2526],
        [2891],
        [2889],
        [2982],
        [3116]], device='cuda:0')
[2024-07-24 10:20:10,696][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[ 8814],
        [ 5884],
        [ 7990],
        [ 8845],
        [10128],
        [ 9790],
        [11814],
        [12168],
        [12385],
        [15627],
        [13690],
        [14111],
        [14075],
        [14822]], device='cuda:0')
[2024-07-24 10:20:10,698][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[17578],
        [19045],
        [17827],
        [18827],
        [19092],
        [16990],
        [15684],
        [15172],
        [15391],
        [13725],
        [15403],
        [16845],
        [16411],
        [16739]], device='cuda:0')
[2024-07-24 10:20:10,701][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[47292],
        [45513],
        [40771],
        [42453],
        [40822],
        [39690],
        [39087],
        [38757],
        [38540],
        [38375],
        [38003],
        [37738],
        [37350],
        [37164]], device='cuda:0')
[2024-07-24 10:20:10,702][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[31769],
        [41164],
        [42913],
        [40782],
        [40968],
        [39186],
        [37327],
        [35057],
        [34601],
        [34239],
        [33485],
        [32336],
        [31430],
        [31185]], device='cuda:0')
[2024-07-24 10:20:10,704][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[40658],
        [18064],
        [23452],
        [19807],
        [18702],
        [18885],
        [19342],
        [19593],
        [20903],
        [20108],
        [20897],
        [20913],
        [20732],
        [20457]], device='cuda:0')
[2024-07-24 10:20:10,707][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[3559],
        [2413],
        [3256],
        [3669],
        [5353],
        [2739],
        [2892],
        [3179],
        [3413],
        [3280],
        [4419],
        [4574],
        [3675],
        [4254]], device='cuda:0')
[2024-07-24 10:20:10,708][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[13849],
        [12320],
        [13673],
        [ 3302],
        [12838],
        [12586],
        [12174],
        [ 2695],
        [12132],
        [ 4982],
        [ 8289],
        [12094],
        [ 6606],
        [ 9324]], device='cuda:0')
[2024-07-24 10:20:10,710][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[45232],
        [44088],
        [46095],
        [30409],
        [29250],
        [46658],
        [45817],
        [28906],
        [45688],
        [23604],
        [29026],
        [21789],
        [25064],
        [37879]], device='cuda:0')
[2024-07-24 10:20:10,712][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[15403],
        [12020],
        [10761],
        [ 9828],
        [11111],
        [11552],
        [12433],
        [12789],
        [11820],
        [12305],
        [13040],
        [13432],
        [12501],
        [13016]], device='cuda:0')
[2024-07-24 10:20:10,714][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[ 1851],
        [ 4450],
        [ 3798],
        [11802],
        [ 7185],
        [ 3460],
        [ 4374],
        [ 5011],
        [ 3921],
        [ 5688],
        [ 5439],
        [ 3551],
        [ 5046],
        [ 2983]], device='cuda:0')
[2024-07-24 10:20:10,716][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[34828],
        [31181],
        [32672],
        [33317],
        [33117],
        [34694],
        [34356],
        [34231],
        [34616],
        [34229],
        [34266],
        [34679],
        [34746],
        [34808]], device='cuda:0')
[2024-07-24 10:20:10,718][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[6901],
        [7866],
        [9069],
        [8043],
        [8227],
        [8405],
        [8608],
        [8294],
        [8513],
        [7938],
        [7696],
        [7648],
        [7717],
        [7676]], device='cuda:0')
[2024-07-24 10:20:10,721][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[36510],
        [ 6768],
        [11398],
        [ 9266],
        [10534],
        [ 7806],
        [10096],
        [ 9941],
        [ 9052],
        [ 7551],
        [ 8146],
        [ 8520],
        [ 8714],
        [ 8288]], device='cuda:0')
[2024-07-24 10:20:10,722][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[18686],
        [17348],
        [15933],
        [15616],
        [16484],
        [18410],
        [20607],
        [21694],
        [20960],
        [18600],
        [21618],
        [19840],
        [18311],
        [17751]], device='cuda:0')
[2024-07-24 10:20:10,723][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[34880],
        [27386],
        [22749],
        [22195],
        [20790],
        [25389],
        [23775],
        [23412],
        [23288],
        [21847],
        [21081],
        [21609],
        [22551],
        [22862]], device='cuda:0')
[2024-07-24 10:20:10,726][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[11872],
        [ 3323],
        [ 4935],
        [ 5356],
        [ 4488],
        [ 5593],
        [ 4796],
        [ 5939],
        [ 6724],
        [ 5580],
        [ 5430],
        [ 4642],
        [ 2577],
        [ 3752]], device='cuda:0')
[2024-07-24 10:20:10,728][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[4299],
        [ 274],
        [ 982],
        [ 572],
        [4832],
        [4164],
        [7033],
        [5966],
        [5771],
        [5902],
        [6540],
        [7192],
        [7046],
        [6517]], device='cuda:0')
[2024-07-24 10:20:10,729][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[18074],
        [21389],
        [27187],
        [17501],
        [10210],
        [11054],
        [ 7875],
        [ 8030],
        [12124],
        [10333],
        [10705],
        [10300],
        [10097],
        [12701]], device='cuda:0')
[2024-07-24 10:20:10,732][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[24282],
        [37690],
        [32394],
        [36675],
        [34045],
        [31766],
        [31565],
        [35225],
        [29477],
        [34708],
        [33731],
        [35420],
        [36714],
        [34143]], device='cuda:0')
[2024-07-24 10:20:10,735][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[38865],
        [40972],
        [40665],
        [41459],
        [39795],
        [42703],
        [41604],
        [42830],
        [43079],
        [42904],
        [39998],
        [40685],
        [42457],
        [41530]], device='cuda:0')
[2024-07-24 10:20:10,736][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[4937],
        [4937],
        [4937],
        [4937],
        [4937],
        [4937],
        [4937],
        [4937],
        [4937],
        [4937],
        [4937],
        [4937],
        [4937],
        [4937]], device='cuda:0')
[2024-07-24 10:20:10,810][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:20:10,811][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:10,812][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:10,813][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:10,813][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:10,814][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:10,815][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:10,815][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:10,816][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:10,817][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:10,817][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:10,818][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:10,819][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:10,819][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Benjamin] are: tensor([0.3206, 0.6794], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:10,820][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Benjamin] are: tensor([0.3005, 0.6995], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:10,821][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Benjamin] are: tensor([0.0017, 0.9983], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:10,821][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Benjamin] are: tensor([0.2095, 0.7905], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:10,823][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Benjamin] are: tensor([0.0219, 0.9781], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:10,823][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Benjamin] are: tensor([0.5360, 0.4640], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:10,824][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Benjamin] are: tensor([0.3059, 0.6941], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:10,825][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Benjamin] are: tensor([0.0213, 0.9787], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:10,827][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Benjamin] are: tensor([0.8508, 0.1492], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:10,828][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Benjamin] are: tensor([0.8818, 0.1182], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:10,829][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Benjamin] are: tensor([0.0053, 0.9947], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:10,829][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Benjamin] are: tensor([0.2934, 0.7066], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:10,832][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.3695, 0.2925, 0.3380], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:10,834][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.2732, 0.5882, 0.1386], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:10,835][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ and] are: tensor([2.4342e-04, 2.5373e-01, 7.4603e-01], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:10,835][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.1747, 0.3277, 0.4975], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:10,836][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0838, 0.2350, 0.6811], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:10,839][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.6724, 0.1410, 0.1866], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:10,841][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.2076, 0.2873, 0.5050], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:10,842][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0119, 0.4364, 0.5517], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:10,842][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.8145, 0.0162, 0.1694], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:10,843][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.9473, 0.0209, 0.0317], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:10,846][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0085, 0.6732, 0.3183], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:10,848][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.3077, 0.5117, 0.1806], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:10,848][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Alexander] are: tensor([0.1760, 0.2644, 0.3236, 0.2359], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:10,849][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Alexander] are: tensor([0.5351, 0.2954, 0.0369, 0.1326], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:10,850][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Alexander] are: tensor([1.0489e-04, 8.8658e-02, 7.1523e-01, 1.9600e-01], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:10,852][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Alexander] are: tensor([0.0919, 0.2521, 0.3753, 0.2807], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:10,854][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Alexander] are: tensor([0.0225, 0.2065, 0.4864, 0.2846], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:10,855][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Alexander] are: tensor([0.6514, 0.1423, 0.1596, 0.0468], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:10,856][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Alexander] are: tensor([0.1270, 0.2280, 0.3798, 0.2651], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:10,856][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Alexander] are: tensor([0.0073, 0.2950, 0.3716, 0.3262], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:10,859][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Alexander] are: tensor([0.6011, 0.0413, 0.2612, 0.0964], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:10,861][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Alexander] are: tensor([0.2675, 0.1564, 0.5368, 0.0393], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:10,862][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Alexander] are: tensor([0.0076, 0.6268, 0.2914, 0.0743], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:10,862][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Alexander] are: tensor([0.1022, 0.4115, 0.3721, 0.1141], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:10,863][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ went] are: tensor([0.1644, 0.1418, 0.2482, 0.1719, 0.2737], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:10,866][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ went] are: tensor([0.3840, 0.3266, 0.0827, 0.1669, 0.0398], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:10,868][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ went] are: tensor([7.6348e-05, 4.8265e-02, 8.1399e-01, 7.1524e-02, 6.6142e-02],
       device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:10,868][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ went] are: tensor([0.0769, 0.1689, 0.2644, 0.2006, 0.2892], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:10,869][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ went] are: tensor([0.0425, 0.0401, 0.3090, 0.1631, 0.4453], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:10,870][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ went] are: tensor([0.8281, 0.0300, 0.0522, 0.0215, 0.0682], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:10,872][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ went] are: tensor([0.0968, 0.1877, 0.3332, 0.1679, 0.2144], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:10,874][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ went] are: tensor([0.0046, 0.2192, 0.2817, 0.2443, 0.2502], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:10,875][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.4226, 0.0203, 0.2151, 0.1740, 0.1681], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:10,876][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ went] are: tensor([0.6680, 0.0193, 0.2688, 0.0070, 0.0369], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:10,877][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ went] are: tensor([0.0117, 0.4472, 0.3755, 0.0864, 0.0791], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:10,879][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ went] are: tensor([0.1920, 0.2478, 0.5170, 0.0170, 0.0262], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:10,881][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.1275, 0.1030, 0.1282, 0.1500, 0.2307, 0.2605], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:10,882][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.6017, 0.1840, 0.0379, 0.1218, 0.0345, 0.0202], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:10,883][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ to] are: tensor([6.6168e-05, 8.4342e-02, 2.5524e-01, 9.1529e-02, 4.4626e-02, 5.2419e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:10,883][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0971, 0.1204, 0.1781, 0.1428, 0.1861, 0.2755], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:10,886][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0852, 0.0401, 0.1058, 0.0983, 0.1619, 0.5089], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:10,888][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.9099, 0.0083, 0.0106, 0.0047, 0.0280, 0.0385], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:10,889][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0891, 0.1605, 0.2623, 0.1452, 0.1552, 0.1877], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:10,889][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0047, 0.1704, 0.2178, 0.1902, 0.1940, 0.2228], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:10,890][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.6458, 0.0013, 0.0062, 0.0173, 0.0160, 0.3134], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:10,893][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.6642, 0.0550, 0.1069, 0.0140, 0.1467, 0.0132], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:10,895][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0058, 0.4943, 0.2311, 0.0943, 0.0477, 0.1268], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:10,896][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.1018, 0.5520, 0.1883, 0.0091, 0.1095, 0.0393], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:10,896][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0697, 0.0815, 0.1084, 0.1219, 0.2031, 0.2800, 0.1354],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:10,897][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.3661, 0.2789, 0.0305, 0.1920, 0.0381, 0.0301, 0.0643],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:10,899][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ the] are: tensor([9.0376e-05, 5.4721e-02, 1.7708e-01, 8.6862e-02, 5.2812e-02, 3.6877e-01,
        2.5967e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:10,901][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0643, 0.0973, 0.1457, 0.1162, 0.1577, 0.2283, 0.1906],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:10,902][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0608, 0.0208, 0.0832, 0.0765, 0.1294, 0.3993, 0.2300],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:10,903][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.7279, 0.0089, 0.0214, 0.0059, 0.0505, 0.0914, 0.0941],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:10,904][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0753, 0.1222, 0.2319, 0.1318, 0.1397, 0.1717, 0.1273],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:10,906][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0036, 0.1402, 0.1820, 0.1563, 0.1616, 0.1877, 0.1687],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:10,908][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.3662, 0.0012, 0.0117, 0.0164, 0.0279, 0.4765, 0.1002],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:10,909][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.6316, 0.0316, 0.1855, 0.0047, 0.0916, 0.0242, 0.0308],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:10,910][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0046, 0.4003, 0.2544, 0.0714, 0.0487, 0.1023, 0.1184],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:10,911][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0118, 0.2748, 0.4541, 0.0078, 0.0377, 0.1606, 0.0532],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:10,914][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ station] are: tensor([0.1336, 0.0563, 0.0934, 0.0767, 0.1142, 0.1927, 0.1135, 0.2196],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:10,915][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ station] are: tensor([0.8504, 0.0980, 0.0082, 0.0208, 0.0050, 0.0052, 0.0091, 0.0032],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:10,916][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ station] are: tensor([0.0003, 0.0938, 0.2011, 0.0828, 0.0559, 0.2612, 0.2029, 0.1019],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:10,917][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ station] are: tensor([0.0528, 0.0842, 0.1295, 0.0989, 0.1388, 0.1956, 0.1631, 0.1371],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:10,918][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ station] are: tensor([0.0130, 0.0097, 0.0571, 0.0383, 0.0859, 0.3083, 0.2498, 0.2379],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:10,921][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ station] are: tensor([0.8427, 0.0144, 0.0184, 0.0044, 0.0230, 0.0450, 0.0403, 0.0118],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:10,922][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ station] are: tensor([0.0769, 0.1004, 0.1768, 0.1038, 0.1141, 0.1880, 0.1253, 0.1146],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:10,923][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ station] are: tensor([0.0032, 0.1195, 0.1530, 0.1335, 0.1379, 0.1584, 0.1439, 0.1507],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:10,923][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ station] are: tensor([0.1761, 0.0014, 0.0175, 0.0090, 0.0208, 0.5050, 0.1330, 0.1372],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:10,924][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ station] are: tensor([0.3816, 0.0230, 0.3566, 0.0062, 0.0698, 0.0634, 0.0773, 0.0222],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:10,928][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ station] are: tensor([0.0039, 0.3876, 0.2336, 0.0616, 0.0347, 0.0954, 0.1163, 0.0670],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:10,929][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ station] are: tensor([0.2018, 0.1837, 0.2021, 0.0529, 0.1234, 0.1007, 0.0847, 0.0507],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:10,929][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0559, 0.0502, 0.0650, 0.0850, 0.1288, 0.1645, 0.1072, 0.2376, 0.1058],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:10,930][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.3762, 0.1460, 0.0713, 0.1361, 0.0354, 0.0372, 0.1367, 0.0323, 0.0288],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:10,931][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [,] are: tensor([2.0334e-05, 4.1781e-02, 1.3680e-01, 6.5197e-02, 2.6935e-02, 2.8629e-01,
        2.2856e-01, 9.9805e-02, 1.1462e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:10,935][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0613, 0.0707, 0.1051, 0.0852, 0.1071, 0.1626, 0.1413, 0.1153, 0.1513],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:10,935][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0349, 0.0105, 0.0469, 0.0477, 0.0783, 0.2703, 0.1721, 0.1494, 0.1898],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:10,936][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.7755, 0.0058, 0.0134, 0.0054, 0.0282, 0.0648, 0.0443, 0.0172, 0.0454],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:10,937][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0716, 0.0992, 0.1606, 0.0904, 0.1118, 0.1235, 0.1157, 0.0950, 0.1322],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:10,938][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0035, 0.1016, 0.1287, 0.1131, 0.1159, 0.1322, 0.1212, 0.1263, 0.1575],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:10,942][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.3980, 0.0009, 0.0069, 0.0169, 0.0159, 0.2518, 0.0778, 0.0742, 0.1576],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:10,943][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.6404, 0.0436, 0.0525, 0.0151, 0.0975, 0.0185, 0.0446, 0.0775, 0.0104],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:10,944][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0014, 0.4137, 0.1904, 0.0859, 0.0296, 0.0550, 0.0776, 0.0654, 0.0810],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:10,944][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0838, 0.1885, 0.1553, 0.0209, 0.1235, 0.1045, 0.1157, 0.1568, 0.0511],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:10,948][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Benjamin] are: tensor([0.0341, 0.0528, 0.0842, 0.0680, 0.1228, 0.1614, 0.0806, 0.2080, 0.0983,
        0.0898], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:10,949][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Benjamin] are: tensor([0.4554, 0.2150, 0.0222, 0.0956, 0.0372, 0.0183, 0.0229, 0.0169, 0.0075,
        0.1090], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:10,950][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Benjamin] are: tensor([2.5407e-06, 1.3528e-02, 1.0908e-01, 2.1344e-02, 1.2091e-02, 2.2850e-01,
        2.3140e-01, 3.5076e-02, 1.6656e-01, 1.8241e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:10,950][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Benjamin] are: tensor([0.0380, 0.0655, 0.0984, 0.0765, 0.1040, 0.1458, 0.1238, 0.1121, 0.1376,
        0.0981], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:10,952][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Benjamin] are: tensor([0.0073, 0.0161, 0.0562, 0.0516, 0.0673, 0.2171, 0.1460, 0.1269, 0.1955,
        0.1161], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:10,955][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Benjamin] are: tensor([0.6798, 0.0209, 0.0271, 0.0088, 0.0444, 0.0874, 0.0600, 0.0172, 0.0457,
        0.0087], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:10,956][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Benjamin] are: tensor([0.0390, 0.0749, 0.1406, 0.1040, 0.0928, 0.1408, 0.1083, 0.1044, 0.1163,
        0.0787], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:10,957][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Benjamin] are: tensor([0.0027, 0.0885, 0.1125, 0.0988, 0.1010, 0.1160, 0.1054, 0.1100, 0.1396,
        0.1253], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:10,958][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Benjamin] are: tensor([0.1136, 0.0022, 0.0135, 0.0236, 0.0155, 0.2812, 0.0757, 0.1749, 0.2615,
        0.0384], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:10,962][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Benjamin] are: tensor([0.0335, 0.0220, 0.4055, 0.0084, 0.1193, 0.0935, 0.1843, 0.0566, 0.0736,
        0.0034], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:10,962][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Benjamin] are: tensor([0.0009, 0.3578, 0.2096, 0.0459, 0.0261, 0.0532, 0.0963, 0.0329, 0.1028,
        0.0744], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:10,963][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Benjamin] are: tensor([0.0258, 0.0717, 0.1108, 0.0510, 0.2888, 0.1531, 0.0376, 0.1451, 0.0780,
        0.0381], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:10,964][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.0521, 0.0423, 0.0691, 0.0570, 0.0901, 0.1400, 0.0844, 0.1673, 0.0933,
        0.0837, 0.1208], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:10,966][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.2799, 0.2942, 0.0261, 0.1434, 0.0336, 0.0163, 0.0407, 0.0235, 0.0058,
        0.1193, 0.0172], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:10,969][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([1.8486e-05, 3.2135e-02, 8.2733e-02, 3.8632e-02, 1.2007e-02, 1.7576e-01,
        1.7866e-01, 7.3481e-02, 1.3864e-01, 2.2732e-01, 4.0610e-02],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:10,970][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.0418, 0.0566, 0.0841, 0.0686, 0.0870, 0.1304, 0.1112, 0.0946, 0.1188,
        0.0882, 0.1187], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:10,970][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.0151, 0.0034, 0.0269, 0.0193, 0.0638, 0.1926, 0.1678, 0.0965, 0.1856,
        0.0642, 0.1649], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:10,971][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.7678, 0.0114, 0.0173, 0.0047, 0.0188, 0.0596, 0.0545, 0.0128, 0.0378,
        0.0056, 0.0096], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:10,975][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0504, 0.0844, 0.1533, 0.0831, 0.0802, 0.1220, 0.0758, 0.0836, 0.1083,
        0.0851, 0.0738], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:10,976][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0025, 0.0784, 0.0986, 0.0873, 0.0895, 0.1018, 0.0934, 0.0978, 0.1216,
        0.1106, 0.1186], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:10,977][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.1455, 0.0006, 0.0064, 0.0074, 0.0070, 0.3539, 0.0777, 0.0970, 0.2309,
        0.0248, 0.0487], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:10,977][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.3767, 0.0289, 0.2988, 0.0106, 0.0761, 0.0445, 0.0567, 0.0232, 0.0420,
        0.0058, 0.0367], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:10,980][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0021, 0.2322, 0.1622, 0.0381, 0.0296, 0.0783, 0.1048, 0.0796, 0.1225,
        0.1246, 0.0260], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:10,982][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0550, 0.1291, 0.2040, 0.0224, 0.0531, 0.0949, 0.0888, 0.1751, 0.0689,
        0.0491, 0.0595], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:10,983][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0264, 0.0367, 0.0519, 0.0598, 0.0933, 0.1212, 0.0670, 0.1721, 0.0830,
        0.0869, 0.1396, 0.0620], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:10,984][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.3646, 0.1195, 0.0314, 0.1588, 0.0246, 0.0286, 0.0717, 0.0216, 0.0158,
        0.0751, 0.0594, 0.0288], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:10,985][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ a] are: tensor([3.4869e-05, 1.7117e-02, 5.0860e-02, 3.8296e-02, 2.2472e-02, 1.6060e-01,
        1.5911e-01, 3.6580e-02, 1.5272e-01, 1.1106e-01, 1.4305e-01, 1.0809e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:10,989][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0321, 0.0492, 0.0741, 0.0590, 0.0798, 0.1173, 0.0992, 0.0881, 0.1103,
        0.0820, 0.1128, 0.0960], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:10,992][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0269, 0.0056, 0.0267, 0.0312, 0.0510, 0.1656, 0.1033, 0.0843, 0.1231,
        0.0764, 0.1398, 0.1661], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:10,993][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.6235, 0.0063, 0.0149, 0.0047, 0.0320, 0.0642, 0.0586, 0.0189, 0.0588,
        0.0058, 0.0300, 0.0823], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:10,994][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0518, 0.0735, 0.1316, 0.0833, 0.0779, 0.1006, 0.0711, 0.0784, 0.1185,
        0.0670, 0.0665, 0.0798], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:10,994][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0021, 0.0694, 0.0889, 0.0780, 0.0806, 0.0920, 0.0844, 0.0883, 0.1107,
        0.0994, 0.1085, 0.0977], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:10,995][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.1913, 0.0006, 0.0050, 0.0101, 0.0184, 0.2362, 0.0542, 0.0929, 0.1914,
        0.0248, 0.0956, 0.0795], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:10,999][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.2333, 0.0786, 0.1674, 0.0128, 0.1153, 0.0481, 0.0697, 0.0603, 0.0420,
        0.0130, 0.1390, 0.0205], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:11,000][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0048, 0.2186, 0.1480, 0.0419, 0.0280, 0.0579, 0.1036, 0.0792, 0.0964,
        0.1099, 0.0667, 0.0449], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:11,001][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0015, 0.1767, 0.4515, 0.0054, 0.0204, 0.1008, 0.0636, 0.0308, 0.0950,
        0.0392, 0.0066, 0.0084], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:11,001][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ computer] are: tensor([0.0511, 0.0449, 0.0538, 0.0499, 0.0728, 0.1088, 0.0627, 0.1340, 0.0692,
        0.0700, 0.0975, 0.0619, 0.1233], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:11,004][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ computer] are: tensor([0.3022, 0.2194, 0.0702, 0.0501, 0.0418, 0.0268, 0.0363, 0.0243, 0.0101,
        0.0527, 0.0683, 0.0253, 0.0725], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:11,006][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ computer] are: tensor([3.0921e-06, 1.3296e-02, 8.6422e-02, 2.0116e-02, 2.0327e-02, 1.4041e-01,
        8.6916e-02, 3.1614e-02, 1.1434e-01, 9.4246e-02, 2.3759e-01, 9.6227e-02,
        5.8493e-02], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:11,007][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ computer] are: tensor([0.0265, 0.0496, 0.0752, 0.0567, 0.0750, 0.1069, 0.0904, 0.0803, 0.1006,
        0.0715, 0.1020, 0.0871, 0.0780], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:11,008][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ computer] are: tensor([0.0118, 0.0045, 0.0260, 0.0223, 0.0461, 0.1398, 0.0961, 0.0926, 0.0943,
        0.0457, 0.1110, 0.1468, 0.1629], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:11,009][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ computer] are: tensor([0.7654, 0.0124, 0.0115, 0.0027, 0.0117, 0.0327, 0.0364, 0.0064, 0.0196,
        0.0042, 0.0086, 0.0778, 0.0105], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:11,012][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ computer] are: tensor([0.0346, 0.0557, 0.1131, 0.0603, 0.0742, 0.1029, 0.0832, 0.0908, 0.0895,
        0.0650, 0.0815, 0.0870, 0.0622], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:11,013][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ computer] are: tensor([0.0018, 0.0633, 0.0809, 0.0708, 0.0731, 0.0834, 0.0766, 0.0803, 0.1010,
        0.0912, 0.0995, 0.0893, 0.0887], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:11,014][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ computer] are: tensor([0.1414, 0.0005, 0.0052, 0.0094, 0.0109, 0.1898, 0.0667, 0.0938, 0.2116,
        0.0195, 0.0945, 0.0845, 0.0724], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:11,015][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ computer] are: tensor([0.3069, 0.0554, 0.2102, 0.0116, 0.0951, 0.0465, 0.1021, 0.0337, 0.0438,
        0.0072, 0.0519, 0.0257, 0.0100], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:11,017][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ computer] are: tensor([0.0005, 0.1846, 0.1208, 0.0347, 0.0280, 0.0653, 0.0676, 0.0512, 0.0756,
        0.1680, 0.1085, 0.0625, 0.0328], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:11,020][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ computer] are: tensor([0.0180, 0.2058, 0.0879, 0.0506, 0.1571, 0.0590, 0.0507, 0.0751, 0.0708,
        0.1019, 0.0613, 0.0269, 0.0350], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:11,021][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0236, 0.0328, 0.0379, 0.0536, 0.0717, 0.0857, 0.0566, 0.1338, 0.0625,
        0.0703, 0.1148, 0.0557, 0.1477, 0.0531], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:11,022][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.5954, 0.0987, 0.0222, 0.0674, 0.0182, 0.0115, 0.0386, 0.0147, 0.0102,
        0.0485, 0.0191, 0.0127, 0.0307, 0.0122], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:11,022][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ to] are: tensor([2.6736e-05, 2.0261e-02, 5.4825e-02, 2.9935e-02, 1.4200e-02, 1.5912e-01,
        1.2128e-01, 1.8005e-02, 9.3962e-02, 1.4535e-01, 8.9070e-02, 9.9365e-02,
        4.8886e-02, 1.0571e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:11,026][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0330, 0.0422, 0.0638, 0.0507, 0.0656, 0.0977, 0.0843, 0.0725, 0.0909,
        0.0675, 0.0910, 0.0809, 0.0728, 0.0871], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:11,027][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0231, 0.0049, 0.0166, 0.0183, 0.0278, 0.0811, 0.0698, 0.0646, 0.0828,
        0.0457, 0.0778, 0.1147, 0.1337, 0.2389], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:11,028][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.8275, 0.0037, 0.0059, 0.0027, 0.0114, 0.0201, 0.0167, 0.0079, 0.0231,
        0.0030, 0.0075, 0.0283, 0.0063, 0.0360], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:11,029][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0501, 0.0699, 0.1152, 0.0641, 0.0682, 0.0848, 0.0611, 0.0676, 0.0946,
        0.0596, 0.0586, 0.0634, 0.0678, 0.0748], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:11,031][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0019, 0.0585, 0.0749, 0.0656, 0.0672, 0.0767, 0.0706, 0.0735, 0.0919,
        0.0833, 0.0899, 0.0819, 0.0810, 0.0833], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:11,033][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.3692, 0.0004, 0.0019, 0.0065, 0.0046, 0.0827, 0.0286, 0.0268, 0.1092,
        0.0175, 0.0293, 0.0453, 0.0430, 0.2348], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:11,034][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.2099, 0.0723, 0.1220, 0.0140, 0.1516, 0.0176, 0.0756, 0.1368, 0.0207,
        0.0092, 0.0994, 0.0313, 0.0344, 0.0052], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:11,035][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0016, 0.2586, 0.1284, 0.0427, 0.0223, 0.0601, 0.0790, 0.0608, 0.0835,
        0.1086, 0.0546, 0.0401, 0.0364, 0.0235], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:11,037][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0472, 0.3848, 0.1035, 0.0077, 0.0749, 0.0229, 0.0777, 0.0894, 0.0317,
        0.0667, 0.0334, 0.0367, 0.0078, 0.0156], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:11,120][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:20:11,121][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:11,122][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:11,123][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:11,123][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:11,124][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:11,125][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:11,125][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:11,126][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:11,127][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:11,127][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:11,128][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:11,129][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:11,129][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Benjamin] are: tensor([0.6849, 0.3151], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:11,130][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Benjamin] are: tensor([0.4770, 0.5230], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:11,131][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Benjamin] are: tensor([0.0017, 0.9983], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:11,132][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Benjamin] are: tensor([0.8790, 0.1210], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:11,133][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Benjamin] are: tensor([0.7780, 0.2220], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:11,134][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Benjamin] are: tensor([0.8944, 0.1056], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:11,134][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Benjamin] are: tensor([0.6892, 0.3108], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:11,137][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Benjamin] are: tensor([0.0359, 0.9641], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:11,138][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Benjamin] are: tensor([0.8508, 0.1492], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:11,138][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Benjamin] are: tensor([0.6364, 0.3636], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:11,139][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Benjamin] are: tensor([0.0019, 0.9981], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:11,142][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Benjamin] are: tensor([0.2571, 0.7429], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:11,144][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.8094, 0.0149, 0.1756], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:11,144][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.6203, 0.3299, 0.0498], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:11,145][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([2.4342e-04, 2.5373e-01, 7.4603e-01], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:11,146][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.8345, 0.0118, 0.1537], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:11,148][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.7087, 0.0138, 0.2775], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:11,150][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.9707, 0.0157, 0.0136], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:11,151][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.6606, 0.2013, 0.1382], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:11,152][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0455, 0.5356, 0.4189], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:11,153][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.8145, 0.0162, 0.1694], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:11,155][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.3213, 0.0406, 0.6381], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:11,157][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([5.6985e-04, 2.9804e-01, 7.0139e-01], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:11,158][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.1849, 0.6971, 0.1180], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:11,159][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Alexander] are: tensor([0.5577, 0.0262, 0.2228, 0.1933], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:11,159][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Alexander] are: tensor([0.5420, 0.2190, 0.0419, 0.1971], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:11,161][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Alexander] are: tensor([1.0489e-04, 8.8658e-02, 7.1523e-01, 1.9600e-01], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:11,164][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Alexander] are: tensor([0.6008, 0.0229, 0.1647, 0.2116], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:11,164][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Alexander] are: tensor([0.4178, 0.0317, 0.3931, 0.1574], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:11,165][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Alexander] are: tensor([0.8446, 0.0364, 0.0391, 0.0799], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:11,166][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Alexander] are: tensor([0.5973, 0.1261, 0.1407, 0.1359], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:11,168][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Alexander] are: tensor([0.0248, 0.4275, 0.2476, 0.3001], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:11,170][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Alexander] are: tensor([0.6011, 0.0413, 0.2612, 0.0964], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:11,171][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Alexander] are: tensor([0.5351, 0.0279, 0.3197, 0.1173], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:11,172][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Alexander] are: tensor([2.5792e-04, 1.6102e-01, 7.8920e-01, 4.9520e-02], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:11,173][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Alexander] are: tensor([0.0876, 0.4990, 0.1715, 0.2420], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:11,175][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([0.5953, 0.0056, 0.0718, 0.1936, 0.1337], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:11,177][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([0.3680, 0.2562, 0.0643, 0.2649, 0.0467], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:11,178][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([7.6348e-05, 4.8265e-02, 8.1399e-01, 7.1524e-02, 6.6142e-02],
       device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:11,179][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([0.4672, 0.0083, 0.1420, 0.1454, 0.2371], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:11,179][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([0.2916, 0.0045, 0.1788, 0.0602, 0.4649], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:11,182][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([0.9265, 0.0105, 0.0102, 0.0407, 0.0121], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:11,184][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([0.6628, 0.0937, 0.0931, 0.0984, 0.0520], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:11,185][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([0.0265, 0.2249, 0.2388, 0.2804, 0.2294], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:11,185][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([0.4226, 0.0203, 0.2151, 0.1740, 0.1681], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:11,186][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([0.1251, 0.0126, 0.2518, 0.1718, 0.4387], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:11,189][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([0.0012, 0.1035, 0.8010, 0.0683, 0.0260], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:11,191][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([0.0738, 0.3624, 0.2538, 0.1592, 0.1507], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:11,191][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([9.1047e-01, 4.2055e-04, 1.2532e-03, 1.9605e-02, 1.0565e-02, 5.7686e-02],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:11,192][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.7749, 0.0808, 0.0210, 0.0812, 0.0270, 0.0151], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:11,193][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([6.6168e-05, 8.4342e-02, 2.5524e-01, 9.1529e-02, 4.4626e-02, 5.2419e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:11,195][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.4985, 0.0023, 0.0150, 0.0399, 0.0409, 0.4033], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:11,197][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.5374, 0.0007, 0.0087, 0.0094, 0.0429, 0.4008], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:11,198][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.9841, 0.0017, 0.0011, 0.0041, 0.0045, 0.0044], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:11,199][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.7956, 0.0574, 0.0350, 0.0534, 0.0275, 0.0311], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:11,200][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0535, 0.2664, 0.1381, 0.2636, 0.1784, 0.0999], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:11,203][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.6458, 0.0013, 0.0062, 0.0173, 0.0160, 0.3134], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:11,204][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.2212, 0.0042, 0.0277, 0.0788, 0.1352, 0.5330], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:11,205][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0006, 0.2202, 0.4785, 0.1158, 0.0290, 0.1558], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:11,206][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.1409, 0.5601, 0.0589, 0.1306, 0.0720, 0.0374], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:11,206][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.4336, 0.0007, 0.0044, 0.0344, 0.0357, 0.3664, 0.1248],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:11,210][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.6175, 0.1424, 0.0201, 0.1298, 0.0325, 0.0202, 0.0375],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:11,213][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([9.0376e-05, 5.4721e-02, 1.7708e-01, 8.6862e-02, 5.2812e-02, 3.6877e-01,
        2.5967e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:11,214][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.2160, 0.0016, 0.0170, 0.0349, 0.0413, 0.4562, 0.2329],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:11,215][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.1954, 0.0006, 0.0095, 0.0102, 0.0589, 0.5388, 0.1866],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:11,216][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.9785, 0.0019, 0.0018, 0.0046, 0.0049, 0.0057, 0.0026],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:11,217][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.8079, 0.0368, 0.0300, 0.0420, 0.0250, 0.0309, 0.0273],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:11,219][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0747, 0.1866, 0.0997, 0.1918, 0.1961, 0.1060, 0.1453],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:11,221][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.3662, 0.0012, 0.0117, 0.0164, 0.0279, 0.4765, 0.1002],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:11,222][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0623, 0.0020, 0.0264, 0.0374, 0.0765, 0.6105, 0.1849],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:11,223][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0006, 0.1665, 0.5469, 0.0584, 0.0318, 0.1310, 0.0648],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:11,223][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.1309, 0.4344, 0.0782, 0.1377, 0.1265, 0.0355, 0.0569],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:11,225][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ station] are: tensor([1.6304e-01, 2.5729e-04, 3.3816e-03, 1.5079e-02, 2.2452e-02, 4.0796e-01,
        2.8645e-01, 1.0137e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:11,228][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ station] are: tensor([0.8385, 0.0702, 0.0090, 0.0391, 0.0080, 0.0104, 0.0166, 0.0081],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:11,229][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ station] are: tensor([0.0003, 0.0938, 0.2011, 0.0828, 0.0559, 0.2612, 0.2029, 0.1019],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:11,229][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ station] are: tensor([0.3113, 0.0010, 0.0141, 0.0296, 0.0413, 0.3114, 0.1839, 0.1074],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:11,230][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ station] are: tensor([1.0734e-01, 2.0970e-04, 5.8538e-03, 3.9350e-03, 3.5214e-02, 4.3899e-01,
        2.8294e-01, 1.2551e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:11,234][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ station] are: tensor([0.9720, 0.0023, 0.0016, 0.0071, 0.0039, 0.0059, 0.0021, 0.0052],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:11,235][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ station] are: tensor([0.8191, 0.0230, 0.0254, 0.0405, 0.0261, 0.0236, 0.0205, 0.0218],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:11,235][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ station] are: tensor([0.0747, 0.1025, 0.0673, 0.1511, 0.1234, 0.1005, 0.2079, 0.1726],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:11,236][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ station] are: tensor([0.1761, 0.0014, 0.0175, 0.0090, 0.0208, 0.5050, 0.1330, 0.1372],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:11,237][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ station] are: tensor([0.0425, 0.0010, 0.0170, 0.0223, 0.0666, 0.4080, 0.2430, 0.1995],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:11,241][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ station] are: tensor([0.0014, 0.1668, 0.4274, 0.0586, 0.0142, 0.1626, 0.1102, 0.0589],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:11,242][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ station] are: tensor([0.0353, 0.4646, 0.0819, 0.1540, 0.0693, 0.0345, 0.0558, 0.1046],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:11,243][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([3.6152e-01, 3.2649e-04, 1.9634e-03, 1.8264e-02, 1.6784e-02, 1.7423e-01,
        6.9885e-02, 6.3671e-02, 2.9336e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:11,243][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.7479, 0.0686, 0.0220, 0.0654, 0.0185, 0.0124, 0.0357, 0.0114, 0.0181],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:11,245][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([2.0334e-05, 4.1781e-02, 1.3680e-01, 6.5197e-02, 2.6935e-02, 2.8629e-01,
        2.2856e-01, 9.9805e-02, 1.1462e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:11,248][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.2188, 0.0008, 0.0068, 0.0202, 0.0144, 0.1743, 0.1222, 0.0553, 0.3873],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:11,249][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([1.4497e-01, 2.5126e-04, 3.6946e-03, 5.6104e-03, 2.7244e-02, 2.4697e-01,
        1.0896e-01, 6.3959e-02, 3.9835e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:11,249][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.9694, 0.0017, 0.0011, 0.0062, 0.0039, 0.0052, 0.0021, 0.0045, 0.0059],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:11,250][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.6984, 0.0407, 0.0310, 0.0450, 0.0282, 0.0334, 0.0214, 0.0311, 0.0709],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:11,254][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0505, 0.1228, 0.0552, 0.1609, 0.1228, 0.0794, 0.1324, 0.1299, 0.1461],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:11,255][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.3980, 0.0009, 0.0069, 0.0169, 0.0159, 0.2518, 0.0778, 0.0742, 0.1576],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:11,255][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0520, 0.0012, 0.0081, 0.0296, 0.0219, 0.1164, 0.0626, 0.0365, 0.6718],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:11,256][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([2.2642e-04, 1.9181e-01, 3.9546e-01, 1.1521e-01, 1.2879e-02, 7.3854e-02,
        6.0130e-02, 6.8379e-02, 8.2059e-02], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:11,258][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0766, 0.4971, 0.0468, 0.1511, 0.0544, 0.0300, 0.0496, 0.0634, 0.0310],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:11,261][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Benjamin] are: tensor([0.0958, 0.0009, 0.0039, 0.0209, 0.0232, 0.1346, 0.0832, 0.1738, 0.4207,
        0.0431], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:11,262][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Benjamin] are: tensor([0.4674, 0.1349, 0.0224, 0.1363, 0.0432, 0.0226, 0.0308, 0.0217, 0.0226,
        0.0982], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:11,263][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Benjamin] are: tensor([2.5407e-06, 1.3528e-02, 1.0908e-01, 2.1344e-02, 1.2091e-02, 2.2850e-01,
        2.3140e-01, 3.5076e-02, 1.6656e-01, 1.8241e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:11,263][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Benjamin] are: tensor([0.0929, 0.0016, 0.0104, 0.0297, 0.0205, 0.1648, 0.1412, 0.1167, 0.3588,
        0.0633], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:11,267][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Benjamin] are: tensor([0.0828, 0.0011, 0.0138, 0.0123, 0.0240, 0.2607, 0.1314, 0.0709, 0.3478,
        0.0551], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:11,268][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Benjamin] are: tensor([0.8066, 0.0080, 0.0098, 0.0312, 0.0224, 0.0373, 0.0137, 0.0231, 0.0360,
        0.0120], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:11,269][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Benjamin] are: tensor([0.5790, 0.0388, 0.0430, 0.0504, 0.0352, 0.0491, 0.0367, 0.0431, 0.0953,
        0.0294], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:11,270][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Benjamin] are: tensor([0.0204, 0.1321, 0.0540, 0.1262, 0.0620, 0.0582, 0.1097, 0.1395, 0.1123,
        0.1857], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:11,272][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Benjamin] are: tensor([0.1136, 0.0022, 0.0135, 0.0236, 0.0155, 0.2812, 0.0757, 0.1749, 0.2615,
        0.0384], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:11,274][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Benjamin] are: tensor([0.0300, 0.0020, 0.0121, 0.0224, 0.0400, 0.1151, 0.0534, 0.1053, 0.5382,
        0.0815], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:11,275][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Benjamin] are: tensor([3.8137e-05, 3.4112e-02, 3.4710e-01, 2.2099e-02, 1.1004e-02, 8.1853e-02,
        1.0672e-01, 3.4789e-02, 2.9536e-01, 6.6921e-02], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:11,276][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Benjamin] are: tensor([0.1084, 0.2272, 0.0787, 0.1271, 0.0913, 0.0648, 0.0961, 0.0636, 0.0683,
        0.0744], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:11,277][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([1.8410e-01, 1.4871e-04, 1.3507e-03, 7.5210e-03, 6.2512e-03, 1.5569e-01,
        6.2271e-02, 8.2854e-02, 4.2097e-01, 2.2896e-02, 5.5940e-02],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:11,281][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.4177, 0.1918, 0.0195, 0.1403, 0.0371, 0.0167, 0.0346, 0.0223, 0.0146,
        0.0846, 0.0207], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:11,281][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([1.8486e-05, 3.2135e-02, 8.2733e-02, 3.8632e-02, 1.2007e-02, 1.7576e-01,
        1.7866e-01, 7.3481e-02, 1.3864e-01, 2.2732e-01, 4.0610e-02],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:11,282][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.1308, 0.0008, 0.0080, 0.0181, 0.0127, 0.1927, 0.1202, 0.0697, 0.3313,
        0.0510, 0.0648], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:11,283][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([1.4076e-01, 1.6761e-04, 3.8769e-03, 2.6373e-03, 2.0675e-02, 1.7192e-01,
        1.4422e-01, 5.4713e-02, 3.3605e-01, 2.4922e-02, 1.0005e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:11,285][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.9171, 0.0069, 0.0044, 0.0157, 0.0054, 0.0132, 0.0048, 0.0106, 0.0130,
        0.0056, 0.0033], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:11,288][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.6000, 0.0426, 0.0329, 0.0426, 0.0251, 0.0390, 0.0334, 0.0392, 0.0683,
        0.0425, 0.0343], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:11,289][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0702, 0.0841, 0.0317, 0.1093, 0.0671, 0.0543, 0.1064, 0.1368, 0.0837,
        0.1654, 0.0910], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:11,290][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.1455, 0.0006, 0.0064, 0.0074, 0.0070, 0.3539, 0.0777, 0.0970, 0.2309,
        0.0248, 0.0487], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:11,290][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.0185, 0.0006, 0.0040, 0.0123, 0.0153, 0.1341, 0.0707, 0.0524, 0.5190,
        0.1017, 0.0713], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:11,292][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([2.4630e-04, 4.0455e-02, 2.8181e-01, 2.5854e-02, 1.0215e-02, 7.1836e-02,
        7.9666e-02, 1.0076e-01, 2.5990e-01, 1.2072e-01, 8.5409e-03],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:11,295][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.1488, 0.3951, 0.0406, 0.0706, 0.0403, 0.0321, 0.0622, 0.0579, 0.0465,
        0.0856, 0.0202], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:11,295][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([1.6980e-01, 1.4028e-04, 9.5601e-04, 9.7316e-03, 6.9040e-03, 9.6146e-02,
        3.4937e-02, 4.1508e-02, 3.9522e-01, 4.1824e-02, 6.6718e-02, 1.3611e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:11,296][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.5900, 0.0754, 0.0187, 0.1075, 0.0220, 0.0170, 0.0354, 0.0152, 0.0157,
        0.0460, 0.0357, 0.0211], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:11,297][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([3.4869e-05, 1.7117e-02, 5.0860e-02, 3.8296e-02, 2.2472e-02, 1.6060e-01,
        1.5911e-01, 3.6580e-02, 1.5272e-01, 1.1106e-01, 1.4305e-01, 1.0809e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:11,301][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.1251, 0.0005, 0.0053, 0.0132, 0.0109, 0.1462, 0.0823, 0.0496, 0.3040,
        0.0399, 0.0444, 0.1786], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:11,302][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([1.1569e-01, 2.1775e-04, 2.9813e-03, 4.4110e-03, 1.6368e-02, 1.6636e-01,
        7.5608e-02, 3.1919e-02, 2.3460e-01, 3.3268e-02, 1.1788e-01, 2.0069e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:11,302][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.9509, 0.0018, 0.0018, 0.0061, 0.0046, 0.0065, 0.0027, 0.0068, 0.0086,
        0.0023, 0.0048, 0.0031], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:11,303][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.6605, 0.0390, 0.0254, 0.0368, 0.0228, 0.0260, 0.0215, 0.0276, 0.0574,
        0.0300, 0.0374, 0.0157], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:11,306][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0426, 0.0850, 0.0400, 0.0926, 0.1001, 0.0485, 0.0847, 0.1103, 0.0975,
        0.0683, 0.1826, 0.0478], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:11,308][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.1913, 0.0006, 0.0050, 0.0101, 0.0184, 0.2362, 0.0542, 0.0929, 0.1914,
        0.0248, 0.0956, 0.0795], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:11,309][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0368, 0.0007, 0.0055, 0.0153, 0.0188, 0.1133, 0.0462, 0.0284, 0.4359,
        0.0781, 0.0913, 0.1297], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:11,310][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0005, 0.0690, 0.2801, 0.0346, 0.0146, 0.0575, 0.0838, 0.0777, 0.1262,
        0.1400, 0.0569, 0.0592], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:11,313][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.1439, 0.2804, 0.0503, 0.1128, 0.0816, 0.0268, 0.0632, 0.0513, 0.0439,
        0.0786, 0.0435, 0.0237], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:11,315][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ computer] are: tensor([9.6831e-02, 1.5061e-04, 1.1797e-03, 6.1791e-03, 7.8415e-03, 7.5078e-02,
        3.3251e-02, 6.3323e-02, 3.0842e-01, 1.8532e-02, 1.1151e-01, 1.6765e-01,
        1.1005e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:11,316][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ computer] are: tensor([0.4059, 0.1489, 0.0380, 0.0650, 0.0322, 0.0230, 0.0324, 0.0243, 0.0244,
        0.0468, 0.0647, 0.0331, 0.0615], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:11,317][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ computer] are: tensor([3.0921e-06, 1.3296e-02, 8.6422e-02, 2.0116e-02, 2.0327e-02, 1.4041e-01,
        8.6916e-02, 3.1614e-02, 1.1434e-01, 9.4246e-02, 2.3759e-01, 9.6227e-02,
        5.8493e-02], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:11,320][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ computer] are: tensor([0.0868, 0.0005, 0.0080, 0.0124, 0.0102, 0.1233, 0.0782, 0.0433, 0.3080,
        0.0341, 0.0561, 0.1643, 0.0749], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:11,322][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ computer] are: tensor([2.8428e-02, 1.1342e-04, 2.2742e-03, 1.8740e-03, 1.2470e-02, 1.8561e-01,
        1.0647e-01, 5.4343e-02, 1.8646e-01, 1.1923e-02, 1.1597e-01, 2.3785e-01,
        5.6213e-02], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:11,323][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ computer] are: tensor([0.9070, 0.0042, 0.0026, 0.0106, 0.0059, 0.0113, 0.0041, 0.0093, 0.0080,
        0.0053, 0.0061, 0.0080, 0.0176], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:11,324][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ computer] are: tensor([0.5211, 0.0465, 0.0325, 0.0320, 0.0280, 0.0384, 0.0274, 0.0452, 0.0795,
        0.0324, 0.0493, 0.0199, 0.0479], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:11,325][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ computer] are: tensor([0.0065, 0.0488, 0.0319, 0.0604, 0.0717, 0.0389, 0.1041, 0.1319, 0.0902,
        0.0798, 0.1584, 0.0536, 0.1238], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:11,328][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ computer] are: tensor([0.1414, 0.0005, 0.0052, 0.0094, 0.0109, 0.1898, 0.0667, 0.0938, 0.2116,
        0.0195, 0.0945, 0.0845, 0.0724], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:11,329][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ computer] are: tensor([0.0212, 0.0007, 0.0066, 0.0121, 0.0140, 0.0930, 0.0534, 0.0360, 0.3919,
        0.0543, 0.1007, 0.1636, 0.0526], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:11,330][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ computer] are: tensor([3.6688e-05, 4.0134e-02, 1.8343e-01, 2.1352e-02, 1.1023e-02, 9.7260e-02,
        3.9179e-02, 4.2334e-02, 8.7045e-02, 1.6761e-01, 1.5196e-01, 1.3045e-01,
        2.8184e-02], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:11,331][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ computer] are: tensor([0.0678, 0.2814, 0.0505, 0.1230, 0.0540, 0.0337, 0.0540, 0.0442, 0.0551,
        0.0762, 0.0478, 0.0528, 0.0593], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:11,333][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([6.1444e-01, 1.7840e-04, 2.6342e-04, 7.2175e-03, 1.8377e-03, 1.3574e-02,
        1.0123e-02, 9.5832e-03, 9.6883e-02, 1.2944e-02, 1.7770e-02, 5.1232e-02,
        6.8724e-02, 9.5233e-02], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:11,335][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.7940, 0.0439, 0.0105, 0.0353, 0.0127, 0.0064, 0.0162, 0.0070, 0.0094,
        0.0214, 0.0108, 0.0093, 0.0128, 0.0103], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:11,336][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([2.6736e-05, 2.0261e-02, 5.4825e-02, 2.9935e-02, 1.4200e-02, 1.5912e-01,
        1.2128e-01, 1.8005e-02, 9.3962e-02, 1.4535e-01, 8.9070e-02, 9.9365e-02,
        4.8886e-02, 1.0571e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:11,337][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.2191, 0.0004, 0.0032, 0.0090, 0.0058, 0.0707, 0.0493, 0.0225, 0.1809,
        0.0244, 0.0316, 0.1103, 0.0403, 0.2325], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:11,338][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([1.6878e-01, 1.8561e-04, 1.5464e-03, 2.4758e-03, 6.8819e-03, 5.9092e-02,
        5.6135e-02, 2.0914e-02, 1.5541e-01, 2.0566e-02, 6.7746e-02, 1.3003e-01,
        3.8005e-02, 2.7223e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:11,340][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([9.6503e-01, 1.3046e-03, 8.0357e-04, 3.8351e-03, 2.1851e-03, 2.7780e-03,
        1.2941e-03, 2.7664e-03, 4.9964e-03, 1.2205e-03, 1.3171e-03, 1.7900e-03,
        2.8219e-03, 7.8615e-03], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:11,342][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.7664, 0.0251, 0.0135, 0.0235, 0.0125, 0.0127, 0.0136, 0.0127, 0.0284,
        0.0154, 0.0187, 0.0091, 0.0268, 0.0216], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:11,343][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0188, 0.0649, 0.0425, 0.0897, 0.0675, 0.0405, 0.1030, 0.0717, 0.0872,
        0.0596, 0.1046, 0.0783, 0.1042, 0.0676], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:11,344][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.3692, 0.0004, 0.0019, 0.0065, 0.0046, 0.0827, 0.0286, 0.0268, 0.1092,
        0.0175, 0.0293, 0.0453, 0.0430, 0.2348], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:11,346][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0609, 0.0009, 0.0028, 0.0136, 0.0137, 0.0522, 0.0327, 0.0220, 0.2996,
        0.0553, 0.0398, 0.0953, 0.0661, 0.2451], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:11,349][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0003, 0.0859, 0.2237, 0.0406, 0.0111, 0.0754, 0.0586, 0.0671, 0.1149,
        0.1241, 0.0451, 0.0621, 0.0515, 0.0396], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:11,350][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.1297, 0.3772, 0.0390, 0.0999, 0.0371, 0.0241, 0.0449, 0.0405, 0.0367,
        0.0712, 0.0210, 0.0254, 0.0325, 0.0209], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:11,353][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:20:11,356][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 4675],
        [12487],
        [ 4009],
        [37026],
        [ 3768],
        [ 3380],
        [ 2644],
        [  145],
        [ 4673],
        [ 2779],
        [ 1849],
        [ 4082],
        [   64],
        [ 2321]], device='cuda:0')
[2024-07-24 10:20:11,358][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 4848],
        [13432],
        [10740],
        [36113],
        [ 8564],
        [ 5740],
        [ 5035],
        [  820],
        [ 6135],
        [ 3671],
        [ 1884],
        [ 5772],
        [  865],
        [ 2896]], device='cuda:0')
[2024-07-24 10:20:11,359][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[42979],
        [30379],
        [32395],
        [30519],
        [33911],
        [33522],
        [33588],
        [36708],
        [36183],
        [35348],
        [35630],
        [35908],
        [36177],
        [36274]], device='cuda:0')
[2024-07-24 10:20:11,361][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[19514],
        [13858],
        [12777],
        [19341],
        [18877],
        [19167],
        [18755],
        [16612],
        [15427],
        [18957],
        [19123],
        [18507],
        [13370],
        [15999]], device='cuda:0')
[2024-07-24 10:20:11,364][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[50051],
        [43896],
        [30084],
        [42887],
        [29625],
        [28999],
        [27601],
        [31054],
        [25856],
        [21681],
        [25922],
        [21276],
        [17502],
        [21445]], device='cuda:0')
[2024-07-24 10:20:11,365][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[  53],
        [ 690],
        [ 490],
        [ 581],
        [ 684],
        [ 683],
        [ 736],
        [ 896],
        [ 883],
        [ 943],
        [1002],
        [1118],
        [1153],
        [1131]], device='cuda:0')
[2024-07-24 10:20:11,366][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[4072],
        [ 194],
        [ 147],
        [ 125],
        [ 147],
        [ 204],
        [ 188],
        [ 113],
        [ 120],
        [ 120],
        [  93],
        [  91],
        [  89],
        [ 103]], device='cuda:0')
[2024-07-24 10:20:11,368][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[33752],
        [ 9866],
        [14792],
        [16134],
        [24448],
        [31228],
        [22252],
        [26291],
        [24997],
        [21530],
        [24110],
        [19337],
        [21645],
        [26580]], device='cuda:0')
[2024-07-24 10:20:11,371][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[9836],
        [4888],
        [3586],
        [6274],
        [6110],
        [6335],
        [6904],
        [6177],
        [5734],
        [5653],
        [5391],
        [5464],
        [5508],
        [5416]], device='cuda:0')
[2024-07-24 10:20:11,372][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[44912],
        [44208],
        [44956],
        [45586],
        [44614],
        [44106],
        [43889],
        [43858],
        [43767],
        [44032],
        [43749],
        [43334],
        [42972],
        [42796]], device='cuda:0')
[2024-07-24 10:20:11,374][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[12976],
        [22084],
        [19194],
        [32498],
        [40405],
        [25329],
        [30091],
        [32375],
        [35391],
        [39554],
        [37059],
        [37157],
        [37831],
        [39302]], device='cuda:0')
[2024-07-24 10:20:11,376][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[41649],
        [35091],
        [41275],
        [34837],
        [38083],
        [32463],
        [33425],
        [32135],
        [35191],
        [29073],
        [32137],
        [29636],
        [29102],
        [30893]], device='cuda:0')
[2024-07-24 10:20:11,379][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[24058],
        [ 6183],
        [ 7843],
        [10852],
        [12785],
        [12058],
        [11060],
        [10919],
        [12652],
        [11816],
        [12689],
        [12652],
        [12969],
        [12950]], device='cuda:0')
[2024-07-24 10:20:11,380][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[12162],
        [ 7117],
        [ 9825],
        [ 9429],
        [15879],
        [10406],
        [13110],
        [10251],
        [11407],
        [12533],
        [12615],
        [14172],
        [10388],
        [ 9556]], device='cuda:0')
[2024-07-24 10:20:11,381][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 3024],
        [28874],
        [14491],
        [32990],
        [ 9937],
        [13993],
        [13058],
        [ 3467],
        [15957],
        [22929],
        [20981],
        [17490],
        [ 3291],
        [25944]], device='cuda:0')
[2024-07-24 10:20:11,383][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[21543],
        [19248],
        [14181],
        [16799],
        [17816],
        [21535],
        [19685],
        [20046],
        [18934],
        [18802],
        [16714],
        [16749],
        [17355],
        [16689]], device='cuda:0')
[2024-07-24 10:20:11,386][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[18283],
        [ 8235],
        [ 9795],
        [ 7886],
        [ 7550],
        [11212],
        [ 8622],
        [16660],
        [12465],
        [ 9380],
        [ 8503],
        [10289],
        [ 8653],
        [15420]], device='cuda:0')
[2024-07-24 10:20:11,387][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[10422],
        [42988],
        [46270],
        [46100],
        [45870],
        [49040],
        [49068],
        [48793],
        [48728],
        [49149],
        [49042],
        [48252],
        [47594],
        [48949]], device='cuda:0')
[2024-07-24 10:20:11,389][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[ 3845],
        [ 1145],
        [ 1013],
        [ 2293],
        [ 2899],
        [ 9574],
        [13083],
        [18675],
        [18515],
        [22395],
        [20290],
        [19887],
        [18877],
        [17132]], device='cuda:0')
[2024-07-24 10:20:11,390][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[42323],
        [37332],
        [41433],
        [37613],
        [31383],
        [32192],
        [32527],
        [31633],
        [32814],
        [33675],
        [35947],
        [37585],
        [36925],
        [37101]], device='cuda:0')
[2024-07-24 10:20:11,393][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[34038],
        [32934],
        [34598],
        [23543],
        [30040],
        [33676],
        [33511],
        [33366],
        [33250],
        [21030],
        [30582],
        [32741],
        [30467],
        [33571]], device='cuda:0')
[2024-07-24 10:20:11,395][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[31879],
        [10564],
        [13586],
        [15791],
        [18963],
        [29859],
        [30386],
        [31748],
        [26813],
        [22833],
        [23888],
        [26051],
        [20340],
        [32546]], device='cuda:0')
[2024-07-24 10:20:11,396][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[13620],
        [11851],
        [12125],
        [10049],
        [ 8369],
        [ 7992],
        [ 7684],
        [ 7594],
        [ 7713],
        [ 7763],
        [ 6740],
        [ 6097],
        [ 5635],
        [ 5832]], device='cuda:0')
[2024-07-24 10:20:11,398][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[40231],
        [36996],
        [43720],
        [38121],
        [31334],
        [24235],
        [11584],
        [11931],
        [13605],
        [12964],
        [10325],
        [10216],
        [ 9429],
        [10386]], device='cuda:0')
[2024-07-24 10:20:11,401][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[16267],
        [ 8931],
        [ 8796],
        [ 5737],
        [16232],
        [14712],
        [15942],
        [16684],
        [ 8332],
        [ 8654],
        [ 8128],
        [ 9435],
        [11742],
        [15705]], device='cuda:0')
[2024-07-24 10:20:11,402][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[38016],
        [ 5945],
        [28506],
        [32571],
        [33994],
        [28337],
        [28190],
        [23521],
        [27666],
        [27325],
        [25135],
        [20816],
        [17886],
        [21340]], device='cuda:0')
[2024-07-24 10:20:11,403][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[18452],
        [12588],
        [11062],
        [11974],
        [12136],
        [13613],
        [14014],
        [14118],
        [13710],
        [13686],
        [14362],
        [14108],
        [13234],
        [13641]], device='cuda:0')
[2024-07-24 10:20:11,405][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[ 6686],
        [23518],
        [15525],
        [22771],
        [24725],
        [14603],
        [18269],
        [12765],
        [17425],
        [22392],
        [23584],
        [22383],
        [26897],
        [17589]], device='cuda:0')
[2024-07-24 10:20:11,408][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[44332],
        [39337],
        [26272],
        [26309],
        [21741],
        [17502],
        [22382],
        [24886],
        [22456],
        [19882],
        [21967],
        [23857],
        [24356],
        [12525]], device='cuda:0')
[2024-07-24 10:20:11,410][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[2546],
        [2546],
        [2546],
        [2546],
        [2546],
        [2546],
        [2546],
        [2546],
        [2546],
        [2546],
        [2546],
        [2546],
        [2546],
        [2546]], device='cuda:0')
[2024-07-24 10:20:11,503][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:20:11,504][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:11,504][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:11,505][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:11,506][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:11,506][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:11,507][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:11,508][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:11,508][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:11,509][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:11,510][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:11,510][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:11,511][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:11,511][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Benjamin] are: tensor([0.6473, 0.3527], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:11,514][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Benjamin] are: tensor([0.2147, 0.7853], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:11,515][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Benjamin] are: tensor([0.3919, 0.6081], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:11,516][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Benjamin] are: tensor([0.2696, 0.7304], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:11,516][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Benjamin] are: tensor([0.0929, 0.9071], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:11,518][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Benjamin] are: tensor([0.9886, 0.0114], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:11,521][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Benjamin] are: tensor([0.4765, 0.5235], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:11,522][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Benjamin] are: tensor([0.9119, 0.0881], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:11,522][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Benjamin] are: tensor([0.4730, 0.5270], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:11,523][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Benjamin] are: tensor([0.8359, 0.1641], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:11,525][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Benjamin] are: tensor([0.6382, 0.3618], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:11,528][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Benjamin] are: tensor([0.8619, 0.1381], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:11,528][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.2849, 0.1348, 0.5803], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:11,529][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0030, 0.4688, 0.5282], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:11,530][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.2469, 0.4007, 0.3525], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:11,532][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0411, 0.3333, 0.6256], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:11,534][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.3089, 0.2437, 0.4474], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:11,535][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ and] are: tensor([9.9012e-01, 8.5664e-04, 9.0215e-03], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:11,536][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.4053, 0.4152, 0.1794], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:11,536][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.9723, 0.0023, 0.0254], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:11,539][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.7426, 0.0952, 0.1622], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:11,541][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.7898, 0.0715, 0.1387], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:11,542][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.6030, 0.0603, 0.3367], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:11,543][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.6721, 0.0279, 0.3000], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:11,543][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Alexander] are: tensor([0.2409, 0.0932, 0.3477, 0.3182], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:11,546][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Alexander] are: tensor([0.0093, 0.1502, 0.3750, 0.4654], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:11,548][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Alexander] are: tensor([0.2239, 0.2935, 0.2649, 0.2177], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:11,549][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Alexander] are: tensor([0.0771, 0.1840, 0.2161, 0.5227], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:11,549][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Alexander] are: tensor([5.1776e-04, 8.3912e-01, 1.5819e-01, 2.1732e-03], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:11,550][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Alexander] are: tensor([0.9901, 0.0012, 0.0046, 0.0041], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:11,553][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Alexander] are: tensor([0.3913, 0.2126, 0.2404, 0.1557], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:11,555][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Alexander] are: tensor([0.8243, 0.0182, 0.0710, 0.0864], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:11,555][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Alexander] are: tensor([0.2618, 0.2170, 0.3855, 0.1358], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:11,556][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Alexander] are: tensor([0.7220, 0.0813, 0.0925, 0.1042], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:11,557][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Alexander] are: tensor([0.4418, 0.0815, 0.4030, 0.0737], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:11,559][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Alexander] are: tensor([0.6471, 0.0347, 0.2309, 0.0872], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:11,561][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ went] are: tensor([0.2051, 0.0737, 0.3003, 0.2679, 0.1531], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:11,562][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ went] are: tensor([0.0040, 0.1561, 0.2222, 0.2947, 0.3231], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:11,563][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ went] are: tensor([0.1817, 0.2334, 0.2122, 0.1761, 0.1966], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:11,563][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ went] are: tensor([0.0134, 0.0696, 0.1470, 0.2201, 0.5499], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:11,566][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ went] are: tensor([0.1463, 0.1454, 0.2720, 0.0033, 0.4329], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:11,568][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ went] are: tensor([9.4447e-01, 8.2494e-04, 8.7032e-03, 2.5161e-02, 2.0846e-02],
       device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:11,569][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ went] are: tensor([0.3375, 0.1571, 0.1653, 0.2310, 0.1091], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:11,569][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ went] are: tensor([0.9000, 0.0027, 0.0220, 0.0376, 0.0377], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:11,570][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.5590, 0.0443, 0.1800, 0.0353, 0.1814], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:11,573][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ went] are: tensor([0.7512, 0.0297, 0.0760, 0.0974, 0.0457], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:11,575][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ went] are: tensor([0.6941, 0.0148, 0.1258, 0.0251, 0.1401], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:11,575][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ went] are: tensor([0.2773, 0.0091, 0.1805, 0.0352, 0.4979], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:11,576][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.1260, 0.0319, 0.1444, 0.1323, 0.0595, 0.5060], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:11,577][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0036, 0.0930, 0.1083, 0.2258, 0.3047, 0.2647], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:11,580][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.2024, 0.1946, 0.1836, 0.1467, 0.1597, 0.1130], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:11,581][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0097, 0.0676, 0.1035, 0.1558, 0.3861, 0.2773], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:11,582][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.2097, 0.1820, 0.1511, 0.0083, 0.2022, 0.2466], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:11,583][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ to] are: tensor([9.8924e-01, 7.6143e-05, 3.1303e-04, 2.1772e-03, 1.1849e-03, 7.0124e-03],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:11,584][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.7223, 0.0785, 0.0470, 0.0666, 0.0492, 0.0363], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:11,585][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ to] are: tensor([9.5486e-01, 2.7205e-04, 9.7817e-04, 6.0089e-03, 3.5148e-03, 3.4369e-02],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:11,588][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.6036, 0.0622, 0.0828, 0.0533, 0.1238, 0.0743], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:11,589][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.7895, 0.0255, 0.0285, 0.0640, 0.0126, 0.0799], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:11,590][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.5939, 0.0073, 0.0425, 0.0174, 0.0317, 0.3071], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:11,590][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.2680, 0.0160, 0.0750, 0.1821, 0.2205, 0.2384], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:11,593][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0564, 0.0145, 0.0571, 0.0581, 0.0273, 0.2006, 0.5860],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:11,595][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0048, 0.0511, 0.0870, 0.2184, 0.2432, 0.2301, 0.1653],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:11,596][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.1522, 0.1753, 0.1615, 0.1320, 0.1470, 0.1040, 0.1280],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:11,596][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0194, 0.0594, 0.0811, 0.0987, 0.2584, 0.3763, 0.1067],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:11,597][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0162, 0.2389, 0.1616, 0.0087, 0.2023, 0.2466, 0.1259],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:11,599][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ the] are: tensor([9.6708e-01, 1.4342e-04, 8.4392e-04, 3.6252e-03, 2.2231e-03, 1.7471e-02,
        8.6164e-03], device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:11,601][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.6868, 0.0826, 0.0533, 0.0606, 0.0346, 0.0326, 0.0496],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:11,602][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.6156, 0.0008, 0.0071, 0.0191, 0.0262, 0.2547, 0.0764],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:11,603][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.4297, 0.0471, 0.1219, 0.0411, 0.1580, 0.0974, 0.1050],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:11,604][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.6590, 0.0206, 0.0317, 0.0674, 0.0179, 0.1080, 0.0955],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:11,606][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.3131, 0.0055, 0.0446, 0.0142, 0.0487, 0.3822, 0.1917],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:11,608][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.8019, 0.0035, 0.0161, 0.0225, 0.0800, 0.0510, 0.0249],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:11,609][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ station] are: tensor([0.0624, 0.0133, 0.0594, 0.0531, 0.0281, 0.1806, 0.5544, 0.0487],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:11,610][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ station] are: tensor([0.0034, 0.0427, 0.0452, 0.0974, 0.1109, 0.2874, 0.2529, 0.1600],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:11,611][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ station] are: tensor([0.1389, 0.1517, 0.1359, 0.1083, 0.1271, 0.0968, 0.1102, 0.1311],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:11,614][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ station] are: tensor([0.0030, 0.0335, 0.0540, 0.1161, 0.1906, 0.3166, 0.1136, 0.1726],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:11,615][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ station] are: tensor([0.0972, 0.1980, 0.0919, 0.0041, 0.1745, 0.1141, 0.0571, 0.2630],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:11,616][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ station] are: tensor([9.8078e-01, 6.5338e-05, 3.3686e-04, 1.2121e-03, 9.5170e-04, 7.7855e-03,
        4.5537e-03, 4.3153e-03], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:11,617][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ station] are: tensor([0.4721, 0.0708, 0.0505, 0.0870, 0.0715, 0.0682, 0.1233, 0.0566],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:11,617][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ station] are: tensor([5.8481e-01, 5.4869e-04, 6.6932e-03, 1.0796e-02, 2.3105e-02, 2.5007e-01,
        9.0416e-02, 3.3560e-02], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:11,621][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ station] are: tensor([0.3986, 0.0471, 0.1052, 0.0411, 0.1687, 0.0891, 0.0789, 0.0715],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:11,622][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ station] are: tensor([0.8289, 0.0122, 0.0161, 0.0324, 0.0082, 0.0410, 0.0359, 0.0253],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:11,623][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ station] are: tensor([0.5844, 0.0080, 0.0445, 0.0111, 0.0380, 0.1609, 0.1119, 0.0412],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:11,623][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ station] are: tensor([0.4998, 0.0030, 0.0618, 0.0310, 0.1016, 0.1729, 0.0916, 0.0382],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:11,624][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0532, 0.0133, 0.0569, 0.0536, 0.0229, 0.1791, 0.4942, 0.0390, 0.0879],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:11,628][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0003, 0.0189, 0.0449, 0.1684, 0.1534, 0.1654, 0.1728, 0.1019, 0.1740],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:11,629][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.1220, 0.1339, 0.1260, 0.0988, 0.1124, 0.0806, 0.0985, 0.1148, 0.1132],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:11,629][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0116, 0.0615, 0.0713, 0.0888, 0.2427, 0.1929, 0.0634, 0.1905, 0.0774],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:11,630][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0237, 0.0953, 0.0702, 0.0056, 0.1200, 0.1580, 0.0959, 0.3364, 0.0949],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:11,631][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [,] are: tensor([9.6060e-01, 4.8390e-05, 1.6562e-04, 1.3349e-03, 4.9770e-04, 4.2694e-03,
        2.2284e-03, 1.8987e-03, 2.8956e-02], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:11,634][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.2462, 0.1036, 0.0682, 0.1497, 0.0814, 0.0635, 0.1212, 0.0385, 0.1277],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:11,635][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [,] are: tensor([6.1835e-01, 2.6161e-04, 2.3767e-03, 6.7022e-03, 9.5187e-03, 9.5742e-02,
        3.9917e-02, 1.9142e-02, 2.0799e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:11,636][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.4988, 0.0315, 0.0607, 0.0304, 0.1046, 0.0668, 0.0852, 0.0475, 0.0745],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:11,637][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.5632, 0.0187, 0.0253, 0.0733, 0.0113, 0.0846, 0.0679, 0.0304, 0.1252],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:11,638][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.1879, 0.0035, 0.0259, 0.0103, 0.0214, 0.1707, 0.0897, 0.0343, 0.4563],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:11,642][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.4127, 0.0054, 0.0219, 0.0507, 0.1027, 0.0817, 0.1190, 0.0252, 0.1806],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:11,644][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Benjamin] are: tensor([0.0743, 0.0155, 0.0555, 0.0556, 0.0252, 0.1611, 0.4222, 0.0361, 0.0920,
        0.0625], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:11,645][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Benjamin] are: tensor([0.0005, 0.0062, 0.0200, 0.0361, 0.0998, 0.1091, 0.1801, 0.1326, 0.2142,
        0.2012], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:11,646][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Benjamin] are: tensor([0.0941, 0.1214, 0.1098, 0.0905, 0.0987, 0.0734, 0.0922, 0.1026, 0.1052,
        0.1121], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:11,647][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Benjamin] are: tensor([0.0604, 0.0322, 0.0255, 0.0512, 0.1860, 0.1990, 0.0481, 0.2994, 0.0481,
        0.0501], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:11,648][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Benjamin] are: tensor([0.0022, 0.5078, 0.0792, 0.0047, 0.1467, 0.0541, 0.0249, 0.1469, 0.0185,
        0.0149], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:11,650][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Benjamin] are: tensor([9.3745e-01, 3.0573e-04, 6.7656e-04, 2.3325e-03, 1.2457e-03, 5.0756e-03,
        2.6481e-03, 6.3826e-03, 3.9535e-02, 4.3520e-03], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:11,652][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Benjamin] are: tensor([0.2446, 0.0603, 0.0606, 0.0767, 0.0484, 0.0757, 0.1243, 0.0684, 0.1405,
        0.1005], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:11,653][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Benjamin] are: tensor([0.1174, 0.0012, 0.0076, 0.0150, 0.0268, 0.2044, 0.0812, 0.0720, 0.4062,
        0.0681], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:11,653][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Benjamin] are: tensor([0.1131, 0.0825, 0.1343, 0.0513, 0.1812, 0.0877, 0.1069, 0.0956, 0.1270,
        0.0204], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:11,656][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Benjamin] are: tensor([0.5796, 0.0271, 0.0274, 0.0592, 0.0130, 0.0546, 0.0506, 0.0358, 0.0667,
        0.0860], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:11,658][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Benjamin] are: tensor([0.2075, 0.0120, 0.0473, 0.0137, 0.0395, 0.1328, 0.0775, 0.0536, 0.3606,
        0.0557], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:11,659][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Benjamin] are: tensor([0.1788, 0.0160, 0.0777, 0.0437, 0.3096, 0.0613, 0.0629, 0.0742, 0.1580,
        0.0178], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:11,660][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.0401, 0.0138, 0.0540, 0.0481, 0.0227, 0.1707, 0.4526, 0.0368, 0.0821,
        0.0551, 0.0239], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:11,662][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0020, 0.0221, 0.0254, 0.0604, 0.1906, 0.0820, 0.1506, 0.1211, 0.1649,
        0.1188, 0.0620], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:11,664][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0897, 0.1072, 0.0979, 0.0796, 0.0899, 0.0672, 0.0843, 0.0920, 0.0941,
        0.1010, 0.0972], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:11,665][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.0290, 0.0332, 0.0210, 0.0477, 0.1536, 0.1571, 0.0468, 0.2709, 0.0539,
        0.0623, 0.1246], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:11,666][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.0662, 0.0526, 0.0417, 0.0019, 0.0736, 0.0889, 0.0468, 0.2164, 0.0422,
        0.0192, 0.3504], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:11,667][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([8.9286e-01, 6.0548e-05, 2.8569e-04, 1.4138e-03, 7.7916e-04, 8.9658e-03,
        5.6289e-03, 5.3319e-03, 7.3771e-02, 6.0681e-03, 4.8343e-03],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:11,670][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.3283, 0.0386, 0.0424, 0.0602, 0.0260, 0.0372, 0.0776, 0.0382, 0.1483,
        0.0549, 0.1481], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:11,671][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([4.3027e-01, 2.9445e-04, 2.1969e-03, 5.4609e-03, 7.4459e-03, 1.3868e-01,
        4.6780e-02, 2.2201e-02, 2.5889e-01, 5.3664e-02, 3.4111e-02],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:11,672][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.3407, 0.0293, 0.0833, 0.0226, 0.0945, 0.0780, 0.0857, 0.0529, 0.0886,
        0.0131, 0.1112], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:11,673][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.5979, 0.0137, 0.0236, 0.0385, 0.0101, 0.0605, 0.0548, 0.0262, 0.0574,
        0.0584, 0.0588], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:11,677][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.2450, 0.0029, 0.0217, 0.0071, 0.0234, 0.1351, 0.0779, 0.0374, 0.3062,
        0.0329, 0.1103], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:11,678][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.2696, 0.0049, 0.0174, 0.0206, 0.1582, 0.0623, 0.0286, 0.1167, 0.1562,
        0.0088, 0.1566], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:11,678][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0408, 0.0092, 0.0350, 0.0354, 0.0149, 0.1137, 0.3091, 0.0265, 0.0642,
        0.0373, 0.0152, 0.2986], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:11,679][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0025, 0.0089, 0.0166, 0.0802, 0.0968, 0.0373, 0.0781, 0.0530, 0.1548,
        0.2630, 0.1378, 0.0710], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:11,683][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0928, 0.0979, 0.0908, 0.0729, 0.0826, 0.0595, 0.0743, 0.0910, 0.0856,
        0.0905, 0.0932, 0.0689], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:11,684][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0318, 0.0496, 0.0501, 0.0656, 0.1554, 0.1755, 0.0534, 0.1932, 0.0504,
        0.0418, 0.0859, 0.0471], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:11,685][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0036, 0.1058, 0.0496, 0.0042, 0.0705, 0.0858, 0.0509, 0.1750, 0.0460,
        0.0202, 0.3548, 0.0336], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:11,686][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ a] are: tensor([8.8835e-01, 1.2273e-04, 4.1174e-04, 2.7618e-03, 9.5743e-04, 6.9358e-03,
        3.4231e-03, 4.3761e-03, 6.6141e-02, 7.1056e-03, 6.6269e-03, 1.2786e-02],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:11,689][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.3844, 0.0444, 0.0506, 0.0615, 0.0320, 0.0278, 0.0549, 0.0203, 0.0867,
        0.0594, 0.1089, 0.0692], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:11,690][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.2709, 0.0004, 0.0031, 0.0119, 0.0104, 0.1165, 0.0371, 0.0278, 0.2596,
        0.0706, 0.0455, 0.1463], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:11,691][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.2849, 0.0320, 0.0771, 0.0306, 0.0902, 0.0611, 0.0668, 0.0451, 0.0723,
        0.0128, 0.1114, 0.1157], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:11,692][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.5086, 0.0110, 0.0187, 0.0384, 0.0096, 0.0685, 0.0551, 0.0233, 0.0664,
        0.0610, 0.0603, 0.0790], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:11,696][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.1124, 0.0020, 0.0174, 0.0086, 0.0190, 0.1570, 0.0743, 0.0427, 0.3513,
        0.0355, 0.0915, 0.0883], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:11,697][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.5515, 0.0048, 0.0160, 0.0251, 0.0450, 0.0378, 0.0141, 0.0153, 0.1185,
        0.0102, 0.0723, 0.0895], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:11,698][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ computer] are: tensor([0.0266, 0.0092, 0.0360, 0.0345, 0.0152, 0.1144, 0.3000, 0.0280, 0.0584,
        0.0382, 0.0170, 0.2842, 0.0383], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:11,698][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ computer] are: tensor([8.5426e-05, 9.4138e-03, 1.1987e-02, 2.9433e-02, 5.3684e-02, 3.6296e-02,
        6.0447e-02, 4.7432e-02, 9.1222e-02, 8.5634e-02, 1.3472e-01, 8.8179e-02,
        3.5147e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:11,702][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ computer] are: tensor([0.1079, 0.0845, 0.0810, 0.0656, 0.0749, 0.0529, 0.0744, 0.0839, 0.0824,
        0.0834, 0.0833, 0.0647, 0.0610], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:11,703][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ computer] are: tensor([0.0324, 0.0318, 0.0266, 0.0336, 0.0902, 0.1111, 0.0351, 0.3111, 0.0326,
        0.0390, 0.0815, 0.0361, 0.1388], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:11,704][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ computer] are: tensor([0.0194, 0.1369, 0.0440, 0.0029, 0.0832, 0.0637, 0.0348, 0.1375, 0.0290,
        0.0170, 0.3046, 0.0254, 0.1015], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:11,705][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ computer] are: tensor([8.9486e-01, 1.1201e-04, 3.1503e-04, 1.7278e-03, 8.4069e-04, 5.7699e-03,
        2.9915e-03, 6.0891e-03, 4.7428e-02, 4.5825e-03, 6.7945e-03, 1.3791e-02,
        1.4695e-02], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:11,709][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ computer] are: tensor([0.1590, 0.0378, 0.0320, 0.0509, 0.0437, 0.0430, 0.0618, 0.0367, 0.0691,
        0.0491, 0.1538, 0.1014, 0.1616], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:11,709][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ computer] are: tensor([0.3655, 0.0004, 0.0022, 0.0072, 0.0128, 0.0999, 0.0323, 0.0257, 0.1779,
        0.0449, 0.0420, 0.1360, 0.0531], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:11,710][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ computer] are: tensor([0.2519, 0.0419, 0.0776, 0.0261, 0.0796, 0.0559, 0.0591, 0.0435, 0.0655,
        0.0134, 0.1115, 0.1382, 0.0358], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:11,711][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ computer] are: tensor([0.3928, 0.0150, 0.0182, 0.0430, 0.0154, 0.0597, 0.0511, 0.0227, 0.0785,
        0.0860, 0.0653, 0.0845, 0.0678], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:11,715][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ computer] are: tensor([0.1904, 0.0059, 0.0248, 0.0067, 0.0231, 0.1054, 0.0684, 0.0272, 0.3075,
        0.0338, 0.1002, 0.0719, 0.0347], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:11,716][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ computer] are: tensor([0.1565, 0.0035, 0.0314, 0.0164, 0.0748, 0.0479, 0.0437, 0.0330, 0.2579,
        0.0087, 0.0668, 0.2200, 0.0393], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:11,717][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0381, 0.0073, 0.0284, 0.0289, 0.0117, 0.1016, 0.2874, 0.0201, 0.0516,
        0.0295, 0.0116, 0.2792, 0.0291, 0.0756], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:11,718][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0010, 0.0078, 0.0189, 0.0335, 0.0588, 0.0518, 0.0758, 0.0299, 0.1676,
        0.1416, 0.0848, 0.0673, 0.1886, 0.0725], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:11,721][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1201, 0.0860, 0.0801, 0.0652, 0.0699, 0.0482, 0.0638, 0.0822, 0.0732,
        0.0775, 0.0795, 0.0561, 0.0537, 0.0445], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:11,722][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0083, 0.0410, 0.0344, 0.0384, 0.0798, 0.0702, 0.0393, 0.1323, 0.0502,
        0.0461, 0.0804, 0.0411, 0.2024, 0.1359], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:11,723][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0163, 0.0974, 0.0375, 0.0050, 0.0476, 0.0705, 0.0460, 0.1411, 0.0452,
        0.0211, 0.2646, 0.0363, 0.1270, 0.0444], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:11,724][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ to] are: tensor([9.5086e-01, 4.1589e-05, 9.4614e-05, 8.5922e-04, 2.8873e-04, 1.5394e-03,
        1.0749e-03, 1.1882e-03, 2.0026e-02, 2.2431e-03, 1.4805e-03, 4.8604e-03,
        5.7838e-03, 9.6548e-03], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:11,728][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.4827, 0.0307, 0.0265, 0.0366, 0.0207, 0.0185, 0.0293, 0.0146, 0.0654,
        0.0245, 0.0581, 0.0446, 0.1121, 0.0356], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:11,729][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ to] are: tensor([7.6300e-01, 1.4928e-04, 3.4752e-04, 3.3946e-03, 1.3024e-03, 1.4962e-02,
        5.6935e-03, 4.5119e-03, 4.9879e-02, 1.6444e-02, 5.4850e-03, 2.5962e-02,
        1.6567e-02, 9.2297e-02], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:11,730][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.2634, 0.0444, 0.0540, 0.0411, 0.0743, 0.0425, 0.0657, 0.0420, 0.0500,
        0.0174, 0.1252, 0.1162, 0.0282, 0.0358], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:11,730][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.6697, 0.0129, 0.0108, 0.0328, 0.0047, 0.0243, 0.0230, 0.0102, 0.0279,
        0.0390, 0.0247, 0.0306, 0.0234, 0.0661], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:11,734][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.2270, 0.0023, 0.0136, 0.0055, 0.0089, 0.1058, 0.0489, 0.0217, 0.2561,
        0.0251, 0.0535, 0.0533, 0.0237, 0.1545], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:11,735][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0997, 0.0058, 0.0243, 0.0525, 0.0477, 0.0600, 0.0328, 0.0074, 0.2331,
        0.0048, 0.0502, 0.2130, 0.0255, 0.1432], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:11,819][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:20:11,820][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:11,821][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:11,821][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:11,822][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:11,823][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:11,823][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:11,824][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:11,825][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:11,826][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:11,827][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:11,827][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:11,828][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:11,829][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Benjamin] are: tensor([0.8458, 0.1542], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:11,830][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Benjamin] are: tensor([0.0998, 0.9002], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:11,830][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Benjamin] are: tensor([0.3093, 0.6907], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:11,831][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Benjamin] are: tensor([0.6198, 0.3802], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:11,833][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Benjamin] are: tensor([0.5572, 0.4428], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:11,834][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Benjamin] are: tensor([0.9736, 0.0264], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:11,835][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Benjamin] are: tensor([0.9852, 0.0148], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:11,835][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Benjamin] are: tensor([0.9503, 0.0497], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:11,837][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Benjamin] are: tensor([0.4534, 0.5466], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:11,840][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Benjamin] are: tensor([0.3554, 0.6446], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:11,841][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Benjamin] are: tensor([0.6499, 0.3501], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:11,841][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Benjamin] are: tensor([0.2783, 0.7217], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:11,842][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.9564, 0.0408, 0.0028], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:11,845][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0145, 0.5630, 0.4224], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:11,847][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.2175, 0.4466, 0.3359], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:11,848][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.6663, 0.1987, 0.1350], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:11,848][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.3577, 0.0087, 0.6336], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:11,849][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.9850, 0.0031, 0.0119], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:11,850][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([9.9912e-01, 8.5078e-04, 3.1647e-05], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:11,853][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.8272, 0.0897, 0.0831], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:11,857][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.1849, 0.4111, 0.4040], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:11,857][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.1845, 0.2208, 0.5947], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:11,858][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.5674, 0.0625, 0.3701], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:11,859][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.1361, 0.1262, 0.7377], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:11,860][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Alexander] are: tensor([0.9224, 0.0740, 0.0013, 0.0022], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:11,862][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Alexander] are: tensor([0.0298, 0.2401, 0.3809, 0.3492], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:11,864][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Alexander] are: tensor([0.3242, 0.3654, 0.1918, 0.1185], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:11,865][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Alexander] are: tensor([0.5988, 0.1020, 0.1054, 0.1938], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:11,866][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Alexander] are: tensor([0.0892, 0.0265, 0.1457, 0.7385], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:11,866][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Alexander] are: tensor([0.9185, 0.0102, 0.0435, 0.0278], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:11,868][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Alexander] are: tensor([9.8827e-01, 7.6868e-03, 3.2709e-03, 7.7679e-04], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:11,871][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Alexander] are: tensor([0.9169, 0.0433, 0.0264, 0.0134], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:11,872][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Alexander] are: tensor([0.6507, 0.1484, 0.1539, 0.0469], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:11,872][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Alexander] are: tensor([0.1017, 0.2065, 0.3596, 0.3323], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:11,873][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Alexander] are: tensor([0.3746, 0.0490, 0.2362, 0.3402], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:11,876][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Alexander] are: tensor([0.1658, 0.1039, 0.4406, 0.2897], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:11,878][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([9.2731e-01, 6.4413e-03, 1.4899e-04, 2.8323e-04, 6.5812e-02],
       device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:11,878][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([0.0142, 0.2304, 0.3007, 0.2931, 0.1616], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:11,879][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([0.1706, 0.2443, 0.2078, 0.1065, 0.2707], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:11,880][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([0.4631, 0.0425, 0.1020, 0.2022, 0.1901], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:11,883][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([0.0405, 0.0016, 0.1331, 0.4507, 0.3741], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:11,885][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([0.8654, 0.0057, 0.0241, 0.0415, 0.0633], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:11,885][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([9.9929e-01, 3.1567e-04, 2.8282e-04, 2.3857e-05, 8.9945e-05],
       device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:11,886][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([0.8839, 0.0550, 0.0137, 0.0145, 0.0328], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:11,887][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([0.3339, 0.1854, 0.2022, 0.0742, 0.2042], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:11,889][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([0.0773, 0.0780, 0.2128, 0.2023, 0.4297], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:11,891][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([0.3036, 0.0159, 0.1823, 0.2272, 0.2710], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:11,892][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([0.1247, 0.0347, 0.2602, 0.3063, 0.2740], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:11,893][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([9.2088e-01, 2.1708e-02, 5.4183e-04, 1.4664e-03, 5.4659e-02, 7.4811e-04],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:11,894][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0207, 0.1981, 0.1713, 0.2384, 0.1913, 0.1802], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:11,896][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.3296, 0.2125, 0.1257, 0.1052, 0.1310, 0.0960], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:11,898][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.5510, 0.0597, 0.0482, 0.1318, 0.0955, 0.1138], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:11,899][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([3.8021e-02, 1.1538e-04, 4.3938e-03, 1.0087e-01, 1.7673e-02, 8.3893e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:11,900][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.9300, 0.0016, 0.0037, 0.0138, 0.0189, 0.0320], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:11,900][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([9.9678e-01, 2.3417e-03, 4.0886e-04, 1.3943e-04, 2.5033e-04, 8.0470e-05],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:11,903][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.7676, 0.1205, 0.0170, 0.0193, 0.0536, 0.0220], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:11,905][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.1014, 0.1594, 0.1798, 0.0767, 0.2017, 0.2809], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:11,906][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0744, 0.0528, 0.1550, 0.1702, 0.3097, 0.2378], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:11,906][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.3571, 0.0071, 0.0383, 0.1144, 0.0444, 0.4386], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:11,907][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.1031, 0.0156, 0.0530, 0.1809, 0.0543, 0.5931], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:11,909][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([9.1131e-01, 3.4894e-02, 7.7222e-04, 1.1346e-03, 5.1380e-02, 5.0597e-04,
        1.0769e-07], device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:11,911][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0184, 0.1264, 0.1483, 0.2486, 0.1610, 0.1671, 0.1302],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:11,912][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.2485, 0.1331, 0.1156, 0.0794, 0.1461, 0.1020, 0.1752],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:11,913][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.2339, 0.0734, 0.0480, 0.1619, 0.1317, 0.1594, 0.1917],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:11,914][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([5.6010e-03, 4.8672e-05, 2.5585e-03, 3.8039e-02, 7.9172e-03, 6.0928e-01,
        3.3656e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:11,916][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.8154, 0.0020, 0.0089, 0.0192, 0.0336, 0.0798, 0.0410],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:11,918][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([9.9305e-01, 3.8952e-03, 1.1706e-03, 2.5880e-04, 5.1500e-04, 7.8125e-04,
        3.3077e-04], device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:11,919][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.5239, 0.1929, 0.0274, 0.0305, 0.0646, 0.0404, 0.1203],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:11,920][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.1169, 0.1387, 0.1519, 0.0585, 0.1570, 0.2118, 0.1653],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:11,921][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0616, 0.0383, 0.1186, 0.1351, 0.3000, 0.1998, 0.1467],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:11,924][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.1754, 0.0058, 0.0325, 0.0812, 0.0529, 0.3724, 0.2797],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:11,925][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0516, 0.0154, 0.0443, 0.1392, 0.0592, 0.3659, 0.3245],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:11,926][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ station] are: tensor([9.7569e-01, 9.6814e-03, 1.7234e-04, 2.9780e-04, 8.8677e-03, 4.6935e-05,
        5.9803e-09, 5.2401e-03], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:11,927][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ station] are: tensor([0.0134, 0.0826, 0.0633, 0.1048, 0.0595, 0.1660, 0.1583, 0.3520],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:11,927][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ station] are: tensor([0.2567, 0.0434, 0.0596, 0.0330, 0.1065, 0.0473, 0.0675, 0.3860],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:11,931][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ station] are: tensor([0.3176, 0.0167, 0.0574, 0.0923, 0.1088, 0.1484, 0.1441, 0.1147],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:11,932][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ station] are: tensor([3.6831e-03, 2.9363e-05, 1.9694e-03, 1.9296e-02, 9.3592e-03, 5.0468e-01,
        2.8053e-01, 1.8045e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:11,933][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ station] are: tensor([0.8979, 0.0010, 0.0037, 0.0065, 0.0145, 0.0362, 0.0248, 0.0153],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:11,933][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ station] are: tensor([9.9638e-01, 1.6585e-03, 7.9030e-04, 1.2841e-04, 1.8997e-04, 3.6205e-04,
        3.1117e-04, 1.7676e-04], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:11,934][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ station] are: tensor([0.3815, 0.1368, 0.0073, 0.0098, 0.0263, 0.0098, 0.0509, 0.3776],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:11,938][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ station] are: tensor([0.2780, 0.0990, 0.1063, 0.0346, 0.0884, 0.1605, 0.1130, 0.1202],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:11,939][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ station] are: tensor([0.0185, 0.0472, 0.1147, 0.0911, 0.1714, 0.1384, 0.1181, 0.3006],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:11,939][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ station] are: tensor([0.1464, 0.0024, 0.0313, 0.0602, 0.0504, 0.3011, 0.2281, 0.1800],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:11,940][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ station] are: tensor([0.0193, 0.0061, 0.0410, 0.0490, 0.0385, 0.4061, 0.3226, 0.1174],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:11,941][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([9.4154e-01, 1.1628e-02, 1.0587e-03, 9.9057e-04, 3.2264e-02, 6.6800e-04,
        5.1005e-07, 1.0349e-02, 1.5049e-03], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:11,945][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0027, 0.0573, 0.0720, 0.1809, 0.0776, 0.1124, 0.1248, 0.2621, 0.1103],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:11,945][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.2463, 0.0840, 0.0999, 0.0358, 0.0624, 0.0610, 0.0885, 0.2485, 0.0735],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:11,946][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.2247, 0.0426, 0.0482, 0.1161, 0.0873, 0.1018, 0.1020, 0.0359, 0.2413],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:11,947][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([7.1139e-03, 2.2479e-05, 9.1234e-04, 2.0123e-02, 4.1979e-03, 2.3854e-01,
        1.2877e-01, 1.1098e-01, 4.8934e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:11,948][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([8.7316e-01, 6.7768e-04, 1.9739e-03, 6.8269e-03, 9.3058e-03, 2.2348e-02,
        1.3817e-02, 8.3007e-03, 6.3592e-02], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:11,949][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([9.9849e-01, 9.7346e-04, 1.2081e-04, 5.8023e-05, 9.5254e-05, 3.6692e-05,
        7.9043e-05, 9.6759e-05, 4.7670e-05], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:11,952][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.1163, 0.0919, 0.0122, 0.0201, 0.0288, 0.0171, 0.0739, 0.6311, 0.0087],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:11,953][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0799, 0.1082, 0.0994, 0.0419, 0.0979, 0.1535, 0.1095, 0.1378, 0.1720],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:11,954][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0528, 0.0189, 0.0612, 0.0842, 0.1579, 0.1095, 0.0721, 0.3481, 0.0953],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:11,954][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0927, 0.0037, 0.0190, 0.0529, 0.0225, 0.1655, 0.1264, 0.0622, 0.4551],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:11,958][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0346, 0.0078, 0.0249, 0.0811, 0.0180, 0.1961, 0.1635, 0.0645, 0.4095],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:11,959][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Benjamin] are: tensor([5.0180e-01, 3.3011e-02, 6.2036e-04, 1.5891e-03, 3.5391e-02, 5.4255e-04,
        2.9145e-07, 9.3141e-03, 1.4304e-03, 4.1630e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:11,960][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Benjamin] are: tensor([0.0030, 0.0224, 0.0375, 0.0500, 0.0500, 0.0806, 0.1376, 0.2352, 0.1630,
        0.2207], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:11,960][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Benjamin] are: tensor([0.2731, 0.1053, 0.0595, 0.0413, 0.0408, 0.0422, 0.0787, 0.2253, 0.0455,
        0.0882], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:11,962][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Benjamin] are: tensor([0.3606, 0.0382, 0.0347, 0.0792, 0.0889, 0.0649, 0.0607, 0.0687, 0.1594,
        0.0446], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:11,965][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Benjamin] are: tensor([2.6748e-03, 9.1288e-05, 1.2769e-03, 2.6416e-02, 6.7108e-03, 1.6445e-01,
        1.4391e-01, 1.3318e-01, 3.9670e-01, 1.2460e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:11,966][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Benjamin] are: tensor([0.5805, 0.0030, 0.0117, 0.0192, 0.0318, 0.0563, 0.0344, 0.0507, 0.1804,
        0.0318], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:11,967][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Benjamin] are: tensor([9.7282e-01, 8.6126e-03, 5.8146e-03, 7.7789e-04, 4.8796e-04, 1.9156e-03,
        1.2347e-03, 9.5944e-04, 2.5546e-03, 4.8259e-03], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:11,968][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Benjamin] are: tensor([0.5874, 0.0424, 0.0073, 0.0071, 0.0215, 0.0085, 0.0339, 0.2487, 0.0055,
        0.0378], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:11,971][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Benjamin] are: tensor([0.5514, 0.0761, 0.0667, 0.0171, 0.0372, 0.0670, 0.0386, 0.0617, 0.0677,
        0.0164], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:11,972][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Benjamin] are: tensor([0.0268, 0.0316, 0.0797, 0.0745, 0.1501, 0.0967, 0.0774, 0.2768, 0.0991,
        0.0872], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:11,973][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Benjamin] are: tensor([0.0855, 0.0047, 0.0227, 0.0515, 0.0280, 0.1343, 0.0897, 0.1060, 0.3550,
        0.1227], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:11,974][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Benjamin] are: tensor([0.0558, 0.0093, 0.0303, 0.0520, 0.0591, 0.1419, 0.1309, 0.1265, 0.2890,
        0.1053], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:11,975][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([4.9591e-01, 1.5282e-02, 3.9376e-04, 3.1124e-04, 5.9684e-02, 9.1989e-05,
        8.5907e-09, 2.8316e-03, 6.4588e-04, 3.9635e-01, 2.8501e-02],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:11,979][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0123, 0.0572, 0.0439, 0.0772, 0.0692, 0.0502, 0.0967, 0.2487, 0.1010,
        0.1986, 0.0449], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:11,979][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.1093, 0.0724, 0.0588, 0.0294, 0.0642, 0.0572, 0.1047, 0.2355, 0.0724,
        0.0971, 0.0990], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:11,980][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.2639, 0.0363, 0.0272, 0.1125, 0.0776, 0.0828, 0.0927, 0.0520, 0.1344,
        0.0599, 0.0607], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:11,981][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([1.5513e-03, 8.9929e-06, 4.9976e-04, 7.1721e-03, 2.4333e-03, 2.5741e-01,
        1.6164e-01, 6.6872e-02, 3.3763e-01, 7.8657e-02, 8.6128e-02],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:11,985][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.7519, 0.0010, 0.0028, 0.0072, 0.0104, 0.0348, 0.0233, 0.0183, 0.1029,
        0.0182, 0.0292], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:11,986][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([9.8278e-01, 4.3238e-03, 2.5049e-03, 4.9025e-04, 5.6824e-04, 1.3567e-03,
        5.6425e-04, 7.5946e-04, 1.1059e-03, 2.4890e-03, 3.0559e-03],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:11,986][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.4361, 0.0700, 0.0094, 0.0120, 0.0213, 0.0104, 0.0404, 0.3330, 0.0066,
        0.0501, 0.0107], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:11,987][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.2387, 0.0904, 0.0797, 0.0273, 0.0662, 0.1126, 0.0757, 0.0947, 0.1157,
        0.0309, 0.0682], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:11,989][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.0332, 0.0179, 0.0616, 0.0568, 0.1307, 0.0911, 0.0690, 0.2398, 0.0788,
        0.0715, 0.1496], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:11,992][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0751, 0.0017, 0.0125, 0.0318, 0.0206, 0.1440, 0.1158, 0.0712, 0.3426,
        0.0819, 0.1028], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:11,993][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.0201, 0.0036, 0.0141, 0.0324, 0.0218, 0.2007, 0.1327, 0.0857, 0.3312,
        0.0962, 0.0615], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:11,994][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([6.2641e-01, 2.8795e-02, 5.6917e-04, 1.2184e-03, 4.2333e-02, 1.9435e-04,
        8.4388e-08, 5.3938e-03, 1.2345e-03, 2.6091e-01, 3.2943e-02, 4.6409e-07],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:11,994][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0056, 0.0382, 0.0346, 0.0987, 0.0547, 0.0339, 0.0665, 0.1216, 0.1113,
        0.2803, 0.0915, 0.0631], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:11,998][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.1538, 0.0658, 0.0559, 0.0360, 0.0493, 0.0520, 0.0830, 0.2623, 0.0604,
        0.0585, 0.0765, 0.0465], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:11,999][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.2060, 0.0419, 0.0326, 0.1025, 0.0587, 0.0695, 0.0802, 0.0404, 0.1562,
        0.0445, 0.0676, 0.0998], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:12,000][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([2.5119e-03, 1.9142e-05, 8.9102e-04, 1.4296e-02, 4.1154e-03, 1.4952e-01,
        1.2096e-01, 6.5165e-02, 3.2648e-01, 9.2838e-02, 9.4038e-02, 1.2916e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:12,001][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.6264, 0.0014, 0.0047, 0.0134, 0.0173, 0.0399, 0.0200, 0.0192, 0.1465,
        0.0220, 0.0566, 0.0327], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:12,002][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([9.8684e-01, 3.8218e-03, 1.5870e-03, 3.3441e-04, 4.4805e-04, 9.3927e-04,
        3.8902e-04, 4.8348e-04, 9.2094e-04, 1.8714e-03, 1.6036e-03, 7.6604e-04],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:12,005][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.2389, 0.1110, 0.0148, 0.0149, 0.0269, 0.0177, 0.0509, 0.4431, 0.0074,
        0.0446, 0.0148, 0.0149], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:12,006][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.1613, 0.0871, 0.0830, 0.0311, 0.0763, 0.1096, 0.0745, 0.0964, 0.1133,
        0.0352, 0.0744, 0.0577], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:12,007][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0360, 0.0154, 0.0477, 0.0576, 0.1180, 0.0863, 0.0578, 0.2399, 0.0640,
        0.0628, 0.1219, 0.0927], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:12,008][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0812, 0.0018, 0.0103, 0.0358, 0.0155, 0.1149, 0.0846, 0.0533, 0.2741,
        0.0853, 0.0620, 0.1812], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:12,012][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0283, 0.0039, 0.0130, 0.0440, 0.0144, 0.1441, 0.1120, 0.0434, 0.2878,
        0.0797, 0.0445, 0.1848], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:12,013][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ computer] are: tensor([3.5601e-01, 1.4046e-02, 4.9346e-04, 3.6087e-04, 2.2024e-02, 1.3520e-04,
        3.2521e-08, 5.6051e-03, 2.2892e-03, 4.3386e-01, 2.5786e-02, 2.2936e-07,
        1.3939e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:12,013][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ computer] are: tensor([0.0013, 0.0403, 0.0298, 0.0440, 0.0316, 0.0311, 0.0479, 0.1153, 0.0578,
        0.1236, 0.0825, 0.0612, 0.3336], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:12,014][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ computer] are: tensor([0.0971, 0.0594, 0.0492, 0.0330, 0.0754, 0.0451, 0.0940, 0.2114, 0.0457,
        0.0524, 0.0817, 0.0368, 0.1189], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:12,017][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ computer] are: tensor([0.1904, 0.0259, 0.0159, 0.1053, 0.0588, 0.0426, 0.0511, 0.0350, 0.0970,
        0.0684, 0.0633, 0.0599, 0.1862], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:12,019][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ computer] are: tensor([1.2110e-03, 3.1944e-05, 6.3342e-04, 9.8260e-03, 4.8431e-03, 1.2152e-01,
        9.1963e-02, 5.6163e-02, 1.9916e-01, 4.8458e-02, 1.4129e-01, 1.7207e-01,
        1.5284e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:12,020][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ computer] are: tensor([0.5736, 0.0010, 0.0035, 0.0093, 0.0152, 0.0377, 0.0233, 0.0305, 0.1371,
        0.0184, 0.0594, 0.0502, 0.0407], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:12,021][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ computer] are: tensor([9.6602e-01, 5.9910e-03, 2.3488e-03, 8.1399e-04, 1.4358e-03, 1.2434e-03,
        1.0412e-03, 8.8558e-04, 1.1341e-03, 6.6742e-03, 4.6223e-03, 2.1504e-03,
        5.6398e-03], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:12,022][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ computer] are: tensor([0.6484, 0.0653, 0.0069, 0.0055, 0.0125, 0.0065, 0.0204, 0.1668, 0.0028,
        0.0246, 0.0062, 0.0061, 0.0279], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:12,025][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ computer] are: tensor([0.3581, 0.0727, 0.0678, 0.0195, 0.0509, 0.0823, 0.0519, 0.0685, 0.0851,
        0.0213, 0.0511, 0.0384, 0.0323], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:12,026][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ computer] are: tensor([0.0164, 0.0201, 0.0525, 0.0410, 0.0911, 0.0722, 0.0600, 0.1494, 0.0816,
        0.0635, 0.1129, 0.0942, 0.1452], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:12,027][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ computer] are: tensor([0.0589, 0.0020, 0.0114, 0.0292, 0.0190, 0.1032, 0.0729, 0.0508, 0.2462,
        0.0913, 0.0759, 0.1417, 0.0974], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:12,028][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ computer] are: tensor([0.0115, 0.0086, 0.0197, 0.0404, 0.0139, 0.1708, 0.1039, 0.0352, 0.2506,
        0.0929, 0.0489, 0.1365, 0.0671], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:12,029][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([6.2756e-01, 1.9119e-02, 3.5577e-04, 8.7182e-04, 2.9878e-02, 2.7758e-04,
        7.6572e-08, 3.1871e-03, 1.6836e-03, 2.3608e-01, 1.7797e-02, 4.5112e-07,
        6.2961e-02, 2.2655e-04], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:12,033][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0041, 0.0365, 0.0414, 0.0481, 0.0379, 0.0379, 0.0589, 0.0844, 0.1129,
        0.1680, 0.0612, 0.0513, 0.2195, 0.0378], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:12,033][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.2103, 0.0741, 0.0440, 0.0367, 0.0492, 0.0307, 0.0729, 0.1784, 0.0511,
        0.0451, 0.0635, 0.0335, 0.0860, 0.0244], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:12,034][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.3221, 0.0293, 0.0141, 0.0755, 0.0240, 0.0357, 0.0440, 0.0230, 0.1064,
        0.0370, 0.0315, 0.0636, 0.0809, 0.1129], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:12,035][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([7.7520e-03, 1.8390e-05, 2.9959e-04, 1.1939e-02, 1.3886e-03, 5.2246e-02,
        4.7563e-02, 2.2952e-02, 1.6451e-01, 3.9480e-02, 3.3359e-02, 6.9491e-02,
        1.4893e-01, 4.0007e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:12,039][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.7664, 0.0011, 0.0022, 0.0089, 0.0101, 0.0163, 0.0114, 0.0084, 0.0686,
        0.0134, 0.0235, 0.0193, 0.0185, 0.0318], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:12,040][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([9.9119e-01, 2.3946e-03, 6.3025e-04, 2.8508e-04, 4.4256e-04, 1.1926e-04,
        2.9860e-04, 3.8734e-04, 1.9212e-04, 1.0554e-03, 6.1030e-04, 4.9040e-04,
        1.6271e-03, 2.8044e-04], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:12,041][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.1640, 0.1223, 0.0078, 0.0170, 0.0219, 0.0108, 0.0497, 0.3726, 0.0076,
        0.0586, 0.0128, 0.0179, 0.0914, 0.0456], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:12,041][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0847, 0.0702, 0.0705, 0.0287, 0.0727, 0.1010, 0.0675, 0.0978, 0.1080,
        0.0346, 0.0739, 0.0522, 0.0508, 0.0872], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:12,044][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0235, 0.0133, 0.0386, 0.0464, 0.0797, 0.0606, 0.0438, 0.1658, 0.0504,
        0.0547, 0.0951, 0.0694, 0.1604, 0.0984], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:12,046][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.1247, 0.0014, 0.0067, 0.0222, 0.0067, 0.0730, 0.0490, 0.0249, 0.1937,
        0.0618, 0.0360, 0.0985, 0.0538, 0.2477], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:12,047][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0320, 0.0036, 0.0080, 0.0319, 0.0075, 0.0947, 0.0780, 0.0219, 0.1746,
        0.0575, 0.0244, 0.1499, 0.0650, 0.2511], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:12,051][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:20:12,054][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 4745],
        [ 6597],
        [  926],
        [27947],
        [ 1512],
        [  392],
        [  138],
        [   10],
        [  252],
        [  366],
        [   52],
        [  185],
        [    9],
        [  132]], device='cuda:0')
[2024-07-24 10:20:12,057][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 4789],
        [13666],
        [ 3846],
        [41545],
        [ 4420],
        [ 2362],
        [ 1251],
        [   49],
        [ 1883],
        [ 1598],
        [  487],
        [ 1465],
        [   38],
        [  959]], device='cuda:0')
[2024-07-24 10:20:12,058][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[ 9880],
        [18933],
        [14952],
        [15939],
        [19625],
        [18376],
        [15413],
        [16067],
        [15890],
        [16008],
        [16617],
        [13620],
        [14292],
        [13898]], device='cuda:0')
[2024-07-24 10:20:12,060][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[35831],
        [49813],
        [46789],
        [47943],
        [37491],
        [27442],
        [26041],
        [22365],
        [25910],
        [26749],
        [21145],
        [30757],
        [21333],
        [24552]], device='cuda:0')
[2024-07-24 10:20:12,061][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[12877],
        [18519],
        [14877],
        [16539],
        [15935],
        [14669],
        [14322],
        [13727],
        [14039],
        [15300],
        [16114],
        [15943],
        [15704],
        [15341]], device='cuda:0')
[2024-07-24 10:20:12,063][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[40512],
        [22538],
        [13531],
        [22524],
        [19710],
        [16192],
        [12946],
        [ 9481],
        [ 9291],
        [ 6946],
        [ 5782],
        [ 7050],
        [ 4709],
        [ 5468]], device='cuda:0')
[2024-07-24 10:20:12,065][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[18752],
        [ 8215],
        [ 9319],
        [ 8252],
        [ 9990],
        [11308],
        [10818],
        [10552],
        [11207],
        [ 9179],
        [11269],
        [10839],
        [10622],
        [11069]], device='cuda:0')
[2024-07-24 10:20:12,067][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[11646],
        [11083],
        [11366],
        [11494],
        [11451],
        [11361],
        [10766],
        [11168],
        [12022],
        [12285],
        [12995],
        [12891],
        [12551],
        [12018]], device='cuda:0')
[2024-07-24 10:20:12,068][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[18664],
        [48982],
        [47688],
        [47381],
        [46654],
        [42445],
        [41119],
        [33270],
        [38866],
        [34178],
        [30153],
        [31440],
        [24766],
        [26786]], device='cuda:0')
[2024-07-24 10:20:12,070][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[42936],
        [43741],
        [43407],
        [46098],
        [44876],
        [44438],
        [48637],
        [48547],
        [48117],
        [44856],
        [47585],
        [46817],
        [47379],
        [48024]], device='cuda:0')
[2024-07-24 10:20:12,073][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[12872],
        [ 3750],
        [10229],
        [ 6105],
        [16332],
        [12658],
        [17006],
        [17859],
        [17567],
        [17161],
        [18766],
        [17989],
        [18044],
        [16586]], device='cuda:0')
[2024-07-24 10:20:12,074][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[22971],
        [16013],
        [17655],
        [14269],
        [17216],
        [19298],
        [23156],
        [24321],
        [22693],
        [23859],
        [24314],
        [24874],
        [25683],
        [23989]], device='cuda:0')
[2024-07-24 10:20:12,075][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[12275],
        [ 1601],
        [ 3832],
        [ 2505],
        [ 3288],
        [ 3224],
        [ 2956],
        [ 2963],
        [ 3118],
        [ 2588],
        [ 2780],
        [ 2693],
        [ 2678],
        [ 2826]], device='cuda:0')
[2024-07-24 10:20:12,077][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[ 8291],
        [ 2568],
        [36543],
        [ 5652],
        [35984],
        [11860],
        [25235],
        [40246],
        [33419],
        [36725],
        [40649],
        [35551],
        [41469],
        [39049]], device='cuda:0')
[2024-07-24 10:20:12,080][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[9727],
        [6018],
        [3265],
        [4558],
        [3525],
        [4746],
        [4364],
        [5566],
        [4900],
        [6237],
        [5171],
        [6388],
        [6377],
        [6021]], device='cuda:0')
[2024-07-24 10:20:12,082][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[16822],
        [ 2593],
        [ 6412],
        [ 3659],
        [ 6852],
        [ 5317],
        [ 4627],
        [11484],
        [ 6257],
        [ 8038],
        [ 9079],
        [ 8040],
        [ 6205],
        [ 5592]], device='cuda:0')
[2024-07-24 10:20:12,083][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[ 474],
        [3526],
        [4330],
        [3289],
        [3889],
        [3377],
        [2442],
        [ 970],
        [1248],
        [1723],
        [2138],
        [3448],
        [ 376],
        [ 775]], device='cuda:0')
[2024-07-24 10:20:12,085][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[21754],
        [13681],
        [12433],
        [10120],
        [ 9912],
        [12110],
        [15800],
        [13485],
        [16424],
        [17666],
        [18122],
        [16457],
        [15587],
        [15668]], device='cuda:0')
[2024-07-24 10:20:12,088][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[30317],
        [29444],
        [27182],
        [30212],
        [30227],
        [25114],
        [21712],
        [19597],
        [19951],
        [21375],
        [20815],
        [20918],
        [23938],
        [22020]], device='cuda:0')
[2024-07-24 10:20:12,089][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[20580],
        [31395],
        [25897],
        [28064],
        [25816],
        [35273],
        [35471],
        [38584],
        [37614],
        [40573],
        [39983],
        [40219],
        [42509],
        [42127]], device='cuda:0')
[2024-07-24 10:20:12,090][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[31002],
        [30605],
        [30559],
        [27976],
        [25605],
        [28143],
        [26074],
        [27607],
        [25233],
        [24026],
        [23873],
        [24670],
        [26134],
        [24879]], device='cuda:0')
[2024-07-24 10:20:12,092][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[7546],
        [7547],
        [7543],
        [7456],
        [7536],
        [7545],
        [7550],
        [7577],
        [7561],
        [7601],
        [7668],
        [7749],
        [8068],
        [7780]], device='cuda:0')
[2024-07-24 10:20:12,095][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[13351],
        [13678],
        [14052],
        [13949],
        [14296],
        [13710],
        [11357],
        [ 5598],
        [ 4053],
        [ 6941],
        [ 5744],
        [ 4981],
        [ 8679],
        [ 5420]], device='cuda:0')
[2024-07-24 10:20:12,096][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[14868],
        [ 7170],
        [ 6574],
        [ 6250],
        [ 6447],
        [ 7993],
        [ 8274],
        [ 8431],
        [ 8861],
        [ 8265],
        [ 8570],
        [ 8467],
        [ 8526],
        [ 8739]], device='cuda:0')
[2024-07-24 10:20:12,098][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[14295],
        [ 7223],
        [13481],
        [11851],
        [12767],
        [12628],
        [12592],
        [13433],
        [13420],
        [12433],
        [11963],
        [11801],
        [11419],
        [11559]], device='cuda:0')
[2024-07-24 10:20:12,099][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[ 3234],
        [13289],
        [ 8081],
        [ 9311],
        [ 5174],
        [ 9574],
        [ 7748],
        [ 8534],
        [ 4767],
        [ 6285],
        [ 5294],
        [ 4773],
        [ 5818],
        [ 4822]], device='cuda:0')
[2024-07-24 10:20:12,102][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[42567],
        [46687],
        [48889],
        [48465],
        [46368],
        [48524],
        [47039],
        [45930],
        [47757],
        [48301],
        [48619],
        [48997],
        [49247],
        [49213]], device='cuda:0')
[2024-07-24 10:20:12,104][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[29928],
        [29384],
        [27191],
        [29008],
        [32582],
        [29693],
        [34047],
        [38415],
        [40330],
        [36633],
        [37685],
        [37896],
        [35127],
        [39032]], device='cuda:0')
[2024-07-24 10:20:12,105][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[34638],
        [35437],
        [36344],
        [36802],
        [38584],
        [34260],
        [32801],
        [31001],
        [33451],
        [32210],
        [32676],
        [30233],
        [31860],
        [33252]], device='cuda:0')
[2024-07-24 10:20:12,107][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[4831],
        [4831],
        [4831],
        [4831],
        [4831],
        [4831],
        [4831],
        [4831],
        [4831],
        [4831],
        [4831],
        [4831],
        [4831],
        [4831]], device='cuda:0')
[2024-07-24 10:20:12,202][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:20:12,203][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:12,203][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:12,204][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:12,204][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:12,204][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:12,205][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:12,205][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:12,206][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:12,209][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:12,209][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:12,210][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:12,210][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:12,210][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Benjamin] are: tensor([0.1415, 0.8585], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:12,211][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Benjamin] are: tensor([0.0058, 0.9942], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:12,211][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Benjamin] are: tensor([0.0971, 0.9029], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:12,211][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Benjamin] are: tensor([0.7034, 0.2966], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:12,212][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Benjamin] are: tensor([0.0044, 0.9956], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:12,214][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Benjamin] are: tensor([0.2135, 0.7865], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:12,216][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Benjamin] are: tensor([0.0018, 0.9982], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:12,216][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Benjamin] are: tensor([0.0140, 0.9860], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:12,217][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Benjamin] are: tensor([0.3919, 0.6081], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:12,217][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Benjamin] are: tensor([0.0014, 0.9986], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:12,217][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Benjamin] are: tensor([0.2938, 0.7062], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:12,218][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Benjamin] are: tensor([0.4829, 0.5171], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:12,218][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0663, 0.5924, 0.3413], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:12,218][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0086, 0.5611, 0.4303], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:12,219][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.2654, 0.4715, 0.2631], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:12,223][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.2208, 0.0027, 0.7765], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:12,223][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0154, 0.3878, 0.5969], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:12,223][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.3227, 0.1771, 0.5002], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:12,224][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ and] are: tensor([4.6914e-04, 2.1676e-01, 7.8277e-01], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:12,224][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0156, 0.1306, 0.8538], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:12,224][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0514, 0.2066, 0.7419], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:12,225][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ and] are: tensor([1.6780e-04, 2.3167e-01, 7.6816e-01], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:12,225][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ and] are: tensor([3.0573e-02, 7.9358e-04, 9.6863e-01], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:12,225][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.7247, 0.2332, 0.0421], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:12,227][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Alexander] are: tensor([0.0112, 0.0392, 0.0402, 0.9095], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:12,229][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Alexander] are: tensor([0.0067, 0.4450, 0.1791, 0.3692], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:12,230][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Alexander] are: tensor([0.1270, 0.3813, 0.1524, 0.3394], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:12,230][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Alexander] are: tensor([0.3132, 0.0090, 0.0293, 0.6485], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:12,230][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Alexander] are: tensor([0.0054, 0.1019, 0.2017, 0.6910], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:12,231][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Alexander] are: tensor([0.0951, 0.0959, 0.1147, 0.6942], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:12,231][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Alexander] are: tensor([3.1626e-04, 1.2022e-01, 4.0882e-01, 4.7064e-01], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:12,231][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Alexander] are: tensor([0.0724, 0.2198, 0.1493, 0.5584], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:12,232][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Alexander] are: tensor([0.0402, 0.0683, 0.2843, 0.6071], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:12,233][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Alexander] are: tensor([7.8632e-05, 1.3533e-01, 8.2261e-01, 4.1980e-02], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:12,236][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Alexander] are: tensor([9.7303e-03, 9.6558e-04, 1.9363e-02, 9.6994e-01], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:12,236][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Alexander] are: tensor([0.0421, 0.1449, 0.1673, 0.6458], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:12,237][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ went] are: tensor([0.0224, 0.0088, 0.0547, 0.7630, 0.1511], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:12,237][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ went] are: tensor([0.0052, 0.2047, 0.1768, 0.4681, 0.1452], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:12,237][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ went] are: tensor([0.0685, 0.0732, 0.1506, 0.3023, 0.4053], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:12,238][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ went] are: tensor([1.0630e-02, 6.0115e-05, 5.8774e-03, 9.6003e-01, 2.3403e-02],
       device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:12,238][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ went] are: tensor([0.0086, 0.0251, 0.1390, 0.2549, 0.5723], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:12,238][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ went] are: tensor([0.1945, 0.0393, 0.0887, 0.4778, 0.1996], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:12,239][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ went] are: tensor([1.1213e-04, 3.4539e-02, 1.8655e-01, 2.3791e-01, 5.4089e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:12,241][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ went] are: tensor([0.0030, 0.0067, 0.1275, 0.4092, 0.4536], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:12,243][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.0503, 0.0347, 0.2120, 0.5675, 0.1355], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:12,243][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ went] are: tensor([5.8257e-05, 1.4543e-01, 5.5313e-01, 7.6279e-02, 2.2511e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:12,243][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ went] are: tensor([3.8201e-04, 1.3392e-05, 9.5408e-03, 9.0929e-01, 8.0770e-02],
       device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:12,244][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ went] are: tensor([0.0731, 0.0983, 0.1231, 0.3921, 0.3133], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:12,244][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0543, 0.0233, 0.0190, 0.7451, 0.0405, 0.1178], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:12,245][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0068, 0.1524, 0.1397, 0.3674, 0.1010, 0.2326], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:12,245][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.2644, 0.1071, 0.0610, 0.1986, 0.1069, 0.2620], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:12,245][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ to] are: tensor([7.4945e-02, 7.8772e-06, 8.8348e-05, 2.5183e-01, 6.6665e-04, 6.7246e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:12,248][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0035, 0.0300, 0.0830, 0.2291, 0.3168, 0.3376], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:12,250][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.1461, 0.0121, 0.0261, 0.2254, 0.0559, 0.5345], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:12,250][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ to] are: tensor([5.6432e-05, 3.9421e-02, 1.1674e-01, 2.8080e-01, 1.7921e-01, 3.8377e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:12,250][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0105, 0.0058, 0.0199, 0.3804, 0.0974, 0.4859], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:12,251][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0722, 0.0372, 0.0807, 0.5909, 0.1594, 0.0596], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:12,251][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ to] are: tensor([7.5464e-06, 2.8814e-02, 2.9521e-01, 3.2698e-02, 2.0304e-01, 4.4023e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:12,251][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ to] are: tensor([7.6769e-04, 4.7783e-07, 3.2551e-05, 6.0645e-02, 3.5578e-04, 9.3820e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:12,252][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.1799, 0.1382, 0.0386, 0.4045, 0.1712, 0.0677], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:12,252][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0124, 0.0072, 0.0135, 0.5811, 0.0576, 0.1765, 0.1517],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:12,254][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0063, 0.0890, 0.1026, 0.2483, 0.1215, 0.2084, 0.2239],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:12,256][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0518, 0.0320, 0.0490, 0.1293, 0.0978, 0.3135, 0.3267],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:12,257][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ the] are: tensor([1.1816e-02, 4.7866e-06, 6.5051e-05, 1.6455e-01, 6.3203e-04, 6.6353e-01,
        1.5940e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:12,257][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0013, 0.0298, 0.0334, 0.1762, 0.3249, 0.3279, 0.1065],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:12,257][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0629, 0.0047, 0.0201, 0.1535, 0.0445, 0.4889, 0.2253],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:12,258][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ the] are: tensor([1.9285e-05, 2.2303e-02, 6.4329e-02, 1.6809e-01, 1.7277e-01, 3.8658e-01,
        1.8591e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:12,258][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0057, 0.0026, 0.0185, 0.1795, 0.0817, 0.4285, 0.2836],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:12,258][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0277, 0.0279, 0.0902, 0.5658, 0.0978, 0.0857, 0.1050],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:12,259][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ the] are: tensor([1.9551e-06, 1.0138e-02, 1.6263e-01, 2.4943e-02, 1.4658e-01, 4.3689e-01,
        2.1882e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:12,260][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ the] are: tensor([7.5700e-05, 2.2180e-07, 2.0946e-05, 2.7378e-02, 2.5693e-04, 7.2429e-01,
        2.4798e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:12,266][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0772, 0.0827, 0.0434, 0.2870, 0.2315, 0.1633, 0.1148],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:12,266][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ station] are: tensor([0.0218, 0.0013, 0.0050, 0.2996, 0.0138, 0.0834, 0.0685, 0.5065],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:12,266][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ station] are: tensor([0.0032, 0.1071, 0.0858, 0.2883, 0.0631, 0.1721, 0.1485, 0.1319],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:12,267][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ station] are: tensor([0.0722, 0.0096, 0.0191, 0.1037, 0.0675, 0.2219, 0.3033, 0.2028],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:12,267][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ station] are: tensor([5.2307e-02, 6.9590e-06, 8.8201e-05, 7.1711e-02, 5.1638e-04, 4.9870e-01,
        1.6167e-01, 2.1500e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:12,267][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ station] are: tensor([0.0014, 0.0309, 0.0668, 0.1450, 0.1856, 0.3168, 0.0926, 0.1611],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:12,268][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ station] are: tensor([0.0755, 0.0031, 0.0120, 0.1013, 0.0424, 0.2808, 0.1627, 0.3222],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:12,268][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ station] are: tensor([5.6498e-05, 1.5608e-02, 6.9896e-02, 1.2931e-01, 1.0658e-01, 3.4792e-01,
        1.8005e-01, 1.5057e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:12,269][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ station] are: tensor([0.0034, 0.0007, 0.0066, 0.0718, 0.0339, 0.1872, 0.1888, 0.5076],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:12,269][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ station] are: tensor([0.1049, 0.0102, 0.0540, 0.2705, 0.0675, 0.0674, 0.0588, 0.3668],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:12,270][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ station] are: tensor([4.3256e-05, 5.7538e-02, 2.2968e-01, 1.3896e-01, 1.4754e-01, 1.9063e-01,
        1.1018e-01, 1.2543e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:12,273][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ station] are: tensor([1.4985e-04, 2.3796e-07, 2.7094e-05, 1.6984e-02, 3.5181e-04, 6.7759e-01,
        2.0581e-01, 9.9094e-02], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:12,273][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ station] are: tensor([0.0237, 0.0267, 0.0207, 0.1082, 0.1373, 0.0564, 0.1038, 0.5233],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:12,274][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0074, 0.0076, 0.0123, 0.5336, 0.0227, 0.0852, 0.1019, 0.0763, 0.1530],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:12,274][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0034, 0.0680, 0.0802, 0.1950, 0.0466, 0.1543, 0.1111, 0.1402, 0.2012],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:12,274][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0295, 0.0281, 0.0225, 0.1159, 0.0450, 0.1619, 0.1597, 0.0724, 0.3649],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:12,275][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [,] are: tensor([1.1578e-02, 2.3133e-06, 2.1961e-05, 7.4573e-02, 1.1920e-04, 1.2285e-01,
        3.9407e-02, 6.5770e-02, 6.8568e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:12,275][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0006, 0.0230, 0.0626, 0.1584, 0.1902, 0.2009, 0.0980, 0.0851, 0.1812],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:12,276][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0301, 0.0059, 0.0204, 0.1867, 0.0381, 0.3127, 0.1486, 0.1366, 0.1208],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:12,277][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [,] are: tensor([1.8675e-05, 1.7279e-02, 5.6935e-02, 1.1897e-01, 4.3930e-02, 3.0223e-01,
        1.6723e-01, 1.2190e-01, 1.7151e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:12,280][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0035, 0.0014, 0.0050, 0.0932, 0.0245, 0.1131, 0.1055, 0.3336, 0.3203],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:12,280][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0105, 0.0379, 0.0491, 0.3676, 0.0646, 0.0227, 0.0716, 0.2006, 0.1752],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:12,281][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [,] are: tensor([5.5481e-06, 2.7397e-02, 1.3872e-01, 3.3702e-02, 8.5863e-02, 2.2630e-01,
        1.4758e-01, 6.3046e-02, 2.7739e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:12,281][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [,] are: tensor([1.4744e-04, 1.9080e-07, 1.0179e-05, 2.4659e-02, 1.0424e-04, 3.1604e-01,
        1.0334e-01, 3.6511e-02, 5.1919e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:12,281][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0714, 0.0291, 0.0042, 0.1796, 0.1613, 0.0202, 0.0298, 0.4947, 0.0098],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:12,282][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Benjamin] are: tensor([0.0098, 0.0109, 0.0108, 0.3765, 0.0334, 0.0470, 0.0440, 0.1548, 0.1048,
        0.2079], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:12,282][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Benjamin] are: tensor([0.0045, 0.0861, 0.0710, 0.1899, 0.0278, 0.0920, 0.0919, 0.1129, 0.2192,
        0.1049], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:12,285][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Benjamin] are: tensor([0.0209, 0.0152, 0.0132, 0.0410, 0.0475, 0.1346, 0.1514, 0.1752, 0.3159,
        0.0851], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:12,287][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Benjamin] are: tensor([3.1796e-02, 7.1401e-05, 4.7594e-05, 6.5117e-02, 3.0044e-04, 4.9019e-02,
        1.5791e-02, 9.7331e-02, 2.1486e-01, 5.2567e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:12,287][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Benjamin] are: tensor([0.0025, 0.0340, 0.0616, 0.1305, 0.1453, 0.2378, 0.1028, 0.1040, 0.1079,
        0.0735], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:12,287][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Benjamin] are: tensor([0.0426, 0.0099, 0.0176, 0.1450, 0.0485, 0.1751, 0.0958, 0.1305, 0.0658,
        0.2692], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:12,288][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Benjamin] are: tensor([2.5755e-05, 1.1713e-02, 3.9214e-02, 9.4065e-02, 7.2254e-02, 1.6438e-01,
        8.5254e-02, 2.0314e-01, 1.2331e-01, 2.0664e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:12,288][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Benjamin] are: tensor([0.0053, 0.0067, 0.0103, 0.0854, 0.0252, 0.0620, 0.0648, 0.3968, 0.2102,
        0.1335], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:12,289][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Benjamin] are: tensor([0.0222, 0.0303, 0.0489, 0.1687, 0.0702, 0.0305, 0.0643, 0.2423, 0.2547,
        0.0679], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:12,289][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Benjamin] are: tensor([3.4421e-06, 2.0667e-02, 1.5333e-01, 2.6505e-02, 1.1188e-01, 1.1616e-01,
        1.2636e-01, 4.4699e-02, 1.8705e-01, 2.1334e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:12,291][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Benjamin] are: tensor([3.1363e-04, 1.7206e-06, 1.3395e-05, 1.5825e-02, 1.3925e-04, 1.6875e-01,
        4.8778e-02, 4.6287e-02, 2.0735e-01, 5.1255e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:12,293][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Benjamin] are: tensor([0.0078, 0.0071, 0.0324, 0.0757, 0.1098, 0.0630, 0.0795, 0.5463, 0.0592,
        0.0192], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:12,294][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.0084, 0.0038, 0.0081, 0.2552, 0.0113, 0.1057, 0.0866, 0.0758, 0.1560,
        0.1417, 0.1474], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:12,294][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0032, 0.0347, 0.0500, 0.1169, 0.0338, 0.1222, 0.0967, 0.1024, 0.2534,
        0.0955, 0.0912], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:12,295][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0120, 0.0102, 0.0137, 0.0536, 0.0295, 0.1481, 0.1393, 0.0825, 0.2662,
        0.0548, 0.1901], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:12,295][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([1.0747e-03, 1.8611e-07, 8.4135e-06, 8.4648e-03, 2.3301e-05, 6.6820e-02,
        1.5826e-02, 2.0825e-02, 5.0549e-01, 3.7535e-01, 6.1263e-03],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:12,295][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.0026, 0.0191, 0.0541, 0.1081, 0.1368, 0.1789, 0.1058, 0.0622, 0.1137,
        0.0573, 0.1613], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:12,296][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.0223, 0.0044, 0.0111, 0.1048, 0.0225, 0.2516, 0.1160, 0.0921, 0.0660,
        0.2091, 0.1000], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:12,297][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([4.7521e-05, 2.2201e-02, 4.8865e-02, 1.0415e-01, 6.3933e-02, 1.4389e-01,
        1.1689e-01, 1.4046e-01, 1.1805e-01, 1.0398e-01, 1.3754e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:12,300][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([5.7627e-04, 1.9805e-04, 2.1165e-03, 1.9279e-02, 8.6445e-03, 9.3426e-02,
        8.1008e-02, 1.6167e-01, 2.8670e-01, 1.3242e-01, 2.1396e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:12,300][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.0116, 0.0117, 0.0369, 0.1492, 0.0442, 0.0308, 0.0993, 0.2104, 0.1989,
        0.0638, 0.1433], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:12,301][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([4.2847e-06, 1.6522e-02, 1.3101e-01, 3.3254e-02, 4.8613e-02, 8.9301e-02,
        6.1156e-02, 3.5402e-02, 2.2107e-01, 3.0594e-01, 5.7734e-02],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:12,301][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([1.7877e-05, 2.4090e-08, 3.6814e-06, 2.9041e-03, 4.9365e-05, 2.2063e-01,
        5.0562e-02, 2.0750e-02, 2.9439e-01, 3.8133e-01, 2.9358e-02],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:12,302][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0088, 0.0305, 0.0243, 0.0555, 0.0664, 0.0315, 0.0744, 0.5689, 0.0172,
        0.0580, 0.0644], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:12,302][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0161, 0.0042, 0.0087, 0.3103, 0.0212, 0.0698, 0.0918, 0.0767, 0.1319,
        0.1118, 0.1005, 0.0568], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:12,302][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0037, 0.0433, 0.0368, 0.1124, 0.0291, 0.0872, 0.0899, 0.1168, 0.1912,
        0.0898, 0.1077, 0.0921], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:12,303][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0274, 0.0073, 0.0198, 0.0864, 0.0502, 0.1270, 0.1204, 0.0667, 0.2142,
        0.0463, 0.1344, 0.1000], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:12,304][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ a] are: tensor([3.9814e-03, 6.4231e-07, 4.6061e-06, 2.2089e-02, 2.4313e-05, 3.5261e-02,
        9.1088e-03, 1.4536e-02, 2.1227e-01, 6.5207e-01, 5.0799e-03, 4.5566e-02],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:12,307][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0014, 0.0104, 0.0326, 0.1078, 0.1202, 0.1526, 0.1089, 0.0841, 0.0915,
        0.0303, 0.1696, 0.0906], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:12,308][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0596, 0.0032, 0.0094, 0.0927, 0.0277, 0.2259, 0.0984, 0.0837, 0.0492,
        0.1728, 0.0888, 0.0884], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:12,308][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ a] are: tensor([2.6117e-05, 8.1725e-03, 3.4376e-02, 4.8859e-02, 4.0538e-02, 1.9073e-01,
        1.3022e-01, 8.7817e-02, 1.0244e-01, 8.3889e-02, 1.3838e-01, 1.3455e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:12,308][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0041, 0.0005, 0.0029, 0.0465, 0.0117, 0.0709, 0.0614, 0.1798, 0.2668,
        0.1284, 0.1662, 0.0607], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:12,309][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0224, 0.0184, 0.0263, 0.2110, 0.0303, 0.0238, 0.0490, 0.1208, 0.2077,
        0.0974, 0.1386, 0.0544], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:12,309][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ a] are: tensor([2.1335e-06, 8.0403e-03, 7.0148e-02, 1.5984e-02, 5.3315e-02, 1.0825e-01,
        8.5001e-02, 3.3992e-02, 1.4548e-01, 2.3833e-01, 7.9960e-02, 1.6149e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:12,310][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ a] are: tensor([4.1601e-05, 4.4225e-08, 3.4548e-06, 6.2337e-03, 2.5092e-05, 8.9804e-02,
        2.8465e-02, 1.4913e-02, 2.0524e-01, 5.0842e-01, 2.3633e-02, 1.2322e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:12,312][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0242, 0.0257, 0.0037, 0.0352, 0.0089, 0.0163, 0.0138, 0.7790, 0.0086,
        0.0646, 0.0123, 0.0077], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:12,314][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ computer] are: tensor([0.0028, 0.0021, 0.0027, 0.2287, 0.0125, 0.0424, 0.0360, 0.0762, 0.0760,
        0.0940, 0.0746, 0.0142, 0.3378], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:12,314][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ computer] are: tensor([0.0007, 0.0265, 0.0380, 0.0988, 0.0290, 0.0927, 0.0680, 0.1055, 0.1559,
        0.0786, 0.1264, 0.0932, 0.0868], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:12,315][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ computer] are: tensor([0.0085, 0.0083, 0.0096, 0.0456, 0.0269, 0.0616, 0.0647, 0.0473, 0.0866,
        0.0288, 0.0759, 0.0561, 0.4800], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:12,315][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ computer] are: tensor([1.0697e-02, 5.2792e-06, 7.7418e-06, 1.9145e-02, 3.4130e-05, 2.0561e-02,
        5.9037e-03, 2.7337e-02, 1.0813e-01, 1.7603e-01, 6.2801e-03, 3.2184e-02,
        5.9369e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:12,316][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ computer] are: tensor([0.0011, 0.0249, 0.0639, 0.1421, 0.1317, 0.2031, 0.0618, 0.0430, 0.0816,
        0.0342, 0.0931, 0.0576, 0.0619], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:12,316][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ computer] are: tensor([0.0204, 0.0055, 0.0099, 0.0819, 0.0188, 0.1739, 0.0605, 0.0641, 0.0396,
        0.1354, 0.0973, 0.0444, 0.2483], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:12,316][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ computer] are: tensor([7.2828e-06, 7.5691e-03, 2.3856e-02, 4.2819e-02, 2.7289e-02, 9.6721e-02,
        4.8794e-02, 6.3968e-02, 8.2807e-02, 1.1852e-01, 2.4488e-01, 9.5274e-02,
        1.4749e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:12,320][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ computer] are: tensor([0.0037, 0.0022, 0.0043, 0.0519, 0.0169, 0.0499, 0.0454, 0.1865, 0.1443,
        0.1178, 0.1925, 0.0428, 0.1418], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:12,321][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ computer] are: tensor([0.0174, 0.0757, 0.0323, 0.2464, 0.0322, 0.0182, 0.0279, 0.1296, 0.1595,
        0.0830, 0.0945, 0.0238, 0.0597], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:12,321][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ computer] are: tensor([6.5162e-07, 2.5376e-02, 7.5914e-02, 1.8972e-02, 4.6339e-02, 7.1193e-02,
        3.4631e-02, 3.3345e-02, 1.1627e-01, 3.0026e-01, 1.0279e-01, 1.4157e-01,
        3.3339e-02], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:12,321][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ computer] are: tensor([1.6218e-04, 2.8195e-07, 3.0067e-06, 5.0637e-03, 8.0990e-05, 6.9948e-02,
        1.7530e-02, 3.2917e-02, 9.9195e-02, 2.0126e-01, 3.6947e-02, 6.0095e-02,
        4.7680e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:12,322][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ computer] are: tensor([0.0178, 0.0210, 0.0250, 0.0915, 0.1209, 0.0194, 0.0395, 0.2556, 0.0243,
        0.0233, 0.0535, 0.0205, 0.2875], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:12,322][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0195, 0.0060, 0.0033, 0.3168, 0.0090, 0.0267, 0.0319, 0.0741, 0.0668,
        0.0729, 0.0486, 0.0164, 0.2441, 0.0640], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:12,323][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0024, 0.0349, 0.0505, 0.1004, 0.0205, 0.0840, 0.0619, 0.0644, 0.1128,
        0.0341, 0.0799, 0.0584, 0.0577, 0.2381], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:12,324][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0721, 0.0213, 0.0102, 0.0653, 0.0177, 0.0328, 0.0445, 0.0331, 0.1271,
        0.0254, 0.0581, 0.0315, 0.3484, 0.1126], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:12,327][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ to] are: tensor([9.5961e-03, 5.6387e-07, 6.3865e-07, 7.7219e-03, 2.6600e-06, 3.4527e-03,
        1.7430e-03, 1.7475e-03, 3.8442e-02, 1.3107e-01, 5.8714e-04, 1.1283e-02,
        3.2227e-01, 4.7208e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:12,327][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0021, 0.0057, 0.0252, 0.0584, 0.0538, 0.1088, 0.0629, 0.0516, 0.1098,
        0.0256, 0.1660, 0.0674, 0.0519, 0.2109], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:12,328][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0540, 0.0038, 0.0067, 0.0725, 0.0141, 0.1612, 0.0646, 0.0456, 0.0349,
        0.1575, 0.0697, 0.0578, 0.1386, 0.1187], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:12,328][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ to] are: tensor([1.5361e-05, 9.3103e-03, 2.0461e-02, 5.0813e-02, 2.3710e-02, 8.9935e-02,
        5.1704e-02, 6.3635e-02, 8.8956e-02, 6.1394e-02, 7.7338e-02, 7.2015e-02,
        1.8598e-01, 2.0474e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:12,329][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0093, 0.0006, 0.0016, 0.0346, 0.0039, 0.0289, 0.0299, 0.1025, 0.1623,
        0.0855, 0.0610, 0.0318, 0.1620, 0.2859], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:12,329][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0401, 0.0363, 0.0227, 0.2342, 0.0303, 0.0152, 0.0251, 0.1606, 0.1678,
        0.0812, 0.0877, 0.0223, 0.0522, 0.0241], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:12,330][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ to] are: tensor([1.0357e-06, 1.1371e-02, 5.5988e-02, 1.6813e-02, 2.4672e-02, 6.4573e-02,
        4.1221e-02, 1.2073e-02, 1.0355e-01, 1.4995e-01, 2.7319e-02, 7.6763e-02,
        1.2892e-02, 4.0281e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:12,330][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ to] are: tensor([1.0036e-04, 1.7315e-08, 2.2973e-07, 1.8830e-03, 2.8053e-06, 7.0837e-03,
        3.5400e-03, 1.4428e-03, 3.2138e-02, 9.6263e-02, 2.1592e-03, 1.3986e-02,
        2.1072e-01, 6.3068e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:12,334][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0275, 0.0269, 0.0048, 0.0521, 0.0142, 0.0093, 0.0196, 0.2940, 0.0085,
        0.0448, 0.0292, 0.0121, 0.4290, 0.0279], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:12,380][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:20:12,381][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:12,381][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:12,382][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:12,383][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:12,383][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:12,384][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:12,385][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:12,385][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:12,386][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:12,387][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:12,387][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:12,388][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:12,391][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Benjamin] are: tensor([0.1415, 0.8585], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:12,392][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Benjamin] are: tensor([0.0058, 0.9942], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:12,392][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Benjamin] are: tensor([0.0971, 0.9029], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:12,393][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Benjamin] are: tensor([0.7034, 0.2966], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:12,395][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Benjamin] are: tensor([0.0044, 0.9956], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:12,398][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Benjamin] are: tensor([0.2135, 0.7865], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:12,398][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Benjamin] are: tensor([0.0018, 0.9982], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:12,399][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Benjamin] are: tensor([0.0140, 0.9860], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:12,400][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Benjamin] are: tensor([0.3919, 0.6081], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:12,402][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Benjamin] are: tensor([0.0024, 0.9976], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:12,404][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Benjamin] are: tensor([0.2938, 0.7062], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:12,405][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Benjamin] are: tensor([0.1602, 0.8398], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:12,406][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0663, 0.5924, 0.3413], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:12,407][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0086, 0.5611, 0.4303], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:12,409][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.2654, 0.4715, 0.2631], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:12,411][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.2208, 0.0027, 0.7765], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:12,412][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0154, 0.3878, 0.5969], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:12,413][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.3227, 0.1771, 0.5002], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:12,413][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([4.6914e-04, 2.1676e-01, 7.8277e-01], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:12,416][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0156, 0.1306, 0.8538], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:12,418][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0514, 0.2066, 0.7419], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:12,419][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([2.2751e-04, 2.5135e-01, 7.4842e-01], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:12,419][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([3.0573e-02, 7.9358e-04, 9.6863e-01], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:12,420][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.1008, 0.4119, 0.4873], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:12,423][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Alexander] are: tensor([0.0112, 0.0392, 0.0402, 0.9095], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:12,425][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Alexander] are: tensor([0.0067, 0.4450, 0.1791, 0.3692], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:12,426][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Alexander] are: tensor([0.1270, 0.3813, 0.1524, 0.3394], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:12,426][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Alexander] are: tensor([0.3132, 0.0090, 0.0293, 0.6485], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:12,427][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Alexander] are: tensor([0.0054, 0.1019, 0.2017, 0.6910], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:12,430][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Alexander] are: tensor([0.0951, 0.0959, 0.1147, 0.6942], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:12,432][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Alexander] are: tensor([3.1626e-04, 1.2022e-01, 4.0882e-01, 4.7064e-01], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:12,432][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Alexander] are: tensor([0.0724, 0.2198, 0.1493, 0.5584], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:12,433][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Alexander] are: tensor([0.0402, 0.0683, 0.2843, 0.6071], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:12,434][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Alexander] are: tensor([1.6516e-04, 8.4321e-02, 7.9622e-01, 1.1929e-01], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:12,435][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Alexander] are: tensor([9.7303e-03, 9.6558e-04, 1.9363e-02, 9.6994e-01], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:12,438][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Alexander] are: tensor([0.0611, 0.3172, 0.1638, 0.4580], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:12,439][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([0.0224, 0.0088, 0.0547, 0.7630, 0.1511], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:12,440][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([0.0052, 0.2047, 0.1768, 0.4681, 0.1452], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:12,440][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([0.0685, 0.0732, 0.1506, 0.3023, 0.4053], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:12,442][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([1.0630e-02, 6.0115e-05, 5.8774e-03, 9.6003e-01, 2.3403e-02],
       device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:12,445][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([0.0086, 0.0251, 0.1390, 0.2549, 0.5723], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:12,446][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([0.1945, 0.0393, 0.0887, 0.4778, 0.1996], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:12,446][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([1.1213e-04, 3.4539e-02, 1.8655e-01, 2.3791e-01, 5.4089e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:12,447][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([0.0030, 0.0067, 0.1275, 0.4092, 0.4536], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:12,450][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([0.0503, 0.0347, 0.2120, 0.5675, 0.1355], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:12,452][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([1.4469e-04, 7.5827e-02, 4.3959e-01, 1.4416e-01, 3.4028e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:12,452][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([3.8201e-04, 1.3392e-05, 9.5408e-03, 9.0929e-01, 8.0770e-02],
       device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:12,453][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([0.0090, 0.2430, 0.1775, 0.3024, 0.2681], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:12,454][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0543, 0.0233, 0.0190, 0.7451, 0.0405, 0.1178], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:12,457][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0068, 0.1524, 0.1397, 0.3674, 0.1010, 0.2326], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:12,458][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.2644, 0.1071, 0.0610, 0.1986, 0.1069, 0.2620], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:12,459][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([7.4945e-02, 7.8772e-06, 8.8348e-05, 2.5183e-01, 6.6665e-04, 6.7246e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:12,460][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0035, 0.0300, 0.0830, 0.2291, 0.3168, 0.3376], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:12,461][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.1461, 0.0121, 0.0261, 0.2254, 0.0559, 0.5345], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:12,462][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([5.6432e-05, 3.9421e-02, 1.1674e-01, 2.8080e-01, 1.7921e-01, 3.8377e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:12,465][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0105, 0.0058, 0.0199, 0.3804, 0.0974, 0.4859], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:12,466][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0722, 0.0372, 0.0807, 0.5909, 0.1594, 0.0596], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:12,467][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([1.3912e-05, 1.7702e-02, 1.3386e-01, 6.3025e-02, 1.5046e-01, 6.3494e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:12,467][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([7.6769e-04, 4.7783e-07, 3.2551e-05, 6.0645e-02, 3.5578e-04, 9.3820e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:12,470][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0325, 0.1761, 0.1168, 0.1908, 0.2361, 0.2477], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:12,472][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0124, 0.0072, 0.0135, 0.5811, 0.0576, 0.1765, 0.1517],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:12,473][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0063, 0.0890, 0.1026, 0.2483, 0.1215, 0.2084, 0.2239],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:12,473][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0518, 0.0320, 0.0490, 0.1293, 0.0978, 0.3135, 0.3267],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:12,474][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([1.1816e-02, 4.7866e-06, 6.5051e-05, 1.6455e-01, 6.3203e-04, 6.6353e-01,
        1.5940e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:12,478][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0013, 0.0298, 0.0334, 0.1762, 0.3249, 0.3279, 0.1065],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:12,481][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.0629, 0.0047, 0.0201, 0.1535, 0.0445, 0.4889, 0.2253],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:12,482][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([1.9285e-05, 2.2303e-02, 6.4329e-02, 1.6809e-01, 1.7277e-01, 3.8658e-01,
        1.8591e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:12,483][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0057, 0.0026, 0.0185, 0.1795, 0.0817, 0.4285, 0.2836],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:12,483][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0277, 0.0279, 0.0902, 0.5658, 0.0978, 0.0857, 0.1050],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:12,484][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([3.9342e-06, 7.5959e-03, 8.1282e-02, 4.3144e-02, 1.1575e-01, 5.3332e-01,
        2.1890e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:12,486][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([7.5700e-05, 2.2180e-07, 2.0946e-05, 2.7378e-02, 2.5693e-04, 7.2429e-01,
        2.4798e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:12,489][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0240, 0.1038, 0.0901, 0.2334, 0.1845, 0.1737, 0.1906],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:12,489][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ station] are: tensor([0.0218, 0.0013, 0.0050, 0.2996, 0.0138, 0.0834, 0.0685, 0.5065],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:12,490][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ station] are: tensor([0.0032, 0.1071, 0.0858, 0.2883, 0.0631, 0.1721, 0.1485, 0.1319],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:12,491][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ station] are: tensor([0.0722, 0.0096, 0.0191, 0.1037, 0.0675, 0.2219, 0.3033, 0.2028],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:12,493][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ station] are: tensor([5.2307e-02, 6.9590e-06, 8.8201e-05, 7.1711e-02, 5.1638e-04, 4.9870e-01,
        1.6167e-01, 2.1500e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:12,495][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ station] are: tensor([0.0014, 0.0309, 0.0668, 0.1450, 0.1856, 0.3168, 0.0926, 0.1611],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:12,496][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ station] are: tensor([0.0755, 0.0031, 0.0120, 0.1013, 0.0424, 0.2808, 0.1627, 0.3222],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:12,497][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ station] are: tensor([5.6498e-05, 1.5608e-02, 6.9896e-02, 1.2931e-01, 1.0658e-01, 3.4792e-01,
        1.8005e-01, 1.5057e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:12,498][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ station] are: tensor([0.0034, 0.0007, 0.0066, 0.0718, 0.0339, 0.1872, 0.1888, 0.5076],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:12,500][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ station] are: tensor([0.1049, 0.0102, 0.0540, 0.2705, 0.0675, 0.0674, 0.0588, 0.3668],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:12,502][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ station] are: tensor([6.1949e-05, 1.9909e-02, 1.3927e-01, 1.5462e-01, 9.7709e-02, 3.2177e-01,
        1.1185e-01, 1.5481e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:12,503][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ station] are: tensor([1.4985e-04, 2.3796e-07, 2.7094e-05, 1.6984e-02, 3.5181e-04, 6.7759e-01,
        2.0581e-01, 9.9094e-02], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:12,504][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ station] are: tensor([0.0105, 0.1598, 0.0687, 0.1443, 0.1348, 0.1311, 0.1377, 0.2131],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:12,505][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0074, 0.0076, 0.0123, 0.5336, 0.0227, 0.0852, 0.1019, 0.0763, 0.1530],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:12,508][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0034, 0.0680, 0.0802, 0.1950, 0.0466, 0.1543, 0.1111, 0.1402, 0.2012],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:12,509][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0295, 0.0281, 0.0225, 0.1159, 0.0450, 0.1619, 0.1597, 0.0724, 0.3649],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:12,510][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([1.1578e-02, 2.3133e-06, 2.1961e-05, 7.4573e-02, 1.1920e-04, 1.2285e-01,
        3.9407e-02, 6.5770e-02, 6.8568e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:12,511][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0006, 0.0230, 0.0626, 0.1584, 0.1902, 0.2009, 0.0980, 0.0851, 0.1812],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:12,511][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0301, 0.0059, 0.0204, 0.1867, 0.0381, 0.3127, 0.1486, 0.1366, 0.1208],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:12,513][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([1.8675e-05, 1.7279e-02, 5.6935e-02, 1.1897e-01, 4.3930e-02, 3.0223e-01,
        1.6723e-01, 1.2190e-01, 1.7151e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:12,516][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0035, 0.0014, 0.0050, 0.0932, 0.0245, 0.1131, 0.1055, 0.3336, 0.3203],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:12,516][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0105, 0.0379, 0.0491, 0.3676, 0.0646, 0.0227, 0.0716, 0.2006, 0.1752],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:12,517][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([4.6068e-06, 1.3930e-02, 8.8161e-02, 5.4835e-02, 5.1347e-02, 3.7416e-01,
        1.7678e-01, 5.4983e-02, 1.8580e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:12,518][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([1.4744e-04, 1.9080e-07, 1.0179e-05, 2.4659e-02, 1.0424e-04, 3.1604e-01,
        1.0334e-01, 3.6511e-02, 5.1919e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:12,522][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0120, 0.1331, 0.0845, 0.1718, 0.1036, 0.1051, 0.1226, 0.1210, 0.1462],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:12,523][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Benjamin] are: tensor([0.0098, 0.0109, 0.0108, 0.3765, 0.0334, 0.0470, 0.0440, 0.1548, 0.1048,
        0.2079], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:12,523][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Benjamin] are: tensor([0.0045, 0.0861, 0.0710, 0.1899, 0.0278, 0.0920, 0.0919, 0.1129, 0.2192,
        0.1049], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:12,524][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Benjamin] are: tensor([0.0209, 0.0152, 0.0132, 0.0410, 0.0475, 0.1346, 0.1514, 0.1752, 0.3159,
        0.0851], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:12,525][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Benjamin] are: tensor([3.1796e-02, 7.1401e-05, 4.7594e-05, 6.5117e-02, 3.0044e-04, 4.9019e-02,
        1.5791e-02, 9.7331e-02, 2.1486e-01, 5.2567e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:12,528][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Benjamin] are: tensor([0.0025, 0.0340, 0.0616, 0.1305, 0.1453, 0.2378, 0.1028, 0.1040, 0.1079,
        0.0735], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:12,529][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Benjamin] are: tensor([0.0426, 0.0099, 0.0176, 0.1450, 0.0485, 0.1751, 0.0958, 0.1305, 0.0658,
        0.2692], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:12,530][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Benjamin] are: tensor([2.5755e-05, 1.1713e-02, 3.9214e-02, 9.4065e-02, 7.2254e-02, 1.6438e-01,
        8.5254e-02, 2.0314e-01, 1.2331e-01, 2.0664e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:12,531][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Benjamin] are: tensor([0.0053, 0.0067, 0.0103, 0.0854, 0.0252, 0.0620, 0.0648, 0.3968, 0.2102,
        0.1335], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:12,532][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Benjamin] are: tensor([0.0222, 0.0303, 0.0489, 0.1687, 0.0702, 0.0305, 0.0643, 0.2423, 0.2547,
        0.0679], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:12,534][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Benjamin] are: tensor([2.6937e-06, 6.3705e-03, 7.7289e-02, 3.5657e-02, 4.6139e-02, 2.2851e-01,
        1.3846e-01, 4.4738e-02, 1.7357e-01, 2.4926e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:12,536][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Benjamin] are: tensor([3.1363e-04, 1.7206e-06, 1.3395e-05, 1.5825e-02, 1.3925e-04, 1.6875e-01,
        4.8778e-02, 4.6287e-02, 2.0735e-01, 5.1255e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:12,537][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Benjamin] are: tensor([0.0230, 0.0670, 0.0578, 0.1855, 0.1184, 0.0670, 0.1069, 0.2025, 0.0974,
        0.0745], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:12,537][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.0084, 0.0038, 0.0081, 0.2552, 0.0113, 0.1057, 0.0866, 0.0758, 0.1560,
        0.1417, 0.1474], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:12,538][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0032, 0.0347, 0.0500, 0.1169, 0.0338, 0.1222, 0.0967, 0.1024, 0.2534,
        0.0955, 0.0912], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:12,542][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.0120, 0.0102, 0.0137, 0.0536, 0.0295, 0.1481, 0.1393, 0.0825, 0.2662,
        0.0548, 0.1901], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:12,543][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([1.0747e-03, 1.8611e-07, 8.4135e-06, 8.4648e-03, 2.3301e-05, 6.6820e-02,
        1.5826e-02, 2.0825e-02, 5.0549e-01, 3.7535e-01, 6.1263e-03],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:12,544][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.0026, 0.0191, 0.0541, 0.1081, 0.1368, 0.1789, 0.1058, 0.0622, 0.1137,
        0.0573, 0.1613], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:12,544][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.0223, 0.0044, 0.0111, 0.1048, 0.0225, 0.2516, 0.1160, 0.0921, 0.0660,
        0.2091, 0.1000], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:12,545][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([4.7521e-05, 2.2201e-02, 4.8865e-02, 1.0415e-01, 6.3933e-02, 1.4389e-01,
        1.1689e-01, 1.4046e-01, 1.1805e-01, 1.0398e-01, 1.3754e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:12,547][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([5.7627e-04, 1.9805e-04, 2.1165e-03, 1.9279e-02, 8.6445e-03, 9.3426e-02,
        8.1008e-02, 1.6167e-01, 2.8670e-01, 1.3242e-01, 2.1396e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:12,549][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.0116, 0.0117, 0.0369, 0.1492, 0.0442, 0.0308, 0.0993, 0.2104, 0.1989,
        0.0638, 0.1433], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:12,550][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([7.3245e-06, 7.8104e-03, 8.0215e-02, 5.1166e-02, 3.9721e-02, 1.7336e-01,
        8.1360e-02, 5.1024e-02, 1.6852e-01, 2.6098e-01, 8.5832e-02],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:12,551][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([1.7877e-05, 2.4090e-08, 3.6814e-06, 2.9041e-03, 4.9365e-05, 2.2063e-01,
        5.0562e-02, 2.0750e-02, 2.9439e-01, 3.8133e-01, 2.9358e-02],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:12,552][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.0077, 0.0967, 0.0515, 0.1549, 0.0649, 0.0610, 0.1108, 0.1611, 0.1242,
        0.0899, 0.0772], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:12,555][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0161, 0.0042, 0.0087, 0.3103, 0.0212, 0.0698, 0.0918, 0.0767, 0.1319,
        0.1118, 0.1005, 0.0568], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:12,556][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0037, 0.0433, 0.0368, 0.1124, 0.0291, 0.0872, 0.0899, 0.1168, 0.1912,
        0.0898, 0.1077, 0.0921], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:12,557][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0274, 0.0073, 0.0198, 0.0864, 0.0502, 0.1270, 0.1204, 0.0667, 0.2142,
        0.0463, 0.1344, 0.1000], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:12,558][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([3.9814e-03, 6.4231e-07, 4.6061e-06, 2.2089e-02, 2.4313e-05, 3.5261e-02,
        9.1088e-03, 1.4536e-02, 2.1227e-01, 6.5207e-01, 5.0799e-03, 4.5566e-02],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:12,560][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0014, 0.0104, 0.0326, 0.1078, 0.1202, 0.1526, 0.1089, 0.0841, 0.0915,
        0.0303, 0.1696, 0.0906], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:12,563][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0596, 0.0032, 0.0094, 0.0927, 0.0277, 0.2259, 0.0984, 0.0837, 0.0492,
        0.1728, 0.0888, 0.0884], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:12,564][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([2.6117e-05, 8.1725e-03, 3.4376e-02, 4.8859e-02, 4.0538e-02, 1.9073e-01,
        1.3022e-01, 8.7817e-02, 1.0244e-01, 8.3889e-02, 1.3838e-01, 1.3455e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:12,564][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0041, 0.0005, 0.0029, 0.0465, 0.0117, 0.0709, 0.0614, 0.1798, 0.2668,
        0.1284, 0.1662, 0.0607], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:12,565][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0224, 0.0184, 0.0263, 0.2110, 0.0303, 0.0238, 0.0490, 0.1208, 0.2077,
        0.0974, 0.1386, 0.0544], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:12,567][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([4.3519e-06, 6.6355e-03, 4.7545e-02, 2.9190e-02, 4.3087e-02, 1.6722e-01,
        1.0296e-01, 4.1270e-02, 9.0953e-02, 2.3430e-01, 9.3567e-02, 1.4327e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:12,570][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([4.1601e-05, 4.4225e-08, 3.4548e-06, 6.2337e-03, 2.5092e-05, 8.9804e-02,
        2.8465e-02, 1.4913e-02, 2.0524e-01, 5.0842e-01, 2.3633e-02, 1.2322e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:12,570][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0127, 0.0538, 0.0291, 0.0882, 0.0630, 0.0787, 0.0975, 0.1030, 0.1824,
        0.0782, 0.0812, 0.1321], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:12,571][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ computer] are: tensor([0.0028, 0.0021, 0.0027, 0.2287, 0.0125, 0.0424, 0.0360, 0.0762, 0.0760,
        0.0940, 0.0746, 0.0142, 0.3378], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:12,572][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ computer] are: tensor([0.0007, 0.0265, 0.0380, 0.0988, 0.0290, 0.0927, 0.0680, 0.1055, 0.1559,
        0.0786, 0.1264, 0.0932, 0.0868], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:12,576][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ computer] are: tensor([0.0085, 0.0083, 0.0096, 0.0456, 0.0269, 0.0616, 0.0647, 0.0473, 0.0866,
        0.0288, 0.0759, 0.0561, 0.4800], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:12,577][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ computer] are: tensor([1.0697e-02, 5.2792e-06, 7.7418e-06, 1.9145e-02, 3.4130e-05, 2.0561e-02,
        5.9037e-03, 2.7337e-02, 1.0813e-01, 1.7603e-01, 6.2801e-03, 3.2184e-02,
        5.9369e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:12,577][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ computer] are: tensor([0.0011, 0.0249, 0.0639, 0.1421, 0.1317, 0.2031, 0.0618, 0.0430, 0.0816,
        0.0342, 0.0931, 0.0576, 0.0619], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:12,578][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ computer] are: tensor([0.0204, 0.0055, 0.0099, 0.0819, 0.0188, 0.1739, 0.0605, 0.0641, 0.0396,
        0.1354, 0.0973, 0.0444, 0.2483], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:12,579][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ computer] are: tensor([7.2828e-06, 7.5691e-03, 2.3856e-02, 4.2819e-02, 2.7289e-02, 9.6721e-02,
        4.8794e-02, 6.3968e-02, 8.2807e-02, 1.1852e-01, 2.4488e-01, 9.5274e-02,
        1.4749e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:12,583][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ computer] are: tensor([0.0037, 0.0022, 0.0043, 0.0519, 0.0169, 0.0499, 0.0454, 0.1865, 0.1443,
        0.1178, 0.1925, 0.0428, 0.1418], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:12,584][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ computer] are: tensor([0.0174, 0.0757, 0.0323, 0.2464, 0.0322, 0.0182, 0.0279, 0.1296, 0.1595,
        0.0830, 0.0945, 0.0238, 0.0597], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:12,585][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ computer] are: tensor([2.5743e-06, 1.3712e-02, 4.6077e-02, 2.9621e-02, 3.8362e-02, 1.3220e-01,
        4.7974e-02, 4.9012e-02, 7.7451e-02, 2.2578e-01, 1.7181e-01, 1.1476e-01,
        5.3237e-02], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:12,586][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ computer] are: tensor([1.6218e-04, 2.8195e-07, 3.0067e-06, 5.0637e-03, 8.0990e-05, 6.9948e-02,
        1.7530e-02, 3.2917e-02, 9.9195e-02, 2.0126e-01, 3.6947e-02, 6.0095e-02,
        4.7680e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:12,589][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ computer] are: tensor([0.0032, 0.0520, 0.0344, 0.0638, 0.0739, 0.0517, 0.0551, 0.0883, 0.1040,
        0.0384, 0.1088, 0.0894, 0.2372], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:12,590][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0195, 0.0060, 0.0033, 0.3168, 0.0090, 0.0267, 0.0319, 0.0741, 0.0668,
        0.0729, 0.0486, 0.0164, 0.2441, 0.0640], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:12,591][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0024, 0.0349, 0.0505, 0.1004, 0.0205, 0.0840, 0.0619, 0.0644, 0.1128,
        0.0341, 0.0799, 0.0584, 0.0577, 0.2381], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:12,592][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0721, 0.0213, 0.0102, 0.0653, 0.0177, 0.0328, 0.0445, 0.0331, 0.1271,
        0.0254, 0.0581, 0.0315, 0.3484, 0.1126], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:12,594][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([9.5961e-03, 5.6387e-07, 6.3865e-07, 7.7219e-03, 2.6600e-06, 3.4527e-03,
        1.7430e-03, 1.7475e-03, 3.8442e-02, 1.3107e-01, 5.8714e-04, 1.1283e-02,
        3.2227e-01, 4.7208e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:12,596][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0021, 0.0057, 0.0252, 0.0584, 0.0538, 0.1088, 0.0629, 0.0516, 0.1098,
        0.0256, 0.1660, 0.0674, 0.0519, 0.2109], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:12,597][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0540, 0.0038, 0.0067, 0.0725, 0.0141, 0.1612, 0.0646, 0.0456, 0.0349,
        0.1575, 0.0697, 0.0578, 0.1386, 0.1187], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:12,598][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([1.5361e-05, 9.3103e-03, 2.0461e-02, 5.0813e-02, 2.3710e-02, 8.9935e-02,
        5.1704e-02, 6.3635e-02, 8.8956e-02, 6.1394e-02, 7.7338e-02, 7.2015e-02,
        1.8598e-01, 2.0474e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:12,599][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0093, 0.0006, 0.0016, 0.0346, 0.0039, 0.0289, 0.0299, 0.1025, 0.1623,
        0.0855, 0.0610, 0.0318, 0.1620, 0.2859], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:12,603][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0401, 0.0363, 0.0227, 0.2342, 0.0303, 0.0152, 0.0251, 0.1606, 0.1678,
        0.0812, 0.0877, 0.0223, 0.0522, 0.0241], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:12,604][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([1.9991e-06, 5.6949e-03, 2.9721e-02, 2.4664e-02, 1.8747e-02, 1.1202e-01,
        5.1886e-02, 2.2452e-02, 6.1298e-02, 1.2623e-01, 4.2149e-02, 6.9691e-02,
        2.4866e-02, 4.1058e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:12,604][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([1.0036e-04, 1.7315e-08, 2.2973e-07, 1.8830e-03, 2.8053e-06, 7.0837e-03,
        3.5400e-03, 1.4428e-03, 3.2138e-02, 9.6263e-02, 2.1592e-03, 1.3986e-02,
        2.1072e-01, 6.3068e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:12,605][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0112, 0.0401, 0.0169, 0.0464, 0.0331, 0.0377, 0.0470, 0.0613, 0.1295,
        0.0537, 0.0454, 0.0663, 0.2737, 0.1377], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:12,609][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:20:12,611][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 319],
        [ 319],
        [  40],
        [3463],
        [ 357],
        [  36],
        [  13],
        [   1],
        [   8],
        [  53],
        [   7],
        [  17],
        [   3],
        [   5]], device='cuda:0')
[2024-07-24 10:20:12,613][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 345],
        [1250],
        [ 189],
        [5656],
        [ 555],
        [  68],
        [  39],
        [   8],
        [  25],
        [ 132],
        [  16],
        [  42],
        [  10],
        [  26]], device='cuda:0')
[2024-07-24 10:20:12,615][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[ 8147],
        [10352],
        [11102],
        [41150],
        [41901],
        [41683],
        [41363],
        [35547],
        [37299],
        [32804],
        [30906],
        [33196],
        [23263],
        [27319]], device='cuda:0')
[2024-07-24 10:20:12,618][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[31902],
        [17790],
        [15372],
        [27449],
        [30106],
        [26668],
        [21740],
        [20733],
        [17060],
        [17079],
        [14534],
        [14097],
        [12231],
        [12805]], device='cuda:0')
[2024-07-24 10:20:12,619][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 7811],
        [43044],
        [39606],
        [44883],
        [36456],
        [37212],
        [31687],
        [32073],
        [36888],
        [37575],
        [36129],
        [37229],
        [38643],
        [38582]], device='cuda:0')
[2024-07-24 10:20:12,620][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[35286],
        [27073],
        [31671],
        [31251],
        [30159],
        [38279],
        [37923],
        [38965],
        [38067],
        [37678],
        [38054],
        [37128],
        [39949],
        [39062]], device='cuda:0')
[2024-07-24 10:20:12,622][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[ 7749],
        [  473],
        [ 6177],
        [ 8174],
        [21089],
        [25053],
        [28525],
        [23394],
        [22425],
        [21493],
        [26612],
        [26651],
        [24984],
        [31421]], device='cuda:0')
[2024-07-24 10:20:12,625][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[35882],
        [ 7122],
        [ 4303],
        [  453],
        [  730],
        [ 1751],
        [ 2370],
        [ 3143],
        [ 2242],
        [ 1987],
        [ 2567],
        [ 3093],
        [ 3728],
        [ 4109]], device='cuda:0')
[2024-07-24 10:20:12,626][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[35456],
        [16814],
        [14059],
        [47826],
        [32994],
        [39998],
        [24857],
        [29868],
        [30768],
        [33729],
        [32164],
        [19351],
        [23945],
        [25138]], device='cuda:0')
[2024-07-24 10:20:12,628][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[9060],
        [3801],
        [2031],
        [ 491],
        [ 244],
        [ 542],
        [1153],
        [ 443],
        [ 568],
        [ 391],
        [1010],
        [ 760],
        [ 573],
        [ 626]], device='cuda:0')
[2024-07-24 10:20:12,630][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[  402],
        [36016],
        [48104],
        [50184],
        [50189],
        [50194],
        [50183],
        [50157],
        [50132],
        [49880],
        [49847],
        [49859],
        [50011],
        [49973]], device='cuda:0')
[2024-07-24 10:20:12,633][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[44061],
        [19238],
        [ 8596],
        [11227],
        [ 7290],
        [ 1203],
        [  811],
        [ 5634],
        [ 1109],
        [ 2911],
        [ 5486],
        [ 4144],
        [ 6270],
        [ 1900]], device='cuda:0')
[2024-07-24 10:20:12,634][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[17288],
        [ 2885],
        [ 5524],
        [ 8632],
        [ 9005],
        [ 7096],
        [ 7000],
        [ 7469],
        [ 9939],
        [ 7013],
        [ 7711],
        [ 8165],
        [10868],
        [ 9646]], device='cuda:0')
[2024-07-24 10:20:12,635][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[31859],
        [28793],
        [32724],
        [12637],
        [27315],
        [23621],
        [31214],
        [35201],
        [34019],
        [36183],
        [35982],
        [35389],
        [35223],
        [34305]], device='cuda:0')
[2024-07-24 10:20:12,637][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[4016],
        [2706],
        [1819],
        [1157],
        [1997],
        [2355],
        [1532],
        [1005],
        [1137],
        [1183],
        [1261],
        [1701],
        [1131],
        [1375]], device='cuda:0')
[2024-07-24 10:20:12,640][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[10392],
        [ 6880],
        [ 7603],
        [ 7005],
        [ 7846],
        [ 8319],
        [10467],
        [11993],
        [ 7551],
        [ 9366],
        [13261],
        [11522],
        [ 8906],
        [ 8116]], device='cuda:0')
[2024-07-24 10:20:12,641][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[24744],
        [23778],
        [34720],
        [30582],
        [27306],
        [30711],
        [29991],
        [31583],
        [34358],
        [33546],
        [33253],
        [32485],
        [32785],
        [35623]], device='cuda:0')
[2024-07-24 10:20:12,643][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[10559],
        [26050],
        [28950],
        [32763],
        [15419],
        [19808],
        [17050],
        [16892],
        [17965],
        [16612],
        [15849],
        [16549],
        [14943],
        [15603]], device='cuda:0')
[2024-07-24 10:20:12,644][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[  348],
        [ 5010],
        [ 8104],
        [12590],
        [18492],
        [ 3696],
        [ 3477],
        [ 2769],
        [ 4998],
        [ 3885],
        [ 4190],
        [ 4372],
        [ 1798],
        [ 2675]], device='cuda:0')
[2024-07-24 10:20:12,647][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[16843],
        [17533],
        [17621],
        [17685],
        [ 6187],
        [ 7290],
        [ 7672],
        [ 8673],
        [ 8417],
        [ 9125],
        [ 9124],
        [ 9410],
        [ 9272],
        [ 9571]], device='cuda:0')
[2024-07-24 10:20:12,649][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[28108],
        [ 7437],
        [ 9751],
        [17666],
        [11732],
        [ 8994],
        [10195],
        [15586],
        [14918],
        [16484],
        [16351],
        [14189],
        [11368],
        [11292]], device='cuda:0')
[2024-07-24 10:20:12,650][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[ 2145],
        [17839],
        [24911],
        [20401],
        [26416],
        [24684],
        [25945],
        [25756],
        [18585],
        [20018],
        [20095],
        [20905],
        [20703],
        [21785]], device='cuda:0')
[2024-07-24 10:20:12,652][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[ 5295],
        [ 6249],
        [36231],
        [29699],
        [45176],
        [42758],
        [41955],
        [39459],
        [37838],
        [34386],
        [33161],
        [33777],
        [35587],
        [39556]], device='cuda:0')
[2024-07-24 10:20:12,655][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[11663],
        [ 6828],
        [ 8760],
        [ 5939],
        [ 7084],
        [ 7605],
        [ 8462],
        [ 8748],
        [10488],
        [13527],
        [12383],
        [11811],
        [10470],
        [10944]], device='cuda:0')
[2024-07-24 10:20:12,656][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[15787],
        [27160],
        [46724],
        [46098],
        [47161],
        [43426],
        [41122],
        [35753],
        [37301],
        [37868],
        [37168],
        [37920],
        [37809],
        [39581]], device='cuda:0')
[2024-07-24 10:20:12,657][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[ 1147],
        [26860],
        [10358],
        [11953],
        [13059],
        [19667],
        [18547],
        [18432],
        [12281],
        [17443],
        [15928],
        [17554],
        [13701],
        [17587]], device='cuda:0')
[2024-07-24 10:20:12,659][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[7843],
        [4556],
        [7431],
        [3640],
        [7106],
        [6859],
        [6877],
        [6574],
        [6510],
        [5617],
        [4455],
        [4400],
        [4160],
        [3517]], device='cuda:0')
[2024-07-24 10:20:12,662][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[47419],
        [36909],
        [22872],
        [22000],
        [26768],
        [31228],
        [32093],
        [31266],
        [33448],
        [30987],
        [30903],
        [32091],
        [37381],
        [34242]], device='cuda:0')
[2024-07-24 10:20:12,663][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[45648],
        [48468],
        [49240],
        [48709],
        [47762],
        [48348],
        [48462],
        [48587],
        [49153],
        [48941],
        [49119],
        [48635],
        [48915],
        [49033]], device='cuda:0')
[2024-07-24 10:20:12,665][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[2180],
        [2180],
        [2180],
        [2180],
        [2180],
        [2180],
        [2180],
        [2180],
        [2180],
        [2180],
        [2180],
        [2180],
        [2180],
        [2180]], device='cuda:0')
[2024-07-24 10:20:12,779][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:20:12,781][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:12,782][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:12,782][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:12,782][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:12,783][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:12,783][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:12,783][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:12,784][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:12,784][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:12,786][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:12,788][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:12,788][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:12,789][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Benjamin] are: tensor([0.1334, 0.8666], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:12,789][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Benjamin] are: tensor([4.4057e-04, 9.9956e-01], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:12,789][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Benjamin] are: tensor([0.2680, 0.7320], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:12,790][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Benjamin] are: tensor([0.1068, 0.8932], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:12,790][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Benjamin] are: tensor([0.5593, 0.4407], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:12,790][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Benjamin] are: tensor([0.0706, 0.9294], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:12,791][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Benjamin] are: tensor([0.1838, 0.8162], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:12,792][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Benjamin] are: tensor([0.1763, 0.8237], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:12,792][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Benjamin] are: tensor([0.0128, 0.9872], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:12,793][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Benjamin] are: tensor([0.1601, 0.8399], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:12,793][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Benjamin] are: tensor([0.0038, 0.9962], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:12,793][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Benjamin] are: tensor([6.4782e-04, 9.9935e-01], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:12,793][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0197, 0.4986, 0.4818], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:12,794][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ and] are: tensor([4.4133e-05, 9.9582e-02, 9.0037e-01], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:12,794][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.2554, 0.3524, 0.3922], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:12,794][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.2382, 0.3778, 0.3841], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:12,795][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.3093, 0.0467, 0.6440], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:12,795][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ and] are: tensor([1.1769e-02, 3.9791e-04, 9.8783e-01], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:12,795][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0022, 0.1426, 0.8552], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:12,796][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.2510, 0.5421, 0.2069], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:12,796][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0261, 0.5890, 0.3849], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:12,796][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ and] are: tensor([4.9097e-03, 1.9182e-04, 9.9490e-01], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:12,797][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ and] are: tensor([1.1404e-04, 7.0695e-03, 9.9282e-01], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:12,797][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ and] are: tensor([5.2978e-05, 1.2440e-01, 8.7554e-01], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:12,797][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Alexander] are: tensor([0.0096, 0.2191, 0.1970, 0.5743], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:12,798][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Alexander] are: tensor([3.7452e-05, 1.9857e-01, 6.0898e-01, 1.9242e-01], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:12,798][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Alexander] are: tensor([0.1016, 0.3486, 0.1648, 0.3850], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:12,798][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Alexander] are: tensor([0.3781, 0.3613, 0.1779, 0.0827], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:12,799][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Alexander] are: tensor([0.2099, 0.0609, 0.5412, 0.1879], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:12,800][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Alexander] are: tensor([2.1715e-02, 8.0584e-04, 4.1301e-03, 9.7335e-01], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:12,802][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Alexander] are: tensor([0.0054, 0.1429, 0.4280, 0.4237], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:12,802][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Alexander] are: tensor([0.0823, 0.2482, 0.1650, 0.5044], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:12,803][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Alexander] are: tensor([0.0485, 0.6158, 0.1347, 0.2009], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:12,803][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Alexander] are: tensor([1.8312e-02, 2.6010e-04, 1.2094e-03, 9.8022e-01], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:12,803][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Alexander] are: tensor([6.7551e-06, 1.5706e-03, 9.9415e-01, 4.2719e-03], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:12,804][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Alexander] are: tensor([0.0013, 0.2558, 0.3168, 0.4261], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:12,804][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ went] are: tensor([4.9592e-04, 1.0336e-02, 7.0602e-02, 1.6016e-01, 7.5841e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:12,804][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ went] are: tensor([1.7535e-05, 3.8273e-02, 4.9184e-01, 1.0436e-01, 3.6550e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:12,807][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ went] are: tensor([0.0093, 0.0781, 0.1790, 0.3953, 0.3383], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:12,809][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ went] are: tensor([0.1857, 0.1977, 0.2754, 0.1757, 0.1655], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:12,809][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ went] are: tensor([0.0832, 0.0148, 0.2737, 0.2583, 0.3699], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:12,809][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ went] are: tensor([5.8689e-05, 6.5919e-07, 1.5077e-03, 9.3649e-01, 6.1947e-02],
       device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:12,810][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ went] are: tensor([3.3867e-04, 1.7487e-02, 2.3667e-01, 2.1245e-01, 5.3305e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:12,810][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ went] are: tensor([0.0757, 0.0607, 0.3062, 0.2393, 0.3182], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:12,810][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.0096, 0.1306, 0.1512, 0.1402, 0.5684], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:12,811][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ went] are: tensor([1.2438e-05, 8.1765e-08, 5.9587e-04, 9.8289e-01, 1.6501e-02],
       device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:12,811][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ went] are: tensor([3.6832e-08, 1.0034e-04, 9.9563e-01, 4.0193e-04, 3.8640e-03],
       device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:12,812][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ went] are: tensor([1.6251e-04, 2.3371e-02, 2.9306e-01, 3.7811e-01, 3.0530e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:12,815][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0036, 0.0800, 0.0260, 0.3477, 0.4837, 0.0591], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:12,816][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ to] are: tensor([1.5112e-05, 2.8844e-02, 1.1219e-01, 1.0194e-01, 1.5238e-01, 6.0462e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:12,816][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0284, 0.1058, 0.0757, 0.4176, 0.2084, 0.1640], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:12,816][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.5388, 0.1561, 0.0992, 0.0877, 0.0539, 0.0643], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:12,817][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.3495, 0.0024, 0.0267, 0.0942, 0.0400, 0.4873], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:12,817][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ to] are: tensor([6.7028e-04, 1.7803e-07, 8.7950e-06, 3.0762e-01, 3.4756e-04, 6.9135e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:12,817][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0015, 0.0571, 0.0957, 0.2708, 0.3020, 0.2729], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:12,818][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.1776, 0.1199, 0.0783, 0.5250, 0.0404, 0.0589], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:12,820][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0184, 0.1768, 0.1348, 0.1829, 0.3275, 0.1596], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:12,822][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ to] are: tensor([7.3979e-05, 1.5818e-08, 1.2437e-06, 1.0042e-01, 1.9091e-05, 8.9948e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:12,822][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ to] are: tensor([1.3985e-06, 1.4349e-03, 7.7471e-01, 3.1195e-03, 2.5837e-02, 1.9490e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:12,823][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0099, 0.0351, 0.1979, 0.1607, 0.1183, 0.4781], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:12,823][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0007, 0.0441, 0.0176, 0.2788, 0.4454, 0.0596, 0.1538],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:12,823][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ the] are: tensor([3.4891e-06, 1.2093e-02, 9.5172e-02, 5.8290e-02, 8.4769e-02, 5.0443e-01,
        2.4524e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:12,824][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0135, 0.0659, 0.0413, 0.4088, 0.2036, 0.1553, 0.1117],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:12,824][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.3924, 0.1278, 0.0840, 0.1182, 0.0589, 0.0894, 0.1293],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:12,825][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0620, 0.0006, 0.0150, 0.0439, 0.0193, 0.5091, 0.3501],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:12,826][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ the] are: tensor([2.8205e-04, 1.4388e-07, 9.9043e-06, 1.3764e-01, 4.1674e-04, 5.7090e-01,
        2.9075e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:12,828][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ the] are: tensor([2.1567e-04, 1.8982e-02, 7.2181e-02, 1.3203e-01, 2.2109e-01, 2.9933e-01,
        2.5616e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:12,829][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.1117, 0.0680, 0.1099, 0.2981, 0.0552, 0.1126, 0.2446],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:12,829][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0107, 0.1013, 0.0895, 0.1851, 0.2081, 0.1718, 0.2335],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:12,830][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ the] are: tensor([1.3783e-05, 1.0215e-08, 7.0354e-07, 4.8925e-02, 1.1585e-05, 6.8594e-01,
        2.6511e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:12,830][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ the] are: tensor([1.5499e-06, 5.0822e-04, 5.2387e-01, 1.0887e-03, 6.5618e-03, 1.3724e-01,
        3.3073e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:12,830][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ the] are: tensor([2.0820e-04, 6.7526e-03, 9.3869e-02, 1.0339e-01, 1.2342e-01, 4.1493e-01,
        2.5743e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:12,831][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ station] are: tensor([0.0013, 0.0083, 0.0195, 0.2384, 0.2166, 0.0496, 0.1124, 0.3538],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:12,831][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ station] are: tensor([4.5203e-06, 2.2238e-03, 4.8554e-02, 2.6205e-02, 4.7483e-02, 4.7817e-01,
        2.1973e-01, 1.7763e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:12,833][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ station] are: tensor([0.0089, 0.0245, 0.0510, 0.2927, 0.1878, 0.1779, 0.0894, 0.1679],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:12,835][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ station] are: tensor([0.1422, 0.0679, 0.0477, 0.1245, 0.0660, 0.0448, 0.0564, 0.4505],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:12,836][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ station] are: tensor([0.0384, 0.0006, 0.0105, 0.0276, 0.0218, 0.5002, 0.2759, 0.1251],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:12,836][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ station] are: tensor([2.1749e-04, 6.9745e-08, 1.0412e-05, 6.8000e-02, 2.5604e-04, 5.1747e-01,
        2.0693e-01, 2.0712e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:12,837][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ station] are: tensor([0.0009, 0.0123, 0.0336, 0.2222, 0.1869, 0.1339, 0.1084, 0.3017],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:12,837][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ station] are: tensor([0.0889, 0.0427, 0.1153, 0.2712, 0.1135, 0.0738, 0.1140, 0.1806],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:12,837][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ station] are: tensor([0.0228, 0.0988, 0.0373, 0.1731, 0.1460, 0.0863, 0.1602, 0.2755],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:12,838][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ station] are: tensor([5.2384e-05, 1.0911e-08, 9.5905e-07, 1.3201e-02, 1.8652e-05, 5.1860e-01,
        1.3852e-01, 3.2961e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:12,838][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ station] are: tensor([3.9422e-07, 1.2555e-04, 5.4029e-01, 4.2163e-04, 3.9102e-03, 7.4009e-02,
        3.8080e-01, 4.3744e-04], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:12,841][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ station] are: tensor([0.0289, 0.0129, 0.0739, 0.1596, 0.0924, 0.0655, 0.0344, 0.5324],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:12,842][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [,] are: tensor([2.6264e-04, 5.0029e-02, 1.2782e-02, 2.8321e-01, 8.0841e-02, 4.2090e-02,
        8.3888e-02, 2.6467e-01, 1.8222e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:12,843][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [,] are: tensor([2.7180e-06, 1.6170e-02, 9.9021e-02, 5.5285e-02, 4.2256e-02, 3.8971e-01,
        1.2760e-01, 8.2477e-02, 1.8747e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:12,843][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0027, 0.0755, 0.0381, 0.4256, 0.0630, 0.1110, 0.0464, 0.1086, 0.1291],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:12,843][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.1021, 0.2488, 0.0500, 0.0912, 0.0147, 0.0278, 0.0289, 0.3991, 0.0375],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:12,844][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0262, 0.0017, 0.0098, 0.0366, 0.0082, 0.3142, 0.2453, 0.0459, 0.3120],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:12,844][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [,] are: tensor([1.7836e-04, 5.2582e-08, 1.6351e-06, 3.7800e-02, 4.4765e-05, 9.9732e-02,
        6.1305e-02, 5.3463e-02, 7.4747e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:12,844][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [,] are: tensor([6.5149e-05, 2.2802e-02, 5.8718e-02, 1.0457e-01, 4.3701e-02, 2.6894e-01,
        1.2098e-01, 1.2854e-01, 2.5169e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:12,847][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0124, 0.0327, 0.0421, 0.0789, 0.0168, 0.0277, 0.0459, 0.0403, 0.7031],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:12,849][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0100, 0.1140, 0.0758, 0.2872, 0.0545, 0.1070, 0.1242, 0.1236, 0.1036],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:12,849][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [,] are: tensor([1.5465e-05, 3.1268e-09, 1.1617e-07, 1.8262e-02, 2.7549e-06, 1.1311e-01,
        6.5597e-02, 3.7223e-02, 7.6579e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:12,850][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [,] are: tensor([1.1220e-06, 4.9271e-04, 3.5211e-01, 8.8550e-04, 6.8913e-03, 8.6069e-02,
        2.6080e-01, 6.8645e-04, 2.9206e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:12,850][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [,] are: tensor([2.1129e-04, 1.1056e-02, 4.2776e-02, 1.0617e-01, 3.7533e-02, 2.2708e-01,
        1.0173e-01, 1.7952e-01, 2.9392e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:12,850][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Benjamin] are: tensor([0.0008, 0.0362, 0.0183, 0.1790, 0.2206, 0.0338, 0.0602, 0.2560, 0.1227,
        0.0723], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:12,851][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Benjamin] are: tensor([7.0920e-06, 2.3322e-02, 7.8048e-02, 7.0026e-02, 9.7397e-02, 3.3813e-01,
        1.3466e-01, 1.4296e-01, 1.0440e-01, 1.1056e-02], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:12,851][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Benjamin] are: tensor([0.0074, 0.1386, 0.0508, 0.2701, 0.1467, 0.0676, 0.0229, 0.1630, 0.0534,
        0.0795], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:12,854][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Benjamin] are: tensor([0.0913, 0.2470, 0.0823, 0.0688, 0.0518, 0.0313, 0.0220, 0.3167, 0.0261,
        0.0626], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:12,856][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Benjamin] are: tensor([0.0312, 0.0041, 0.0169, 0.0204, 0.0414, 0.3674, 0.1574, 0.0628, 0.1412,
        0.1572], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:12,856][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Benjamin] are: tensor([3.5024e-04, 6.7783e-07, 2.3362e-06, 3.0668e-02, 4.1995e-05, 3.0397e-02,
        1.2475e-02, 2.4742e-02, 9.5530e-02, 8.0579e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:12,856][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Benjamin] are: tensor([0.0007, 0.0226, 0.0627, 0.1634, 0.1142, 0.1481, 0.1073, 0.1365, 0.1503,
        0.0941], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:12,857][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Benjamin] are: tensor([0.0202, 0.0375, 0.0662, 0.2126, 0.0443, 0.0298, 0.0368, 0.0574, 0.4543,
        0.0411], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:12,857][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Benjamin] are: tensor([0.0065, 0.0757, 0.0281, 0.1717, 0.1609, 0.0438, 0.1341, 0.2216, 0.0736,
        0.0839], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:12,857][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Benjamin] are: tensor([4.5608e-05, 4.8841e-08, 6.3638e-08, 5.4686e-03, 1.9015e-06, 8.2351e-03,
        6.8205e-03, 1.7908e-02, 4.8451e-02, 9.1307e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:12,858][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Benjamin] are: tensor([1.1100e-06, 5.7505e-04, 2.9792e-01, 1.6630e-03, 1.3163e-02, 1.5131e-01,
        3.5524e-01, 1.3754e-03, 1.7859e-01, 1.6514e-04], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:12,860][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Benjamin] are: tensor([0.0011, 0.0389, 0.0417, 0.1022, 0.0793, 0.0842, 0.0688, 0.2105, 0.2137,
        0.1595], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:12,862][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([1.1817e-04, 4.0702e-03, 1.1106e-02, 9.2701e-02, 6.1293e-02, 6.0271e-02,
        7.6284e-02, 1.1840e-01, 2.2351e-01, 8.7808e-02, 2.6443e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:12,863][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([8.3966e-06, 1.1237e-02, 9.6771e-02, 4.8840e-02, 3.5062e-02, 2.6178e-01,
        1.0582e-01, 2.3146e-01, 1.4493e-01, 5.7437e-03, 5.8350e-02],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:12,863][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0115, 0.0411, 0.0363, 0.2230, 0.0719, 0.0811, 0.0414, 0.1005, 0.0979,
        0.1052, 0.1901], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:12,863][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.1316, 0.1363, 0.0316, 0.0735, 0.0118, 0.0243, 0.0307, 0.3467, 0.0563,
        0.0970, 0.0602], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:12,864][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.0051, 0.0005, 0.0062, 0.0234, 0.0082, 0.3084, 0.1674, 0.0409, 0.2172,
        0.1346, 0.0881], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:12,864][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([2.5345e-06, 7.1114e-10, 1.5970e-07, 2.4925e-03, 8.6941e-06, 2.7368e-02,
        1.8281e-02, 9.0841e-03, 2.7774e-01, 6.5453e-01, 1.0496e-02],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:12,865][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0003, 0.0125, 0.0727, 0.0636, 0.0593, 0.1846, 0.0989, 0.0854, 0.2487,
        0.0284, 0.1458], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:12,867][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0262, 0.0291, 0.0624, 0.1069, 0.0279, 0.0421, 0.0445, 0.0359, 0.5156,
        0.0290, 0.0804], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:12,869][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.0128, 0.1051, 0.0283, 0.0709, 0.0693, 0.0495, 0.0859, 0.2122, 0.1377,
        0.0867, 0.1416], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:12,869][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([7.9949e-08, 2.0170e-11, 5.8771e-09, 2.4950e-04, 2.4300e-07, 2.3477e-02,
        1.2457e-02, 3.7604e-03, 1.4943e-01, 8.0316e-01, 7.4717e-03],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:12,870][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([1.7464e-07, 1.1239e-04, 5.5320e-01, 2.8677e-04, 2.9142e-03, 5.5800e-02,
        2.1422e-01, 2.3325e-04, 1.6350e-01, 1.6391e-05, 9.7147e-03],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:12,870][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0010, 0.0128, 0.0459, 0.1019, 0.0357, 0.1295, 0.0671, 0.1256, 0.2384,
        0.1213, 0.1207], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:12,871][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0006, 0.0143, 0.0073, 0.1364, 0.0738, 0.0361, 0.0759, 0.1377, 0.0814,
        0.0390, 0.2461, 0.1512], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:12,871][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ a] are: tensor([9.4411e-06, 7.6110e-03, 3.8710e-02, 3.1209e-02, 2.3723e-02, 2.8414e-01,
        1.3454e-01, 1.3494e-01, 1.4565e-01, 7.7828e-03, 1.0246e-01, 8.9225e-02],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:12,871][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0091, 0.0320, 0.0244, 0.1973, 0.0760, 0.0957, 0.0511, 0.0831, 0.0738,
        0.0972, 0.2214, 0.0389], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:12,874][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.2686, 0.0731, 0.0264, 0.0490, 0.0176, 0.0272, 0.0286, 0.3237, 0.0402,
        0.0482, 0.0452, 0.0523], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:12,876][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ a] are: tensor([3.0164e-02, 3.0769e-04, 4.2465e-03, 2.5901e-02, 4.5294e-03, 1.3794e-01,
        1.0101e-01, 2.9394e-02, 1.4956e-01, 1.1646e-01, 4.7312e-02, 3.5319e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:12,876][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ a] are: tensor([4.8276e-05, 6.5094e-09, 2.3987e-07, 1.0413e-02, 8.0474e-06, 1.7084e-02,
        1.0541e-02, 8.9712e-03, 1.4968e-01, 6.3093e-01, 5.8659e-03, 1.6645e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:12,876][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0003, 0.0070, 0.0377, 0.0703, 0.0633, 0.1503, 0.1317, 0.0908, 0.1460,
        0.0257, 0.1676, 0.1092], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:12,877][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.1153, 0.0232, 0.0316, 0.0872, 0.0156, 0.0371, 0.0644, 0.0590, 0.4093,
        0.0250, 0.0384, 0.0940], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:12,877][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0092, 0.0575, 0.0468, 0.1097, 0.0754, 0.0760, 0.1217, 0.1157, 0.1142,
        0.0762, 0.1176, 0.0799], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:12,878][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ a] are: tensor([2.5519e-06, 2.0063e-10, 6.4019e-09, 2.0891e-03, 7.3038e-08, 7.0646e-03,
        3.2935e-03, 1.5558e-03, 5.1102e-02, 8.7833e-01, 3.0382e-03, 5.3528e-02],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:12,878][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ a] are: tensor([1.4545e-06, 2.2340e-04, 3.3516e-01, 5.8261e-04, 2.5398e-03, 6.6231e-02,
        1.7952e-01, 3.8982e-04, 1.8446e-01, 6.3880e-05, 1.1650e-02, 2.1919e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:12,881][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0013, 0.0038, 0.0339, 0.0695, 0.0292, 0.1602, 0.1037, 0.1100, 0.2417,
        0.0631, 0.1515, 0.0321], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:12,882][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ computer] are: tensor([0.0005, 0.0166, 0.0083, 0.1146, 0.0798, 0.0239, 0.0339, 0.1436, 0.0927,
        0.0307, 0.1833, 0.0817, 0.1905], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:12,883][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ computer] are: tensor([4.1179e-06, 2.9541e-02, 8.8085e-02, 4.5108e-02, 3.2176e-02, 2.7653e-01,
        8.9690e-02, 1.0005e-01, 1.3461e-01, 7.0379e-03, 9.8131e-02, 4.6433e-02,
        5.2595e-02], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:12,883][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ computer] are: tensor([0.0024, 0.0345, 0.0375, 0.1753, 0.0877, 0.0698, 0.0305, 0.1223, 0.0598,
        0.0471, 0.1628, 0.0222, 0.1482], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:12,884][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ computer] are: tensor([0.0597, 0.2132, 0.0364, 0.0424, 0.0304, 0.0267, 0.0173, 0.3597, 0.0287,
        0.0348, 0.0465, 0.0278, 0.0765], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:12,884][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ computer] are: tensor([0.0073, 0.0007, 0.0058, 0.0171, 0.0076, 0.1160, 0.0484, 0.0217, 0.0813,
        0.0511, 0.0455, 0.1592, 0.4382], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:12,885][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ computer] are: tensor([1.0099e-04, 8.3315e-08, 4.2847e-07, 1.1920e-02, 1.8012e-05, 1.0556e-02,
        6.4781e-03, 9.8776e-03, 6.9253e-02, 2.5859e-01, 8.4249e-03, 6.2280e-02,
        5.6250e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:12,885][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ computer] are: tensor([1.1792e-04, 1.6265e-02, 4.6811e-02, 9.4461e-02, 2.4886e-02, 1.5235e-01,
        6.6356e-02, 1.2202e-01, 1.6055e-01, 4.1805e-02, 7.8664e-02, 5.1366e-02,
        1.4435e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:12,888][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ computer] are: tensor([0.0361, 0.0372, 0.0441, 0.1215, 0.0201, 0.0332, 0.0408, 0.0508, 0.3521,
        0.0181, 0.0538, 0.0562, 0.1358], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:12,892][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ computer] are: tensor([0.0020, 0.0628, 0.0334, 0.1033, 0.1026, 0.0529, 0.0781, 0.1391, 0.0668,
        0.0393, 0.1760, 0.0440, 0.0997], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:12,892][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ computer] are: tensor([3.5230e-06, 8.0845e-10, 1.1208e-09, 2.2629e-04, 5.9754e-08, 6.1360e-04,
        4.1176e-04, 1.2139e-03, 4.1549e-03, 6.6689e-02, 5.7941e-04, 6.3581e-03,
        9.1975e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:12,893][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ computer] are: tensor([3.7032e-07, 9.9891e-05, 4.3838e-01, 2.6740e-04, 2.1391e-03, 6.5702e-02,
        1.6578e-01, 3.8809e-04, 2.4151e-01, 1.1920e-05, 6.0688e-03, 7.9363e-02,
        2.9062e-04], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:12,893][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ computer] are: tensor([0.0030, 0.0163, 0.0318, 0.0772, 0.0298, 0.0511, 0.0337, 0.0854, 0.1557,
        0.0346, 0.0628, 0.0085, 0.4101], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:12,893][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0005, 0.0234, 0.0045, 0.1603, 0.0627, 0.0159, 0.0337, 0.1336, 0.0785,
        0.0263, 0.1513, 0.0766, 0.1499, 0.0828], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:12,894][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ to] are: tensor([6.6691e-06, 2.3114e-02, 4.5628e-02, 5.3200e-02, 2.3459e-02, 2.0254e-01,
        7.8617e-02, 6.9618e-02, 1.1151e-01, 4.4691e-03, 7.9700e-02, 5.1699e-02,
        2.4139e-02, 2.3230e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:12,894][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0051, 0.0351, 0.0266, 0.1936, 0.0510, 0.0638, 0.0338, 0.0544, 0.0806,
        0.0669, 0.1352, 0.0248, 0.0956, 0.1335], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:12,895][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.1954, 0.1011, 0.0302, 0.0582, 0.0143, 0.0299, 0.0324, 0.1728, 0.0738,
        0.0412, 0.0388, 0.0461, 0.1063, 0.0595], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:12,895][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ to] are: tensor([1.7491e-02, 2.5076e-04, 1.9713e-03, 1.2652e-02, 1.5527e-03, 2.9109e-02,
        3.3794e-02, 8.2483e-03, 5.8456e-02, 2.8776e-02, 1.6230e-02, 9.8541e-02,
        1.8013e-01, 5.1280e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:12,897][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ to] are: tensor([1.5595e-04, 6.3051e-09, 2.4716e-08, 6.1755e-03, 8.0476e-07, 1.1659e-03,
        1.0026e-03, 1.1638e-03, 1.8428e-02, 1.5995e-01, 6.7301e-04, 1.3928e-02,
        3.2190e-01, 4.7546e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:12,899][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0002, 0.0132, 0.0234, 0.0877, 0.0339, 0.0841, 0.0668, 0.0833, 0.1026,
        0.0248, 0.0846, 0.0484, 0.1150, 0.2321], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:12,900][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0666, 0.0327, 0.0265, 0.0928, 0.0100, 0.0231, 0.0373, 0.0337, 0.4776,
        0.0166, 0.0178, 0.0398, 0.0564, 0.0690], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:12,900][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0028, 0.0562, 0.0484, 0.1278, 0.0763, 0.0521, 0.0911, 0.0901, 0.1054,
        0.0535, 0.1217, 0.0558, 0.0497, 0.0693], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:12,901][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ to] are: tensor([6.5636e-06, 2.2352e-10, 2.3503e-10, 2.0733e-04, 3.7390e-09, 1.4522e-04,
        1.4502e-04, 1.6684e-04, 2.5879e-03, 7.2403e-02, 9.5244e-05, 2.0289e-03,
        4.5232e-01, 4.6990e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:12,901][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ to] are: tensor([1.0031e-07, 1.7541e-04, 2.7954e-01, 5.4652e-04, 4.5815e-03, 6.2987e-02,
        2.2220e-01, 1.9392e-04, 2.7139e-01, 2.2670e-05, 7.6431e-03, 1.1978e-01,
        2.1644e-04, 3.0728e-02], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:12,901][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0239, 0.0181, 0.0400, 0.0679, 0.0121, 0.0840, 0.0392, 0.0663, 0.1957,
        0.0433, 0.0397, 0.0079, 0.2115, 0.1503], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:12,959][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:20:12,961][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:12,961][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:12,962][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:12,962][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:12,962][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:12,962][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:12,963][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:12,963][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:12,964][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:12,967][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:12,968][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:12,968][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:12,968][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Benjamin] are: tensor([0.1334, 0.8666], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:12,968][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Benjamin] are: tensor([4.4057e-04, 9.9956e-01], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:12,969][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Benjamin] are: tensor([0.2680, 0.7320], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:12,969][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Benjamin] are: tensor([0.1068, 0.8932], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:12,969][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Benjamin] are: tensor([0.5593, 0.4407], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:12,970][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Benjamin] are: tensor([0.0706, 0.9294], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:12,970][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Benjamin] are: tensor([0.1838, 0.8162], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:12,981][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Benjamin] are: tensor([0.1763, 0.8237], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:12,981][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Benjamin] are: tensor([0.0128, 0.9872], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:12,982][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Benjamin] are: tensor([0.1601, 0.8399], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:12,982][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Benjamin] are: tensor([0.0030, 0.9970], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:12,982][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Benjamin] are: tensor([6.4782e-04, 9.9935e-01], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:12,983][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0197, 0.4986, 0.4818], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:12,983][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([4.4133e-05, 9.9582e-02, 9.0037e-01], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:12,985][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.2554, 0.3524, 0.3922], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:12,987][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.2382, 0.3778, 0.3841], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:12,988][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.3093, 0.0467, 0.6440], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:12,988][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([1.1769e-02, 3.9791e-04, 9.8783e-01], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:12,988][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0022, 0.1426, 0.8552], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:12,989][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2510, 0.5421, 0.2069], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:12,989][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0261, 0.5890, 0.3849], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:12,989][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([4.9097e-03, 1.9182e-04, 9.9490e-01], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:12,990][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0029, 0.9896, 0.0075], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:12,990][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([5.2978e-05, 1.2440e-01, 8.7554e-01], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:12,994][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Alexander] are: tensor([0.0096, 0.2191, 0.1970, 0.5743], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:12,994][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Alexander] are: tensor([3.7452e-05, 1.9857e-01, 6.0898e-01, 1.9242e-01], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:12,995][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Alexander] are: tensor([0.1016, 0.3486, 0.1648, 0.3850], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:12,995][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Alexander] are: tensor([0.3781, 0.3613, 0.1779, 0.0827], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:12,995][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Alexander] are: tensor([0.2099, 0.0609, 0.5412, 0.1879], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:12,996][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Alexander] are: tensor([2.1715e-02, 8.0584e-04, 4.1301e-03, 9.7335e-01], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:12,996][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Alexander] are: tensor([0.0054, 0.1429, 0.4280, 0.4237], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:12,996][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Alexander] are: tensor([0.0823, 0.2482, 0.1650, 0.5044], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:12,999][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Alexander] are: tensor([0.0485, 0.6158, 0.1347, 0.2009], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:13,001][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Alexander] are: tensor([1.8312e-02, 2.6010e-04, 1.2094e-03, 9.8022e-01], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:13,001][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Alexander] are: tensor([0.0019, 0.8714, 0.0232, 0.1035], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:13,001][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Alexander] are: tensor([0.0013, 0.2558, 0.3168, 0.4261], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:13,002][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([4.9592e-04, 1.0336e-02, 7.0602e-02, 1.6016e-01, 7.5841e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:13,002][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([1.7535e-05, 3.8273e-02, 4.9184e-01, 1.0436e-01, 3.6550e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:13,003][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([0.0093, 0.0781, 0.1790, 0.3953, 0.3383], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:13,003][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([0.1857, 0.1977, 0.2754, 0.1757, 0.1655], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:13,003][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([0.0832, 0.0148, 0.2737, 0.2583, 0.3699], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:13,005][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([5.8689e-05, 6.5919e-07, 1.5077e-03, 9.3649e-01, 6.1947e-02],
       device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:13,007][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([3.3867e-04, 1.7487e-02, 2.3667e-01, 2.1245e-01, 5.3305e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:13,008][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([0.0757, 0.0607, 0.3062, 0.2393, 0.3182], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:13,008][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([0.0096, 0.1306, 0.1512, 0.1402, 0.5684], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:13,008][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([1.2438e-05, 8.1765e-08, 5.9587e-04, 9.8289e-01, 1.6501e-02],
       device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:13,009][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([3.4036e-04, 8.4029e-01, 9.0902e-03, 9.5544e-02, 5.4733e-02],
       device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:13,009][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([1.6251e-04, 2.3371e-02, 2.9306e-01, 3.7811e-01, 3.0530e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:13,009][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0036, 0.0800, 0.0260, 0.3477, 0.4837, 0.0591], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:13,010][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([1.5112e-05, 2.8844e-02, 1.1219e-01, 1.0194e-01, 1.5238e-01, 6.0462e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:13,010][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0284, 0.1058, 0.0757, 0.4176, 0.2084, 0.1640], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:13,012][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.5388, 0.1561, 0.0992, 0.0877, 0.0539, 0.0643], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:13,014][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.3495, 0.0024, 0.0267, 0.0942, 0.0400, 0.4873], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:13,015][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([6.7028e-04, 1.7803e-07, 8.7950e-06, 3.0762e-01, 3.4756e-04, 6.9135e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:13,015][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0015, 0.0571, 0.0957, 0.2708, 0.3020, 0.2729], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:13,015][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.1776, 0.1199, 0.0783, 0.5250, 0.0404, 0.0589], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:13,016][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0184, 0.1768, 0.1348, 0.1829, 0.3275, 0.1596], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:13,016][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([7.3979e-05, 1.5818e-08, 1.2437e-06, 1.0042e-01, 1.9091e-05, 8.9948e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:13,017][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0014, 0.7923, 0.0037, 0.1619, 0.0382, 0.0025], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:13,017][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0099, 0.0351, 0.1979, 0.1607, 0.1183, 0.4781], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:13,019][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0007, 0.0441, 0.0176, 0.2788, 0.4454, 0.0596, 0.1538],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:13,021][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([3.4891e-06, 1.2093e-02, 9.5172e-02, 5.8290e-02, 8.4769e-02, 5.0443e-01,
        2.4524e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:13,022][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0135, 0.0659, 0.0413, 0.4088, 0.2036, 0.1553, 0.1117],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:13,022][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.3924, 0.1278, 0.0840, 0.1182, 0.0589, 0.0894, 0.1293],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:13,022][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0620, 0.0006, 0.0150, 0.0439, 0.0193, 0.5091, 0.3501],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:13,023][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([2.8205e-04, 1.4388e-07, 9.9043e-06, 1.3764e-01, 4.1674e-04, 5.7090e-01,
        2.9075e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:13,023][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([2.1567e-04, 1.8982e-02, 7.2181e-02, 1.3203e-01, 2.2109e-01, 2.9933e-01,
        2.5616e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:13,023][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.1117, 0.0680, 0.1099, 0.2981, 0.0552, 0.1126, 0.2446],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:13,024][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0107, 0.1013, 0.0895, 0.1851, 0.2081, 0.1718, 0.2335],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:13,025][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([1.3783e-05, 1.0215e-08, 7.0354e-07, 4.8925e-02, 1.1585e-05, 6.8594e-01,
        2.6511e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:13,028][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([4.8104e-04, 8.2250e-01, 2.8218e-03, 1.3410e-01, 3.5259e-02, 3.1672e-03,
        1.6689e-03], device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:13,028][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([2.0820e-04, 6.7526e-03, 9.3869e-02, 1.0339e-01, 1.2342e-01, 4.1493e-01,
        2.5743e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:13,029][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ station] are: tensor([0.0013, 0.0083, 0.0195, 0.2384, 0.2166, 0.0496, 0.1124, 0.3538],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:13,029][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ station] are: tensor([4.5203e-06, 2.2238e-03, 4.8554e-02, 2.6205e-02, 4.7483e-02, 4.7817e-01,
        2.1973e-01, 1.7763e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:13,029][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ station] are: tensor([0.0089, 0.0245, 0.0510, 0.2927, 0.1878, 0.1779, 0.0894, 0.1679],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:13,030][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ station] are: tensor([0.1422, 0.0679, 0.0477, 0.1245, 0.0660, 0.0448, 0.0564, 0.4505],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:13,030][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ station] are: tensor([0.0384, 0.0006, 0.0105, 0.0276, 0.0218, 0.5002, 0.2759, 0.1251],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:13,031][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ station] are: tensor([2.1749e-04, 6.9745e-08, 1.0412e-05, 6.8000e-02, 2.5604e-04, 5.1747e-01,
        2.0693e-01, 2.0712e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:13,035][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ station] are: tensor([0.0009, 0.0123, 0.0336, 0.2222, 0.1869, 0.1339, 0.1084, 0.3017],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:13,035][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ station] are: tensor([0.0889, 0.0427, 0.1153, 0.2712, 0.1135, 0.0738, 0.1140, 0.1806],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:13,035][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ station] are: tensor([0.0228, 0.0988, 0.0373, 0.1731, 0.1460, 0.0863, 0.1602, 0.2755],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:13,036][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ station] are: tensor([5.2384e-05, 1.0911e-08, 9.5905e-07, 1.3201e-02, 1.8652e-05, 5.1860e-01,
        1.3852e-01, 3.2961e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:13,036][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ station] are: tensor([0.0008, 0.6109, 0.0058, 0.3030, 0.0508, 0.0046, 0.0032, 0.0208],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:13,037][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ station] are: tensor([0.0289, 0.0129, 0.0739, 0.1596, 0.0924, 0.0655, 0.0344, 0.5324],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:13,037][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([2.6264e-04, 5.0029e-02, 1.2782e-02, 2.8321e-01, 8.0841e-02, 4.2090e-02,
        8.3888e-02, 2.6467e-01, 1.8222e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:13,038][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([2.7180e-06, 1.6170e-02, 9.9021e-02, 5.5285e-02, 4.2256e-02, 3.8971e-01,
        1.2760e-01, 8.2477e-02, 1.8747e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:13,041][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0027, 0.0755, 0.0381, 0.4256, 0.0630, 0.1110, 0.0464, 0.1086, 0.1291],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:13,042][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.1021, 0.2488, 0.0500, 0.0912, 0.0147, 0.0278, 0.0289, 0.3991, 0.0375],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:13,042][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0262, 0.0017, 0.0098, 0.0366, 0.0082, 0.3142, 0.2453, 0.0459, 0.3120],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:13,043][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([1.7836e-04, 5.2582e-08, 1.6351e-06, 3.7800e-02, 4.4765e-05, 9.9732e-02,
        6.1305e-02, 5.3463e-02, 7.4747e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:13,043][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([6.5149e-05, 2.2802e-02, 5.8718e-02, 1.0457e-01, 4.3701e-02, 2.6894e-01,
        1.2098e-01, 1.2854e-01, 2.5169e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:13,043][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0124, 0.0327, 0.0421, 0.0789, 0.0168, 0.0277, 0.0459, 0.0403, 0.7031],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:13,044][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0100, 0.1140, 0.0758, 0.2872, 0.0545, 0.1070, 0.1242, 0.1236, 0.1036],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:13,045][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([1.5465e-05, 3.1268e-09, 1.1617e-07, 1.8262e-02, 2.7549e-06, 1.1311e-01,
        6.5597e-02, 3.7223e-02, 7.6579e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:13,046][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([6.7328e-04, 7.7080e-01, 5.1015e-03, 1.7757e-01, 2.6511e-02, 3.5082e-03,
        2.1619e-03, 1.2488e-02, 1.1842e-03], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:13,048][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([2.1129e-04, 1.1056e-02, 4.2776e-02, 1.0617e-01, 3.7533e-02, 2.2708e-01,
        1.0173e-01, 1.7952e-01, 2.9392e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:13,049][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Benjamin] are: tensor([0.0008, 0.0362, 0.0183, 0.1790, 0.2206, 0.0338, 0.0602, 0.2560, 0.1227,
        0.0723], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:13,049][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Benjamin] are: tensor([7.0920e-06, 2.3322e-02, 7.8048e-02, 7.0026e-02, 9.7397e-02, 3.3813e-01,
        1.3466e-01, 1.4296e-01, 1.0440e-01, 1.1056e-02], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:13,049][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Benjamin] are: tensor([0.0074, 0.1386, 0.0508, 0.2701, 0.1467, 0.0676, 0.0229, 0.1630, 0.0534,
        0.0795], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:13,050][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Benjamin] are: tensor([0.0913, 0.2470, 0.0823, 0.0688, 0.0518, 0.0313, 0.0220, 0.3167, 0.0261,
        0.0626], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:13,050][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Benjamin] are: tensor([0.0312, 0.0041, 0.0169, 0.0204, 0.0414, 0.3674, 0.1574, 0.0628, 0.1412,
        0.1572], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:13,051][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Benjamin] are: tensor([3.5024e-04, 6.7783e-07, 2.3362e-06, 3.0668e-02, 4.1995e-05, 3.0397e-02,
        1.2475e-02, 2.4742e-02, 9.5530e-02, 8.0579e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:13,053][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Benjamin] are: tensor([0.0007, 0.0226, 0.0627, 0.1634, 0.1142, 0.1481, 0.1073, 0.1365, 0.1503,
        0.0941], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:13,055][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Benjamin] are: tensor([0.0202, 0.0375, 0.0662, 0.2126, 0.0443, 0.0298, 0.0368, 0.0574, 0.4543,
        0.0411], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:13,055][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Benjamin] are: tensor([0.0065, 0.0757, 0.0281, 0.1717, 0.1609, 0.0438, 0.1341, 0.2216, 0.0736,
        0.0839], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:13,056][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Benjamin] are: tensor([4.5608e-05, 4.8841e-08, 6.3638e-08, 5.4686e-03, 1.9015e-06, 8.2351e-03,
        6.8205e-03, 1.7908e-02, 4.8451e-02, 9.1307e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:13,056][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Benjamin] are: tensor([0.0007, 0.6606, 0.0161, 0.1878, 0.1003, 0.0060, 0.0029, 0.0220, 0.0012,
        0.0023], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:13,057][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Benjamin] are: tensor([0.0011, 0.0389, 0.0417, 0.1022, 0.0793, 0.0842, 0.0688, 0.2105, 0.2137,
        0.1595], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:13,057][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([1.1817e-04, 4.0702e-03, 1.1106e-02, 9.2701e-02, 6.1293e-02, 6.0271e-02,
        7.6284e-02, 1.1840e-01, 2.2351e-01, 8.7808e-02, 2.6443e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:13,057][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([8.3966e-06, 1.1237e-02, 9.6771e-02, 4.8840e-02, 3.5062e-02, 2.6178e-01,
        1.0582e-01, 2.3146e-01, 1.4493e-01, 5.7437e-03, 5.8350e-02],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:13,060][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.0115, 0.0411, 0.0363, 0.2230, 0.0719, 0.0811, 0.0414, 0.1005, 0.0979,
        0.1052, 0.1901], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:13,062][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.1316, 0.1363, 0.0316, 0.0735, 0.0118, 0.0243, 0.0307, 0.3467, 0.0563,
        0.0970, 0.0602], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:13,062][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.0051, 0.0005, 0.0062, 0.0234, 0.0082, 0.3084, 0.1674, 0.0409, 0.2172,
        0.1346, 0.0881], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:13,063][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([2.5345e-06, 7.1114e-10, 1.5970e-07, 2.4925e-03, 8.6941e-06, 2.7368e-02,
        1.8281e-02, 9.0841e-03, 2.7774e-01, 6.5453e-01, 1.0496e-02],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:13,063][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.0003, 0.0125, 0.0727, 0.0636, 0.0593, 0.1846, 0.0989, 0.0854, 0.2487,
        0.0284, 0.1458], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:13,063][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0262, 0.0291, 0.0624, 0.1069, 0.0279, 0.0421, 0.0445, 0.0359, 0.5156,
        0.0290, 0.0804], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:13,064][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.0128, 0.1051, 0.0283, 0.0709, 0.0693, 0.0495, 0.0859, 0.2122, 0.1377,
        0.0867, 0.1416], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:13,064][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([7.9949e-08, 2.0170e-11, 5.8771e-09, 2.4950e-04, 2.4300e-07, 2.3477e-02,
        1.2457e-02, 3.7604e-03, 1.4943e-01, 8.0316e-01, 7.4717e-03],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:13,067][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0007, 0.5550, 0.0113, 0.2639, 0.0486, 0.0054, 0.0033, 0.0236, 0.0017,
        0.0013, 0.0852], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:13,069][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.0010, 0.0128, 0.0459, 0.1019, 0.0357, 0.1295, 0.0671, 0.1256, 0.2384,
        0.1213, 0.1207], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:13,069][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0006, 0.0143, 0.0073, 0.1364, 0.0738, 0.0361, 0.0759, 0.1377, 0.0814,
        0.0390, 0.2461, 0.1512], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:13,069][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([9.4411e-06, 7.6110e-03, 3.8710e-02, 3.1209e-02, 2.3723e-02, 2.8414e-01,
        1.3454e-01, 1.3494e-01, 1.4565e-01, 7.7828e-03, 1.0246e-01, 8.9225e-02],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:13,070][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0091, 0.0320, 0.0244, 0.1973, 0.0760, 0.0957, 0.0511, 0.0831, 0.0738,
        0.0972, 0.2214, 0.0389], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:13,070][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.2686, 0.0731, 0.0264, 0.0490, 0.0176, 0.0272, 0.0286, 0.3237, 0.0402,
        0.0482, 0.0452, 0.0523], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:13,071][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([3.0164e-02, 3.0769e-04, 4.2465e-03, 2.5901e-02, 4.5294e-03, 1.3794e-01,
        1.0101e-01, 2.9394e-02, 1.4956e-01, 1.1646e-01, 4.7312e-02, 3.5319e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:13,071][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([4.8276e-05, 6.5094e-09, 2.3987e-07, 1.0413e-02, 8.0474e-06, 1.7084e-02,
        1.0541e-02, 8.9712e-03, 1.4968e-01, 6.3093e-01, 5.8659e-03, 1.6645e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:13,073][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0003, 0.0070, 0.0377, 0.0703, 0.0633, 0.1503, 0.1317, 0.0908, 0.1460,
        0.0257, 0.1676, 0.1092], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:13,075][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.1153, 0.0232, 0.0316, 0.0872, 0.0156, 0.0371, 0.0644, 0.0590, 0.4093,
        0.0250, 0.0384, 0.0940], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:13,076][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0092, 0.0575, 0.0468, 0.1097, 0.0754, 0.0760, 0.1217, 0.1157, 0.1142,
        0.0762, 0.1176, 0.0799], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:13,076][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([2.5519e-06, 2.0063e-10, 6.4019e-09, 2.0891e-03, 7.3038e-08, 7.0646e-03,
        3.2935e-03, 1.5558e-03, 5.1102e-02, 8.7833e-01, 3.0382e-03, 5.3528e-02],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:13,077][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0015, 0.5167, 0.0053, 0.1887, 0.0508, 0.0060, 0.0037, 0.0215, 0.0014,
        0.0013, 0.1906, 0.0124], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:13,077][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0013, 0.0038, 0.0339, 0.0695, 0.0292, 0.1602, 0.1037, 0.1100, 0.2417,
        0.0631, 0.1515, 0.0321], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:13,077][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ computer] are: tensor([0.0005, 0.0166, 0.0083, 0.1146, 0.0798, 0.0239, 0.0339, 0.1436, 0.0927,
        0.0307, 0.1833, 0.0817, 0.1905], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:13,078][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ computer] are: tensor([4.1179e-06, 2.9541e-02, 8.8085e-02, 4.5108e-02, 3.2176e-02, 2.7653e-01,
        8.9690e-02, 1.0005e-01, 1.3461e-01, 7.0379e-03, 9.8131e-02, 4.6433e-02,
        5.2595e-02], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:13,081][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ computer] are: tensor([0.0024, 0.0345, 0.0375, 0.1753, 0.0877, 0.0698, 0.0305, 0.1223, 0.0598,
        0.0471, 0.1628, 0.0222, 0.1482], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:13,082][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ computer] are: tensor([0.0597, 0.2132, 0.0364, 0.0424, 0.0304, 0.0267, 0.0173, 0.3597, 0.0287,
        0.0348, 0.0465, 0.0278, 0.0765], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:13,082][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ computer] are: tensor([0.0073, 0.0007, 0.0058, 0.0171, 0.0076, 0.1160, 0.0484, 0.0217, 0.0813,
        0.0511, 0.0455, 0.1592, 0.4382], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:13,083][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ computer] are: tensor([1.0099e-04, 8.3315e-08, 4.2847e-07, 1.1920e-02, 1.8012e-05, 1.0556e-02,
        6.4781e-03, 9.8776e-03, 6.9253e-02, 2.5859e-01, 8.4249e-03, 6.2280e-02,
        5.6250e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:13,083][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ computer] are: tensor([1.1792e-04, 1.6265e-02, 4.6811e-02, 9.4461e-02, 2.4886e-02, 1.5235e-01,
        6.6356e-02, 1.2202e-01, 1.6055e-01, 4.1805e-02, 7.8664e-02, 5.1366e-02,
        1.4435e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:13,084][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ computer] are: tensor([0.0361, 0.0372, 0.0441, 0.1215, 0.0201, 0.0332, 0.0408, 0.0508, 0.3521,
        0.0181, 0.0538, 0.0562, 0.1358], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:13,084][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ computer] are: tensor([0.0020, 0.0628, 0.0334, 0.1033, 0.1026, 0.0529, 0.0781, 0.1391, 0.0668,
        0.0393, 0.1760, 0.0440, 0.0997], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:13,085][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ computer] are: tensor([3.5230e-06, 8.0845e-10, 1.1208e-09, 2.2629e-04, 5.9754e-08, 6.1360e-04,
        4.1176e-04, 1.2139e-03, 4.1549e-03, 6.6689e-02, 5.7941e-04, 6.3581e-03,
        9.1975e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:13,087][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ computer] are: tensor([2.9791e-04, 7.3970e-01, 7.2040e-03, 1.2480e-01, 2.5613e-02, 2.7476e-03,
        1.6333e-03, 7.2782e-03, 1.1019e-03, 5.4178e-04, 8.2599e-02, 4.2609e-03,
        2.2207e-03], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:13,089][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ computer] are: tensor([0.0030, 0.0163, 0.0318, 0.0772, 0.0298, 0.0511, 0.0337, 0.0854, 0.1557,
        0.0346, 0.0628, 0.0085, 0.4101], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:13,089][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0005, 0.0234, 0.0045, 0.1603, 0.0627, 0.0159, 0.0337, 0.1336, 0.0785,
        0.0263, 0.1513, 0.0766, 0.1499, 0.0828], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:13,090][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([6.6691e-06, 2.3114e-02, 4.5628e-02, 5.3200e-02, 2.3459e-02, 2.0254e-01,
        7.8617e-02, 6.9618e-02, 1.1151e-01, 4.4691e-03, 7.9700e-02, 5.1699e-02,
        2.4139e-02, 2.3230e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:13,090][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0051, 0.0351, 0.0266, 0.1936, 0.0510, 0.0638, 0.0338, 0.0544, 0.0806,
        0.0669, 0.1352, 0.0248, 0.0956, 0.1335], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:13,090][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.1954, 0.1011, 0.0302, 0.0582, 0.0143, 0.0299, 0.0324, 0.1728, 0.0738,
        0.0412, 0.0388, 0.0461, 0.1063, 0.0595], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:13,091][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([1.7491e-02, 2.5076e-04, 1.9713e-03, 1.2652e-02, 1.5527e-03, 2.9109e-02,
        3.3794e-02, 8.2483e-03, 5.8456e-02, 2.8776e-02, 1.6230e-02, 9.8541e-02,
        1.8013e-01, 5.1280e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:13,092][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([1.5595e-04, 6.3051e-09, 2.4716e-08, 6.1755e-03, 8.0476e-07, 1.1659e-03,
        1.0026e-03, 1.1638e-03, 1.8428e-02, 1.5995e-01, 6.7301e-04, 1.3928e-02,
        3.2190e-01, 4.7546e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:13,096][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0002, 0.0132, 0.0234, 0.0877, 0.0339, 0.0841, 0.0668, 0.0833, 0.1026,
        0.0248, 0.0846, 0.0484, 0.1150, 0.2321], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:13,098][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0666, 0.0327, 0.0265, 0.0928, 0.0100, 0.0231, 0.0373, 0.0337, 0.4776,
        0.0166, 0.0178, 0.0398, 0.0564, 0.0690], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:13,099][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0028, 0.0562, 0.0484, 0.1278, 0.0763, 0.0521, 0.0911, 0.0901, 0.1054,
        0.0535, 0.1217, 0.0558, 0.0497, 0.0693], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:13,099][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([6.5636e-06, 2.2352e-10, 2.3503e-10, 2.0733e-04, 3.7390e-09, 1.4522e-04,
        1.4502e-04, 1.6684e-04, 2.5879e-03, 7.2403e-02, 9.5244e-05, 2.0289e-03,
        4.5232e-01, 4.6990e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:13,099][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([9.7762e-04, 6.5189e-01, 3.8914e-03, 2.0448e-01, 2.2849e-02, 2.9439e-03,
        1.6574e-03, 8.0403e-03, 8.4829e-04, 6.3876e-04, 9.2843e-02, 5.1631e-03,
        2.0340e-03, 1.7406e-03], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:13,100][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0239, 0.0181, 0.0400, 0.0679, 0.0121, 0.0840, 0.0392, 0.0663, 0.1957,
        0.0433, 0.0397, 0.0079, 0.2115, 0.1503], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:13,101][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:20:13,102][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 91],
        [ 42],
        [ 19],
        [704],
        [118],
        [  3],
        [  7],
        [ 22],
        [  8],
        [ 32],
        [  7],
        [  7],
        [  1],
        [  2]], device='cuda:0')
[2024-07-24 10:20:13,105][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 73],
        [ 63],
        [ 14],
        [489],
        [ 74],
        [  1],
        [  5],
        [  7],
        [  2],
        [ 10],
        [  1],
        [  3],
        [  1],
        [  1]], device='cuda:0')
[2024-07-24 10:20:13,107][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[11893],
        [24943],
        [40015],
        [50195],
        [49392],
        [50067],
        [49934],
        [50037],
        [50032],
        [49785],
        [49019],
        [49627],
        [49480],
        [49694]], device='cuda:0')
[2024-07-24 10:20:13,108][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[38626],
        [21493],
        [27620],
        [30752],
        [29783],
        [20553],
        [18907],
        [20582],
        [20317],
        [22623],
        [23013],
        [20288],
        [20969],
        [19025]], device='cuda:0')
[2024-07-24 10:20:13,109][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[10270],
        [45486],
        [28929],
        [48951],
        [38801],
        [42910],
        [40804],
        [30018],
        [44198],
        [39279],
        [33068],
        [29239],
        [29793],
        [33117]], device='cuda:0')
[2024-07-24 10:20:13,110][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[3342],
        [6232],
        [6171],
        [6041],
        [5689],
        [4883],
        [5001],
        [2022],
        [2344],
        [2563],
        [2381],
        [2232],
        [2511],
        [3690]], device='cuda:0')
[2024-07-24 10:20:13,111][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[15245],
        [33172],
        [36787],
        [34446],
        [32920],
        [35179],
        [38397],
        [38647],
        [37081],
        [36509],
        [37045],
        [39490],
        [44640],
        [40993]], device='cuda:0')
[2024-07-24 10:20:13,113][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[16802],
        [39429],
        [38217],
        [27775],
        [28261],
        [39180],
        [39470],
        [40663],
        [41487],
        [39830],
        [40761],
        [40258],
        [37319],
        [38038]], device='cuda:0')
[2024-07-24 10:20:13,115][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[32085],
        [45001],
        [43521],
        [49052],
        [41233],
        [47126],
        [45908],
        [47516],
        [47334],
        [47259],
        [45437],
        [45829],
        [46543],
        [44949]], device='cuda:0')
[2024-07-24 10:20:13,116][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[32708],
        [ 4243],
        [ 4908],
        [   44],
        [ 2067],
        [   29],
        [ 1139],
        [ 2036],
        [17779],
        [ 4398],
        [13104],
        [13002],
        [ 9780],
        [14196]], device='cuda:0')
[2024-07-24 10:20:13,117][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[14656],
        [25417],
        [20031],
        [19502],
        [ 9223],
        [11536],
        [10989],
        [10273],
        [11101],
        [ 9075],
        [11435],
        [11311],
        [10942],
        [10349]], device='cuda:0')
[2024-07-24 10:20:13,118][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[30478],
        [24868],
        [46531],
        [36623],
        [36501],
        [41776],
        [42086],
        [41524],
        [45021],
        [39568],
        [40771],
        [39977],
        [48533],
        [47404]], device='cuda:0')
[2024-07-24 10:20:13,120][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[2799],
        [ 210],
        [1306],
        [1303],
        [1315],
        [1191],
        [1177],
        [1197],
        [1258],
        [1197],
        [1240],
        [1130],
        [1217],
        [1185]], device='cuda:0')
[2024-07-24 10:20:13,121][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[17140],
        [25668],
        [29392],
        [33218],
        [32410],
        [30625],
        [30517],
        [32782],
        [29819],
        [30839],
        [30456],
        [29565],
        [28587],
        [28419]], device='cuda:0')
[2024-07-24 10:20:13,123][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 5685],
        [18368],
        [10857],
        [16436],
        [ 4260],
        [ 3771],
        [ 6814],
        [ 9250],
        [10389],
        [18575],
        [10221],
        [12208],
        [ 6293],
        [ 7079]], device='cuda:0')
[2024-07-24 10:20:13,124][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[21592],
        [17806],
        [18664],
        [33244],
        [35123],
        [36463],
        [37338],
        [34563],
        [36279],
        [36442],
        [41746],
        [41634],
        [39826],
        [39579]], device='cuda:0')
[2024-07-24 10:20:13,125][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[39946],
        [33076],
        [44194],
        [43451],
        [42064],
        [38287],
        [37948],
        [39766],
        [40606],
        [41062],
        [41602],
        [40036],
        [40123],
        [39176]], device='cuda:0')
[2024-07-24 10:20:13,126][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[17633],
        [29076],
        [27192],
        [29947],
        [25557],
        [24780],
        [23882],
        [21742],
        [25902],
        [24908],
        [21719],
        [20836],
        [20311],
        [20897]], device='cuda:0')
[2024-07-24 10:20:13,128][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[30882],
        [11996],
        [10214],
        [13322],
        [12306],
        [14773],
        [11817],
        [14120],
        [13256],
        [12488],
        [14336],
        [14829],
        [13519],
        [13741]], device='cuda:0')
[2024-07-24 10:20:13,129][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[16137],
        [ 1437],
        [ 4649],
        [ 5189],
        [ 5478],
        [ 7242],
        [ 6434],
        [ 5816],
        [ 5427],
        [ 5183],
        [ 4793],
        [ 4347],
        [ 3278],
        [ 6710]], device='cuda:0')
[2024-07-24 10:20:13,132][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[2871],
        [4324],
        [5659],
        [4675],
        [4251],
        [3268],
        [3545],
        [2759],
        [4007],
        [3897],
        [3743],
        [3519],
        [3807],
        [4681]], device='cuda:0')
[2024-07-24 10:20:13,133][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[ 4847],
        [10826],
        [ 9646],
        [ 4564],
        [ 5560],
        [ 2851],
        [ 3605],
        [ 3012],
        [ 2727],
        [ 3076],
        [ 2756],
        [ 2898],
        [ 2653],
        [ 2608]], device='cuda:0')
[2024-07-24 10:20:13,134][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[11195],
        [12601],
        [ 9589],
        [15272],
        [14709],
        [17528],
        [16611],
        [16881],
        [12192],
        [14885],
        [12728],
        [14094],
        [15115],
        [13886]], device='cuda:0')
[2024-07-24 10:20:13,135][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[ 8471],
        [13668],
        [26314],
        [22685],
        [30761],
        [32037],
        [30257],
        [27071],
        [29706],
        [27223],
        [20584],
        [21081],
        [19145],
        [20559]], device='cuda:0')
[2024-07-24 10:20:13,136][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[37877],
        [28774],
        [ 9742],
        [26545],
        [26387],
        [ 7363],
        [ 8862],
        [ 9224],
        [17358],
        [29495],
        [27569],
        [29457],
        [13564],
        [13291]], device='cuda:0')
[2024-07-24 10:20:13,138][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[19051],
        [19443],
        [19499],
        [19744],
        [19711],
        [19755],
        [19718],
        [20225],
        [19785],
        [20327],
        [21664],
        [23680],
        [21031],
        [21397]], device='cuda:0')
[2024-07-24 10:20:13,140][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 3717],
        [ 3067],
        [12050],
        [ 8371],
        [ 8259],
        [11493],
        [12393],
        [ 7984],
        [13625],
        [ 9065],
        [10220],
        [11795],
        [ 4557],
        [ 7969]], device='cuda:0')
[2024-07-24 10:20:13,141][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[13977],
        [23389],
        [15275],
        [10927],
        [10343],
        [12849],
        [12435],
        [16815],
        [10808],
        [11622],
        [11277],
        [11077],
        [19574],
        [14604]], device='cuda:0')
[2024-07-24 10:20:13,142][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[38512],
        [10287],
        [20628],
        [ 3438],
        [32116],
        [26626],
        [23247],
        [33417],
        [12426],
        [15319],
        [29592],
        [ 6370],
        [31540],
        [15680]], device='cuda:0')
[2024-07-24 10:20:13,143][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[5276],
        [5276],
        [5276],
        [5276],
        [5276],
        [5276],
        [5276],
        [5276],
        [5276],
        [5276],
        [5276],
        [5276],
        [5276],
        [5276]], device='cuda:0')
[2024-07-24 10:20:13,219][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:20:13,220][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:13,220][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:13,220][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:13,221][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:13,221][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:13,221][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:13,222][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:13,222][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:13,224][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:13,226][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:13,226][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:13,227][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:13,227][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Benjamin] are: tensor([0.6627, 0.3373], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:13,227][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Benjamin] are: tensor([0.0073, 0.9927], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:13,228][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Benjamin] are: tensor([0.0640, 0.9360], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:13,228][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Benjamin] are: tensor([0.3201, 0.6799], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:13,228][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Benjamin] are: tensor([0.2961, 0.7039], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:13,229][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Benjamin] are: tensor([0.0030, 0.9970], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:13,231][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Benjamin] are: tensor([0.3579, 0.6421], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:13,233][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Benjamin] are: tensor([0.0420, 0.9580], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:13,233][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Benjamin] are: tensor([0.0206, 0.9794], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:13,234][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Benjamin] are: tensor([0.0012, 0.9988], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:13,234][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Benjamin] are: tensor([0.9741, 0.0259], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:13,234][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Benjamin] are: tensor([0.8276, 0.1724], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:13,235][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.6636, 0.0374, 0.2989], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:13,235][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0057, 0.4167, 0.5776], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:13,235][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0451, 0.4842, 0.4707], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:13,236][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0511, 0.1245, 0.8244], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:13,238][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0162, 0.0215, 0.9623], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:13,240][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ and] are: tensor([5.4560e-04, 2.0836e-01, 7.9110e-01], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:13,240][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0703, 0.0365, 0.8932], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:13,240][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0492, 0.6095, 0.3413], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:13,241][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0135, 0.0522, 0.9343], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:13,241][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ and] are: tensor([6.3094e-04, 2.6268e-01, 7.3669e-01], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:13,241][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.9562, 0.0082, 0.0356], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:13,242][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.1242, 0.0043, 0.8715], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:13,242][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Alexander] are: tensor([0.1702, 0.0545, 0.2104, 0.5649], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:13,244][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Alexander] are: tensor([0.0017, 0.3618, 0.5318, 0.1047], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:13,246][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Alexander] are: tensor([0.0083, 0.1383, 0.4118, 0.4416], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:13,247][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Alexander] are: tensor([0.0346, 0.0507, 0.2658, 0.6489], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:13,247][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Alexander] are: tensor([0.0039, 0.0167, 0.4779, 0.5015], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:13,247][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Alexander] are: tensor([1.5178e-04, 7.1423e-02, 5.1213e-01, 4.1629e-01], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:13,248][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Alexander] are: tensor([0.0132, 0.0235, 0.3793, 0.5839], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:13,248][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Alexander] are: tensor([0.0152, 0.3055, 0.1519, 0.5274], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:13,249][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Alexander] are: tensor([0.0294, 0.1108, 0.4277, 0.4321], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:13,249][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Alexander] are: tensor([1.3435e-04, 2.1070e-01, 5.2697e-01, 2.6219e-01], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:13,251][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Alexander] are: tensor([0.1714, 0.0063, 0.0227, 0.7996], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:13,253][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Alexander] are: tensor([0.6760, 0.0028, 0.0853, 0.2359], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:13,254][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ went] are: tensor([0.5045, 0.0061, 0.0645, 0.3297, 0.0952], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:13,254][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ went] are: tensor([0.0012, 0.1146, 0.7693, 0.0603, 0.0545], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:13,254][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ went] are: tensor([0.0020, 0.0073, 0.0521, 0.1229, 0.8157], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:13,255][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ went] are: tensor([0.0024, 0.0185, 0.2274, 0.6810, 0.0706], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:13,255][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ went] are: tensor([3.7652e-04, 1.6040e-03, 8.1055e-02, 1.4448e-01, 7.7248e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:13,255][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ went] are: tensor([4.3995e-05, 2.5383e-02, 2.1938e-01, 1.9839e-01, 5.5680e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:13,256][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ went] are: tensor([0.0019, 0.0013, 0.0351, 0.0584, 0.9033], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:13,258][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ went] are: tensor([0.0011, 0.0239, 0.0459, 0.1332, 0.7958], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:13,260][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.0027, 0.0046, 0.1301, 0.3418, 0.5208], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:13,260][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ went] are: tensor([5.0234e-05, 2.5174e-02, 2.6850e-01, 6.3457e-02, 6.4282e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:13,261][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ went] are: tensor([0.0156, 0.0014, 0.0644, 0.8082, 0.1104], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:13,261][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ went] are: tensor([5.5339e-02, 4.5174e-04, 1.6397e-01, 5.0843e-01, 2.7181e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:13,261][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.5329, 0.0024, 0.0313, 0.2351, 0.0378, 0.1605], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:13,262][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0103, 0.1963, 0.3743, 0.1370, 0.0644, 0.2177], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:13,262][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0008, 0.0129, 0.0811, 0.3153, 0.4025, 0.1874], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:13,262][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0316, 0.0088, 0.1048, 0.4118, 0.0208, 0.4222], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:13,264][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ to] are: tensor([1.4702e-03, 3.5781e-04, 2.2502e-02, 6.3226e-02, 1.8917e-01, 7.2328e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:13,266][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ to] are: tensor([6.2523e-05, 1.5202e-02, 1.0938e-01, 1.5991e-01, 3.4525e-01, 3.7020e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:13,267][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0081, 0.0016, 0.0199, 0.1117, 0.5708, 0.2879], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:13,267][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0203, 0.0636, 0.0298, 0.1669, 0.5775, 0.1420], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:13,268][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0081, 0.0014, 0.0302, 0.1898, 0.1202, 0.6502], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:13,268][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0004, 0.0639, 0.1472, 0.1382, 0.3819, 0.2684], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:13,268][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.3922, 0.0007, 0.0044, 0.1329, 0.0022, 0.4676], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:13,269][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ to] are: tensor([2.7411e-01, 8.9109e-05, 1.9099e-02, 7.2713e-02, 8.2208e-03, 6.2576e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:13,269][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.2644, 0.0010, 0.0260, 0.1133, 0.0093, 0.1924, 0.3937],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:13,270][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0038, 0.1600, 0.3717, 0.1050, 0.0560, 0.2135, 0.0899],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:13,273][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0008, 0.0034, 0.0582, 0.1605, 0.1136, 0.2009, 0.4626],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:13,274][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0092, 0.0059, 0.0707, 0.2162, 0.0157, 0.4087, 0.2735],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:13,274][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ the] are: tensor([2.9642e-04, 1.0613e-04, 8.6199e-03, 2.8267e-02, 9.7187e-02, 3.3087e-01,
        5.3466e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:13,274][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ the] are: tensor([1.3354e-05, 2.4256e-03, 3.4635e-02, 4.3265e-02, 8.0949e-02, 1.5039e-01,
        6.8832e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:13,275][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ the] are: tensor([2.2449e-03, 3.1420e-04, 9.8808e-03, 3.5375e-02, 3.6542e-01, 2.4212e-01,
        3.4465e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:13,275][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0093, 0.0337, 0.0193, 0.0876, 0.2302, 0.0871, 0.5327],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:13,275][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ the] are: tensor([5.6840e-03, 1.9275e-04, 3.6003e-03, 8.8447e-02, 1.9938e-02, 2.2578e-01,
        6.5636e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:13,276][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ the] are: tensor([6.3080e-05, 1.1829e-02, 4.4242e-02, 2.3483e-02, 9.1694e-02, 1.4122e-01,
        6.8747e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:13,276][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0547, 0.0007, 0.0043, 0.1820, 0.0040, 0.6622, 0.0920],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:13,277][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ the] are: tensor([5.2556e-02, 3.1642e-05, 9.5420e-03, 4.0078e-02, 1.4440e-02, 7.5541e-01,
        1.2795e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:13,280][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ station] are: tensor([0.2403, 0.0014, 0.0222, 0.0737, 0.0160, 0.1909, 0.2465, 0.2089],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:13,281][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ station] are: tensor([0.0019, 0.1393, 0.4814, 0.0825, 0.0439, 0.1674, 0.0603, 0.0233],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:13,281][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ station] are: tensor([3.1651e-04, 5.2247e-04, 3.4576e-02, 3.5420e-02, 3.1531e-02, 1.8130e-01,
        6.7250e-01, 4.3828e-02], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:13,282][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ station] are: tensor([0.0023, 0.0028, 0.0478, 0.0881, 0.0151, 0.4209, 0.2572, 0.1659],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:13,282][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ station] are: tensor([2.8778e-04, 2.0735e-04, 9.3006e-03, 2.5202e-02, 8.0389e-02, 3.9528e-01,
        3.7129e-01, 1.1805e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:13,282][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ station] are: tensor([7.1180e-06, 4.3344e-04, 1.2416e-02, 1.5510e-02, 5.4844e-02, 1.7548e-01,
        6.7438e-01, 6.6925e-02], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:13,283][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ station] are: tensor([3.5083e-03, 3.8900e-04, 6.6133e-03, 1.6797e-02, 2.1989e-01, 1.2153e-01,
        4.1807e-01, 2.1320e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:13,283][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ station] are: tensor([0.0011, 0.0027, 0.0052, 0.0381, 0.1128, 0.0906, 0.6168, 0.1328],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:13,284][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ station] are: tensor([4.1766e-04, 1.4399e-04, 2.2718e-03, 3.9672e-02, 1.0341e-02, 1.4479e-01,
        1.6376e-01, 6.3860e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:13,287][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ station] are: tensor([7.2702e-05, 9.3336e-03, 6.2924e-02, 2.6611e-02, 4.8738e-02, 1.7437e-01,
        6.2050e-01, 5.7451e-02], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:13,287][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ station] are: tensor([1.3973e-02, 2.0649e-04, 5.0117e-03, 3.6271e-01, 5.4069e-03, 4.0105e-01,
        4.6486e-02, 1.6516e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:13,288][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ station] are: tensor([1.3310e-02, 6.7066e-06, 5.8342e-03, 1.5847e-02, 8.6000e-03, 4.5581e-01,
        6.6408e-02, 4.3419e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:13,288][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.3048, 0.0008, 0.0072, 0.0864, 0.0037, 0.0381, 0.0660, 0.1094, 0.3836],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:13,288][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0019, 0.2088, 0.3141, 0.1894, 0.0273, 0.1066, 0.0499, 0.0076, 0.0944],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:13,289][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [,] are: tensor([4.5735e-04, 1.8744e-03, 1.1219e-02, 8.2453e-02, 5.9539e-02, 5.1436e-02,
        7.5204e-02, 2.0277e-01, 5.1505e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:13,289][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0078, 0.0065, 0.0341, 0.1203, 0.0105, 0.1843, 0.1274, 0.0886, 0.4204],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:13,290][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [,] are: tensor([1.1132e-04, 5.5629e-05, 2.9755e-03, 9.7933e-03, 2.0888e-02, 9.2127e-02,
        1.4508e-01, 2.1195e-02, 7.0778e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:13,290][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [,] are: tensor([5.3101e-06, 4.0240e-04, 7.9593e-03, 7.4968e-03, 1.6932e-02, 6.0494e-02,
        1.8485e-01, 2.5264e-02, 6.9660e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:13,292][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [,] are: tensor([4.2541e-03, 1.7100e-04, 4.0558e-03, 2.0108e-02, 1.2822e-01, 1.1478e-01,
        1.2583e-01, 2.3079e-01, 3.7180e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:13,294][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0039, 0.0061, 0.0047, 0.0176, 0.0287, 0.0298, 0.1222, 0.0666, 0.7204],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:13,294][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [,] are: tensor([9.1862e-03, 3.5128e-04, 2.9599e-03, 4.1872e-02, 5.0186e-03, 5.1177e-02,
        9.4754e-02, 2.9878e-01, 4.9590e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:13,295][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [,] are: tensor([3.4801e-05, 1.7237e-03, 6.6391e-03, 5.8510e-03, 7.8373e-03, 3.5580e-02,
        1.2378e-01, 1.1844e-02, 8.0671e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:13,295][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.1037, 0.0007, 0.0036, 0.2348, 0.0014, 0.2509, 0.0332, 0.1119, 0.2598],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:13,295][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [,] are: tensor([4.2133e-02, 1.9716e-05, 6.0024e-03, 3.6262e-02, 2.5781e-03, 2.7437e-01,
        3.2602e-02, 6.1325e-02, 5.4470e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:13,296][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Benjamin] are: tensor([0.0572, 0.0024, 0.0225, 0.1160, 0.0122, 0.1309, 0.1500, 0.0746, 0.3682,
        0.0660], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:13,296][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Benjamin] are: tensor([3.8947e-04, 1.6037e-01, 4.0905e-01, 1.0690e-01, 3.3413e-02, 1.2295e-01,
        4.7147e-02, 1.3445e-02, 8.8374e-02, 1.7965e-02], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:13,298][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Benjamin] are: tensor([7.8740e-05, 3.2572e-03, 4.3378e-02, 4.0681e-02, 1.0692e-01, 9.0125e-02,
        1.2797e-01, 2.5429e-02, 5.5415e-01, 8.0101e-03], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:13,302][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Benjamin] are: tensor([0.0026, 0.0055, 0.0389, 0.0679, 0.0139, 0.1885, 0.1188, 0.1043, 0.3898,
        0.0700], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:13,304][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Benjamin] are: tensor([0.0006, 0.0004, 0.0167, 0.0328, 0.2034, 0.2009, 0.1796, 0.0636, 0.2664,
        0.0356], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:13,304][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Benjamin] are: tensor([2.5419e-06, 9.4512e-04, 1.5283e-02, 1.4305e-02, 3.7551e-02, 6.9149e-02,
        2.2112e-01, 9.3974e-02, 5.3477e-01, 1.2903e-02], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:13,304][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Benjamin] are: tensor([0.0004, 0.0005, 0.0093, 0.0127, 0.2259, 0.1113, 0.1842, 0.1248, 0.2929,
        0.0381], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:13,305][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Benjamin] are: tensor([0.0069, 0.0331, 0.0385, 0.0443, 0.1610, 0.0660, 0.1873, 0.0709, 0.3544,
        0.0376], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:13,305][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Benjamin] are: tensor([3.7128e-04, 6.0732e-04, 3.4623e-03, 2.7172e-02, 4.4111e-03, 5.5528e-02,
        6.2715e-02, 3.2774e-01, 6.8479e-02, 4.4951e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:13,305][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Benjamin] are: tensor([1.9215e-05, 5.8125e-03, 2.0669e-02, 1.0980e-02, 1.4884e-02, 5.6444e-02,
        1.2330e-01, 7.9929e-02, 6.8214e-01, 5.8202e-03], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:13,306][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Benjamin] are: tensor([0.0473, 0.0012, 0.0037, 0.2773, 0.0063, 0.3121, 0.0373, 0.0907, 0.1192,
        0.1049], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:13,306][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Benjamin] are: tensor([5.5615e-02, 5.3781e-05, 5.8935e-03, 1.7353e-02, 1.2879e-02, 1.6622e-01,
        2.1157e-02, 1.3616e-01, 4.0365e-01, 1.8103e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:13,307][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([8.3292e-02, 4.2868e-04, 5.3809e-03, 1.1612e-01, 9.0322e-03, 4.1153e-02,
        6.0889e-02, 6.1830e-02, 4.7055e-01, 3.9145e-02, 1.1217e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:13,309][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0006, 0.0699, 0.4523, 0.0947, 0.0251, 0.1554, 0.0561, 0.0076, 0.1011,
        0.0163, 0.0208], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:13,311][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0012, 0.0036, 0.0104, 0.0719, 0.0645, 0.0375, 0.0851, 0.0751, 0.3146,
        0.0159, 0.3202], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:13,311][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.0012, 0.0015, 0.0273, 0.0540, 0.0049, 0.1879, 0.0986, 0.0766, 0.4481,
        0.0847, 0.0152], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:13,312][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([1.8317e-04, 8.2343e-05, 3.3302e-03, 2.0969e-02, 4.6016e-02, 7.1832e-02,
        1.2266e-01, 2.9819e-02, 3.7465e-01, 7.3348e-02, 2.5711e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:13,312][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([7.6369e-06, 9.4791e-04, 6.8593e-03, 1.0997e-02, 1.5376e-02, 4.3375e-02,
        1.3288e-01, 9.0658e-03, 3.5534e-01, 4.2689e-03, 4.2088e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:13,313][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([4.9262e-04, 8.9101e-05, 2.0479e-03, 6.0102e-03, 7.6261e-02, 4.8496e-02,
        1.1504e-01, 6.3747e-02, 2.7425e-01, 2.4583e-02, 3.8899e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:13,313][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0037, 0.0035, 0.0037, 0.0142, 0.0249, 0.0251, 0.0863, 0.0357, 0.5757,
        0.0377, 0.1895], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:13,313][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([2.7709e-04, 3.0222e-05, 7.7831e-04, 6.5832e-03, 1.9144e-03, 3.1142e-02,
        4.3812e-02, 9.1296e-02, 2.5218e-01, 1.4715e-01, 4.2483e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:13,315][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([1.6056e-05, 1.6033e-03, 5.7616e-03, 3.8899e-03, 4.3403e-03, 2.3177e-02,
        5.7131e-02, 7.9587e-03, 4.9086e-01, 2.0754e-03, 4.0319e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:13,317][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([6.7870e-03, 1.5915e-04, 1.8249e-03, 6.6987e-02, 8.9880e-04, 4.2401e-01,
        4.1298e-02, 6.6415e-02, 2.7031e-01, 9.5528e-02, 2.5776e-02],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:13,318][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([3.2268e-03, 4.6063e-06, 1.9323e-03, 1.5432e-02, 2.5782e-03, 1.6089e-01,
        2.0395e-02, 8.2792e-02, 4.7259e-01, 2.2950e-01, 1.0666e-02],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:13,318][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ a] are: tensor([8.3415e-02, 3.1265e-04, 6.4249e-03, 6.7653e-02, 4.9311e-03, 5.2219e-02,
        7.2496e-02, 8.3655e-02, 3.2199e-01, 3.6477e-02, 5.4345e-02, 2.1608e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:13,319][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0016, 0.0938, 0.3516, 0.0987, 0.0358, 0.1511, 0.0596, 0.0114, 0.1020,
        0.0225, 0.0310, 0.0410], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:13,319][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0012, 0.0024, 0.0111, 0.0585, 0.0135, 0.0443, 0.0788, 0.0298, 0.1730,
        0.0127, 0.1005, 0.4742], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:13,319][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0029, 0.0017, 0.0181, 0.0656, 0.0048, 0.1280, 0.0749, 0.0645, 0.4106,
        0.1285, 0.0197, 0.0806], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:13,320][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ a] are: tensor([3.4424e-04, 6.7334e-05, 2.5183e-03, 1.4542e-02, 3.1737e-02, 7.9511e-02,
        1.2627e-01, 2.2441e-02, 2.6508e-01, 3.6047e-02, 7.3508e-02, 3.4794e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:13,320][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ a] are: tensor([8.9456e-06, 1.6072e-03, 9.8568e-03, 1.2083e-02, 1.5783e-02, 5.4001e-02,
        1.3685e-01, 1.2671e-02, 2.1768e-01, 6.1648e-03, 3.1111e-01, 2.2218e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:13,322][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ a] are: tensor([1.1775e-03, 1.1099e-04, 1.9198e-03, 9.7780e-03, 6.0112e-02, 6.3603e-02,
        6.7163e-02, 9.8103e-02, 1.5753e-01, 1.6765e-02, 3.1590e-01, 2.0784e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:13,325][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0047, 0.0070, 0.0046, 0.0139, 0.0343, 0.0338, 0.1175, 0.0683, 0.4264,
        0.0409, 0.1460, 0.1025], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:13,325][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ a] are: tensor([1.6611e-03, 6.3861e-05, 6.3261e-04, 1.3164e-02, 1.7839e-03, 2.4531e-02,
        5.1778e-02, 9.9544e-02, 1.6619e-01, 2.6342e-01, 2.1533e-01, 1.6190e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:13,326][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ a] are: tensor([9.1730e-05, 2.1801e-03, 4.9499e-03, 2.9084e-03, 4.4788e-03, 1.7237e-02,
        6.9977e-02, 8.0047e-03, 3.4639e-01, 1.2260e-03, 5.0561e-01, 3.6943e-02],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:13,326][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ a] are: tensor([6.0042e-02, 2.1494e-04, 2.2735e-03, 6.4176e-02, 1.2909e-03, 3.3459e-01,
        3.5216e-02, 6.8205e-02, 1.8885e-01, 9.7040e-02, 1.3978e-02, 1.3412e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:13,327][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ a] are: tensor([2.1218e-02, 8.6522e-06, 2.0519e-03, 7.4878e-03, 1.5779e-03, 1.4689e-01,
        2.1199e-02, 4.8301e-02, 3.8526e-01, 2.3368e-01, 1.0293e-02, 1.2203e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:13,327][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ computer] are: tensor([1.8722e-02, 3.3508e-04, 1.2447e-02, 2.3563e-02, 4.3630e-03, 1.2337e-01,
        8.7591e-02, 3.8859e-02, 3.8930e-01, 1.9139e-02, 4.4114e-02, 1.3756e-01,
        1.0064e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:13,327][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ computer] are: tensor([0.0004, 0.2133, 0.2955, 0.0813, 0.0338, 0.1200, 0.0446, 0.0138, 0.0896,
        0.0159, 0.0256, 0.0327, 0.0336], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:13,329][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ computer] are: tensor([9.6516e-06, 2.8950e-05, 4.8340e-03, 7.9618e-04, 1.5294e-03, 1.0572e-02,
        1.6944e-02, 7.1325e-03, 8.2629e-01, 2.1410e-04, 3.7163e-02, 7.0540e-02,
        2.3943e-02], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:13,332][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ computer] are: tensor([0.0024, 0.0018, 0.0156, 0.0390, 0.0100, 0.0993, 0.0705, 0.0961, 0.2341,
        0.0566, 0.0242, 0.1435, 0.2068], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:13,332][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ computer] are: tensor([4.9469e-05, 4.1555e-05, 2.1064e-03, 5.9725e-03, 1.8303e-02, 6.0962e-02,
        7.7724e-02, 2.6452e-02, 2.4114e-01, 2.2208e-02, 8.3391e-02, 2.5352e-01,
        2.0813e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:13,333][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ computer] are: tensor([1.6389e-05, 5.0053e-04, 4.7249e-03, 6.9289e-03, 1.5269e-02, 3.7822e-02,
        8.7965e-02, 6.6056e-02, 2.9418e-01, 4.8135e-03, 2.7703e-01, 1.3414e-01,
        7.0558e-02], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:13,333][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ computer] are: tensor([1.2116e-03, 1.9090e-04, 2.5947e-03, 7.2697e-03, 5.4063e-02, 4.9160e-02,
        4.1907e-02, 9.5445e-02, 1.0755e-01, 1.2347e-02, 2.8985e-01, 1.2259e-01,
        2.1583e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:13,333][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ computer] are: tensor([0.0058, 0.0135, 0.0065, 0.0099, 0.0202, 0.0216, 0.0730, 0.0452, 0.4027,
        0.0172, 0.1338, 0.0508, 0.2000], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:13,334][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ computer] are: tensor([8.5272e-04, 1.0832e-04, 5.6540e-04, 8.5927e-03, 1.0954e-03, 2.5491e-02,
        2.6154e-02, 1.1496e-01, 7.8389e-02, 3.9760e-01, 1.6057e-01, 6.3911e-02,
        1.2170e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:13,334][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ computer] are: tensor([2.4760e-05, 8.2799e-04, 3.4807e-03, 9.9064e-04, 1.2724e-03, 1.3733e-02,
        3.6922e-02, 1.2687e-02, 5.9848e-01, 6.3465e-04, 2.9616e-01, 1.5336e-02,
        1.9448e-02], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:13,337][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ computer] are: tensor([0.0804, 0.0023, 0.0017, 0.1521, 0.0033, 0.1660, 0.0172, 0.1496, 0.1123,
        0.1277, 0.0172, 0.0850, 0.0852], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:13,338][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ computer] are: tensor([7.3212e-03, 1.4680e-05, 1.5738e-03, 1.3706e-02, 2.4332e-03, 7.2807e-02,
        1.0568e-02, 7.1935e-02, 2.0283e-01, 1.1600e-01, 7.9830e-03, 6.1471e-02,
        4.3136e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:13,339][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0891, 0.0004, 0.0044, 0.0312, 0.0041, 0.0457, 0.0656, 0.0531, 0.2670,
        0.0266, 0.0471, 0.1336, 0.1156, 0.1164], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:13,339][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0053, 0.1229, 0.2123, 0.1061, 0.0355, 0.1269, 0.0589, 0.0145, 0.0976,
        0.0259, 0.0358, 0.0412, 0.0387, 0.0784], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:13,340][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ to] are: tensor([4.7533e-05, 4.4136e-04, 7.7938e-03, 9.6874e-03, 1.0235e-02, 1.7923e-02,
        8.6276e-02, 5.1997e-03, 3.9766e-01, 7.7262e-04, 7.6666e-02, 2.6089e-01,
        5.7947e-02, 6.8460e-02], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:13,340][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0160, 0.0012, 0.0138, 0.0547, 0.0044, 0.0541, 0.0498, 0.0665, 0.2280,
        0.0752, 0.0119, 0.0613, 0.1372, 0.2259], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:13,341][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ to] are: tensor([1.3591e-04, 1.9539e-05, 1.0679e-03, 5.1857e-03, 6.6685e-03, 3.8628e-02,
        6.4160e-02, 6.9124e-03, 2.3345e-01, 2.2742e-02, 2.8215e-02, 1.7317e-01,
        1.1535e-01, 3.0429e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:13,341][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ to] are: tensor([6.9262e-06, 4.4231e-04, 5.6692e-03, 7.5699e-03, 8.6612e-03, 3.7808e-02,
        9.9741e-02, 1.9570e-02, 2.9583e-01, 4.6588e-03, 1.8204e-01, 1.6862e-01,
        3.8577e-02, 1.3082e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:13,343][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ to] are: tensor([2.2021e-03, 1.6715e-04, 1.6647e-03, 1.5042e-02, 3.5121e-02, 3.5700e-02,
        2.4471e-02, 8.4992e-02, 6.6996e-02, 1.2040e-02, 1.7771e-01, 7.1784e-02,
        2.2425e-01, 2.4786e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:13,345][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0039, 0.0050, 0.0023, 0.0076, 0.0201, 0.0182, 0.0720, 0.0320, 0.3705,
        0.0211, 0.1188, 0.0663, 0.1674, 0.0949], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:13,346][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ to] are: tensor([3.8729e-03, 1.2277e-04, 5.0119e-04, 9.8830e-03, 1.7016e-03, 1.6959e-02,
        3.7377e-02, 8.9234e-02, 9.5741e-02, 2.1510e-01, 1.0351e-01, 9.8285e-02,
        1.0753e-01, 2.2018e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:13,346][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ to] are: tensor([3.1036e-05, 1.2092e-03, 3.9248e-03, 2.8201e-03, 2.6027e-03, 1.7465e-02,
        4.7860e-02, 5.3084e-03, 4.8230e-01, 8.6167e-04, 3.7745e-01, 2.4485e-02,
        1.2765e-02, 2.0916e-02], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:13,346][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ to] are: tensor([4.0850e-01, 7.6182e-04, 5.0147e-04, 4.7494e-02, 3.1226e-04, 5.4068e-02,
        4.9544e-03, 2.7988e-02, 3.2743e-02, 5.7094e-02, 3.8208e-03, 2.1550e-02,
        1.8229e-02, 3.2199e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:13,347][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ to] are: tensor([4.5792e-02, 1.1057e-05, 8.3380e-04, 7.6937e-03, 2.8881e-04, 2.6520e-02,
        6.9511e-03, 1.8729e-02, 1.6399e-01, 1.4261e-01, 3.2236e-03, 1.7338e-02,
        2.4298e-01, 3.2303e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:13,411][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:20:13,412][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:13,412][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:13,413][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:13,413][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:13,413][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:13,414][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:13,415][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:13,416][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:13,416][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:13,416][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:13,417][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:13,417][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:20:13,417][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Benjamin] are: tensor([0.6627, 0.3373], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:13,418][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Benjamin] are: tensor([0.0835, 0.9165], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:13,418][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Benjamin] are: tensor([0.1198, 0.8802], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:13,418][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Benjamin] are: tensor([0.5499, 0.4501], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:13,419][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Benjamin] are: tensor([0.3165, 0.6835], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:13,419][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Benjamin] are: tensor([0.0019, 0.9981], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:13,419][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Benjamin] are: tensor([0.6639, 0.3361], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:13,420][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Benjamin] are: tensor([0.0420, 0.9580], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:13,421][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Benjamin] are: tensor([0.0206, 0.9794], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:13,421][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Benjamin] are: tensor([0.0012, 0.9988], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:13,422][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Benjamin] are: tensor([0.7315, 0.2685], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:13,422][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Benjamin] are: tensor([0.0391, 0.9609], device='cuda:0') for source tokens [After Benjamin]
[2024-07-24 10:20:13,422][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.6636, 0.0374, 0.2989], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:13,423][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.1195, 0.7265, 0.1541], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:13,423][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0180, 0.2307, 0.7513], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:13,423][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.2423, 0.0025, 0.7552], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:13,424][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0060, 0.0155, 0.9785], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:13,424][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([5.1681e-04, 2.1664e-01, 7.8285e-01], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:13,424][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.1582, 0.0732, 0.7686], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:13,425][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0492, 0.6095, 0.3413], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:13,425][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0135, 0.0522, 0.9343], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:13,425][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([6.3094e-04, 2.6268e-01, 7.3669e-01], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:13,425][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.6292, 0.0208, 0.3500], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:13,426][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0208, 0.0841, 0.8952], device='cuda:0') for source tokens [After Benjamin and]
[2024-07-24 10:20:13,426][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Alexander] are: tensor([0.1702, 0.0545, 0.2104, 0.5649], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:13,426][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Alexander] are: tensor([0.0351, 0.6151, 0.1021, 0.2477], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:13,427][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Alexander] are: tensor([0.0021, 0.0650, 0.1646, 0.7683], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:13,427][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Alexander] are: tensor([0.0247, 0.0016, 0.0162, 0.9575], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:13,428][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Alexander] are: tensor([0.0031, 0.0105, 0.3791, 0.6073], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:13,428][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Alexander] are: tensor([1.1739e-04, 6.0965e-02, 4.7454e-01, 4.6438e-01], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:13,428][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Alexander] are: tensor([0.0181, 0.0219, 0.0717, 0.8883], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:13,429][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Alexander] are: tensor([0.0152, 0.3055, 0.1519, 0.5274], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:13,429][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Alexander] are: tensor([0.0294, 0.1108, 0.4277, 0.4321], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:13,429][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Alexander] are: tensor([1.3435e-04, 2.1070e-01, 5.2697e-01, 2.6219e-01], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:13,430][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Alexander] are: tensor([0.0062, 0.0017, 0.0047, 0.9875], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:13,430][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Alexander] are: tensor([0.0555, 0.1383, 0.1319, 0.6743], device='cuda:0') for source tokens [After Benjamin and Alexander]
[2024-07-24 10:20:13,430][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([0.5045, 0.0061, 0.0645, 0.3297, 0.0952], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:13,431][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([0.0093, 0.0800, 0.0593, 0.1152, 0.7363], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:13,433][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([0.0005, 0.0067, 0.0617, 0.3936, 0.5374], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:13,433][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([2.3099e-03, 9.7840e-06, 7.6808e-03, 8.9961e-01, 9.0393e-02],
       device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:13,433][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([1.3661e-04, 8.1268e-04, 5.8857e-02, 1.3489e-01, 8.0530e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:13,434][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([3.8325e-05, 2.5341e-02, 2.1824e-01, 2.3341e-01, 5.2297e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:13,434][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([6.3458e-04, 1.8912e-03, 2.3494e-02, 2.6122e-01, 7.1276e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:13,434][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([0.0011, 0.0239, 0.0459, 0.1332, 0.7958], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:13,435][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([0.0027, 0.0046, 0.1301, 0.3418, 0.5208], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:13,435][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([5.0234e-05, 2.5174e-02, 2.6850e-01, 6.3457e-02, 6.4282e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:13,436][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([1.7310e-03, 1.2451e-04, 5.0425e-03, 8.8971e-01, 1.0339e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:13,439][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([0.0069, 0.0047, 0.0710, 0.6161, 0.3013], device='cuda:0') for source tokens [After Benjamin and Alexander went]
[2024-07-24 10:20:13,440][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.5329, 0.0024, 0.0313, 0.2351, 0.0378, 0.1605], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:13,440][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.2185, 0.1768, 0.0227, 0.1749, 0.3690, 0.0382], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:13,440][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0014, 0.0095, 0.0512, 0.6025, 0.1512, 0.1842], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:13,441][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([3.8302e-03, 2.0344e-06, 2.8722e-04, 2.6094e-01, 5.5511e-03, 7.2939e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:13,441][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([4.1883e-04, 2.2306e-04, 1.8737e-02, 7.8670e-02, 2.8496e-01, 6.1699e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:13,441][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([7.8113e-05, 1.5225e-02, 1.0141e-01, 2.1094e-01, 3.1621e-01, 3.5615e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:13,442][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0063, 0.0019, 0.0075, 0.4098, 0.3677, 0.2067], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:13,444][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0203, 0.0636, 0.0298, 0.1669, 0.5775, 0.1420], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:13,446][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0081, 0.0014, 0.0302, 0.1898, 0.1202, 0.6502], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:13,446][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0004, 0.0639, 0.1472, 0.1382, 0.3819, 0.2684], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:13,447][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([7.1438e-02, 2.4234e-04, 1.9020e-03, 7.1158e-01, 8.8295e-03, 2.0601e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:13,447][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0131, 0.0039, 0.0105, 0.2484, 0.0368, 0.6873], device='cuda:0') for source tokens [After Benjamin and Alexander went to]
[2024-07-24 10:20:13,447][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.2644, 0.0010, 0.0260, 0.1133, 0.0093, 0.1924, 0.3937],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:13,448][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0618, 0.1456, 0.0417, 0.1338, 0.4091, 0.0822, 0.1260],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:13,448][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([4.5522e-04, 3.4528e-03, 1.7177e-02, 2.9164e-01, 6.1735e-02, 7.7706e-02,
        5.4784e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:13,449][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([1.0580e-03, 4.7621e-07, 5.7390e-05, 1.0632e-01, 1.0621e-03, 4.7717e-01,
        4.1433e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:13,450][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([1.0066e-04, 7.3963e-05, 8.0615e-03, 3.3940e-02, 1.3844e-01, 2.8278e-01,
        5.3660e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:13,452][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([1.7826e-05, 2.0204e-03, 2.8221e-02, 5.1596e-02, 6.6641e-02, 1.3651e-01,
        7.1499e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:13,453][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0022, 0.0006, 0.0042, 0.1871, 0.2280, 0.1507, 0.4272],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:13,453][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0093, 0.0337, 0.0193, 0.0876, 0.2302, 0.0871, 0.5327],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:13,454][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([5.6840e-03, 1.9275e-04, 3.6003e-03, 8.8447e-02, 1.9938e-02, 2.2578e-01,
        6.5636e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:13,454][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([6.3080e-05, 1.1829e-02, 4.4242e-02, 2.3483e-02, 9.1694e-02, 1.4122e-01,
        6.8747e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:13,454][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([2.1349e-02, 5.8607e-05, 6.3325e-04, 5.7665e-01, 9.1360e-03, 2.4816e-01,
        1.4401e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:13,455][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([1.3846e-03, 3.5950e-04, 1.4651e-03, 5.1732e-02, 1.2392e-02, 2.9100e-01,
        6.4166e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the]
[2024-07-24 10:20:13,455][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ station] are: tensor([0.2403, 0.0014, 0.0222, 0.0737, 0.0160, 0.1909, 0.2465, 0.2089],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:13,457][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ station] are: tensor([0.0091, 0.0097, 0.0160, 0.0461, 0.2905, 0.0599, 0.0936, 0.4751],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:13,459][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ station] are: tensor([0.0011, 0.0018, 0.0217, 0.2629, 0.0492, 0.0928, 0.4433, 0.1273],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:13,460][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ station] are: tensor([3.7848e-04, 2.5619e-07, 6.3091e-05, 5.3639e-02, 2.4616e-03, 3.5248e-01,
        3.8873e-01, 2.0226e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:13,460][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ station] are: tensor([2.7775e-04, 1.4357e-04, 6.5153e-03, 2.8837e-02, 7.2774e-02, 3.1382e-01,
        3.7268e-01, 2.0495e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:13,461][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ station] are: tensor([8.0593e-06, 2.7511e-04, 9.0490e-03, 1.5894e-02, 4.2027e-02, 1.5691e-01,
        6.9326e-01, 8.2575e-02], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:13,461][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ station] are: tensor([1.8002e-03, 3.5232e-04, 2.7806e-03, 7.8301e-02, 7.7886e-02, 1.4737e-01,
        5.3916e-01, 1.5235e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:13,461][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ station] are: tensor([0.0011, 0.0027, 0.0052, 0.0381, 0.1128, 0.0906, 0.6168, 0.1328],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:13,462][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ station] are: tensor([4.1766e-04, 1.4399e-04, 2.2718e-03, 3.9672e-02, 1.0341e-02, 1.4479e-01,
        1.6376e-01, 6.3860e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:13,462][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ station] are: tensor([7.2702e-05, 9.3336e-03, 6.2924e-02, 2.6611e-02, 4.8738e-02, 1.7437e-01,
        6.2050e-01, 5.7451e-02], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:13,463][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ station] are: tensor([6.8535e-03, 4.3687e-05, 6.7651e-04, 4.2732e-01, 6.1625e-03, 6.6682e-02,
        3.9587e-02, 4.5267e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:13,466][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ station] are: tensor([1.9361e-03, 3.2247e-04, 1.9366e-03, 5.7283e-02, 6.0830e-03, 2.6294e-01,
        6.3606e-01, 3.3435e-02], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station]
[2024-07-24 10:20:13,466][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.3048, 0.0008, 0.0072, 0.0864, 0.0037, 0.0381, 0.0660, 0.1094, 0.3836],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:13,467][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0532, 0.0307, 0.0078, 0.0674, 0.0439, 0.0227, 0.0315, 0.2334, 0.5094],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:13,467][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([2.5789e-04, 5.6480e-04, 2.7868e-03, 6.4443e-02, 4.7553e-03, 1.6835e-02,
        4.5294e-02, 8.8983e-02, 7.7608e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:13,468][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([5.5418e-04, 1.0638e-07, 4.2620e-06, 3.3363e-02, 1.0835e-04, 6.6585e-02,
        5.1506e-02, 3.7870e-02, 8.1001e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:13,468][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([4.4970e-05, 4.1897e-05, 2.5498e-03, 9.8797e-03, 2.2640e-02, 7.2393e-02,
        1.3207e-01, 2.9293e-02, 7.3109e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:13,468][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([4.9897e-06, 2.4456e-04, 5.1731e-03, 6.5075e-03, 1.0555e-02, 4.4026e-02,
        1.4835e-01, 2.5845e-02, 7.5930e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:13,469][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([1.5974e-03, 1.6124e-04, 1.0983e-03, 5.1513e-02, 3.4490e-02, 5.5589e-02,
        1.0030e-01, 2.3187e-02, 7.3206e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:13,471][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0039, 0.0061, 0.0047, 0.0176, 0.0287, 0.0298, 0.1222, 0.0666, 0.7204],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:13,473][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([9.1862e-03, 3.5128e-04, 2.9599e-03, 4.1872e-02, 5.0186e-03, 5.1177e-02,
        9.4754e-02, 2.9878e-01, 4.9590e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:13,473][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([3.4801e-05, 1.7237e-03, 6.6391e-03, 5.8510e-03, 7.8373e-03, 3.5580e-02,
        1.2378e-01, 1.1844e-02, 8.0671e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:13,474][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([6.3579e-03, 4.2999e-06, 4.5092e-05, 1.0827e-01, 3.9496e-04, 2.0603e-02,
        1.1830e-02, 1.3332e-01, 7.1918e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:13,474][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([2.2245e-04, 4.8530e-05, 3.3413e-04, 3.9100e-02, 9.1703e-04, 4.8426e-02,
        1.0267e-01, 1.3870e-03, 8.0690e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station,]
[2024-07-24 10:20:13,475][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Benjamin] are: tensor([0.0572, 0.0024, 0.0225, 0.1160, 0.0122, 0.1309, 0.1500, 0.0746, 0.3682,
        0.0660], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:13,475][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Benjamin] are: tensor([0.0177, 0.0760, 0.0265, 0.0516, 0.2033, 0.0548, 0.0363, 0.2576, 0.2551,
        0.0211], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:13,475][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Benjamin] are: tensor([2.2204e-04, 3.3700e-03, 2.0040e-02, 1.2420e-01, 4.7383e-02, 3.3082e-02,
        9.4396e-02, 6.7809e-02, 5.8183e-01, 2.7663e-02], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:13,477][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Benjamin] are: tensor([1.2356e-03, 1.5311e-05, 1.8294e-04, 8.9831e-02, 1.9187e-03, 7.0132e-02,
        6.1417e-02, 1.3393e-01, 4.9767e-01, 1.4366e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:13,480][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Benjamin] are: tensor([0.0007, 0.0003, 0.0147, 0.0416, 0.2138, 0.1470, 0.1562, 0.1056, 0.2929,
        0.0273], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:13,480][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Benjamin] are: tensor([1.8807e-06, 5.4975e-04, 1.0533e-02, 1.2766e-02, 2.4214e-02, 5.2861e-02,
        1.9274e-01, 1.0834e-01, 5.8700e-01, 1.0989e-02], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:13,481][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Benjamin] are: tensor([0.0019, 0.0019, 0.0048, 0.0634, 0.0965, 0.0846, 0.1457, 0.0675, 0.5188,
        0.0149], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:13,481][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Benjamin] are: tensor([0.0069, 0.0331, 0.0385, 0.0443, 0.1610, 0.0660, 0.1873, 0.0709, 0.3544,
        0.0376], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:13,481][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Benjamin] are: tensor([3.7128e-04, 6.0732e-04, 3.4623e-03, 2.7172e-02, 4.4111e-03, 5.5528e-02,
        6.2715e-02, 3.2774e-01, 6.8479e-02, 4.4951e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:13,482][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Benjamin] are: tensor([1.9215e-05, 5.8125e-03, 2.0669e-02, 1.0980e-02, 1.4884e-02, 5.6444e-02,
        1.2330e-01, 7.9929e-02, 6.8214e-01, 5.8202e-03], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:13,482][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Benjamin] are: tensor([1.0635e-02, 1.8067e-04, 5.3405e-04, 3.6717e-01, 5.2257e-03, 3.4895e-02,
        1.0803e-02, 1.0381e-01, 1.0095e-01, 3.6580e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:13,485][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Benjamin] are: tensor([0.0029, 0.0020, 0.0035, 0.0903, 0.0056, 0.0688, 0.0667, 0.0067, 0.6645,
        0.0890], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin]
[2024-07-24 10:20:13,486][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([8.3292e-02, 4.2868e-04, 5.3809e-03, 1.1612e-01, 9.0322e-03, 4.1153e-02,
        6.0889e-02, 6.1830e-02, 4.7055e-01, 3.9145e-02, 1.1217e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:13,487][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0138, 0.0095, 0.0041, 0.0233, 0.0342, 0.0230, 0.0303, 0.1042, 0.5184,
        0.0372, 0.2020], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:13,487][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.0006, 0.0013, 0.0036, 0.1385, 0.0125, 0.0186, 0.0702, 0.0766, 0.4719,
        0.0338, 0.1724], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:13,488][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([1.1527e-05, 8.1992e-09, 2.2346e-06, 3.6367e-03, 3.5171e-05, 5.4812e-02,
        3.8442e-02, 1.3819e-02, 8.5427e-01, 2.8897e-02, 6.0703e-03],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:13,488][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([1.1013e-04, 6.0413e-05, 2.6637e-03, 2.4219e-02, 5.3131e-02, 5.4270e-02,
        1.1841e-01, 5.2478e-02, 4.3553e-01, 4.9985e-02, 2.0915e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:13,488][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([7.7347e-06, 5.9340e-04, 4.3627e-03, 9.8707e-03, 9.7456e-03, 3.3182e-02,
        1.1581e-01, 8.8105e-03, 3.9335e-01, 3.5112e-03, 4.2076e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:13,489][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([5.5163e-04, 1.6014e-04, 9.0179e-04, 1.9476e-02, 2.9248e-02, 3.1952e-02,
        8.1395e-02, 1.0966e-02, 5.3025e-01, 8.2248e-03, 2.8688e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:13,491][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0037, 0.0035, 0.0037, 0.0142, 0.0249, 0.0251, 0.0863, 0.0357, 0.5757,
        0.0377, 0.1895], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:13,493][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([2.7709e-04, 3.0222e-05, 7.7831e-04, 6.5832e-03, 1.9144e-03, 3.1142e-02,
        4.3812e-02, 9.1296e-02, 2.5218e-01, 1.4715e-01, 4.2483e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:13,494][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([1.6056e-05, 1.6033e-03, 5.7616e-03, 3.8899e-03, 4.3403e-03, 2.3177e-02,
        5.7131e-02, 7.9587e-03, 4.9086e-01, 2.0754e-03, 4.0319e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:13,494][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([1.3484e-03, 2.8789e-06, 3.1298e-05, 3.6352e-02, 3.2798e-04, 2.8522e-02,
        1.2338e-02, 3.7352e-02, 6.0877e-01, 1.9395e-01, 8.1008e-02],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:13,494][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([1.7913e-04, 1.4600e-05, 1.3160e-04, 1.0778e-02, 5.9420e-04, 2.9266e-02,
        5.0357e-02, 1.3522e-03, 8.1442e-01, 1.8183e-02, 7.4727e-02],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave]
[2024-07-24 10:20:13,495][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([8.3415e-02, 3.1265e-04, 6.4249e-03, 6.7653e-02, 4.9311e-03, 5.2219e-02,
        7.2496e-02, 8.3655e-02, 3.2199e-01, 3.6477e-02, 5.4345e-02, 2.1608e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:13,495][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0642, 0.0437, 0.0067, 0.0374, 0.0541, 0.0219, 0.0303, 0.1395, 0.3519,
        0.0289, 0.1877, 0.0337], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:13,496][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([3.5158e-04, 1.2066e-03, 2.7371e-03, 9.7704e-02, 7.1015e-03, 1.4238e-02,
        6.4636e-02, 4.1542e-02, 4.0658e-01, 1.1027e-02, 1.2345e-01, 2.2942e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:13,497][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([2.8960e-04, 7.3059e-08, 6.3151e-06, 1.7109e-02, 6.3875e-05, 6.7369e-02,
        4.5764e-02, 4.1100e-02, 6.4669e-01, 6.0790e-02, 5.0174e-03, 1.1581e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:13,499][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([1.4872e-04, 5.5204e-05, 2.6705e-03, 1.6013e-02, 4.2829e-02, 8.2376e-02,
        1.4939e-01, 3.7418e-02, 3.2926e-01, 2.4232e-02, 7.8608e-02, 2.3700e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:13,500][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([1.1613e-05, 1.2955e-03, 7.2640e-03, 1.2598e-02, 1.1652e-02, 4.5454e-02,
        1.2213e-01, 1.3756e-02, 2.4462e-01, 5.6312e-03, 3.2551e-01, 2.1008e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:13,501][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([1.6161e-03, 2.2379e-04, 7.3339e-04, 3.7881e-02, 2.8534e-02, 4.1107e-02,
        8.8809e-02, 1.8131e-02, 2.9258e-01, 5.5578e-03, 3.0748e-01, 1.7734e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:13,501][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0047, 0.0070, 0.0046, 0.0139, 0.0343, 0.0338, 0.1175, 0.0683, 0.4264,
        0.0409, 0.1460, 0.1025], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:13,501][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([1.6611e-03, 6.3861e-05, 6.3261e-04, 1.3164e-02, 1.7839e-03, 2.4531e-02,
        5.1778e-02, 9.9544e-02, 1.6619e-01, 2.6342e-01, 2.1533e-01, 1.6190e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:13,502][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([9.1730e-05, 2.1801e-03, 4.9499e-03, 2.9084e-03, 4.4788e-03, 1.7237e-02,
        6.9977e-02, 8.0047e-03, 3.4639e-01, 1.2260e-03, 5.0561e-01, 3.6943e-02],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:13,502][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([1.1912e-02, 7.1255e-06, 6.4746e-05, 5.8123e-02, 5.6712e-04, 3.2426e-02,
        1.3675e-02, 4.1835e-02, 3.4316e-01, 2.4360e-01, 3.3194e-02, 2.2143e-01],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:13,503][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([8.1374e-04, 8.7356e-05, 3.3275e-04, 1.2298e-02, 7.5090e-04, 5.6173e-02,
        7.2334e-02, 1.2741e-03, 6.7405e-01, 3.7622e-02, 6.5110e-02, 7.9158e-02],
       device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a]
[2024-07-24 10:20:13,504][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ computer] are: tensor([1.8722e-02, 3.3508e-04, 1.2447e-02, 2.3563e-02, 4.3630e-03, 1.2337e-01,
        8.7591e-02, 3.8859e-02, 3.8930e-01, 1.9139e-02, 4.4114e-02, 1.3756e-01,
        1.0064e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:13,507][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ computer] are: tensor([0.0083, 0.0074, 0.0047, 0.0186, 0.0281, 0.0206, 0.0246, 0.2423, 0.4657,
        0.0077, 0.0934, 0.0177, 0.0610], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:13,507][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ computer] are: tensor([5.1474e-05, 3.4535e-04, 2.4796e-03, 2.4831e-02, 2.9430e-03, 8.4179e-03,
        2.2556e-02, 2.5885e-02, 4.9554e-01, 4.0206e-03, 8.4146e-02, 1.1646e-01,
        2.1232e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:13,508][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ computer] are: tensor([3.1441e-04, 3.6323e-07, 1.5773e-05, 4.3754e-02, 3.5430e-04, 1.1139e-01,
        5.1192e-02, 9.0203e-02, 5.1434e-01, 3.9632e-02, 1.0960e-02, 9.2514e-02,
        4.5332e-02], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:13,508][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ computer] are: tensor([6.4612e-05, 4.7988e-05, 2.2480e-03, 9.0286e-03, 1.8807e-02, 5.2634e-02,
        8.0069e-02, 5.2508e-02, 3.5254e-01, 1.8146e-02, 4.8039e-02, 1.1127e-01,
        2.5460e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:13,508][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ computer] are: tensor([1.6924e-05, 2.6833e-04, 2.6358e-03, 6.1467e-03, 9.1784e-03, 2.6355e-02,
        6.8075e-02, 8.3253e-02, 3.3240e-01, 3.7207e-03, 2.8378e-01, 1.1065e-01,
        7.3511e-02], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:13,509][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ computer] are: tensor([5.2211e-04, 3.0611e-04, 1.0895e-03, 1.5367e-02, 1.4891e-02, 4.0802e-02,
        6.1692e-02, 1.4463e-02, 4.6210e-01, 1.8873e-03, 2.2589e-01, 1.2283e-01,
        3.8149e-02], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:13,509][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ computer] are: tensor([0.0058, 0.0135, 0.0065, 0.0099, 0.0202, 0.0216, 0.0730, 0.0452, 0.4027,
        0.0172, 0.1338, 0.0508, 0.2000], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:13,511][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ computer] are: tensor([8.5272e-04, 1.0832e-04, 5.6540e-04, 8.5927e-03, 1.0954e-03, 2.5491e-02,
        2.6154e-02, 1.1496e-01, 7.8389e-02, 3.9760e-01, 1.6057e-01, 6.3911e-02,
        1.2170e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:13,513][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ computer] are: tensor([2.4760e-05, 8.2799e-04, 3.4807e-03, 9.9064e-04, 1.2724e-03, 1.3733e-02,
        3.6922e-02, 1.2687e-02, 5.9848e-01, 6.3465e-04, 2.9616e-01, 1.5336e-02,
        1.9448e-02], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:13,516][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ computer] are: tensor([1.1445e-02, 1.2158e-05, 3.6626e-05, 6.9221e-02, 7.2522e-04, 1.2366e-02,
        4.5580e-03, 1.1122e-01, 1.3053e-01, 1.5647e-01, 2.4738e-02, 8.4537e-02,
        3.9413e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:13,517][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ computer] are: tensor([4.4962e-04, 7.0100e-05, 3.2011e-04, 2.5352e-02, 8.1846e-04, 3.5534e-02,
        4.8679e-02, 1.8028e-03, 7.0880e-01, 1.4020e-02, 6.7409e-02, 5.3710e-02,
        4.3032e-02], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer]
[2024-07-24 10:20:13,517][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0891, 0.0004, 0.0044, 0.0312, 0.0041, 0.0457, 0.0656, 0.0531, 0.2670,
        0.0266, 0.0471, 0.1336, 0.1156, 0.1164], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:13,518][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0316, 0.0258, 0.0050, 0.0425, 0.0356, 0.0164, 0.0287, 0.1485, 0.4061,
        0.0214, 0.1185, 0.0213, 0.0632, 0.0355], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:13,518][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([9.8795e-05, 5.9505e-04, 2.4150e-03, 3.3818e-02, 2.5898e-03, 1.0371e-02,
        4.0550e-02, 2.0559e-02, 4.4640e-01, 4.6513e-03, 6.5187e-02, 1.0320e-01,
        2.0446e-01, 6.5097e-02], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:13,519][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([3.5971e-04, 1.4823e-07, 3.8009e-06, 7.4122e-03, 6.0479e-05, 1.7788e-02,
        1.6590e-02, 1.5577e-02, 1.8911e-01, 1.8593e-02, 2.8651e-03, 4.1039e-02,
        3.5805e-02, 6.5480e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:13,519][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([4.3628e-05, 1.4227e-05, 9.4729e-04, 6.1473e-03, 8.6687e-03, 3.6459e-02,
        6.8038e-02, 1.6398e-02, 2.8044e-01, 1.7956e-02, 3.2208e-02, 1.0481e-01,
        1.9504e-01, 2.3284e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:13,519][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([7.0994e-06, 2.5035e-04, 3.5481e-03, 7.0564e-03, 5.4264e-03, 2.7921e-02,
        8.3901e-02, 2.0872e-02, 3.4644e-01, 3.7258e-03, 1.7881e-01, 1.5415e-01,
        4.0811e-02, 1.2708e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:13,520][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0013, 0.0004, 0.0008, 0.0409, 0.0183, 0.0306, 0.0660, 0.0089, 0.3358,
        0.0034, 0.1771, 0.1351, 0.0486, 0.1327], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:13,523][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0039, 0.0050, 0.0023, 0.0076, 0.0201, 0.0182, 0.0720, 0.0320, 0.3705,
        0.0211, 0.1188, 0.0663, 0.1674, 0.0949], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:13,524][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([3.8729e-03, 1.2277e-04, 5.0119e-04, 9.8830e-03, 1.7016e-03, 1.6959e-02,
        3.7377e-02, 8.9234e-02, 9.5741e-02, 2.1510e-01, 1.0351e-01, 9.8285e-02,
        1.0753e-01, 2.2018e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:13,524][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([3.1036e-05, 1.2092e-03, 3.9248e-03, 2.8201e-03, 2.6027e-03, 1.7465e-02,
        4.7860e-02, 5.3084e-03, 4.8230e-01, 8.6167e-04, 3.7745e-01, 2.4485e-02,
        1.2765e-02, 2.0916e-02], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:13,525][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([2.1631e-02, 1.3384e-05, 3.0612e-05, 3.1425e-02, 1.4135e-04, 6.7732e-03,
        2.6317e-03, 2.3032e-02, 6.3808e-02, 6.7671e-02, 5.9649e-03, 2.9998e-02,
        6.5893e-02, 6.8099e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:13,525][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([2.0270e-03, 4.1703e-04, 4.0759e-04, 1.7198e-02, 3.4745e-04, 3.1055e-02,
        5.0279e-02, 7.6985e-04, 6.2933e-01, 1.5773e-02, 3.6277e-02, 1.9762e-02,
        1.9234e-02, 1.7713e-01], device='cuda:0') for source tokens [After Benjamin and Alexander went to the station, Benjamin gave a computer to]
[2024-07-24 10:20:13,527][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:20:13,528][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[679],
        [ 14],
        [130],
        [  3],
        [531],
        [ 13],
        [ 22],
        [416],
        [ 15],
        [  7],
        [199],
        [ 10],
        [115],
        [  1]], device='cuda:0')
[2024-07-24 10:20:13,530][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[753],
        [ 14],
        [131],
        [  2],
        [558],
        [ 20],
        [ 27],
        [391],
        [ 17],
        [ 11],
        [189],
        [ 17],
        [122],
        [  6]], device='cuda:0')
[2024-07-24 10:20:13,532][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[3351],
        [9376],
        [4273],
        [2167],
        [1634],
        [1466],
        [1766],
        [1461],
        [1843],
        [1890],
        [2061],
        [2388],
        [2516],
        [2728]], device='cuda:0')
[2024-07-24 10:20:13,533][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[  530],
        [ 7480],
        [ 7382],
        [10906],
        [ 9031],
        [ 6696],
        [ 5070],
        [ 5613],
        [10594],
        [ 7367],
        [ 6159],
        [ 5368],
        [ 4809],
        [ 4157]], device='cuda:0')
[2024-07-24 10:20:13,534][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[18536],
        [ 6729],
        [28060],
        [  147],
        [20723],
        [ 1520],
        [11682],
        [27781],
        [20136],
        [33404],
        [22582],
        [31678],
        [38682],
        [39063]], device='cuda:0')
[2024-07-24 10:20:13,535][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[22525],
        [38527],
        [36766],
        [44548],
        [43957],
        [39021],
        [34737],
        [30772],
        [28383],
        [26453],
        [25123],
        [24815],
        [21143],
        [18683]], device='cuda:0')
[2024-07-24 10:20:13,537][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[ 6526],
        [ 9269],
        [11254],
        [10746],
        [ 9172],
        [11550],
        [16442],
        [15250],
        [16165],
        [13986],
        [16488],
        [16522],
        [16391],
        [16718]], device='cuda:0')
[2024-07-24 10:20:13,538][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[47137],
        [26944],
        [27794],
        [21606],
        [26371],
        [26941],
        [28541],
        [29139],
        [28366],
        [28805],
        [26156],
        [26751],
        [27394],
        [27971]], device='cuda:0')
[2024-07-24 10:20:13,541][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[10822],
        [ 9589],
        [ 4165],
        [ 7502],
        [ 3319],
        [ 3787],
        [ 3507],
        [ 3955],
        [ 3373],
        [ 3135],
        [ 2166],
        [ 2492],
        [ 2769],
        [ 2726]], device='cuda:0')
[2024-07-24 10:20:13,541][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[43737],
        [ 5035],
        [ 7749],
        [ 2895],
        [ 9443],
        [ 8264],
        [15532],
        [19403],
        [13176],
        [13154],
        [13057],
        [13522],
        [18546],
        [18920]], device='cuda:0')
[2024-07-24 10:20:13,542][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[ 5080],
        [28448],
        [29117],
        [36975],
        [24515],
        [25589],
        [23022],
        [29185],
        [23044],
        [30589],
        [21750],
        [23044],
        [27754],
        [23784]], device='cuda:0')
[2024-07-24 10:20:13,543][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[34202],
        [25803],
        [44362],
        [45357],
        [36211],
        [38676],
        [37398],
        [38130],
        [32505],
        [33498],
        [33262],
        [33509],
        [32741],
        [33052]], device='cuda:0')
[2024-07-24 10:20:13,545][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[9476],
        [4290],
        [2546],
        [   1],
        [   1],
        [ 108],
        [ 180],
        [   8],
        [  35],
        [  24],
        [ 390],
        [ 306],
        [  64],
        [ 653]], device='cuda:0')
[2024-07-24 10:20:13,546][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[29316],
        [30364],
        [37151],
        [41839],
        [40266],
        [33796],
        [30995],
        [36645],
        [37909],
        [37991],
        [37599],
        [36603],
        [35291],
        [34734]], device='cuda:0')
[2024-07-24 10:20:13,549][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 7297],
        [ 6649],
        [ 5133],
        [10140],
        [ 9390],
        [ 7412],
        [ 7139],
        [ 6249],
        [ 7665],
        [ 7629],
        [ 9312],
        [ 7369],
        [ 8545],
        [ 7745]], device='cuda:0')
[2024-07-24 10:20:13,550][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[11214],
        [ 4460],
        [11161],
        [ 8740],
        [ 8242],
        [ 7690],
        [ 9385],
        [ 9969],
        [10196],
        [ 9503],
        [ 9890],
        [ 9773],
        [ 9553],
        [ 8833]], device='cuda:0')
[2024-07-24 10:20:13,551][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[14981],
        [16892],
        [16674],
        [15618],
        [11679],
        [13064],
        [11667],
        [ 5442],
        [ 7234],
        [ 7554],
        [ 9511],
        [ 9842],
        [ 7607],
        [ 8994]], device='cuda:0')
[2024-07-24 10:20:13,552][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[27451],
        [ 6014],
        [22500],
        [18669],
        [31877],
        [24695],
        [29939],
        [28604],
        [22241],
        [23855],
        [22283],
        [23466],
        [22880],
        [24008]], device='cuda:0')
[2024-07-24 10:20:13,553][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[7423],
        [2952],
        [2799],
        [1825],
        [1697],
        [2676],
        [2168],
        [2248],
        [2301],
        [2245],
        [2291],
        [2221],
        [2228],
        [2880]], device='cuda:0')
[2024-07-24 10:20:13,555][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[6226],
        [5868],
        [ 794],
        [3281],
        [2785],
        [1239],
        [2996],
        [3011],
        [2343],
        [2490],
        [2674],
        [2690],
        [3093],
        [3276]], device='cuda:0')
[2024-07-24 10:20:13,557][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[1575],
        [4534],
        [6933],
        [4594],
        [4212],
        [4222],
        [3966],
        [4238],
        [6114],
        [6054],
        [6458],
        [6658],
        [6567],
        [6223]], device='cuda:0')
[2024-07-24 10:20:13,558][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[ 1956],
        [ 3873],
        [15176],
        [ 9991],
        [25975],
        [19314],
        [22290],
        [19823],
        [14552],
        [16603],
        [19725],
        [22477],
        [20266],
        [21256]], device='cuda:0')
[2024-07-24 10:20:13,559][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[10503],
        [ 1427],
        [ 2805],
        [ 3706],
        [ 6781],
        [ 6132],
        [ 6382],
        [ 6325],
        [ 6729],
        [ 6165],
        [ 6111],
        [ 6104],
        [ 6249],
        [ 6363]], device='cuda:0')
[2024-07-24 10:20:13,560][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[16207],
        [14350],
        [ 7095],
        [11487],
        [ 6291],
        [ 6113],
        [ 6351],
        [ 5417],
        [ 6367],
        [ 6525],
        [ 6774],
        [ 6506],
        [ 6909],
        [ 5825]], device='cuda:0')
[2024-07-24 10:20:13,562][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[2749],
        [4502],
        [1196],
        [1041],
        [1370],
        [1544],
        [2057],
        [2088],
        [1693],
        [1836],
        [1866],
        [1979],
        [1826],
        [1890]], device='cuda:0')
[2024-07-24 10:20:13,563][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[ 3740],
        [23326],
        [14763],
        [20106],
        [21017],
        [18031],
        [16638],
        [ 8772],
        [ 8129],
        [13292],
        [10034],
        [10604],
        [ 8018],
        [10290]], device='cuda:0')
[2024-07-24 10:20:13,565][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[2064],
        [5839],
        [3730],
        [6502],
        [6259],
        [3102],
        [4372],
        [4521],
        [4646],
        [4818],
        [4850],
        [4795],
        [4842],
        [4305]], device='cuda:0')
[2024-07-24 10:20:13,566][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[37467],
        [38585],
        [37449],
        [37064],
        [32595],
        [36529],
        [35075],
        [38024],
        [37945],
        [36464],
        [35735],
        [35077],
        [36872],
        [35326]], device='cuda:0')
[2024-07-24 10:20:13,567][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[34786],
        [37199],
        [39216],
        [38595],
        [37744],
        [39389],
        [38937],
        [40440],
        [38441],
        [38933],
        [37230],
        [38878],
        [37658],
        [37816]], device='cuda:0')
[2024-07-24 10:20:13,568][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[5013],
        [5013],
        [5013],
        [5013],
        [5013],
        [5013],
        [5013],
        [5013],
        [5013],
        [5013],
        [5013],
        [5013],
        [5013],
        [5013]], device='cuda:0')
